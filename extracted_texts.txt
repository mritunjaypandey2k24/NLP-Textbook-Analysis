c∝⌋ir⌋l⌉⌋o√yrtA. Kshemkalyaniand M.Singhal,2005
Limitedcirculationwithinaclassroom,afterseeking perm issionfromauthors.
1
DISTRIBUTED COMPUTING:
PRINCIPLES,ALGORITHMS, and SYSTEMS
Ajay D. Kshemkalyani
Departmentof ComputerScience
Universityof Illinois atChicago
Chicago,IL 60607MukeshSinghal
Department ofComputerScience
University of Kentucky
Lexington,KY 40506
January29,2007
“To myfatherShri Digambarand mymotherShrimatiVimala.”
-Ajay D. Kshemkalyani
“To mymotherChandraPrabha Singhal,my fatherBrij MohanSi nghal,
and mydaughtersMeenakshi,Malvika,and Priyanka.“
-MukeshSinghal
i
Preface
Background
TheﬁeldofDistributedComputingcovers“ allaspectsofcomputingandinformationaccessacross
multipleprocessingelementsconnectedbyanyformofcommu nicationnetworks,whetherlocalor
wide-area in the coverage ”. Since the advent of the Internet in the 1970s, there has bee n a steady
growth of new applications requiring distributed processi ng. This was enabled by advances in
networking and hardware technology, falling cost of hardwa re, and greater end-user awareness.
Thesefactorscontributedtomakingdistributedcomputing acost-effective,high-performance,and
fault-tolerant reality. Around the turn of the millenium, t here has been an explosivegrowth in the
expansionandefﬁciencyoftheInternet,andamatchingoutr eachofaccesstonetworkedresources
throughtheWorldWideWeb,allacrosstheworld. Coupledwit hanequallydramaticgrowthinthe
wireless and mobile networking areas, and plummeting price s of bandwidth and storage devices,
wearewitnessingarapidspurtindistributedapplications andanaccompanyinginterestintheﬁeld
ofdistributedcomputingin universities,governmentsorg anizations,andprivateinstitutions.
Advances in hardware technology have suddenly made sensor n etworking a reality, and em-
bedded and sensornetworks are rapidlybecoming an integral part of each person’slife– from the
homenetwork with the interconnected gadgets to the automob ilecommunicatingby GPS (Global
Positioning System), to the fully networked ofﬁce with RFID monitoring. In the emerging global
village, distributed computing will be the centerpiece of a ll computing and information access
sub-disciplines within computer science. Clearly, this is a very important ﬁeld. Moreover, this
evolving ﬁeld is characterized by a diverse range of challen ges for which the solutions need to
havefoundationsonsolidprinciples.
The ﬁeld of distributed computing is very important, and the re is a huge demand for a good
comprehensivebook. Thebookcomprehensivelycoversallim portanttopicsinagreatdepth. This
book providesboth the depth and thebreadth of coverageof to picsin conjunctionwith theclarity
of explanation and ease of understanding. The book will be pa rticularly valuable to the academic
communityandthecomputerindustryatlarge. Writingsucha comprehensivebookisanherculean
task and isa hugeundertaking. Thereis adeep senseof satisf actionin knowingthat wewere able
completethismajortask andperform thisserviceto thecomm unity.
Description, Approach, and Features
The book will focus on fundamental principles and models und erlying all aspects of distributed
computing. The book will address the principles underlying the theory, algorithms, and systems
aspects of distributed computing. The manner of presentati on of the algorithms is very lucid, ex-
plaining the main ideas and the intuition with ﬁgures and sim ple explanations rather than getting
entangled in intimidating notations and lengthy and hard-t o-follow rigorous proofs of the algo-
rithms. The selection of chapter themes is broad and compreh ensive, and the book covers all im-
portanttopicsindepth. Theselectionofalgorithmswithin each chapterhasbeendonecarefullyto
elucidate new and important techniques of algorithm design . Although the book focuses on foun-
dational aspects and algorithms for distributed computing , it thoroughly addresses all practical
systems-like problems (e.g., mutual exclusion, deadlock d etection, termination detection, failure
ii
recovery, authentication, global state and time, etc.) by p resenting the theory behind and algo-
rithms for such problems. The book is written keeping in mind the impact of emerging topics
such aspeer-to-peer computing andnetwork security on the foundational aspects of distributed
computing.
Chapters of the book includeﬁgures, examples, exercise pro blems, a summary, and bibliogra-
phy/references. AnIndex includestheindexterms.
Readership
Thisbookis aimedas atextbookfor
•Graduate students and Senior level undergraduate students in Computer Science and Com-
puterEngineering.
•Graduate students in Electrical Engineering and Mathemati cs. As wireless networks, peer-
to-peernetworks,andmobilecomputingcontinuetogrowini mportance,anincreasingnum-
berofstudentsfrom Electrical EngineeringDepartmentswi llalso ﬁnd thisbooknecessary.
•Practitioners,systemsdesigners/programmers,and consu ltantsinindustryandresearch labs
willﬁndthebookaveryusefulreferencebecauseitwillcont ainthestateoftheartalgorithms
and principles to address various design issues in distribu ted systems, as well as the latest
references.
The breadth and depth of coverage, accompanied by clarity of explanation and ease of under-
standingthatthebookofferswillmakeitavery widelyadopt edtextbook.
Hard and softprerequisitesfor theuseofthisbookinclude
•An undergraduatecoursein algorithmsisrequired.
•Undergraduatecourses inoperatingsystemsandcomputerne tworkswouldbeuseful.
•A reasonablefamiliaritywithprogramming.
We have aimed for a very comprehensive book that will be the si ngle source that covers dis-
tributedcomputingmodelsandalgorithms. Thebookwillhav ebothdepthandbreadthofcoverage
oftopics,andwillbecharacterized byclearandeasyexplan ations. Noneoftheexistingtextbooks
on distributedcomputingprovidesall ofthesefeatures.
Acknowledgements
ThisbookgrewfromthenotesusedinthegraduatecoursesonD istributedComputingat theOhio
State University, the University of Illinois at Chicago and at University of Kentucky. We would
liketothankthegraduatestudentsatboththeseschoolsfor theircontributionstothebookinmany
ways.
The book is based on the published research results of numero us researchers in the ﬁeld. We
havemadealleffortstopresentthematerialinourlanguage andhavegivencredittooriginalsource
of the information. We would like to thank all researchers wh ose work has been reported in this
book. Finally,wewouldliketo thankthestaffoftheCambrid geUniversityPress forprovidingus
withan excellentsupportforpublicationofthebook.
iii
Accessto Resources
Thefollowingwebsiteswillbemaintainedforthebook. Anye rrorsandcommentsshouldbesent
to ajayk@cs.uic.edu or singhal@cs.uky.edu. Further infor mation about the book can be obtained
from authors’web pages.
•http://www.cs.uic.edu/ ∼ajayk/DCS-Book
•http://www.cs.uky.edu/ ∼singhal/DCS-Book
Ajay D.Kshemkalyani
MukeshSinghal
iv
Contents
1 Introduction 1
1.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Relationto ComputerSystemComponents . . . . . . . . . . . . . . . . . . . . . . 2
1.3 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.4 Relationto ParallelMultiprocessor/MulticomputerSy stems . . . . . . . . . . . . . 5
1.4.1 Characteristics ofParallel Systems . . . . . . . . . . . . . . . . . . . . . . 5
1.4.2 Flynn’sTaxonomy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 0
1.4.3 Coupling,Parallelism,Concurrency,and Granularit y . . . . . . . . . . . . 10
1.5 MessagePassingSystemsversusShared MemorySystems . . . . . . . . . . . . . 13
1.5.1 Emulatingmessage-passingonshared memorysystem( MP→SM). . . . 13
1.5.2 Emulatingshared memoryon amessage-passingsystem( SM→MP). . . 13
1.6 PrimitivesforDistributedCommunication . . . . . . . . . . . . . . . . . . . . . . 14
1.6.1 Blocking/Nonblocking,Synchronous/AsynchronousP rimitives . . . . . . 14
1.6.2 Processor Synchrony . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.6.3 Libraries and Standards . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.7 SynchronousversusAsynchronousExecutions . . . . . . . . . . . . . . . . . . . 18
1.7.1 Emulatingan asynchronoussystembyasynchronoussys tem(A→S). . . 19
1.7.2 Emulatinga synchronoussystembyan asynchronoussys tem(S→A). . . 19
1.7.3 Emulations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 0
1.8 DesignIssuesand Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
1.8.1 DistributedSystemsChallengesfrom aSystemPerspec tive . . . . . . . . . 21
1.8.2 AlgorithmicChallenges inDistributedComputing . . . . . . . . . . . . . 22
1.8.3 ApplicationsofDistributedComputingand NewerChal lenges . . . . . . . 28
1.9 Selectionand CoverageofTopics. . . . . . . . . . . . . . . . . . . . . . . . . . . 30
1.10 ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
1.11 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
1.12 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
2 A Model ofDistributed Computations 37
2.1 ADistributedProgram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
2.2 AModelofDistributedExecutions . . . . . . . . . . . . . . . . . . . . . . . . . . 38
2.3 ModelsofCommunicationNetwork . . . . . . . . . . . . . . . . . . . . . . . . . 40
2.4 GlobalStateofaDistributedSystem . . . . . . . . . . . . . . . . . . . . . . . . . 40
2.4.1 GlobalState . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1
2.5 CutsofaDistributedComputation . . . . . . . . . . . . . . . . . . . . . . . . . . 42
v
2.6 Pastand FutureCones ofan Event . . . . . . . . . . . . . . . . . . . . . . . . . . 43
2.7 ModelsofProcess Communications . . . . . . . . . . . . . . . . . . . . . . . . . 44
3 Logical Time 47
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
3.2 AFramework foraSystem ofLogicalClocks . . . . . . . . . . . . . . . . . . . . 48
3.2.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
3.2.2 ImplementingLogical Clocks . . . . . . . . . . . . . . . . . . . . . . . . 49
3.3 ScalarTime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.3.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.3.2 Basic Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
3.4 VectorTime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
3.4.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
3.4.2 Basic Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
3.4.3 On theSizeofVectorClocks . . . . . . . . . . . . . . . . . . . . . . . . . 54
3.5 EfﬁcientImplementationsofVectorClocks . . . . . . . . . . . . . . . . . . . . . 56
3.5.1 Singhal-Kshemkalyani’sDifferentialTechnique . . . . . . . . . . . . . . . 56
3.5.2 Fowler-Zwaenepoel’sDirect-Dependency Technique . . . . . . . . . . . . 58
3.6 Jard-Jourdan’sAdaptiveTechnique . . . . . . . . . . . . . . . . . . . . . . . . . . 60
3.7 MatrixTime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
3.7.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
3.7.2 Basic Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
3.8 VirtualTime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
3.8.1 Virtual TimeDeﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
3.8.2 ComparisonwithLamport’sLogicalClocks . . . . . . . . . . . . . . . . . 66
3.8.3 TimeWarp Mechanism . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 7
3.8.4 TheLocal ControlMechanism . . . . . . . . . . . . . . . . . . . . . . . . 67
3.8.5 GlobalControl Mechanism . . . . . . . . . . . . . . . . . . . . . . . . . . 69
3.8.6 An Example: DistributedDiscreteEventSimulations . . . . . . . . . . . . 71
3.9 PhysicalClock Synchronization: NTP . . . . . . . . . . . . . . . . . . . . . . . . 72
3.9.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
3.9.2 Deﬁnitionsand Terminology . . . . . . . . . . . . . . . . . . . . . . . . . 73
3.9.3 Clock Inaccuracies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
3.10 ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
3.11 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
3.12 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
4 GlobalState andSnapshot Recording Algorithms 82
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
4.2 SystemModeland Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.2.1 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.2.2 A ConsistentGlobalState . . . . . . . . . . . . . . . . . . . . . . . . . . 85
4.2.3 Interpretation inTermsofCuts . . . . . . . . . . . . . . . . . . . . . . . . 86
4.2.4 Issues inRecording aGlobalState . . . . . . . . . . . . . . . . . . . . . . 86
4.3 SnapshotAlgorithmsforFIFO Channels . . . . . . . . . . . . . . . . . . . . . . . 87
vi
4.3.1 Chandy-Lamport Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 87
4.3.2 Properties oftheRecorded Global State . . . . . . . . . . . . . . . . . . . 89
4.4 VariationsoftheChandy-LamportAlgorithm . . . . . . . . . . . . . . . . . . . . 91
4.4.1 Spezialetti-Kearns Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 91
4.4.2 Venkatesan’sIncremental SnapshotAlgorithm . . . . . . . . . . . . . . . 92
4.4.3 Helary’s WaveSynchronizationMethod . . . . . . . . . . . . . . . . . . . 93
4.5 SnapshotAlgorithmsforNon-FIFO Channels . . . . . . . . . . . . . . . . . . . . 94
4.5.1 Lai-Yang Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
4.5.2 Li et al.’sAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
4.5.3 Mattern’sAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
4.6 SnapshotsinaCausal DeliverySystem . . . . . . . . . . . . . . . . . . . . . . . . 98
4.6.1 Process StateRecording . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
4.6.2 Channel StateRecording in Acharya-Badrinath Algori thm . . . . . . . . . 99
4.6.3 Channel StateRecording in Alagar-VenkatesanAlgori thm . . . . . . . . . 100
4.7 MonitoringGlobalState . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
4.8 Necessary and SufﬁcientConditionsforConsistentGlob al Snapshots . . . . . . . 102
4.8.1 Zigzag Pathsand ConsistentGlobalSnapshots . . . . . . . . . . . . . . . 103
4.9 FindingConsistentGlobalSnapshotsin aDistributedCo mputation . . . . . . . . . 106
4.9.1 FindingConsistentGlobalSnapshots . . . . . . . . . . . . . . . . . . . . 106
4.9.2 Manivannan-Netzer-SinghalAlgorithmforEnumerati ngConsistentSnap-
shots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
4.9.3 FindingZ-paths inaDistributedComputation . . . . . . . . . . . . . . . . 110
4.10 ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
4.11 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
4.12 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
5 Terminology and BasicAlgorithms 118
5.1 TopologyAbstractionandOverlays . . . . . . . . . . . . . . . . . . . . . . . . . 118
5.2 ClassiﬁcationsandBasic Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . 120
5.2.1 ApplicationExecutionsand ControlAlgorithmExecut ions . . . . . . . . . 120
5.2.2 Centralized andDistributedAlgorithms . . . . . . . . . . . . . . . . . . . 120
5.2.3 SymmetricandAsymmetricAlgorithms . . . . . . . . . . . . . . . . . . . 121
5.2.4 AnonymousAlgorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
5.2.5 UniformAlgorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
5.2.6 AdaptiveAlgorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
5.2.7 DeterministicVersusNondeterministicExecutions . . . . . . . . . . . . . 122
5.2.8 ExecutionInhibition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
5.2.9 Synchronous andAsynchronousSystems . . . . . . . . . . . . . . . . . . 124
5.2.10 OnlineversusOfﬂineAlgorithms . . . . . . . . . . . . . . . . . . . . . . 124
5.2.11 FailureModels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
5.2.12 Wait-free algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
5.2.13 CommunicationChannels . . . . . . . . . . . . . . . . . . . . . . . . . . 126
5.3 ComplexityMeasuresand Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . 127
5.4 Program Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
5.5 ElementaryGraph Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
vii
5.5.1 Synchronous Single-Initiator Spanning Tree Algorit hm Using Flooding:
Algorithm0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
5.5.2 Asynchronous Single-Initiator Spanning Tree Algori thm Using Flooding:
AlgorithmI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
5.5.3 AsynchronousConcurrent-InitiatorSpanningTreeAl gorithmUsingFlood-
ing: AlgorithmII . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
5.5.4 Asynchronous Concurrent-Initiator Depth First Sear ch Spanning Tree Al-
gorithm: AlgorithmIII . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
5.5.5 Broadcast andConvergecast on aTree . . . . . . . . . . . . . . . . . . . . 137
5.5.6 SingleSource ShortestPath Algorithm: SynchronousB ellman-Ford . . . . 140
5.5.7 DistanceVectorRouting . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
5.5.8 SingleSource ShortestPath Algorithm: Asynchronous Bellman-Ford . . . 141
5.5.9 All Sources ShortestPaths: AsynchronousDistribute dFloyd-Warshall . . . 142
5.5.10 Asynchronous and Synchronous Constrained Flooding (w/o a Spanning
Tree) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
5.5.11 MinimumWeightSpanningTree(MST)AlgorithminaSyn chronousSystem146
5.5.12 MinimumWeightSpanningTree(MST)in an Asynchronou sSystem . . . 152
5.6 Synchronizers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
5.7 MaximalIndependent Set (MIS) . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
5.8 Connected DominatingSet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
5.9 CompactRoutingTables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
5.10 LeaderElection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
5.11 Challengesin DesigningDistributedGraph Algorithms . . . . . . . . . . . . . . . 164
5.12 ObjectReplicationProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
5.12.1 Problem Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
5.12.2 AlgorithmOutline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
5.12.3 Reads and Writes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
5.12.4 Convergingto an ReplicationScheme . . . . . . . . . . . . . . . . . . . . 167
5.13 ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
5.14 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
5.15 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
6 MessageOrdering and GroupCommunication 179
6.1 MessageOrdering Paradigms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
6.1.1 AsynchronousExecutions . . . . . . . . . . . . . . . . . . . . . . . . . . 180
6.1.2 FIFO Executions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 80
6.1.3 Causally Ordered (CO) Executions . . . . . . . . . . . . . . . . . . . . . 181
6.1.4 Synchronous Execution(SYNC) . . . . . . . . . . . . . . . . . . . . . . . 184
6.2 AsynchronousExecutionwithSynchronous Communicatio n . . . . . . . . . . . . 184
6.2.1 ExecutionsRealizablewithSynchronousCommunicati on(RSC) . . . . . . 185
6.2.2 Hierarchy ofOrdering Paradigms . . . . . . . . . . . . . . . . . . . . . . 188
6.2.3 Simulations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 89
6.3 SynchronousProgram Orderon anAsynchronousSystem . . . . . . . . . . . . . . 190
6.3.1 Rendezvous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 1
6.3.2 Algorithmfor Binary Rendezvous . . . . . . . . . . . . . . . . . . . . . . 192
viii
6.4 GroupCommunication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
6.5 Causal Order(CO) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
6.5.1 TheRaynal-Schiper-Toueg Algorithm . . . . . . . . . . . . . . . . . . . . 197
6.5.2 TheKshemkalyani-SinghalOptimalAlgorithm . . . . . . . . . . . . . . . 198
6.6 TotalOrder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
6.6.1 Centralized AlgorithmforTotalOrder . . . . . . . . . . . . . . . . . . . . 205
6.6.2 Three-Phase DistributedAlgorithm . . . . . . . . . . . . . . . . . . . . . 206
6.7 ANomenclatureForMulticast . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
6.8 PropagationTrees ForMulticast . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
6.9 ClassiﬁcationofApplication-LevelMulticastAlgorit hms . . . . . . . . . . . . . . 214
6.10 SemanticsofFault-TolerantGroupCommunication . . . . . . . . . . . . . . . . . 216
6.11 DistributedMulticastAlgorithmsAtTheNetwork Layer . . . . . . . . . . . . . . 218
6.11.1 ReversePath Forwarding(RPF) ForConstrained Flood ing . . . . . . . . . 219
6.11.2 Steiner Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
6.11.3 MulticastCostFunctions . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
6.11.4 Delay-Bounded SteinerTrees . . . . . . . . . . . . . . . . . . . . . . . . 221
6.11.5 Core-Based Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
6.12 ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223
6.13 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223
6.14 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224
7 Termination Detection 230
7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
7.2 SystemModelofaDistributedComputation . . . . . . . . . . . . . . . . . . . . . 231
7.3 TerminationDetectionUsingDistributedSnapshots . . . . . . . . . . . . . . . . . 232
7.3.1 Informal Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
7.3.2 Formal Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
7.3.3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3
7.4 TerminationDetectionby WeightThrowing . . . . . . . . . . . . . . . . . . . . . 234
7.4.1 Formal Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
7.4.2 Correctness oftheAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . 235
7.5 ASpanning-Tree-Based TerminationDetectionAlgorith m . . . . . . . . . . . . . 236
7.5.1 Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 6
7.5.2 A SimpleAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 36
7.5.3 TheCorrect Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
7.5.4 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
7.5.5 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 2
7.6 Message-OptimalTerminationDetection . . . . . . . . . . . . . . . . . . . . . . . 242
7.6.1 TheMainIdea . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
7.6.2 Formal DescriptionoftheAlgorithm . . . . . . . . . . . . . . . . . . . . 243
7.6.3 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 5
7.7 TerminationDetectionin aVery General DistributedCom putingModel . . . . . . 245
7.7.1 ModelDeﬁnitionand Assumptions . . . . . . . . . . . . . . . . . . . . . 246
7.7.2 Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 6
7.7.3 TerminationDeﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
ix
7.7.4 A StaticTerminationDetectionAlgorithm . . . . . . . . . . . . . . . . . . 247
7.7.5 A DynamicTerminationDetectionAlgorithm . . . . . . . . . . . . . . . . 249
7.8 TerminationDetectionin theAtomicComputationModel . . . . . . . . . . . . . . 251
7.8.1 TheAtomicModelofExecution . . . . . . . . . . . . . . . . . . . . . . . 252
7.8.2 A NaiveCountingMethod . . . . . . . . . . . . . . . . . . . . . . . . . . 252
7.8.3 TheFourCounterMethod . . . . . . . . . . . . . . . . . . . . . . . . . . 253
7.8.4 TheScepticAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
7.8.5 TheTimeAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 55
7.8.6 VectorCounters Method . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
7.8.7 A Channel CountingMethod . . . . . . . . . . . . . . . . . . . . . . . . . 258
7.9 TerminationDetectionin aFaultyDistributedSystem . . . . . . . . . . . . . . . . 260
7.9.1 Flow DetectingScheme . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
7.9.2 Taking Snapshots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
7.9.3 DescriptionoftheAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . 263
7.9.4 Performance Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
7.10 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
7.11 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
8 Reasoning withKnowledge 271
8.1 TheMuddyChildren Puzzle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
8.2 LogicofKnowledge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
8.2.1 KnowledgeOperators . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
8.2.2 TheMuddyChildren PuzzleAgain . . . . . . . . . . . . . . . . . . . . . 273
8.2.3 KripkeStructures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
8.2.4 MuddyChildren PuzzleusingKripkeStructures . . . . . . . . . . . . . . 275
8.2.5 Properties ofKnowledge . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
8.3 Knowledgein SynchronousSystems . . . . . . . . . . . . . . . . . . . . . . . . . 277
8.4 Knowledgein AsynchronousSystems . . . . . . . . . . . . . . . . . . . . . . . . 278
8.4.1 LogicandDeﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
8.4.2 Agreement inAsynchronousSystems . . . . . . . . . . . . . . . . . . . . 279
8.4.3 Variants ofCommonKnowledge . . . . . . . . . . . . . . . . . . . . . . . 280
8.4.4 Concurrent CommonKnowledge . . . . . . . . . . . . . . . . . . . . . . 281
8.5 KnowledgeTransfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
8.6 Knowledgeand Clocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
8.7 ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
8.8 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
8.9 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
9 Distributed Mutual ExclusionAlgorithms 293
9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
9.2 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
9.2.1 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
9.2.2 Requirements ofMutualExclusionAlgorithms . . . . . . . . . . . . . . . 294
9.2.3 Performance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
9.3 Lamport’sAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
x
9.4 Ricart-AgrawalaAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300
9.4.1 DescriptionoftheAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . 300
9.5 Singhal’sDynamicInformation-StructureAlgorithm . . . . . . . . . . . . . . . . 303
9.5.1 TheAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 5
9.5.2 Correctness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 07
9.5.3 Performance Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
9.5.4 AdaptivityinHeterogeneous TrafﬁcPatterns . . . . . . . . . . . . . . . . 309
9.6 Lodhaand Kshemkalyani’sFairMutualExclusionAlgorit hm . . . . . . . . . . . . 309
9.6.1 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
9.6.2 TheAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 0
9.6.3 Safety, Fairness andLiveness . . . . . . . . . . . . . . . . . . . . . . . . 313
9.6.4 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
9.6.5 MessageComplexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
9.7 Quorum-BasedMutualExclusionAlgorithms . . . . . . . . . . . . . . . . . . . . 316
9.8 Maekawa’sAlgorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
9.8.1 TheAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 7
9.8.2 Problem ofDeadlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318
9.9 Agarwal-ElAbbadiQuorum-Based Algorithm . . . . . . . . . . . . . . . . . . . . 320
9.9.1 Constructingatree-structured quorum . . . . . . . . . . . . . . . . . . . . 320
9.9.2 Analysisofthealgorithmforconstructingtree-stru ctured quorums . . . . . 321
9.9.3 Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 21
9.9.4 ExamplesofTree-Structured Quorums . . . . . . . . . . . . . . . . . . . 322
9.9.5 TheAlgorithmforDistributedMutualExclusion . . . . . . . . . . . . . . 323
9.9.6 Correctness proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
9.9.7 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
9.10 Token-Based Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
9.11 Suzuki-Kasami’sBroadcast Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 325
9.12 Raymond’sTree-Based Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 327
9.12.1 TheHOLDERVariables . . . . . . . . . . . . . . . . . . . . . . . . . . . 328
9.12.2 TheOperation oftheAlgorithm . . . . . . . . . . . . . . . . . . . . . . . 329
9.12.3 Correctness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333
9.12.4 Cost and Performance Analysis . . . . . . . . . . . . . . . . . . . . . . . 335
9.12.5 AlgorithmInitialization . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
9.12.6 NodeFailuresand Recovery . . . . . . . . . . . . . . . . . . . . . . . . . 336
9.13 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336
9.14 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
10 Deadlock Detection inDistributed Systems 342
10.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
10.2 SystemModel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
10.2.1 Wait-For-Graph (WFG) . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
10.3 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
10.3.1 Deadlock HandlingStrategies . . . . . . . . . . . . . . . . . . . . . . . . 343
10.3.2 Issues inDeadlock Detection . . . . . . . . . . . . . . . . . . . . . . . . . 344
10.4 ModelsofDeadlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
xi
10.4.1 TheSingleResourceModel . . . . . . . . . . . . . . . . . . . . . . . . . 345
10.4.2 TheAND Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346
10.4.3 TheORModel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346
10.4.4 TheAND-ORModel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 7
10.4.5 The/parenleftbigp
q/parenrightbig
Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
10.4.6 Unrestricted Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
10.5 Knapp’sClassiﬁcationofDistributedDeadlock Detect ionAlgorithms . . . . . . . 348
10.5.1 Path-PushingAlgorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 348
10.5.2 Edge-Chasing Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . 348
10.5.3 DiffusingComputationsBased Algorithms . . . . . . . . . . . . . . . . . 348
10.5.4 GlobalState DetectionBased Algorithms . . . . . . . . . . . . . . . . . . 349
10.6 Mitchelland Merritt’sAlgorithmfortheSingle-Resou rce Model . . . . . . . . . . 349
10.7 Chandy-Misra-HaasAlgorithmfortheAND Model . . . . . . . . . . . . . . . . . 352
10.8 Chandy-Misra-HaasAlgorithmfortheORModel . . . . . . . . . . . . . . . . . . 353
10.9 Kshemkalyani-SinghalAlgorithmforP-out-of-Q Model . . . . . . . . . . . . . . 355
10.9.1 Informal DescriptionoftheAlgorithm . . . . . . . . . . . . . . . . . . . . 357
10.9.2 TheAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 58
10.9.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361
10.10Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364
10.11BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
10.12ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
11 GlobalPredicate Detection 370
11.1 StableandUnstablePredicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
11.1.1 StablePredicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371
11.1.2 UnstablePredicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372
11.2 ModalitiesonPredicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373
11.2.1 ComplexityofPredicate Detection . . . . . . . . . . . . . . . . . . . . . . 374
11.3 Centralized AlgorithmforRelationalPredicates . . . . . . . . . . . . . . . . . . . 374
11.4 ConjunctivePredicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
11.4.1 Interval-based Centralized AlgorithmforConjunct ivePredicates . . . . . . 379
11.4.2 Global State based Centralized Algorithm for Possibly (φ), whereφis
conjunctive . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381
11.5 DistributedAlgorithmsforConjunctivePredicates . . . . . . . . . . . . . . . . . . 384
11.5.1 DistributedState-basedTokenAlgorithmfor Possibly (φ),whereφisCon-
junctive . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384
11.5.2 Distributed Interval-based Token Algorithm for Definitely (φ), whereφ
is Conjunctive . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
11.5.3 DistributedInterval-basedPiggybackingAlgorith mforPossibly (φ),where
φisConjunctive . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
11.6 FurtherClassiﬁcationofPredicates . . . . . . . . . . . . . . . . . . . . . . . . . . 393
11.7 ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394
11.8 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394
11.9 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
xii
12 Distributed Shared Memory 399
12.1 Abstractionand Advantages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399
12.2 MemoryConsistencyModels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 402
12.2.1 Strict consistency/Atomicconsistency/Lineariza bility . . . . . . . . . . . . 403
12.2.2 Sequential Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
12.2.3 Causal Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409
12.2.4 PRAM (PipelinedRAM)orProcessorConsistency . . . . . . . . . . . . . 411
12.2.5 Slow Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 2
12.2.6 Hierarchy ofConsistencyModels . . . . . . . . . . . . . . . . . . . . . . 413
12.2.7 OtherModelsbased onSynchronizationInstructions . . . . . . . . . . . . 414
12.3 Shared MemoryMutualExclusion . . . . . . . . . . . . . . . . . . . . . . . . . . 416
12.3.1 Lamport’sBakery Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 416
12.3.2 Lamport’sWRWRMechanismand FastMutualExclusion . . . . . . . . . 418
12.3.3 Hardware supportformutualexclusion . . . . . . . . . . . . . . . . . . . 421
12.4 Wait-freedom . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 422
12.5 RegisterHierarchy and Wait-freeSimulations . . . . . . . . . . . . . . . . . . . . 423
12.5.1 Construction1: SRSW Safe toMRSW Safe . . . . . . . . . . . . . . . . . 426
12.5.2 Construction2: SRSW Regularto MRSW Regular . . . . . . . . . . . . . 427
12.5.3 Construction3: Boolean MRSW Safe tointeger-valued MRSW Safe . . . . 427
12.5.4 Construction4: Boolean MRSW Safe tobooleanMRSW Reg ular . . . . . 427
12.5.5 Construction5: Boolean MRSW Regulartointeger-val uedMRSW Regular 428
12.5.6 Construction6: Boolean MRSW Regulartointeger-val uedMRSW Atomic 429
12.5.7 Construction7: IntegerMRSW Atomicto integerMRMWA tomic . . . . 432
12.5.8 Construction8: IntegerSRSW AtomictointegerMRSW A tomic . . . . . 433
12.6 Wait-freeAtomicSnapshotsofShared Objects . . . . . . . . . . . . . . . . . . . 435
12.7 ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 438
12.8 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440
12.9 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440
13 Checkpointing andRollbackRecovery 445
13.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445
13.2 Backgroundand Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 446
13.2.1 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 6
13.2.2 A Local Checkpoint . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447
13.2.3 ConsistentSystemStates . . . . . . . . . . . . . . . . . . . . . . . . . . . 447
13.2.4 Interactions withtheOutsideWorld . . . . . . . . . . . . . . . . . . . . . 448
13.2.5 Different TypesofMessages . . . . . . . . . . . . . . . . . . . . . . . . . 449
13.3 IssuesinFailureRecovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 450
13.4 CheckpointBased Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 452
13.4.1 UncoordinatedCheckpointing . . . . . . . . . . . . . . . . . . . . . . . . 452
13.4.2 Coordinated Checkpointing . . . . . . . . . . . . . . . . . . . . . . . . . 454
13.4.3 ImpossibilityofMinProcess Non-blockingCheckpoi nting . . . . . . . . . 456
13.4.4 Communication-InducedCheckpointing . . . . . . . . . . . . . . . . . . . 456
13.5 Log-basedRollback Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . 458
13.5.1 DeterministicandNondeterministicEvents . . . . . . . . . . . . . . . . . 458
xiii
13.5.2 PessimisticLogging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 459
13.5.3 OptimisticLogging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 461
13.5.4 Causal Logging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 462
13.6 Koo-TouegCoordinatedCheckpointingAlgorithm . . . . . . . . . . . . . . . . . 463
13.6.1 TheCheckpointingAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . 463
13.6.2 TheRollback Recovery Algorithm . . . . . . . . . . . . . . . . . . . . . . 465
13.7 Juangand VenkatesanAlgorithmforAsynchronousCheck pointingand Recovery . 466
13.7.1 System ModelandAssumptions . . . . . . . . . . . . . . . . . . . . . . . 466
13.7.2 AsynchronousCheckpointing . . . . . . . . . . . . . . . . . . . . . . . . 467
13.7.3 TheRecovery Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 467
13.7.4 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 469
13.8 Manivannan-SinghalQuasi-SynchronousCheckpointin gAlgorithm . . . . . . . . 470
13.8.1 CheckpointingAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 471
13.8.2 Recovery Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 473
13.8.3 ComprehensiveMessageHandling . . . . . . . . . . . . . . . . . . . . . . 476
13.9 Peterson-KearnsAlgorithmBased onVectorTime . . . . . . . . . . . . . . . . . . 479
13.9.1 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 9
13.9.2 Informal DescriptionoftheAlgorithm . . . . . . . . . . . . . . . . . . . . 480
13.9.3 Formal DescriptionoftheRollBack Protocol . . . . . . . . . . . . . . . . 482
13.9.4 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 483
13.9.5 Correctness Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 484
13.10Helary-Mostefaoui-Netzer-Raynal Communication-i nducedProtocol . . . . . . . . 486
13.10.1Design Principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 487
13.10.2TheCheckpointingProtocol . . . . . . . . . . . . . . . . . . . . . . . . . 491
13.11BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 494
13.12ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 495
14 Consensus andAgreement Algorithms 500
14.1 ProblemDeﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 500
14.1.1 TheByzantineAgreement andOtherProblems . . . . . . . . . . . . . . . 502
14.1.2 EquivalenceoftheProblems andNotations . . . . . . . . . . . . . . . . . 503
14.2 OverviewofResults . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 504
14.3 Agreementin aFailure-Free System(SynchronousorAsy nchronous) . . . . . . . 505
14.4 Agreementin (Message-Passing)SynchronousSystemsw ithFailures . . . . . . . 506
14.4.1 ConsensusAlgorithmforCrash Failures(Synchronou s System) . . . . . . 506
14.4.2 ConsensusAlgorithmsforByzantineFailures (Synch ronousSystem) . . . 507
14.4.3 UpperBound onByzantineProcesses . . . . . . . . . . . . . . . . . . . . 507
14.4.4 ByzantineAgreement TreeAlgorithm: Exponential(S ynchronousSystem) 509
14.5 Agreementin AsynchronousMessage-PassingSystemswi thFailures . . . . . . . . 518
14.5.1 ImpossibilityResult fortheConsensus Problem . . . . . . . . . . . . . . . 518
14.5.2 TerminatingReliableBroadcast . . . . . . . . . . . . . . . . . . . . . . . 520
14.5.3 DistributedTransactionCommit . . . . . . . . . . . . . . . . . . . . . . . 521
14.5.4k-set consensus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 521
14.5.5 ApproximateAgreement . . . . . . . . . . . . . . . . . . . . . . . . . . . 522
14.5.6 Renaming Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 527
xiv
14.5.7 ReliableBroadcast . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 532
14.6 Wait-freeShared MemoryConsensusinAsynchronousSys tems . . . . . . . . . . 533
14.6.1 ImpossibilityResult . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 533
14.6.2 ConsensusNumbers andConsensusHierarchy . . . . . . . . . . . . . . . 536
14.6.3 UniversalityofConsensusObjects . . . . . . . . . . . . . . . . . . . . . . 540
14.6.4 Shared Memory k-set Consensus . . . . . . . . . . . . . . . . . . . . . . . 545
14.6.5 Shared MemoryRenaming . . . . . . . . . . . . . . . . . . . . . . . . . . 545
14.6.6 Shared MemoryRenamingusingSplitters . . . . . . . . . . . . . . . . . . 547
14.7 ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 549
14.8 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 550
14.9 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 552
15 FailureDetectors 555
15.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 555
15.2 UnreliableFailureDetectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 556
15.2.1 TheSystem Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 56
15.2.2 FailureDetectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 557
15.2.3 Completenessand Accuracy Properties . . . . . . . . . . . . . . . . . . . 557
15.2.4 Types ofFailureDetectors . . . . . . . . . . . . . . . . . . . . . . . . . . 560
15.2.5 ReducibilityofFailureDetectors . . . . . . . . . . . . . . . . . . . . . . . 560
15.2.6 Reducing Weak FailureDetectorW toaStrong FailureD etectorS . . . . . 561
15.2.7 ReducinganEventuallyWeakFailureDetector ♦WtoanEventuallyStrong
FailureDetector♦S . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563
15.3 TheConsensus Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 565
15.3.1 SolutionstotheConsensusProblem . . . . . . . . . . . . . . . . . . . . . 566
15.3.2 A SolutionUsingStrongFailureDetectorS . . . . . . . . . . . . . . . . . 566
15.3.3 A SolutionUsingEventuallyStrongFailureDetector ♦S . . . . . . . . . . 568
15.4 AtomicBroadcast . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 570
15.5 ASolutiontoAtomicBroadcast . . . . . . . . . . . . . . . . . . . . . . . . . . . 571
15.6 TheWeakest FailureDetectors toSolveFundamental Agr eementProblems . . . . 573
15.6.1 RealisticFailureDetectors . . . . . . . . . . . . . . . . . . . . . . . . . . 574
15.6.2 Theweakest failuredetectorforconsensus . . . . . . . . . . . . . . . . . 575
15.6.3 TheWeakest FailureDetectorforTerminatingReliab leBroadcast . . . . . 576
15.7 AnImplementationofaFailureDetector . . . . . . . . . . . . . . . . . . . . . . . 576
15.8 AnAdaptiveFailureDetectionProtocol . . . . . . . . . . . . . . . . . . . . . . . 578
15.8.1 Lazy FailureDetectionProtocol ( FDL) . . . . . . . . . . . . . . . . . . . 579
15.9 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 582
15.10ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 582
16 Authentication inDistributed System 586
16.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 586
16.2 Backgroundand Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 586
16.2.1 Basis ofAuthentication . . . . . . . . . . . . . . . . . . . . . . . . . . . . 587
16.2.2 Types ofPrincipals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 587
16.2.3 A SimpleClassiﬁcation ofAuthenticationProtocols . . . . . . . . . . . . 588
xv
16.2.4 Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 88
16.2.5 Design PrinciplesforCryptographicProtocols . . . . . . . . . . . . . . . 589
16.3 ProtocolsBased on SymmetricCryptosystems . . . . . . . . . . . . . . . . . . . . 590
16.3.1 Basic Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 590
16.3.2 Modiﬁed ProtocolwithNonce . . . . . . . . . . . . . . . . . . . . . . . . 591
16.3.3 Wide-MouthFrog Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . 592
16.3.4 A Protocol Based On an AuthenticationServer . . . . . . . . . . . . . . . 593
16.3.5 One-TimePassword Scheme . . . . . . . . . . . . . . . . . . . . . . . . . 594
16.3.6 Otway-Rees Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 596
16.3.7 Kerberos AuthenticationService . . . . . . . . . . . . . . . . . . . . . . . 597
16.4 ProtocolsBased on AsymmetricCryptosystems . . . . . . . . . . . . . . . . . . . 602
16.4.1 TheBasicProtocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602
16.4.2 A ModiﬁedProtocol withaCertiﬁcation Authority . . . . . . . . . . . . . 602
16.4.3 Needham and Schroeder Protocol . . . . . . . . . . . . . . . . . . . . . . 603
16.4.4 SSL Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 05
16.5 Password-basedAuthentication . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609
16.5.1 Encrypted KeyExchange(EKE)Protocol . . . . . . . . . . . . . . . . . . 609
16.5.2 Secure RemotePassword(SRP) Protocol . . . . . . . . . . . . . . . . . . 610
16.6 AuthenticationProtocolFailures . . . . . . . . . . . . . . . . . . . . . . . . . . . 611
16.7 BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 613
16.8 ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 613
17 Self-Stabilization 619
17.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 619
17.2 SystemModel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 620
17.3 DeﬁnitionofSelf-Stabilization . . . . . . . . . . . . . . . . . . . . . . . . . . . . 622
17.4 Issuesinthedesignofself-stabilizationalgorithms . . . . . . . . . . . . . . . . . 624
17.4.1 TheNumberofStates in Each oftheIndividualUnits . . . . . . . . . . . . 625
17.4.2 UniformVs. Non-uniformNetworks . . . . . . . . . . . . . . . . . . . . 631
17.4.3 Central andDistributedDemons . . . . . . . . . . . . . . . . . . . . . . . 632
17.4.4 Reducing thenumberofstatesin atokenring . . . . . . . . . . . . . . . . 633
17.4.5 Shared memoryModels . . . . . . . . . . . . . . . . . . . . . . . . . . . 633
17.4.6 MutualExclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 634
17.4.7 Costs ofself-stabilization . . . . . . . . . . . . . . . . . . . . . . . . . . . 634
17.5 Methodologiesfordesigningself-stabilizingsystem s . . . . . . . . . . . . . . . . 635
17.6 CommunicationProtocols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 637
17.7 Self-StabilizingDistributedSpanningTrees . . . . . . . . . . . . . . . . . . . . . 638
17.8 Self-StabilizingAlgorithmsforSpanning-treeConst ruction . . . . . . . . . . . . . 640
17.8.1 Dolev,Israeli,and Moran Algorithm . . . . . . . . . . . . . . . . . . . . . 640
17.8.2 Afek, Kutten,and YungAlgorithmforSpanning-treeC onstruction . . . . . 642
17.8.3 Arora andGoudaAlgorithmforSpanning-treeConstru ction . . . . . . . . 643
17.8.4 Huang et al. AlgorithmsforSpanning-treeConstruct ion . . . . . . . . . . 643
17.8.5 Afek and Bremler AlgorithmforSpanning-treeConstr uction . . . . . . . . 644
17.9 Ananonymousself-stabilizingalgorithmfor 1-maxima lindependentset intrees . . 645
17.10AProbabilisticSelf-StabilizingLeader ElectionAl gorithm . . . . . . . . . . . . . 646
xvi
17.11Theroleofcompilersinself-stabilization . . . . . . . . . . . . . . . . . . . . . . 649
17.11.1Compilersforsequentialprograms . . . . . . . . . . . . . . . . . . . . . . 649
17.11.2Compilersforasynchronousmessagepassingsystem s . . . . . . . . . . . 650
17.11.3Compilersforasynchronousshared memorysystems . . . . . . . . . . . . 651
17.12Selfstabilizationas aSolutiontoFaultTolerance . . . . . . . . . . . . . . . . . . 652
17.13FactorsPreventingSelf-Stabilization . . . . . . . . . . . . . . . . . . . . . . . . . 654
17.14LimitationsofSelf-Stabilization . . . . . . . . . . . . . . . . . . . . . . . . . . . 655
17.15ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 657
17.16BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 657
17.17ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 658
18 Peer-to-Peer Computing andOverlayGraphs 666
18.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 666
18.1.1 Napster . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 7
18.1.2 ApplicationLayerOverlays . . . . . . . . . . . . . . . . . . . . . . . . . 667
18.2 DataIndexingand Overlays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 668
18.2.1 DistributedIndexing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 669
18.3 UnstructuredOverlays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 670
18.3.1 UnstructuredOverlays: Properties . . . . . . . . . . . . . . . . . . . . . . 670
18.3.2 Gnutella . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 70
18.3.3 Search in Gnutellaand UnstructuredOverlays . . . . . . . . . . . . . . . . 671
18.3.4 Replication Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 673
18.3.5 ImplementingReplication Strategies. . . . . . . . . . . . . . . . . . . . . 675
18.4 Chord DistributedHashTable . . . . . . . . . . . . . . . . . . . . . . . . . . . . 676
18.4.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 6
18.4.2 Simplelookup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 77
18.4.3 Scalable Lookup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 678
18.4.4 ManagingChurn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 78
18.4.5 Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 82
18.5 ContentAddressibleNetworks: CAN . . . . . . . . . . . . . . . . . . . . . . . . 683
18.5.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 3
18.5.2 CAN Initialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 684
18.5.3 CAN Routing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 5
18.5.4 CAN Maintainence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 686
18.5.5 CAN Optimizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 688
18.5.6 CAN Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 89
18.6 Tapestry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 689
18.6.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 9
18.6.2 Overlay andRouting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 689
18.6.3 Object PublicationandObject Search . . . . . . . . . . . . . . . . . . . . 692
18.6.4 NodeInsertion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 693
18.6.5 NodeDeletion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 94
18.7 SomeOtherChallenges inP2P SystemDesign . . . . . . . . . . . . . . . . . . . . 695
18.7.1 Fairness: AGameTheory Application . . . . . . . . . . . . . . . . . . . . 695
18.7.2 TrustorReputationManagement . . . . . . . . . . . . . . . . . . . . . . 696
xvii
18.8 Tradeoffsbetween TableStorage andRouteLengths . . . . . . . . . . . . . . . . 696
18.8.1 UnifyingDHT Protocols . . . . . . . . . . . . . . . . . . . . . . . . . . . 696
18.8.2 Bounds onDHT Storageand RoutingDistance . . . . . . . . . . . . . . . 697
18.9 GraphStructures ofComplexNetworks . . . . . . . . . . . . . . . . . . . . . . . 699
18.10Internetgraphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 701
18.10.1Basic Lawsand theirDeﬁnitions . . . . . . . . . . . . . . . . . . . . . . . 701
18.10.2Properties oftheInternet . . . . . . . . . . . . . . . . . . . . . . . . . . . 702
18.10.3Error andAttack ToleranceofComplexNetworks . . . . . . . . . . . . . 704
18.11RandomGraphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 707
18.11.1Graph Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 07
18.11.2Graph DegreeDistribution . . . . . . . . . . . . . . . . . . . . . . . . . . 708
18.11.3Graph Diameter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 708
18.11.4Graph ClusteringCoefﬁcient . . . . . . . . . . . . . . . . . . . . . . . . . 708
18.11.5Generalized RandomGraph Networks . . . . . . . . . . . . . . . . . . . . 709
18.12Small-worldNetworks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 709
18.13Scale-free Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 710
18.13.1Master-equationapproach . . . . . . . . . . . . . . . . . . . . . . . . . . 710
18.13.2Rate-equation approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 711
18.14EvolvingNetworks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 712
18.14.1Extended Barabasi-Albert Model . . . . . . . . . . . . . . . . . . . . . . 713
18.15ChapterSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 714
18.16ExerciseProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 716
18.17BibliographicNotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 716
xviii
Chapter1
Introduction
1.1 Deﬁnition
A distributed system is a collection of independent entitie s that cooperate to solve a problem that
cannot be individually solved. Distributed systems have be en in existence since the start of the
universe. From aschool of ﬁsh to a ﬂock of birds and entire eco systems ofmicroorganisms,there
is communication among mobile intelligent agents in nature . With the widespread proliferation
of the internet and the emerging global village, the notion o f distributed computing systems as a
usefulandwidelydeployedtoolisbecomingareality. Forco mputingsystems,adistributedsystem
has been characterized inoneofseveralways.
•Youknowyouareusingonewhenthecrashofacomputeryouhave neverheard ofprevents
youfrom doingwork. (Lamport)
•A collection of computers that do not share common memory or a common physical clock,
and that communicate by message passing over a communicatio n network; and each com-
puter has its own memory and runs its own operating system. Ty pically the computers are
semi-autonomousandarelooselycoupledwhiletheycoopera tetoaddressaproblemcollec-
tively. (Singhal-Shivaratri[10])
•A collection of independent computers that appears to the us ers of the system as a single
coherent computer. (Tanenbaum [11])
•A term that describes a wide range of computers, from weakly c oupled systems such as
wide-areanetworkstostronglycoupledsystemssuchasloca lareanetworkstoverystrongly-
coupledsystemssuchas multiprocessorsystems. (Goscinsk i[6])
A distributed system can be characterized as a collection of mostly autonomous processors
communicatingoveracommunicationnetworkand havingthef ollowingfeatures.
•No common physical clock. This is an important assumption because it introduces the el e-
ment of “distribution” in the system and gives rise to the inh erent asynchrony amongst the
processors.
1
PPP P
P
P PMM M
M MM MCommunication network
(WAN/ LAN)P     processor(s)
M    memory bank(s)
Figure1.1: A distributedsystemthatconnects processorsb y acommunicationnetwork.
•Nosharedmemory. Thisisakeyfeaturethatrequiresmessage-passingrequire dforcommu-
nication. Thisfeatureimpliestheabsenceofthecommonphy sicalclock.
It may be noted that a distributed system may still provideth e abstraction of a common ad-
dressspaceviathedistributedsharedmemoryabstraction. Severalaspectsofsharedmemory
multiprocessorsystemshavealsobeen studiedinthedistri butedcomputingliterature.
•Geographical separation. The geographically wider apart that the processors are, the more
representativeisthesystemofadistributedsystem. Howev er,itisnotnecessaryforthepro-
cessorstobeonawide-areanetwork(WAN).Recently,theNet work/ClusterofWorkstations
(NOW/COW) conﬁguration connecting processors on a LAN is al so being increasingly re-
gardedasasmalldistributedsystem. ThisNOWconﬁguration isbecomingpopularbecause
ofthelow-costhigh-speedoff-the-shelfprocessorsnowav ailable. TheGooglesearchengine
isbased on theNOWarchitecture.
•Autonomyandheterogeneity. Theprocessorsare“looselycoupled”inthattheyhavediffe rent
speeds and each can be running a different operating system. They are usually not part of a
dedicated system, but cooperate with one another by offerin g services or solving a problem
jointly.
1.2 RelationtoComputerSystemComponents
AtypicaldistributedsystemisshowninFigure1.1. Eachcom puterhasamemory-processingunit
and the computers are connected by a communication network. Figure 1.2 shows the relation-
ships of the software components that run on each of the compu ters and use the local operating
system and network protocol stack for its functioning. The d istributed software is also termed as
middleware . Adistributedexecution is the executionofprocesses across thedistributedsystem to
collaborativelyachieve a common goal. An execution is also sometimes termed a computation or
arun.
The distributed system uses a layered architecture to break down the complexity of system
design. The middleware is the distributed software that dri ves the distributed system, while pro-
2
protocolsdistributedExtent of Distributed application
Network layer(middleware libraries)
Application layer
Data link layerTransport layer
Network protocol stackDistributed software
systemOperating
Figure1.2: Interaction ofthesoftwarecomponentsateach p rocessor.
viding transparency of heterogeneity at the platform level . Figure 1.2 schematically shows the
interactionofthissoftwarewiththesesystemcomponentsa t each processor. Here weassumethat
the middleware layer does not contain the traditional appli cation layer functions of the network
protocol stack, such as http,mail,ftp, andtelnet. Various primitivesand calls to functions deﬁned
in various libraries of the middleware layer are embedded in the user program code. There exist
severallibrariestochoosefromtoinvokeprimitivesforth emorecommonfunctions–suchasreli-
ableandorderedmulticasting,ofthemiddlewarelayer. The reareseveralstandardssuchasObject
Management Group’s (OMG) Common Object Request Broker Arch itecture (CORBA), and the
Remote Procedure Call (RPC) mechanism. The RPC mechanism co nceptually works like a local
procedure call, with the difference that the procedure code may reside on a remote machine, and
the RPC software sends a message across the network to invoke the remote procedure. It then
awaits a reply, after which the procedure call completes fro m the perspective of the program that
invoked it. Currently deployed commercial versions of midd leware often use CORBA, DCOM
(Distributed Component Object Model), Java, and RMI (Remot e Method Invocation) technolo-
gies. TheMessage-PassingInterface(MPI)developedinthe researchcommunityisanexampleof
an interfaceforvariouscommunicationfunctions.
1.3 Motivation
Themotivationforusinga distributedsystemis someorallo fthefollowingrequirements.
1.Inherently distributed computations. In many applications such as money transfer in bank-
ing,orreachingconsensusamongpartiesthat aregeographi callydistant,thecomputationis
inherentlydistributed.
2.Resource sharing. Resources such as peripherals, complete data sets in databa ses, special
libraries, as well as data (variable/ﬁles) cannot be fully r eplicated at all the sites because
it is often neither practical nor cost-effective. Further, they cannot be placed at a single
site because access to that site might prove to be a bottlenec k. Therefore, such resources
3
are typically distributed across the system. For example, d istributed databases such as DB2
partitionthedatasetsacrossseveralservers,inaddition toreplicatingthematafewsitesfor
rapid access as wellas reliability.
3.Access to geographicallyremote data and resources. In many scenarios, the data cannot be
replicated at every siteparticipating in the distributede xecutionbecause it may be too large
ortoosensitivetobereplicated. Forexample,payrolldata withinamultinationalcorporation
is both too large and too sensitiveto be replicated at every b ranch ofﬁce/site. It is therefore
storedatacentralserverwhichcanbequeriedbybranchofﬁc es. Similarly,specialresources
such as supercomputers exist only in certain locations, and to access such supercomputers,
users need tologin remotely.
Advances in the design of resource-constrained mobile devi ces as well as in wireless tech-
nologyusingwhichthesedevicescommunicatehavegivenfur therimpetustotheimportance
ofdistributedprotocolsandmiddleware.
4.Enhanced reliability. A distributed system has the inherent potential to provide i ncreased
reliability because of the possibility of replicating reso urces and executions, as well as the
reality that geographically distributed resources are not likely to crash/malfunction at the
sametimeundernormalcircumstances. Reliabilityentails severalaspects.
•Availability,i.e., theresource shouldbeaccessibleat al ltimes.
•Integrity,i.e.,thevalue/stateoftheresourceshouldbec orrect,inthefaceofconcurrent
access frommultipleprocessors, as perthesemanticsexpec ted bytheapplication.
•Fault-tolerance, i.e., the ability to recover from system f ailures, where such failures
may be deﬁned to occur in one of many failure models, which we w ill study in Chap-
ter14.
5.IncreasedPerformance/Costratio. Byresourcesharingandaccessinggeographicallyremote
data and resources, the Performance/Cost ratio is increase d. Although higher throughput
has not necessarily been the main objectivebehind using a di stributed system, nevertheless,
a task can be partitioned across the various computers in the distributed system. Such a
conﬁgurationprovidesabetterPerformance/Cost ratio tha nusingspecialparallel machines.
ThisisparticularlytrueoftheNOWconﬁguration.
In addition to meeting the above requirements, a distribute d system also offers the following ad-
vantages.
6.Scalability. As the processors are usually connected by a wide-area netwo rk, adding more
processorsdoes notposeadirectbottleneckforthecommuni cationnetwork.
7.Modularity and incremental expandability. Heterogeneous processors may be easily added
into the system without affecting the performance, as long a s those processors are running
the same middleware algorithms. Similarly, existing proce ssors may be easily replaced by
otherprocessors.
4
MMP P P
PP PM M
M  memory P   processor(b) (a)Interconnection network Interconnection networkPP P P
MM MMM M
Figure 1.3: Two standard architectures for parallel system s. (a) Uniform memory access (UMA)
multiprocessor system. (b) Non-uniform memory access (NUM A) multiprocessor. In both archi-
tectures, theprocessors maylocallycache datafrommemory .
1.4 RelationtoParallelMultiprocessor/MulticomputerSy stems
The characteristics of a distributed system were identiﬁed above. A typical distributed system
wouldlookas shownin Figure1.1. However,howdoesoneclass ifyasystemthatmeetssomebut
not all of the characteristics? Is the system still a distrib uted system, or does it become a parallel
multiprocessorsystem? Tobetteranswerthesequestions,w eﬁrstexaminethearchitectureofpar-
allel systems, and then examine some well-known taxonomies for multiprocessor/multicomputer
systems.
1.4.1 Characteristicsof ParallelSystems
A parallel systemmay bebroadlyclassiﬁed asbelongingtoon eofthreetypes.
1. Amultiprocessor system is a parallel system in which the multiple processors have direct
access to shared memory which forms a common address space. The architecture is show n
inFigure1.3(a). Such processors usuallydonothaveacommo nclock.
Amultiprocessorsystem usuallycorrespondstoauniformmemoryaccess (UMA)architec-
ture in which the access latency, i.e., waiting time, to comp lete an access to any memory
locationfromanyprocessoristhesame. Theprocessorsarei nveryclosephysicalproximity
and are usually very tightly coupled (homogenous hardware a nd software), are connected
by an interconnection network. Interprocess communicatio n across processors is tradition-
ally through read and write operations on the shared memory, although the use of message-
passing primitives such as those provided by the MPI, is also possible (using emulation on
thesharedmemory). Alltheprocessorsusuallyrunthesameo peratingsystem,andboththe
hardwareand softwareare verytightlycoupled.
The processors are usually of the same type, and are housed wi thin the same box/container
withasharedmemoryamongthem. Theinterconnectionnetwor ktoaccessthememorymay
5
be a bus, although for greater efﬁciency, it is usually a multistage switch with a symmetric
and regulardesign.
Figure 1.4 shows two popular interconnection networks – the Omega network and the But-
terﬂy network, each of which is a multi-stage network formed of 2x2 switching elements.
Each 2x2 switch allows data on either of the two input wires to be switched to the upper or
theloweroutputwire. However,inasinglestep,onlyonedat aunitcan besentonanoutput
wire. Soifthedatafromboththeinputwiresistoberoutedto anoutputwireinasinglestep,
there is a collsion. Various techniques such as buffering or more elaborate interconnection
designscan address collisions.
Each 2x2 switch is represented as a rectangle in the ﬁgure. Fu rthermore, a n-input andn-
outputnetwork uses lognstages andlognbits for addressing. Routing in the 2x2 switch at
stagekuses only the kth bit, and hence can be done at clock speed in hardware. The mu lti-
stage networks can be constructed recursively, and the inte rconnection pattern between any
two stages can be expressed using an iterative or a recursive generating function. Besides
the Omega and Butterﬂy (banyan) networks, other examples of multistage interconnection
networks are the Benes and the shufﬂe-exchange networks. Ea ch of these has very inter-
esting mathematical properties that allow rich connectivi ty between the processor bank and
memorybank.
Omega interconnection function. The Omega network which connects nprocessors to
nmemory units hasn
2·log2nswitching elements of size 2x2 arranged in log2nstages.
Between each pair of adjacent stages of the Omega network, a l ink exists between output i
of a stage and the input jto the next stage according to the following perfect shufﬂe pattern
which is a left-rotation operation on the binary representa tion ofito getj. The iterative
generationfunctionis as follows.
j=/braceleftbigg2i for0≤i≤n/2−1
2i+ 1−nforn/2≤i≤n−1(1.1)
Consider any stage of switches. Informally, the upper (lowe r) input lines for each switch
comeinsequentialorderfrom theupper(lower)halfofthesw itchesintheearlierstage.
With respect to the Omega network in Figure 1.4(a), n= 8. Hence, for any stage, for the
outputsi, where 0≤i≤3, the output iis connected to input 2iof the next stage. For
4≤i≤7,theoutputiofany stageis connected toinput 2i+ 1−nofthenextstage.
Omega routing function. The routing function from input line ito output line jconsiders
onlyjand the stage number s, wheres∈[0,log2n−1]. In a stage sswitch, if the s+ 1th
MSBofjis0, thedataisrouted totheupperoutputwire, otherwiseit isrouted tothelower
outputwire.
Butterﬂy interconnection function. Unlike the Omega network, the generation of the in-
terconnection pattern between a pair of adjacent stages dep ends not only on nbut also on
the stagenumber s. The recursiveexpressionis as follows. Let there be M=n/2switches
per stage, and let a switch be denoted by the tuple ∝a\}⌊ra⌋k⌉tl⌉{tx,s∝a\}⌊ra⌋k⌉tri}ht, wherex∈[0,M−1]and stage
s∈[0,log2n−1].
6
Thetwooutgoingedgesfromanyswitch ∝a\}⌊ra⌋k⌉tl⌉{tx,s∝a\}⌊ra⌋k⌉tri}htareasfollows. Thereisanedgefromswitch
∝a\}⌊ra⌋k⌉tl⌉{tx,s∝a\}⌊ra⌋k⌉tri}htto switch∝a\}⌊ra⌋k⌉tl⌉{ty,s+ 1∝a\}⌊ra⌋k⌉tri}htif (i)x=yor (ii)xXORyhas exactly one 1 bit, which is in the
(s+ 1)thMSB. Forstage s,apply theruleabovefor M/2sswitches.
Whetherthe twoincomingconnections go to theupperor thelo werinputport is not impor-
tantbecauseoftheroutingfunction,givenbelow.
Example. Consider the Butterﬂy network in Figure 1.4(b), n= 8andM= 4. There are
threestages, s= 0,1,2,and theinterconnectionpattern isdeﬁned between s= 0ands= 1
and between s= 1ands= 2. The switch number xvaries from 0 to 3 in each stage, i.e.,
xis a 2-bit string. (Note that unlikethe Omeganetwork formul ation using input and output
lines given above, this formulation uses switch numbers. Ex ercise 5 asks you to prove a
formulationoftheOmegainterconnectionpatternusingswi tchnumbersinsteadofinputand
outputport numbers.)
Consider the ﬁrst stage interconnection ( s= 0) of a butterﬂy of size M, and hence having
log22Mstages. For stage s= 0, as per rule (i), the ﬁrst output line from switch 00 goes
to input line of switch 00 of stage s= 1. As per rule (ii), the second output line of switch
00 goes to input line of switch 10 of stage s= 1. Similarly,∝a\}⌊ra⌋k⌉tl⌉{tx,s∝a\}⌊ra⌋k⌉tri}ht= (01) has one output
line go to an input line of switch (11) in stage s= 1. The other connections in this stage
can be determined similarly. For stage s= 1connecting to stage s= 2, we apply the rules
considering only M/21=M/2switches, i.e., builds 2 butterﬂies of size M/2- the ”upper
half"andthe”lowerhalf"switches. Therecursionterminat esforM/2s= 1,whenthereisa
singleswitch.
Butterﬂy routing function. In a stagesswitch, if the s+ 1th MSB ofjis 0, the data is
routedto theupperoutputwire, otherwiseitisrouted tothe loweroutputwire.
Observe that for the Butterﬂy and the Omega networks, the pat hs from the different inputs
to any one output form a spanning tree. This implies that coll isions will occur when data is
destinedtothesameoutputline. However,theadvantageist hatdatacanbecombinedatthe
switchesiftheapplicationsemantics(e.g., summationofn umbers)are known.
2. Amulticomputerparallelsystem isaparallelsysteminwhichthemultipleprocessors donot
have direct access to shared memory. The memory of the multiple processors may or may
not form a common address space. Such computers usually do no t have a common clock.
ThearchitectureisshowninFigure1.3(b).
Theprocessorsareinclosephysicalproximityandareusual lyverytightlycoupled(homoge-
noushardwareandsoftware),andconnectedbyaninterconne ctionnetwork. Theprocessors
communicateeither via a common address space or via message -passing. A multicomputer
systemthat has a common address space usuallycorresponds to a non-uniformmemory ac-
cess (NUMA) architecture in which the latency to access vari ous shared memory locations
fromthedifferent processorsvaries.
Examples of parallel multicomputers are: the NYU Ultracomp uter and the Sequent shared
memory machines, the CM* Connection machine and processors conﬁgured in regular and
symmetricaltopologiessuchasanarrayormesh,ring,torus ,cube,andhypercube(message-
passing machines). The regular and symmetrical topologies have interesting mathematical
7
P0
P1
P2
P3
P4
P6
P7101P5000
001M0
M1
010
011
100
101
110
111001
101
110
111100
111110100011010000
M2 010000
001
100
101P0
P1
P2
P3
P4
P5
P6
P7
(a)3−stage Omega network (n=8, M=4) (b) (n=8, M=4) 3−stage Butterfly network011 M3
M4
M5
M6
M7000
001
010
011M0
M1
M2
M3
M4
M5
M6
M7110
111
Figure 1.4: Interconnection networks for shared memory mul tiprocessorsystems. (a) Omeganet-
work forn= 8processorsP0−P7and memory banks M0−M7. (b) Butterﬂy network for
n= 8processorsP0−P7andmemorybanks M0−M7.
properties that enable very easy routing and provide many ri ch features such as alternate
routing.
Figure 1.5(a) shows a wrap-around 4x4 mesh. For a k×kmesh which will contain k2
processors, the maximum path length between any two process ors is 2(k/2−1). Routing
can be done along the Manhattan grid. Figure 1.5(b) shows a 4- dimensional hypercube. A
k-dimensional hypercube has 2kprocessor-and-memory units. Each such unit is a node in
the hypercube, and has a unique k-bit label. Each of the kdimensions is associated with a
bitpositioninthelabel. Thelabelsofanytwoadjacentnode sareidenticalexceptforthebit
positioncorrespondingtothedimensioninwhichthetwonod esdiffer. Thus,theprocessors
arelabelledsuchthattheshortestpathbetweenanytwoproc essorsisthe Hammingdistance
(deﬁnedasthenumberofbitpositionsinwhichthetwoequals izedbitstringsdiffer)between
theprocessorlabels. Thisis clearly boundedby k.
Example. Nodes0101and1100haveaHammingdistanceof2. THeshortest pathbetween
themhas length2.
Routinginthehypercubeisdonehop-by-hop. Atanyhop,them essagecanbesentalongany
dimensioncorrespondingtothebitpositioninwhichthecur rentnode’saddressandthedes-
tination address differ. The 4-D hypercube shown in the ﬁgur e is formed by connecting the
correspondingedgesoftwo3-Dhypercubes(correspondingt otheleftandtheright“cubes”
in the ﬁgure) along the fourth dimension; the labels of the 4- D hypercube are formed by
prepending a ‘0’ to the labels of the left 3-D hypercube and pr epending a ‘1’ to the labels
of the right 3-D hypercube. This can be extended to construct hypercubes of higher dimen-
sions. Observe that there are multiple routes between any pa ir of nodes, which provides
fault-tolerance as well as a congestion control mechanism. The hypercube and its variant
topologies have very interesting mathematical properties with implications for routing and
fault-tolerance.
3.Array processors belong to a class of parallel computers that are physically c o-located, are
8
0010
0111
00110101
(b) (a)processor + memory1100
10001110
1010
1111
101110011101
00010110 0100
0000
Figure 1.5: Some popular topologies for multicomputer shar ed-memory machines. (a) Wrap-
around 2D-mesh,alsoknownas torus. (b)Hypercubeofdimens ion4.
very tightly coupled, and have a common system clock (but may not share memory and
communicate by passing data using messages). Array process ors and systolic arrays that
performtightlysynchronizedprocessinganddataexchange inlock-stepforapplicationssuch
as DSP and image processing belong to this category. These ap plications usually involve a
largenumberofiterationsonthedata. Thisclassofparalle lsystemshasaverynichemarket.
The distinction between UMA multiprocessors on the one hand , and NUMA and message-
passingmulticomputersontheotherhand,isimportantbeca usethealgorithmdesignanddataand
taskpartitioningamongtheprocessorsmustaccountforthe variableandunpredictablelatenciesin
accessing memory/communication. As compared to UMA system s and array processors, NUMA
and message-passing multicomputer systems are less suitab le when the degree of granularity of
accessing shared dataand communicationisvery ﬁne.
The primary and most efﬁcacious use of parallel systems is fo r obtaining a higher throughput
by dividing the computational workload among the processor s. The tasks that are most amenable
to higher speedups on parallel systems are those that can be p artitioned into subtasks very nicely,
involving much number-crunching and relatively little com munication for synchronization. Once
thetaskhasbeendecomposed,theprocessorsperformlargev ector,arrayandmatrixcomputations
that are common in scientiﬁcapplications. Searching throu ghlarge state spaces can be performed
with signiﬁcant speedup on parallel machines. While such pa rallel machines were an object of
much theoretical and systems research in the 1980s and early 1990s, they have not proved to be
economically viable for two related reasons. First, the ove rall market for the applications that
can potentially attain high speedups is relatively small. S econd, due to economy of scale and the
high processing power offered by relatively inexpensiveof f-the-shelf networked PCs, specialized
parallelmachinesarenotcost-effectivetomanufacture. T heyadditionallyrequirespecialcompiler
and othersystemsupportformaximumthroughput.
9
1.4.2 Flynn’sTaxonomy
Flynn identiﬁed four processing modes, based on whether the processors execute the same or
different instruction streams at the same time, and whether or not the processors processed the
same(identical)dataat thesametime. It isinstructiveto e xaminethisclassiﬁcationto understand
therangeofoptionsused forconﬁguringsystems.
SingleInstruction stream, SingleData stream (SISD). This mode corresponds to the conven-
tional processing in the von Neumann paradigm with a single C PU, and a single memory
unitconnected byasystembus.
SingleInstruction stream, MultipleData stream (SIMD). This mode corresponds to the pro-
cessing by multiple homogenous processors which execute in lock-step on different data
items. Applications that involve operations on large array s and matrices, such as scientiﬁc
applications,can bestexploitsystemsthatprovidetheSIM D modeofoperationbecausethe
datasetscan bepartitionedeasily.
Several of the earliest parallel computers, such as Illiac- IV, MPP, CM2, and MasPar MP-1
wereSIMDmachines. Vectorprocessors,arrayprocessorsan dsystolicarraysalsobelongto
the SIMD class of processing. Recent SIMD architectures inc ludeco-processing units such
as the MMX units in Intel processors (e.g., Pentium with the S treaming SIMD Extensions
(SSE) options)and DSP chipssuchas theSharc.
MultipleInstruction stream, SingleData stream (MISD). This mode corresponds to the exe-
cution of different operations in parallel on the same data. This is a specialized mode of
operationwithlimitedbut nicheapplications,e.g.,visua lization.
MultipleInstruction stream, Multiple Datastream (MIMD). Inthismode,thevariousproces-
sors execute different code on different data. This is the mo de of operation in distributed
systems as well as in the vast majority of parallel systems. T here is no common clock
amongthesystemprocessors. SunUltraservers,multicompu terPCs,andIBMSPmachines
areexamplemachines thatexecuteinMIMD mode.
SIMD, MISD, MIMD architectures are illustrated in Figure 1. 6. MIMD architectures are most
generalandallowmuchﬂexibilityinpartitioningcodeandd atatobeprocessed,amongtheproces-
sors. MIMDarchitecturesalsoincludetheclassicallyunde rstoodmodeofexecutionindistributed
systems.
1.4.3 Coupling, Parallelism, Concurrency, and Granularit y
1.4.3.1 Coupling.
The degree of coupling among a set of modules, whether hardwa re or software, is measured in
terms of the interdependency and binding and/or homogeneit y among the modules. When the
degree of coupling is high (low), the modules are said to be ti ghtly (loosely) coupled. SIMD
and MISD architectures generally tend to be tightly coupled because of the common clocking of
the shared instruction stream or the shared data stream. Her e we brieﬂy examine various MIMD
architectures interms ofcoupling.
10
P PC C C CI I
I I I II I I
DP
(c) MISD (b) MIMD (a) SIMDdata streamProcessing UnitControl Unit
P
Dinstruction streamICC
P
D DP P
D D
Figure 1.6: Flynn’s taxonomy of SIMD, MIMD, and MISD archite ctures for multiproces-
sor/multicomputersystems.
1. Tightly-coupledmultiprocessors(with UMA shared memor y). These may be either switch-
based (e.g.,NYU Ultracomputer,and RP3) orbus-based (e.g. , Sequent,Encore).
2. Tightly-coupledmultiprocessors(withNUMAsharedmemo ryorthatcommunicatebymes-
sagepassing). Examplesare theSGI Origin2000and theSun Ul traHPCservers (thatcom-
municate via NUMA shared memory), and the hypercube and the t orus (that communicate
bymessagepassing).
3. Loosely-coupled multicomputers (without shared memory ) physically co-located. These
may be bus-based (e.g., NOW connected by a LAN or Myrinet card ) or using a more gen-
eral communication network, and the processors may be heter ogenous. In such systems,
processors neither share memory nor have a common clock, and hence may be classiﬁed as
distributed systems – however, the processors are very clos e to one another, which is char-
acteristic of a parallel system. As the communication laten cy may be signiﬁcantly lower
than in wide-area distributed systems, the solution approa ches to various problems may be
differentforsuch systemsthan forwide-areadistributeds ystems.
4. Loosely-coupled multicomputers(without shared memory and withoutcommon clock) that
arephysicallyremote. Thesecorrespondto theconventiona lnotionofdistributedsystems.
1.4.3.2 Parallelismorspeedup ofaprogram onaspeciﬁc syst em.
This is a measure of the relativespeedup of a speciﬁc program , on a given machine. The speedup
dependsonthenumberofprocessorsandthemappingofthecod etotheprocessors. Itisexpressed
as theratioofthetime T(n)withnprocessors,tothetime T(1)withasingleprocessor.
1.4.3.3 Parallelismwithina parallel/distributed progra m.
This is an aggregate measure of the percentage of time that al l the processors are executing CPU
instructions productively, as opposed to waiting for commu nication (either via shared memory or
message-passing) operations to complete. The term is tradi tionally used to characterize parallel
11
programs. Iftheaggregatemeasureis afunctionofonlythec ode, then theparallelismisindepen-
dent of the architecture. Otherwise, this deﬁnition degene rates to the deﬁnition of parallelism in
Section 1.4.3.2.
1.4.3.4 Concurrency ofaprogram.
This is a broader term that means roughly the same as parallel ism of a program, but is used in the
contextofdistributedprograms. The parallelism/concurrency inaparallel/distributedprogramcan
be measured by the ratio ofthe numberoflocal (non-communic ationand non-shared memoryac-
cess)operationstothetotalnumberofoperations,includi ngthecommunicationorsharedmemory
access operations.
1.4.3.5 Granularityofa program.
The relative measure of the amount of computation to the amou nt of communication within the
parallel/distributedprogramistermedas granularity . Ifthedegreeofparallelismiscoarse-grained
(ﬁne-grained),therearerelativelymanymore(fewer)prod uctiveCPUinstructionexecutions,com-
pared to the numberof times the processors communicate(eit her via shared memory or message-
passing) and wait to get synchronized with the other process ors. Programs with ﬁne-grained par-
allelism are best suited for tightly coupled systems. These typically include SIMD and MISD
architectures, tightly coupled MIMD multiprocessors (tha t have shared memory), and loosely-
coupled multicomputers(withoutshared memory)that are ph ysicallycolocated. If programs with
ﬁne-grainedparallelismwererunoverloosely-coupledmul tiprocessorsthatarephysicallyremote,
the latency delays for the frequent communication over the W AN would signiﬁcantly degrade the
overall throughput. As a corollary, it follows that on such l oosely-coupled multicomputers, pro-
grams with a coarse-grained communication/message-passi ng granularity will incur substantially
lessoverhead.
Figure1.2showedtherelationshipsbetweenthelocalopera tingsystem,themiddlewareimple-
menting the distributed software, and the network protocol stack. Before moving on, we identify
variousclassesofmultiprocessor/multicomputeroperati ngsystems.
•Theoperatingsystemrunningonlooselycoupledprocessors (i.e., heterogenousand/orgeo-
graphicallydistantprocessors),whicharethemselvesrun ninglooselycoupledsoftware(i.e.,
software that is heterogenous) is classiﬁed as a Network Operating System . In this case,
the application cannot run any signiﬁcant distributed func tion that is not provided by the
ApplicationLayerofthenetworkprotocolstacks onthevari ousprocessors.
•Theoperatingsystemrunningonlooselycoupledprocessors ,whicharerunningtightlycou-
pled software (i.e., the middleware software on the process ors is homogenous) is classiﬁed
as aDistributedOperatingSystem .
•The operating system running on tightly coupled processors , which are themselves running
tightlycoupled software is classiﬁed as a MultiprocessorOperatingSystem . Such a parallel
systemcan runsophisticatedalgorithmscontainedintheti ghtlycoupledsoftware.
12
1.5 MessagePassingSystemsversusSharedMemorySystems
Shared memory systems are those in which there is a (common) s hared address space throughout
the system. Communication among processors takes place via shared data variables, and control
variables for synchronization among the processors. Semap hores and monitors that were origi-
nally designed for shared memory uniprocessors and multipr ocessors are examples of how syn-
chronization can be achieved in shared memory systems. All m ulticomputer (NUMA as well as
message-passing) systems that do not have a shared address s pace provided by the underlying
architecture and hardware necessarily communicate by mess age passing. Conceptually, program-
mers ﬁnd iteasierto programusingshared memorythanby mess agepassing. Forthisand several
other reasons that we examine later, the abstraction called shared memory is sometimes provided
to simulate a shared address space. For a distributed system , this abstraction is called distributed
shared memory . Implementing this abstraction has a certain cost but it sim pliﬁes the task of the
application programmer. There also exists a well-known folklore result thatcommunication via
message-passing can be simulated by communication via shar ed memory and vice-versa . There-
fore, thetwoparadigmsare equivalent.
1.5.1 Emulating message-passingon sharedmemorysystem( MP→SM).
The shared address space can be partitioned into disjoint pa rts, one part being assigned to each
processor. “Send” and “Receive” operations can be implemen ted by writing to and reading from
thedestination/senderprocessor’saddressspace,respec tively. Speciﬁcally,aseparatelocationcan
be reserved as the mailbox for each ordered pair of processes . APi–Pjmessage-passing can be
emulatedbyaWriteby PitothemailboxandthenaRead by Pjfromthemailbox. Inthesimplest
case,thesemailboxescanbeassumedtohaveunboundedsize. Thewriteandreadoperationsneed
to be controlled using synchronization primitives to infor m the receiver/sender after the data has
been sent/received.
1.5.2 Emulatingsharedmemoryonamessage-passingsystem( SM→MP).
Thisinvolvestheuseof“Send”and“Receive”operationsfor “Write”and“Read”operations. Each
shared location can be modeled as a separate process; “Write ” to a shared location is emulated by
sending an update message to the corresponding owner proces s; a “Read” to a shared location
is emulated by sending a query message to the owner process. A s accessing another processor’s
memory requires Send and Receive operations, this emulatio n is expensive. Although emulating
shared memory might seem to be more attractive from a program mer’s perspective, it must be
remembered that in a distributed system, it is only an abstra ction. Thus, the latencies involved in
readandwriteoperationsmaybehighevenwhenusingsharedm emoryemulationbecausetheread
and writeoperationsare implementedby usingnetwork-wide communicationunderthecovers.
An application can of course use a combination of shared memo ry and message-passing. In a
MIMD message-passing multicomputer system, each “process or” may be a tightly-coupled mul-
tiprocessor system with shared memory. Within the multipro cessor system, the processors com-
municateviasharedmemory. Betweentwocomputers,thecomm unicationisbymessagepassing.
Asmessage-passingsystemsaremorecommonandmoresuitedf orwide-areadistributedsystems,
13
wewillconsidermessage-passingsystemsmoreextensively thanweconsidersharedmemorysys-
tems.
1.6 Primitivesfor DistributedCommunication
1.6.1 Blocking/Nonblocking, Synchronous/Asynchronous P rimitives
Message send and message receive communication primitives are denoted Send()andReceive() ,
respectively. A Sendprimitive has at least two parameters - the destination, and the buffer in the
userspace,containingthedatatobesent. Similarly,a Receiveprimitivehasatleasttwoparameters
- the source from which the data is to be received (this could b e a wildcard), and the user buffer
intowhichthedataisto bereceived.
Therearetwowaysofsendingdatawhenthe Sendprimitiveisinvoked-thebufferedoptionand
the unbuffered option. The buffered option which is the standard option copies the data from the
userbuffertothekernelbuffer. Thedatalatergetscopiedf romthekernelbufferontothenetwork.
In theunbuffered option , the data gets copied directly from the user buffer onto the n etwork. For
theReceiveprimitive, the buffered option is usually required because the data may already have
arrivedwhen theprimitiveisinvoked,and needsa storagepl acein thekernel.
The following are some deﬁnitions of blocking/nonblocking and synchronous/asynchronous
primitives.
Synchronous primitives. ASendor aReceiveprimitive is synchronous if both the Send()and
Receive() handshake with each other. The processing for the Sendprimitivecompletes only
after the invoking processor learns that the other correspo ndingReceiveprimitive has also
been invoked and that the receive operation has been complet ed. The processing for the
Receiveprimitive completes when the data to be received is copied in to the receiver’s user
buffer.
Asynchronous primitives. ASendprimitiveis said to be asynchronous ifcontrol returns back to
the invoking process after the data item to be sent has been co pied out of the user-speciﬁed
buffer.
It doesnotmakesensetodeﬁne asynchronous Receiveprimitives.
Blocking primitives. A primitive is blocking if control returns to the invoking process after the
processingfortheprimitive(whetherinsynchronousorasy nchronousmode)completes.
Nonblocking primitives. A primitive is nonblocking if control returns back to the invoking pro-
cess immediatelyafter invocation, even though theoperati on has not completed. For a non-
blocking Send, control returns to the process even before the data is copie d out of the user
buffer. For a nonblocking Receive, control returns to the process even before the data may
havearrivedfrom thesender.
Fornonblockingprimitives,areturnparameterontheprimi tivecallreturnsasystem-generated
handlewhichcanbelaterusedtocheckthestatusofcompletionofth ecall. Theprocesscan
check for the completion of the call in two ways. First, it can keep checking (in a loop or
periodically)if thehandlehas been ﬂagged or posted. Second, it can issuea Waitwith alist
14
Send(X, destination, handle k) //handle kisareturn parameter
...
...
Wait(handle 1,handle 2,...,handle k,...,handle m) //Waitalwaysblocks
Figure1.7: Anonblocking sendprimitive. Whenthe Waitcallreturns,atleastoneofitsparameters
isposted.
of handles as parameters. The Waitcall usually blocks untilone of the parameter handles is
posted. Presumably after issuing the primitive in nonblock ing mode, the process has done
whateveractions it could and now needs to know the statusof c ompletionof the call, there-
foreusingablocking Wait()callisusualprogrammingpractice. Thecodeforanonblocki ng
Sendwouldlookas showninFigure1.7.
If at the time that Wait()is issued, the processing for the primitive (whether synchr onous
or asynchronous) has completed, the Waitreturns immediately. The completion of the pro-
cessing of the primitive is detectable by checking the value ofhandle k. If the processing
of the primitive has not completed, the Waitblocks and waits for a signal to wake it up.
When the processing for the primitive completes, the commun ication subsystem software
setsthevalueof handle kandwakesup(signals)anyprocesswitha Waitcallblockedonthis
handle k. Thisiscalled postingthecompletionoftheoperation.
There are therefore four versions of the Sendprimitive – synchronous blocking, synchronous
nonblocking, asynchronous blocking, and asynchronous non blocking. For the Receiveprimitive,
there are the blocking synchronous and nonblocking synchro nous versions. These versions of
the primitives are illustrated in Figure 1.8 using a timing d iagram. Here, three time lines are
shownforeach process: (1)fortheprocessexecution,(2)fo rtheuserbufferfrom/towhichdatais
sent/received,and (3)forthekernel/communicationsubsy stem.
Blocking synchronous Send(Figure 1.8(a)): The data gets copied from the user buffer to the
kernel buffer and is then sent over the network. After the dat a is copied to the receiver’s
systembuffer,anacknowledgementbacktothesendercauses controltoreturntotheprocess
thatinvokedthe Sendoperation andcompletesthe Send.
Nonblocking synchronous Send(Figure 1.8(b)): Control returns back to the invoking process as
soonasthecopyofdatafrom theuserbuffertothekernelbuff erisinitiated. A parameterin
thenonblockingcallalsogetssetwiththehandleofalocati onthattheuserprocesscanlater
check for the completion of the synchronous send operation. The location gets posted after
an acknowledgement returns from the receiver, as per the sem antics described for (a). The
user process can keep checking for the completion of the nonb locking synchronous Send
by testing the returned handle, or it can invoke the blocking Waitoperation on the returned
handle.
Blocking asynchronous Send(Figure 1.8(c)): The user process that invokes the Sendis blocked
untilthedataiscopiedfromtheuser’sbuffertothekernelb uffer. (Fortheunbufferedoption,
theuserprocessthatinvokesthe Sendisblockeduntilthedataiscopiedfromtheuser’sbuffer
tothenetwork.)
15
S_C
R_C R
PS_CP, (a) blocking sync. Send, blocking Receive (b) nonblocking sync. Send, nonblocking ReceiveP, R_CS_CP,
R_C
WSend
The completion of the previously initiated nonblocking operationduration in which the process issuing send or receive primitive is blocked
          primitive  issued
                primitive  issuedReceiveSend(c) blocking async. Send (d) nonblocking async. Send
S
processing for                   completesSW WS_CS
kernel_ibuffer_iprocess iR R W WW W
Receive
Process may issue             to check completion of nonblocking operation Waitduration to copy data from or to user buffer
processing for                completesS S_C process i
buffer_i
kernel_i
process jbuffer_jkernel_jS
Figure 1.8: Blocking/nonblocking and synchronous/asynch ronous primitives. Process Piis send-
ing and process Pjis receiving. (a) Blocking synchronous Sendand blocking (synchronous)
Receive. (b)Nonblockingsynchronous Sendandnonblocking(synchronous) Receive. (c)Block-
ingasynchronous Send. (d)Nonblockingasynchronous Send.
Nonblocking asynchronous Send(Figure 1.8(d)): The user process that invokes the Sendis
blocked until the transfer of the data from the user’s buffer to the kernel buffer is initiated.
(For theunbuffered option, theuser process that invokesth eSendis blocked until thetrans-
fer of the data from the user’s buffer to the network is initia ted.) Control returns to the user
processassoonasthistransferisinitiated,andaparamete rinthenonblockingcallalsogets
setwiththehandleofalocationthattheuserprocesscanche cklaterusingthe Waitoperation
for the completion of the asynchronous Sendoperation. The asynchronous Sendcompletes
whenthedatahasbeencopiedoutoftheuser’sbuffer. Theche ckingforthecompletionmay
benecessary iftheuserwants toreusethebufferfromwhich t hedatawas sent.
Blocking Receive(Figure 1.8(a)): TheReceivecall blocks until the data expected arrives and is
writteninthespeciﬁed userbuffer. Then controlisreturne d to theuserprocess.
16
Nonblocking Receive(Figure 1.8(b)): TheReceivecall will cause the kernel to register the call
andreturnthehandleofalocationthattheuserprocesscanl atercheckforthecompletionof
thenonblocking Receiveoperation. Thislocationgetspostedbythekernelafterthe expected
dataarrivesandiscopiedtotheuser-speciﬁedbuffer. Theu serprocesscankeepcheckingfor
the completion of the nonblocking Receiveby invoking the Waitoperation on the returned
handle. (If the data has already arrived when the call is made , it would be pending in some
kernel buffer,and stillneedsto becopiedto theuserbuffer .)
A synchronous Sendis easier to use from a programmer’s perspective because the handshake
between the Sendand theReceivemakes the communication appear instantaneous, thereby sim -
plifyingtheprogram logic. The“instantaneity”is, ofcour se, onlyan illusion,as can beseen from
Figure 1.8(a) and (b). In fact, the Receivemay not get issued until much after the data arrives at
Pj, in which case the data arrived would have to be buffered in th e system buffer at Pjand not in
theuserbuffer. Allthiswhile,thesenderwouldremainbloc ked. Thus,asynchronous Sendlowers
theefﬁciencywithinprocess Pi.
Thenonblockingasynchronous Send(seeFigure1.8(d))isusefulwhenalargedataitemisbe-
ingsentbecauseit allowstheprocesstoperform otherinstr uctionsin parallelwiththecompletion
of theSend. The nonblocking synchronous Send(see Figure 1.8(b)) also avoids the potentially
large delays for handshaking, particularly when the receiv er has not yet issued the Receivecall.
The nonblocking Receive(see Figure 1.8(b)) is useful when a large data item is being r eceived
and/or when the sender has not yet issued the Sendcall, because it allows the process to perform
other instructions in parallel with the completion of the Receive. Note that if the data has already
arrived, it is stored in the kernel buffer, and it may take a wh ileto copy it to the user buffer speci-
ﬁed in the Receivecall. For nonblocking calls, however, the burden on the prog rammer increases
because he has to keep track of the completion of such operati ons in order to meaningfully reuse
(writetoorread from)theuserbuffersagain. Thus,concept ually,blockingprimitivesareeasierto
use.
1.6.2 ProcessorSynchrony
Asopposedtotheclassiﬁcationofsynchronousandasynchro nouscommunicationprimitives,there
is alsotheclassiﬁcation ofsynchronousversusasynchrono usprocessors. Processorsynchrony in-
dicates that all the processors execute in lock-step with th eir clocks synchronized. As this syn-
chronyisnotattainablein adistributedsystem,what ismor egenerallyindicatedisthat foralarge
granularity of code, usually termed as a step, the processors are synchronized. This abstraction is
implemented using some form of barrier synchronization to e nsure that no processor begins exe-
cutingthenextstepofcodeuntilalltheprocessorshavecom pletedexecutingthepreviousstepsof
codeassignedtoeach oftheprocessors.
1.6.3 Libraries andStandards
The previous subsections identiﬁed the main principles und erlying all communication primitives.
In thissubsection, we brieﬂy mentionsomepublicly availab leinterfaces that embodysome ofthe
aboveconcepts.
17
Thereexistsawiderangeofprimitivesformessage-passing . Manycommercialsoftwareprod-
ucts (banking, payroll, etc. applications)use proprietar y primitivelibraries suppliedwith thesoft-
ware marketed by the vendors (e.g., the IBM CICS software whi ch has a very widely installed
customer base worldwide uses its own primitives). The Messa ge-Passing Interface (MPI) library
and the PVM (Parallel Virtual Machine) library are used larg ely by the scientiﬁc community, but
other alternative libraries exist. Commercial software is often written using the Remote Proce-
dure Calls (RPC) mechanism in which procedures that potenti ally reside across the network are
invoked transparently to the user, in the same manner that a l ocal procedure is invoked. Under
thecovers,socketprimitivesorsocket-liketransportlay erprimitivesareinvokedtocalltheproce-
dureremotely. ThereexistmanyimplementationsofRPC-for example,SunRPC,andDistributed
ComputingEnvironment(DCE)RPC.“Messaging”and“streami ng”aretwoothermechanismsfor
communication. Withthegrowthofobjectbasedsoftware,li brariesforRemoteMethodInvocation
(RMI) and Remote Object Invocation (ROI) with their own set o f primitives are being proposed
and standardized by different agencies. CORBA (Common Obje ct Request Broker Architecture)
and DCOM (Distributed Component Object Model) are two other standardized architectures with
their own set of primitives. Additionally,several project s in the research stage are designing their
ownﬂavourofcommunicationprimitives.
1.7 SynchronousversusAsynchronousExecutions
internal event send event receive eventP
P
P
P0
1
2
3m1 m7
m4m2 m6
m5 m3
Figure 1.9: An example of an asynchronous execution in a mess age-passing system. A timing
diagramis usedto illustratetheexecution.
In additionto the two classiﬁcations of processor synchron y/asynchrony and of synchronous/
asynchronouscommunicationprimitives,thereisanotherc lassiﬁcation,namelythatof synchronous/
asynchronousexecutions .
•Anasynchronous execution is an execution in which (1) there is no processor synchrony
andthereisnoboundonthedriftrateofprocessorclocks,(2 )messagedelays(transmission
+ propagation times) are ﬁnite but unbounded, and (3) there i s no upper bound on the time
takenbyaprocesstoexecuteastep. Anexampleasynchronous executionwithfourprocesses
P0toP3is shown in Figure 1.9. The arrows denote the messages; the he ad and tail of an
arrow mark the sendandreceiveevent for that message, denoted by a circle and vertical
18
line, respectively. Non-communicationevents, also terme d asinternalevents, are shownby
shadedcircles.
•Asynchronous execution is an execution in which (1) processors are synchronized and the
clockdriftratesbetweenanytwoprocessorsisbounded,(2) messagedelivery(transmission
+ delivery) times are such that they occur in one logical step or round, and (3) there is a
known upper bound on the time taken by a process to execute a st ep. An example of a
synchronous execution with four processes P0toP3is shown in Figure 1.10. The arrows
denotethemessages.
It is easier to design and verify algorithms assuming synchr onous executions because of the
coordinated nature of the executions at all the processes. H owever, there is a hurdle to having
a truly synchronous execution. It is practically difﬁcult t o build a completely synchronous sys-
tem, and have the messages delivered within a bounded time. T herefore, this synchrony has to be
simulated under the covers, and will inevitably involve del aying or blocking some processes for
some time durations. Thus, synchronous execution is an abst raction that needs to be provided to
the programs. When implementing this abstraction, observe that the fewer the steps or “synchro-
nizations” of the processors, the lower the delays and costs . If processors are allowed to have an
asynchronous execution for a period of time and then they syn chronize, then the granularity of
the synchrony is coarse. This is really a virtually synchronous execution , and the abstraction is
sometimes termed as virtual synchrony . Ideally, many programs want the processes to execute a
series of instructions in rounds (also termed as steps or pha ses) asynchronously, with the require-
ment that after each round/step/phase, all the processes sh ould be synchronized and all messages
sent should be delivered. This is the commonly understood no tion of a synchronous execution.
Withineachround/phase/step,theremaybeaﬁniteandbound ednumberofsequentialsub-rounds
(or sub-phases or sub-steps) that processes execute. Each s ub-round is assumed to send at most
onemessageperprocess; hencethemessage(s)sent willreac h ina singlemessagehop.
The timing diagram of an example synchronous execution is sh own in Figure 1.10. In this
system, there are four nodes P0toP3. In each round, process Pisends a message to P(i+1)mod4
andP(i−1)mod4and calculates some application-speciﬁc function on the re ceived values. The
messages are sent as per the code given in function Sync_Execution . There are krounds in the
execution.
1.7.1 Emulatinganasynchronoussystembyasynchronoussys tem(A→S).
Anasynchronousprogram(writtenforanasynchronoussyste m)canbeemulatedonasynchronous
systemfairly triviallyas thesynchronoussystemisa speci alcase ofan asynchronoussystem–all
communicationﬁnisheswithinthesameroundin whichitis in itiated.
1.7.2 Emulatingasynchronoussystembyanasynchronoussys tem(S→A).
A synchronous program (written for a synchronous system) ca n be emulated on an asynchronous
systemusinga toolcalled synchronizer ,tobestudiedinChapter 2.
19
phase 1 phase 2 phase 3PPP
P
320
1
(1)Sync_Execution (intk,n)
//There are krounds.
(2)forr=1tokdo
(3) process isends amessage to (i+ 1)mod nand(i−1)mod n;
(4) each process ireceives a message from (i+ 1)mod nand(i−1)mod n;
(5) compute someapplication-speciﬁc function onthe recei ved values.
Figure 1.10: An example of a synchronous execution in a messa ge-passing system. All the mes-
sages sentin aroundare receivedwithinthat sameround.
1.7.3 Emulations.
Section1.5showedhowasharedmemorysystemcouldbeemulat edbyamessage-passingsystem,
and vice-versa. We now have 4 broad classes of programs, as sh own in Figure 1.11. Using the
emulationsshown,anyclasscanbeemulatedbyanyother. Ifs ystemAcanbeemulatedbysystem
B,denotedA
B,andifaproblemisnotsolvablein B,thenitisalsonotsolvablein A. Likewise,ifa
problemis solvablein A, it isalso solvablein B. Hence, ina sense, all fourclasses are equivalent
interms of“computability”– what can and cannotbecomputed – infailure-free systems.
However,infault-pronesystems,thisisnotthecaseaswewi llseeinChapter14;asynchronous
systemoffersmorecomputabilitythan an asynchronoussyst em.
Synchronous 
shared memory (ASM)Asynchronous Synchronous
shared memory (SSM)message−passing (SMP)
SM−>MP MP−>SM SM−>MP MP−>SMA−>S
S−>AA−>SS−>A (AMP)Asynchronous 
message−passing
Figure1.11: Emulationsamongtheprincipalsystemclasses in afailure-free system.
20
1.8 DesignIssuesandChallenges
Distributedcomputingsystemshavebeen inwidespread exis tencesincethe1970swhen theinter-
netandARPANETcameintobeing. Atthetime,theprimaryissu esinthedesignofthedistributed
systems included providing access to remote data in the face of failures, ﬁle system design and
directory structure design. While these continue to be impo rtant issues, many newer issues have
surfacedasthewidespreadproliferationofthehigh-speed high-bandwidthinternetanddistributed
applicationscontinuesrapidly.
Below we describe the important design issues and challenge s after categorizing them as (i)
havingagreater componentrelated to systemsdesignand ope ratingsystemsdesign,or(ii)having
agreatercomponentrelatedtoalgorithmdesign,or(iii)em ergingfromrecenttechnologyadvances
and/ordrivenbynewapplications. Thereissomeoverlapbet weenthesecategories. However,itis
usefultoidentifythesecategoriesbecauseofthechasmamo ngthe(i)thesystemscommunity,(ii)
thetheoreticalalgorithmscommunitywithindistributedc omputing,and(iii)theforcesdrivingthe
emerging applicationsand technology. Forexample, thecur rent practiceof distributedcomputing
followstheclient-serverarchitecture to alarge degree, w hereas that receives scant attentionin the
theoretical distributed algorithms community. Two reason s for this chasm are as follows. First,
an overwhelming number of applications outside the scienti ﬁc computing community of users of
distributedsystemsare businessapplicationsforwhich si mplemodelsare adequate. Forexample,
the client server model has been ﬁrmly entrenched with the le gacy applicationsﬁrst developedby
theBlueChipcompanies(e.g., HP,IBM, Wang,DECwhichisnow Compaq,Microsoft)sincethe
1970sand1980s. Thismodelislargelyadequatefortraditio nalbusinessapplications. Second,the
state of the practice is largely controlled by industry stan dards, which do not necessarily choose
the“technicallybest”solution.
1.8.1 Distributed SystemsChallenges froma SystemPerspec tive
Thefollowingfunctionsmustbeaddressed whendesigningan d buildingadistributedsystem.
•Communication. This task involves designing appropriate m echanisms for communication
amongtheprocessesinthenetwork. Someexamplemechanisms are: RemoteProcedureCall
(RPC), Remote Object Invocation (ROI), message-oriented c ommunication versus stream-
orientedcommunication.
•Processes. Someoftheissuesinvolvedare: managementofpr ocessesandthreadsatclients/servers;
codemigration;and thedesignofsoftwareand mobileagents .
•Naming. Devising easy to use and robust schemes for names, id entiﬁers, and addresses is
essentialforlocatingresources and processes inatranspa rent and scalablemanner. Naming
in mobile systems provides additional challenges because n aming cannot easily be tied to
anystaticgeographical topology.
•Synchronization. Mechanismsfor synchronizationor coord ination amongthe processes are
essential. Mutual exclusion is the classical example of syn chronization, but many other
formsofsynchronization,suchasleaderelectionarealson eeded. Inaddition,synchronizing
physical clocks, and devising logical clocks that capture t he essence of the passage of time,
as wellas globalstaterecordingalgorithmsall requiredif ferentforms ofsynchronization.
21
•Datastorageandaccess. Schemesfordatastorage,andimpli citlyforaccessingthedataina
fast and scalable manner across the network are important fo r efﬁciency. Traditional issues
suchas ﬁle systemdesignhavetobereconsidered inthesetti ngofadistributedsystem.
•Consistency and replication. To avoid bottlenecks, to prov ide fast access to data, and to
provide scalability, replication of data objects is highly desirable. This leads to issues of
managing the replicas, and dealing with consistency among t he replicas/caches in a dis-
tributed setting. A simple exxample issue is deciding the le vel of granularity (i.e., size) of
dataaccess.
•Fault tolerance. Fault tolerance requires maintaining cor rect and efﬁcient operation in spite
of any failures of links, nodes, and processes. Process resi lience, reliable communication,
distributedcommit,checkpointingandrecovery,agreemen tandconsensus,failuredetection,
and self-stabilizationaresomeofthemechanismsto provid efault-tolerance.
•Security. Distributedsystemssecurityinvolvesvariousa spectsofcryptography,securechan-
nels,accesscontrol,keymanagement–generationanddistr ibution,authorization,andsecure
groupmanagement.
•Applications Programming Interface (API) and transparenc y. The API for communication
and other specialized services is important for the ease of u se and wider adoption of the
distributedsystemsservices by non-technical users. Tran sparency deals with hidingthe im-
plementation policies from the user, and can be classiﬁed as follows.Access transparency
hides differences in data representation on different syst ems and providing uniform opera-
tions to access system resources. Location transparency makes the locations of resources
transparent to the users. Migration transparency allows relocating resources without the
usersnoticingit. Theabilitytorelocatetheresourcesast heyarebeingaccessedis relocation
transparency .Replication transparency does not let the user become aware of any replica-
tion.Concurrency transparency deals with masking the concurrent use of shared resources
fortheuser. Failuretransparency refers tothesystembeing reliableand fault-tolerant.
•Scalability and modularity. The algorithms, data (objects ), and services must be as dis-
tributedaspossible. Varioustechniquessuchasreplicati on,cachingandcachemanagement,
and asynchronousprocessinghelp toachievescalability.
Someoftherecent experimentsin designinglarge-scale dis tributedsystemsincludetheGlobe
project at Vrije University [32], and the Globus project [33 ]. The Grid infrastructure for large-
scaledistributedcomputingisaveryambitiousprojecttha thasgainedsigniﬁcantattentiontodate
[35, 34]. Alltheseprojectsattemptto providetheabovelis tedfunctionsas efﬁciently as possible.
1.8.2 Algorithmic Challenges in Distributed Computing
The previous section addresses the challenges in designing distributed systems from a system
building perspective. In this section, we brieﬂy summarize the key algorithmic challenges in dis-
tributedcomputing.
22
Designing useful execution models andframeworks. Theinterleaving model and partialorder
modelaretwowidelyadoptedmodelsofdistributedsystemex ecutions. Theyhaveprovedto
beparticularlyusefulforoperationalreasoningandthede signofdistributedalgorithms. The
Input/Outputautomata modelandthe TLA (TemporalLogicofActions) aretwootherexam-
ples of models that provide different degrees of infrastruc ture for reasoning more formally
withand provingthecorrectness ofdistributedprograms.
Dynamicdistributed graph algorithmsand distributed rout ing algorithms. Thedistributedsys-
temismodeledasadistributedgraph,andthegraphalgorith msformthebuildingblocksfora
largenumberofhigherlevelcommunication,datadissemina tion,objectlocation,andobject
search functions. The algorithms need to deal with dynamica lly changing graph character-
istics, such as to model varying link loads in a routing algor ithm. The efﬁciency of these
algorithmsimpactsnotonlytheuser-perceivedlatencybut alsothetrafﬁcandhencetheload
or congestion in the network. Hence, the design of efﬁcient d istributed graph algorithms is
ofparamountimportance.
Timeand globalstateina distributed system. The processes in the system are spread across
three-dimensional physical space. Another dimension, tim e, has to be superimposed uni-
formly across space. The challenges pertain to providing ac curatephysical time , and to
providing a variant of time, called logical time . Logical time is relative time, and elimi-
nates the overheads of providing physical time for applicat ions where physical time is not
required. More importantly, logical time can (i) capture th e logic and inter-process depen-
dencies within the distributed program, and also (ii) track the relative progress at each pro-
cess.
Observingthe globalstate ofthesystem(acrossspace)alsoinvolvesthetimedimensio nfor
consistentobservation. Duetotheinherentdistributedna tureofthesystem,itisnotpossible
for any one process to directly observe a meaningful global s tate across all the processes,
withoutusingextrastate-gatheringeffort whichneeds tob edoneinacoordinated manner.
Deriving appropriate measures of concurrency also involve sthe time dimension,as judging
the independence of different threads of execution depends not only on the program logic
but also on execution speeds within the logical threads, and communication speeds among
threads.
Synchronization/ coordination mechanisms. Theprocessesmustbeallowedtoexecuteconcur-
rently, except when they need to synchronize to exchange inf ormation, i.e., communicate
about shared data. Synchronization is essential for the dis tributed processes to overcome
the limited observation of the system state from the viewpoi nt of any one process. Over-
coming this limited observation is necessary for taking any actions that would impact other
processes. The synchronization mechanisms can also be view ed as resource management
and concurrency management mechanisms to streamline the be havior of the processes that
wouldotherwiseactindependently. Herearesomeexampleso fproblemsrequiringsynchro-
nization.
•Physical clock synchronization. Physical clocks ususally diverge in their values due
to hardware limitations. Keeping them synchronized is a fun damental challenge to
maintaincommontime.
23
•Leader election. All theprocesses need to agree onwhich pro cess willplay theroleof
a distinguishedprocess – called a leader process. A leader i s necessary even for many
distributed algorithms because there is often some asymmet ry – as in initiating some
actionlikeabroadcastorcollectingthestateofthesystem ,orin“regenerating”atoken
that gets“lost”inthesystem.
•Mutual exclusion. This is clearly a synchronization proble m because access to the
critical resource(s)has to becoordinated.
•Deadlock detectionand resolution. Deadlock detectionsho uldbecoordinatedto avoid
duplicate work, and deadlock resolution should be coordina ted to avoid unnecessary
aborts ofprocesses.
•Termination detection. This requires cooperation among th e processes to detect the
speciﬁc globalstateofquiescence.
•Garbage collection. Garbagerefers to objectsthat are no lo ngerin useand that are not
pointed to by any other process. Detecting garbage requires coordination among the
processes.
Groupcommunication, multicast, andordered messagedeliv ery.Agroupisacollectionofpro-
cessesthatshareacommoncontextandcollaborateonacommo ntaskwithinanapplication
domain. Speciﬁc algorithms need to be designed to enable efﬁ cient group communication
and group management wherein processes can join and leave gr oups dynamically, or even
fail. When multipleprocesses send messages concurrently, different recipients may receive
themessagesindifferentorders,possiblyviolatingthese manticsofthedistributedprogram.
Hence,formalspeciﬁcationsofthesemanticsofordereddel iveryneedtobeformulated,and
thenimplemented.
Monitoring distributed events and predicates. Predicatesdeﬁned onprogramvariablesthatare
local to different processes are useful for specifying cond itions on the global system state,
andareusefulforapplicationssuchasdebugging,sensingt heenvironment,andinindustrial
process control. On-linealgorithmsformonitoringsuchpr edicates are henceimportant. An
important paradigm for monitoring distributed events is th at ofevent streaming , wherein
streams of relevant events reported from different process es are examined collectively to
detect predicates. Typically, the speciﬁcation of such pre dicates uses physical or logical
timerelationships.
Distributed program design andveriﬁcationtools. Methodically designed and veriﬁably cor-
rect programscangreatly reducetheoverheadofsoftwarede sign,debugging,and engineer-
ing. Designingmechanismstoachievethesedesignand veriﬁ cationgoalsis achallenge.
Debugging distributed programs. Debuggingsequentialprogramsishard;debuggingdistribu ted
programs is that much harder because of the concurrency in ac tions and the ensuing uncer-
tainty due to the large number of possible executions deﬁned by the interleaved concurrent
actions. Adequate debugging mechanisms and tools need to be designed to meet this chal-
lenge.
Data replication, consistency models, and caching. Fast access to data and other resources re-
quires them to be replicated in the distributed system. Mana ging such replicas in the face
24
of updates introduces the problems of ensuring consistency among the replicas and cached
copies. Additionally, placement of the replicas in the syst ems is also a challenge because
resources usuallycannotbefreely replicated.
WorldWideWebdesign– caching, searching, scheduling. TheWebisanexampleofawidespread
distributedsystemwithadirectinterfacetotheenduser,w hereintheoperationsarepredomi-
nantlyread-intensiveonmostobjects. Theissuesofobject replicationandcachingdiscussed
above have to be tailored to the web. Further, prefetching of objects when access patterns
and other characteristics of the objects are known, can also be performed. An example of
where prefetching can be used is the case of subscribing to Co ntent Distribution Servers.
Minimizing response time to minimize user-perceived laten cies is an important challenge.
Objectsearchandnavigationonthewebareimportantfuncti onsintheoperationoftheweb,
and are very resource-intensive. Designingmechanismsto d o this efﬁcientlyand accurately
aregreat challenges.
Distributed shared memory abstraction. Asharedmemoryabstractionsimpliﬁesthetaskofthe
programmer because he has to deal only with Read and Write ope rations, and no message
communicationprimitives. However, under the covers in the middlewarelayer, the abstrac-
tion of a shared address space has to be implemented by using m essage-passing. Hence, in
termsofoverheads,theshared memoryabstractionis notles sexpensive.
•Wait-free algorithms. Wait-freedom, which can be informal ly deﬁned as the ability
of a process to complete its execution irrespective of the ac tions of other processes,
gainedprominenceinthedesignofalgorithmstocontrolacc cesstosharedresourcesin
the shared memory abstraction. It corresponds to n−1-fault resilience in a nprocess
system and is an important principle in fault-tolerant syst em design. While wait-free
algorithms are highly desirable, they are also expensive, a nd designing low overhead
wait-free algorithmsisa challenge.
•Mutual exclusion. A ﬁrst course in Operating Systems covers the basic algorithms
(such as the Bakery algorithm and using semaphores) for mutu al exclusion in a mul-
tiprocessing (uniprocessor or multiprocessor) shared mem ory setting. More sophisti-
cated algorithms – such as those based on hardware primitive s, fast mutual exclusion,
and wait-free algorithms– willbecovered inthisbook.
•Registerconstructions. Inlightofpromisingandemerging technologiesoftomorrow–
such as biocomputingand quantumcomputing– that can alter t hepresent foundations
of computer “hardware” design, we need to revisit the assump tions of memory access
ofcurrent systemsthatare exclusivelybasedon thesemicon ductortechnologyandthe
von Neumann architecture. Speciﬁcally, the assumption of s ingle/multiport memory
with serial access via the bus in tight synchronization with the system hardware clock
may not be a valid assumption in the possibility of “unrestri cted” and “overlapping”
concurrent access to the same memory location. The study of r egister constructions
deals with the design of registers from scratch, with very we ak assumptions on the
accessesallowedtoaregister. Thisﬁeldformsafoundation forfuturearchitecturesthat
allowconcurrentaccesseventoprimitiveunitsofmemory(i ndependentoftechnology)
withoutanyrestrictionsontheconcurrency permitted.
25
•Consistency models. For multiple copies of a variable/obje ct, varying degrees of con-
sistency among the replicas can be allowed. These represent a trade-off of coherence
versus cost of implementation. Clearly, a strict deﬁnition of consistency (such as in a
uniprocessor system) would be expensive to implement in ter ms of high latency, high
message overhead, and low concurrency. Hence, relaxed but s till meaningful models
ofconsistencyaredesirable.
Reliableandfault-tolerant distributed systems. A reliable and fault-tolerant environment has
multiplerequirementsand aspects,and thesecan beaddress ed usingvariousstrategies.
•Consensus algorithms. All algorithms ultimately rely on me ssage-passing, and the
recipients take actions based on the contents of the receive d messages. Consensus
algorithmsallowcorrectlyfunctioningprocessestoreach agreementamongthemselves
in spiteoftheexistenceofsomemalicious(adversarial)pr ocesseswhoseidentitiesare
notknowntothecorrectlyfunctioningprocesses. Thegoalo fthemaliciousprocessesis
topreventthecorrectlyfunctioningprocessesfromreachi ngagreement. Themalicious
processes operate by sending messages with misleading info rmation, to confuse the
correctly functioningprocesses.
•Replication and replica management. Replication (as in hav ing backup servers) is a
classicalmethodofprovidingfault-tolerance. TheTriple ModularRedundancy(TMR)
technique has long been used in software as well as hardware i nstallations. More so-
phisticatedand efﬁcient mechanismsforreplicationare th esubject ofstudyhere.
•Voting and quorum systems. Providing redundancy in the acti ve (e.g., processes) or
passive(e.g., hardware resources) components in the syste m and then performing vot-
ing based on some quorum criterion is a classical way of deali ng with fault-tolerance.
Designingefﬁcient algorithmsforthispurposeis thechall enge.
•Distributeddatabasesanddistributedcommit. Fordistrib uteddatabases,thetraditional
properties ofthe transaction (A.C.I.D. – Atomicity,Consi stency,Isolation,Durability)
need to be preserved in the distributed setting. The ﬁeld of t raditional “transaction
commit”protocolsis a fairly maturaarea. Transactionalpr operties can also be viewed
ashavingacounterpartforguaranteesonmessagedeliveryi ngroupcommunicationin
thepresence offailures. Resultsdevelopedinoneﬁeld can b eadapted totheother.
•Self-stabilizing systems. All system executions have asso ciated good (or legal) states
and bad (or illegal) states; during correct functioning, th e system makes transitions
among the good states. Faults, internal or external to the pr ogram and system, may
causeabadstatetoariseintheexecution. A self-stabilizing algorithmisanyalgorithm
that isguaranteed to eventuallytakethesystemtoagood sta teevenifabad statewere
toariseduetosomeerror. Self-stabilizingalgorithmsreq uiresomein-builtredundancy
to track additional variables of the state or by doing extra w ork. Designing efﬁcient
self-stabilizingalgorithmsisachallenge.
•Checkpointing and recovery algorithms. Checkpointing inv olves periodically record-
ing stateonsecondary storageso thatin case ofafailure, th eentirecomputationis not
lost but can be recovered from one of the recently taken check points. Checkpointing
26
in a distributedenvironment is difﬁcult because if the chec kpoints at the different pro-
cessesarenotcoordinated,thelocalcheckpointsmaybecom euselessbecausetheyare
inconsistentwiththecheckpointsat otherprocesses.
•Failure detectors. A fundamental limitation of asynchrono us distributed systems is
that there is no theoretical bound on the message transmissi on times. Hence, it is
impossible to distinguish a sent-but-not-yet-arrived mes sage from a message that was
never sent. This implies that it is impossibleusing message transmissionto determine
whether some other process across thenetwork is aliveor has failed. Failuredetectors
represent a class of algorithmsthat probabilisticallysus pect another process as having
failed (suchas aftertimingoutafternon-receiptofamessa geforsometime),andthen
convergeon adeterminationoftheup/downstatusofthesusp ected process.
Loadbalancing. The goal of load balancing is to gain higher throughput, and r educe the user-
perceivedlatency. Load balancing maybe necessary because ofavariety offactors such as:
high network trafﬁc or high request rate causing the network connection to be a bottleneck,
or high computational load. A common situation where load ba lancing is used is in server
farms, where the objective is to service incoming client req uests with the least turnaround
time. Severalresultsfromtraditionaloperatingsystemsc anbeusedhere,althoughtheyneed
to be adapted to the speciﬁcs of the distributedenvironment . The followingare some forms
ofloadbalancing.
•Data migration. The ability to move data (which may be replic ated) around in the
system,based ontheaccess pattern oftheusers.
•Computation migration. The ability to relocate processes i n order to perform a redis-
tributionoftheworkload.
•Distributed scheduling. This achieves a better turnaround time for the users by using
idleprocessingpowerin thesystemmoreefﬁciently.
Real-timescheduling. Real-time scheduling is important for mission-critical ap plications, to ac-
complish the task execution on schedule. The problem become s more challenging in a
distributed system where a global view of the system state is absent. On-line or dynamic
changes tothescheduleare alsoharder tomakewithoutaglob alviewofthestate.
Furthermore, message propagation delays which are network -dependent are hard to con-
trol or predict, which makes meeting real-time guarantees t hat are inherently dependent on
communicationamongtheprocessesharder. Althoughnetwor ksofferingQuality-of-Service
guaranteescanbeused,theyalleviatetheuncertaintyinpr opagationdelaysonlytoalimited
extent. Further, suchnetworksmay notalways beavailable.
Performance. Although high throughput is not the primary goal of using a di stributed system,
achieving good performance is important. In large distribu ted systems, network latency
(propagationandtransmissiontimes)andaccesstosharedr esourcescanleadtolargedelays
whichmustbeminimized. Theuser-perceivedturn-aroundti meis veryimportant.
Thefollowingaresomeexampleissuesarisein determiningt heperformance.
27
•Metrics. Appropriate metrics must be deﬁned or identiﬁed fo r measuring the perfor-
mance of theoretical distributed algorithms, as well as for implementations of such
algorithms. The former would involve various complexity me asures on the metrics,
whereas thelatterwouldinvolvevarioussystemandstatist icalmetrics.
•Measurement methods/tools. As a real distributed system is a complex entity and has
to deal with all the difﬁculties that arise in measuring perf ormance over a WAN/the
Internet, appropriate methodologies and tools must be deve loped for measuring the
performance metrics.
1.8.3 Applications ofDistributed Computing and Newer Chal lenges
Mobilesystems. Mobilesystemstypicallyusewirelesscommunicationwhich isbasedonelectro-
magneticwaves and utilizes a shared broadcast medium. Henc e, the characteristics of com-
municationare different; many issues such as range of trans missionand power of transmis-
sion come into play, besides various engineering issues suc h as battery powerconservation,
interfacing with the wired internet, signal processing and interference. From a computer
science perspective, there is a rich set of problems such as r outing, location management,
channelallocation,localizationandpositionestimation ,andtheoverallmanagementofmo-
bility.
There are two popular architectures for a mobile network. Th e ﬁrst is the base-station ap-
proach,alsoknownasthe cellularapproach ,whereina cellwhichisthegeographicalregion
within range of a static but powerful base transmission stat ion is associated with that base
station. All mobile processes in that cell communicate with the rest of the system via the
base station. The second approach is the ad-hoc network approach where there is no base
station (which essentially acted as a centralized node for i ts cell). All responsibility for
communicationisdistributedamongthemobilenodes,where inmobilenodeshavetopartic-
ipate in routing by forwarding packets of other pairs of comm unicating nodes. Clearly, this
is a complex model. It poses many graph-theoretical challen ges from a computer science
perspective,in additionto variousengineering challenge s.
Sensor networks. A sensor is a processor with an electro-mechanical interfac e that is capable of
sensing physical parameters, such as temperature, velocit y, pressure, humidity, and chemi-
cals. Recent developments in cost-effective hardware tech nology have made it possible to
deploy very large (of the order of 106or higher) low-cost sensors. An important paradigm
for monitoring distributed events is that of event streaming , deﬁned earlier. The streaming
data reported from a sensor network differs from the streami ng data reported by “computer
processes”inthattheeventsreportedbyasensornetworkar eintheenvironment,externalto
thecomputernetworkandprocesses. Thislimitsthenatureo finformationaboutthereported
eventinasensornetwork.
Sensornetworkshaveawiderangeofapplications. Sensorsm aybemobileorstatic;sensors
maycommunicatewirelessly,althoughtheymayalsocommuni cateacrossawirewhenthey
arestaticallyinstalled. Sensorsmayhavetoself-conﬁgur etoformanad-hocnetwork,which
introducesawholenew setofchallenges, suchas positiones timationand timeestimation.
28
Ubiquitous orpervasivecomputing. Ubiquitous systems represent a class of computing where
theprocessorsembedded inand seamlesslypervadingthroug htheenvironmentperform ap-
plication functions in the background, much like in the sci- ﬁ movies. The intelligent home,
and the smart workplace are some example of ubiquitous envir onments currently under in-
tense research and development. Ubiquitous systems are ess entially distributed systems;
recent advances in technology allow them to leverage wirele ss communication and sensor
andactuatormechanisms. Theycanbeself-organizingandne twork-centric,whilealsobeing
resourceconstrained. Suchsystemsaretypicallycharacte rizedashavingmanysmallproces-
sorsoperatingcollectivelyinadynamicambientnetwork. T heprocessorsmaybeconnected
to more powerful networks and processing resources in the ba ckground for processing and
collatingdata.
Peer-to-peer computing. Peer-to-peer(P2P)computingrepresentscomputingoveran application
layer network wherein all interactions among the processor s are at a “peer” level, without
any hierarchy among the processors. Thus, all processors ar e equal and play a symmetric
role in the computation. P2P computing arose as a paradigm sh ift from client-server com-
putingwheretherolesamongtheprocessorsareessentially asymmetrical. P2Pnetworksare
typically self-organizing, and may or may not have a regular structure to the network. No
central directories (such as those used in Domain Name Serve rs) for name resolution and
objectlookupare allowed. Someofthekeychallenges includ e: object storagemechanisms,
efﬁcient object lookup and retreival in a scalable manner; d ynamic reconﬁguration with
nodes as well as objects joining and leaving the network rand omly; replication strategies
to expedite object search; tradeoffs between object size la tency and table sizes; anonymity,
privacy,andsecurity.
Publish-subscribe, content distribution, and multimedia .With the explosion in the amount of
information, there is a greater need to receive and access on ly information of interest. Such
information can be speciﬁed using ﬁlters. In a dynamic envir onment where the information
constantly ﬂuctuates (varying stock prices is a typical exa mple), there needs to be: (i) an
efﬁcient mechanism for distributing this information ( publish), (ii) an efﬁcient mechanism
to allowend users to indicateinterest in receiving speciﬁc kindsof information( subscribe ),
and(iii)anefﬁcientmechanismforaggregatinglargevolum esofpublishedinformationand
ﬁlteringit asper theuser’s subscriptionﬁlter.
Content distributionrefers to a class of mechanisms, prima rily in the web and P2P comput-
ing context, whereby speciﬁc information which can be broad ly characterized by a set of
parametersistobedistributedtointerestedprocesses. Cl early,thereisoverlapbetweencon-
tentdistributionmechanismsandpublish-subscribemecha nisms. Whenthecontentinvolves
multimedia data, special requirement such as the following arise: multimedia data is usu-
ally very large and information-intensive, requires compr ession, and often requires special
synchronizationduringstorageand playback.
Distributed agents. Agents are software processes or robots that can move around the system to
do speciﬁc tasks for which they are specially programmed. Th e name “agent” derives from
the fact that the agents do work on behalf of some broader obje ctive. Agents collect and
processinformation,andcanexchangesuchinformationwit hotheragents. Often,theagents
29
cooperateasinanantcolony,buttheycanalsohavefriendly competition,asinafreemarket
economy. Challenges in distributedagent systemsincludec oordinationmechanismsamong
the agents, controlling the mobility of the agents, and thei r software design and interfaces.
Research in agents is inter-disciplinary: spanning artiﬁc ial intelligence, mobile computing,
economicmarket models,softwareengineering,and distrib utedcomputing.
Distributed data mining. Data mining algorithms examine large amounts of data to dete ct pat-
terns and trends in the data, to mineor extract useful information. A traditional example is:
examiningthepurchasingpatternsofcustomersinordertop roﬁlethecustomersandenhance
the efﬁcacy of directed marketing schemes. The mining can be done by applying database
andartiﬁcialintelligencetechniquestoadatarepository . Inmanysituations,thedataisnec-
essarilydistributedandcannotbecollectedinasinglerep ository,as inbankingapplications
where the data is privateand sensitive, or in atmosphericwe ather prediction where the data
sets are far too massive to collect and process at a single rep ository in real-time. In such
cases, efﬁcient distributeddataminingalgorithmsare req uired.
Gridcomputing. Analogous to the electrical power distribution grid, it is e nvisaged that the in-
formationandcomputinggridwillbecomearealitysomeday. Verysimplystated,idleCPU
cyclesofmachinesconnectedtothenetworkwillbeavailabl etoothers. Manychallengesin
makinggridcomputingarealityinclude: schedulingjobsin suchadistributedenvironment,
a framework for implementing Quality of Service and real-ti me guarantees, and of course,
securityofindividualmachinesas wellas ofjobsbeingexec utedin thissetting.
Security indistributed systems. Thetraditionalchallengesofsecurityinadistributedset tingin-
clude: conﬁdentiality (ensuring that only authorized proc esses can access certain informa-
tion), authentication (ensuring the source of received inf ormation and the identity of the
sendingprocess), and availability(maintainingallowed a ccess to services despitemalicious
actions). The goal is to meet these challenges with efﬁcient and scalable solutions. These
basic challenges have been addressed in traditional distri buted settings. For the newer dis-
tributed architectures, such as wireless, peer-to-peer, g rid, and pervasive computing dis-
cussed in this subsection), these challenges become more in teresting due to factors such as
aresource-constrained environment,abroadcast medium,t helack ofstructure, and thelack
oftrustinthenetwork.
1.9 SelectionandCoverageof Topics
This is a long list of topics and difﬁcult to cover in a single t extbook. This book covers a broad
selection of topics from the above list, in order to present t he fundamental principles underlying
the various topics. The goal has been to select topics that wi ll give a good understanding of the
ﬁeld, and ofthetechniquesused todesignsolutions.
Sometopicsthathavebeenomittedareinterdisciplinary,a crossﬁeldswithincomputerscience.
An example is load balancing, which is traditionally covere d in detail in a course on Parallel
Processing. As the focus of distributed systems has shifted away from gaining higher efﬁciency
to providing better services and fault-tolerance, the impo rtance of load balancing in distributed
computing has diminished. Another example is mobilesystem s. A mobilesystem is a distributed
30
system having certain unique characteristics, and there ar e courses devoted speciﬁcally to mobile
systems.
1.10 ChapterSummary
Thischapterﬁrstcharacterizeddistributedsystemsbyloo kingatvariousinformaldeﬁnitionsbased
onfunctionalaspects. Itthenlookedatvariousarchitectu resofmultipleprocessorsystems,andthe
requirements that have traditionally driven distributed s ystems. The relationship of a distributed
systemto“middleware”,theoperatingsystem,andthenetwo rkprotocolstackprovidedadifferent
perspectiveonadistributedsystem.
The relationship between parallel systems and distributed systems, covering aspects such de-
grees of software and hardware coupling, and the relative pl acement of the processors, memory
units, and interconnection networks, was examined in detai l. There is some overlap between the
ﬁelds of parallel computing and distributed computing, and hence it is important to understand
their relationhip clearly. For example, various interconn ection networks such as the Omega net-
work,theButterﬂynetwork,andthehypercubenetwork,were designedforparallelcomputingbut
theyarerecentlyﬁndingsurprisingapplicationsinthedes ignofapplication-leveloverlaynetworks
for distributed computing. The traditional taxonomy of mul tiple processor systems by Flynn was
also studied. Important concepts such as the degree of paral lelism and of concurrency, and the
degreeofcouplingwere alsointroducedinformally.
The chapter then introduced three fundamental concepts in d istributed computing. The ﬁrst
concept is the paradigm of shared memory communication vers us message-passing communica-
tion. Thesecondconceptistheparadigmofsynchronousexec utionsandasynchronousexecutions.
Forboththeseconcepts,emulationofoneparadigmbyanothe rwasstudiedforerror-free systems.
The third concept was that of synchronous and asynchronous s end communication primitives, of
synchronousreceivecommunicaitonprimitives,andofbloc kingandnonblockingsendandreceive
communicationprimitives.
The chapter then presented design issues and challenges in t he ﬁeld of distributed computing.
The challenges were classiﬁed as (i) being important from a s ystems design perspective, or (ii)
being importantfrom an algorithmicperspective,or (iii)t hosethat are drivenby new applications
and emerging technologies. This classiﬁcation is not ortho gonal and is somewhat subjective. The
various topics that will be covered in the rest of the book are portrayed on a miniature canvas in
thesectiononthedesignissuesand challenges.
1.11 BibliographicNotes
The selection of topics and material for this book has been sh aped by the authors’ perception of
theimportanceofvarioussubjects,as well asthecoverageb ytheexistingtextbooks.
Therearemanybooksondistributedcomputinganddistribut edsystems. AttiyaandWelch [1]
and Lynch [7] provide a formal theoretical treatment of the ﬁ eld. The books by Barbosa [2] and
Tel [12] focus on algorithms. The books by Chow and Johnson [3 ], Coulouris, Dollimore, and
Kindberg [4], Garg [5], Goscinski [6], Mullender [8], Rayna l [22], Singhal and Shivaratri [10],
and Tanenbaumand vanSteen [11]provideablendoftheoretic al and systemsissues.
31
Much of the material in this introductory chapter is based on well understood concepts and
paradigms in the distributed systems community, and is difﬁ cult to attribute to any particular
source.
A recent overview of the challenges in middleware design fro m systems’ perspective is given
inthespecialissuebyLea,Vinoski,andVogels[30]. Anover viewoftheCommonObjectRequest
Broker Model (CORBA) of the Object Management Group (OMG) is given by Vinoski[22]. The
DistributedComponentObjectModel(DCOM)fromMicrosoft, Sun’sJavaRemoteMethodInvo-
cation(RMI), andCORBA areanalyzedinperspectivebyCampb ell,Coulson,andKounavis[26].
A detailed treatment of CORBA, RMI, and RPC is given by Coulou ris, Dollimore, and Kindberg
[4]. The Open Foundations’s Distributed Computing Environ ment (DCE) is described in [31];
DCE is not likely to be enjoy a continuing support base. Descr iptions of the Message Passing In-
terface can befoundinSniret al. [23]and Groppet al. [24]. T heParallelVirtualMachine(PVM)
frameworkfor paralleldistributedprogrammingisdescrib ed bySunderam [29].
The discussion of parallel processing, and of the UMA and NUM A parallel architectures, is
based on Kumar, Grama, Gupta, and Karypis [18]. The properti es of the hypercube architecture
aresurveyedbyFeng[27]andHarary,Hayes,andWu[28]. Them ulti-stageinterconnectionarchi-
tectures – the Omega (Benes) [14], the Butterﬂy [16], and Clo s [15] were proposed in the papers
indicated. Agoodoverviewofmultistageinterconnectionn etworksisgivenbyWuandFeng[25].
Flynn’s taxomomy of multiprocessors is based on [21]. The di scussion on blocking/nonblocking
primitivesaswellassynchronousandasynchropnousprimit ivesisextendedfromCypherandLeu
[20]. The section on design issues and challenges is based on the vast research literature in the
area.
TheGlobearchitectureisdescribedbyvanSteen,Homburg,a ndTanenbaum[32]. TheGlobus
architectureisdescribed byFosterand Kesselman[33]. The gridinfrastructureand thedistributed
computngvisionforthe21stcenturyisdescribedbyFostera ndKesselman[35]andbyFoster[34].
The World-Wide Web is an excellent example of a distributed s ystem that has largely evolved of
itsown;TimBerners-LeeiscreditedwithseedingtheWWWpro ject;itsearlydescriptionisgiven
by Berners-Lee, Cailliau,Luotonen,Nielsen,and Secret [3 6].
1.12 ExerciseProblems
1. What arethemaindifferences between aparallel systeman d adistributedsystem?
2. Identify some distributed applications in the scientiﬁc and commercial application areas.
For each application, determine which of the motivating fac tors listed in Section 1.3 are
importantforbuildingtheapplicationoveradistributeds ystem.
3. Draw theOmegaand Butterﬂy networksfor n= 16inputsand outputs.
4. For the Omega and Butterﬂy networks shown in Figure 1.4, tr ace the paths from P5toM2,
and fromP6toM1.
5. FormulatetheinterconnectionfunctionfortheOmeganet workhaving ninputsand outputs,
only in terms of the M=n/2switch numbers in each stage. (Hint: Follow an approach
similartotheButterﬂy networkformulation.)
32
6. In Figure 1.4, observe that the paths from input 000 to outp ut 111 and from input 101 to
output 110 have a common edge. Therefore, simultaneous tran smission over these paths
is not possible; one path blocksanother. Hence, the Omega and Butterﬂy networks are
classiﬁed as blocking interconnectionnetworks .
LetΠ(n)beanypermutationon {0...n−1},mappingtheinputdomaintotheoutputrange.
Anonblockinginterconnectionnetwork allowssimultaneoustransmissionfromtheinputsto
theoutputsforanypermutation.
Considerthenetworkbuiltas follows. Taketheimageofa but terﬂyin avertical mirror,and
append this mirror image to the output of a butterﬂy. Hence, f orninputs and outputs, there
willbe 2log2nstages. Provethatthisnetworkis nonblocking.
7. The Baseline Clos network has a interconnection generati on function as follows. Let there
beM=n/2switches per stage, and let a switch be denoted by the tuple ∝a\}⌊ra⌋k⌉tl⌉{tx,s∝a\}⌊ra⌋k⌉tri}ht, where
x∈[0,M−1]and stages∈[0,log2n−1].
Thereisanedgefromswitch ∝a\}⌊ra⌋k⌉tl⌉{tx,s∝a\}⌊ra⌋k⌉tri}httoswitch∝a\}⌊ra⌋k⌉tl⌉{ty,s+ 1∝a\}⌊ra⌋k⌉tri}htif(i)yisthecyclicright-shiftofthe
(log2n−s)least signiﬁcant bits of x, (ii)yis the cyclic right-shift of the (log2n−s)least
signiﬁcantbitsof x′, wherex′isobtained bycomplementingtheLSB of x.
Draw the interconnection diagram for the Clos network havin gn= 16inputs and outputs,
i.e.,having 8switchesin each ofthe4stages.
8. Twointerconnectionnetworksareisomorphicifthereisa 1:1mapping fbetweentheswitches
such that forany switches xandythatare connected to each otherin adjacent stages in one
network,f(x)andf(y)arealsoconnected in theothernetwork.
ShowthattheOmega,Butterﬂy, and Clos(Baseline) networks areisomorphicto each other.
9. Explainwhya Receivecall cannot beasynchronous.
10. What are the three aspects of reliability? Is it possible to order them in different ways in
terms of importance, based on different applications’ requ irements? Justify your answer by
givingexamplesofdifferentapplications.
11. Figure 1.11 shows the emulations among the principal sys tem classes in a failure-free sys-
tem.
(a) Which oftheseemulationsarepossibleinafailure-pron esystem? Explain.
(b) Which oftheseemulationsarenotpossibleinafailure-p ronesystem? Explain.
12. Examine the impact of unreliable links and node failures on each of the challenges listed in
Section 1.8.2.
33
Bibliography
[1] H.Attiya,J.Welch,DistributedComputingFundamental s,Simulations,andAdvancedTopics,
WileyInter-Science, 2ndedition,2004.
[2] V. Barbosa, An Introductionto DistributedAlgorithms, MITPress, 1996.
[3] R. Chow and D. Johnson, Distributed Operating Systems an d Algorithms, Addison-Wesley,
1997.
[4] G. Coulouris, J. Dollimore, and T. Kindberg, Distribute d Systems Concepts and Design,
Addison-Wesley,3rd edition,2001.
[5] V. Garg, ElementsofDistributedComputing,JohnWiley, 2003.
[6] A. Goscinski,DistributedOperating Systems: TheLogic alDesign,Addison-Wesley,1991.
[7] N. Lynch,DistributedAlgorithms,Morgan Kaufmann,199 6.
[8] S. Mullender,DistributedSystems,Addison-Wesley,2n dedition,1993.
[9] M.Raynal, DistributedAlgorithmsand Protocols,JohnW iley,1988.
[10] M.SinghalandN.Shivaratri,AdvancedConceptsinOper atingSystems,McGrawHill,1994.
[11] A.Tanenbaum,M.VanSteen,DistributedSystems: Princ iplesandParadigms,Prentice-Hall,
2003.
[12] G.Tel, IntroductiontoDistributedAlgorithms,Cambr idgeUniversityPress, 1994.
[13] A.Ananda,B.Tay,E,Koh,Asurveyofasynchronousremor eprocedurecalls,ACMSIGOPS
OperatingSystemsReview,26(2): 92-109,1992.
[14] V.E.Benes,MathematicalTheoryofConnectingNetwork sandTelephoneTrafﬁc,Academic
Press, New York,1965.
[15] C. Clos, A study of non-blocking switching networks, Be ll Systems Technical Journal, 32:
406-424,1953.
[16] J.M.Cooley,J.W.Tukey,Analgorithmforthemachineca lculationofcompleFourierseries,
MathematicalComp.,19,297-301,1965.
34
[17] A.Birrell,B.Nelson,Implementingremoteprocedurec alls,ACMTransactionsonComputer
Systems,2(1): 39-59, 1984.
[18] V. Kumar, A. Grama, A. Gupta, G. Karypis, Introduction t o Parallel Computing, Benjamin-
Cummins,2nd edition,2003.
[19] A.Tanenbaum, ComputerNetworks,3rd edition,Prentic e-Hall PTR, NJ, 1996.1994
[20] R. Cypher, E. Leu, The semantics of blocking and nonbloc king send and receive primitives,
8thInternationalSymposiumon ParallelProcessing, 729-7 35,1994.
[21] M. Flynn, Some computer organizations and their effect iveness, IEEE Trans. Comput., Vol.
C-21, pp.94, 1972.
[22] S. Vinoski, CORBA: Integrating diverse applications w ithin heterogeneous distributed envi-
ronments,IEEECommunicationsMagazine,35(2): 1997.
[23] M.Snir,S. Otto,S.Huss-Lederman,D. Walker,J.Dongar ra, MPI:TheCompleteReference,
MITPress, 1996.
[24] W. Gropp, E. Lusk, A. Skjellum, Using MPI: portable para llel programming with the
message-passinginterface, MITPress, 1994.
[25] C.L. Wu, T.-Y. Feng, On a class of multistage interconne ction networks, IEEE Transactions
onComputers. Vol.C-29, pp.694-702.Aug. 1980
[26] A. Campbell, G. Coulson, M. Counavis, Managing complex ity: Middleware explained, IT
ProfessionalMagazine, October1999.
[27] T.Y. Feng, A surveyofinterconnectionnetworks,IEEE C omput.,14,pp.12-27, Dec. 1981.
[28] F. Harary, J.P. Hayes, H. Wu, A survey of the theory of hyp ercube graphs, Computational
MathematicalApplications15(4): 277-289,1988.
[29] V.Sunderam,PVM:Aframeworkforparalleldistributed computing,Concurrency-Practice
and Experience, 2(4): 315-339,1990.
[30] D. Lea, S. Vinoski, W. Vogels, Guest editors’ introduct ion: Asynchronous middleware and
services, IEEEInternet Computing,10(1): 14-17,2006.
[31] J. Shirley, W. Hu, D. Magid, Guide to Writing DCE Applica tions, O’Reilly and Associates,
Inc., ISBN 1-56592-045-7,USA.
[32] M. van Steen, P. Homburg, A. Tanenbaum, Globe: A wide-ar ea distributed system, IEEE
Concurrency,70-78, 1999.
[33] I. Foster, C. Kesselman, Globus: A metacomputinginfra structure toolkit,International Jour-
nal ofSupercomputerApplications,11(2): 115-128,1997.
[34] I. Foster, The Grid: A new infrastructure for 21st centu ry science, Physics Today, 55(2):42-
47,2002.
35
[35] I. Foster, C. Kesselman, The Grid: Blueprint for a New Co mputing Infrastructure, Morgan
Kaufmann,1998.
[36] T.Berners-Lee,R.Cailliau,A.Luotonen,H.Nielsen,A .Secret,TheWorld-WideWeb,Com-
municationsoftheACM, 37(8): 76-82,1994.
36
Chapter2
A ModelofDistributed Computations
A distributed system consists of a set of processors that are connected by a communication net-
work. The communication network provides the facility of in formation exchange among proces-
sors. Thecommunicationdelayisﬁnitebutunpredictable. T heprocessorsdonotshareacommon
global memory and communicate solely by passing messages ov er the communication network.
Thereisnophysicalglobalclockinthesystemtowhichproce sseshaveinstantaneousaccess. The
communication medium may deliver messages out of order, mes sages may be lost, garbled, or
duplicated due to timeout and retransmission, processors m ay fail, and communication links may
godown. Thesystemcanbemodeledasadirectedgraphinwhich verticesrepresenttheprocesses
and edges represent unidirectionalcommunicationchannel s.
Adistributedapplicationrunsasacollectionofprocesses onadistributedsystem. Thischapter
presentsamodelofadistributedcomputationandintroduce sseveralterms,concepts,andnotations
thatwillbeused inthesubsequentchapters.
2.1 ADistributedProgram
A distributed program is composed of a set of nasynchronous processes p1,p2, ...,pi, ...,pnthat
communicatebymessagepassingoverthecommunicationnetw ork. Withoutlossofgenerality,we
assume that each process is running on a different processor . The processes do not share a global
memoryandcommunicatesolelybypassingmessages. Let Cijdenotethechannelfromprocess pi
toprocesspjandletmijdenoteamessagesentby pitopj. Thecommunicationdelayisﬁniteand
unpredictable. Also, these processes do not share a global c lock that is instantaneouslyaccessible
to these processes. Process execution and message transfer are asynchronous – a process may
executeanactionspontaneouslyandaprocesssendingamess agedoesnotwaitforthedeliveryof
themessagetobecomplete.
Theglobalstateofadistributedcomputationiscomposedof thestatesoftheprocessesandthe
communicationchannels[2]. Thestateofaprocessischarac terizedbythestateofitslocalmemory
and depends upon the context. The state of a channel is charac terized by the set of messages in
transitinthechannel.
37
2.2 AModel ofDistributedExecutions
Theexecutionofaprocessconsistsofasequentialexecutio nofitsactions. Theactionsareatomic
andtheactionsofaprocessaremodeledasthreetypesofeven ts,namely,internalevents,message
send events, and message receive events. Let ex
idenote thexth event at process pi. Subscripts
and/or superscripts will be dropped when they are irrelevan t or are clear from the context. For a
messagem, letsend(m)andrec(m)denoteitssendand receiveevents,respectively.
Theoccurrenceofeventschangesthestatesofrespectivepr ocessesandchannels,thuscausing
transitionsintheglobalsystemstate. Aninternaleventch angesthestateoftheprocessatwhichit
occurs. A send event (or a receive event) changes the state of the process that sends (or receives)
the message and the state of the channel on which the message i s sent (or received). An internal
eventonlyaffects theprocess at whichit occurs.
The events at a process are linearly ordered by their order of occurrence. The execution of
processpiproducesasequenceofevents e1
i,e2
i, ...,ex
i,ex+1
i, ... and isdenotedby Hiwhere
Hi=(hi,→i)
hiisthesetofeventsproducedby piandbinaryrelation →ideﬁnesalinearorderontheseevents.
Relation→iexpressescausal dependencies amongtheeventsof pi.
Thesendandthereceiveeventssignifytheﬂowofinformatio nbetweenprocessesandestablish
causal dependency from thesender process to the receiver pr ocess. A relation→msgthat captures
the causal dependency due to message exchange, is deﬁned as f ollows. For every message mthat
isexchanged between twoprocesses, wehave
send(m)→msgrec(m).
Relation→msgdeﬁnes causal dependencies between the pairs of correspond ing send and receive
events.
p
p
p1
2
3e
e
e321e1e1e1e1
e2e2e2 e2
e2
e3e3
e312 3 4
1 2 3 4
5
23
45
6
1
time
Figure2.1: Thespace-timediagramofadistributedexecuti on.
Theevolutionofadistributedexecutionisdepictedbyaspa ce-timediagram. Figure2.1shows
the time-space diagram of a distributed execution involvin g three processes. A horizontal line
represents the progress of the process; a dot indicates an ev ent; a slant arrow indicates a message
transfer. Generally, the execution of an event takes a ﬁnite amount of time; however, since we
38
assume that an event execution is atomic (hence, indivisibl e and instantaneous), it is justiﬁed to
denote it as a dot on a process line. In this ﬁgure, for process p1, the second event is a message
send event,thethirdeventisan internalevent,and thefour th eventis amessagereceiveevent.
CausalPrecedence Relation
The execution of a distributed application results in a set o f distributed events produced by the
processes. Let H=∪ihidenote the set of events executed in a distributed computati on. Next, we
deﬁne a binary relation on the set H, denoted as→, that expresses causal dependencies between
eventsin thedistributedexecution.
∀ex
i,∀ey
j∈H, ex
i→ey
j⇔

ex
i→iey
ji.e.,(i=j)∧(x≤y)
or
ex
i→msgey
j
or
∃ez
k∈H:ex
i→ez
k∧ez
k→ey
j
Thecausalprecedencerelationinducesanirreﬂexiveparti alorderontheeventsofadistributed
computation[6]thatis denotedas H=(H,→).
Notethattherelation →isLamport’s“happensbefore"relation1[4]. Foranytwoevents eiand
ej, ifei→ej, then event ejis directly or transitivelydependent on event ei; graphically, it means
that there exists a path consisting of message arrows and pro cess-line segments (along increasing
time)inthespace-timediagramthatstartsat eiandendsatej. Forexample,inFigure2.1, e1
1→e3
3
ande3
3→e6
2. Note that relation →denotes ﬂow of information in a distributed computation and
ei→ejdictatesthatalltheinformationavailableat eiispotentiallyaccessibleat ej. Forexample,
inFigure2.1, event e6
2has theknowledgeofallothereventsshownintheﬁgure.
For any two events eiandej,ei∝\⌉}atio\slash→ejdenotes the fact that event ejdoes not directly or
transitively dependent on event ei. That is, event eidoes not causally affect event ej. Eventejis
not aware of the execution of eior any event executed after eion the same process. For example,
inFigure2.1, e3
1∝\⌉}atio\slash→e3
3ande4
2∝\⌉}atio\slash→e1
3. Notethefollowingtworules:
•Foranytwoevents eiandej,ei∝\⌉}atio\slash→ej∝\⌉}atio\slash:ej∝\⌉}atio\slash→ei.
•Foranytwoevents eiandej,ei→ej:ej∝\⌉}atio\slash→ei.
For any two events eiandej, ifei∝\⌉}atio\slash→ejandej∝\⌉}atio\slash→ei, then events eiandejare said to be
concurrent and the relation is denoted as ei∝⌊ar⌈⌊lej. In the execution of Figure 2.1, e3
1∝⌊ar⌈⌊le3
3and
e4
2∝⌊ar⌈⌊le1
3. Note that relation ∝⌊ar⌈⌊lis not transitive; that is, ( ei∝⌊ar⌈⌊lej)∧(ej∝⌊ar⌈⌊lek)∝\⌉}atio\slash:ei∝⌊ar⌈⌊lek. For example,
inFigure2.1, e3
3∝⌊ar⌈⌊le4
2ande4
2∝⌊ar⌈⌊le5
1, however,e3
3∝\⌉}atio\slash∝⌊ar⌈⌊le5
1.
Notethatforanytwoevents eiandejinadistributedexecution, ei→ejorej→ei,orei∝⌊ar⌈⌊lej.
1In Lamport’s “happens before” relation, an event e1happens before an event e2, denoted by ei→ej, if (a) e1
occurs before e2on the same process, or (b) e1is the send event of a message and e2is the receive event of that
message,or(c)∃e′|e1happensbefore e′ande′happensbefore e2.
39
Logicalvs. PhysicalConcurrency
Inadistributedcomputation,twoeventsarelogicallyconc urrentifandonlyiftheydonotcausally
affect each other. Physicalconcurrency, on theotherhand, has aconnotationthat theeventsoccur
atthesameinstantinphysicaltime. Notethattwoormoreeve ntsmaybelogicallyconcurrenteven
thoughtheydonotoccuratthesameinstantinphysicaltime. Forexample,inFigure2.1,eventsin
theset{e3
1,e4
2,e3
3}arelogicallyconcurrent,buttheyoccurred atdifferenti nstantsinphysicaltime.
However, note that if processor speed and message delays wou ld have been different, the execu-
tion of these events could have very well coincided in physic al time. Whether a set of logically
concurrent events coincide in the physical time or in what or der in the physical time they occur
does notchangetheoutcomeofthecomputation.
Therefore, eventhougha set oflogically concurrent events may not haveoccurred at thesame
instantinphysicaltime,forallpractical andtheoretical purposes,wecan assumethattheseevents
occured at thesameinstantinphysicaltime.
2.3 ModelsofCommunicationNetwork
There are several models of the service provided by communic ation networks, namely, FIFO,
Non-FIFO,andcausalordering. IntheFIFOmodel,eachchann elactsasaﬁrst-inﬁrst-outmessage
queueandthus,messageorderingispreservedbyachannel. I nthenon-FIFOmodel,achannelacts
like a set in which the sender process adds messages and the re ceiver process removes messages
fromitinarandomorder. The“causalordering”model[1]isb asedonLamport’s“happensbefore”
relation. A systemthatsupportsthecausal orderingmodels atisﬁes thefollowingproperty:
CO:Foranytwomessages mijandmkj,ifsend(mij)−→send(mkj),thenrec(mij)−→rec(mkj).
That is, this property ensures that causally related messag es destined to the same destination
are delivered in an order that is consistent with their causa lity relation. Causally ordered delivery
ofmessagesimpliesFIFO messagedelivery. Furthermore, no tethatCO⊂FIFO⊂Non-FIFO.
Causal ordering model is useful in developing distributed a lgorithms. Generally, it consider-
ably simpliﬁes the design of distributedalgorithms becaus e it provides a built-in synchronization.
For example, in replicated database systems, it is importan t that every process responsible for up-
dating a replica receives the updates in the same order to mai ntain database consistency. Without
causal ordering, each update must be checked to ensure that d atabase consistency is not being
violated. Causal orderingeliminatestheneed forsuch chec ks.
2.4 GlobalStateofa DistributedSystem
Theglobalstateofadistributedsystemisacollectionofth elocalstatesofitscomponents,namely,
theprocessesandthecommunicationchannels[2],[3]. Thes tateofaprocessatanytimeisdeﬁned
by thecontents ofprocessor registers,stacks, local memor y, etc. and depends on thelocal context
of thedistributedapplication. Thestate ofchannel is give nby theset of messages in transit in the
channel.
Theoccurrenceofeventschangesthestatesofrespectivepr ocessesandchannels,thuscausing
transitions in global system state. For example, an interna l event changes the state of the process
40
at whichitoccurs. A sendevent(orareceiveevent)changest hestateoftheprocessthatsends(or
receives)themessageandthestateofthechannel onwhich th emessageissent (orreceived).
LetLSx
idenote the state of process piafter the occurrence of event ex
iand before the event
ex+1
i.LS0
idenotes the initial state of process pi.LSx
iis a result of the execution of all the events
executed by process pitillex
i. Letsend(m)≤LSx
idenote the fact that ∃y:1≤y≤x::ey
i=send(m).
Likewise,let rec(m)∝\⌉}atio\slash≤LSx
idenotethefact that ∀y:1≤y≤x::ey
i∝\⌉}atio\slash=rec(m).
The state of a channel is difﬁcult to state formally because a channel is a distributed entity
and its state depends upon the states of the processes it conn ects. LetSCx,y
ijdenote the state of a
channelCijdeﬁned as follows:
SCx,y
ij={mij|send(mij)≤ex
i/logicalandtextrec(mij)∝\⌉}atio\slash≤ey
j}
Thus,channelstate SCx,y
ijdenotesallmessagesthat pisentuptoevent ex
iandwhichprocess pj
had notreceiveduntilevent ey
j.
2.4.1 GlobalState
The global state of a distributed system is a collection of th e local states of the processes and the
channels. Notationally,globalstate GSisdeﬁned as,
GS={/uniontext
iLSxi
i,/uniontext
j,kSCyj,zk
jk}
For a global snapshot to be meaningful, the states of all the c omponents of the distributed
system must be recorded at the same instant. This will be poss ibleif the local clocks at processes
wereperfectlysynchronizedoriftherewereaglobalsystem clockthatcanbeinstantaneouslyread
by theprocesses. However,bothare impossible.
However, it turns out that even if the state of all the compone nts in a distributed system has
notbeenrecordedatthesameinstant,suchastatewillbemea ningfulprovidedeverymessagethat
is recorded as received is also recorded as sent. Basic idea i s that an effect should not be present
without its cause. A message cannot be received if it was not s ent; that is, the state should not
violate causality. Such states are called consistent global states and are meaningful global states.
Inconsistentglobal states are not meaningfulin thesense t hata distributedsystemcan neverbein
an inconsistentstate.
A global state GS= {/uniontext
iLSxi
i,/uniontext
j,kSCyj,zk
jk} is aconsistent global state iff it satisﬁes the
followingcondition:
∀LSxi
i∀SCyi,zk
ik::yi=xi
That is, channel state SCyi,zk
ikand process state LSzk
kmust not include any message that pro-
cesspisent after executing event exi
iand must include all messages that process pisent upto the
executionofevent exi
i.
In the distributed execution of Figure 2.2, a global state GS1consisting of local states { LS1
1,
LS3
2,LS3
3,LS2
4} is inconsistent because the state of p2has recorded the receipt of message m12,
however, the state of p1has not recorded its send. On the contrary, a global state GS2consisting
of local states { LS2
1,LS4
2,LS4
3,LS2
4} is consistent; all the channels are empty except C21that
containsmessage m21.
41
3
41
2
timee e e
e
e e e e
e ee
12
eeep
p
p
p1 1 1 1
2 2 22
3 3 3
4 41 2 3 4
42 3e1
31
323 4 5
1 2m21m
Figure2.2: Thespace-timediagramofadistributedexecuti on.
A globalstate GS=istransitless iff
∀i,∀j: 1≤i,j≤n::SCyi,zj
ij=φ.
Thus, all channels are recorded as empty in a transitless glo bal state. Note that a transitless
global stateis always a consistentglobalstate. A global st ateisstronglyconsistent iffit is transit-
less as well as consistent. Note that in Figure 2.2, the globa l state consistingof local states { LS2
1,
LS3
2,LS4
3,LS2
4} is stronglyconsistent.
Recording theglobal state of a distributed system is an impo rtant paradigm when one is inter-
estedinanalyzing,monitoring,testing,orverifyingprop ertiesofdistributedapplications,systems,
and algorithms. Design of efﬁcient methods for recording th e global state of a distributed system
isan importantproblem.
2.5 Cutsofa DistributedComputation
In the space-time diagram of a distributed computation, a zi gzag line joining one arbitrary point
oneach processlineistermeda cutinthecomputation. Such alineslicesthespace-timediagra m,
and thus the set of events in the distributed computation, in to a PAST and a FUTURE. The PAST
contains all the events to the left of the cut and the FUTURE co ntains all the events to the right
of the cut. For a cut C, let PAST(C) and FUTURE( C) denote the set of events in the PAST and
FUTURE of C, respectively. Every cut corresponds to aglobal stateand e very globalstatecan be
graphicallyrepresented as acut inthecomputation’sspace -timediagram[6].
Deﬁnition: IfeMax_PAST i(C)
i denotes the latest event at process pithat is in the PAST of a cut C,
thentheglobalstaterepresentedbythecutis{/uniontext
iLSMax_PAST i(C)
i ,/uniontext
j,kSCyj,zk
jk}whereSCyj,zk
jk={m
|send(m)∈PAST(C)∧rec(m)∈FUTURE(C)}.
A consistentglobalstatecorrespondsto acut inwhich every messagereceivedin thePAST of
the cut was sent in the PAST of that cut. Such a cut is known as a consistent cut . All messages
that cross the cut from the PAST to the FUTURE are in transit in the corresponding consistent
42
3
41
2
timee e e
e
e e e e
e e1e
eeeC C
p
p
p
p1 1 1 1
2 2 22
3 3 3
4 41 2 3 4
42 3e1
31
323 4 5
1 22
Figure2.3: Illustrationofcuts inadistributedexecution .
globalstate. A cutis inconsistent ifamessagecrossesthecutfromtheFUTUREtothePAST.For
example, the space-time diagram of Figure 2.3 shows two cuts ,C1andC2.C1is an inconsistent
cut, whereas C2is a consistent cut. Note that these two cuts respectively co rrespond to the two
globalstates GS1andGS2,identiﬁed intheprevioussubsection.
Cuts in a space-time diagram provide a powerful graphical ai d in representing and reasoning
aboutglobalstates ofa computation.
2.6 PastandFutureConesof anEvent
In a distributed computation, an event ejcould have been affected only by all events eisuch that
ei→ejand all the information available at eicould be made accessible at ej. All such events ei
belong to the past of ej[6]. LetPast(ej)denote all events in the past of ejin a computation ( H,
→). Then,
Past(ej) ={ei|∀ei∈H, e i→ej}.
Figure2.4showsthepastofanevent ej. LetPast i(ej)bethesetofallthoseeventsof Past(ej)
thatareonprocess pi. Clearly,Past i(ej)isatotallyorderedset,orderedbytherelation →i,whose
maximal element is denoted by max(Past i(ej)). Obviously, max(Past i(ej)) is the latest event at
processpithat affected event ej(see Figure ??). Note that max(Past i(ej)) is always a message
send event.
LetMax_Past(ej)=/uniontext
(∀i){max(Past i(ej))}.Max_Past(ej)consists of the latest event at
everyprocessthataffectedevent ejandisreferred toasthe surfaceofthepastcone ofej[6]. Note
thatMax_Past(ej)is a consistent cut [7]. Past(ej)represents all events on the past light cone
thataffectej.
Similar to the past is deﬁned the future of an event. The futur e of an event ej, denoted by
Future (ej),containsallevents eithatarecausallyaffectedby ej(seeFigure2.4). Inacomputation
(H,→),Future (ej)is deﬁned as:
Future (ej) ={ei|∀ei∈H, e j→ei}.
43
ej)
jFUTURE( ej
e)PAST(pimax(Past (iej))min(Futurei(ej))
Figure2.4: Illustrationofpastand futurecones inadistri butedcomputation.
Likewise, we can deﬁne Future i(ej)as the set of those events of Future (ej)that are on
processpiandmin(Future i(ej)) as the ﬁrst event on process pithat is affected by ej. Note
thatmin(Future i(ej)) is always a message receive event. Likewise, Min_Past(ej), deﬁned as/uniontext
(∀i){min(Future i(ej))}, consists of the ﬁrst event at every process that is causally affected by
eventejand is referred to as the surfaceof the futurecone ofej[6]. It denotes a consistentcut in
thecomputation[7]. Future (ej)represents all eventson the future lightcone that are affec ted by
ej.
It is obvious that all events at a process pithat occurred after max(Past i(ej))but before
min(Future i(ej))are concurrent with ej. Therefore, all and only those events of computation
Hthat belongtotheset “ H−Past(ej)−Future (ej)”areconcurrent withevent ej.
2.7 ModelsofProcessCommunications
There are two basic models of process communications [8] – sy nchronous and asynchronous.
Thesynchronous communication model is a blocking type where on a message sen d, the sender
process blocks until the message has been received by the rec eiver process. The sender process
resumes execution only after it learns that the receiver pro cess has accepted the message. Thus,
thesenderandthereceiverprocessesmustsynchronizetoex changeamessage. Ontheotherhand,
asynchronous communication model is a non-blocking type where the sender and the receiver do
not synchronize to exchange a message. After having sent a me ssage, the sender process does
not wait for the message to be delivered to the receiver proce ss. The message is bufferred by the
system and is delivered to the receiver process when it is rea dy to accept the message. A buffer
overﬂowmayoccurifaprocess sendsalarge numberofmessage sinaburst toanotherprocess.
Neither of the communication models is superior to the other . Asynchronous communication
provideshigherparallelismbecause thesenderprocess can executewhilethemessageisin transit
44
to thereceiver. However,an implementationofasynchronou scommunicationrequires morecom-
plex buffer management. In addition, due to higher degree of parallelism and non-determinism,
it is much more difﬁcultto design, verify, and implementdis tributedalgorithmsfor asynchronous
communications. The state space of such algorithms are like ly to be much larger. Synchronous
communicationissimplertohandleandimplement. However, duetofrequentblocking,itislikely
tohavepoorperformance and islikelytobemorepronetodead locks.
45
Bibliography
[1] K. Birman, T. Joseph, Reliable Communication in Presence of Failures, ACM Transactions
onComputerSystems,47-76,3, 1987.
[2] K.M.Chandy,L. Lamport, DistributedSnapshots: DeterminingGlobalStatesofDistr ibuted
Systems,ACM Transactionson ComputerSystems,63-75,3(1), 1985.
[3] A. Kshemkalyani, M. Raynal, and M. Singhal, “Global Snap shots of a Distributed System”,
DistributedSystemsEngineeringJournal ,Vol2, No4, December1995,pp. 224-233.
[4] L. Lamport, Time, clocks and the ordering of events in a distributed syst em.Comm. ACM,
vol.21,(July 1978),pp.558-564.
[5] A. Lynch, Distributed Processing Solves Main-frame Problems. Data Communications, pp.
17-22,December1976.
[6] F. Mattern, Virtual time and global states of distributed systems. Proc. "Parallel and dis-
tributedalgorithms"Conf., (Cosnard, Quinton,Raynal, Ro bert Eds), North-Holland,(1988),
pp.215-226.
[7] P. Panengaden and K. Taylor, Concurrent Common Knowledge: A New Deﬁnition of Agree-
ment for AsynchronousEvents. Proc. of the 5th Symp. on Principles of Distributed Comput-
ing,pp.197-209,1988.
[8] Sol M. Shatz, Communication Mechanisms for Programming Distributed Sys tems,IEEE
Computer,June1984,pp.21-28.
46
Chapter3
Logical Time
3.1 Introduction
The concept of causality between events is fundamental to th e design and analysis of parallel and
distributed computing and operating systems. Usually caus ality is tracked using physical time.
However, in distributed systems, it is not possible to have g lobal physical time; it is possible to
realize only an approximation of it. As asynchronous distri buted computations make progress
in spurts, it turns out that the logical time, which advances in jumps, is sufﬁcient to capture the
fundamental monotonicityproperty associated with causal ity in distributed systems. This chapter
discussesthreewaystoimplementlogicaltime(e.g.,scala rtime,vectortime,andmatrixtime)that
havebeen proposedtocapturecausalitybetween eventsofa d istributedcomputation.
Causality(orthecausalprecedencerelation)amongevents inadistributedsystemisapowerful
concept in reasoning, analyzing, and drawing inferences ab out a computation. The knowledge of
the causal precedence relation among the events of processe s helps solve a variety of problems in
distributedsystems. Examplesofsomeoftheseproblemsisa s follows:
•Distributed algorithms design: The knowledge of the causal precedence relation among
events helps ensure liveness and fairness in mutual exclusi on algorithms, helps maintain
consistency in replicated databases, and helps design corr ect deadlock detection algorithms
toavoid phantomand undetecteddeadlocks.
•Trackingofdependentevents: Indistributeddebugging,th eknowledgeofthecausaldepen-
dency among events helps construct a consistent state for re suming reexecution; in failure
recovery, it helps build a checkpoint; in replicated databa ses, it aids in the detection of ﬁle
inconsistenciesincase ofanetworkpartitioning.
•Knowledgeabouttheprogress: Theknowledgeofthecausalde pendencyamongeventshelps
measuretheprogressofprocessesinthedistributedcomput ation. Thisisusefulindiscarding
obsoleteinformation,garbagecollection,andterminatio ndetection.
•Concurrency measure: Theknowledgeofhowmanyeventsare ca usallydependentis useful
in measuring the amount of concurrency in a computation. All events that are not causally
related can be executed concurrently. Thus, an analysis of t he causality in a computation
givesan ideaoftheconcurrency in theprogram.
47
The concept of causality is widely used by human beings, ofte n unconsciously, in planning,
scheduling, and execution of a chore or an enterprise, in det ermining infeasibility of a plan or the
innocence of an accused. In day-to-day life, the global time to deduce causality relation is ob-
tainedfromlooselysynchronizedclocks(i.e., wristwatch es,wallclocks). However,indistributed
computingsystems,therateofoccurrenceofeventsissever almagnitudeshigherandtheeventex-
ecution time is several magnitudes smaller. Consequently, if the physical clocks are not precisely
synchronized,thecausalityrelationbetweeneventsmayno tbeaccuratelycaptured. NetworkTime
Protocols[18], which can maintaintimeaccurate toafew ten s ofmillisecondson theInternet,are
not adequate to capture the causality relation in distribut ed systems. However, in a distributed
computation, generally the progress is made in spurts and th e interaction between processes oc-
curs in spurts. Consequently, it turns out that in a distribu ted computation, the causality relation
between events produced by a program execution and its funda mental monotonicity property can
beaccurately captured by logicalclocks.
In a system of logical clocks, every process has a logical clo ck that is advanced using a set
of rules. Every event is assigned a timestamp and the causali ty relation between events can be
generallyinferredfromtheirtimestamps. Thetimestampsa ssignedtoeventsobeythefundamental
monotonicityproperty; that is, if an event acausally affects an event b, then the timestampof ais
smallerthan thetimestampof b.
This chapter ﬁrst presents a general framework of a system of logical clocks in distributed
systems and then discusses three ways to implement logical t ime in a distributed system. In the
ﬁrst method, Lamport’s scalar clocks, the time is represent ed by non-negative integers; in the
second method, the time is represented by a vector of non-neg ative integers; in the third method,
the timeis represented as a matrix of non-negativeintegers . We also discuss methodsfor efﬁcient
implementationofthesystemsofvectorclocks.
The chapter ends with a discussion of virtual time, its imple mentation using the time-warp
mechanismand abriefdiscussionofphysicalclock synchron izationandtheNetwork TimeProto-
col.
3.2 AFrameworkfora SystemofLogicalClocks
3.2.1 Deﬁnition
A systemoflogical clocksconsistsofa timedomain Tand a logicalclock C[23]. Elementsof T
form a partially ordered set over a relation <. This relation is usually called the happened before
orcausalprecedence . Intuitively,thisrelationisanalogoustothe earlierthan relationprovidedby
thephysicaltime. Thelogicalclock Cisafunctionthatmapsan event einadistributedsystemto
an elementin the timedomain T, denoted as C( e) and called thetimestampof e, and is deﬁned as
follows:
C:H∝ma√sto→T
such thatthefollowingproperty issatisﬁed:
fortwo events eiandej,ei→ej=:C(ei)<C(ej).
This monotonicity property is called the clock consistency condition . WhenTandCsatisfy the
followingcondition,
48
fortwoevents eiandej,ei→ej⇔C(ei)<C(ej)
thesystemofclocks issaidto be stronglyconsistent .
3.2.2 Implementing LogicalClocks
Implementationoflogicalclocksrequiresaddressingtwoi ssues[23]: datastructureslocaltoevery
processtorepresentlogicaltimeandaprotocol(setofrule s)toupdatethedatastructurestoensure
theconsistencycondition.
Each process pimaintainsdatastructures thatallowitthefollowingtwoca pabilities:
•Alocallogicalclock , denotedby lci, thathelpsprocess pimeasureitsownprogress.
•Alogical global clock , denoted by gci, that is a representation of process pi’s local view of
the logical global time. It allows this process to assign con sistent timestamps to its local
events. Typically, lciisapart ofgci.
The protocol ensures that a process’s logical clock, and thu s its view of the global time, is
managed consistently. Theprotocolconsistsofthefollowi ngtwo rules:
•R1: This rule governs how the local logical clock is updated by a process when it executes
an event(send,receive, orinternal).
•R2: This rule governs how a process updates its global logical c lock to update its view of
the global time and global progress. It dictates what inform ation about the logical time
is piggybacked in a message and how this information is used b y the receiving process to
updateitsview oftheglobaltime.
Systems of logical clocks differ in their representation of logical time and also in the protocol
to update the logical clocks. However, all logical clock sys tems implement rules R1andR2and
consequently ensure the fundamental monotonicity propert y associated with causality. Moreover,
each particularlogicalclock systemprovidesitsusers wit hsomeadditionalproperties.
3.3 ScalarTime
3.3.1 Deﬁnition
The scalar time representation was proposed by Lamport in 19 78 [11] as an attempt to totally
order eventsin a distributedsystem. Timedomain in this rep resentation is the set of non-negative
integers. The logical local clock of a process piand its local view of the global time are squashed
intooneintegervariable Ci.
RulesR1andR2to updatetheclocksare as follows:
•R1: Beforeexecutinganevent(send,receive,orinternal),pr ocesspiexecutesthefollowing:
Ci:=Ci+d (d>0)
49
In general, every time R1is executed, dcan have a different value, and this value may be
application-dependent. However, typically dis kept at 1 because this is able to identify the
timeofeach eventuniquelyataprocess,whilekeepingthera teofincreaseof dtoitslowest
level.
•R2: Eachmessagepiggybackstheclockvalueofitssenderatsen dingtime. Whenaprocess
pireceivesamessagewithtimestamp Cmsg, itexecutesthefollowingactions:
–Ci:=max(Ci,Cmsg)
–ExecuteR1.
–Deliverthemessage.
Figure3.1 showstheevolutionofscalartimewith d=1.
p1
p
2
p31 2 3
3 1011
5      6       72
79
4
b18 9
4 5
1
Figure3.1: Evolutionofscalar time.
3.3.2 BasicProperties
Consistency Property
Clearly, scalarclockssatisfythemonotonicityand hencet heconsistencyproperty:
fortwo events eiandej,ei→ej=:C(ei)<C(ej).
Total Ordering
Scalar clocks can be used to totally order events in a distrib uted system [11]. The main problem
in totally ordering events is that two or more events at diffe rent processes may have identical
timestamp. (Note that for two events e1ande2, C(e1)=C(e2)= :e1∝⌊ar⌈⌊le2.) For example in
Figure 3.1, the third event of process P1and the second event of process P2have identical scalar
timestamp. Thus, a tie-breaking mechanism is needed to orde r such events. Typically, a tie is
broken as follows: process identiﬁers are linearly ordered and a tie among events with identical
scalartimestampisbrokenonthebasisoftheirprocessiden tiﬁers. Thelowertheprocessidentiﬁer
intheranking,thehigherthepriority. Thetimestampofane ventisdenotedbyatuple( t,i)where
50
tis its time of occurrence and iis the identity of the process where it occurred. The total or der
relation≺ontwoevents xandywithtimestamps (h,i)and(k,j),respectively,isdeﬁnedasfollows:
x≺y⇔(h<kor(h=kandi<j))
Since events that occur at the same logical scalar time are in dependent (i.e., they are not
causally related), they can be ordered using any arbitrary c riterion without violating the causal-
ity relation→. Therefore, a total order is consistent with the causality r elation “→". Note that
x≺y= :x→y∨x∝⌊ar⌈⌊ly. A total order is generally used to ensure liveness properti es in dis-
tributed algorithms. Requests are timestamped and served a ccording to the total order based on
thesetimestamps[11].
Event Counting
Iftheincrementvalue disalways1,thescalartimehasthefollowinginterestingpr operty: ifevent
ehas atimestamp h, thenh-1representstheminimumlogicalduration,counted inunitso fevents,
required before producing the event e[6]; we call it the height of the event e. In other words, h-1
eventshavebeenproducedsequentiallybeforetheevent eregardlessoftheprocessesthatproduced
these events. For example, in Figure 3.1, ﬁve events precede eventbon the longest causal path
endingat b.
No Strong Consistency
The system of scalar clocks is not strongly consistent; that is, for two events eiandej, C(ei)
<C(ej)∝\⌉}atio\slash= :ei→ej. For example, in Figure 3.1, the third event of process P1has smaller scalar
timestampthanthethirdeventofprocess P2. However,theformerdidnothappenbeforethelatter.
The reason that scalar clocks are not strongly consistent is that the logical local clock and logical
global clock of a process are squashed into one, resulting in the loss causal dependency informa-
tionamongeventsatdifferentprocesses. Forexample,inFi gure3.1,whenprocess P2receivesthe
ﬁrst message from process P1, it updates its clock to 3, forgetting that the timestamp of t he latest
eventatP1onwhich itdependsis 2.
3.4 VectorTime
3.4.1 Deﬁnition
ThesystemofvectorclockswasdevelopedindependentlybyF idge[6],Mattern[14]andSchmuck
[27]. Inthesystemofvectorclocks,thetimedomainisrepre sentedbyasetof n-dimensionalnon-
negative integer vectors. Each process pimaintains a vector vti[1..n], wherevti[i]is the local
logical clock of piand describes the logical time progress at process pi.vti[j]represents process
pi’s latest knowledge of process pjlocal time. If vti[j]=x, then process piknows that local time
at processpjhas progressed till x. The entire vector vticonstitutespi’s view of the global logical
timeand isused totimestampevents.
Processpiusesthefollowingtworules R1andR2to updateitsclock:
51
•R1: Before executingan event,process piupdatesitslocal logicaltimeas follows:
vti[i] :=vti[i] +d (d>0)
•R2: Eachmessage mispiggybackedwiththevectorclock vtofthesenderprocessatsending
time. Onthereceiptofsuchamessage (m,vt),processpiexecutesthefollowingsequenceof
actions:
–Updateitsgloballogicaltimeas follows:
1≤k≤n:vti[k] :=max(vti[k],vt[k])
–ExecuteR1.
–Deliverthemessage m.
Thetimestampassociatedwithaneventisthevalueofthevec torclockofitsprocesswhenthe
eventisexecuted. Figure3.2showsanexampleofvectorcloc ksprogresswiththeincrementvalue
d=1. Initially,avectorclock is [0,0,0,....,0].
Thefollowingrelationsare deﬁned tocomparetwovectortim estamps,vhandvk:
vh=vk⇔ ∀x:vh[x] =vk[x]
vh≤vk⇔ ∀x:vh[x]≤vk[x]
vh<vk⇔vh≤vkand∃x:vh[x]<vk[x]
vh∝⌊ar⌈⌊lvk⇔ ¬ (vh<vk )∧¬(vk<vh )
3pp12
0
03
0
04	
3
4
0
1
02
0
0 2
3
02
4
02
3
45
3
4
5
6
4
0
0
12
3
32
3
42p
2
3
02
2
0
2
3
21
0
05
3
4
5
5
4
Figure3.2: Evolutionofvectortime.
52
3.4.2 BasicProperties
Isomorphism
Recall that relation “ →" induces a partial order on the set of events that are produce d by a dis-
tributed execution. If events in a distributed system are ti mestamped using a system of vector
clocks,wehavethefollowingproperty.
If twoevents xandyhavetimestamps vhandvk, respectively,then
x→y⇔vh<vk
x∝⌊ar⌈⌊ly⇔vh∝⌊ar⌈⌊lvk.
Thus, there is an isomorphism between the set of partially or dered events produced by a dis-
tributed computation and their vector timestamps. This is a very powerful, useful, and interesting
propertyofvectorclocks.
If the process at which an event occurred is known, the test to compare two timestamps can
be simpliﬁed as follows: If events xandyrespectively occurred at processes piandpjand are
assignedtimestamps vhandvk, respectively,then
x→y⇔vh[i]≤vk[i]
x∝⌊ar⌈⌊ly⇔vh[i]>vk[i]∧vh[j]<vk[j]
Strong Consistency
The system of vector clocks is strongly consistent; thus, by examining the vector timestamp of
two events, we can determine if the events are causally relat ed. However, Charron-Bost showed
that the dimension of vector clocks cannot be less than n, the total number of processes in the
distributedcomputation,forthispropertyto hold[4].
Event Counting
Ifdis always 1 in therule R1, then theithcomponentof vectorclock at process pi,vti[i], denotes
the number of events that have occurred at piuntil that instant. So, if an event ehas timestamp
vh,vh[j]denotes the number of events executed by process pjthat causally precede e. Clearly,/summationtextvh[j]−1represents the total number of events that causally precede ein the distributed com-
putation.
Applications
Since vector time tracks causal dependencies exactly, it ﬁn ds a wide variety of applications. For
example, they are used in distributeddebugging, implement ationsof causal ordering communica-
tionandcausaldistributedsharedmemory,establishmento fglobalbreakpoints,andindetermining
theconsistencyofcheckpointsinoptimisticrecovery.
53
A Brief HistoricalPerspective ofVectorClocks
Although the theory associated with vector clocks was ﬁrst d eveloped in 1988 independently by
Fidge and Mattern, vector clocks were informally introduce d and used by several researchers ear-
lier. Parker et al.[20] used a rudimentary vector clocks system to detect incon sistencies of repli-
cated ﬁles due to network partitioning. Liskov and Ladin [13 ] proposed a vector clock system
to deﬁne highly available distributed services. Similar sy stem of clocks was used by Strom and
Yemini [30] to keep track of the causal dependencies between events in their optimistic recovery
algorithm and by Raynal to prevent drift between logical clo cks [21]. Singhal [28] used vector
clocks coupled with a boolean vector to determine the curren cy of a critical section execution
request bydetectingthecusalityrelationbetween acritic al sectionrequestand itsexecution.
3.4.3 Onthe Size ofVector Clocks
An important question to ask is whether vector clocks of size nare necessary in a computation
consistingof nprocesses. Toanswerthis,weexaminetheusageofvectorclo cks.
•Avectorclockprovidesthelatestknownlocaltimeateachot herprocess. Ifthisinformation
intheclockistobeusedtoexplicitlytracktheprogressate veryotherprocess,thenavector
clock ofsize nis necessary.
•A popularuseof vectorclocks is to determinethecausalityb etween a pairofevents. Given
anyeventseandf,thetestfor e≺fifand onlyif T(e)<T(f),whichrequiresacompari-
sonofthevectorclocksof eandf. Althoughitappearsthattheclockofsize nisnecessary,
that is not quite accurate. It can be shown that a size equal to the dimension of the partial
order(E,≺)is necessary, where the upper bound on this dimension is n. This is explained
below.
To understand this result on the size of clocks for determini ng causality between a pair of
events, we ﬁrst introduce some deﬁnitions. A linear extension of a partial order (E,≺)is a linear
ordering of Ethat is consistent with the partial order, i.e., if two event s are ordered in the partial
order, they are also ordered in the linear order. A linear ext ension can be viewed as projecting
all the events from the different processes on a single time a xis. However, the linear order will
necessarilyintroduceordering betweeneach pairofevents ,and someoftheseorderingsarenotin
thepartialorder. Alsoobservethatdifferentlinearexten sionsarepossibleingeneral. Let Pdenote
theset oftuplesin thepartial order deﬁned by thecausality relation; so thereis atuple (e,f)inP
foreachpairofevents eandfsuchthate≺f. LetL1,L2...denotethesetsoftuplesindifferent
linear extensions of this partial order. The set Pis contained in the set obtained by taking the
intersection of any such collection of linear extensions L1,L2.... This is because each Limust
contain all the tuples, i.e., causality dependencies, that are inP. Thedimension of a partial order
istheminimumnumberoflinearextensionswhoseintersecti ongivesexactlythepartialorder.
Consider a client-server interaction between a pair of proc esses. Queries to the server and
responses to the client occur in strict alternating sequenc es. Although n= 2, all the events are
strictly ordered, and there is only one linear order of all th e events that is consistent with the
“partial” order. Hence the dimension of this "partial order " is 1. A scalar clock such as one
implementedby Lamport’s scalar clock rules is adequate to d eterminee≺ffor any events eand
finthisexecution.
54
Nowconsideranexecutiononprocesses P1andP2suchthateachsendsamessagetotheother
before receiving the other’s message. The two send events ar e concurrent, as are the two receive
events. To determine the causality between the send events o r between the receive events, it is
not sufﬁcient to use a single integer; a vector clock of size n= 2is necessary. This execution
exhibits the graphical property called a crown, wherein there are some messages m0,...m n−1
such thatSend(mi)≺Receive (mi+1mod(n−1))for allifrom 0 ton−1. A crown of nmessages
has dimension n. Weintroducedthenotionofcrownand studieditspropertie sin Chapter3.
fa b d  h i
jj
e
fca  h i g
(i)
ed
      (ii) two linear extensions
  < c, e, f, a, b,   d, g, h, i  , j  >
  <         a,b,c,d,g,h,i,e,j,f> range of events "c", "e", "f"b
cg
Figure 3.3: Example illustrating dimension of a execution (E,≺). Forn= 4processes, the
dimensionis2.
Foracomplexexecution,itisnot straightforwardtodeterm inethedimensionofthepartial or-
der. Figure3.3showsanexecutioninvolvingfourprocesses . However,thedimensionofthispartial
order is two. To see this informally,considerthe longestch ain∝a\}⌊ra⌋k⌉tl⌉{ta,b,d,g,h,i,j∝a\}⌊ra⌋k⌉tri}ht. There are events
outside this chain that can yield multiple linear extension s. Hence, the dimension is more than 1.
The right side of Figure 3.3 shows the earliest possible and t he latest possible occurrences of the
eventsnotinthischain,withrespecttotheeventsinthisch ain. LetL1be∝a\}⌊ra⌋k⌉tl⌉{tc,e,f,a,b,d,g,h,i,j ∝a\}⌊ra⌋k⌉tri}ht,
whichcontainsthefollowingtuplesthatare notin P:
(c,a),(c,b),(c,d),(c,g),(c,h),(c,i),(c,j),
(e,a),(e,b),(e,d),(e,g),(e,h),(e,i),(e,j),
(f,a),(f,b),(f,d),(f,g),(f,h),(f,i),(f,j).
LetL2be∝a\}⌊ra⌋k⌉tl⌉{ta,b,c,d,g,h,i,e,j,f ∝a\}⌊ra⌋k⌉tri}ht,which containsthefollowingtuplesnotin P:
(a,c),(b,c),(c,d),(c,g),(c,h),(c,i),(c,j),
(a,e),(b,e),(d,e),(g,e),(h,e),(i,e),(e,j),
(a,f),(b,f),(d,f),(g,f),(h,f),(i,f),(j,f).
Further, observe that (L1\P)/intersectiontextL2=∅and(L2\P)/intersectiontextL1=∅. Hence,L1/intersectiontextL2=Pand the
dimensionoftheexecutionis2 as thesetwo linearextension sareenoughto generate P.
Unfortunately, it is not computationallyeasy to determine the dimension of a partial order. To
exacerbatetheproblem,theaboveformofanalysishastobec ompletedaposteriori(i.e., off-line),
oncetheentirepartial orderhas been determinedafterthec ompletionoftheexecution.
55
3.5 EfﬁcientImplementationsofVectorClocks
If the number of processes in a distributed computation is la rge, then vector clocks will require
piggybacking of huge amount of information in messages for t he purpose of disseminating time
progressandupdatingclocks. Themessageoverheadgrowsli nearlywiththenumberofprocessors
inthesystemandwhentherearethousandsofprocessorsinth esystem,themessagesizebecomes
huge even if there are only a few events occurring in few proce ssors. In this section, we discuss
efﬁcient ways to maintain vector clocks; similar technique s can be used to efﬁciently implement
matrixclocks.
Charron-Bost showed [4] that if vector clocks have to satisf y the strong consistency property,
then ingeneral vectortimestampsmustbe at least ofsize n, thetotalnumberofprocesses. There-
fore, in general thesizeof avectortimestampis thenumbero fprocesses involvedin a distributed
computation; however, several optimizations are possible and next, we discuss techniques to im-
plementvectorclocks efﬁciently[23].
3.5.1 Singhal-Kshemkalyani’s Differential Technique
Singhal-Kshemkalyani’s differential technique [29] is based on the observation that between suc-
cessive message sends to the same process, only a few entries of the vector clock at the sender
process are likely to change. This is more likely when the num ber of processes is large because
onlyafewofthemwillinteractfrequentlybypassingmessag es. Inthistechnique,whenaprocess
pisends a message to a process pj, it piggybacks only those entries of its vector clock that di ffer
sincethelast messagesentto pj.
Thetechniqueworksasfollows: Ifentries i1,i2,...,i n1ofthevectorclockat pihavechanged
tov1,v2,...,v n1, respectively, since the last message sent to pj, then process pipiggybacks a
compressedtimestampoftheform
{(i1,v1),(i2,v2),...,(in1,vn1)}
tothenextmessageto pj. Whenpjreceives thismessage,itupdatesitsvectorclock asfollow s:
vti[k] =max(vti[k],vk)fork= 1,2,...,n 1.
Thusthistechniquecutsdownthemessagesize,communicati onbandwidthandbuffer(tostore
messages) requirements. In the worst of case, every element of the vector clock has been updated
atpisincethelastmessagetoprocess pj,andthenextmessagefrom pitopjwillneed tocarry the
entirevectortimestampofsize n. However,ontheaveragethesizeofthetimestamponamessag e
willbelessthan n. Notethatimplementationofthistechniquerequireseach p rocess toremember
the vector timestamp in the message last sent to every other p rocess. Direct implementation of
this will result in O(n2)storage overhead at each process. This technique also requi res that the
communicationchannelsfollowFIFO disciplineformessage delivery.
Singhal and Kshemkalyani developed a clever technique that cuts down this storage overhead
at each process to O(n). The technique works in the following manner: Process pimaintains the
followingtwoadditionalvectors:
56
•LSi[1..n](‘Last Sent’):
LSi[j]indicates thevalueof vti[i]when process pilast sentamessagetoprocess pj.
•LUi[1..n](‘Last Update’):
LUi[j]indicatesthevalueof vti[i]when process pilast updatedtheentry vti[j].
Clearly,LUi[i] =vti[j]at all times and LUi[j]needs to be updated only when the receipt of
a message causes pito update entry vti[j]. Also,LSi[j]needs to be updated only when pisends
a message to pj. Since the last communication from pitopj, only those elements of vector clock
vti[k]havechanged for which LSi[j]<LU i[k]holds. Hence, only theseelements need to be sent
ina messagefrom pitopj. Whenpisendsa messageto pj, itsendsonlyaset oftuples
{(x,vt i[x])|LSi[j]<LU i[x]}
as thevectortimestampto pj, insteadofsendingavectorof nentries inamessage.
Thus the entire vector of size nis not sent along with a message. Instead, only the elements
in the vector clock that have changed since the last message s end to that process are sent in the
format{(p1,latest_value),(p2,latest_value),...},wherepiindicatesthatthe pithcomponentof
thevectorclock haschanged.
 p1
 p
2
 p3
 p41
0
0
01
1
0
01
3
2
01
2
1
0
0
0
2
00
0
3
10
0
4
1
0
0
0
11
4
4
1
0
0
1
0{(1,1)}
{(3,1)} {(3,2)}{(3,4),(4,1)}
{(4,1)}
Figure3.4: Vectorclocksprogress inSinghal-Kshemkalyan itechnique
ThismethodisillustratedinFigure3.4. Forinstance,thes econdmessagefrom p3top2(which
contains a timestamp {(3,2)}) informsp2that the third component of the vector clock has been
modiﬁed and thenew valueis 2. This is because the process p3(indicated by thethird component
ofthevector)has advanceditsclock valuefrom 1to2sincethelastmessagesentto p2.
Thecostofmaintainingvectorclocksinlargesystemscanbe substantiallyreducedbythistech-
nique, especially if the process interactions exhibit temp oral or spatial localities. This technique
wouldturnadvantageousinavarietyofapplicationsinclud ingcausaldistributedsharedmemories,
distributed deadlock detection, enforcement of mutual exc lusion and localized communications
typicallyobservedindistributedsystems.
57
3.5.2 Fowler-Zwaenepoel’sDirect-Dependency Technique
Fowler-Zwaenepoel direct dependencytechnique[8] reduce s thesize ofmessagesby transmitting
onlyascalarvalueinthemessages. Novectorclocksaremain tainedon-the-ﬂy. Instead,aprocess
only maintains information regarding direct dependencies on other processes. A vector time for
an event, that represents transitivedependencies on other processes, is constructed off-line from a
recursivesearch ofthedirect dependencyinformationat pr ocesses.
Each process pimaintainsa dependency-vector Di. Initially,
Di[j] = 0forj= 1,...,n.
Diisupdated as follows:
Step 1:Whenever an event occurs at pi,Di[i] :=Di[i] + 1. That is, the vector component
correspondingtoitsownlocal timeisincremented byone.
Step2:Whenaprocess pisendsamessagetoprocess pj,itpiggybackstheupdatedvalueof
Di[i]in themessage.
Step3:Whenpireceivesamessagefrom pjwithpiggybackedvalue d,piupdatesitsdepen-
dencyvectorasfollows: Di[j]:=max{Di[j],d}.
Thusthedependencyvector Direﬂectsonlydirectdependencies. Atanyinstant, Di[j]denotes
the sequence number of the latest event on process pjthatdirectlyaffects the current state. Note
thatthiseventmayprecede thelatesteventat pjthatcausallyaffects thecurrent state.
 p1
 p
2
 p
3
 p41
0
0
01
1
0
01
3
2
01
2
1
0
0
0
1
00
0
2
00
0
3
10
0
4
1
0
0
0
11
4
4
0
{1}
{1}{2} {4}{1}
Figure3.5: Vectorclock progressin Fowler-Zwaenepoeltec hnique
Figure 3.5 illustrates the Fowler-Zwaenepoel technique. F or instance, when process p4sends
a message to process p3, it piggybacks a scalar that indicates the direct dependenc y ofp3onp4
because of this message. Subsequently, process p3sends a message to process p2piggybacking a
58
scalar to indicate the direct dependency of p2onp3because of this message. Now, process p2is
in fact indirectly dependent on process p4since process p3is dependent on process p4. However,
processp2isneverinformedaboutitsindirectdependencyon p4.
Thusalthoughthedirectdependenciesaredulyinformedtot hereceivingprocesses,thetransi-
tive (indirect) dependencies are not maintained by this met hod. They can be obtained only by re-
cursivelytracingthedirect-dependencyvectorsoftheeve ntsoff-line. Thisinvolvescomputational
overhead and latencies. Thus this method is ideal only for th ose applications that do not require
computation of transitive dependencies on the ﬂy. The compu tational overheads characteristic
of this method makes it best suitable for applications like c ausal-breakpoints and asynchronous
checkpointrecoverywhere computationofcausal dependenc iesis performedofﬂine.
This technique results in considerable saving in the cost; o nly one scalar is piggybacked on
everymessage. However,thedependencyvectordoesnotrepr esenttransitivedependencies(i.e.,a
vectortimestamps). Thetransitivedependency(orthevect ortimestamp)ofaneventisobtainedby
recursivelytracingthedirect-dependencyvectorsofproc esses. Clearly,thiswillhaveoverheadand
willinvolvelatencies. Therefore,thistechniqueisnotsu itableforapplicationsthatrequireon-the-
ﬂy computation of vector timestamps. Nonetheless, this tec hnique is ideal for applications where
computation of causal dependencies is performed off-line ( e.g., causal breakpoint, asynchronous
checkpointingrecovery).
The transitive dependencies could be determined by combini ng an event’s direct dependency
withthatofitsdirectly dependentevent. In Figure3.5,the fourtheventofprocess p3is dependent
on the ﬁrst event of process p4and fourth event of process p2is dependent on fourth event of
processp3. By combiningthesetwo direct dependencies, it is possible to deduce that fourth event
ofprocessp2dependson ﬁrst eventofprocess p4. It isimportantto notethatifevent ejat process
pjoccursbeforeevent eiatprocesspi,thenalltheeventsfrom e0toej−1inprocesspjalsohappen
beforeei. Hence, it issufﬁcient torecord for eithelatesteventofprocess pjthat happened before
ei. Thisway,eacheventwouldrecorditsdependenciesonthela testeventoneveryotherprocessit
dependsonandthoseeventsmaintaintheirowndependencies . Combiningallthesedependencies,
theentireset ofeventsthat aparticulareventdepends onco uldbedeterminedoff-line.
The off-line computation of transitive dependencies can be performed using a recursive algo-
rithmproposedin[8]andisillustratedinamodiﬁedforminA lgorithm1. DTVisthedependency-
tracking vector of size n(wherenis the number of process) which is supposed to track all the
causal dependencies ofa particularevent eiin processpi. Thealgorithmthen needs to be invoked
asDependencyTrack (i,De
i[i]). Thealgorithminitializes DTVtotheleastpossibletimestampvalue
whichis 0forall entries except iforwhich thevalueis setto De
i[i]:
Forallk= 1,...,nandk∝\⌉}atio\slash=i,DTV[k]=0andDTV[i]=De
i[i]
Thealgorithmthen calls the VisitEvent algorithmon process piand eventei.VisitEvent checks all
the entries ( 1,...,n) ofDTVandDe
iand if the value in De
iis greater than the value in DTVfor
that entry, then DTVassumes the value of De
ifor that entry. This ensures that the latest event in
processjthateidepends on is recorded in DTV.VisitEvent is recursivelycalled on all entries that
are newlyincludedin DTVsothatthelatestdependency informationcan beaccurately tracked.
Let us illustrate the Recursive Dependency Trace Algorithm by by tracking the dependencies
offourtheventatprocess p2. Thealgorithmisinvokedas DependencyTrack (2,4).DTVisinitially
set to<0 4 0 0>byDependenyTrack . It then calls VisitEvent (2,4). The values held by D4
2are
<1 4 4 0>. So,DTVis now updated to <1 4 0 0>andVisitEvent (1,1)is called. The values
59
DependencyTrack (i:process,σ:eventindex )
\∗Casual distributedbreakpointfor σi∗\
\∗DTVholdstheresult∗\
forallk∝\⌉}atio\slash=ido
DTV[k]=0
end for
DTV[i]=σ
endDependencyTrack
VisitEvent (j:process,e:eventindex )
\∗Placedependencies of τintoDTV∗\
forallk∝\⌉}atio\slash=jdo
α=De
j[k]
ifα>DTV[k]then
DTV[k]=α
VisitEvent (k,α)
end if
end for
endVisitEvent
Algorithm 1 : RecursiveDependencyTraceAlgorithm
heldbyD1
1are<1 0 0 0>. Sincenoneoftheentriesaregreaterthanthosein DTV, thealgorithm
returns. Again the values held by D4
2are checked and this time entry 3is found to be greater in
D4
2thanDTV. So,DTVis updated as <1 4 4 0>andVisiEvent (3,4)is called. The values held
byD4
3are<0 0 4 1>. Since entry 4ofD4
3is greater than that of DTV, it is updated as <1 4 4
1>andVisitEvent (4,1) is called. Since none of the entries in D1
4:<1 0 0 0>are greater than
those ofDTV, the algorithm returns to VisitEvent (2,4). Since all the entries have been checked,
VisitEvent (2,4) is exited and so is DependencyTrack . At this point, DTVholds<1 4 4 1>,
meaning event 4of processp2is dependent upon event 1of processp1, event 4of processp3and
event1in processp4. Also, it is dependent on events that precede event 4of processp3and these
dependencies could be obtained by invoking the DependencyTrack algorithm on fourth event of
processp3. Thus,allthecausal dependencies couldbetracked off-lin e.
Thistechniquecan resultinaconsiderablesavingofcostsi nceonlyonescalarispiggybacked
on every message. One of the important requirements is that a process updates and records its
dependencyvectorsafterreceivingamessageandbeforesen dingoutanymessage. Also,ifevents
occurfrequently,thistechniquewillrequirerecording th ehistoryofalargenumberofevents.
3.6 Jard-Jourdan’sAdaptiveTechnique
TheFowler-Zwaenepoel’sdirect-dependencytechniquedoe snotallowthetransitivedependencies
to be captured in real time during the execution of processes . In addition, a process must ob-
servean event (i.e., updateand record itsdependency vecto r)after receivinga messagebut before
sending out any message. Otherwise, during the reconstruct ion of a vector timestamp from the
60
direct-dependency vectors, all the causal dependencies wi ll not be captured. If events occur very
frequently,thistechniquewillrequirerecording thehist oryofalargenumberofevents.
In the Jard-Jourdan’s technique[10], events can be adaptiv elyobserved while maintainingthe
capability of retrieving all the causal dependencies of an o bserved event. (Observing an event
means recording of the information about its dependencies. ) This method uses the idea that when
anobservedevent erecordsitsdependencies,theneventsthatfollowcandeter minetheirtransitive
dependencies, that is, the set of events that they indirectl y depend on, by making use of the infor-
mationrecordedabout e. Thereasonisthatwhenanevent eisobserved,theinformationaboutthe
sendandreceiveofmessagesmaintainedbyaprocessisrecor dedinthateventandtheinformation
maintainedby theprocess isthen reset and updated. So, when theprocess propagates information
aftere,itpropagatesonlyhistoryofactivitiesthattookplaceaf tere. Thenextobservedeventeither
inthesameprocessorinadifferentone,wouldthenhavetolo okattheinformationrecordedfor e
to know about the activities that happened before e. This method still does not allow determining
all the causal dependencies in real time, but avoids the prob lem of recording a large amount of
historywhichisrealized whenusingthedirect dependencyt echnique.
Toimplementthetechniqueofrecordingtheinformationina nobservedeventandresettingthe
informationmanaged by a process, Jard-Jourdan deﬁned a pseudo-direct relation≪on theevents
ofadistributedcomputationas follows:
Ifeventseiandejhappenatprocess piandpj,respectively,then ej≪eiiffthereexistsapathof
messagetransfersthatstartsafter ejontheprocess pjandendsbefore eiontheprocess eisuchthat
there is no observed event on the path. The relation is termed pseudo-direct because event eimay
depend upon many unobserved events on the path, say ue1,ue2,...,uen, etc., which are in turn
dependentoneachother. If eihappensafter uen,theneiisstillconsidereddirectlydependentupon
ue1,ue2,...,uen,sincetheseeventsareunobserved,whichisafalselyassum eddirectdependency.
Ifanotherevent ekhappensafter ei,thenthetransitivedependenciesof ekonue1,ue2,...,uencan
bedeterminedby usingtheinformationrecorded at eiandeican do thesamewith ej.
The technique is implemented using the following mechanism : The partial vector clock p_vti
at processpiis a list of tuples of the form ( j,v) indicating that the current state of piis pseudo-
dependent on the event on process pjwhose sequence number is v. Initially, at a process pi:
p_vti={(i, 0)}.
Letp_vti={(i1,v1),...,(i,v),...(in,vn}denote the current partial vector clock at process
pi. Lete_vtibeavariablethatholdsthetimestampoftheobserved event
(i) Whenever an event is observed at process pi, the contents of the partial vector clock p_vti
aretransferred to e_vtiandp_vtiisreset and updatedas follows:
e_vti={(i1,v1),...,(i,v),...,(in,vn)}
p_vti={(i,v+ 1)}
(ii) When process pjsends a message to pi, it piggybacks the current value of p_vtjin the
message.
(iii) Whenpireceivesamessagepiggybackedwithtimestamp p_vt,piupdatesp_vtisuch thatit
istheunionofthefollowing: (Let p_vt={(im1,vm1),...,(imk,vmk)}andp_vti={(i1,v1)„...,(il,vl)}.)
–all (imx,vmx)such that(imx,.)does notappear in v_pti,
61
–all (ix,vx)such that(ix,.)does notappearin v_pt, and
–all (ix,max(vx,vmx)) forall(vx,.)that appearin v_ptandv_pti.
={(1,0)} 1={(1,1)}
{(1,0)}
2={(2,0)}v_pt  v_pt  
v_pt  v_pt  
{(1,0),(2,0)}=
{(1,0),(2,0)}
v_pt  3={(3,0)} (2,0),(3,1)}
{(4,0),(5,1)} {(4,1)}
{(5,1)}{(4,1)}
v_pt  5 ={(5,2)} ={(5,0)}
v_pt  5 ={(5,1)}
{(5,0)}v_pt    =
{(4,1),(5,1)} {(4,1),(5,1)}v_pt  4={(4,0)}
4p
5p3p2p1p1
5v_pt  
5e2_pt    =5
e1_pt   =5 4
{(4,0),(5,1)}(2,0),(3,1)}
{(4,1)}3{(3,2),(4,1)}v−pt  v−pt  
{(3,3)} {(3,2),(4,1)} {(3,2)}3v_pt   = 3=v_pt   {(1,0),
{(3,1)}v_pt  2
3e3_pt     =
e1_pt    =e2_pt    =3e1_pt    =  {(3,0)}   {(1,0)3 =3 =
v_pt  4=v_pt  4==3
Figure3.6: Vectorclocksprogress inJard-Jourdan techniq ue
In Figure 3.6, eX_ptndenotes the timestamp of the Xthobserved event at process pn. For
instance,theevent 1observedat p4istimestamped e1_pt4={(4,0),(5,1)};thistimestampmeans
that the pseudo-direct predecessors of this event are locat ed at process p4andp5, and are respec-
tively the event 0observed at p4and event 1observed at p5.v_ptndenotes a list of timestamps
collected by a process pnfor the unobserved events and is reset and updated after an ev ent is ob-
served atpn. For instance, let us consider v_pt3. Processp3ﬁrst collects the timestamp of event
zero(3,0)intov_pt3and when the observed event 1occurs, it transfers its content to e1_pt3, re-
sets its list and updates its value to (3,1)which is the timestamp of the observed event. When it
receives a message from process p2, it includes those elements that are not already present in i ts
list,namely, (1,0)and(2,0)tov_pt3. Again,whenevent 2isobserved,itresets itslistto {(3,2)}
and transfers its content to e2_pt3which holds{(1,0),(2,0),(3,1)}. It can be seen that event 2
at processp3is directly dependent upon event 0on processp2and event 1on processp3. But, it
62
is pseudo-directly dependent upon event 0at processp1. It also depends on event 0at processp3
butthisdependency informationis obtainedbyexamining e1_pt3recorded bytheobservedevent.
Thus,transitivedependenciesofevent 2atprocessp3canbecomputedbyexaminingtheobserved
events ine2_pt3. If this is done recursively, then all the causal dependenci es of an observed event
can be retrieved. It is also pertinent to observe here that th ese transitive dependencies cannot be
determinedonlinebutfrom alogoftheevents.
Thismethodcanhelpensurethatthelistpiggybackedonames sageisofoptimalsize. Itisalso
possible to limit the size of the list by introducing a dummy o bserved event. If the size of the list
is to be limited to k, then when timestamps of kevents have been collected in the list, a dummy
observed event can be introduced to receive the contents of t he list. This allowsa lot of ﬂexibility
inmanagingthesizeofmessages.
3.7 MatrixTime
3.7.1 Deﬁnition
In a system of matrix clocks, the time is represented by a set o fn×nmatrices of non-negative
integers. A process pimaintainsamatrix mti[1..n,1..n]where,
•mti[i,i]denotes the local logical clock of piand tracks the progress of the computation at
processpi.
•mti[i,j]denotes the latest knowledge that process pihas about the local logical clock,
mtj[j,j], of process pj. Note that row mti[i,.]is nothing but the vector clock vti[.]and
exhibitsallthepropertiesofvectorclocks.
•mti[j,k]represents theknowledgethatprocess pihasaboutthelatestknowledgethat pjhas
aboutthelocallogicalclock, mtk[k,k], ofpk.
Theentirematrix mtidenotespi’slocalviewofthegloballogicaltime. Thematrixtimestam p
ofan eventisthevalueofthematrixclock oftheprocesswhen theeventis executed.
Processpiuses thefollowingrules R1andR2toupdateitsclock:
•R1: Before executingan event,process piupdatesitslocallogical timeasfollows:
mti[i,i] :=mti[i,i] +d (d>0)
•R2: Each message mis piggybackedwith matrixtime mt. Whenpireceives such amessage
(m,mt)fromaprocess pj,piexecutesthefollowingsequenceofactions:
–Updateitsgloballogicaltimeas follows:
(a) 1≤k≤n:mti[i,k] :=max(mti[i,k],mt[j,k])
(That is,updateitsrow mti[i,∗]withthepj’srow inthereceivedtimestamp, mt.)
(b) 1≤k,l≤n:mti[k,l] :=max(mti[k,l],mt[k,l])
63
–ExecuteR1.
–Delivermessage m.
e1
jej2ke2e1
k
mt    k,j mt    j,j]
p
ppk
j
iemm
mm2
34e ee e
1
mte[ [
[mt    i,k mt    i,k
[ ]]
]
Figure 3.7: Evolutionofmatrixtime.
Figure 3.7 givesan exampleto illustratehow matrix clocks p rogress in a distributedcomputa-
tion. Weassume d=1. Letusconsiderthefollowingevents: ewhichisthe xi-theventatprocess pi,
e1
kande2
kwhich are the x1
k-th andx2
k-th event at process pk, ande1
jande2
jwhich are the x1
j-th and
x2
j-th events at pj. Letmtedenote the matrix timestamp associated with event e. Due to message
m4,e2
kis the last event of pkthat causally precedes e, therefore, we have mte[i,k]=mte[k,k]=x2
k.
Likewise,mte[i,j]=mte[j,j]=x2
j. The last event of pkknown bypj, to the knowledge of piwhen
itexecutedevent e, ise1
k; therefore,mte[j,k]=x1
k. Likewise,wehave mte[k,j]=x1
j.
A system of matrix clocks was ﬁrst informally proposed by Mic hael and Fischer [7] and has
been usedbyWuuand Bernstein[32]andby Lynchand Sarin [26] to discardobsoleteinformation
inreplicated databases.
3.7.2 BasicProperties
Clearly,vector mti[i,.]containsallthepropertiesofvectorclocks. Inaddition,m atrixclockshave
thefollowingproperty:
min
k(mti[k,l])≥t:processpiknowsthateveryotherprocess pkknows
thatpl’slocal timehasprogressed till t
If this is true, it is clear that process piknows that all other processes know that plwill never
send information with a local time ≤t. In many applications, this implies that processes will no
longerrequirefrom plcertain informationand can usethisfact todiscard obsolet einformation.
Ifdis always 1 in the rule R1, thenmti[k,l]denotes the number of events occurred at pland
knownbypkas faraspi’sknowledgeisconcerned.
3.8 VirtualTime
Virtual timesystem is a paradigm for organizing and synchro nizing distributedsystemsusing vir-
tual time [9]. This section a provides description of virtua l time and its implementation using
64
the Time Warp mechanism (a lookahead-rollback synchroniza tion mechanism using rollback via
antimessages).
The implementation of virtual time using Time Warp mechanis m works on the basis of an
optimistic assumption. Time Warp relies on the general look ahead-rollback mechanism where
each process executes without regard to other processes hav ing synchronization conﬂicts. If a
conﬂict is discovered, the offending processes are rolled b ack to the time just before the conﬂict
and executed forward along the revised path. Detection of co nﬂicts and rollbacks are transparent
to users. The implementation of Virtual Time using Time Warp mechanism makes the following
optimisticassumption: synchronizationconﬂicts and thus rollbacksgenerallyoccurs rarely.
In thefollowingsections,wediscussin detail VirtualTime and howTimeWarp mechanismis
used toimplementit.
3.8.1 VirtualTimeDeﬁnition
Virtualtimeisaglobal,onedimensional,temporalcoordin atesystemonadistributedcomputation
to measure the computational progress and to deﬁne synchron ization. A virtual time system is a
distributedsystemexecutingin coordinationwithan imagi naryvirtualclock thatuses virtualtime
[9]. Virtual times are real values that are totally ordered b y the less than relation, “<”. Virtual
time is implemented a collection of several loosely synchro nized local virtual clocks. As a rule,
these local virtual clocks move forward to higher virtual ti mes; however, occasionaly they move
backwards.
In a distributed system, processes run concurrently and com municate with each other by ex-
changingmessages. Every messageischaracterized by fourv alues:
a)Name ofthesender
b)Virtualsend time
c) Nameofthereceiver
d)Virtualreceive time
Virtual send time is the virtual time at the sender when the me ssage is sent, whereas virtual
receive time speciﬁes the virtual time when the message must be received (and processed) by the
receiver. Clearly, a big problem arises when a message arriv es at process late, that is, the virtual
receive time of the message is less than the local virtual tim e at the receiver process when the
messagearrives.
Virtualtimesystemsaresubject totwosemanticrules simil artoLamport’sclockconditions:
Rule1:Virtualsendtimeofeach message<virtualreceivetimeofth atmessage.
Rule2:Virtualtimeofeach eventina process<Virtual timeofnexte ventin thatprocess.
The above two rules imply that a process sends all messages in increasing order of virtual
send time and a process receives (and processes) all message s in the increasing order of virtual
receivetime. Causalityofeventsisanimportantconceptin distributedsystemsandisalsoamajor
constraintintheimplementationofvirtualtime. Itisimpo rtanttoknowwhicheventcausedanother
oneandtheonethatcausesanothershouldbecompletelyexec utedbedorethecausedeventcanbe
processed.
65
The constraint in the implementation of virtual time can be s tated as follows: “If an event A
causeseventB,thentheexecutionofAandBmustbescheduled inrealtimesothatAiscompleted
beforeB starts”.
If event A has an earlier virtual timethan eventB, we need exe cuteA before B providedthere
isno causal chainfrom A toB. Betterperformancecan beachie vedbyschedulingAconcurrently
with B or scheduling A after B. If A and B have exactly the same v irtual time coordinate, then
there is no restriction on the order of their scheduling. If A and B are distinct events, they will
have different virtual space coordinates (since they occur at different processes) and neither will
be a cause for the other. Hence to sum it up, events with virtua l time < ‘t’ complete before the
startingofeventsattime‘t’andeventswithvirtualtime>‘ t’willstartonlyaftereventsat time‘t’
are complete.
Characteristics ofVirtual Time
1. Virtualtimesystemsare notall isomorphic;itmaybeeith erdiscreteorcontinuous.
2. Virtualtimemay beonly partiallyordered (In thisimplem entation,totalorderisassumed.)
3. Virtualtimemay berelated to real timeormay beindepende ntofit.
4. Virtualtimesystemsmaybevisibletoprogrammersandman ipulatedexplicitlyasvalues,or
hiddenand manipulatedimplicitlyaccordingto somesystem -deﬁneddiscipline
5. Virtual times associated with events may be explicitly ca lculated by user programs or they
maybeassignedby ﬁxed rules.
3.8.2 ComparisonwithLamport’sLogicalClocks
Lamportshowed thatreal-timetemporal relationships“ happens before” and “happensafter” , op-
erationally deﬁnable within a distributed system, form onl y a partial order, not a total order, and
concurrent events are incomparable under that partial orde r. He also showed that it is always pos-
sibletoextendpartialordertototalorderbydeﬁningartiﬁ cialclocks. Anartiﬁcialclockiscreated
one for each process with unique labels from a totally ordere d set in a manner consistent with
partial order. He also providedan algorithmon howto accomp lishthis task ofyieldingan assign-
ment oftotallyordered clock values. In virtual time,there verse oftheaboveisdone by assuming
that every event is labeled with a clock value from a totally o rdered virtual time scale satisfying
Lamport’sclock conditions. ThustheTimeWarp mechanismis an inverseofLamport’sscheme.
InLamport’sscheme,allclocksareconservativelymaintai nedsothattheyneverviolatecausal-
ity. Aprocessadvancesitsclockassoonasitlearnsofnewca usaldependency. Inthevirtualtime,
clocksareoptimisticalyadvancedandcorrectiveactionsa retakenwheneveraviolationisdetected.
Lamport’sinitialideabroughtabouttheconceptofvirtual timebutthemodelfailedtopreserve
causal independence. It was possible to make an analysis in t he real world using timestamps but
the same principle could not be implemented completely in th e case of asynchronous distributed
systemsforthelack ofacommontimebase.
The implementation of virtual time concept using Time Warp m echanism is easier to under-
standand reason aboutthan real time.
66
3.8.3 TimeWarpMechanism
IntheimplementationofvirtualtimeusingTimeWarpmechan ism,virtualreceivetimeofmessage
is considered as its timestamp. The necessary and sufﬁcient conditions for the correct implemen-
tation of virtual time are that each process must handle inco ming messages in timestamp order.
This is highlyundesirableand restrictivebecause process speeds and messagedelays are likelyto
highlyvariable. So itnatural forsomeprocesses toget ahea d invirtualtimeofotherprocesses.
Since we assume virtual times are real numbers, it is impossi ble for a process on the basis of
local information alone to block and wait for the message wit h the next timestamp. It is always
possiblethatamessagewithearliertimestamparriveslate r. So,whenaprocessexecutesamessage,
it is very difﬁcult for it determine whether a message with an earlier timestamp will arrive later.
Thisisthecentral probleminvirtualtimethat issolvedbyt heTimeWarp mechanism.
The advantage of Time warp mechanism is that it doesn’t depen d on the underlying computer
architecture and so portabilityto different systems is eas ily achieved. However, message commu-
nicationisassumedto bereliable,butmessages maynotbede liveredinFIFO order.
Time Warp mechanism consists of two major parts: local contr ol mechanism and global con-
trol mechanism. The local control mechanism insures that ev ents are executed and messages are
processed in the correct order. The global control mechanis m takes care of global issues such as
globalprogress,terminationdetection,I/Oerror handlin g,ﬂow control,etc.
3.8.4 The LocalControl Mechanism
There is no global virtual clock variable in this implementa tion; each process has a local virtual
clockvariable. The local virtual clock of a process doesn’t chang e during an event at that process
but it changes only between events. On the processing of next message from the input queue,
the process increases its local clock to the timestamp of the message. At any instant, the value
of virtual time may differ for each process but the value is tr ansparent to other processes in the
system.
When a message is sent, the virtual send time is copied from th e sender’s virtual clock while
thenameofthereceiverandvirtualreceivetimeareassigne dbasedonapplicationspeciﬁccontext.
Allarrivingmessagesataprocessarestoredinaninputqueu eintheincreasingorderoftimes-
tamps(receive times). Ideally, no messages from thepast (c alled latemessages)should arriveat a
process. However, processes will receive late messages due to factors such as different computa-
tion rates of processes and network delays. The semantics of virtual time demands that incoming
messagesbereceivedbyeach processstrictlyinthetimesta mporder. Theonlywaytoaccomplish
this is as follows: on the reception of a late message, the rec eiver rolls back to an earlier virtual
time,cancellingallintermediatesideeffectsandthenexe cutesforwardagainbyexecutingthelate
messagein theproper sequence. If all themessages in the inp utqueueof a process are processed,
the state of the process is said to terminate and its clock is set to + inf. However, the process is
notdestroyedasalatemessagemayarriveresultingittorol lbackandexecuteagain. Thesituation
can be described by saying that each process is doing a consta nt “lookahead”, processing future
messagesfrom itsinputqueue.
Overalengthcomputation,eachprocessmayrollbacksevera ltimeswhilegenerallyprogress-
ing forward with rollback completely transparent to other p rocesses in the system. Programmers
can writecorrect softwarewithoutpayingmuchattentionto late-arrivingmessages.
67
Rollback in a distributed system is complicated by the fact t hat the process that wants to roll-
back might have sent many messages to other processes, which in turn might have sent many
messages to other processes, and so on, leading to deep side e ffects. For rollback, messages must
be effectively “ unsent”and their side effects should be undone. This is achieved efﬁ ciently by
usingantimessages.
Antimessagesandthe Rollback Mechanism
Runtimerepresentationofaprocess iscomposedofthefollo wing:
1.Process name : Virtualspaces coordinatewhich isuniquein thesystem.
2.Local virtual clock: V irtualtimecoordinate
3.State: Data space of the process including execution stack, progr am counter and its own
variables
4.State queue : Contains saved copies of process’s recent states as roll ba ck with Time warp
mechanism requires the state of the process being saved. But it is not necessary to retain
states from all the way beginning of the virtual time the reas on for which will be explained
inGlobalControl mechanism.
5.Input queue : Contains all recently arrived messages in order of virtual receive time. Pro-
cessed messages from the input queue are not deleted as they a re saved in the output queue
withanegativesign(antimessage)tofacilitatefuturerol l backs.
6.Outputqueue : Containsnegativecopiesofmessagestheprocesshasrecen tlysentinvirtual
sendtimeorder. Theyare needed incaseofa rollback.
Foreverymessage,thereexistsanantimessagethatisthesa meincontentbutoppositeinsign.
Whenever a process sends a message, a copy of the message is tr ansmitted to receiver’s input
queueand a negativecopy (antimessage)is retained in these nder’s outputqueueforusein sender
rollback.
Whenever a message and its antimessage appear in the same que ue no matter in which order
they arrived, they immediately annihilate each other resul ting in shortening of the queue by one
message.
Generally when a message arrives at the input queue of a proce ss with timestamp greater than
virtual clock timeof its destinationprocess, it is simply e nqueued by the interrupt routine and the
runningprocesscontinues. Butwhenthedestinationproces s’virtualtimeisgreaterthanthevirtual
timeofmessagereceived, theprocess mustdoarollback.
The ﬁrst step in the rollback mechanism is to search the "Stat e queue" for the last saved state
withtimestampthatislessthanthetimestampofthemessage receivedandrestoreit. Wemakethe
timestampofthereceivedmessageasthevalueofthelocalvi rtualclockanddiscardfromthestate
queue all states saved after this time. Then the execution re sumes forward from this point. Now
all the messages that are sent between the current state and e arlier state must be “unsent”. This is
taken careofby executingasimplerule:
68
“To unsenda message,simplytransmititsantimessage.”
Thisresultsinantimessagesfollowingthepositiveonesto thedestination. Anegativemessage
causes a rollback at its destinationifit’svirtual receive timeis lessthan the receiver’svirtual time
(justas apositivemessagedoes).
Dependingon thetiming,thereareseveralpossibilitiesat thereceiver’send:
1. If the original (positive) message has arrived but not yet been processed, its virtual receive
time must be greater than the value in the receiver’s virtual clock. The negative message,
havingthesamevirtualreceivestime,willbeenqueuedandw illnotcausearollback. Itwill,
howevercauseannihilationwiththe positivemessageleavi ng thereceiver withno record of
thatmessage.
2. Second possibilityisthattheoriginalpositivemessage has avirtualreceivetimethatisnow
inthepresentorpastwithrespecttothereceiver’svirtual clockanditmayhavealreadybeen
partially or completely processed, causing side effects on receiver’s state. In this case, the
negativemessage will also arrive in the receiver’s past and cause the receiver to roll back to
a virtual time when the positive message was received. It wil l also annihilate the positive
message leaving the receiver with no record that the message existed. When the receiver
executes again, the execution will assume that these messag e never existed. Note that as
aresultoftherollback,theprocess maysend antimessagest o otherprocesses.
3. Anegativemessagecanalsoarriveatthedestinationbefo rethepositiveone. Inthiscase,itis
enqueued and will be annihilated when positivemessage arri ves. If it is negativemessage’s
turntobeexecutedataprocesss’inputqueqe,thereceiverm aytakeanyactionlikeano-op.
Any action taken will eventually be rolled back when the corr esponding positive message
arrives. An optimization would be to skip the antimessage fr om the input queue and treat
it as a no-op, and when the corresponding positive message ar rives, it will annihilate the
negativemessage, andinhibitanyrollback.
The antimessage protocol has several advantages: It is extr emely robust and works under all
possible circumstances. It is free from deadlocks as there i s no blocking. It is also free from
dominoeffects. Intheworstcase, allprocessesinsystemro llbacktosamevirtualtimeasoriginal
onedidand thenproceed forward again.
3.8.5 GlobalControlMechanism
Globalcontrolmechanismresolvesthefollowingissues:
1. Systemglobalprogress amidstrollback activity?
2. Detectionofglobaltermination?
3. Errors, I/Ohandlingonrollbacks?
4. Runningoutofmemorywhilesavingcopies ofmessages?
How these issues are resolved by global control mechanism wi ll be discussed later; ﬁrst we
discusstheimportantconceptofglobalvirtualtime.
69
GlobalVirtual Time(GVT)
The concept of global virtual time is central to Global Contr ol mechanism. Global virtual time
[14] is a property of an instantaneous global snapshot of sys tem at real time ’r’ and is deﬁned as
follows:
GlobalvirtualtimeGVT at real timeris theminimumof
1. Allvirtualtimesinall virtualclocksat timer, and
2. Virtual send times of all messages that have been sent but h ave not yet been processed at
time’r’.
GVT is deﬁned in terms of virtual send time of unprocessed messages, instead of the virtual
receive time because of the ﬂow control which will be discuss ed later. If every event completes
normally, if messages are delivered reliably, if the schedu ler does not indeﬁnitely postpone exe-
cution of the farthest behind process and if there is sufﬁcie nt memory, then GVT will eventually
increase.
It is easily shown by induction that the message(sends, arri vals, and receipts) neverdecreases
GVT even though local virtual time clocks roll back frequent ly. These properties make it appro-
priate to consider GVT as virtual clock for the system as a who le and to use it as the measure
of system progress. GVT can thus be viewed as a moving commitm ent horizon: any event with
virtualtimelessthan GVT cannotberolledback and may becom mittedsafely.
It is generally impossiblefor Timewarp mechanismto know at any real time’r’, exactly what
GVT is. But GVT can be characterized more operationally by it s two properties discussed above.
This characterization leads to a fast distributed GVT estim ation algorithm that takes O(d) time
where ’d’ is the delay required for one broadcast to all proce ssors in the system. The algorithm
runsconcurrentlywithmaincomputationandreturnsvaluet hatisbetweentrueGVTatthemoment
whenthealgorithmstartsandthetrueGVTatmomentofcomple tion. Thusitgivesaslightlyout-
of-datevalueforGVT whichis thebest onecan get.
During execution of a virtual time system, Time warp must est imate GVT every so often.
Higher frequency of GVT estimation produces faster respons e time and better space utilization at
theexpenseofprocessortimeandnetwork bandwidth.
Applications of GVT
GVT ﬁndsseveralapplicationsinavirtualtimesystemusing thetimewarp mechanism.
Memory Management andFlow Control
AnattractivefeatureinTimeWarpmechanismisthatitispos sibletogivesimplealgorithmsfor
managingmemory. TimeWarp mechanismusestheconcept offos sildetectionwhereinformation
olderthanGVTisdestroyedtoavoidmemoryoverheadsduetoo ldstatesinstatequeues,messages
stored in output queues, "past" messages in input queue that have already been processed and
"future"messagesin inputqueuethat havenotyet been recei ved.
There is another kind of memory overhead due to future messag es in the input queues that
have not yet been received. So, if a receiver’s memory is full of input messages, the Time Warp
mechanism may be able to recover space by returning an unrece ived message to the process that
70
sentit andthen rollbackto cancel outthesendingevent.
NormalTermination Detection
The Time Warp mechanism handles the termination detection p roblem through GVT. A pro-
cessterminateswheneveritrunsoutofmessagesanditsloca lvirtualclockissetto+inf. Whenever
GVTreaches+inf,alllocalvirtualclockvariablesmustrea d+infandnomessagecanbeintransit.
No process can ever again unterminate by rolling back to a ﬁni te virtual time. The Time Warp
mechanismsignalsterminationwheneverGVTcalculation re turns“+inf” valueinthesystem.
Error Handling
All errors don’t cause termination. Most of theerrors can be avoided by rollingback thelocal
virtualclock to someﬁnitevalue. Theerror isonly “committ ed”ifitis impossiblefortheprocess
torollbacktoavirtualtimeonorbeforetheerror. Thecommi ttederrorisreportedtosomepolicy
softwareortotheuser.
Input and output
When a process sends a command to an output device, it is impor tant that the physical output
activity not be committed immediately because the sending p rocess may roll back and cancel the
output request. An output activity can only be performed whe n GVT exceeds the virtual receive
timeofthemessagecontainingthecommand.
Snapshots andCrashRecovery
An entiresnapshotofthesystemat virtualtime‘t’canbecon structedbyaprocedurein which
each process “snapshots” itself as it passes virtual time t in the forward direction an d “unsnap-
shots”itselfwheneverit rolls back overvirtual time‘t’. Wheneve rGVT exceeds ‘t’, thesnapshot
iscompleteand valid.
3.8.6 AnExample: Distributed Discrete EventSimulations
Distributeddiscreteeventsimulation [16,2,25]isthemos tstudidexampleofvirtualtimesystems,
every process represents an object in the simulation and vir tual time is identiﬁed with simulation
time. The fundamental operation in discrete event simulati on is for one process to schedule an
event for execution by another process at a later simulation time. This is emulated by having the
ﬁrst process send a message to the second process with virtua l receive time of the message equal
toevent’sscheduledtimeinthesimulation. Whenaneventme ssageisreceivedbyaprocess,there
arethreepossibilities: itstimestampiseitherbefore, af terorequalto thelocalvalueofsimulation
time.
Ifitstimestampisafterthelocaltime,aninputeventcombi nationisformedandtheappropriate
actionistaken. Howeverifthetimestampofthereceivedeve ntmessageislessthanorequaltothe
localclockvalue,theprocesshasalreadyprocessedaneven tcombinationwithtimegreaterthanor
equal to the incoming event. The process must then rollback t o the timeof the incomingmessage
which is done by an elaborate checkpointing mechanism that a llows earlier states to be restored.
Essentiallyanearlierstateisrestored,inputeventcombi nationsarerescheduled andoutputevents
are cancelled by sending antimessages. The process has buff ers that save past inputs, past states
and antimessages.
71
Distributeddiscreteeventsimulationisoneofthemostgen eral applicationsofthevirtualtime
paradigm because the virtual times of events are completely under the control of the user and
becauseitmakesuseofalmostallthedegreesoffreedomallo wedinthedeﬁnitionofavirtualtime
system.
3.9 PhysicalClockSynchronization: NTP
3.9.1 Motivation
Incentralizedsystems,thereisnoneedforclockssynchron izationbecausegenerally,thereisonly
singleclock. A process gets the time by simply issuing a syst em call to the kernel. When another
process after that tries to get the time, it will get a highert ime value. Thus, in such systems, there
isaclearorderingofeventsand thereisnoambiguityaboutt hetimesatwhichtheseeventsoccur.
In distributed systems, there is no global clock or common me mory. Each processor has its
own internal clock and its own notion of time. In practice, th ese clocks can easily drift seconds
per day, accumulating signiﬁcant errors over time. Also, be cause different clocks tick at different
rates, they may not remain always synchronized although the y might be synchronized when they
start. This clearly poses serious problems to applications that depend on a synchronized notion of
time. Formostapplicationsand algorithmsthat run ina dist ributedsystem,weneed to knowtime
inoneormoreofthefollowingcontexts:
•Thetimeoftheday at whichan eventhappened onaspeciﬁc mach ineinthenetwork.
•Thetimeintervalbetweentwo eventsthat happenedon differ entmachinesin thenetwork.
•Therelativeordering ofeventsthat happenedon differentm achinesin thenetwork.
Unless the clocks in each machine have a common notion of time , time-based queries cannot
beanswered. Somepractical examplesthat stresstheneed fo rsynchronizationare listedbelow.
•Indatabasesystems,theorderinwhichprocessesperformup datesonadatabaseisimportant
toensureaconsistent,correct viewofthedatabase. Toensu retherightorderingofevents,a
commonnotionoftimebetween co-operatingprocesses becom esimperative.
•Liskov[12] states that clock synchronizationimprovesthe performance of distributedalgo-
rithms by replacing communication with local computation. When a node pneeds to query
nodeqregarding a property, it can deduce the property with some pr evious information it
has aboutnode pand itsknowledgeofthelocal timeinnode q.
•Itisquitecommonthatdistributedapplicationsandnetwor kprotocolsusetimeouts,andtheir
performance depends on how well physically dispersed proce ssors are time-synchronized.
Designofsuchapplicationsissimpliﬁedwhenclocks aresyn chronized.
Clock synchronization is the process of ensuring that physi cally distributed processors have a
common notion of time. It has a signiﬁcant effect on many prob lems like secure systems, fault
diagnosis and recovery, scheduled operations, database sy stems, and real-world clock values. It
72
is quite common that distributed applications and network p rotocols use timeouts, and their per-
formance depends on how well physically dispersed processo rs are time-synchronized. Design of
such applicationsissimpliﬁedwhenclocks aresynchronize d.
Clock synchronization is the process of ensuring that physi cally distributed processors have
a common notion of time. It has a signiﬁcant effect on many are as like security systems, fault
diagnosisand recovery,scheduledoperations,databasesy stems,and real-world clock values.
Duetodifferentclocksrates,theclocksatvarioussitesma ydivergewithtimeandperiodically
aclocksynchrinizationmustbeperformedtocorrectthiscl ockskewindistributedsystems. Clocks
aresynchronizedtoanaccuratereal-timestandardlikeUTC (UniversalCoordinatedTime). Clocks
that must not only be synchronized with each other but also ha ve to adhere to physical time are
termedphysicalclocks .
3.9.2 Deﬁnitions and Terminology
Weprovidethefollowingdeﬁnitions[16, 17]. CaandCbare anytwo clocks.
Time:The time of a clock in a machine pis given by the function Cp(t), whereCp(t)=tfor a
perfect clock.
Frequency : Frequency is the rate at which a clock progresses. The freque ncy at timetof clock
CaisC′
a(t).
Offset:Clock offset isthedifference between thetimereported by a clock and the real time. The
offset of the clock Cais given by Ca(t)−t. The offset of clock Carelative toCbat time
t≥0isgivenbyCa(t)−Cb(t).
Skew:The skew of a clock is the difference in the frequencies of the clock and the perfect clock.
Theskewofaclock Carelativetoclock Cbat timetis(C′
a(t)−C′
b(t)).
Iftheskewisboundedby ρ, then asperEquation3.1,clock valuesareallowedtodiverg eat
aratein therangeof 1−ρto1 +ρ.
Drift(rate): Thedriftofclock Caisthesecondderivativeoftheclockvaluewithrespecttoti me,
namely,C′′
a(t). Thedriftofclock Carelativetoclock Cbat timetisC′′
a(t)−C′′
b(t).
3.9.3 ClockInaccuracies
Physical clocks are synchronized to an accurate real-time s tandard like UTC (Universal Coordi-
nated Time).
However, due to the clock inaccuracy discussed above, a time r (clock) is said to be working
withinitsspeciﬁcationif
1−ρ≤dC
dt≤1 +ρ (3.1)
where constant ρis the maximum skew rate speciﬁed by the manufacturer. Figur e 3.8 illustrates
thebehavioroffast, slow,and perfect clockswithrespect t oUTC.
73
Clock time, C
UTC, tFast Clock
dC/dt > 1
Perfect Clock
dC/dt = 1
Slow Clock
dC/dt < 1
Figure3.8: Thebehavioroffast, slow,and perfect clocks wi threspect toUTC.
Offsetdelay estimationmethod
TheNetwork Time Protocol (NTP) [18] which is widely used for clock synchronization on the
Internet uses the The Offset Delay Estimation method. The design of NTP involves a hierarchical
tree of time servers. The primary server at the root synchron izes with the UTC. The next level
contains secondary servers, which act as a backup to the prim ary server. At thelowest level is the
synchronizationsubnetwhich hastheclients.
T3T1
ABT2
T4
Figure3.9: Offset anddelay estimation[18].
Clock offset and delay estimation: In practice, a source node cannot accurately estimate the
local time on the target node due to varying message or networ k delays between the nodes. This
protocol employs a very common practice of performing sever al trials and chooses the trial with
theminimumdelay. RecallthatCristian’sremoteclockread ingmethod[5]alsoreliedonthesame
strategytoestimatemessagedelay.
Figure 3.9 shows howNTP timestampsare numbered and exchang ed between peers AandB.
LetT1,T2,T3,T4be the values of the four most recent timestamps as shown. Ass ume that clocks
74
AandBarestableandrunningatthesamespeed. Let a=T1−T3andb=T2−T4. Ifthenetwork
delay difference from AtoBand fromBtoA, calleddifferential delay , is small, the clock offset
θand roundtripdelay δofBrelativetoAat timeT4areapproximatelygivenbythefollowing.
θ=a+b
2, δ=a−b (3.2)
Ti-3Ti-2 Server A
Server BTi-1
Ti
Figure3.10: Timingdiagramforthetwoservers [18].
Each NTP message includes the latest three timestamps T1,T2andT3, whileT4is determined
uponarrival. Thus,bothpeers AandBcanindependentlycalculatedelayandoffsetusingasingle
bidirectionalmessagestreamas showninFigure3.10. TheNT Pprotocolis shownin Figure3.11.
3.10 ChapterSummary
The concept of causality between events is fundamental to th e design and analysis of distributed
programs. The notion of time is basic to capture causality be tween events; however, there is no
built-in physical time in distributed systems and it is poss ible only to realize an approximation of
it. Typically, a distributed computation makes progress in spurts and consequently logical time,
which advances in jumps, is sufﬁcient to capture the monoton icity property induced by causality
in distributed systems. Causality among events in a distrib uted system is a powerful concept in
reasoning,analyzing,and drawinginferences about acompu tation.
Wepresented ageneral frameworkoflogicalclocksindistri butedsystemsanddiscussedthree
systems of logical clocks, namely, scalar, vector, and matr ix clocks, that have been proposed to
capturecausalitybetween eventsofadistributedcomputat ion. Thesesystemsofclockshavebeen
used to solve a variety of problems in distributed systems su ch as distributed algorithms design,
debuggingdistributedprograms,checkpointingandfailur erecovery,dataconsistencyinreplicated
databases, discardingobsoleteinformation,garbagecoll ection,and terminationdetection.
In scalar clocks, the clock at a process is represented by an i nteger. The message and the
compuatationoverheadsaresmall,butthepowerofscalarcl ocksislimited–theyarenotstrongly
consistent. In vector clocks, the clock at a process is repre sented by a vector of integers. Thus,
themessageand thecompuatationoverheadsare likelyto beh igh;however,vectorclockspossess
a powerful property – there is an isomorphism between the set of partially ordered events in a
distributedcomputationandtheirvectortimestamps. This isaveryusefulandinterestingproperty
75
•Apair ofservers in symmetric mode exchange pairs oftiming m essages.
•Astore ofdata isthen built upabout the relationship betwee n the twoservers (pairs ofoffset
and delay).
Speciﬁcally, assume that each peer maintains pairs ( Oi,Di), where
Oi-measure of offset ( θ)
Di-transmission delay oftwomessages ( δ).
•Theoffset corresponding tothe minimum delay ischosen.
Speciﬁcally, the delay and offset are calculated as follows . Assume that message mtakes
timetto transfer and m′takest′totransfer.
–The offset between A’s clock and B’s clock is O. IfA’s local clock time is A(t)and
B’slocal clock timeis B(t),wehave
A(t) =B(t) +O (3.3)
Then,
Ti−2=Ti−3+t+O (3.4)
Ti=Ti−1−O+t′(3.5)
Assuming t=t′,the offset Oican beestimated as:
Oi= (Ti−2−Ti−3+Ti−1−Ti)/2 (3.6)
Theround-trip delay is estimated as:
Di= (Ti−Ti−3)−(Ti−1−Ti−2) (3.7)
–Theeight mostrecent pairs of( Oi,Di)areretained.
–Thevalue of Oithat corresponds to minimum Diis chosen toestimate O.
Figure3.11: TheNetworkTimeProtocol synchronizationpro tocol[18].
ofvectorclocksthatﬁndsapplicationsinseveralproblemd omains. Inmatrixclocks,theclockata
process isrepresented bya matrixofintegers. Thus,themes sageand thecompuatationoverheads
are high; however, matrix clocks are very powerful – besides containing information about the
direct dependencies, a matrix clock contains information a bout the latest direct dependencies of
thosedependencies. Thisinformationcanbeveryusefulina plicationssuchasdistributedgarbage
collection. Thus,thepowerofsystemsofclocksincreasesi ntheorderofscalar,vector,andmatrix,
butso dothecomplexityandtheoverheads.
We discussed three efﬁcient implementationsof vector cloc ks; similartechniques can be used
toefﬁcientlyimplementmatrixclocks. Singhal-Kshemkaly ani’sdifferentialtechniqueexploitsthe
fact that between successive events at a process, only few en tries of its vector clock are likely to
76
change. Thus, when aprocess pisendsa messagetoa process pj, itpiggybacksonly thoseentries
of its vector clock that have changed since the last message s end topj, reducing the communica-
tion and buffer (to store messages)overheads. Fowler-Zwae nepoel’s direct-dependency technique
doesnotmaintainvectorclockson-the-ﬂy. Instead,aproce ssonlymaintainsinformationregarding
direct dependencies on other processes. A vector timestamp for an event, that represents transi-
tive dependencies on other processes, is constructed off-l ine from a recursive search of the direct
dependency information at processes. Thus, the technique h as low run-time overhead. In the
Fowler-Zwaenepoel’stechnique,however,aprocessmustup dateandrecorditsdependencyvector
after receiving a message but before sending out any message . If events occur very frequently,
thistechniquewillrequirerecordingthehistoryofalarge numberofevents. IntheJard-Jourdan’s
technique, eventscan be adaptivelyobserved whilemaintai ningthecapability ofretrieving all the
causal dependenciesofan observedevent.
Virtual time system is a paradigm for organizing and synchro nizing distributed systems using
virtualtime. Wediscussedvirtualtimeand itsimplementat ionusingtheTimeWarp mechanism.
3.11 BibliographicNotes
The idea of logical time was proposed by Lamport in 1978 [11] i n an attempt to order events in
distributed systems. He also suggested an implementationo f logical time as a scalar time. Vector
clocksweredevelopedindependentlybyFidge[6],Mattern[ 14]andSchmuck[27]. Charron-Bost
formally showed [4] that if vector clocks have to satisfy the strong consistency property, then the
length of vector timestamps must be at least n. Efﬁcient implementations of vector clocks can be
foundin [10, 29]. Matrixclockswas informallyproposed byM ichaeland Fischer[7]and usedby
Wuu and Bernstein [32] and by Lynch and Sarin [26]to discard o bsoleteinformation. Raynal and
Singhal present a survey of scalar, vector, and matrix clock s in [23]. More details on virtual time
can be found in a classical paper by Jefferson [9]. A survey of physical clock synchronization in
wirelesssensornetworkscan befoundin [31].
3.12 ExerciseProblems
1. Whyisit difﬁculttokeep asynchronizedsystemofphysica lclocks indistributedsystems?
2. If events corresponding to vector timestamps Vt1,Vt2, ....,Vtnare mutually concurrent,
thenprovethat
(Vt1[1],Vt2[2], ....Vtn[n])=max(Vt1,Vt2, ....,Vtn).
3. If events eiandejrespectively occurred at processes piandpjand are assigned vector
timestamps VTeiandVTej, respectively,thenshowthat
ei→ej⇔VTei[i]<VT ej[i].
77
4. The size of matrix clocks is quadratic with respect to the s ystem size. Hence the message
overhead is likely to be substantial. Propose a technique fo r matrix clocks similar to that of
Singhal-Kshemkalyani to decrease the volume of informatio n transmitted in messages and
storedat processes.
78
Bibliography
[1] Awerbuch,B. Complexityof networksynchronization. JournaloftheACM, vol.32,4,(1985),
pp.804-823.
[2] BrunoR.Preiss,UniversityofWaterloo,“TheYaddesDis tributedDiscreteEventSimulation
Speciﬁcation LanguageandExecutionEnvironments”
[3] Chandy, K.M., Misra, J. The drinking philosophers problem. ACM Toplas, vol.6,4, (1984),
pp.632-646.
[4] Charron-Bost, B. Concerning thesizeof logicalclocks in distributedsystem s.Inf. Proc. Let-
ters,vol.39,(1991), pp.11-16.
[5] F. Cristian. Probabilistic Clock Synchronization. Distributed Computing, 3:146–158,
Springer-Verlag, 1989.
[6] Fidge,C. Logicaltimeindistributedcomputingsystems. IEEEComputer,(August1991),pp.
28-33.
[7] Fischer, M.J., Michael, A. Sacrifying serializabilityto attain hight availability o f data in an
unreliable network. Proc. of ACM Symposium on Principles of Database Systems, (1 982),
pp.70-75.
[8] Fowler J., Zwaenepoel W. Causal distributed breakpoints. Proc. of 10th Int’l. Conf. on Dis-
tributedComputingSystems,(1990),pp. 134-141.
[9] Jefferson,D. Virtualtime. ACM Toplas,vol.7,3,(1985), pp.404-425.
[10] JardC.,JourdanG-C. Dependencytrackingandﬁlteringindistributedcomputati ons.inBrief
announcements of the ACM symposium on PODC, (1994). (A full p resentation appeared as
IRISA Tech. Report No.851, 1994).
[11] Lamport, L. Time, clocks and the ordering of events in a distributed syst em.Comm. ACM,
vol.21,(July 1978),pp.558-564.
[12] B.Liskov,PracticalUsesofSynchronizedClocksinDis tributedSystems, Proc.TenthAnnual
ACM SymposiumonPrinciplesofDistributedComputing, pp.1–9,Aug. 1991.
[13] Liskov, B., Ladin, R. Highly available distributed services and fault-tolerant distributed
garbagecollection. Proc. 5thACM Symposiumon PODC, (1986),pp. 29-39.
79
[14] Mattern, F. Virtual time and global states of distributed systems. Proc. "Parallel and dis-
tributedalgorithms"Conf., (Cosnard, Quinton,Raynal, Ro bert Eds), North-Holland,(1988),
pp.215-226.
[15] Mills,DavidL. OntheAccuracyandStabilityofClocks SynchronizedbyNetw orkTimePro-
tocol in the Internet System. ACM Computer Communication Review 20, 1 (January 1990),
pp.65-75.
[16] D.L. Mills. Network Time Protocol (version 3): Speciﬁc ation, Implementation, and Anal-
ysis.Technical Report, Network Information Center, SRI Interna tional, Menlo Park, CA,
Mar.1992.
[17] D.L.Mills. ModellingandAnalysisofComputerNetwork Clocks.TechnicalReport,92-5-2,
ElectricalEngineeringDepartment,UniversityofDelawar e,May 1992.
[18] D.L. Mills. Internet Time Synchronization: the Networ k Time Protocol. IEEE Trans. Com-
munications, Vol39, no10, pp.1482–1493,Oct. 1991.
[19] Misra, J. Distributed discrete event simulation. ACM Computing Surveys, vol.18,1, (1986),
pp.39-65.
[20] Parker, D.S. et al. Detection of mutual inconsistency in distributed sys tems.IEEE Trans. on
Soft. Eng.,vol.SE9,3, (May1983), pp.240-246.
[21] Raynal, M. A distributed algorithm to prevent mutual drift between n lo gical clocks. Inf.
ProcessingLetters, vol.24,(1987), pp.199-202.
[22] Raynal, M., Helary, J.M. Synchronization and control of distributed systems and pro grams.
Wiley&sons,(1990),124 p.
[23] M.Raynal andM.Singhal, LogicalTime: CapturingCausalityinDistributedSystems ,IEEE
Computer,February 1996,Vol30, No2, pp.49-56.
[24] Ricart,G.,Agrawala,A.K. Anoptimalalgorithmformutualexclusionincomputernetwo rks.
Comm.ACM, vol.24,1,(Jan. 1981),pp.9-17.
[25] Righter,R.,Walrand,J.C. Distributedsimulationofdiscreteeventsystems. Proc.oftheIEEE,
(Jan. 1988),pp.99-113.
[26] Sarin, S.K., Lynch, L. Discarding obsolete information in a replicated data base s ystem.
IEEETrans. onSoft. Eng.,vol.SE 13,1,(Jan. 1987),pp.39-4 6.
[27] Schmuck,F. Theuseofefﬁcientbroadcastinasynchronousdistributeds ystems.Ph.D.Thesis,
Cornell University,TR88-928,(1988),124 pages.
[28] M. Singhal, A Heuristically-Aided Mutual Exclusion Algorithm for Dist ributed Systems.
IEEETrans. onComputers,Vol 38,No 5,(May 1989),pp. 651-66 2.
[29] Singhal, M., Kshemkalyani, A. An Efﬁcient Implementation of Vector Clocks. Information
ProcessingLetters, 43,August1992,pp.47-52.
80
[30] Strom, R.E., Yemini, S. Optimistic recovery in distributed systems. ACM TOCS, vol.3,3,
(August1985),pp.204-226.
[31] B. Sundararaman, U. Buy, A.D. Kshemkalyani, Clock Sync hronization in Wireless Sensor
Networks: A Survey,Ad-HocNetworks,3(3): 281-323,May 200 5.
[32] Wuu,G.T.J.,Bernstein,A.J. Efﬁcientsolutionstothereplicatedloganddictionarypro blems.
Proc. 3rd ACM SymposiumonPODC, (1984),pp. 233-242
81
Chapter4
Global StateandSnapshot Recording
Algorithms
Recording on-the-ﬂy the global state of a distributed syste m is an important paradigm when one
is interested in analyzing, testing, or verifying properti es associated with distributed executions.
Unfortunately,thelackofbothagloballysharedmemoryand aglobalclockinadistributedsystem,
added to the fact that message transfer delays in these syste ms are ﬁnite but unpredictable, makes
thisproblemnon-trivial.
This chapter ﬁrst deﬁnes consistent global states (also cal led consistent snapshots) and dis-
cusses issues which have to be addressed to compute consiste nt distributed snapshots. Then sev-
eral algorithmsto determineon-the-ﬂy such snapshotsare p resented forseveral typesof networks
(accordingtothepropertiesoftheircommunicationchanne ls,namely,FIFO,non-FIFO,andcausal
delivery).
4.1 Introduction
A distributed computing system consists of spatially separ ated processes that do not share a com-
mon memory and communicate asynchronously with each other b y message passing over com-
munication channels. Each component of a distributed syste m has a local state. The state of a
processis characterized by thestateofitslocalmemoryand ahistoryofitsactivity. Thestateofa
channel is characterized by the set of messages sent along th e channel less the messages received
along the channel. The global state of a distributed system i s a collection of the local states of its
components.
Recording the global state of a distributed system is an impo rtant paradigm and it ﬁnds ap-
plications in several aspects of distributed system design . For examples, in detection of stable
properties such as deadlocks [17] and termination [22], glo bal state of the system is examined for
certainproperties;forfailurerecovery,aglobalstateof thedistributedsystem(calledacheckpoint)
is periodically saved and recovery from a processor failure is done by restoring the system to the
last saved global state [15]; for debugging distributed sof tware, the system is restored to a consis-
tent global state [8, 9] and the execution resumes from there in a controlled manner. A snapshot
recording method has been used in the distributed debugging facility of Estelle [13, 11], a dis-
tributed programmingenvironment. Other applicationsinc ludemonitoringdistributedevents[30]
82
such as in industrial process control, setting distributed breakpoints [24], protocol speciﬁcation
and veriﬁcation[4, 10, 14], and discardingobsoleteinform ation[12].
Therefore, it is important that we have efﬁcient ways of reco rding the global state of a dis-
tributed system [6, 16]. Unfortunately, there is no shared m emory and no global clock in a dis-
tributed system and the distributed nature of the local cloc ks and local memory makes it difﬁcult
torecord theglobalstateofthesystemefﬁciently.
If shared memory were available, an up-to-date state of the e ntire system would be available
to the processes sharing the memory. The absence of shared me mory necessitates ways of getting
a coherent and complete view of the system based on the local s tates of individual processes. A
meaningful global snapshot can be obtained if the component s of the distributed system record
their local states at the same time. This would be possible if the local clocks at processes were
perfectly synchronized or if there were a global system cloc k that could be instantaneously read
by the processes. However, it is technologically infeasibl e to have perfectly synchronized clocks
at various sites – clocks are bound to drift. If processes rea d time from a single common clock
(maintained at one process), various indeterminate transm ission delays during the read operation
will cause the processes to identify various physical insta nts as the same time. In both cases, the
collection of local state observations will be made at diffe rent times and may not be meaningful,
as illustratedby thefollowingexample.
$0C12
C21 $0 $0$50 $50
$0$50 $0
$0$600 $550 $550
$120 $120 $170
$80$80$50$630 $630
4S2:BS1:A
$200 $200
t t1t2 0 t3t
Figure4.1: A Bankingexampleto illustraterecording ofcon sistentstates.
An Example
Let S1 and S2 be two distinct sites of a distributed system whi ch maintain bank accounts A and
B, respectively. A site refers to a process in this example. L et the communication channels from
siteS1 tositeS2andfromsiteS2 tositeS1bedenotedby C12andC21,respectively. Considerthe
followingsequenceofactions,whichare alsoillustratedi nthetimingdiagramofFigure4.1.
timet0:Initially,Account A =$600,AccountB =$200, C12=$0,C21=$0.
83
timet1:Site S1 initiates a transfer of $50 from Account A to Account B . Account A is decre-
mented by $50 to $550 and a request for $50 credit to Account B i s sent on Channel C12to
siteS2. Account A= $550,AccountB=$200, C12=$50,C21=$0.
timet2:Site S2 initiates a transfer of $80 from Account B to Account A . Account B is decre-
mented by $80 to $120 and a request for $80 credit to Account A i s sent on Channel C21to
siteS1. Account A= $550,AccountB=$120, C12=$50,C21=$80.
timet3:Site S1 receives the message for a $80 credit to Account A and u pdates Account A.
AccountA =$630,Account B=$120, C12=$50,C21= $0.
timet4:Site S2 receives the message for a $50 credit to Account B and u pdates Account B.
AccountA =$630,Account B=$170, C12=$0,C21=$0.
Suppose the local state of Account A is recorded at time t0to show $600 and the local state
of Account B and channels C12andC21are recorded at time t2to show $120, $50, and $80,
respectively. Then the recorded global state shows $850 in t he system. An extra $50 appears in
thesystem. ThereasonfortheinconsistencyisthatAccount A’sstatewasrecordedbeforethe$50
transfer to Account B using channel C12was initiated, whereas channel C12’s state was recorded
afterthe$50transfer wasinitiated.
This simple example shows that recording a consistent globa l state of a distributed system is
notatrivialtask. Recordingactivitiesofindividualcomp onentsmustbecoordinatedappropriately.
This chapter addresses the fundamental issue of recording a consistent global state in distributed
computingsystems.
Next section presents the system model and a formal deﬁnitio n of the notion of consistent
globalstate. Thesubsequentsectionspresentalgorithmst orecordsuchglobalstatesundervarious
communication models such as FIFO communication channels, non-FIFO communication chan-
nels,and causal deliveryofmessages. Thesealgorithmsare called snapshotrecording algorithms.
to showwe present
4.2 SystemModelandDeﬁnitions
4.2.1 SystemModel
The system consists of a collection of nprocesses,p1,p2, ...,pn, that are connected by chan-
nels. Thereisnogloballysharedmemoryandprocessescommu nicatesolelybypassingmessages.
There is no physicalglobal clock in thesystem. Message send and receiveis asynchronous. Mes-
sages are delivered reliably with ﬁnite but arbitrary time d elay. The system can be described as a
directed graph in which vertices represent the processes an d edges represent unidirectional com-
municationchannels. Let Cijdenotethechannelfrom process pitoprocesspj.
Processes and channels have states associated with them. Th e state of a process at any time
is deﬁned by the contents of processor registers, stacks, lo cal memory, etc. and may be highly
dependent on thelocal contextofthedistributedapplicati on. The stateofchannel Cij, denotedby
SCij, isgivenbythesetofmessagesin transitinthechannel.
84
The actions performed by a process are modeled as three types of events, namely, internal
events, message send events, and message receive events. Fo r a message mijthat is sent by pro-
cesspito processpj, letsend(mij)andrec(mij)denote its send and receive events, respectively.
Occurrence of eventschanges the states of respectiveproce sses and channels, thus causing transi-
tions in the global system state. For example, an internal ev ent changes the state of the process at
which it occurs. A send event (or a receive event) changes the state of the process that sends (or
receives)themessageand thestateofthechannel on whichth emessageissent(or received). The
eventsat aprocess are linearlyordered by theirorderofocc urrence.
At any instant, the state of process pi, denoted by LSi, is a result of the sequence of all the
events executed by pitill that instant. For an event eand a process state LSi,e∈LSiiffebelongs
tothesequenceofeventsthathavetakenprocess pitostateLSi. Foranevent eandaprocessstate
LSi,e∝\⌉}atio\slash∈LSiiffedoes notbelongtothesequenceofeventsthat havetaken proc esspitostateLSi.
A channel is a distributed entity and its state depends on the local states of the processes on
which it is incident. For a channel Cij, the following set of messages can be deﬁned based on the
local statesoftheprocesses piandpj[12].
Transit:transit (LSi,LS j) ={mij|send(mij)∈LSi/logicalandtextrec(mij)∝\⌉}atio\slash∈LSj}
Thus,ifasnapshotrecordingalgorithmrecordsthestateof processespiandpjasLSiandLSj,
respectively,thenit mustrecord thestateofchannel Cijastransit (LSi,LS j).
Thereareseveralmodelsofcommunicationamongprocessesa nddifferentsnapshotalgorithms
have assumed different models of communication. In FIFO mod el, each channel acts as a ﬁrst-
in ﬁrst-out message queue and thus, message ordering is pres erved by a channel. In non-FIFO
model,achannelactslikeasetinwhichthesenderprocessad dsmessagesandthereceiverprocess
removes messages from it in a random order. A system that supp orts causal delivery of messages
satisﬁesthefollowingproperty: “Foranytwomessages mijandmkj,ifsend(mij)−→send(mkj),
thenrec(mij)−→rec(mkj)".
Causallyordered deliveryofmessagesimpliesFIFO message delivery. Causalorderingmodel
isuseful indevelopingdistributedalgorithmsand maysimp lifythedesignofalgorithms.
4.2.2 AConsistent GlobalState
The global state of a distributed system is a collection of th e local states of the processes and the
channels. Notationally,globalstate GSisdeﬁned as,
GS={/uniontext
iLSi,/uniontext
i,jSCij}
A globalstate GSis aconsistentglobalstate iffit satisﬁesthefollowingtwoconditions[16]:
C1:send(mij)∈LSi:mij∈SCij⊕rec(mij)∈LSj. (⊕isEx-ORoperator.)
C2:send(mij)∝\⌉}atio\slash∈LSi:mij∝\⌉}atio\slash∈SCij∧rec(mij)∝\⌉}atio\slash∈LSj.
Condition C1 states the law of conservation of messages. Eve ry messagemijthat is recorded
as sent in the local state of a process pimust be captured in the state of the channel Cijor in the
collected local state of the receiver process pj. Condition C2 states that in the collected global
state, for every effect, its cause must be present. If a messa gemijis not recorded as sent in the
85
local state of process pi, then it must neither be present in the state of the channel Cijnor in the
collected localstateofthereceiverprocess pj.
In aconsistentglobalstate,everymessagethatisrecorded asreceivedisalsorecorded as sent.
Such aglobal statecaptures thenotionof causalitythat a me ssagecannot bereceived if itwas not
sent. Consistent global states are meaningful global state s and inconsistent global states are not
meaningfulinthesensethat adistributedsystemcan neverb einan inconsistentstate.
4.2.3 InterpretationinTermsof Cuts
Cutsinaspace-timediagramprovideapowerfulgraphicalai dinrepresentingandreasoningabout
global states of a computation. A cut is a line joining an arbi trary point on each process line that
slices the space-time diagram into a PAST and a FUTURE. Recal l that every cut corresponds to
a global state and every global state can be graphically repr esented by a cut in the computation’s
space-timediagram [3].
A consistent global state corresponds to a cut in which every message received in the PAST
of the cut has been sent in the PAST of that cut. Such a cut is kno wn as aconsistent cut . All
the messages that cross the cut from the PAST to the FUTURE are captured in the corresponding
channel state. For example, consider the space-time diagra m for the computation illustrated in
Figure4.2. CutC1isinconsistentbecausemessagem1isﬂowi ngfromtheFUTURE tothePAST.
Cut C2 isconsistentand messagem4mustbecaptured inthesta teofchannel C21.
Notethatinaconsistentsnapshot,alltherecordedlocalst atesofprocessesareconcurrent;that
is, recorded local stateof no process casually affects the r ecorded local state of any otherprocess.
(Notethatthenotionofcausalitycanbeextendedfromthese tofeventstothesetofrecordedlocal
states.)
mmm
345m1
m2
3
41
2
timee e e
e
e e e e
e ee
eeeC C
p
p
p
p1 1 1 1
2 2 2 2
3 3 3
4 41 2 3 4
42 3e1
31
323 4 5
1 22 1
Figure4.2: AnInterpretation inTermsofa Cut.
4.2.4 Issuesin Recording a GlobalState
Ifaglobalphysicalclockwereavailable,thefollowingsim pleprocedurecouldbeusedtorecorda
consistentglobalsnapshotofadistributedsystem: Theini tiatorofthesnapshotcollectiondecides
a future time at which the snapshot is to be taken and broadcas ts this time to every process. All
86
processes take their local snapshots at that instant in theg lobal time. The snapshot of channel Cij
includes all the messages that process pjreceives after taking the snapshot and whose timestamp
is smaller than the time of the snapshot. (All messages are ti mestamped with the sender’s clock.)
Clearly, if channels are not FIFO, a termination detection s cheme will be needed to determine
when tostopwaitingformessageson channels.
However,aglobalphysicalclockisnotavailableinadistri butedsystemand thefollowingtwo
issues need to be addressed in recording of a consistent glob al snapshot of a distributed system
[16]:
I1:How to distinguish between the messages to be recorded in the snapshot (either in a channel
state or a process state) from those not to be recorded. The an swer to this comes from
conditions C1andC2as follows:
Anymessagethatissentbyaprocessbeforerecordingitssna pshot,mustberecordedinthe
globalsnapshot(from C1).
Any message that is sent by a process after recording its snap shot, must not be recorded in
theglobalsnapshot(from C2).
I2:How to determine the instant when a process takes its snapsho t. The answer to this comes
fromcondition C2is as follows:
A processpjmust record its snapshot before processing a message mijthat was sent by
processpiafterrecording itssnapshot.
We next discuss a set of representative snapshot algorithms for distributed systems. These al-
gorithms assume different interprocess communication cap abilities about the underlying system
and illustrate how interprocess communication affects the design complexity of these algorithms.
There are two types of messages: computation messages and co ntrol messages. The former are
exchanged by the underlying application and the latter are e xchanged by the snapshot algorithm.
Execution of a snapshot algorithm is transparent to the unde rlying application, except for occa-
sionaldelayingofsomeactionsoftheapplication.
4.3 SnapshotAlgorithmsforFIFOChannels
This section presents Chandy and Lamport algorithm [6], whi ch was the ﬁrst algorithm to record
theglobalsnapshot. Wealso presentthreevariationsofthe Chandy and Lamportalgorithm.
4.3.1 Chandy-Lamport Algorithm
TheChandy-Lamportalgorithmusesacontrolmessage,calle damarker. Afterasitehasrecorded
its snapshot, it sends a marker, along all of its outgoing channels before sending out any mo re
messages. Since channels are FIFO, a marker separates the me ssages in the channel into those to
be included in the snapshot (i.e., channel state or process s tate) from those not to be recorded in
thesnapshot. Thisaddresses issue I1. Theroleofmarkers in aFIFO systemis toact as delimiters
for the messages in the channels so that the channel state rec orded by the process at the receiving
end ofthechannel satisﬁesthecondition C2.
87
Marker Sending Rule for processi
1. Processirecords itsstate.
2. Foreach outgoingchannel C onwhich amarker
has notbeen sent, isendsamarkeralongC
beforeisendsfurthermessagesalongC.
Marker Receiving Rule forprocessj
On receivingamarkeralongchannel C:
ifjhasnot recorded itsstate then
Record thestateofCas theemptyset
Followthe“MarkerSending Rule"
else
Record thestateofCas thesetofmessages
receivedalong Cafter j’sstatewas recorded
and beforejreceivedthemarkeralongC
Figure4.3: TheChandy-Lamportalgorithm.
Sinceallmessagesthatfollowamarkeronchannel Cijhavebeensentbyprocess piafterpihas
taken its snapshot, process pjmust record its snapshot no later than when it receives a mark er on
channelCij. In general, aprocess mustrecord its snapshotno laterthan when itreceives amarker
on anyofitsincomingchannels. Thisaddresses issue I2.
The Algorithm
The Chandy-Lamport snapshot recording algorithm is given i n Figure 4.3. A process initiates
snapshot collection by executing the “Marker Sending Rule" by which it records its local state
and sends a marker on each outgoing channel. A process execut es the “Marker Receiving Rule"
on receiving a marker. If the process has not yet recorded its local state, it records the state of
the channel on which themarker is received as empty and execu tes the “Marker Sending Rule" to
recorditslocalstate. Otherwise,thestateoftheincoming channelonwhichthemarkerisreceived
is recorded as the set of computation messages received on th at channel after recording the local
statebutbeforereceivingthemarkeronthatchannel. Theal gorithmcanbeinitiatedbyanyprocess
byexecutingthe“MarkerSendingRule". Thealgorithmtermi natesaftereachprocesshasreceived
amarkeron allofitsincomingchannels.
Therecordedlocalsnapshotscanbeputtogethertocreateth eglobalsnapshotinseveralways.
Onepolicyistohaveeachprocesssenditslocalsnapshottot heinitiatorofthealgorithm. Another
policy is to have each process send the information it record s along all outgoing channels, and
to have each process receiving such information for the ﬁrst time propagate it along its outgoing
channels. All the local snapshots get disseminated to all ot her processes and all the processes can
determinetheglobalstate.
Multipleprocessescan initiatethealgorithmconcurrentl y. Ifmultipleprocessesinitiatetheal-
88
gorithmconcurrently,each initiationneedstobedistingu ishedbyusinguniquemarkers. Different
initiationsbyaprocess areidentiﬁed byasequencenumber.
Correcteness
To prove the correctness of the algorithm, we show that a reco rded snapshot satisﬁes conditions
C1andC2. Since a process records its snapshot when it receives the ﬁr st marker on any incom-
ing channel, no messages that follow markers on the channels incoming to it are recorded in the
process’s snapshot. Moreover, a process stops recording th e state of an incoming channel when a
marker is received on that channel. Due to FIFO property of ch annels, it follows that no message
sent after the marker on that channel is recorded in the chann el state. Thus, condition C2is satis-
ﬁed. When a process pjreceives message mijthat precedes the marker on channel Cij, it acts as
follows: If process pjhas not taken its snapshot yet, then it includes mijin its recorded snapshot.
Otherwise,it records mijin thestateofthechannel Cij. Thus, condition C1is satisﬁed.
Complexity
The recording part of a single instance of the algorithm requ iresO(e)messages and O(d)time,
whereeis thenumberofedgesin thenetwork and disthediameterofthenetwork.
$50
$0$0C21C12 $04t3t0 2 t1
$50$630$630
$50
$80
$80$170$120$120$550$550$600
$0$0$50
$0tt
markers
(2nd example)markers
(1st example)execution
message$200$200S1:A
S2:B
Figure4.4: TimingDiagramofTwo PossibleExecutionsofthe BankingExample.
4.3.2 Properties ofthe Recorded GlobalState
The recorded global state may not correspond to any of the glo bal states that occurred during the
computation. Consider two possible executions of the snaps hot algorithm (shown in Figure 4.4)
forthemoneytransferexampleofFigure4.2.
89
1. (Markersshownusingdashed-and-dottedarrows.) Letsit eS1initiatethealgorithmjustafter
t1. Site S1 records its local state (Account A = $550) and sends a marker to site S2. The
marker is received by site S2 after t4. When site S2 receives the marker, it records its local
state (Account B = $170), the state of channel C12as $0, and sends a marker along channel
C21. WhensiteS1receivesthismarker,itrecordsthestateofCh annelC21as$80. The$800
amountinthesystemis conservedintherecorded globalstat e,
A= $550,B= $170,C12= $0,C21= $80
2. (Markers shown using dotted arrows.) Let site S1 initiate the algorithm just after t0and
before sending the $50 for S2. Site S1 records its local state (Account A = $600) and sends
a marker to site S2. The marker is received by site S2 between t2andt3. When site S2
receivesthemarker,itrecords itslocal state(AccountB=$ 120),thestateofchannel C12as
$0, and sends a marker along channel C21. When siteS1 receives this marker, it records the
state of Channel C21as $80. The $800 amount in the system is conserved in the recor ded
globalstate,
A= $600,B= $120,C12= $0,C21= $80
In both these possible runs of the algorithm, the recorded gl obal states never occurred in the exe-
cution. This happens because a process can change its state a synchronously before the markers it
sentare receivedby othersites andtheothersitesrecord th eirstates.
Nevertheless, as we discuss next, the system could have pass ed through the recorded global
states in some equivalent executions. Suppose the algorith m is initiated in global state Siand it
terminates in global state St. Letseqbe the sequence of events which takes the system from Si
toSt. LetS∗be the global state recorded by the algorithm. Chandy and Lam port [6] showed that
there exists a sequence seq′which is a permutation of seqsuch thatS∗is reachable from Siby
executingapreﬁx of seq′andStisreachable from S∗byexecutingtherest oftheeventsof seq′.
A briefskecthoftheproofisas follows: Anevent eisdeﬁned asaprerecording/postrecording
event ifeoccurs on a process pandprecords its state after/before einseq. A postrecording
event may occur after a prerecording event only if the two eve nts occur on different processes. It
is shown that a postrecording event can be swapped with an imm ediately following prerecording
eventinasequencewithoutaffectingthelocalstatesofeit herofthetwoprocessesonwhichthetwo
events occur. By iteratively applying this operation to seq, the above-described permutation seq′
is obtained. It is then shown that S∗, the global state recorded by the algorithm for the processe s
and channels, is the state after all the prerecording events have been executed, but before any
postrecordingevent.
Thus, the recorded global state is a valid state in an equival ent execution and if a stable prop-
erty (i.e., a property that persists such as termination or d eadlock) holds in the system before the
snapshot algorithm begins, it holds in the recorded global s napshot. Therefore, a recorded global
stateisusefulin detectingstableproperties.
Aphysicalinterpretationofthecollectedglobalstateisa sfollows: Considerthetwoinstantsof
recordingofthelocalstatesinthebankingexample. Ifthec utformedbytheseinstantsisviewedas
beinganelasticbandandiftheelasticbandisstretchedsot hatitisvertical,thenrecordedstatesof
all processes occur simultaneouslyat one physical instant , and the recorded global state occurs in
the execution that is depicted in this modiﬁed space-time di agram. This is called the rubber-band
90
criterion. Forexample,considerthetwodifferentexecuti onsofthesnapshotalgorithm,depictedin
Figure4.4. Fortheexecutionforwhichthemarkersareshown usingdashed-and-dottedarrows,the
instants of the local state recordings are marked by squares . Applying the rubber-band criterion,
these can be stretched to be vertical or instantaneous. Simi larly for the other execution for which
the markers are shown using dotted arrows and the instants of local state rcordings are marked
by circles. Note that the system execution would have been li ke this, had the processors’ speeds
and message delays been different. Yet another physical int erpretation of the collected global
state is as follows: All the recorded process states are mutu ally concurrent – no recorded process
statecausally dependsupon another. Therefore, logically we can view that all theseprocess states
occurred simultaneously even though they might have occurr ed at different instants in physical
time.
4.4 VariationsoftheChandy-LamportAlgorithm
Several variants of the Chandy-Lamport snapshot algorithm followed. These variants reﬁned and
optimizedthebasicalgorithm. Forexample,Spezialettian d Kearnsalgorithm[29]optimizescon-
current initiationofsnapshotcollectionandefﬁcientlyd istributestherecorded snapshot. Venkate-
san’salgorithm[32]optimizesthebasicsnapshotalgorith mtoefﬁcientlyrecordrepeatedsnapshots
ofadistributedsystemthatare required inrecoveryalgori thmswith synchronouscheckpointing.
4.4.1 Spezialetti-Kearns Algorithm
Therearetwophasesinobtainingaglobalsnapshot: locally recordingthesnapshotateveryprocess
and distributing the resultant global snapshot to all the in itiators. Spezialetti and Kearns [29]
provided two optimizations to the Chandy-Lamport algorith m. The ﬁrst optimization combines
snapshots concurrently initiated by multiple processes in to a single snapshot. This optimization
is linked with the second optimization which deals with the e fﬁcient distribution of the global
snapshot. A process needs to take only one snapshot, irrespe ctive of the number of concurrent
initiators and all processes are not sent the global snapsho t. This algorithm assumes bidirectional
channelsin thesystem.
Efﬁcient Snapshot Recording
IntheSpezialetti-Kearnsalgorithm,amarkerscarriesthe identiﬁeroftheinitiatorofthealgorithm.
Each process has a variable masterto keep track of the initiatorof the algorithm. When a proces s
executesthe“MarkerSendingRule"onthereceiptofitsﬁrst marker,itrecordstheinitiator’siden-
tiﬁer carried in the received marker in the mastervariable. A process that initiates the algorithm
records itsownidentiﬁerinthe mastervariable.
Akeynotionusedbytheoptimizationsisthatofa regioninthesystem. Aregionencompasses
all the processes whose masterﬁeld contains the identiﬁer of the same initiator. A region i s iden-
tiﬁed by the initiator’s identiﬁer. When there are multiple concurrent initiators, the system gets
partitionedintomultipleregions.
When the initiator’s identiﬁer in a marker received along a c hannel is different from the value
in themastervariable, a concurrent initiation of the algorithm is detec ted and the sender of the
91
marker lies in a different region. The identiﬁer of the concu rrent initiator is recorded in a local
variableid-border-set. The process receiving the marker does not take a snapshotfo r this marker
and does not propagate this marker. Thus, the algorithm efﬁc iently handles concurrent snapshot
initiations by suppressing redundant snapshot collection s – a process does not take a snapshot or
propagateasnapshotrequestinitiatedbyaprocessifithas alreadytakenasnapshotinresponseto
someothersnapshotinitiation.
The state of the channel is recorded just as in the Chandy-Lam port algorithm (including those
that cross a border between regions). This enables the snaps hot recorded in one region to be
mergedwiththesnapshotrecordedintheadjacentregion. Th us,eventhoughmarkersarrivingata
node contain identiﬁers of different initiators, they are c onsidered part of the sameinstance of the
algorithmforthepurposeofchannel staterecording.
Snapshot recording at a process is complete after it has rece ived a marker along each of its
channels. Afterevery process has recorded itssnapshot,th esystemis partitionedintoas manyre-
gionsas thenumberofconcurrent initiationsofthealgorit hm. Variable id-border-setataprocess
containstheidentiﬁersoftheneighboringregions.
Efﬁcient Disseminationof the Recorded Snapshot
The Spezialetti-Kearns algorithm efﬁciently assembles th e snapshot as follows: In the snapshot
recording phase, a forest of spanning trees is implicitly cr eated in the system. The initiator of the
algorithmistherootofaspanningtreeandallprocessesini tsregionbelongtoitsspanningtree. If
processpiexecutedthe“MarkerSendingRule"becauseitreceiveditsﬁ rstmarkerfromprocess pj,
thenprocess pjistheparentofprocess piinthespanningtree. Whenaleafprocessinthespanning
tree has recorded the states of all incoming channels, the pr ocess sends the locally recorded state
(local snapshot, id-border-set) to its parent in the spanning tree. After an intermediatepr ocess in
a spanning tree has received the recorded states from all its child processes and has recorded the
statesofallincomingchannels,itforwardsitslocallyrec ordedstateandthelocallyrecordedstates
ofallitsdescendent processes toitsparent.
When the initiator receives the locally recorded states of a ll its descendents from its children
processes,itassemblesthesnapshotforalltheprocessesi nitsregionandthechannelsincidenton
theseprocesses. Theinitiatorknowstheidentiﬁersofinit iatorsinadjacentregionsusing id-border-
setinformation it receives from processes in its region. The in itiator exchanges the snapshot of
its region with the initiators in adjacent regions in rounds . In each round, an initiator sends to
initiatorsinadjacentregions,anynewinformationobtain edfromtheinitiatorintheadjacentregion
during the previous round of message exchange. A round is com plete when an initiator receives
information, or the blankmessage (signifying no new information will be forthcoming ) from all
initiatorsofadjacent regionsfromwhich ithas notalready receiveda blankmessage.
Themessagecomplexityofsnapshotrecordingis O(e)irrespectiveofthenumberofconcurrent
initiationsofthealgorithm. Themessagecomplexityofass emblinganddisseminatingthesnapshot
isO(rn2)whereristhenumberofconcurrent initiations.
4.4.2 Venkatesan’sIncrementalSnapshot Algorithm
Many applicationsrequirerepeated collectionof globalsn apshotsof thesystem. For example,re-
coveryalgorithmswithsynchronouscheckpointingneedtoa dvancetheircheckpointsperiodically.
92
This can be achieved by repeated invocationsof the Chandy-L amport algorithm. Venkatesan [32]
proposedthefollowingefﬁcientapproach: Executeanalgor ithmtorecordanincrementalsnapshot
sincethemostrecentsnapshotwastakenandcombineitwitht hemostrecentsnapshottoobtainthe
latestsnapshotofthesystem. Theincrementalsnapshotalg orithmofVenkatesan[32]modiﬁesthe
global snapshot algorithm of Chandy-Lamport to save on mess ages when computation messages
aresentonlyonafewofthenetworkchannels,betweentherec ordingoftwosuccessivesnapshots.
The incremental snapshot algorithm assumes bidirectional FIFO channels, the presence of a
singleinitiator,aﬁxedspanningtreeinthenetwork,andfo urtypesofcontrolmessages: init_snap,
snap_completed ,regular,andack.init_snap andsnap_completed messagestraversespanningtree
edges.regularandackmessages which serve to record the state of non-spanning edg es are not
senton thoseedges onwhich nocomputationmessagehas been s entsincetheprevioussnapshot.
Venkatesan [32] showed that the lower bound on the message co mplexity of an incremental
snapshot algorithmis Ω(u+n)whereuis the number of edges on which a computationmessage
has been sent since the previous snapshot. Venkatesan’s alg orithm achieves this lower bound in
messagecomplexity.
The algorithm works as follows: Snapshots are assigned vers ion numbers and all algorithm
messages carry this version number. The initiator notiﬁes a ll the processes the version number
of the new snapshot by sending init_snap messages along the spanning tree edges. A process
followsthe “Marker Sending Rule" when it receives thisnoti ﬁcation or when it receives a regular
message with a new version number. The “Marker Sending Rule" is modiﬁed so that the process
sendsregularmessages along only those channels on which it has sent compu tation messages
since the previous snapshot, and the process waits for ackmessages in response to these regular
messages. When a leaf process in the spanning tree receives a ll theackmessages it expects, it
sends asnap_completed message to its parent process. When a non-leaf process in the spanning
treereceivesallthe ackmessagesitexpects,aswellasa snap_completed messagefromeachofits
childprocesses, itsendsa snap_completed messageto itsparent process.
The algorithm terminates when the initiator has received al l theackmessages it expects, as
wellasasnap_completed messagefromeachofitschildprocesses. Theselectivemann erinwhich
regularmessages are sent has the effect that a process does not know w hether to expect a regular
message on an incoming channel. A process can be sure that no s uch message will be received
and that the snapshot is complete only when it executes the “M arker Sending Rule" for the next
initiationofthealgorithm.
4.4.3 Helary’sWave Synchronization Method
Helary’ssnapshotalgorithm[12]incorporatestheconcept ofmessagewavesintheChandy-Lamport
algorithm. A wave is a ﬂow of control messages such that every process in the system is visited
exactlyoncebyawavecontrolmessage,andatleastoneproce ssinthesystemcandeterminewhen
this ﬂow of control messages terminates. A wave is initiated after the previous wave terminates.
Wave sequences may be implemented by various traversal stru ctures such as a ring. A process
beginsrecordingthelocalsnapshotwhen itisvisitedby the wavecontrolmessage.
InHelary’salgorithm,the“MarkerSendingRule"isexecute dwhenacontrolmessagebelong-
ing to the wave ﬂow visitsthe process. The process then forwa rds a control messageto other pro-
cesses,dependingonthewavetraversalstructure,toconti nuethewave’sprogression. The“Marker
Receiving Rule" is modiﬁed so that if the process has not reco rded its state when a marker is re-
93
ceived on some channel, the “Marker Receiving Rule" is not ex ecuted and no messages received
afterthemarkeronthischannelareprocesseduntilthecont rolmessagebelongingtothewaveﬂow
visits the process. Thus, each process follows the “Marker R eceiving Rule" only after it is visited
by acontrolmessagebelongingtothewave.
Note that in this algorithm, the primary function of wave syn chronization is to evaluate func-
tions over the recorded global snapshot. This algorithm has a message complexity of O(e)to
record asnapshot(becauseall channels need tobetraversed to implementthewave).
An example of this function is the number of messages in trans it to each process in a global
snapshot, and whether the global snapshot is strongly consi stent. For this function, each process
maintainstwovectors, SENTandRECD. Theithelementsofthesevectorsindicatethenumber
of messages sent to/received from process i, respectively, since the previous visit of a wave con-
trol message. The wave control messages carry a global abstr act counter vector whose ithentry
indicates the number of messages in transit to process i. These entries in the vector are updated
usingtheSENTandRECDvectorsateachnodevisited. Whenthecontrolwaveterminat es,the
numberofmessagesin transittoeach processas recorded int hesnapshotis known.
4.5 SnapshotAlgorithmsforNon-FIFOChannels
AFIFOsystemensuresthatallmessagessentafteramarkeron achannelwillbedeliveredafterthe
marker. This ensures that condition C2is satisﬁed in therecorded snapshotif LSi,LSj, andSCij
arerecordedasdescribedintheChandy-Lamportalgorithm. Inanon-FIFOsystem,theproblemof
global snapshot recording is complicated because a marker c annot be used to delineate messages
into those to be recorded in the global state from those not to be recorded in the global state. In
such systems, different techniques have to be used to ensure that a recorded global state satisﬁes
condition C2.
Inanon-FIFOsystem,eithersomedegreeofinhibition(i.e. ,temporarilydelayingtheexecution
of an application process or delaying the send of a computati on message) or piggybacking of
control information on computation messages to capture out -of-sequence messages, is necessary
to record a consistent global snapshot [31]. The non-FIFO al gorithm by Helary uses message
inhibition [12]. The non-FIFO algorithms by Lai and Yang [18 ], Li et al. [20], and Mattern [23]
use message piggybacking to distinguish computation messa ges sent after the marker from those
sentbefore themarker.
The non-FIFO algorithm of Helary [12] uses message inhibiti on to avoid an inconsistency in
a global snapshot in the following way: When a process receiv es a marker, it immediatelyreturns
an acknowledgement. After a process pihas sent a marker on the outgoing channel to process pj,
it does not send any messages on this channel until it is sure t hatpjhas recorded its local state.
Processpican conclude this if it has received an acknowledgementfor t he marker sent to pj, or it
has receivedamarkerforthissnapshotfrom pj.
We next discuss snapshot recording algorithms for systems w ith non-FIFO channels that use
piggybackingofcomputationmessages.
94
4.5.1 Lai-YangAlgorithm
LaiandYang’sglobalsnapshotalgorithmfornon-FIFOsyste ms[18]isbasedontwoobservations
on the role of a marker in a FIFO system. The ﬁrst observation i s that a marker ensures that
condition C2is satisﬁed for LSiandLSjwhen the snapshots are recorded at processes iandj,
respectively. The Lai-Yang algorithm fulﬁlls this role of a marker in a non-FIFO system by using
acoloringschemeoncomputationmessages thatworksas foll ows:
1. Every process is initiallywhiteand turns red whiletakin g a snapshot. The equivalentof the
“MarkerSending Rule"is executedwhena processturnsred.
2. Every message sent by a white (red) process is colored whit e (red). Thus, a white (red)
message is a message that was sent before (after) the sender o f that message recorded its
localsnapshot.
3. Every white process takes its snapshot at its convenience , but no later than the instant it
receivesared message.
Thus,whenawhiteprocessreceivesaredmessage,itrecords itslocalsnapshotbeforeprocess-
ing the message. This ensures that no messagesent by a proces s after recording its local snapshot
is processed by the destination process before the destinat ion records its local snapshot. Thus,
an explicit marker message is not required in this algorithm and the ‘marker’ is piggybacked on
computationmessagesusingacoloringscheme.
Thesecond observationisthat themarkerinformsprocess jofthevalueof{send(mij)|
send(mij)∈LSi}sothatthestateofthechannel Cijcanbecomputedas transit (LSi,LS j). The
Lai-Yang algorithmfulﬁllsthisroleofthemarkerin thefol lowingway:
4. Everywhiteprocessrecordsahistoryofallwhitemessage ssentorreceivedbyitalongeach
channel.
5. When a process turns red, it sends these histories along wi th its snapshot to the initiator
process thatcollectstheglobalsnapshot.
6. The initiator process evaluates transit (LSi,LS j)to compute the state of a channel Cijas
givenbelow:
SCij=whitemessagessentby pionCij−whitemessagesreceivedby pjonCij={send(mij)|send(mij)∈
LSi}−{rec(mij)|rec(mij)∈LSj}.
Condition C2holds because a red message is not included in the snapshot of the recipient
process and a channel state is the difference of two sets of wh ite messages. Condition C1holds
because a white message mijis included in the snapshot of process pjifpjreceivesmijbefore
takingitssnapshot. Otherwise, mijisincludedinthestateofchannel Cij.
Though marker messages are not required in the algorithm, ea ch process has to record the
entiremessagehistoryoneachchannelas partofthelocalsn apshot. Thus,thespacerequirements
of the algorithm may be large. However, in applications (suc h as termination detection) where
the number of messages in transit in a channel is sufﬁcient, m essage histories can be replaced by
integer counters reducing the space requirement. Lai and Ya ng describe how the size of the local
95
storage and snapshot recording can be reduced by storing onl y the messages sent and received
since the previous snapshot recording, assuming that the pr evious snapshot is still available. This
approachcanbeveryusefulinapplicationsthatrequirerep eatedsnapshotsofadistributedsystem.
4.5.2 Lietal.’sAlgorithm
Li et al.’s algorithm [20] for recording a global snapshot in a non-FIFO system is similar to the
Lai-Yang algorithm. Markers are tagged so as to generalize t he red/white colors of the Lai-Yang
algorithm to accommodate repeated invocations of the algor ithm and multiple initiators. In addi-
tion, the algorithm is not concerned with the contents of com putation messages and the state of
a channel is computed as the number of messages in transit in t he channel. A process maintains
two counters for each incident channel to record the number o f messages sent and received on
the channel and reports these counter values with its snapsh ot to the initiator. This simpliﬁcation
is combined with the incremental technique to compute chann el states, which reduces the size of
message histories to be stored and transmitted. The initiat or computes the state of Cijas: (the
numberof messages in Cijin the previoussnapshot)+ (the numberof messages sent on Cijsince
thelast snapshotat process pi)−(the numberof messages received on Cijsince thelast snapshot
at processpj).
Snapshotsinitiatedbyaninitiatorareassignedasequence number. Allmessagessentafteralo-
calsnapshotrecordingaretaggedbyatuple <init_id,MKNO> ,whereinit_idistheinitiator’s
identiﬁerand MKNO isthesequencenumberofthealgorithm’smostrecentinvoca tionbyinitia-
torinit_id; to insure liveness, markers with tags similar to the above t ags are explicitly sent only
onalloutgoingchannelsonwhichnomessagesmightbesent. T hetuple<init_id,MKNO> is
a generalizationof thered/whitecolors used in Lai-Yang to accommodaterepeated invocationsof
thealgorithmand multipleinitiators.
For simplicity,we explain this algorithmusing the framewo rk of the Lai-Yang algorithm. The
local staterecording isdoneas describedby Rules 1-3ofthe Lai-Yang algorithm.
A process maintains Input/Output counters for the number of messages sent and received on
eachincidentchannelafterthelastsnapshot(bythatiniti ator). Thealgorithmisnotconcernedwith
thecontentsofcomputationmessagesandsothecomputation ofthestateofachannelissimpliﬁed
to computing the number of messages in transit in the channel . This simpliﬁcation is combined
withanincrementaltechniqueforcomputingin-transitmes sages,alsosuggestedindependentlyby
Lai and Yang [18], for reducing the size of the entire message history to be locally stored and to
berecorded inalocalsnapshottocomputechannelstates. Th einitiatorofthealgorithmmaintains
a variableTRANSIT ijfor the number of messages in transit in the channel from proc esspito
processpj, as recorded in the previous snapshot. The channel states ar e recorded as described in
Rules 4-6 oftheLai-Yang algorithm.
4. Every white process records a history, as Input and Output counters, of all white messages
sentorreceived byitalong each channel afterthepreviouss napshot(by thesameinitiator).
5. Whenaprocessturnsred,itsendsthesehistories(i.e.,I nputandOutputcounters)alongwith
itssnapshottotheinitiatorprocess thatcollectstheglob alsnapshot.
6. Theinitiatorprocess computesthestateofchannel Cijas follows:
SCij=transit (LSi,LS j)=TRANSIT ij+ (# messages sent on that channel since the last
96
snapshot)−(# messagesreceivedon thatchannel sincethelast snapshot ).
Iftheinitiatorinitiatesasnapshotbeforethecompletion oftheprevioussnapshot,itispossible
that some process may get a message with a lower sequence numb er after participating in a snap-
shot initiated later. In this case, the algorithm uses the sn apshot with the higher sequence number
toalso create thesnapshotforthelowersequencenumber.
The algorithm works for multiple initiators if separate Inp ut/Output counters are associated
with each initiator,and marker messages and the tag ﬁelds ca rry a vectorof tuples,with one tuple
foreach initiator.
Though this algorithm does not require any additional messa ge to record a global snapshot
provided computation messages are eventually sent on each c hannel, the local storage and size
of tags on computation messages are of size O(n), wherenis the number of initiators. The
Spezialetti and Kearns technique [29] of combining concurr ently initiated snapshots can be used
withthisalgorithm.
4.5.3 Mattern’sAlgorithm
Mattern’s algorithm [23] is based on vector clocks. Recall t hat in vector clocks, the clock at a
process inan integervectoroflength n, withonecomponentforeach process.
Mattern’salgorithmassumesa singleinitiatorprocess and works as follows:
1. Theinitiator“ticks"itslocalclockandselectsafuture vectortimesatwhichitwouldlikea
global snapshot to be recorded. It then broadcasts this time sand freezes all activity until it
receivesall acknowledgementsofthereceipt ofthisbroadc ast.
2. When a process receives the broadcast, it remembers the va luesand returns an acknowl-
edgementto theinitiator.
3. After having received an acknowledgement from every proc ess, the initiator increases its
vector clock to sand broadcasts a dummy message to all processes. (Observe th at before
broadcastingthisdummymessage,thelocal clocksofotherp rocesseshaveavalue ∝\⌉}atio\slash≥s.)
4. Thereceiptofthisdummymessageforceseach recipientto increaseitsclocktoavalue ≥s
ifnotalready≥s.
5. Each process takes a local snapshot and sends it to the init iator when (just before) its clock
increases from a value less than sto a value≥s. Observe that this may happen before the
dummymessagearrivesat theprocess.
6. Thestateof Cijisallmessagessentalong Cij,whosetimestampissmallerthan sandwhich
arereceived by pjafterrecording LSj.
Processes record theirlocal snapshotas perrule(5). Anyme ssagemijsent byprocess piafter
it records itslocal snapshot LSihas atimestamp >s. Assumethat this mijis receivedby process
pjbeforeitrecords LSj. Afterreceivingthis mijandbeforepjrecordsLSj,pj’slocalclockreadsa
value>s,asperrulesforupdatingvectorclocks. Thisimplies pjmusthavealreadyrecorded LSj
as per rule (5), which contradicts the assumption. Therefor e,mijcannot be received by pjbefore
97
it recordsLSj. By rule (6), mijis not recorded in SCijand therefore, condition C2is satisﬁed.
Condition C1holds because each message mijwith a timestamp less than sis included in the
snapshot of process pjifpjreceivesmijbefore taking its snapshot. Otherwise, mijis included in
thestateofchannel Cij.
The following observations about the above algorithm lead t o various optimizations: (i) The
initiatorcan bemadea“virtual"process;so,no processhas tofreeze. (ii)As longasanewhigher
value ofsis selected, the phase of broadcasting sand returning the acks can be eliminated. (iii)
Only the initiator’s component of sis used to determine when to record a snapshot. Also, one
needstoknowonlyiftheinitiator’scomponentofthevector timestampinamessagehasincreased
beyond the value of the corresponding component in s. Therefore, it sufﬁces to have just two
valuesofs, say,whiteand red, whichcan berepresented usingonebit.
With these optimizations, the algorithm becomes similarto the Lai-Yang algorithm except for
the manner in which transit (LSi,LS j)is evaluated for channel Cij. In Mattern’s algorithm, a
process is not required to store message histories to evalua te the channel states. The state of any
channelisthesetofallthewhitemessagesthatarereceived byaredprocessonwhichthatchannel
is incident. A termination detection scheme for non-FIFO ch annels is required to detect that no
whitemessagesareintransittoensurethattherecordingof allthechannelstatesiscomplete. One
ofthefollowingschemes can beusedfor terminationdetecti on:
1. Each process ikeeps a counter cntr ithat indicates the difference between the number of
white messages it has sent and received before recording its snapshot. It reports this value
to the initiator process along with its snapshot and forward s all white messages, it receives
henceforth, to the initiator. Snapshot collection termina tes when the initiator has received/summationtext
icntr inumberofforwarded whitemessages.
2. Each red message sent by a process carries a piggybacked va lue of the number of white
messagessentonthatchannelbeforethelocalstaterecordi ng. Eachprocesskeepsacounter
forthenumberofwhitemessagesreceivedoneachchannel. Ap rocesscandetecttermination
of recording the states of incoming channels when it receive s as many white messages on
each channel as thevaluepiggybackedonred messages receiv edon thatchannel.
The savings of not storing and transmitting entire message h istories, over the Lai-Yang algo-
rithm, comes at the expense of delay in the termination of the snapshot recording algorithm and
need foraterminationdetection scheme(e.g., amessagecou nterper channel).
4.6 Snapshotsina CausalDeliverySystem
Twoglobalsnapshotrecordingalgorithms,namely,Acharya -Badrinath[1]andAlagar-Venkatesan
[2] assume that the underlying system supports causal messa ge delivery. The causal message
delivery property COprovides a built-in message synchronization to control and computation
messages. Consequently, snapshot algorithms for such syst ems are considerably simpliﬁed. For
example, these algorithms do not send control messages (i.e ., markers) on every channel and are
simplerthanthesnapshotalgorithmsforaFIFO system.
Several protocolsexistforimplementingcausal ordering[ 5, 6, 26, 28].
98
4.6.1 ProcessState Recording
Both these algorithms use an identical principle to record t he state of processes. An initiator
processbroadcastsatoken,denotedas token,toeveryprocessincludingitself. Letthecopyofthe
token received by process pibe denotedtoken i. A process pirecords its local snapshot LSiwhen
it receivestoken iand sends therecorded snapshotto theinitiator. Thealgori thmterminateswhen
theinitiatorreceivesthesnapshotrecorded by each proces s.
These algorithms do not require each process to send markers on each channel, and the pro-
cessesdonotcoordinatetheirlocalsnapshotrecordingswi thotherprocesses. Nonetheless,forany
twoprocesses piandpj, thefollowingproperty(called Property P1)issatisﬁed:
send(mij)∝\⌉}atio\slash∈LSi:rec(mij)∝\⌉}atio\slash∈LSj.
This is due to the causal ordering property of the underlying system as explained next. Let a
messagemijbesuchthat rec(token i)−→send(mij). Thensend(token j)−→send(mij)andthe
underlying causal ordering property ensures that rec(token j), at which instant process pjrecords
LSj, happens before rec(mij). Thus,mijwhose send is not recorded in LSi, is not recorded as
receivedinLSj.
Methodsofchannelstaterecordingaredifferentinthesetw oalgorithmsandarediscussednext.
4.6.2 Channel State Recording in Acharya-Badrinath Algori thm
Each process pimaintainsarrays SENT i[1,...N]andRECD i[1,...,N ].SENT i[j]is thenumber
of messages sent by process pito processpjandRECD i[j]is the number of messages received
by processpifrom process pj. The arrays may not contribute to the storage complexity of t he
algorithm because the underlying causal ordering protocol may require these arrays to enforce
causal ordering.
Channel states are recorded as follows: When a process pirecords its local snapshot LSion
the receipt of token i, it includes arrays RECD iandSENT iin its local state before sending
the snapshot to the initiator. When the algorithm terminate s, the initiator determines the state of
channelsin theglobalsnapshotbeingassembledas follows:
1. Thestateofeach channelfrom theinitiatortoeach proces sis empty.
2. The state of channel from process pito processpjis the set of messages whose sequence
numbersaregivenby {RECD j[i] + 1,...,SENT i[j]}.
We nowshowthat thealgorithmsatisﬁesconditions C1andC2.
Let a message mijbe such that rec(token i)−→send(mij). Clearly,send(token j)−→
send(mij)and the sequence number of mijis greater than SENT i[j]. Therefore, mijis not
recordedinSCij. Thus,send( mij)∝\⌉}atio\slash∈LSi:mij∝\⌉}atio\slash∈SCij. ThisinconjunctionwithProperty P1implies
thatthealgorithmsatisﬁes condition C2.
Consideramessage mijwhichisthe kthmessagefromprocess pitoprocesspjbeforepitakes
itssnapshot. Thetwo possibilitiesbelowimplythatcondit ionC1is satisﬁed.
•Processpjreceivesmijbefore taking its snapshot. In this case, mijis recorded in pj’s
snapshot.
99
•Otherwise,RECD j[i]≤k≤SENT i[j] and the message mijwill be included in the state
ofchannelCij.
This algorithm requires 2nmessages and 2time units for recording and assembling the snap-
shot, where one timeunit is required for the deliveryof a mes sage. If the contents of messages in
channelsstateare required,thealgorithmrequires 2 nmessagesand 2 timeunitsadditionally.
4.6.3 Channel State Recording in Alagar-VenkatesanAlgori thm
A messageis referred to as oldif thesend of themessagecausally precedes thesend ofthe to ken.
Otherwise, themessageis referred to as new. Whetheramessageis newor oldcan bedetermined
by examining the vector timestamp in the message, which is ne eded to enforce causal ordering
amongmessages.
In Alagar-Venkatesan algorithm[2], channel statesarerec orded as follows:
1. When a process receives the token, it takes its snapshot, initializes the state of all channel s
to empty, and returns Donemessage to the initiator. Now onwards, a process includes a
messagereceived onachannel inthechannel stateonlyifit i san oldmessage.
2. Aftertheinitiatorhasreceived Donemessagefromallprocesses,itbroadcastsa Terminate
message.
3. A processstopsthesnapshotalgorithmafterreceivinga Terminate message.
An interestingobservationisthata processreceivesall th eoldmessagesinitsincomingchan-
nels beforeit receivesthe Terminate message. Thisis ensured by theunderlyingcausal message
deliveryproperty.
Causal ordering property ensures that no new message is deli vered to a process prior to the
tokenandonlyoldmessagesarerecordedinthechannelstates. Thu s,send(mij)∝\⌉}atio\slash∈LSi:mij∝\⌉}atio\slash∈SCij.
This together with Property P1implies that condition C2is satisﬁed. Condition C1is satis-
ﬁed because each old message mijis delivered either before the token is delivered or before t he
Terminate isdeliveredtoa processand thusgetsrecorded in LSiorSCij,respectively.
A comparison of the salient features of the various snapshot recording algorithms discused is
givenin Table4.1.
4.7 MonitoringGlobalState
Several applications such as debugging a distributed progr am need to detect a system state which
is determined by the values of variables on a subset of proces ses. This state can be expressed
as a predicate on variables distributed across the involved processes. Rather than recording and
evaluating snapshots at regular intervals, it is more efﬁci ent to monitor changes to the variables
thataffect thepredicateand evaluatethepredicate onlywh ensomecomponentvariablechanges.
Spezialetti andKearns [30]proposedatechnique, called simultaneousregions ,fortheconsis-
tentmonitoringofdistributedsystemstodetectglobalpre dicates. Aprocesswhoselocalvariableis
acomponentoftheglobalpredicateinformsamonitorwhenev erthevalueofthevariablechanges.
100
Algorithms Features
Chandy- Baselinealgorithm. Requires FIFO channels. O(e)messages
Lamport[6] torecord snapshotand O(d)time.
Spezialetti- Improvementsover[6]: supportsconcurrent initiators,ef ﬁcient assembly
Kearns[29] and distributionofasnapshot. Assumesbidirectionalchan nels.
O(e)messagesto record, O(rn2)messages toassembleand
distributesnapshot.
Venkatesan[32] Based on [6]. Selectivesendingofmarkers.
Providesmessage-optimalincrementalsnapshots.
Ω(n+u)messagesto record snapshot.
Helary [12] Based on [6]. Useswavesynchronization.
Evaluatesfunctionoverrecorded globalstate.
Adaptableto non-FIFO systemsbutrequires inhibition.
Lai-Yang [18] Works fornon-FIFO channels. Markers piggybacked
on computationmessages. Messagehistoryrequired
tocomputechannel states.
Liet al. [20] Similarto [18]. Small messagehistory
needed as channel statesarecomputedincrementally.
Mattern[23] Similarto [18]. No messagehistoryrequired.
Terminationdetection (e.g.,a messagecounterperchannel )
required tocomputechannel states.
Acharya- Requires causal deliverysupport,Centralized computatio nofchannel
Badrinath [1] states,Channel messagecontentsneed not beknown.
Requires 2n messages,2timeunits.
Alagar-Venkatesan[2] Requires causal deliverysupport,Distributedcomputatio nofchannel
states. Requires 3 nmessages,3 timeunits,smallmessages.
Table4.1: A comparisonofsnapshotalgorithms.
n=# processes,u=#edgesonwhichmessagesweresentafterpr evioussnapshot,e=# channels,
disthediameterofthenetwork,r=# concurrent initiators.
101
This process also coerces other processes to inform the moni tor of the values of their variables
that are components of the global predicate. The monitor eva luates the global predicate when it
receives the next message from each of the involved processe s, informing it of the value(s) of
their local variable(s). The periods of local computation o n each process between the ithand the
i+ 1steventsat whichthevaluesofthelocalcomponent(s)ofthegl obalpredicateare reportedto
the monitor are deﬁned to be the i+ 1stsimultaneous regions. The above scheme is extended to
arrange multiplemonitorshierarchicallyto evaluatecomp lexglobalpredicates.
4.8 Necessary and Sufﬁcient Conditions for Consistent Glob al
Snapshots
Many applications (such as transparent failure recovery, d istributed debugging, monitoring dis-
tributedevents,settingdistributedbreakpoints,protoc olspeciﬁcationandveriﬁcation,etc.) require
thatlocalprocessstatesareperiodicallyrecordedandana lyzedduringexecutionorpostmartem. A
savedintermediatestateofaprocessduringitsexecutioni scalleda localcheckpoint oftheprocess.
Aglobalsnapshotofadistributedsystemisasetoflocalche ckpointsonefromeachprocessandit
represents a snapshotof the distributedcomputationexecu tion at some instant. A global snapshot
isconsistent,ifthereisnocausalpathbetweenanytwodist inctcheckpointsintheglobalsnapshot.
Therefore,aconsistentsnapshotconsistsofasetoflocals tatesthatoccurredconcurrentlyorhada
potentialto occur simultaneously. This conditionfor the c onsistencyof a globalsnapshot (that no
causalpathbetweenanytwocheckpoints)isonlythenecessa ryconditionbutitisnotthesufﬁcient
condition. In this section, we present the necessary and suf ﬁcient conditions under which a local
checkpointoraset ofarbitrary collectionoflocalcheckpo intscan begroupedwithcheckpointsat
otherprocessesto formaconsistentglobalsnapshot.
Processes take checkpoints asynchronously. Each checkpoi nt taken by a process is assigned a
uniquesequencenumber. The ith(i≥0)checkpointofprocess ppisassignedthesequencenumber
iand isdenotedby Cp,i. We assumethateach process takesan initialcheckpointbef ore execution
begins and takes a virtualcheckpoint after execution ends. The ithcheckpoint interval of process
ppconsistsofallthecomputationperformedbetweenits (i−1)thandithcheckpoints(andincludes
the(i−1)thcheckpointbutnot ith).
p1
p2
p3C2,0C2,1C1,1
C3,1C3,0C2,2
C3,2C1,2C1,0
C2,3
C3,3
        A checkpoint   Legend:4m m
m m1
23m5
m6
Figure4.5: AnIllustrationofzigzag paths.
We ﬁrst show with the help of an example that even if two local c heckpoints do not have a
causal path between them (i.e., neither happened before the other using Lamport’s happen before
102
relation), they may not belong to the same consistent global snapshot. Consider the execution
shown in Figure 4.5. Although neither of the checkpoints C1,1andC3,2happened before the
other,theycannotbegroupedtogetherwithacheckpointonp rocessp2toformaconsistentglobal
snapshot. No checkpoint on p2can be grouped with both C1,1andC3,2while maintaining the
consistency. Becauseofmessage m4,C3,2cannotbeconsistentwith C2,1oranyearliercheckpoint
inp2, and because of message m3,C1,1cannot be consistent with C2,2or any later checkpoint in
p2. Thusno checkpointon p2isavailableto formaconsistentglobalsnapshotwith C1,1andC3,2,.
To describe the necessary and sufﬁcient conditions for a con sistent snapshot, Netzer and Xu
[25] deﬁned a generalization of the Lamport’s happen before relation, called a zigzag path. A
checkpoint C1 happens before a checkpoint C2 (or a causal pat h exists between two checkpoints)
if a sequence of messages exists from C1 to C2 such that each me ssage is sent after the previous
oneinthesequenceisreceived. Azigzagpathbetweentwoche ckpointsisacausalpath,however,
a zigzag path allows a message to be sent before the previous o ne in the path is received. For
example, in Figure 4.5 although a causal path does not exist f romC1,1toC3,2, a zigzag path does
exist fromC1,1toC3,2. This zigzag path is formed by messages m3andm4. This zigzag path
meansthat noconsistentsnapshotexistsinthisexecutiont hat containsboth C1,1andC3,2.
Several applications require saving or analyzing consiste nt snapshots and zigzag paths have
implication on such applications. For example, the state fr om which a distributed computation
mustrestart afteracrash mustbeconsistent. Consistencye nsures thatno processisrestartedfrom
astatethathas recorded thereceipt ofamessage(called an o rphanmessage)thatno otherprocess
claims to have sent in the rolled back state. Processes take l ocal checkpoints independently and
a consistent global snapshot/checkpoint is found from the l ocal checkpoints for a crash recovery.
Clearly, dueto zigzag paths, notall checkpoints taken byth eprocesses will belongto a consistent
snapshot. Byreducingthenumberofzigzagpathsinthelocal checkpointstakenbyprocesses,one
canincreasethenumberoflocalcheckpointsthatbelongtoa consistentsnapshot,thusminimizing
therollbacknecessarytoﬁndaconsistentsnapshot1. Thiscanbeachievedbytrackingzigzagpaths
online and allowing each process to adaptively take checkpo ints at certain points in the execution
sothat thenumberofcheckpointsthat cannotbelongto acons istentsnapshotisminimized.
4.8.1 ZigzagPathsand Consistent GlobalSnapshots
In this section, we provide a formal deﬁnition of zigzag path s and use zigzag paths to character-
ize condition under which a set of local checkpoints togethe r can belong to the same consistent
snapshot. Wethenpresenttwospecialcases: First,thecond itionsforanarbitrarycheckpointtobe
useful (i.e., a consistent snapshot exists that contains th is checkpoint), and second, the conditions
fortwoarbitrary checkpointsto belongtothesameconsiste ntsnapshot.
AZigzagPath
Recallthatifaglobalsnapshotisconsistent,thennoneofi tscheckpointshappenedbeforetheother
(i.e., thereisno causal path between anytwocheckpointsin thesnapshot). However,as explained
earlier using Figure 4.5, if we have two checkpoints such tha t none of them happened before the
other,stillitisnotsufﬁcienttoensurethattheycanbelon gtogethertothesameconsistentsnapshot.
1Intheworstcase,thesystemwouldhavetorestartitsexecut ionrightfromthebeginningafterrepeatedrollbacks.
103
This happens when a zigzag path exists between such checkpoi nts. A zigzag path is deﬁned as a
generalizationofLamport’shappenedbefore relation.
Deﬁnition 1. Azigzag path exists from a checkpoint Cx,ito a checkpoint Cy,jiff there exists mes-
sagesm1,m2,...mn(n≥1) suchthat
1.m1issentbyprocess pxafterCx,i.
2. Ifmk(1≤k≤n) is received by process pz, thenmk+1is sent bypzin the same or a later
checkpointinterval(although mk+1maybesentbeforeor after mkisreceived), and
3.mnisreceived byprocess pybeforeCy,j.
For example, in Figure 4.5, a zigzag path exists from C1,1toC3,2due to messages m3and
m4. Even though process p2sendsm4before receiving m3, it does these in the same checkpoint
interval. However, a zigzag path does not exist from C1,2toC3,3(due to messages m5andm6)
becauseprocess p2sendsm6and receives m5indifferent checkpointintervals.
Deﬁnition2. AcheckpointCisinvolvedina zigzagcycle iffthereisazigzagpathfromCtoitself.
For example, in Figure 4.6, C2,1is on a zigzag cycle formed by messages m1andm2. Note
thatmessages m1andm2arerespectivelysent and receivedinthesamecheckpointin tervalatp1.
Difference Betweena ZigzagPathand aCausalPath
It is important to understand differences between a causal p ath and a zigzag path. A causal path
exists from a checkpoint A to another checkpoint B iff there i s chain of messages starting after A
and ending before Bsuch that each messageis sent afterthe pr eviousonein thechain is received.
Azigzagpathconsistsofsuchamessagechain,however,ames sageinthechaincanbesentbefore
thepreviousoneinthechainisreceived,aslongasthesenda ndreceiveareinthesamecheckpoint
interval. Thusacausal pathis alwaysazigzag path, butazig zag pathneed not beacausal path.
Figure 4.5 illustrates the difference between causal and zi gzag paths. A causal path exists
fromC1,0toC3,1formed by chain of messages m1andm2; this causal path is also a zigzag path.
Similarly,azigzagpathexistsfrom C1,1toC3,2formedbythechainofmessages m3andm4. Since
thereceiveof m3happenedafterthesendof m4,thiszigzagpathisnotacausalpathand C1,1does
nothappen before C3,2.
Another difference between a zigzag path and a causal path is that a zigzag path can form a
cycle but a causal path never forms a cycle. That is, it is poss iblefor a zigzag path to exist from a
checkpoint back to itself, called a zigzag cycle. In contras t, causal paths can neverform cycles. A
zigzagpathmayformacyclebecauseazigzagpathneednotrep resentcausality–inazigzagpath,
we allow a message to be sent before the previous message in th e path is received as long as the
send and receive are in the same interval. Figure 4.6 shows a z igzag cycle involving C2,1, formed
by messages m1andm2.
104
3,2CC1,1
4mm2m3p1
C2,1m1C2,0
C3,0C1,0
3,1CC2,2C2,31,2C
p2
p3
Figure4.6: A zigzag cycle, inconsistentsnapshot,and cons istentsnapshot.
Consistent GlobalSnapshots
Netzer and Xu [25] proved that if no zigzag path (or cycle) exi sts between any two checkpoints
from a set S of checkpoints, then a consistent snapshot can be formed that includes the set S of
checkpointsand viceversa.
For a formal proof, the readers should consult the original p aper. Here we give an intuitive
explanation. Intuitively, if a zigzag path exists between t wo checkpoints, and that zigzag path is
alsoacausalpath,thenthecheckpointsareorderedandhenc ecannotbelongtothesameconsistent
snapshot. If the zigzag path between two checkpoints is not a causal path, a consistent snapshot
cannot be formed that contains both the checkpoints. The zig zag nature of the path causes any
snapshot that includes the two checkpoints to be inconsiste nt. To visualize the effect of a zigzag
path, consider a snapshot line2through the two checkpoints. Because of the existance of a zi gzag
pathbetweenthetwocheckpoints,thesnapshotlinewillalw ayscrossamessagethatcausesoneof
thecheckpointstohappenbeforetheother,makingthesnaps hotinconsistent. Figure4.6illustrates
this. Twosnapshotlinesaredrawnfrom C1,1toC3,2. Thezigzagpathfrom C1,1toC3,2rendersboth
the snapshot lines to be inconsistent. This is because messa gesm3andm4cross either snapshot
linein way thatorders thetwoofitscheckpoints.
Conversely,ifnozigzagpathexistsbetweentwocheckpoint s(includingzigzagcycles),thenit
is always possible to construct a consistent snapshot that i ncludes these two checkpoints. We can
form a consistent snapshot by including the ﬁrst checkpoint at every process that has no zigzag
path to either checkpoint. Note that messages can cross a con sistent snapshot line as long as they
do not cause any of the line’s checkpoints to happen before ea ch other. For example, in Figure
4.6,C1,2andC2,3canbegroupedwith C3,1toformaconsistentsnapshoteventhoughmessage m4
crosses thesnapshotline.
As asummary,
•Theabsenceofacausalpathbetweencheckpointsinasnapsho tcorrespondstothenecessary
conditionforaconsistentsnapshot,andtheabsenceofazig zagpathbetweencheckpointsin
asnapshotcorrespondstothenecessary and sufﬁcientcondi tionsforaconsistentsnapshot.
•A setofcheckpointsScan beextendedtoaconsistentsnapsho tifand onlyifno checkpoint
inS hasazigzag path toany othercheckpointin S.
2A snapshotline isaline drawnthroughaset ofcheckpoints.
105
•A checkpoint can be a part of a consistent snapshot if and only if it is not invloved in a
Z-cycle.
4.9 FindingConsistentGlobalSnapshotsinaDistributedCo m-
putation
Wenowaddresstheproblemtodeterminehowindividuallocal checkpointscanbecombinedwith
thosefromotherprocessestoformglobalsnapshotsthatare consistent. Asolutiontothisproblem
formsthebasisformanyalgorithmsandprotocolsthatmustr ecordon-the-ﬂyconsistentsnapshots
ordeterminepost-mortemwhich globalsnapshotsare consis tent.
Netzer and Xu [25] proved the necessary and sufﬁcient condit ions to construct a consistent
snapshot from a set of checkpoints S. However, they did not deﬁne the set of possible consistent
snapshots and did not present an algorithm to construct them . Manivannan-Netzer-Singhal ana-
lyzedthesetof allconsistentsnapshotsthatcan bebuiltfromasetofcheckpoi ntsS. Theyproved
exactly which sets of local checkpoints from other processe s can be combined with those in Sto
form a consistent snapshot. They also developed an algorith m that enumerates all such consistent
snapshots.
We deﬁnethefollowingnotationsdueto Wang [33, 34].
Deﬁnition 3. LetA,Bbe individual checkpoints and R,Sbe sets of checkpoints. Let ;be a
relationdeﬁnedover checkpointsandsets ofcheckpointssu chthat
1.A;Biffa Z-path existsfrom AtoB,
2.A;Siffa Z-pathexistsfrom Atosomemember ofS,
3.S;Aiffa Z-pathexistsfrom somemember ofStoA, and
4.R;Siffa Z-pathexistsfrom somemember ofRtosomemember ofS.
S∝\⌉}atio\slash;Sdeﬁnes that no Z-path (including Z-cycle) exists from any me mber ofSto any other
memberofSand impliesthatcheckpointsin Sare allfrom differentprocesses.
Usingtheabovenotations,theresults ofNetzer and Xucan be expressed as follows:
Theorem 1. A set of checkpoints Scan be extended to a consistent global snapshot if and only if
S∝\⌉}atio\slash;S.
Corollary 1. A checkpoint Ccan be part of a consistent global snapshot if and only if it is not
involvedin a Z-cycle.
Corollary 2. A set of checkpoints Sis a consistent global snapshot if and only if S∝\⌉}atio\slash;Sand
|S|=N, whereNisthenumberof processes.
4.9.1 Finding Consistent GlobalSnapshots
We now discuss exactly which consistent snapshots can be bui lt from a set of checkpoints S. We
alsopresent an algorithmto enumeratetheseconsistentsna pshots.
106
ExtendingStoa Consistent Snapshot
Given a set Sof checkpoints such that S∝\⌉}atio\slash;S, we ﬁrst discuss what checkpoints from other pro-
cesses can be combined with Sto build a consistent global snapshot. The result is based on the
followingthreeobservations.
First Observation: None of the checkpointsthat havea Z-path to or from any ofthe checkpoints
inScan beused. This is because from Theorem 1, no checkpoints be tween which a Z-path exists
can ever be part of a consistent snapshot. Thus, only those ch eckpoints that have no Z-paths to or
from any of the checkpoints in Sare candidates for inclusion in the consistent snapshot. We call
thesetofallsuchcandidatesthe Z-coneofS. Similarly,wecallthesetofallcheckpointsthathave
no causalpath toorfrom anycheckpointin StheC-coneofS.3
The Z-cone and C-cone help us reason about orderings and cons istency. Since a causal path
is always Z-path, the Z-cone of Sis a subset of the C-cone of Sfor an arbitrary S, as shown in
Figure 4.7. Note that if a Z-path exists from checkpoint Cp,iin processppto a checkpoint in S,
then a Z-path also exists from every checkpoint in ppprecedingCp,ito the same checkpoint in S
(becauseZ-pathsaretransitive). Likewise,ifaZ-pathexi stsfromacheckpointin Stoacheckpoint
Cq,jin processpq, then a Z-path also exists from the same checkpoint in Sto every checkpoint in
pqfollowingCq,j. Causal paths arealso transitiveand similarresultsholdf orthem.
Z − cone)(
(C − cone)Z − paths to S               Z − unordered with S             Z − paths from S
Casually unordered with S Casual paths from SEdge of C − cone Edges of  Z − cone Edge of C − coneS
Casual paths to S                         
Figure4.7: The Z-coneand theC-coneassociatedwithaset ofcheckpoints S.
Second Observation: Although candidates for building a consistent snapshot fro mSmust lie
3These terms are inspired by the so-called light cone of an event ewhich is the set of all eventswith causal paths
frome(i.e., events in e’s future). Although the light cone of econtains events ordered aftere, we deﬁne the Z-cone
andC-coneof Stobethoseeventswith nozigzagorcausalordering,respectively,toorfromanymemb erofS.
107
in the Z-cone of S, not all checkpoints in the Z-cone can form a consistent snap shot withS.
FromCorollary1,ifacheckpointintheZ-coneisinvolvedin aZ-cycle,thenitcannotbepartofa
consistentsnapshot. Lemma2belowstatesthatifweremovef romconsiderationallcheckpointsin
theZ-conethat areinvolvedin Z-cycles, theneach oftherem ainingcheckpointscan becombined
withStobuildaconsistentsnapshot.
First wedeﬁnetheset ofusefulcheckpointswithrespect tos etS.
Deﬁnition 4. LetSbe a set of checkpoints such that S∝\⌉}atio\slash;S. Then, for each process pq, the set
Sq
usefulis deﬁnedas
Sq
useful={Cq,i|(S∝\⌉}atio\slash;Cq,i)∧(Cq,i∝\⌉}atio\slash;S)∧(Cq,i∝\⌉}atio\slash;Cq,i)}.
In addition,wedeﬁne
Suseful=/uniondisplay
qSq
useful.
Thus, with respect to set S, a checkpoint Cis useful ifCdoes not have a zigzag path to any
checkpointin S, no checkpointin Shas azigzag pathto C, andCisnoton aZ-cycle.
Lemma 2. LetSbe a set of checkpoints such that S∝\⌉}atio\slash;S. LetCq,ibe any checkpoint of process
pqsuch thatCq,i∝\⌉}atio\slash∈S. ThenS∪{Cq,i}can be extended to a consistent snapshot if and only if
Cq,i∈Suseful.
We omit the proof of the Lemma and interested readers can refe r to the original paper for a
proof.
Lemma2statesthatifwearegivenaset SsuchthatS∝\⌉}atio\slash;S,weareguaranteedthatany single
checkpointfrom Susefulcan belongto aconsistentglobalsnapshotthatalsocontain sS.
Third Observation: However, if we attempt to build a consistent snapshot from Sby choosing a
subsetTofcheckpointsfrom Susefultocombinewith S,thereisnoguaranteethatthecheckpoints
inThavenoZ-pathsbetweenthem. Inotherwords,althoughnoneo fthecheckpointsin Susefulhas
aZ-pathtoorfromanycheckpointin S,Z-pathsmayexistbetweenmembersof Suseful. Therefore,
we place one ﬁnal constraint on the set Twe choose from Susefulto build a consistent snapshot
fromS: checkpoints in Tmust have no Z-paths between them. Furthermore, since S∝\⌉}atio\slash;S, from
Theorem 1,at least onesuch Tmustexist.
Theorem 3. LetSbe a set of checkpoints such that S∝\⌉}atio\slash;Sand letTbe any set of checkpoints
suchthatS∩T=∅. Then,S∪Tis aconsistentglobalsnapshotif andonlyif
1.T⊆Suseful,
2.T∝\⌉}atio\slash;T,and
3.|S∪T|=N.
We omit the proof of the Theorem and interested readers can re fer to the original paper for a
proof.
108
4.9.2 Manivannan-Netzer-Singhal Algorithm for Enumerati ng Consistent
Snapshots
In the previous section, we showed which checkpoints can be u sed to extend a set of checkpoints
Sto a consistent snapshot. We now present an algorithm due to M anivannan-Netzer-Singhal that
explicitly computes all consistent snapshots that include a given set a set of checkpoints S. The
algorithmrestrictsitsselectionofcheckpointstothosew ithintheZ-coneof Sanditchecksforthe
presence ofZ-cycleswithintheZ-cone. In thenextsection, wediscusshowto detect Z-cones and
Z-pathsusingagraph byWang [33, 34],
1:ComputeAllCgs (S){
2: letG=∅
3: ifS∝\⌉}atio\slash;Sthen
4: letAllProcs betheset ofallprocesses notrepresented in S
5: ComputeAllCgsFrom (S,AllProcs )
6: returnG
7:}
8:ComputeAllCgsFrom (T,ProcSet ){
9: if(ProcSet =∅)then
10: G=G∪{T}
11: else
12: letpqbeanyprocess in ProcSet
13: foreach checkpoint C∈Tq
usefuldo
14: ComputeAllCgsFrom (T∪{C},ProcSet\{pq})
15:}
Figure4.8: Algorithmforcomputingallconsistentsnapsho tscontaining S.
The algorithm is shown in Figure 4.8 and it computes all consi stent snapshots that include a
given setS. The function ComputeAllCgs (S)returns the set of all consistent checkpoints that
containS. The heart of the algorithm is the function ComputeAllCgsFrom (T,ProcSet )which
extendsasetofcheckpoints Tinallpossibleconsistentways,butusescheckpointsonlyf rompro-
cessesintheset ProcSet. Afterverifyingthat S∝\⌉}atio\slash;S,ComputeAllCgs callsComputeAllCgsFrom ,
passingaProcSet consistingoftheprocessesnotrepresented in S(lines2–5). Theresultingcon-
sistent snapshots are collected in the global variable Gwhich is returned (line 6). It is worth
nothingthat if S=∅, thealgorithmcomputes allconsistentsnapshotsthatexistintheexecution.
The recursive function ComputeAllCgsFrom (T,ProcSet )works by choosing any process
fromProcSet, saypq, and iterating through all checkpoints CinTq
useful. From Lemma 2, each
such checkpoint extends Ttoward a consistent snapshot. This means T∪Ccan itself be further
extended, eventually arriving at a consistent snapshot. Si nce this further extension is simply an-
other instance of constructing all consistent snapshots th at contain checkpoints from a given set,
wemakearecursivecall(line14),passing T∪CandaProcSet fromwhichprocess pqisremoved.
The recursion eventually terminates when the passed set con tains checkpoints from all processes
109
(i.e.,ProcSet is empty). In this case Tis a global snapshot, as it contains one checkpoint from
every process, and it is added to G(line 10). When the algorithm terminates, all candidates in
Susefulhavebeen usedin extending S, soG containsallconsistentsnapshotsthat contain S.
Thefollowingtheoremargues thecorrectness ofthealgorit hm.
Theorem 4. LetSbe a set of checkpoints and Gbe the set returned by ComputeAllCgs (S). If
S∝\⌉}atio\slash;S, thenT∈Gif and only if Tis a consistent snapshot containing S. That is,Gcontains
exactlytheconsistentsnapshotsthatcontain S.
We omit the proof of the theorem and interested readers can re fer to the original paper for a
proof.
4.9.3 Finding Z-paths ina Distributed Computation
Tracking Z-paths on-the-ﬂy is difﬁcult and remains an open p roblem. We describe a method for
determining the existence of Z-paths between checkpoints i n a distributed computation that has
terminated or has stopped execution, using the rollback-de pendency graph (R-graph) introduced
by Wang[33, 34]. First,wepresent thedeﬁnitionofan R-grap h.
Deﬁnition 5. The rollback-dependency graph of a distributed computatio n is a directed graph
G= (V,E), where the vertices Vare the checkpoints of the distributedcomputation and an ed ge
(Cp,i,Cq,j)fromcheckpoint Cp,itocheckpoint Cq,jbelongstoEif
1.p=qandj=i+ 1,or
2.p∝\⌉}atio\slash=qanda message msentfromthe ithcheckpointintervalof ppisreceived by pqinitsjth
checkpointinterval( i,j > 0).
Construction ofanR-graph
When a process ppsends a message min itsithcheckpoint interval, it piggybacks the pair (p,i)
with the message. When the receiver pqreceivesmin itsjthcheckpoint interval, it records the
existence of an edge from Cp,itoCq,j. When a process wants to construct the R-graph for ﬁnd-
ing Z-paths between checkpoints, it broadcasts a request me ssage to collect the existing direct
dependencies from all other processes and constructsthe co mpleteR-graph. We assumethat each
processstopsexecutionafteritsendsareplytotherequest sothatadditionaldependenciesbetween
checkpoints are not formed while the R-graph is being constr ucted. For each process, a volatile
checkpointisadded; thevolatilecheckpointrepresents th evolatilestateoftheprocess[33, 34].
Example ofanR-graph
Figure4.10 showstheR-graph ofthecomputationshownin Fig ure4.9. In Figure 4.10, C1,3,C2,3,
andC3,3represent the volatile checkpoints, the checkpoints repre senting the last state the process
attainedbefore terminating.
We denotethefact that thereis a path from CtoDin theR-graph by Crd;D. It only denotes
the existence of a path; it does not specify any particular pa th. For example, in Figure 4.10,
110
p2
p3p1
m6m2C1,0 C1,1
C2,0
C3,0C2,1C1,2
C2,2
C3,2C3,1m3mm
m14
5
Figure4.9: Adistributedcomputation.
C3,1 C C3,2 3,3C3,0C2,3
C2,2C2,1 C2,0C1,0C1,1C1,2 C1,3
Volatile
checkpoints
Figure4.10: TheR-graph ofthecomputationinFigure4.9.
C1,0rd;C3,2. When weneed tospecify aparticularpath, wegivethesequen ce ofcheckpointsthat
constitute the path. For example, (C1,0,C1,1,C1,2,C2,1,C3,1,C3,2)is a path from C1,0toC3,2and
(C1,0,C1,1,C1,2,C2,1,C2,2,C2,3,C3,2)isalso apathfrom C1,0toC3,2.
The following theorem establishes the correspondence betw een the paths in the R-graph and
the Z-paths between checkpoints. This correspondence is ve ry useful in determining whether or
notaZ-path existsbetween twogivencheckpoints.
Theorem 5. LetG= (V,E)be the R-graph of a distributed computation. Then, for any tw o
checkpoints Cp,iandCq,j,Cp,i;Cq,jif andonlyif
1.p=qandi<j,or
2.Cp,i+1rd;Cq,jinG(notethatinthiscase pcouldstillbeequal to q).
Forexample,inthedistributedcomputationshowninFigure 4.9,azigzagpathexistsfrom C1,1
toC3,1because in the corresponding R-graph, shown in Figure 4.10, C1,2rd;C3,1. Likewise, C2,1
ison aZ-cyclebecauseinthecorrespondingR-graph, showni nFigure4.10, C2,2rd;C2,1.
4.10 ChapterSummary
Recording global state of a distributed system is an importa nt paradigm in the design of the dis-
tributed systems and the design of efﬁcient methods of recor ding the global state is an important
111
issue. Recording of global state of a distributed system is c omplicated due to the lack of both a
globally shared memory and a global clock in a distributed sy stem. This chapter ﬁrst presented a
formal deﬁnition of the global state of a distributed system and exposed issues related to its cap-
ture;itthendescribedseveralalgorithmstorecordasnaps hotofadistributedsystemundervarious
communicationmodels.
Table 4.1 gives a comparison of the salient features of the va rious snapshot recording algo-
rithms. Clearly,thehigherthelevelofabstractionprovid edbyacommunicationmodel,thesimpler
thesnapshotalgorithm. However,thereisnobestperformin gsnapshotalgorithmandanappropri-
atealgorithmcanbechosenbasedontheapplication’srequi rement. Forexamples,fortermination
detection, a snapshot algorithm that computes a channel sta te as the number of messages is ade-
quate; forcheckpointingforrecovery from failures, an inc rementalsnapshotalgorithmislikelyto
be the most efﬁcient; for global state monitoring, rather th an recording and evaluating complete
snapshotsatregularintervals,itismoreefﬁcienttomonit orchangestothevariablesthataffectthe
predicateand evaluatethepredicateonlywhen somecompone ntvariablechanges.
As indicated in the introduction, the paradigm of global sna pshots ﬁnds a large number of
applications (such as detection of stable properties, chec kpointing, monitoring, debugging, analy-
ses of distributed computation, discarding of obsolete inf ormation). Moreover, in addition to the
problems they solve, the algorithms presented in this chapt er are of great importance to people
interested in distributed computing as these algorithms il lustrate the incidence of properties of
communicationchannels(FIFO, non-FIFO,causalordering) onthedesignofaclassofdistributed
algorithms.
We also discussed the necessary and sufﬁcient conditions fo r consistent snapshots. The non-
causal path between checkpoints in a snapshot corresponds t o the necessary condition for consis-
tent snapshot, and the non-zigzag path corresponds to the ne cessary and sufﬁcient conditions for
consistent snapshot. Tracking of zigzag path is helpful in f orming a global consistent snapshot.
The avoidance of zigzag path between any pair of checkpoints from a collection of checkpoints
(snapshot) is the necessary and sufﬁcient conditions for a c onsistent global snapshot. Avoidance
ofcausal pathsalonewillnotbesufﬁcientforconsistency.
We alsopresented an algorithmforﬁndingall consistentsna pshotscontainingagivenset Sof
local checkpoints; if we take S=∅, then the algorithm gives the set of all consistent snapshot s
of a distributedcomputationrun. We established the corres pondence between the Z-paths and the
pathsin theR-graph whichhelpsin ﬁndingtheexistenceofZ- pathsbetween checkpoints.
4.11 BibliographicNotes
Thenotionofaglobalstateinadistributedsystemwasforma lizedbyChandyandLamport[6]who
also proposed the ﬁrst algorithm (CL) for recording the glob al state, and ﬁrst studied the various
properties of the recorded global state. The space-time dia gram which is a very useful graphical
tool to visualize distributed executions was introduced by Lamport [19]. A detailed survey of
snapshotrecordingalgorithmsis givenby Kshemkalyani,Ra ynal, and Singhal[16].
Spezialetti and Kearns proposed a variant of the CL algorith m to optimize concurrent initia-
tions by different processes, and to efﬁciently distribute the recorded snapshot [29]. Venkatesan
proposed a variant that handles repeated snapshots efﬁcien tly [32]. Helary proposed a variant of
theCLalgorithmtoincorporatemessagewavesinthealgorit hm[12]. Helary’salgorithmisadapt-
112
able to a system with non-FIFO channels but requires inhibit ion[31]. Besides Helary’s algorithm
[12], the algorithms proposed by Lai and Yang [18] Li, Radhak rishnan, and Venkatesh [20], and
by Mattern [23] can all record snapshots in systems with non- FIFO channels. If the underlying
network can provide causal order of message delivery [5], th en the algorithms by Acharya and
Badrinath [1]and by Alagarand Venkatesan [2]can record the globalstateusing O(n)numberof
messages.
The notion of simultaneous regions for monitoring global st ate was proposed by Spezialetti
and Kearns [30]. The necessary and sufﬁcient conditions for consistent global snapshots were
formulated by Netzer and Xu [25] based on the zigzag paths. Th ese have particular applicationin
checkpointing and recovery. Manivannan, Netzer, and Singh al analyzed the set of all consistent
snaspshotsthatcanbebuiltfromagivensetofcheckpoints[ 21]. Theyalsoproposedanalgorithm
to enumerate all such consistent snapshots. The deﬁnition o f theR−graphand other notations
and frameworkused by[21]were proposedbyWang [33, 34].
Recording the global state of a distributed system ﬁnds appl ications at several places in dis-
tributedsystems. Forapplicationsindetectionofstablep ropertiessuchas deadlocks,see[17]and
for termination, see [22]. For failure recovery, a global st ate of the distributed system is periodi-
cally saved and recovery from a processor failure is done by r estoring thesystem to thelast saved
global state [15]. For debugging distributedsoftware, the system is restored to a consistent global
state [8, 9] and the execution resumes from there in a control led manner. A snapshot record-
ing method has been used in the distributed debugging facili ty of Estelle [13, 11], a distributed
programming environment. Other applications include moni toring distributed events [30], setting
distributedbreakpoints[24], protocolspeciﬁcation and v eriﬁcation[4, 10, 14], and discardingob-
soleteinformation[12].
WewillstudysnapshotalgorithmsforsharedmemoryintheDi stributedSharedMemoryChap-
ter.
4.12 ExerciseProblems
1. Considerthefollowingsimplemethodtocollectaglobals napshot(itmaynotalwayscollect
aconsistentglobalsnapshot): Initiatorprocesstakesits snapshotandbroadcastsarequestto
takesnapshot. When someotherprocess receives thisreques t,it takes asnapshot. Channels
arenot FIFO.
Prove that such a collected distributed snapshot will be con sistent iff the following holds
(assume there are nprocesses in the system and Vtidenotes the vector timestamp of the
snapshottaken process pi):
(Vt1[1],Vt2[2], ....,Vtn[n])=max(Vt1,Vt2, ....,Vtn)
Don’tworry about channelstates.
2. What good is a distributed snapshot when the system was nev er in the state represented by
thedistributedsnapshot? Givean applicationofdistribut edsnapshots.
3. Consideradistributedsystemwhereeverynodehasitsphy sicalclockandallphysicalclocks
are perfectly synchronized. Give an algorithm to record glo bal state assuming the commu-
113
nication network is reliable. (Note that your algorithm sho uld be simpler than the Chandy-
Lamportalgorithm.)
4. What modiﬁcations should be done to the Chandy-Lamport sn apshot algorithm so that it
records astronglyconsistentsnapshot(i.e.,all channel s tatesarerecorded empty).
5. Consider two consistent cuts whose eventsare denoted by C1=C1(1),C1(2),...,C 1(n)and
C2=C2(1),C2(2),...,C 2(n),respectively.
Deﬁne a third cut, C3=C3(1),C3(2),...,C 3(n)that is the maximum of C1andC2; that is,
foreveryk, C3(k)=laterofC1(k)andC2(k).
Deﬁne a fourth cut, C4=C4(1),C4(2),...,C 4(n)that is the minimumof C1andC2; that is,
foreveryk, C4(k)=earlierofC1(k)andC2(k).
ProvethatC3andC4arealso consistentcuts.
114
Bibliography
[1] A. Acharya, B. R. Badrinath, Recording Distributed Snapshots Based on Causal Order of
MessageDelivery, InformationProcessingLetters, NorthHolland,44,317-32 1,1992.
[2] S. Alagar, S. Venkatesan, An Optimal Algorithm for Distributed Snapshots with Causal Mes-
sageOrdering, InformationProcessing Letters,vol 50,1994,pp.311-316.
[3] O. Babaoglu, K. Marzullo, Consistent Global States of Distributed Systems: Fundamen tal
Concepts and Mechanisms, DistributedSystems, ACM Press (editor S.J. Mullender), Ch apter
4, 1993.
[4] O. Babaoglu, Raynal M., Speciﬁcation and veriﬁcation of dynamic properties in dist ributed
computations, JournalofParalleland DistributedSystems,Vol. 28(2),19 95.
[5] K.Birman,T.Joseph, ReliableCommunicationinPresenceofFailures, ACMTransactionson
ComputerSystems,47-76, 3,1987.
[6] K.Birman,A.Schiper,P.Stephenson, LightweightCausalandAtomicGroupMulticast, ACM
Transactionson ComputerSystems,272-314,9(3), 1991.
[7] K.M. Chandy, L. Lamport, Distributed Snapshots: Determining Global States of Distr ibuted
Systems,ACM TransactionsonComputerSystems,63-75, 3(1),1985.
[8] R. Cooper and K. Marzullo, Consistent Detection of Global Predicates , Proc. of ACM/ONR
WorkshoponParallel and DistributedDebugging,May1991,p p. 163-173.
[9] E. Fromentin, Plouzeau N., Raynal M., An introduction to the analysis and debug of dis-
tributedcomputations, Proc. 1st IEEE Int. Conf. on Algorithmsand Architectures fo r Parallel
Processing,Brisbane, Australia,April 1995,pp.545-554.
[10] K. Geihs, M. Seifert, Automated Validation of a Cooperation Protocol for Distrib uted Sys-
tems,Proceedings of the 6th International Conference on Distrib uted Computing Systems,
436-443,1986.
[11] O. Gerstel, Hurﬁn M., Plouzeau N., Raynal M., Zaks S., On-the-ﬂy replay: a practical
paradigm and its implementation for distributed debugging ,Proc. 6th IEEE Int. Symposium
onParallel and DistributedDebugging,pages 266-272,Dall as, TX,Oct. 1995.
115
[12] J.-M., Helary, Observing Global States of Asynchronous Distributed Appli cations,Proceed-
ingsofthe3rdInternationalWorkshoponDistributedAlgor ithms,LNCS392,SpringerVerlag,
124-134,1989.
[13] M.Hurﬁn,PlouzeauN.,RaynalM., AdebuggingtoolfordistribtedEstelleprograms, Journal
ofComputerCommunications,Vol.16 (5), 328-333,may1993.
[14] J. Kamal and M. Singhal, Speciﬁcation and Veriﬁcation of Distributed Mutual Exclus ion
Algorithms , Tech. Report, Dept. of Computer and Information Science, T he Ohio State Uni-
versity,Columbus,Fall 1992.
[15] R. Koo and S. Toueg, Checkpointing and Rollback-Recovery in Distributed Syste ms, IEEE
Trans.on SoftwareEngineering,January 1987.
[16] A. Kshemkalyani, M. Raynal, and M. Singhal. “Global Sna pshots of a Distributed System”,
DistributedSystemsEngineeringJournal ,Vol2, No 4,December1995, pp.224-233.
[17] A. Kshemkalyani and M. Singhal, Efﬁcient Detection and Resolution of Generalized Dis-
tributed Deadlocks , IEEE Trans. on Software Engineering, January 1994, Vol 20, No. 1, pp.
43-54.
[18] T.H.Lai,T.H. Yang, OnDistributedSnapshots, InformationProcessingLetters,NorthHol-
land,25, 153-158,1987.
[19] L. Lamport, Time, Clocks, and theOrdering of Events in a DistributedSys tem,Communica-
tionsoftheACM, 558-565,21(7),July1978.
[20] H. F. Li, T. Radhakrishnan, K. Venkatesh, Global State Detection in Non-FIFO Networks,
Proceedingsofthe7thInternationalConferenceonDistrib utedComputingSystems,364-370,
1987.
[21] D. Manivannan, R.H.B Netzer, and M. Singhal, Finding Consistent Global Checkpoints in
a Distributed Computation , IEEE Trans. of Parallel and Distributed Systems, June 1997 , pp.
623-627.
[22] F. Mattern, Algorithms for Distributed Termination Detection , Distributed Computing, pp.
161-175,1987.
[23] F. Mattern, Efﬁcient Algorithmsfor DistributedSnapshotsand GlobalV irtualTimeApproxi-
mation,JournalofParalleland DistributedComputing,18,423-434 ,1993.
[24] B. Miller, J. Choi, Breakpoints and Halting in DistributedPrograms, Proceedings of the 8th
InternationalConference on DistributedComputingSystem s,316-323,1988.
116
[25] Robert H. B. Netzer, Jian Xu: Necessary and Sufﬁcient Co nditions for Consistent Global
Snapshots, IEEE Transactions on Parallel and Distributed S ystems, vol. 6, Issue 2 (February
1995),pg 165-169.
[26] M. Raynal, A. Schiper, S. Toueg, Causal Ordering Abstraction and A Simple Way to Imple-
ment It,InformationProcessing Letters,343-350,Sept. 1989.
[27] S.Sarin,N.Lynch, DiscardingObsoleteInformationinaReplicatedDatabaseS ystem,IEEE
Transactions on Software Engineering, Volume 13, Issue 1, J anuary 1987, (Special issue on
distributedsystems)pp39 -47.
[28] A. Schiper, J. Eggli, A. Sandoz, A New Algorithm to Implement Causal Ordering, Proceed-
ingsofthe3rdInternationalWorkshoponDistributedAlgor ithms,LNCS392,SpringerVerlag,
219-232,1989.
[29] M.Spezialetti,P.Kearns, EfﬁcientDistributedSnapshots, Proceedingsofthe6thInternational
Conference on DistributedComputingSystems,382-388,198 6.
[30] M. Spezialetti, P. Kearns, Simultaneous Regions: A Framework for the Consistent Monit or-
ing of Distributed Systems, Proceedings of the 9th International Conference on Distrib uted
ComputingSystems,61-68,1989.
[31] K. Taylor, The Role of Inhibition in Consistent Cut Protocols, Proceedings of the 3rd Inter-
nationalWorkshoponDistributedAlgorithms,LNCS 392,Spr ingerVerlag, 124-134,1989.
[32] S. Venkatesan, Message-Optimal Incremental Snapshots, Journal of Computerand Software
Engineering,Vol.1, No.3, pp211-231,1993.
[33] Yi-MinWang. “Maximumand MinimumConsistent Global Ch eckpointsand theirApplica-
tions”. In Proceedings of the 14thIEEE Symposium on Reliable Distributed Systems , pages
86–95,Bad Neuenahr, Germany,September1995.
[34] Yi-Min Wang. “Consistent Global Checkpoints That Cont ain a Given Set of Local Check-
points”. In IEEE Transactionson Computers ,1997.
117
Chapter5
Terminology andBasic Algorithms
In this chapter, we ﬁrst study a methodical framework in whic h distributed algorithms can be
classiﬁed and analyzed. We then consider some basic distrib uted graph algorithms. We then
studysynchronizers ,whichprovidetheabstractionofasynchronoussystemover anasynchronous
system. Lastly,welookatsomepractical graphproblems,to appreciatethenecessityofdesigning
efﬁcient distributedalgorithms.
5.1 TopologyAbstractionandOverlays
The topology of a distributed system can be typically viewed as an undirected graph in which
the nodes represent the processors and the edges represent t he links connecting the processors.
Weightsontheedgescanrepresentsomecostfunctionweneed tomodelintheapplication. There
areusuallythree(notnecessarilydistinct)levelsoftopo logyabstractionthatareusefulinanalyzing
the distributed system or a distributed application. These are now described using Figure 5.1. To
keep the ﬁgure simple, only the relevant end hostsparticipa ting in the applicationare shown. The
WANs are indicatedby ovalsdrawnusing dashedlines. The swi tchingelements insidethisWAN,
and other end hosts that are not participating in the applica tion, are not shown even though they
belong to the physical topological view. Similarly, all the edges connecting all end hosts and all
edgesconnectingtoalltheswitchingelementsinsidetheWA Nalsobelongtothephysicaltopology
vieweventhoughonlysomeedges areshown.
•Physical topology. The nodes of this topology represent all the network nodes, i ncluding
switching elements (also called routers) in the WAN and all t he end hosts – irrespective of
whether the hosts are participating in the application. The edges in this topology represent
all the communication links in the WAN in addition to all the d irect links between the end
hosts.
In Figure5.1(a), thephysicaltopologyisnot shownexplici tlytokeep theﬁguresimple.
•Logical topology. This is usually deﬁned in the context of a particular applica tion. The
nodesrepresent alltheend hostswhere theapplicationexec utes. Theedges in thistopology
118
WAN
WANWAN WAN
WAN or other network
(a) (b)participating process(or)
Figure5.1: Two examplesoftopologicalviewsat different l evelsofabstraction.
are logical channels (also termed as logical links) among th ese nodes. This view is at a
higherlevelofabstractionthanthatofthephysicaltopolo gy,andthenodesandedgesofthe
physicaltopologyneed notbeincludedinthisview.
Often, logical links are modeled between particular pairs o f end hosts participating in an
application to give a logical topology with useful properti es. Figure 5.1(b) shows each pair
of nodes in the logical topology is connected to give a fully c onnected network. Each pair
of nodes can communicate directly with each other participa nt in the application using an
incident logical link at this level of abstraction of the top ology. However, the logical links
mayalsodeﬁnesomearbitraryconnectivity(neighborhood- relation)onthenodesinthisab-
stract view. In Figure 5.1(a), the logical view provides eac h node with a parital view of the
topology, and the connectivity provided is some neighborho od connectivity. To communi-
cate with another application node that is not a logical neig hbour, a node may have to use a
multi-hoppathcomposedoflogicallinksat thislevelofabs tractionofthetopology.
Whilethefullyconnected logicaltopologyinFigure5.1(b) providesacompleteviewofthe
system, updating such a view in a dynamic system incurs an ove rhead. Neighbourhood-
based logicaltopologiesas inFigure5.1(a)are easiertoma nage.
Wewillconsiderdistributedalgorithmsonlogicaltopolog iesinthisbook,Peer-to-peer(P2P)
networks that we shall study in Chapter 18 are also deﬁned by a logical topology at the
application layer. However, the emphasis of P2P networks is on self-organizing networks
withbuilt-infunctions,e.g.,theimplementationofappli cationlayerfunctionssuchasobject
lookupandlocationin adistributedmanner.
•Superimposed topology. This is a higher-level topology that is superimposed on the l ogical
topology. It isusuallya regularstructuresuch as atree, ri ng, mesh,orhypercube. Themain
reason behind deﬁning such a topology is that it provides a sp ecialized path for efﬁcient
informationdisseminationand/orgatheringas partofa dis tributedalgorithm.
119
Consider the problem of collecting the sum of variables, one from each node. This can be
efﬁciently solvedusing nmessages by circulatinga cumulativecounteron a logicalri ng, or
usingn−1messages on a logical tree. The ring and tree are examples of s uperimposed
topologies on the underlying logical topology – which may be arbirtrary as in Figure 5.1(a)
orwhichmay befullyconnectedas in Figure5.1(b).
We will encounter various examples of these topologies, A superimposed topology is also
termedasa topologyoverlay . Thislattertermisbecomingincreasinglypopularwiththe spreadof
thepeer-to-peercomputingparadigm.
Notation: Whatever the level of topological view we are dealing with, w e assume that an undi-
rected graph (N,L)is used to represent the topology. The notation n=|N|andl=|L|will also
beused.
5.2 Classiﬁcationsand BasicConcepts
5.2.1 Application Executions and ControlAlgorithm Execut ions
The distributed application execution is comprised of the execution of instructions, including th e
communicationinstructions,withinthedistributedappli cationprogram. Theapplicationexecution
representsthelogicoftheapplication. Inmanycases,a controlalgorithm alsoneedstobeexecuted
inordertomonitortheapplicationexecutionortoperformv ariousauxiliaryfunctions. Thecontrol
algorithm performs functions such as: creating a spanning t ree, creating a connected dominating
set, achieving consensus among the nodes, distributed tran saction commit, distributed deadlock
detection, globalpredicatedetection, terminationdetec tion,global staterecording, checkpointing,
and alsomemoryconsistencyenforcement in distributedsha red memorysystems.
The code of the control algorithm is allocated its own memory space. The control algorithm
execution issuperimposed on the underlying application execution, but does not inter fere with
the application execution. In other words, the control algo rithm execution including all its send,
receive,and internaleventsaretransparent to(or notvisi bleby)theapplicationexecution.
The distributed control algorithm is also sometimes termed as a protocol; although the term
protocolis also looselyused forany distributedalgorithm. In theli teratureon formalmodelingof
networkalgorithms,theterm protocolismorecommonlyused.
5.2.2 Centralized and Distributed Algorithms
In a distributed system, a centralized algorithm is one in which a predominant amount of work
is performed by one (or possibly a few) processors, whereas o ther processors play a relatively
smallerroleinaccomplishingthejointtask. Therolesofth eotherprocessorsareusuallyconﬁned
torequestinginformationorsupplyinginformation,eithe rperiodicallyorwhen queried.
A typical system conﬁguration suited for centralized algor ithms is the client-server conﬁgu-
ration. Presently, much commercial software is written usi ng this conﬁguration, and is adequate.
120
From a theoretical perspective, the single server is a poten tial bottleneck for both processing and
bandwidth access on the links. The single server is also a sin gle point of failure. Of course, these
problems are alleviated in practice by using replicated ser vers distributed across the system, and
thentheoverallconﬁgurationisnotas centralized any more .
Adistributedalgorithm is onein whicheach processorplaysan equal rolein sharingt hemes-
sage overhead, time overhead, and space overhead. It is difﬁ cult to design a purely distributed
algorithm(thatisalsoefﬁcient)forsomeapplications. Co nsidertheproblemofrecordingaglobal
state of all the nodes. The well-known Chandy-Lamport algor ithm which we will study in Chap-
ter??is distributed - yet one node, which is typically the initiat or, is responsible for assembling
the local states of the other nodes, and hence plays a slightl y different role. Algorithms that are
designed to run on a logical-ring superimposedtopologyten d to be fully distributed to exploitthe
symmetry in the connectivity. Algorithms that are designed to run on the logical tree and other
asymmetric topologies with a predesignated root node tend t o have some asymmetry that mirrors
the asymmetric topology. Although fully distributed algor ithms are ideal, partly distributed algo-
rithms are sometimes more practical to implement in real sys tems. At any rate, the advances in
peer-to-peer networks, ubiquitous and ad-hoc networks, mo bile systems will require distributed
solutions.
5.2.3 Symmetricand AsymmetricAlgorithms
Asymmetric algorithm is an algorithm in which all the processors execute the same l ogical func-
tions. An asymmetric algorithm is an algorithm in which different processors execute logic ally
different(but perhaps partlyoverlapping)functions.
Acentralizedalgorithmisalwaysasymmetric. Analgorithm thatisnotfullydistributedisalso
asymmetric. Intheclient-serverconﬁguration,theclient sandtheserverexecuteasymmetricalgo-
rithms. Similarly, in a tree conﬁguration, the root and the l eaves usually perform some functions
thatare differentfromeach other, andthat aredifferentfr om thefunctionsoftheinternalnodesof
thetree. Applicationswherethereisinherentasymmetryin therolesofthecooperatingprocessors
will necessarily have asymmetric algorithms. A typical exa mple is where one processor initiates
thecomputationofsomeglobalfunction(e.g., min,sum).
5.2.4 Anonymous Algorithms
Ananonymous system is a system in which neither processes nor processors use the ir process
identiﬁers and processor identiﬁers to make any execution d ecisions in the distributed algorithm.
Ananonymousalgorithm is an algorithmwhich runs on an anonymoussystemand therefo redoes
notuseprocess identiﬁersorprocessoridentiﬁersintheco de.
Ananonymousalgorithmpossessesstructuralelegance. How ever,itisequallyhard,andsome-
times provably impossible, to design – as in the case of desig ning an anonymous leader election
algorithm on a ring. If we examine familiar examples of multi process algorithms, such as the
famous Bakery algorithm for mutual exclusion in a shared mem ory system, or the “wait-wound”
121
or “wound-die” algorithms used for transaction serializab ility in databases, we observe that the
process identiﬁer is used in resolvingties or contentionst hat are otherwiseunresolved despitethe
symmetricandnoncentralized natureofthealgorithms.
5.2.5 Uniform Algorithms
Auniformalgorithm isan algorithmwhichdoesnotuse n,thenumberofprocessesinthesystem,
as a parameter in its code. A uniform algorithm is desirable b ecause it allows scalability trans-
parency, and processes can join or leave the distributed exe cution without intruding on the other
processes, except its immediate neighbors that need to be aw are of any changes in their immedi-
ate topology. Algorithms that run on a logical ring and have n odes communicate only with their
neighboursareuniform. In Chapter ??, wewillstudya uniformalgorithmforleaderelection.
5.2.6 Adaptive Algorithms
Consider the context of a problem X. In a system with nnodes, letk, k≤nbe the number
of nodes “participating” in the context of Xwhen the algorithm to solve Xis executed. If the
complexityofthealgorithmcanbeexpressedintermsof kratherthanintermsof n,thealgorithm
isadaptive. For example, if the complexity of a mutual exclusion algori thm can be expressed
in terms of the actual number of nodes contending for the crit ical section when the algorithm is
executed,thenthealgorithmwouldbeadaptive.
5.2.7 Deterministic Versus Nondeterministic Executions
Adeterministicreceive primitivespeciﬁesthesourcefromwhichitwantstoreceive amessage. A
nondeterministicreceive primitivecanreceiveamessagefromanysource–themessage delivered
to the process is the ﬁrst message that is queued in the local i ncoming buffer, or the ﬁrst message
that comes in subsequently if no message is queued in the loca l incoming buffer. A distributed
program that contains no nondeterministic receives has a deterministic execution ; otherwise, if
it contains at least one nondeterministic receive primitiv e, it is said to have a nondeterministic
execution .
Each executiondeﬁnes apartialorderontheeventsintheexe cution. Eveninan asynchronous
system (deﬁned formally in Section 5.2.9), for any determin istic (asynchronous) execution, re-
peated re-execution will reproduce the same partial order o n the events. This is a very useful
property for applications such as debugging, detection of u nstable predicates, and for reasoning
aboutglobalstates.
Given any nondeterministic execution, any re-execution of that program may result in a very
different outcome, and any assertion about a nondeterminis tic execution can be made only for
that particular execution. Different re-executions may re sult in different partial orders because of
variable factors such as (i) lack of an upper bound on message delivery times and unpredictable
122
congestion;(ii)localschedulingdelaysontheCPUsduetot imesharing. Assuch,nondeterministic
executionsare difﬁcultto reason with.
5.2.8 ExecutionInhibition
Blockingcommunicationprimitivesfreezethelocalexecut ion1untilsomeactionsconnectedwith
the completion of that communication primitivehave occurr ed. But from a logical perspective, is
the process really prevented from executing further? The no nblocking ﬂavors of those primitives
canbeusedtoeliminatethefreezingoftheexecution,andth eprocessinvokingthatprimitivemay
beabletoexecutefurther(fromtheperspectiveoftheprogr amlogic)untilitreaches astageinthe
program logic where it cannot execute further until the comm unication operation has completed.
Onlynowistheprocess really frozen!
Distributed applications can be analyzed for freezing. Oft en, it is more interesting to examine
thecontrolalgorithmforitsfreezing/inhibitoryeffecto ntheapplicationexecution. Here,inhibition
refers to protocols delaying actions of the underlying syst em execution for an interval of time.
In the literature on inhibition, the term “ protocol” is used synonymously with the term “ control
algorithm ”. Protocols that require processors to suspend their norma l execution until some series
of actions stipulated by the protocol have been performed ar e termed as inhibitory orfreezing
protocols .
Different executions of a distributed algorithm can result in a different interleavings of the
events. Thus,therearemultipleexecutionsassociatedwit heachalgorithm(orprotocol). Protocols
can beclassiﬁed as follows,interms ofinhibition.
•A protocol is noninhibitory if no system event is disabled in any execution of the protoco l.
Otherwise,theprotocolis inhibitory .
•A disabled event ein an execution is said to be locallydelayed if there is someextensionof
the execution (beyond the current state) such that: (i) the e vent becomes enabled after the
extension, and (ii) there is no intervening receive event in the extension, Thus, the interval
of inhibition is under local control, A protocol is locally inhibitory if any event disabled in
anyexecutionoftheprotocolislocallydelayed.
•An inhibitory protocol for which there is some execution in w hich some delayed event is
not locally delayed is said to be globally inhibitory . Thus, in some (or all) execution of a
globally inhibitoryprotocol, at least one event is delayed waiting to receive communication
fromanotherprocessor.
Anorthogonalclassiﬁcationisthatof sendinhibition ,receiveinhibition ,andinternaleventinhibi-
tion.
•A protocolis send inhibitory ifsomedelayed eventsaresend events.
1TheOS dispatchableentity–theprocessorthethread– isfro zen.
123
•A protocolis receive inhibitory ifsomedelayed eventsare receiveevents.
•A protocolis internalevent inhibitory ifsomedelayed eventsare internalevents.
These classiﬁcations help to characterize the degree of inh ibition necessary to design protocols
to solve various problems. Problems can be theoretically an alyzed in terms of the possibility or
impossibility of designing protocols to solve them under th e various classes of inhibition. These
classiﬁcations also serve as a yardstick to evaluate protoc ols. The more stringent the class of
inhibition,thelessdesirableistheprotocol. Whenwestud yalgorithmsforrecordingglobalstates
and algorithms for checkpointing, we will have the opportun ity to analyze the protocols in terms
ofinhibition.
5.2.9 Synchronous andAsynchronous Systems
Asynchronoussystem isasystemthatsatisﬁes thefollowingproperties.
•Thereisa knownupperboundonthemessagecommunicationdel ay.
•There is a known bounded drift rate for the local clock of each processor with respect to
real-time. The drift rate between two clocks is deﬁned as the rate at which their values
diverge.
•Thereisaknownupperboundonthetimetakenbyaprocesstoex ecutealogicalstepinthe
execution.
Anasynchronous system is a system in which none of the above three properties of sync hronous
systems are satisﬁed. Clearly, systems can be designed that satisfy some combination but not all
of the criteria that deﬁne a synchronous system. The algorit hms to solve any particular problem
can vary drastically, based on the model assumptions; hence it is important to clearly identify the
system model beforehand. Distributed systems are inherent ly asynchronous; later in this chapter,
wewillstudysynchronizersthatprovidetheabstractionof asynchronousexecution.
5.2.10 Online versusOfﬂine Algorithms
Anon-linealgorithmisanalgorithmthatexecutesasthedataisbeingg enerated. An off-linealgo-
rithm is an algorithm that requires all the data to be availab le before algorithm execution begins.
Clearly, on-line algorithms are more desirable. Debugging and scheduling are two example areas
where on-line algorithms offer clear advantages. On-line s cheduling allows for dynamic changes
tothescheduletoaccountfornewlyarrivedrequestswithcl oserdeadlines. On-linedebuggingcan
detect errors when they occur, as opposed to collecting the e ntire trace of the execution and then
examiningitforerrors.
124
5.2.11 Failure Models
A failure model speciﬁes the manner in which the component(s ) of the system may fail. There
existsarichclassofwell-studiedfailuremodels. Itisimp ortanttospecifythefailuremodelclearly
becausethealgorithmusedtosolveanyparticularproblemc anvarydramatically,dependingonthe
failure model assumed. A system is t-fault tolerant if it continues to satisfy its speciﬁed behavior
aslongasnomorethan tofitscomponents(whetherprocessesorlinksoracombinati onofthem)
fail. The Mean Time between Failures (MTBF) is usually used to specify the expected time until
failure, based onstatisticalanalysisofthecomponent/sy stem.
Process FailureModels
•Fail-stop. Inthismodel,aproperlyfunctioningprocessmayfailbysto ppingexecutionfrom
someinstantthenceforth. Additionally,otherprocessesc an learn thattheprocess hasfailed.
This model provides an abstraction – the exact mechanism by w hich other processes learn
ofthefailurecan vary.
•Crash.In this model, a properly functioning process may fail by sto pping to function from
any instance thenceforth. Unlike the fail-stop model, othe r processes do not learn of this
crash.
•Receive omission. A properly functioning process may fail by intermittently r eceiving only
someofthemessagessentto it,orbycrashing.
•Sendomission. Aproperlyfunctioningprocessmayfailbyintermittentlys endingonlysome
ofthemessages itissupposedtosend, orbycrashing.
•General omission. A properly functioning process may fail by exhibiting eithe r or both of
sendomissionand receiveomissionfailures.
•Byzantine or malicious failure, with authentication. In this model, a process may exhibit
any arbitrary behavior. However, if a faulty process claims to have received a speciﬁc mes-
sage from a correct process, then that claim can be veriﬁed us ing authentication, based on
unforgeablesignatures.
•Byzantine or malicious failure. In this model, a process may exhibit any arbitrary behavior
and noauthenticationtechniquesareapplicableto verifya nyclaims made.
Theaboveprocessfailuremodels,listedinorderofincreas ingseverity(except forsendomissions
and receive omissions which are incomparable with each othe r), apply to both synchronous and
asynchronoussystems.
Timing failures can occur in synchronous systems, and manifest themselves a s some or all
of the following at each process. (1) General omission failu res. (2) Process clocks violating
their prespeciﬁed drift rate. (3) The process violating the bounds on the time taken for a step of
125
execution. In term of severity, timing failures are more sev ere than general omission failures but
lessseverethanByzantinefailures withmessageauthentic ation.
The failure models less severe than Byzantine failures, and timing failures, are considered
“benign”becausetheydonot allowprocesses toarbitrarily changestateorsend messagesthatare
notto besentas perthealgorithm. Benign failuresare easie rto handlethanByzantinefailures.
5.2.11.1 Communication FailureModels
•Crash failure. A properly functioning link may stop carrying messages from some instant
thenceforth.
•Omissionfailures. A linkcarries somemessagesbut nottheothers senton it.
•Byzantine failures. A link can exhibit any arbitrary behavior, including creati ng spurious
messagesand modifyingthemessagessenton it.
The above link failure models apply to both synchronous and a synchronous systems. Timing fail-
urescan occur in synchronous systems, and manifest themselves a s links transporting messages
fasterorslowerthan theirspeciﬁed behavior.
5.2.12 Wait-free algorithms
Await-free algorithm is an algorithm that can execute (synchronization operatio ns) in a (n−1)-
process fault tolerant manner, i.e., it is resilient to n−1process failures. Thus, if an algorithm
is wait-free, then the (synchronization) operations of any process must complete in a bounded
numberofstepsirrespectiveofthefailuresofall theother processes.
Althoughtheconceptofa k-fault-tolerantsystemisveryold,wait-freealgorithmde signindis-
tributed computing received attention in the context of mut ual exclusion synchronization for the
distributedshared memory abstraction. The objectivewas t o enablea process to access its critical
section,eveniftheprocessinthecriticalsectionfailsor misbehavesbynotexitingfromthecritical
section. Wait-free algorithms offer a very high degree of ro bustness. Designing a wait-free algo-
rithmis usuallyvery expensiveand may noteven bepossiblef or somesynchronizationproblems,
e.g., the simple producer-consumer problem. Wait-free alg orithms will be studied in Chapters 12
and 14. Wait-free algorithmscan beviewedas aspecial class offault-tolerantalgorithms.
5.2.13 Communication Channels
CommunicationchannelsarenormallyFirst-InFirst-Outqu eues(FIFO).Atthenetworklayer,this
propertymaynotbesatisﬁed,givingnon-FIFOchannels. The seandotherpropertiessuchascausal
orderofmessageswillbestudiedinChapter 6.
126
5.3 ComplexityMeasuresandMetrics
The performance of sequential algorithms is measured in ter ms of the lower bounds ( Ω,ω) rep-
resenting the best case, the upper bounds ( O,o) representing the worst case, and the exact bound
(θ),onthetimeandspacecomplexity. Fordistributedalgorit hms,thedeﬁnitionsofspaceandtime
complexity need to be reﬁned, and additionally, message com plexity also needs to be considered
formessage-passingsystems. Attheappropriatelevelofab stractionatwhichthealgorithmisrun,
thesystemtopologyisusuallyassumedtobeanundirectedun weightedgraph G= (N,L). Wede-
note|N|asn,|L|asl,andthediameterofthegraphas d. Thediameter ofagraphistheminimum
number of edges that need to be traversed to go from any node to any other node. More formally,
the diameter is max i,j∈N{length of the shortest path between iandj}. For a tree embedded in
the graph, its depth is denoted as h. Other graph parameters, such as eccentricity and degree of
edge incidence, can be used when they are required. It is also assumed that identical code runs at
eachprocessor;ifthisassumptionisnotvalid,thendiffer entcomplexitiesneedtobestatedforthe
differentcodes. Thecomplexitymeasuresare as follows.
•Space complexity per node. This is the memory requirement at a node. The best case,
averagecase, and worstcase memoryrequirementat anodecan bespeciﬁed.
•Systemwide space complexity. The system space complexity (best-case, average case, or
worstcase)isnotnecessarily ntimesthecorrespondingspacecomplexity(best-case,aver age
case,orworstcase)pernode. Forexample,thealgorithmmay notpermitallnodestoachieve
thebestcaseatthesametime. Wewilllaterstudyadistribut edpredicatedetectionalgorithm
(Algorithm 11.14 in Chapter 11) for which both the worst-cas e space complexity per node
as well as theworst-case systemwidespace complexityare pr oportionalto O(n2). If during
execution, the worst case occurs at one node, then the worst c ase will not occur at all the
othernodesinthat execution.
•Time complexity per node. This measures the processing time per node, and does not ex-
plicitly account for the message propagation/transmissio n times, which are measured as a
separatemetric.
•Systemwide time complexity. If the processing in the distributed system occurs at all the
processorsconcurrently,thenthesystemtimecomplexityi snotntimesthetimecomplexity
per node. However, if the executions by the different proces ses are done serially, as in the
case of an algorithm in which only the unique token-holder is allowed to execute, then the
overalltimecomplexityis additive.
•Messagecomplexity. Thishas twocomponents–a spacecomponentand atimecompone nt.
–Number of messages. The number of messages contributes directly to the space com -
plexityofthemessageoverhead.
127
–Sizeofmessages. Thissize,inconjunctionwiththenumberofmessages,measu resthe
space component on messages. Further, for very large messag es, this also contributes
to thetimecomponentviatheincreased transmissiontime.
–Message time complexity. The numberof messages contributesto the timecomponent
indirectly, besides affecting the count of the send events a nd message space overhead.
Dependingonthedegreeofconcurrencyinthesendingofthem essages–i.e.,whether
all messages are sequentially sent (with reference to the ex ecution partial order), or
all processes can send concurrently, or something in betwee n – the time complexity is
affected. Forasynchronousexecutions,thetimecomplexit ycomponentismeasuredin
termsofsequentialmessagehops ,i.e.,thelengthofthelongestchaininthepartialorder
(E,≺)on the events. For synchronous executions, the time complex ity component is
measured in termsofrounds(alsotermed as stepsorphases).
Itisusuallydifﬁculttodeterminealloftheabovecomplexi tiesformostalgorithms. Nevertheless,it
isimportanttobeawareofthedifferentfactorsthatcontri butetowardsoverhead. Whenstatingthe
complexities,itshouldalsobespeciﬁedwhetherthealgori thmhasasynchronousorasynchronous
execution. Depending on the algorithm, further metrics suc h as the number of send events, or the
number of receive events, may be of interest. If message mult icast is allowed, it should be stated
whether a multicast send event is counted as a single event. A lso, whether the message multicast
is counted as a single message or as multiple messages needs t o be clariﬁed. This would depend
onwhetherornothardwaremulticastingisusedbythelowerl ayersofthenetworkprotocolstack.
For shared memory systems, the message complexity is not an i ssue if the shared memory is
not being provided by the distributed shared memory abstrac tion over a message-passing system.
The following additional changes in the emphasis on the usua l complexity measures would need
tobeconsidered.
•The size of shared memory , as opposed to the size of local memory, is important. The
justiﬁcationis thatshared memoryisexpensive,local memo ryisnot.
•Thenumberofsynchronizationoperations usingsynchronizationvariablesisausefulmetric
becauseitaffects thetimecomplexity.
5.4 ProgramStructure
Hoare,whopioneeredprogramminglanguagesupportforconc urrentprocesses,designedConcur-
rentSequentialProcesses(CSP)whichallowscommunicatin gprocessestosynchronizeefﬁciently.
Thetypicalprogramstructureforanyprocess inadistribut edapplicationisbased onCSP’s repet-
itivecommandoverthealternativecommandonmultipleguar ded commands,isas follows.
∗[G1−→CL1||G2−→CL2||···||Gk−→CLk]
Therepetitive command(denoted by “*”) denotes an inﬁniteloop. Inside the repetitive command
is thealternative command over guardedcommands. The alternative command, denoted by a
128
sequenceof“||”separatingguardedcommands,speciﬁesexecutionofexact lyoneofitsconstituent
guarded commands. The guardedcommand has the syntax “ G−→CL” where the guard Gis a
boolean expression and CLis a list of commands that are executed only if Gis true. The guard
expression may contain a term to check if a message from a/any other process has arrived. The
alternativecommandovertheguardedcommandsfailsifallt heguardsfail;ifmorethanoneguard
is true, one of those successful guarded commands is nondete rministically chosen for execution.
WhenaguardedcommandGm−→CLmdoesgetexecuted,theexecutionof CLmisatomicwith
theexecutionof Gm.
Thestructureofdistributedprogramshas similarsemantic stothatofCSP althoughthesyntax
has evolved to something very different. The format for the p seudo-code used in this book is as
indicatedbelow. ThealgorithminFigure5.4serves toillus tratethisformat.
1. The process-local variables whose scope is global to the p rocess, and message types, are
declared ﬁrst.
2. Shared variables, if any, (for distributed shared memory systems) are explicitly labeled as
such.
3. Thisisfollowedbyany initializationcode.
4. Therepetitive and thealternative commandsarenot explicitlyshown.
5. Theguardedcommandsareshownasexplicitmodulesorprocedures(e.g., (1)through(4)in
Figure5.4). Theguard usuallychecks for thearrivalofa mes sageof acertain type, perhaps
withadditionalconditionson someparametervaluesand oth erlocalvariables.
6. The body of the procedure gives the list of commands to be ex ecuted if the guard evaluates
totrue.
7. Process terminationmay beexplicitlystatedinthebodyo fanyprocedure(s).
8. Thesymbol⊥isusedtodenoteanundeﬁnedvalue. Whenusedinacomparison ,itsvalueis
−∞.
5.5 ElementaryGraphAlgorithms
This section examines elementary distributed algorithms o n graphs. The reader is assumed to
be familiar with the centralized algorithms to solve these b asic graph problems. The distributed
algorithms here introduce the reader to the difﬁculty of des igning distributed algorithms wherein
eachnodehasonlyapartialviewofthegraph(system),thati sconﬁnedtoitsimmediateneighbors.
Further, a node can communicate with only its immediate neig hbors along the incident edges.
Unlessotherwisespeciﬁed, weassumeunweightedundirecte dedges,andasynchronousexecution
by theprocessors. Communicationis bymessage-passingont heedges.
129
(local variables)
intvisited,depth←−0
intparent←−⊥
set ofint Neighbors←−setof neighbors
(message types)
QUERY
(1)ifi=rootthen
(2) visited←−1;
(3) depth←−0;
(4) sendQUERYto Neighbors ;
(5)forround = 1todiameter do
(6) ifvisited = 0then
(7) ifanyQUERYmessages arrive then
(8) parent←−randomly select anode from which QUERYwasreceived;
(9) visited←−1;
(10) depth←−round;
(11) sendQUERYto Neighbors\{senders ofQUERYsreceived inthis round };
(12) delete anyQUERYmessages that arrived inthis round.
Figure 5.2: Spanning tree Algorithm0: The synchronous BFS s panning tree algorithm. The code
shownisforprocessor Pi,1≤i≤n.
Theﬁrst algorithmisasynchronousspanningtree algorithm . Thenextthreeareasynchronous
algorithms to construct spanning trees. These elementary a lgorithms are theoretically important
from a practical perspectivebecause spanningtrees are ave ry efﬁcient form ofinformationdistri-
butionandcollectionin distributedsystems.
5.5.1 Synchronous Single-Initiator Spanning Tree Algorit hm Using Flood-
ing: Algorithm 0
The code for all processes is not only symmetrical, but also p roceeds in rounds. This algorithm
assumes a designated root node, root, which initiates the algorithm. The pseudo-code for each
processPiis shown in Figure 5.2. The root initiates a ﬂooding of QUERY m essages in the graph
to identify tree edges. The parent of a node is that node from w hich a QUERY is ﬁrst received; if
multiple QUERYs are received in the same round, one of the sen ders is randomly chosen as the
parent. Exercise1asksyoutomodifythealgorithmsothatea chnodeidentiﬁesnotonlyitsparent
nodebutalsoall itschildrennodes.
Example: Figure 5.3 shows an example execution of the algorithm. The r esulting tree is shown
in boldface, and the round numbers in which the QUERY message s are sent are indicated next to
themessages. Thereader shouldtrace throughthisexamplef or clarity. Forexample,at theend of
round2,EreceivesaQUERYfromBandFandrandomlychoosesFa stheparent. Atotalofnine
QUERY messagesaresent inthenetworkwhich haseightlinks.
130
/0/0/0/1/1/1/0/0/0/1/1/1
/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/0/0/0/0/0/0/1/1/1/1/1/1B C A
E D F(1)
(2)(2)(2) (1)
(3)(3)
(3)(3) QUERY
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/1/1/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1/0/0/1/1/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1 /0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1 /0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/0/0/0/0/0/1/1/1/1/1
/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1
/0/0/0/0/1/1/1/1
Figure 5.3: Example execution of the synchronous BFS spanni ng tree algorithm of Figure 5.2
(Algorithm0).
Termination: The algorithm terminates after all the rounds are executed. It is straightforward to
modifythealgorithmsothataprocessexitsaftertheroundi nwhichitsetsits parentvariable(See
Exercise1).
Complexity:
•Thelocalspacecomplexityat anodeisoftheorderofthedegr eeofedgeincidence.
•Thelocaltimecomplexityatanodeisoftheorderof(diamete r+degreeofedgeincidence).
•Theglobalspacecomplexityisthesumofthelocal spacecomp lexities.
•This algorithm sends at least 1 messages per edge, and at most 2 messages per edge. Thus
thenumberofmessagesisbetween land2l.
•Themessagetimecomplexityis droundsormessagehops.
The spanning tree obtained is a Breadth-First Tree (BFS). Al though the code is the same for all
processes, the predesignated root executes a different log ic to being with. Hence, in the strictest
sense, thealgorithmisasymmetric.
5.5.2 AsynchronousSingle-InitiatorSpanningTreeAlgori thmUsingFlood-
ing: Algorithm I
This algorithm assumes a designated root node which initiat es the algorithm. The pseudo-code
for each process Piis shown in Figure 5.4. The root initiates a ﬂooding of QUERY m essages in
the graph to identify tree edges. The parent of a node is that n ode from which a QUERY is ﬁrst
received; an ACCEPT message is sent in response to such a QUER Y. Other QUERY messages
received are replied to by a REJECT message. Each node termin ates its algorithm when it has
131
(local variables)
intparent←−⊥
set ofint Children,Unrelated ←−∅
set ofint Neighbors←−setof neighbors
(message types)
QUERY,ACCEPT,REJECT
(1) When the predesignated root node wants toinitiate the al gorithm:
(1a)if(i=rootandparent =⊥)then
(1b) sendQUERYto allneighbors;
(1c) parent←−i.
(2) When QUERYarrives from j:
(2a)ifparent =⊥then
(2b) parent←−j;
(2c) sendACCEPTto j;
(2d) sendQUERYto allneighbors except j;
(2e) if(Children∪Unrelated ) = (Neighbors/{parent})then
(2f) terminate .
(2g)else send REJECTto j.
(3) When ACCEPTarrives from j:
(3a)Children←−Children∪{j};
(3b)if(Children∪Unrelated ) = (Neighbors/{parent})then
(3c) terminate .
(4) When REJECTarrives from j:
(4a)Unrelated←−Unrelated∪{j};
(4b)if(Children∪Unrelated ) = (Neighbors/{parent})then
(4c) terminate .
Figure 5.4: Spanning tree Algorithm I: The asynchronous alg orithm assuming a designated root
thatinitiatesaﬂooding. Thecodeshownis forprocessor Pi,1≤i≤n.
receivedfromallitsnon-parentneighborsaresponsetothe QUERYsenttothem. Theprocedures
(1), (2), (3), and (4)areeach executedatomically.
Inthisasynchronoussystem,thereisnoboundonthetimeitt akestopropagateamessage,and
hence no notion of a message round. Unlike in the synchronous algorithm, each node here needs
to track its neighbours to determine which nodes are its chil dren and which nodes are not. This
tracking is necessary in order to know when to terminate. Aft er sending QUERY messages on
the outgoing links, the sender needs to know how long to keep w aiting. This is accomplished by
requiring each node to return an “acknowledgement” for each QUERY it receives. The acknowl-
edgementmessagehas tobeofa differenttypethan theQUERY t ype. Thealgorithmin theﬁgure
uses two messages types – called as ACCEPT (+ ack) and REJECT ( - ack) – besides the QUERY
todistinguishbetween thechildnodes andnon-childnodes.
132
Complexity:
•Thelocalspacecomplexityat anodeisoftheorderofthedegr eeofedgeincidence.
•Thelocaltimecomplexityat anodeisalsooftheorderofthed egreeofedgeincidence.
•Theglobalspacecomplexityisthesumofthelocal spacecomp lexities.
•This algorithm sends at least 2 messages (QUERY and its respo nse) per edge, and at most
4 messages per edge (when two QUERIES are sent concurrently, each will have a REJECT
response). Thus thenumberofmessages isbetween 2land4l.
•Themessagetimecomplexityis (d+ 1)messagehops,assumingsynchronouscommunica-
tion. In an asynchronoussystem, wecannot make any claim abo ut thetree obtained,and its
depth may be equal to the length of the longest path from the ro ot to any other node, which
isboundedonlyby n−1correspondingto adepth-ﬁrsttree.
Termination: Theterminationconditionisgivenabove. Somenotesondist ributedalgorithmsare
inplace. Insomealgorithmssuchasthisalgorithm,itispos sibletolocallydeterminethetermina-
tioncondition;however,forsomealgorithms,theterminat ionconditionisnotlocallydeterminable
and an explicitterminationdetectionalgorithmneeds tobe executed.
/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1B C A
E D F(1)(1)
QUERY
(3)
(2)(4)
(3)
(5)
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1 /0/0/1/1/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1/0/0/1/1/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1 /0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1 /0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/0/0/0/0/1/1/1/1 /0/0/0/1/1/1
/0/0/0/0/0/0/1/1/1/1/1/1
/0/0/0/1/1/1
/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1
Figure 5.5: Example execution of the asynchronous ﬂooding- based single initiator spanning tree
algorithmofFigure5.4 (AlgorithmI).
Example: Figure5.5showsanexampleexecutionoftheasynchronousal gorithm(i.e.,inanasyn-
chronous system). The resulting spanning tree is shown in bo ldface. The numbers next to the
QUERY messages indicate the approximate chronological ord er in which messages get sent. Re-
callthateachprocedureisexecutedatomically;hencethes endingofamessagesentataparticular
timeistriggeredbythereceiptofacorrespondingmessagea tthesametime. Thesamenumbering
used for messages sent by different nodes implies that those actions occur concurrently and inde-
pendently. ACCEPT and REJECT messages are not shown to keep t he ﬁgure simple. It does not
matterwhen theACCEPT andREJECT messagesaredelivered.
133
1. A sendsaQUERY toBand F.
2. FreceivesQUERYfromAanddeterminesthatAFisa treeedge. FforwardstheQUERYto
E andC.
3. E receives a QUERY from F and determines that FE is a tree edge. E forwards theQUERY
to B and D. C receives a QUERY from F and determines that FC is a tree edge. C forwards
theQUERYtoB and D.
4. BreceivesaQUERYfromE anddeterminesthatEBisa treeedge. Bforwards theQUERY
toA, C, and D.
5. DreceivesaQUERYfromEanddeterminesthatEDisa treeedge. DforwardstheQUERY
toB andC.
EachnodesendsanACCEPTmessage(notshowninﬁgureforsimp licity)backtotheparentnode
fromwhichitreceiveditsﬁrstQUERY.Thisistoenablethepa rent,i.e.,thesenderoftheQUERY,
to recognize that the edge is a tree edge, and to identify its c hild. All other QUERY messages
are negativelyacknowledgedby a REJECT (also notshown fors implicity). Thus, a REJECT gets
sentoneach back-edge(suchas BA)andeach-crossedge(such asBD, BC, andCD)toenablethe
sender of the QUERY on that edge to recognize that that edge do es not lead to a child node. We
can also observe that on each tree edge, two messages (a QUERY and an ACCEPT) get sent. On
each cross-edgeand each back-edge, fourmessages(twoQUER Y and twoREJECT)get sent.
Note that this algorithmdoes not guarantee a breadth-ﬁrst t ree. Exercise 3 asks you to modify
thisalgorithmto obtainaBFS tree.
5.5.3 Asynchronous Concurrent-Initiator Spanning Tree Al gorithm Using
Flooding: Algorithm II
We modify Algorithm I by assuming that any node may spontaneo usly initiate the spanning tree
algorithm provided it has not already been invoked locally d ue to the receipt of a QUERY mes-
sage. The resulting algorithm is shown in Figure 5.6. The cru cial problem to handle is that of
dealing with concurrent initiations, where two or more proc esses that are not yet participating in
thealgorithminitiatethealgorithmconcurrently. Astheo bjectiveistoconstructasinglespanning
tree, two options seem available when concurrent initiatio ns are detected. Note that even though
therecan bemultipleconcurrentinitiations,alonganysin gleedge, onlytwo concurrentinitiations
willbedetected.
Design1: When two concurrent initiations are detected by two adjacen t nodes that have sent a
QUERY from different initiations to each other, the two part ially computed spanning trees
can be merged. However, this merging cannot be done based onl y on local knowledge or
theremightbecycles.
134
(local variables)
intparent,myroot←−⊥
set ofint Children,Unrelated ←−∅
set ofint Neighbors←−setof neighbors
(message types)
QUERY,ACCEPT,REJECT
(1) When the node wants toinitiate thealgorithm asaroot:
(1a)if(parent =⊥)then
(1b) sendQUERY( i)to allneighbors;
(1c) parent,myroot←−i.
(2) When QUERY( newroot)arrives from j:
(2a)ifmyroot < newroot then//discard earlier partial execution due toits lowerpriori ty
(2b) parent←−j;myroot←−newroot;Children,Unrelated ←−∅;
(2c) sendQUERY( newroot)toall neighbors except j;
(2d) ifNeighbors ={j}then
(2e) sendACCEPT( myroot)toj;terminate. //leaf node
(2f)else send REJECT( newroot)toj. //if newroot =myrootthenparentisalready identiﬁed.
//ifnewroot < myroot ignore theQUERY. jwillupdate its root whenit receives QUERY( myroot).
(3) When ACCEPT( newroot)arrives from j:
(3a)ifnewroot =myrootthen
(3b) Children←−Children∪{j};
(3c) if(Children∪Unrelated ) = (Neighbors/{parent})then
(3d) ifi=myrootthen
(3e) terminate .
(3f) else send ACCEPT( myroot)toparent.
//ifnewroot < myroot then ignore the message. newroot > myroot willnever occur.
(4) When REJECT( newroot)arrives from j:
(4a)ifnewroot =myrootthen
(4b) Unrelated←−Unrelated∪{j};
(4c) if(Children∪Unrelated ) = (Neighbors/{parent})then
(4d) ifi=myrootthen
(4e) terminate .
(4f) else send ACCEPT( myroot)toparent.
//ifnewroot < myroot then ignore the message. newroot > myroot willnever occur.
Figure 5.6: Spanning tree Algorithm II (asynchronous) with out assuming a designated root. Ini-
tiatorsuseﬂoodingtostart thealgorithm. Thecodeshownis forprocessor Pi,1≤i≤n.
Example: In Figure 5.7, consider that the algorithm is initiated conc urrently by A, G, and
J. The dotted lines show the portions of the graphs covered by the three algorithms. At this
time, the initiations by A and G are detected along edge BD, th e initiations by A and J are
detected along edge CF, the initiations by G and J are detecte d along edge HI. If the three
135
A
C
DB
E F
JIHG/0/0/1/1
/0/0/1/1
/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1
Figure 5.7: Example execution of the asynchronous ﬂooding- based concurrent initiator spanning
treealgorithmofFigure 5.6(AlgorithmII).
partially computed spanning trees are merged along BD, CF, a nd HI, there is no longer a
spanningtree.
Interestingly, even if there are just two initiations, the t wo partially computed trees may
‘meet’ along multiple edges in the graph, and care must be tak en not to introduce cycles
duringthemergerofthetrees.
Design2: Suppress the instance initiated by one root and continue the instance initiated by the
other root, based on some rule such as tie-breaking using the processor identiﬁer. Again, it
mustbeensuredthat theruleiscorrect.
Example: In Figure 5.7, if A’s initiation is suppressed due to the conﬂ ict detected along
BD, G’s initiation is suppressed due to the conﬂict detected along HI, and J’s initiation is
suppressedduetotheconﬂict detectedalong CF, thealgorit hmhangs.
The algorithm presented below uses the second option, allow ing only the algorithm initiated by
the root with the higher processor identiﬁer to continue. To implement this, the messages need
to be enhanced with a parameter that indicates the root node w hich initiated that instance of the
algorithm. Itisrelativelymoredifﬁculttousetheﬁrstopt iontomergepartiallycomputedspanning
trees.
When aQUERY( newroot)fromjarrivesati, thereare threepossibilities.
newroot>myroot :Processishould suppress its current execution due to its lower prior ity. It
reinitializesthedatastructuresand joins j’ssubtreewith newroot as theroot.
newroot =myroot:j’s execution is initiated by the same root as i’s initiation, and ihas already
identiﬁeditsparent. HenceaREJECT issentto j.
136
newroot<myroot :j’s root has a lower priority and hence idoes not join j’s subtree.isends
a REJECT. jwill eventually receive a QUERY( myroot) fromi; and abandon its current
executionin favourof i’smyroot(oralarger value).
When an ACCEPT( newroot) fromjarrivesati, thereare threepossibilities.
newroot =myroot:The ACCEPT is in response to a QUERY sent by i. The ACCEPT is pro-
cessed normally.
newroot<myroot :The ACCEPT is in response to a QUERY ihad sent to jearlier, butihas
updateditsmyrootto ahighervaluesincethen. IgnoretheACCEPT message.
newroot>myroot :The ACCEPT is in response to a QUERY ihad sent earlier. But inever
updatesitsmyrootto alowervalue. So thiscasecannot arise.
The three possibilities when a REJECT( newroot) fromjarrives atiare the same as for the
ACCEPT message.
Complexity: Thetimecomplexityofthealgorithmis O(l)messages,andthenumberofmessages
isO(nl).
Termination: Aseriousdrawback ofthealgorithmisthatonlytherootknow swhen itsalgorithm
has terminated. To inform the other nodes, the root can send a special message along the newly
constructedspanningtreeedges.
5.5.4 AsynchronousConcurrent-InitiatorDepthFirstSear chSpanningTree
Algorithm: Algorithm III
As in AlgorithmII, this algorithmassumesthat any nodemay s pontaneouslyinitiatethespanning
tree algorithm provided it has not already been invoked loca lly due to the receipt of a QUERY
message. ItdiffersfromAlgorithmIIinthatitisbasedonaD epth-FirstSearch(DFS)ofthegraph
to identify the spanning tree. The algorithm should handle c oncurrent initiations (when two or
more processes that are not yet participating in the algorit hm initiate the algorithm concurrently).
The pseudo-codefor each process Piis shownin Figure 5.8. Theparent of each nodeis that node
fromwhichaQUERYisﬁrstreceived;anACCEPTmessageissent inresponsetosuchaQUERY.
Other QUERY messages received are replied to by a REJECT mess age. The actions to execute
when aQUERY, ACCEPT or REJECT arrivesare nontrivialand the analysis forthevariouscases
(newroot<, =,>myroot )are similartotheanalysisofthesecases forAlgorithmII.
Complexity: Thetimecomplexityofthealgorithmis O(l)messages,andthenumberofmessages
isO(nl).
Termination: Theanalysisis thesameas forAlgorithmII.
5.5.5 Broadcastand Convergecastona Tree
A spanning tree is useful for distributing (via a broadcast) and collecting (via a convergecast)
informationto/fromall thenodes. A genericgraph withaspa nningtree, andtheconvergecast and
137
(local variables)
intparent,myroot←−⊥
set ofint Children←−∅
set ofint Neighbors,Unknown ←−set of neighbors
(message types)
QUERY,ACCEPT,REJECT
(1) When the node wants toinitiate thealgorithm asaroot:
(1a)if(parent =⊥)then
(1b) sendQUERY( i)toi(itself).
(2) When QUERY( newroot)arrives from j:
(2a)ifmyroot < newroot then
(2b) parent←−j;myroot←−newroot;Unknown←−set of neighbours;
(2c) Unknown←Unknown/{j};
(2d) ifUnknown∝\⌉}atio\slash=∅then
(2e) deletesomexfromUnknown ;
(2f) sendQUERY( myroot)tox;
(2g) else send ACCEPT( myroot)toj;
(2h)else if myroot =newroot then
(2i) sendREJECTto j. //if newroot < myroot ignore the query.
//jwillupdate itsroot toahigher root identiﬁer when itreceiv es its QUERY.
(3) When ACCEPT( newroot)orREJECT( newroot)arrives from j:
(3a)ifnewroot =myrootthen
(3b) ifACCEPTmessage arrived then
(3c) Children←−Children∪{j};
(3d) ifUnknown =∅then
(3e) ifparent∝\⌉}atio\slash=ithen
(3f) sendACCEPT( myroot)toparent;
(3g) elsesetias the root; terminate .
(3h) else
(3i) deletesomexfromUnknown ;
(3j) sendQUERY( myroot)tox.
//ifnewroot < myroot ignore thequery. Since sending QUERYto j,ihas updated its myroot.
//jwillupdate its myrootto ahigher root identiﬁer when itreceives aQUERYinitiated byit.
//newroot > myroot willnever occur.
Figure 5.8: Spanning tree Algorithm III (DFS, asynchronous ). The code shown is for processor
Pi,1≤i≤n.
broadcast operationsareillustratedinFigure5.9.
Abroadcastalgorithm on aspanningtree can bespeciﬁed bytwo rules.
BC1.Therootsendstheinformationto bebroadcastto allitschil dren. Terminate.
BC2.When a (nonroot) node receives information from its parent, it copies it and forwards it to
138
broadcast
convergecast
initiated by leavesrootinitiated by root
tree edge 
cross−edge back−edge
Figure 5.9: A generic spanning tree on a graph. The broadcast and convergecast operations are
indicated.
itschildren. Terminate.
Aconvergecast algorithm collects information from all the nodes at the root node in or der to
compute some global function . It is initiated by the leaf nodes of the tree, usually in resp onse to
receivingarequest sentby theroot usingabroadcast. Theal gorithmisspeciﬁed as follows.
CVC1.Leaf nodesends itsreportto itsparent. Terminate.
CVC2.At a nonleaf node that is not theroot: When a report is receive d from all the child nodes,
thecollectivereport issentto theparent. Terminate.
CVC3.At the root: When a report is received from all the child nodes , the global function is
evaluatedusingthereports. Terminate.
Termination: Theterminationconditionfor each nodeinabroadcast as wel l as inaconvergecast
isself-evident.
Complexity: Eachbroadcastandeachconvergecastrequires n−1messagesandtimeequaltothe
maximumheightofthetree h, whichisO(n).
Anexampleoftheuseofconvergecastisasfollows. Supposee achnodehasanintegervariable
associated with the application, and the objective is to com pute the minimum of these variables.
Eachleafnodecanreportitslocalvaluetoitsparent. Whena non-leafnodereceivesareportfrom
all its children, it computes the minimum of those values, an d sends this minimum value to its
parent.
Another example of the use of convergecast is in solving the leader election problem. Leader
election requires that all the processes agree on a common di stinguished process, also termed as
theleader. A leader is required in many distributed systems and algori thms because algorithms
139
(local variables)
intlength←−∞
intparent←−⊥
set ofint Neighbors←−setof neighbors
set ofint{weight i,j,weight j,i|j∈Neighbors}←−theknown values ofthe weights ofincident links
(message types)
UPDATE
(1)ifi=i0thenlength←−0;
(2)forround = 1ton−1do
(3) sendUPDATE( i,length)toall neighbors;
(4) awaitUPDATE( j,length j)from each j∈Neighbors ;
(5) foreachj∈Neighbors do
(6) if(length > (length j+weight j,i)then
(7) length←−length j+weight j,i;parent←−j.
Figure5.10: ThesinglesourcesynchronousdistributedBel lman-Fordshortestpathalgorithm. The
sourceisi0. Thecodeshownis forprocessor Pi,1≤i≤n.
are typically not completely symmetrical, and some process has to take the lead in initiating the
algorithm; another reason is that we would not want all the pr ocesses to replicate the algorithm
initiation,tosaveonresources.
5.5.6 Single Source Shortest PathAlgorithm: Synchronous B ellman-Ford
Given a weighted graph, with potentially unidirectional li nks, representing the network topology,
theBellman-Fordsequentialshortestpath algorithmﬁndst heshortestpathfromagivennode,say
i0, to all other nodes. The algorithm is correct when there are n o cyclic paths having negative
weight.
A synchronousdistributedalgorithm to computetheshortes t path is givenin Figure 5.10. It is
assumed that the topology (N,L)is not known to any process; rather, each process can commu-
nicate only with its neighbors and is aware of only the incide nt links and their weights. It is also
assumed that the processes know the number of nodes |N|=n, i.e., the algorithm is not uniform.
Thisassumptionon nisrequired fortermination.
Thefollowingfeatures can beobservedfrom thealgorithm.
•Afterkrounds, each node has its lengthvariable set to the length of the shortest path con-
sisting of at most khops. Theparentvariable points to the parent node along such a path.
Thisparentﬁeld is usedin theroutingtabletorouteto i0.
•Aftertheﬁrstround,the lengthvariableofallnodesonehopawayfromtherootintheﬁnal
minimumspanning tree (MST) would have stablized; after krounds, thelengthvariable of
allthenodesup to khopsaway intheﬁnal MST wouldhavestabilized.
140
•Termination. Asthelongestpathcanbeoflength n−1,thevaluesofallvariablesstabilize
aftern−1rounds.
•Complexity. The time complexity of this synchronous algorithm is: n−1rounds. The
messagecomplexityofthissynchronousalgorithmis: (n−1)lmessages.
5.5.7 Distance Vector Routing
When the network graph is dynamically changing, as in a real c ommunication network wherein
thelinkweights modelthedelays orloads on thelinks,thesh ortestpaths are required forrouting.
TheclassicDistanceVectorRoutingalgorithm(DVR)usedin theARPANET upto1980,isbased
on theabovesynchronousalgorithm(Figure5.10)andrequir es thefollowingchanges.
•The outer forloop runs indeﬁnitely, and the lengthandparentvariables never stabilize,
becauseofthedynamicnatureofthesystem.
•The variable lengthis replaced by array LENGTH [1..n], whereLENGTH [k]denotes
the length measured with node kas source/root. The LENGTH vector is also included on
each UPDATE message. Now, the kthcomponent of the LENGTH received from node m
indicates the length of the shortest path from mto the rootk. For each destination k, the
triangleinequalityoftheBellman-Fordalgorithmisappli edoverallthe LENGTH vectors
receivedin around.
•The variable parentis replaced by array PARENT [1..n], wherePARENT [k]denotes
the next hop to which to route a packet destined for k. The array PARENT serves as the
routingtable.
•Theprocessesexchangetheirdistancevectorsperiodicall yoveranetworkthatisessentially
asynchronous. If a message does not arrive within the period , the algorithm assumes a
default value,and movestothenext round. Thismakes it virt uallysynchronous. Besides, if
theperiod between exchanges is assumed to bemuch larger tha n the propagationtimefrom
a neighbor and the processing time for the received message, the algorithm is effectively
synchronous.
5.5.8 Single Source Shortest PathAlgorithm: Asynchronous Bellman-Ford
The asynchronous version of the Bellman-Ford algorithm is s hown in Figure 5.11. It is assumed
thatthereare nonegativeweightcyclesin (N,L).
The algorithm does not give the termination condition for th e nodes. Exercise 14 asks you to
modify the algorithm so that each node knows when the length o f the shortest path to itself has
been computed.
This algorithm, unfortunately, has been shown to have an exp onential Ω(cn)number of mes-
sages and exponential Ω(cn·d)time complexity in the worst case, where cis some constant (See
Exercise16).
141
(local variables)
intlength←−∞
set ofint Neighbors←−setof neighbors
set ofint{weight i,j,weight j,i|j∈Neighbors}←−theknown values ofthe weights ofincident links
(message types)
UPDATE
(1)ifi=i0then
(1a) length←−0;
(1b) sendUPDATE( i0,0) to allneighbours; terminate .
(2) When UPDATE( i0,length j)arrives from j:
(2a) if(length > (length j+weight j,i))then
(2b) length←−length j+weight j,i;parent←−j;
(2c) sendUPDATE( i0,length) toall neighbors;
Figure5.11: TheasynchronousdistributedBellman-Fordsh ortestpathalgorithmforagivensource
i0. Thecodeshownisforprocessor Pi,1≤i≤n.
If all links are assumed to have equal weight, the algorithm w hich computes the shortest path
effectively computes the minimum-hop path; the minimum-ho p routing tables to all destinations
are computedusing O(n2·l)messages. (See Exercise17).
5.5.9 AllSourcesShortestPaths: AsynchronousDistribute dFloyd-Warshall
The Floyd-Warshall algorithm computes all-pairs shortest paths in a graph in which there are no
negative weight cycles. It is brieﬂy summarized ﬁrst, befor e a distributed version is studied. The
centralized algorithmuses n×nmatricesLENGTH andVIA.
LENGTH [i,j]isthelengthoftheshortestpathfrom itoj.LENGTH [i,j]isinitializedtothe
initial known conditions: (i) weight i,jifiandjare neighbours, (ii) 0 if i=j, and (iii)∞
otherwise.
VIA[i,j]is the ﬁrst hop on the shortest path from itoj.VIA[i,j]is initialized to the initial
knownconditions: (i) jifiandjareneighbours,(ii)0 if i=j, and (iii)∞otherwise.
Afterpivotiterationsoftheouterloop,thefollowing invariant holds:
“LENGTH [i,j]is the shortest path going through intermediate nodes from t he set
{i,...,pivot}.VIA[i,j]isthecorrespondingﬁrst hop.”
Convince yourself of this invariant using the code in Figure 5.12 and Figure 5.13. In this ﬁgure,
the LEN is for the paths that pass through nodes from {1...pivot−1}. The time complexity of
thecentralized algorithmis O(n3).
142
(1)forpivot= 1tondo
(2)fors= 1tondo
(3) fort= 1tondo
(4) ifLENGTH [s, pivot ] +LENGTH [pivot, t ]< LENGTH [s, t]then
(5) LENGTH [s, t]←−LENGTH [s, pivot ] +LENGTH [pivot, t ];
(6) V IA[s, t]←−V IA[s, pivot ].
Figure5.12: Thecentralized Floyd-Warshallall-pairs sho rtestpaths routingalgorithm.
The distributed asynchronous algorithm is shown in Figure 5 .14. Rowiof theLENGTH
andVIAdata structures is stored at node iwhich is responsible for updating this row. To avoid
ambiguity, we rename these data structures as LENandPARENT , respectively. When the
algorithmterminates,theﬁnal valuesofrow iofLENGTH is availableatnode iasLEN.
passes through nodes inpasses through nodes in
{1,2,...,pivot−1}{1,2,...,pivot−1}s d
pivot{1,2,...,pivot−1}passes through nodes in
LEN[s,pivot]LEN[pivot,d]LEN[s,d]
(a) (b)VIA(s,d)VIA((VIA(s,d), d)d
s
Figure5.13: Theall-pairsshortestpathsalgorithmbyFloy d-Warshall. (a)Triangleinequalityused
in iterationpivotuses paths via{1,...,pivot−1}. (b) TheVIArelationships along a branch of
thesinktreeforagiven (s,d)pair.
There aretwochallenges inmakingtheFloyd-Warshallalgor ithmdistributed.
1. How to access the remote datum LENGTH [pivot,t ]for each execution of line (4) in the
centralized algorithmofFigure5.12,nowbeing executedby i?
2. How to synchronize the execution at the different nodes? I f the different nodes are not
executing the same iteration of the outermost loop of Figure 5.12, the distributed algorithm
becomesincorrect.
Theproblemofaccessingtheremotedatum LENGTH [pivot,t ]issolvedbyusingtheideaof
the distributed sink tree. In the centralized algorithm, after each iteration pivotof the outermost
loop, ifLENGTH [s,t]∝\⌉}atio\slash=∞, thenVIA[s,t]pointsto the parent nodeon thepath to tand this is
theshortestpathgoingthroughnodes {1...pivot}. Observethat VIA[VIA[s,t],t]willalsopoint
toVIA[s,t]’sparentnodeontheshortestpathto t,andsoon. Effectively,tracingthroughthe VIA
nodes gives the shortest path to dest; this path is acyclic because of the “shortest path” propert y
143
(local variables)
array ofint LEN[1..n] //LEN[j]is thelength of the shortest known path from itonode j.
//LEN[j] =weight ijfor neighbor j, 0for j=i,∞otherwise
array ofint PARENT [1..n]//PARENT [j]isthe parent of node i(myself) on thesink tree rooted at j.
//PARENT [j] =jforneighbor j,⊥otherwise
set ofint Neighbours←−setof neighbors
intpivot,nbh←−0
(message types)
IN_TREE( pivot),NOT_IN_TREE( pivot),PIV_LEN( pivot,PIV OT _ROW [1..n])
//PIV OT_ROW [k]isLEN[k]of node pivot, which is LEN[pivot,k ]in the central algorithm
//the PIV_LENmessage isused toconvey PIV OT_ROW.
(1)forpivot= 1tondo
(2)foreach neighbour nbh∈Neighbours do
(3) ifPARENT [pivot] =nbhthen
(4) sendIN_TREE( pivot)tonbh;
(5) else send NOT_IN_TREE( pivot)tonbh;
(6)awaitIN_TREEorNOT_IN_TREEmessage from each neighour;
(7)ifLEN[pivot]∝\⌉}atio\slash=∞then
(8) ifpivot∝\⌉}atio\slash=ithen
(9) receivePIV_LEN( pivot,PIV OT _ROW [1..n])from PARENT [pivot];
(10) foreach neighbour nbh∈Neighbours do
(11) ifIN_TREEmessage was received from nbhthen
(12) ifpivot=ithen
(13) sendPIV_LEN( pivot,LEN [1..n]) tonbh;
(14) else send PIV_LEN( pivot,PIV OT _ROW [1..n])tonbh;
(15) fort= 1tondo
(16) ifLEN[pivot] +PIV OT_ROW [t]< LEN [t]then
(17) LEN[t]←−LEN[pivot] +PIV OT_ROW [t];
(18) PARENT [t]←−PARENT [pivot].
Figure 5.14: Toueg’s asynchronous distributed Floyd-Wars hall all-pairs shortest paths routing al-
gorithm. Thecodeshownisforprocessor Pi,1≤i≤n.
(seeinvariant ). Thus, all nodes sfor whichLENGTH [s,t]∝\⌉}atio\slash=∞are part of a tree to t, and this
tree is termed as a sink tree, withtas the root or the sink node . In the distributed algorithm, the
parent ofanynodeonthesinktreefor destisstored inPARENT [t].
Applying the sink tree idea to node pivotin iteration pivotof the distributed algorithm, we
havethefollowingobservationsforanynode iin anyiteration pivot.
•IfLEN[pivot] =∞,theniwillnotupdateits LENandPARENT arraysinthisiteration.
Hence there is no need for ito receive the remotedata PIV_ROW [1,...,n ]. In fact, there
isno knownpath from itopivotat thisstage.
•IfLEN[pivot]∝\⌉}atio\slash=∞,thentheremotedata PIVOT_ROW [1,...,n ]isdistributedtoallthe
144
nodeslyingonthesinktreeof pivot. Observethat inecessarilyliesonthesinktreeof pivot.
Theparent of i, anditsparent’s parent,and so on,all lieon thatsinktree.
The asynchronous distributed algorithm proceeds as follow s. It iteration pivot, nodepivot
broadcastsits LENvectoralongitssinktree. Toimplementthisbroadcast,the parent-childedges
of the sink tree need to be identiﬁed. Note that any node on the sink tree of pivotdoes not know
which of its neighbours are its children. Hence, each node aw aits a IN_TREE or NOT_IN_TREE
messagefromeachofitsneighbours(lines(2)-(6))toident ifyitchildren. Theseﬂowsseenatnode
iareillustratedinFigure5.15. Thebroadcastofthepivot’s LENvectorisinitiatedbynode pivot
inlines (10)-(13). Forexample,considertheﬁrst iteratio n,wherepivot= 1.
Node1.Thenodeexecutes(1),(2)-(5)bysendingNOT_IN_TREE,(6)i nwhichitgetsIN_TREE
messagesfromitsneighbours,(10)-(13)whereinthenodese ndsitsLENvectortoitsneigh-
bours.
Node> 1. In line (1)-(4), the neighbours of node 1 send IN_TREE to node 1. In line (9), the
neighboursreceive PIVOT_LENfrom thepivot,i.e.,node1. Thereadercan stepthrough
theremainderoftheprotocol.
WhenireceivesPIV_LENmessagecontainingthepivot’s PIVOT_ROW [1..n]fromitsparent
(line (9)), it forwards it to its children (lines (10)-(12) a nd (14)). The two inner loops of the
centralized algorithmare thenexecutedin lines(15)-(18) ofthedistributedalgorithm.
The inherent distribution of PIVOT_ROWin lines (9)-(12) via the receivefrom the parent
(line(9))and sendtothechildren(line(14)), aswellasthesynchronizationo fthesend(lines(4)-
(5)) andreceive(line (6)) of IN_TREE and NOT_IN_TREE messages among neighb our nodes
ensures that the asynchronous execution of the nodes gets sy nchronized and all nodes are forced
toexecutetheinnermostnestediterationconcurrentlywit heachother. Noticealsothedependence
between the sendof lines (4)-(5) and receiveof line (6), and between the receiveof line (9) and
thesendoflines(13)or(14).
The techniques for synchronizationused here will be formal ized in Section 5.6 under thesub-
ject ofsynchronizers.
Complexity: In each of the niterations of the outermost loop, two IN_TREE or NOT_IN_TRE E
messages are sent per edge, and at most n−1PIV_LEN messages are sent. The overall number
of messages is n·(2l+n). The PIV_LEN is of size nwhile the IN_TREE and NOT_IN_TREE
messages are of size O(1). The execution time complexity per node is O(n2), plus the time for n
convergecast-broadcast phases.
5.5.10 Asynchronous and Synchronous Constrained Flooding (w/o a Span-
ning Tree)
Asynchronous algorithm (Figure5.16). This algorithm allows any process to initiate a broad-
cast via (constrained) ﬂooding along the edges of the graph. It is assumed that all chan-
nels are FIFO. Duplicates are detected by using sequence num bers. Each process uses the
145
B
CAiNOT_IN_TREE(pivot)
NOT_IN_TREE(pivot)NOT_IN_TREE(pivot)
IN_TREE(pivot)
IN_TREE(pivot)NOT_IN_TREE(pivot)
Figure 5.15: Message ﬂows to determine how to selectively di stributePIV_ROWin iteration
pivotinToueg’sdistributedFloyd-Warshallalgorithm.
SEQNO [1..n]vector, where SEQNO [k]tracks the latest sequence number of the update
initiated by process k. If the sequence number on a newly arrived message is not grea ter
than the sequence numbers already seen for that initiator, t he message is simply discarded;
otherwise, it is ﬂooded on all other outgoing links. This mec hanism is used by the Link
State Routing protocol in the Internet to distribute any upd ates about the link loads and the
networktopology.
Complexity: The message complexity is: 2lmessages in the worst case, where each mes-
sageisofsize|M|. Thetimecomplexityis: diameter dnumberofsequentialhops.
Synchronous algorithm(Figure 5.17). Thisalgorithmallowsallprocessestoﬂood alocal value
throughout the network. The local array STATEVEC [1..n]is such that STATEVEC [k]
istheestimateofthelocalvalueofprocess k. Afterdnumberofrounds,itisguaranteedthat
thelocalvalueofeach processhas propagatedthroughoutth enetwork.
Complexity: The time complexity is: diameter drounds, and the message complexity is:
2l·dmessages, each ofsize n.
5.5.11 MinimumWeightSpanningTree(MST)AlgorithminaSyn chronous
System
A minimum spanning tree (MST) minimizes the cost of transmis sion from any node to any other
node in the graph. The classical centralized MST algorithms such as those by Prim, Dijkstra, and
Kruskalassumethattheentireweightedgraph is availablef orexamination.
•Kruskal’salgorithmbeginswithaforestofgraphcomponent s. Ineach iteration,itidentiﬁes
the minimum-weight edge that connects two different compon ents, and uses this edge to
merge two components. This continues until all the componen ts are merged into a single
component.
146
(local variables)
array ofint SEQNO [1..n]←−0
set ofint Neighbors←−setof neighbors
(message types)
UPDATE
(1) Tosend amessage M:
(1a)ifi=rootthen
(1b) SEQNO [i]←−SEQNO [i] + 1;
(1c) sendUPDATE( M,i,SEQNO [i])toeach j∈Neighbors .
(2) When UPDATE( M,j,seqno j)arrives from k:
(2a)ifSEQNO [j]< seqno jthen
(2b) Process the message M;
(2c) SEQNO [j]←−seqno j;
(2d) sendUPDATE( M,j,seqno j)toNeighbors/{k}
(2e)elsediscard themessage.
Figure5.16: Theasynchronousﬂoodingalgorithm. Thecodes hownisforprocessor Pi,1≤i≤n.
Anyand allnodes can initiatethealgorithmspontaneously.
(local variables)
array ofint STATEV EC [1..n]←−0
set ofint Neighbors←−setof neighbors
(message types)
UPDATE
(1)STATEV EC [i]←−local value;
(2)forround = 1todiameter ddo
(3) sendUPDATE( STATEV EC [1..n]) toeach j∈Neighbors ;
(4) forcount = 1to|Neighbors|do
(5) awaitUPDATE( SV[1..n]) from some j∈Neighbors ;
(6) STATEV EC [1..n]←−max(STATEV EC [1..n],SV[1..n]).
Figure 5.17: The synchronous ﬂooding algorithm for learnin g all node’s identiﬁers. The code
shownisforprocessor Pi,1≤i≤n.
•In Prim’s algorithm and Dijkstra’s algorithm, a single-nod e component is selected. In each
iteration, a minimum weight edge incident on the component i s identiﬁed, and the compo-
nent expands to include that edge and the node at the other end of that edge. After n−1
iterations, all the nodes are included. The MST is deﬁned by t he edges that are identiﬁed in
each iterationto expandtheinitialcomponent.
In a distributed algorithm, each process can communicate on ly with its neighbors and is aware of
only the incident links and their weights. It is also assumed that the processes know the value of
147
|N|=n. The weight of each edge is unique in the network, which is nec essary to guarantee a
unique MST. (If weights are not unique, the IDs of the nodes on which they are incident can be
used astie-breakers bydeﬁning awell-formedorder.)
AdistributedalgorithmthatgeneralizesthestrategyofKr uskal’scentralizedalgorithmisgiven
after reviewing some deﬁnitions. A forest(i.e., a disjoint union of trees) is a graph in which any
pair of nodes is connected by at most one path. A spanning forest of an undirected graph (N,L)
is a maximal forest of (N,L), i.e., an acyclic and not necessarily connected graph whose set of
verticesisN. When aspanningforestis connected,it becomesa spanningtree .
A spanning forest of Gis a subgraph G′ofGhaving the same node set as G; the spanning
forest can be viewed as a set of spanning trees, one spanning t ree per “connected component” of
G′. All MST algorithms begin with a spanning forest having nnodes (or connected components)
and without any edges. They then add a ‘ minimum weight outgoing edge ’ (MWOE) between
two components.2The spanningtrees ofthe combiningconencted componentsco mbinewiththe
MWOEtoformasinglespanningtreeforthecombinedconnecte dcomponent. Theadditionofthe
MWOE is repeated until a spanning tree is produced for the ent ire graph (N,L). Such algorithms
are correct becauseofthefollowingobservation.
Observation1. Foranyspanningforest {(Ni,Li)|i= 1...k}ofaweightedundirectedgraph G,
consideranycomponent (Nj,Lj). Denoteby λj,theedgehavingthesmallestweightamongthose
thatareincidentononlyonenodein Nj. Then anMSTforthegraph Gthatincludesalltheedges
ineachLiin thespanningforest,mustalsoincludeedge λi.
Thisobservationsaysthatforany“minimumweight”compone ntcreatedsofar,whenitgrows
by joininganother component, the growth must be via the MWOE for that component under con-
sideration. Intuitively,the logic is as follows. For any co mponent containing node set Nj, if edge
xis usedinsteadoftheMWOE λjto connectwithnodes in N\Nj, thentheresultingtreecannot
be a MST because edge xcan always be replaced with the MWOE that was not chosen to yie ld a
lowercost tree.
Consider Figure 5.18(a) where three components have been id entiﬁed and are encircled. The
MWOEforeachcomponentismarkedbyanoutgoingedge(othero utgoingedgesarenotshown).
Each of the three componentsshown mustgrow only by merging w ith the component at theother
end oftheMWOE.
In a distributed algorithm, the addition of the edges should be done concurrently by having
all the components identify their respective minimum-weig ht outgoing edge. The synchronous
algorithm of Gallagher-Humblet-Spira uses this above obse rvation, and is given in Figure 5.19.
Initially, each node is the leader of its component which con tains only that node. The algorithm
useslog(n)iterations. Ineachiteration,eachcomponentmergeswitha tleastoneothercomponent.
Hence,log(n)iterationsguarantee terminationwithasinglecomponent.
Eachiterationgoesthroughabroadcast-convergecast-bro adcastsequencetoidentifytheMWOE
ofthecomponent,andtoselectthe leaderforthenextiteration. TheMWOEisidentiﬁedafterthe
2Note that thisisan undirectedgraph. Thedirectionofthe “o utgoing”edgeislogicalin the sense thatit identiﬁes
thedirectionofexpansionoftheconnectedcomponentunder consideration.
148
CAB BA
C
(b) (a)
Figure 5.18: Merging of MWOE components. (a) A cycle of lengt h 2 is possible. (b) A cycle of
lengthgreaterthan 2 isnotpossible.
broadcast (Steps 1 and 2) and convergecast (Step 3) by the cur rent leader, which then does a sec-
ond broadcast (Step 4). The leader is selected at theend of th is second broadcast (Step 4); among
all the components that merge in an iteration, a single leade r is selected, and it identiﬁes itself
among all the nodes in the newly-forming component by doing a third broadcast (Step 5). This
sequenceofstepscanbevisualizedusingtheconnectedcomp onentenclosedwithinarectanglein
Figure 5.20, using the following narrative. (a) Root broadc asts SEARCH_MWOE; (b) Converge-
cast REPLY_MWOE occurs. (c) Root broadcasts ADD_MWOE;(d)I f theMWOE is alsochosen
as the MWOE by the component at the other end of the MWOE, the in cident process with the
higherID is theleader forthenextiterationand broadcasts NEW_LEADER.
The correctness of the above algorithm hinges on the fact tha t in any iteration, when each
componentofthespanningforestjoinswithoneormoreother componentsofthespanningforest,
the result is still a spanning forest! Observe that each comp onent picks exactly oneMWOE with
whichitconnectstoanothercomponent. However,morethant wocomponentscanjointogetherin
oneiteration. Ifmultiplecomponentsjoin,weneed toobser vethattheresultingcomponentisstill
a spanning forest. To do so, model a directed graph (P,M)wherePis the set of components at
the start of an iteration and Mis the set of|P|MWOE edges chosen by the components in P. In
thisgraph,thereisexactlyoneoutgoingedgefromeachnode inP. Recallthatthedirectionofthe
MWOE is logical; theunderlying graph remains undirected. I f component Achooses to includea
MWOE leading to component B, then directed edge (A,B)existsin (P,M). By tracing anypath
in this graph, observe that MWOE weights must be monotonical ly decreasing. To see that (i) the
merging of components retains the spanning forest property , and that (ii) there is a unique leader
ineach componentafter themergerinthepreviousround, con siderthefollowingtwocases.
1. If two components join, then each must have picked the othe r to join with, and we have a
cycle of length two. As each component was a spanning forest, joining via the common
MWOE still retains the spanning forest property, and there i s a unique leader in the merged
component.
149
(message types:)
SEARCH_MWOE (leader ) //broadcast by current leader ontree edges
EXAMINE (leader ) //sent on non-tree edges after receiving SEARCH_MWOE
REPLY_MWOES (local_ID,remote _ID)//details ofpotential MWOEsare convergecast toleader
ADD_MWOE (local_ID,remote _ID) //sent by leader toadd MWOEand identify new leader
NEW_LEADER (leader ) //broadcast by new leader after merging components
leader =i;
forround=1tolog(n)do // each merger ineach iteration involves atleast twocompon ents
1.ifleader =ithen
broadcast SEARCH_MWOE( leader)along marked edges oftree (Sect. 5.5.5).
2. Onreceiving aSEARCH_MWOE( leader)message that wasbroadcast onmarked edges:
(a) Eachprocess i(including leader)sendsanEXAMINEmessagealongunmarked(i.e.,non-tree)
edgestodetermineiftheotherendoftheedgeisinthesameco mponent(i.e.,whetheritsleader
isthe same).
(b) From among all incident edges at i, for which the other end belongs to a different component,
process ipicks itsincident MWOE(localID,remoteID).
3. The leaf nodes in the MST within the component initiate the convergecast (Sect. 5.5.5) using RE-
PLY_MWOEs, informing their parent of their MWOE(localID,r emoteID). All the nodes participate
in this convergecast.
4.ifleader =ithen
awaitconvergecast replies along marked edges.
Select the minimum MWOE(localID,remoteID) from all the rep lies.
broadcast ADD_MWOE(localID,remoteID) along marked edges of tree (Se ct. 5.5.5).
//Toask process localIDtomark the (localID,remoteID )edge,
//i.e., include itin MSTofcomponent.
5.ifan MWOEedge gets marked byboth thecomponents on which itis i ncidentthen
(a) Deﬁne new_leader as the process with the larger ID on which that MWOE is inciden t (i.e.,
process whose ID is max(localID,remoteID )).
(b)new_leader identiﬁes itself asthe leader for the nextround.
(c)new_leader broadcasts NEW_LEADER in the newly formed component along the marked
edges (Sect. 5.5.5) announcing itself asthe leader for the n ext round.
Figure5.19: ThesynchronousMSTalgorithmbyGallagher-Hu mblet-Spira(GHSalgorithm). The
codeshownisforprocessor Pi,1≤i≤n.
2. Ifthreeormorecomponentsjoin,thentwo sub-casesare po ssible.
•There is some cycle of length three or more (see Figure 5.18(b )). But as any path in
(P,M)follows MWOEs of monotonically decreasing weights, this im plies a contra-
150
cross edgeout−edge tree edge
root of component(MWOE)112116112
1314 3487 442754 88
43
16
/0/0/1/1/0/0/1/1
Figure5.20: Thephases withinan iterationin acomponent.
dictionbecauseat least onenodemusthavechosen an incorre ct MWOE.
•There is no cycle of length 3 or more, and at least one node in (P,M)will have two
or more incoming edges (component C in Figure 5.18(a)). Furt her, there must exist a
cycle of length two. Exercise 22 asks you to prove this formal ly. As the graph has a
cycle of length at most two (Case (1)), the resulting compone nt after the merger of all
the involved components is still a spanning component, and t here is a unique leader
in the merged component. That leader is the node with the larg er PID incident on the
MWOE thatgets markedby bothcomponentson whichitis incide nt.
Complexity:
•In each of the log(n)iterations, each component merges with at least one other co mponent.
So after the ﬁrst iteration, there are at most n/2components, after the second, at most n/4
components,andsoon. Hence,atmost log(n)iterationsareneededandthenumberofnodes
in each component after iteration kis at least 2k. In each iteration, the time complexity
isO(n)because the time complexity for broadcast and convergecast is bounded by O(n).
Hencethetimecomplexityis O(n·log(n))
•In each of the log(n)iterations,O(n)messages are sent along the marked tree edges (steps
(1), (3), (4), and (5)). There may be up to l=|L|EXAMINE messages to determine the
MWOEs in step (2) of each iteration. Hence, the total message complexity is O((n+l)·
log(n)).
The correctness of the GHS algorithm hinges on the fact that t he execution occurs in syn-
chronous rounds. This is necessary in Step (2), where a proce ss sends EXAMINE messages to
its unmarked neighbors to determine whether those neighbor s belong to the same or a different
component than itself. If the neighbor is not synchronized, problems can occur. For example,
151
consider edge (j,k), wherejandkbecome a part of the same component in ‘iteration’ x. From
j’sperspective,theneighbor kmaynotyethavereceiveditsleader’sIDthatwasbroadcasti nstep
(5)ofthepreviousiteration;hence krepliestotheEXAMINEmessagesentby jbasedonanolder
IDforitsleader. Thetestingprocess jmay(incorrectly)include kinthesamecomponentasitself,
thereby creating cycles in thegraph. As thedistancefrom th eleader to anynodein itscomponent
is not known, this needs to be dealt with even in a synchronous system. One way to enforce the
synchronicity is to wait for O(n)number of communication steps; this way, all communication
withintheround wouldhavecompletedinthesynchronousmod el.
5.5.12 Minimum Weight Spanning Tree(MST)inanAsynchronou s System
Thereare twoapproaches to designingtheasynchronousMST a lgorithm.
In theﬁrst approach, thesynchronousGHSalgorithmis simulated in an asynchronoussetting.
Insuchasimulation,thesamesynchronousalgorithmisrun, butisaugmentedbyadditionalproto-
col steps and control messages to provide the synchronicity . Observe from the synchronous GHS
that the difﬁculty in making it asynchronous lies in Step (2) . If the two nodes at the ends of an
unmarkededgeareindifferentlevels,thealgorithmcangow rong. Twopossiblewaystodealwith
thisproblemareas follows.
•Aftereach round,anadditionalbroadcastandconvergecast onthemarkededgesareserially
done. The newly identiﬁed leader broadcasts its ID and round number on the tree edges;
the convergecast is then initiated by the leaves to acknowle dge this broadcast. When the
convergecast completes at the leader, it then begins the nex t round. Now in Step (2), if the
recipient of an EXAMINE message is in an earlier round, it sim ply delays the response to
theEXAMINE,thusforcingsynchrony.
Thiscostsn·log(n)extramessagesand increases themessagecomplexity.
•Whenanodegetsinvolvedinanewround,itsimplyinformseac hneighbor(reachablealong
unmarked or non-tree edges) of its new level. Only when the ne ighbors along unmarked
edges areall inthesameround thatthenodesends theEXAMINE messages inStep (2).
Thiscosts|L|·log(n)extramessagesand increases themessagecomplexity.
The second approach to designing the asynchronous MST is to d irectly address all the difﬁ-
culties that arise due to lack of synchrony. The original asy nchronous GHS algorithm uses this
approach even though it is patterned along the synchronous G HS algorithm. By carefully engi-
neering the asynchronous algorithm, it achieves the same me ssage complexity O(n·log(n) +l)
and the same time complexity O(n·log(n)·(l+d))as the synchronous algorithm. We do not
present the algorithm here because it is a well-engineered a lgorithm with intricate details; rather,
weonlypointoutsomeofthedifﬁcultiesin designingthisal gorithm.
•In step (2), ifthetwo nodes arein different componentsorin differentlevels,thereneeds to
beamechanismtodeterminethis.
152
•If the combining of components at different levels is permit ted, then some component may
keepcombiningwithonlysingle-nodecomponentsinthewors t-case,therebyincreasingthe
complexitybychangingthe log(n)factor tothefactor n.
•The search for MWOEs by adjacent components at different lev els needs to be coordinated
carefully. Speciﬁcally, the rules for merging such compone nts, as well as the rules for the
concurrent search fortheMWOEby thesetwo componentsneed t o bespeciﬁed.
5.6 Synchronizers
General Observations on Synchronous and Asynchronous Algo rithms:From the spanning
tree algorithms, shortest path routing algorithms, constr ained ﬂooding algorithms, and the MST
algorithms, it can be observed that it is much more difﬁcult t o design the algorithm for an asyn-
chronous system, than for a synchronous system. This can be g eneralized to all algorithms, with
fewexceptions. Theexamplealgorithmsalsosuggestthatsi mulatingsynchronousbehavior(ofan
algorithmdesignedfor a synchronoussystem)on an asynchro noussystemis often a direct way to
realizethealgorithmson asynchronoussystems.
Given that typical distributed systems are asynchronous, t he logical question to address is
whetherthereisageneraltechniquetoconvertanalgorithm designedforasynchronoussystem,to
runonanasynchronoussystem. Thegenericclassoftransfor mationalgorithmstorunsynchronous
algorithms on asynchronous systems are called synchronizers . We make the following observa-
tions. (1) We consider only failure-free systems, whether s ynchronous or asynchronous. We will
later see (in Chapter ??) that such transformations may not be possible in asynchron ous systems
in which either processes fail or channels are unreliable. ( 2) Using a synchronizerprovides a sure
way to obtain an asynchronous algorithm. However, such an al gorithm may have high complex-
ity. Although more difﬁcult, it may be possible to design mor e efﬁcient asynchronous algorithms
from scratch, rather than transforming the synchronous alg orithms to run on asynchronous sys-
tems. (This was seen in the case of the GHS algorithm.) Thus, t he ﬁeld of systematic algorithm
designforasynchronoussystemsis an openand challengingﬁ eld.
Practically speaking, inan asynchronoussystem,asynchro nizerisa mechanismthat indicates
to each process when it is safe to proceed to the next round of e xecution of the “synchronous”
algorithm. Conceptually,thesynchronizersignalstoeach processwhenitissurethatallmessages
tobereceived inthecurrent roundhavearrived.
The mesage complexity Maand time complexity Taof the asynchronous algorithm are as
follows.
Ma=Ms+ (Minit+rounds·Mround) (5.1)
Ta=Ts+Tinit+rounds·Tround (5.2)
•Msisthenumberofmessagesin thesynchronousalgorithm.
•roundsisthenumberofroundsinthesynchronousalgorithm.
153
Simplesynchronizer αsynchronizer βsynchronizer γsynchronizer
Minit 0 0 O(n·log(n) +|L|) O(kn2)
Tinit d 0 O(n) n·log(n)/log(k)
Mround 2|L| O(|L|) O(n) O(Lc) (≤O(kn))
Tround 1 O(1) O(n) O(hc) (≤O(log(n)/log(k)))
Table 5.1: The message and time complexities for the simple,α,β, andγsynchronizers. hcis
the greatest height of a tree among all the clusters. Lcis the number of tree edges and designated
edges intheclusteringschemeforthe γsynchronizer. dis thegraph diameter.
•Tsis the time for the synchronous algorithm. Assuming one unit (message hop) per round,
thisequalsrounds.
•Mroundis thenumberofmessages needed tosimulatearound,
•Troundisthenumberofsequentialmessagehops needed tosimulatea round.
•MinitandTinitare the number of messages and the number of sequential messa ge hops,
respectively,intheinitializationphaseintheasynchron oussystem.
Wenowlookatfourstandardsynchronizers: thesimple,the α,theβ,andtheγsynchronizers,
proposedbyAwerbuch. Themessageandtimecomplexitiesoft hesearesummarizedinTable5.1.
Theα,β, andγsynchronizers use the notion of process safety, deﬁned as fo llows. A process
iis said to be safein roundrif all messages sent by iin roundrhave been received. The α,β
synchronizersare extremecases ofthe γsynchronizerand formits buildingblocks.
A SimpleSynchronizer: Thissynchronizerrequireseachprocesstosendeveryneigh boroneand
onlyonemessageineachround. Ifnomessageistobesentinth esynchronousalgorithm,an
emptydummymessageissentintheasynchronousalgorithm;i fmorethanonemessageare
sentinthesynchronousalgorithm,theyarecombinedintoon emessageintheasynchronous
algorithm. Inanyround,whenaprocessreceivesamessagefr omeachneighbor,itmovesto
thenextround.
Wemakethefollowingobservationsabout thissynchronizer .
•In physicaltime, any two processes may be only one round apar t. Thus, if process iis
in roundround i, any other adjacent process jmust be in rounds round i−1,round i,
orround i+ 1only.
•When process iis in roundround i, it can receive messages only from rounds round i
orround i+ 1from itsneighbours.
•Initialization: Any process may start round i. Withindtime units, all processes will
participateinthatround. Hence, Tinit=d.Minit= 0becausenoexplicitmessagesare
required solelyforinitialization.
154
•Complexity: Each round requires a message to be sent on each incident link in each
direction. Hence, Mround= 2|L|andTround= 1.
execution messageB B
E E
DC A
DC
A
acknowledgement
(b) (a)3
3
333
3
33 12221
1 2 1
"safe"/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/0/0/1/1
/0/0/1/1/0/0/1/1/0/0/1/1/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1 /0/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/1
Figure 5.21: An example showing steps of the αsynchronizer. (a) Execution messages (Step (1))
and theiracknowledgements(Step (2)). (b)“Iam safe”messa ges(Step (3)).
Theα-synchronizer: At any process i, theαsynchronizer in round rmoves the process to the
nextroundr+ 1ifall theneighboringprocesses are safeforroundr.
A process can learn about the safety of its neighbor if any mes sage sent by this process is
required to beacknowledged. Once aneighbor jhas received acknowledgementsforall the
messagesitsent, itsendsamessageinforming i(and all itsotherneighbors)thatitis safe.
Example: Theoperation is illustratedin Figure5.21. (1) NodeA sends amessage to nodes
C and E, and receives messages from B and E in the same round. (2 ) These messages are
acknowledgedaftertheyarereceived. (3)OncenodeAreceiv estheacknowledgementsfrom
C and E, it sends a message to all its neighbours to notify them that node A is safe. This
allows the neighbours to not wait on A before proceeding to th e next round. Node A itself
can proceed to the next round only after it receives a safety n otiﬁcation from each of its
neighbours, whether or not there was any exchange of applica tion execution messages with
theminthat round.
Complexity: For every message sent ( ≤|L|) in a round, an ack is required. If l′(<|L|)
messages are sent in a round, l′acks are needed, giving a message overhead of 2l′thus far;
but it is assumed that an underlying transport layer (or equi valent) protocol uses acks, and
hencethesecomeforfree. But additionally, 2|L|messagesarerequiredsothateach process
caninformallitsneighborsthatitissafe. Thusthemessage complexityMround=2|L|+ 2l′
=O(|L|). Thetimecomplexity Tround=O(1).
Initialization: No explicit initialization is needed. A process that sponta neously wakes up
155
andinitializesthealgorithmsendsmessagesto(someof)it sneighbours,whothenacknowl-
edgeanymessagereceived,and alsoreply thattheyare safe.
Theβ-synchronizer: This synchronizer assumes a rooted spanning tree. Safe leaf nodes initiate
a convergecast; an intermediate node propagates the conver gecast to its parent when all the
nodes in its subtree, including itself, are safe. When the ro ot becomes safe and receives the
convergecast fromall itschildren, ituses atree broadcast toinformall thenodesto moveto
thenextphase.
Example: Compared to the α-synchronizer, steps (1) and (2) as described with respect
to Figure 5.21 are the same to determine when to notify others about safety. The actual
notiﬁcationaboutsafetyusestheconvergecast-broadcast sequenceonapre-establishedtree,
insteadofusingStep (3)ofFigure5.21.
Complexity: Just as for the αsynchronizer, an ack is required by the β-synchronizer for
each messageofthe l′messages sentin around; hence l′acks are required, but thesecan be
assumedtocomeforfree,thankstothetransportlayerorane quivalentlowerlayerprotocol.
Nowinsteadof 2lfurthermessagesasinthe αsynchronizer,only 2(n−1)furthermessages
are required for the convergecast and broadcast. Hence, Mround= 2(n−1). For each
round,thereisanaveragecase 2·log(n)delayforTroundandworst-case 2ndelayforTround,
incurred bytheconvergecast andthebroadcast.
Initialization: There is an initialization cost, incurred by the set up of the spanning tree
(AlgorithmsinSection5.5). AsstudiedearlierinSection5 .5,thiscostis: O(n·log(n)+|L|)
messagesand O(n)time.
/0/0/1/1 /0/0/1/1
D E FA C B
root
designated (inter−cluster) edgetree edge /0/0/1/1/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/1/1 /0/0/1/1/0/0/1/1/0/0/1/1
Figure 5.22: Cluster organization for the γsynchronizer, showing six clusters A-F. Only the tree
edges withineach cluster,and theinter-cluster designated edges are shown.
Theγ-synchronizer: The network is organized into a set of clusters, as shown in Fi gure 5.22.
Withina cluster, aspanningtree hierarchy existswith adis tinguishedroot node. Theheight
156
(message types)
Subtree_safe //βsynchronizer phase’s convergecast within cluster
This_cluster_safe //βsynchronizer phase’s broadcast within cluster
My_cluster_safe // embedded inter-cluster αsynchronizer’s messages across cluster boundaries
Neighboring_cluster_safe // Convergecast following inter-cluster αsynchronizer phase
Next_round //Broadcast following inter-cluster αsynchronizer phase
foreachrounddo
1.(βsynchronizer phase:) This phase aims to detect when all the nodes within a cluster a re safe, and
inform all thenodes in that cluster.
(a) Using the spanning tree, leaves initiate the convergecast of the ‘Subtree_safe ’ message towards
the root of the cluster.
(b) After the convergecast completes, the root initiates a broadcast of ‘This_cluster_safe ’ on the
spanning tree within the cluster.
(c)(Embedded αsynchronizer:)
i. During this broadcast in the tree, as the nodes get engaged , the nodes also send
‘My_cluster_safe ’ messages on any incident designated inter-cluster edges.
ii. Each node also awaits ‘ My_cluster_safe ’ messages along any such incident designated
edges.
2.(Convergecast and broadcast phase:) This phase aims to detect when all neighboring clusters are
safe, and toinform every node within this cluster.
(a)(Convergecast:)
i. Afterthebroadcast oftheearlier phase (1b) completes, t heleaves initiate aconvergecast us-
ing‘Neighboring_cluster_safe ’ messages oncetheyreceive anyexpected ‘ My_cluster_safe ’
messages (step (1c)) on allthe designated incident edges.
ii. An intermediate node propagates the convergecast once i t receives the ‘ Neighbor-
ing_cluster_safe ’ message from all its children, and also any expected ‘ My_cluster_safe ’
message (as perstep (1c)) along designated edges incident onit.
(b)(Broadcast:) Oncetheconvergecast completesattherootofthecluster, a ‘Next_round ’ message
is broadcast inthe cluster’s tree toinform all the tree node s tomovetothe next round.
Figure5.23: The γsynchronizer.
of a clustering scheme, h(c), is the maximum height of the spanning trees across all of
the clusters. Two clusters are neighbors if there is at least one edge between one node in
each of the two clusters; one of such multiple edges is the designated edge for that pair of
clusters. Within a cluster, the β-synchronizer is executed; once a cluster is ‘stabilized’, the
α-synchronizer is executed among the clusters, over the designated edges. To convey the
results of the stabilization of the inter-cluster αsynchronizer, within each cluster, a con-
vergecastandbroadcastphaseisthenexecuted. Overthe designated inter-clusteredges,two
types of messages are exchanged for the αsynchronizer: My_cluster_safe , andNeighbor-
ing_cluster_safe , with the self-evident semantics. The details of the algori thm are given in
Figure5.23.
157
Complexity:
•LetLcbethetotalnumberoftreeedgesplusdesignatededgesinthe clusteringscheme.
In each round, there are four messages – Subtree_safe ,This_cluster_safe ,Neighbor-
ing_cluster_safe , andNext_round – per tree edge, and two My_cluster_safe messages
overeach designatededge. Hence, MroundisO(Lc).
•Lethcbethemaximumheightofanytreeamongtheclusters,thenthe timecomplexity
componentTroundisO(hc). This is due to the four phases – convergecast, broadcast,
convergecast, and broadcast – contributing 4hctime, the 2 units of time needed for
all processes to become safe, and 1 unit of time needed for the inter-cluster messages
My_cluster_safe .
Exercise25asksyoutoworkoutaformaldesignofhowtoparti tionthenodesintoclusters,
how to choose a root and a spanning tree of appropriate depth f or each cluster, and how
to designate the preferred edges. The requirements on the de sign scheme are to be able to
control the complexity by suitably tuning a parameter k. Theγ(k)-synchronizer reduces to
theα-synchronizer when k=n−1, i.e., each cluster contains a single node. The γ(k)-
synchronizer reduces to the β-synchronizer when k= 2, i.e., there is a single cluster. The
constructionwillallowthe γ(k)-synchronizertobeviewedas aparameterized synchronizer
based onclustering.
5.7 MaximalIndependentSet(MIS)
For a graph (N,L), anindependent set of nodesN′, whereN′⊂N, is such that for each iandj
inN′,(i,j)∝\⌉}atio\slash∈L. An independent set N′is amaximal independent set if no strict superset of N′
isanindependentset. Agraphmayhavemultiplemaximalinde pendentsets;allofwhichmaynot
beofthesamesize.3
The maximal independent set problem requires that adjacent nodes must not be chosen. This
has application in wireless broadcast where it is required t hat transmitters must not broadcast on
the same frequency within range of each other. More generall y, for any shared resources (radio
frequency bandwidth in the above example) to allow a maximum concurrent use while avoiding
interference orconﬂictinguse,amaximalindependentseti s required.
Computing a maximum independent set in a distributed manner is challenging. The problem
becomes further interesting when a maximal independent set must be maintained when processes
joinand leave,and linkscan godown,ornewlinksbetween exi stingnodescan beestablished.
A simple and elegant distributed algorithm for the MIS probl em in a static system, proposed
by Luby, is presented in Figure 5.24 for an asynchronous syst em. The idea is as follows. In
each iteration, each node Piselects a random number random iand exchanges this value with its
neighboursusingtheRANDOMmessage. If random iislessthantherandomnumberschosenby
3The problem of ﬁnding the largest sized independent set is th emaximum independent set problem. This is NP-
hard.
158
(variables)
set ofinteger Neighbours //set ofneighbours
realrandom i // random number from asufﬁciently large range
boolean selected i //becomes true when Piis included in the MIS
boolean eliminated i //becomes true when Piiseliminated from the candidate set
(message types)
RANDOM( realrandom) //a random number is sent
SELECTED( integer pid,boolean indicator ) //whether sender was selected in MIS
ELIMINATED( integer pid,boolean indicator ) //whether sender wasremoved from candidates
(1a)repeat
(1b)ifNeighbours =∅then
(1c) selected i←−true;exit();
(1d)random i←−a random number;
(1e)sendRANDOM (random i)toeach neighbour;
(1f)awaitRANDOM (random j)from each neighbour j∈Neighbours ;
(1g)ifrandom i< random j(∀j∈Neighbours )then
(1h) sendSELECTED (i,true )toeach j∈Neighbours ;
(1i) selected i←−true;exit(); //inMIS
(1j)else
(1k) sendSELECTED (i,false )to each j∈Neighbours ;
(1l) awaitSELECTED (j,⋆)from each j∈Neighbours ;
(1m) ifSELECTED (j,true )arrived from some j∈Neighbours then
(1n) foreachj∈Neighbours from which SELECTED( ⋆,false)arriveddo
(1o) sendSELECTED (i,true )toj;
(1p) eliminated i←−true;exit(); //not inMIS
(1q) else
(1r) sendELIMINATED (i,false )to each j∈Neighbours ;
(1s) awaitELIMINATED (j,⋆)from each j∈Neighbours ;
(1t) for all j∈Neighbours do
(1u) ifELIMINATED (j,true )arrivedthen
(1v) Neighbours←−Neighbours\{j};
(1w)forever.
Figure5.24: Luby’salgorithmfortheMaximalIndependentS etinanasynchronoussystem. Code
shownisforprocess Pi,1≤i≤n.
all its neighbours, the node includes itself in the MIS and ex its. However, whether or not a node
gets includedin theMIS, itinformsits neighboursviathein dicatorparameteron theSELECTED
message. On receiving SELECTED messages from all the neighb ours, if a node ﬁnds that at
least one of its neighbours has been selected for inclusion i n the MIS, the node eliminates itself
from thecandidateset for inclusion. However,whetherorno t an unselectednodeeliminatesitself
from thecandidateset,itinformsitsneighboursviatheind icatorparameteron theELIMINATED
message. If a node learns that a neighbour jis eliminated from candidature, the node deletes j
fromNeighbours ,and proceeds to thenextiteration.
159
67 2
1
025
6
81
6KA E
B
CDG H
F
JI
(a)2 4
59
1
(b)A E
B
CDFG H
I
J K
Figure 5.25: An example showing the execution of the MIS algo rithm. (a) Winners and losers in
round1. (b)Winnersup toround 2,and thelosersin round2.
The algorithm constructs an IS because once a node is selecte d to be in the IS, all its neigh-
bours are deleted from theset ofremaining candidatenodesf or inclusionintheIS. The algorithm
constructs an MIS because only the neighbours of the selecte d nodes are eliminated from being
candidates.
Example: Figure5.25(a)and (b)showtheﬁrst tworoundsin theexecuti onoftheMISalgorithm.
The winners have a check mark and the losers have a cross next t o them. In the third round, the
nodelabeledIincludesitselfas awinner. TheMISis {C,E,G,I,K}.
Complexity: It is evidentthat ineach iteration,at leastonenodewill be includedin theMIS, and
atleastonenodewillbeeliminatedfromthecandidateset. S oatmostn/2iterationsofthe repeat
loop are required. In fact, the expected number of iteration s isO(logn). The reader is referred to
thepaperbyLuby fortheproofofthisbound.
5.8 ConnectedDominatingSet
Adominatingset ofgraph (N,L)isasetN′⊆Nsuchthateachnodein N\N′hasanedgetosome
nodeinN′. Determiningwhetherthereexistsadominatingsetofsize k<|N|isNP-complete. A
connected dominating set (CDS) of (N,L)is a dominating set N′such that the subgraph induced
by thenodes in N′isconnected.
Finding the miminum connected dominating set (MCDS) is NP-c omplete, and hence poly-
nomial time heuristics are used to design approximation alg orithms. In addition to the time and
messagecomplexities,the approximationfactor becomesanimportantmetric. Theapproximation
factor is the worst case ratio of the size of the CDS obtained b y the algorithm to the size of the
MCDS. Another useful metric is the stretch factor . This is the worst-case ratio of the length of
the shortest route between the dominators of two nodes in the CDS overlay, to the length of the
shortestroutesbetween thetwonodesin theunderlyinggrap h.
Theconnecteddominatingsetcanformabackbonealongwhich abroadcastcanbeperformed.
All nodes are guaranteed to be within range of the backbone an d can hence receive the broad-
160
cast. The set is thus useful for routing, particularly in the wide-area network and also in wireless
networks.
A simple heuristic is to create a spanning tree and delete the edges to the leaf nodes to get a
CDS. Another heuristic is to create a MIS and add edges to crea te a CDS. However, designing
an algorithm with a low approximation factor is non-trivial . The Bibliographic Notes point to a
coupleofreferences forefﬁcient distributedCDSalgorith ms.
5.9 CompactRoutingTables
Routingtablesaretraditionallyaslargeasthenumberofde stinationsn. Thiscanhavehighstorage
requirements as well as table lookup and processing overhea ds when routing each packet. If the
table can be reorganized such that it is indexed by the incide nt incoming link, and the table entry
gives the outgoing link, then the table size becomes the degr ee of the node, which can be much
smallerthan n. Furtherefﬁciencywoulddependonhowthedestinationsrea chableperchannelare
representedandaccessed. Someoftheapproachestodesigni ngcompactroutingtablesincludethe
following.
•Hierarchicalroutingschemes: Thenetworkgraphisorganiz edintoclustersinahierarchical
manner,witheachclusterhavingoneclusterheaddesignate dnodethatrepresentsthecluster
atthenexthigherlevelinthehierarchy. Thereisdetailedi nformationaboutroutingwithina
cluster,atalltherouterswithinthatcluster. Ifthedesti nationdoesnotlieinthesamecluster
asthesource,thepacketissenttotheclusterheadandupthe hierarchyas appropriate. Once
theclusterheadofthedestinationisfoundintheroutingta bles,thenthepacketissentacross
the network at that level of the hierarchy, and then down the h ierarchy in the destination
cluster. Thisformofroutingiswidelyused intheInternet.
•Tree-labelingschemes: Thisfamilyofschemesusesalogica ltreetopologyforrouting. The
routingschemerequireslabelingthenodesofthegraphinsu chawaythatallthedestinations
reachable via any link can be represented as a range of contig uous addresses [x,y]. A node
with degree degneed only maintain degentries in its routing table, where each entry is a
range of contiguous addresses. For all the address interval s[x,y]except at most one, the
schememustsatisfy x<y.
Example: Figure 5.26 shows a tree labeling. on a tree with 7 nodes. The t ree edge labels
areenclosed inrectangles. Non-treeedges arein dashedlin es.
Tree-labeling can provide great savings, compared to a tabl e of sizenat each node. Unfor-
tunately,all trafﬁc is conﬁned to the logical tree edges. Ex ercise 26 asks you to showthat it
isalways possibleto generateatree-labeling scheme.
•Interval routing schemes: The tree-labeling schemes suffe r from the fact that data can be
sent only over tree edges, wasting the remaining bandwidth i n the system. Interval routing
extendsthetreelabelingsothatthedatapacketsneednotbe sentonlyontheedgesofatree.
161
1 324
6
5 72−71−14−71−35−7
1−4
6−44−23−35−5
1−67−7
Figure5.26: Treelabelingon agraph with7nodes.
Formally,givenagraph (N,L), an intervalroutingschemeis atuple (B,I),where:
1. Nodelabeling:Bisa 1:1mappingon N, that assignslabels tonodes.
2. Edge labeling: The mapping Ilabels each edge in Lby some subset of node labels
B(N)such that for any node x, all destinations are covered ( ∪y∈NeighboursI(x,y)∪
B(x) =N) and there is no duplication of coverage ( I(x,w)∩I(x,y) =∅for
w,y∈Neighbours ).
3. For any source sand destination tnodes, there must exist a sequence of nodes ∝a\}⌊ra⌋k⌉tl⌉{ts=
x0,x1...x k−1,xk=t∝a\}⌊ra⌋k⌉tri}htwhereB(t)∈I(xi−1,xi)for eachibetween 1 and k. There-
fore, for each source and destination pair, there must exist a path under the new map-
ping.
Toshowthatanintervallabelingschemeispossibleforever ygraph,atreewiththefollowing
property is constructed: “there are no cross-edges in the co rresponding graph”. The tree
generated by a depth-ﬁrst traversal always satisﬁes this pr operty. Nodes are labeled by a
preordertraversal whereas theedgesare labeledby amorede tailedscheme, see[31].
Two drawbacks of interval routing schemes are that: (i) they do not give any guarantees on
the efﬁciency (lengths) of the routing paths that get chosen , and (ii) they are not robust to
smallchangesin thetopology.
•Preﬁx routingschemes: Preﬁx routingschemesovercomethed rawbacksofintervalrouting.
(This preﬁx routing is not to be confused with the CIDR routin g used in the internet. CIDR
also uses the preﬁxes of the destination IP address.) In preﬁ x routing, the node labels as
well as the channel labels are drawn from the same domain and a re viewed as strings. The
routing decision at a router is as follows: identify the chan nels whose label is the longest
preﬁx of the address of the destination. This is the channel o n which to route the packet for
thatparticulardestination.
Thestretch factor of a routing scheme ris deﬁned as max i,j∈N{distance r(i,j)
distance opt(i,j)}. This is an
importantmetricinevaluatingacompact routingscheme.
162
All the above approaches for compact routing are rich in dist ributed graph algorithmic prob-
lems and challenges, including identifying and proving bou nds on the efﬁciency of computed
routes. Different graph topologiesyieldinterestingresu ltsfortheseroutingschemes.
5.10 LeaderElection
Wehaveseentheroleofaleaderprocessinseveralalgorithm ssuchastheMinimumspanningtree
and broadcast/convergecasttocomputeafunctionoverall t heparticipatingprocesses.
Leader election requires that all the processes agree on a co mmon distinguished process, also
termedasthe leader. Aleaderisrequiredinmanydistributedsystemsbecauseal gorithmsaretypi-
callynotcompletelysymmetrical,andsomeprocesshastota ketheleadininitiatingthealgorithm;
another reason is that we would not want all the processes to r eplicate the algorithm initiation, to
saveon resources.
Typical algorithms for leader election assume a ring topolo gy is available. Each process has a
left neighbour and a right neighbour. The Lelang, Chang, and Roberts (LCR) algorithm assumes
an asynchronous unidirectional ring. It also assumes that a ll processes have unique identiﬁers.
Each process in the ring sends its identiﬁer to its left neigh bour. When a process Pireceives the
identiﬁerkfromitsrightneighbour Pj,it acts asfollows.
•i<k: forward theidentiﬁer ktoitsleft neighbour
•i>k: ignorethemessagereceivedfromneighbour j
•i=k: due to the assumption on nonanonymity, Pi’s identiﬁer must have circluated across
theentirering. Hence Pican declare itselftheleader.
Picanthensendanothermessagearoundtheringannouncingtha tithasbeenchosenastheleader.
Thealgorithmis giveninFigure5.27.
Complexity: The LCR algorithm in Figure 5.27 is in its simplest form. Seve ral optimizations
are possible. For example, if ihas frowarded a probe with value zand a probe with value X,
wherei < x < z arrives, no forwarding action on the probe needs to be taken. Despite this, it is
straightforward to see that the message complexityof this a lgorithm isn·(n−1)/2and the time
complexityis O(n).
TheO(n2)message cost can be reduced to O(nlogn )by using a binary search in both direc-
tions. Inround k,thetokeniscirculatedto 2kneighboursonboththeleftandrightsides. Tocover
the entire ring, a logarithmic number of steps are needed. Co nsider that in each round, a process
tries to become a leader, and only the winners in round kcan proceed to round k+ 1. In effect,
a processiis a leader in round kif and only if iis the highest identiﬁer among 2kneighbours in
bothdirections. Hence,anypairofleadersafterround kareatleast 2kapart. Hencethenumberof
leaders diminishes logarithmically as n/2kObserve that in each round, therer are at most nmes-
sages sent, using thesuprewssiontechniqueoftheLCR algor ithm. Thus theoverallcomplexityis
O(n·logn).
163
(variables)
boolean participate←false //becomes true when Piis included in the MIS
(message types)
PROBEinteger // contains a node identiﬁer
SELECTED integer // announcing the result
(1) When aprocess wakes up toparticipate inleader eleciton :
(1a)sendPROBE( i)toright neighbor;
(1b)participate←−true. (2) When aPROBE( k)message arrives from the left neighbour Pj:
(2a)ifparticipate =falsethenexecute step (1) ﬁrst. (2b) ifi > kthen
(2c) discard the probe;
(2d)else if i < kthen(2e) forwardPROBE( k)toright neighbour;
(2f)else if i=kthen
(2g) declare iisthe leader;
(2h) circulate SELECTED( i)to right neighbour; (3) Whena SELECTED( x)message arrives from left neighbour: (3a) ifx
(3b) note xas the leader and forward message toright neighbour; (3c) elsedonot forward theSELECTEDmessage.
Figure 5.27: The LCR leader election algorithm in a synchron ous system. Code shown is for
processPi,1≤i≤n.
It has been shown that there cannot exist a determinisitc lea der election algorithm for anony-
mous rings. Hence, the assumption about uniform node identi ﬁers is necessary in this model.
However,thealgorithmcan beuniform,i.e., thretotalnumb erofporcesses need notbeknown.
5.11 ChallengesinDesigningDistributedGraphAlgorithms
Wehavethusfarconsideredsomeelementarybutimportantgr aphproblems,andseenhowtosolve
them in distributed algorithms. The algorithms either fail or require a more complicated redesign
ifweassumethatthegraph topologychanges dynamically,wh ichhappensin mobilesystems.
•The graph (N,L)changes dynamically in the normal course of execution of a di stributed
execution. An example is the load on a network link, which is r eally determined as the
aggregateof many different ﬂows. It is unrealisticto expec t that this will ever be static. All
ofasudden,theMSTalgorithms(and others)need acompleteo verhaul.
•The graph can change if either there are link or node failures , or worse still, partitions in
the network. The graph can also change when new links and new n odes are added to the
network. Again, the algorithms seen thus far need to be redes igned to accommodate such
changes.
Thechallengeposedbymobilesystemsadditionallyneedsto dealwiththenewcommunication
model. Here, each node is capable of transmitting data wirel essly, and all nodes within a certain
radiuscan receiveit. Thisis theunit-diskradiusmodel.
164
5.12 ObjectReplicationProblems
We now describe a real-life graph problem based on web/data r eplication, and that also requires
dynamicdistributedsolutions.
1. Consideraweightedgraph (N,L),whereinkusersaresituatedatsome Nk⊆Nnodes,and
rreplicas of a data item can be placed at some Nr⊆N. What is the optimal placement of
thereplicasif k>rand theusers access thedataiteminread-only mode?
A solution requires evaluating all placements of Nramong the nodes in Nto identify
min(/summationtext
i∈Nk,ri∈Nrdisti,ri), wheredisti,riis the cost from node itori, the replica nearest
toi.
2. If we assume that the Read accesses from each of the users in Nkhave a certain frequency
(orweight),theminimizationfunctionwouldchange.
3. If each edge has a certain bandwidth or capacity, that too h as to be taken into account in
identifyingafeasiblesolution.
4. NowassumethatauseraccesstotheshareddataisaReadope rationwithprobability x,and
an Update operation with probability 1−x. An Update operation also requires all replicas
tobeupdated. What istheoptimalplacementofthereplicas i fk>r?
Many such graph problems do not always have polynomialsolut ionseven in the staticcase. With
dynamicallychanging inputparameters, thecase appears ev en morehopelessfor an optimalsolu-
tion. Fortunately,heuristicscan often beusedto provideg oodsolutions.
5.12.1 Problem Deﬁnition
In a large distributed system, data replication is useful fo r rapid access to data and for fault-
tolerance. Here we look at Wolfson, Jajodia, and Huang’s opt imal data replication strategy that
isdynamicinthatitadaptstothereadandwritepatternsfro mthedifferentnodes. Letthenetwork
be modeled by the graph (V,E), and let us focus on a single object for simplicity. Deﬁne a repli-
cation scheme as a subsetRofVsuch that each node in Rhas a replica of the object. Let riand
widenote the rates of reads and writes issued by node i. Letcr(i)andcw(i)denote the cost of a
readandwriteissuedbynode i. LetRdenotethesetofallpossiblereplicationschemes. Thegoal
isto minimizethecostofthereplicationscheme:
min
R∈R[/summationdisplay
i∈Vri·cr(i) +/summationdisplay
i∈Vwi·cw(i)] (5.3)
Thealgorithmassumesonecopyserializabilitywhichcanbe implementedbytheRead-One-Write-
All(ROWA)policy. ROWAcanbestrictlyimplementedinconju nctionwithaconcurrencycontrol
mechanism such as two-phase locking; however, lazy propaga tion can also be used for weaker
semantics.
165
5.12.2 Algorithm Outline
For arbitrary graph topologies, minimizing the cost as in Eq uation (5.3) is NP-complete. So we
assume a tree topology T, as shown in Figure 5.28. The nodes inthe replication scheme Rare
shown in the ellipse. If Tis allowed to be a tree overlay Ton the network topology, then all
algorithm communication is conﬁned to the overlay. Concept ually, the set of nodes Rcontaining
the replicas is an amoeba-like connected subgraph that move s around the overlay tree Ttowards
the“centerofgravity”ofthereadandwriteactivity. Theam oeba-likesubgraphexpandswhenthe
relative cost of the reads is more than that of writes, and shr inks as the relative cost of writes is
morethanthatofreads,reachinganequilibriumunderstead ystateactivity. Thisequilibrium-state
subgraph for the replication schemeis optimal. Thealgorit hm executes in steps that are separated
by predetermined time periods or “epochs”. Irrespective of the initial replication scheme, the
algorithmconvergestotheoptimalreplicationschemein( diameter +1)numberofstepsoncethe
read-and-writepattern stabilizes.
A BC
DER R−fringe
R−neighbour
R−neighbour
and
R−fringe/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1
Figure 5.28: The tree topology and the replication scheme R. Nodes inside the ellipse belong to
thereplicationscheme.
5.12.3 Reads and Writes
Read:A read operation is performed from the closest replica on the treeT. If the node issuing
thereadqueryorreceivingaforwardedreadqueryisnotin R,itforwardsthequerytowards
the nodes in Ralong the tree edges – for this, it sufﬁces that a parentpointer point in the
direction of the subgraph R. Once the query reaches a node in R, the value read is returned
alongthesamepath.
Write:A write is performed to every replica in the current replicat ion scheme R. If a write
operation is issued by a node not in R, the operation request is propagated to the closest
nodeinR, likefortheread operationrequest. Onceawriteoperation reaches a node iinR,
thelocalreplicaisupdated,andtheoperationispropagate dtoallneighboursof ithatbelong
toR. To implement this, a node needs to track the set of its neighb ours that belong to R.
Thisisdoneusingavariable, R-neighbours .
166
Implementation: To execute a read or write operation, a node needs to know (i) w hether it is in
R(so it can read/write from the local replica), (ii) which of i ts neighbours are in R(to propagate
writerequests),and(iii)ifthenodeisnotin R,thenwhichofitsneighboursistheuniquenodethat
leadsonthetreeto R(soitcanpropagatereadandwriterequests). Afterappropr iateinitialization,
thisinformationis alwayslocallyavailableby trackingth estatusoftheneighbournodes.
5.12.4 Converging toan Replication Scheme
Withinthereplicationscheme R, threetypesofnodesare deﬁned.
R-neighbour: Suchanode ibelongstoRbuthasatleastoneneighbour jthatdoesnotbelongto
R.
R-fringe:Such a node ibelongs toRand has only one neighbour jthat belongs to R. Thus,iis
aleafnodeinthesubgraphof TinducedbyRandjistheparent of i.
singleton:|R|=1 andi∈R.
Example: In Figure 5.28, node Cis anR-fringenode, nodes AandEare both R-fringeand
R-neighbour nodes,and node DisanR-neighbour node.
Thealgorithmusesthefollowingthreeteststoadjustthere plicationschemetoconvergetothe
optimalscheme.
(a) (b) (c)r
w rw r+w
r+w i j i j
ij/0/0/1/1/0/0/1/1/0/0/1/1/0/0/1/1
Figure5.29: Adaptivedatareplicationtestsexecutedbyno dei. (a)Expansiontest. (b)Contraction
test. (c) Switchtest.
Expansiontest :AnR-neighbour nodeiexamines each such neighbour jto determinewhether j
canbeincludedinthereplicationscheme,usingan expansiontest . Nodejisincludedinthe
replication scheme if the volume of reads coming from and via jis more than the volume
of writes that would have to be propagated to jfromiifjwere included in the replication
scheme.
Example(Figure 5.29(a)): Nodeiincludesjin thereplicationschemeif r>w.
Contractiontest :AnR-fringenodeiexamines whether it can exclude itself from the replication
scheme, using a contraction test . Nodeiexcludes itself from the replication scheme if the
volumeofwritesbeingpropagatedtoitfrom jismorethanthevolumeofreadsthat iwould
167
havetoforwardto jifiweretoexitthereplicationscheme. Beforeexiting,node imustseek
permission from jto prevent a situation where R={i,j}and bothiandjsimultaneously
havea successful contractiontest and exit,leaving nocopies oftheobject.
Example(Figure 5.29(b)): Nodeiexcludesitselffrom thereplicationschemeif w>r.
Switch test :Asingleton nodeiexecutes the switch test to determine if it can transfer its replica
to some neighbour to optimizethe objectivefunction. A sing leton node transfers its replica
toaneighbour jifthevolumeofrequestsbeing forwarded bythat neighbouri sgreaterthan
thevolumeofrequests the nodewould haveto forward to that n eighbourifthe replicawere
shifted from itself to that neighbour. If such a node jexists, observe that it is uniquely
identiﬁedamongtheneighboursofnode i.
Example(Figure5.29(c)): Nodeitransfers itsreplicato jifr+wbeingforwarded by jis
greaterthan r+wthatnodeireceivesfrom allothernodes.
The various tests are executed at the end of each “epoch”. A R-neighbour node may also be
aR-fringenode or a singleton node; in either case, the expansion test is executed ﬁrst and if it
fails, then the contraction test or theswitch test is executed. Note that a singleton node cannot be
aR-fringenode. Thecodeis giveninFigure5.30.
Implementation: Each node needs to be able to determine whether it is in R, whether it is a R-
neighbour node, aR-fringenode, or a singleton node. This can be determined if a node knows
whether it is in R, the set of neighbour nodes, and for each such neighbour, whe ther it is in R.
This is a subset of the information required for implementin g read and write operations, and can
betracked easilyusinglocalexchanges. Hence, theseopera tionsarenotshowninthecodeinFig-
ure 5.30. The actions to service read and write requests desc ribed earlier are also straightforward
and arenot showncode.
Correctness:
Givenaninitialconnectedreplicationscheme,thereplica tionschemeaftereachepochremains
connected, and the replication schemes in two consecutive e pochs either intersect or are adjacent
singletons. This property follows from the fact that for eac h nodei∈R, in each epoch, at most
one of the three tests – expansion, contraction, and switch – succeeds, and the corresponding
transformation satisﬁes the above property. Given two disc onnected components of a replication
scheme, it is easy to see that by adding nodes to combine the co mponents can never increase the
cost(Equation(5.3))ofthereplicationscheme.
Once theread-write pattern stabilizes, thereplication sc hemestabilizeswithing diameter + 1
number of epochs, and the resulting replication scheme is op timal. The proof if fairly complex;
below are the main steps to show termination, and these can be validated intuitively. For the opti-
malityargument,notethateachchangeinanepochreducesth ecost. Theproofthatthereplication
scheme on termination is globally optimal and not just local ly optimal is given in the full paper
[31].
Termination:
168
•Afteraswitchtest succeeds, no other expansiontest can succeed.
•If a node exits the replication scheme in a contraction test , it cannot re-enter the replication
schemeviaan expansiontest .
•If a node exits the replication scheme in a switch test , it cannot re-enter the replication
schemeagain.
Thus,ifanodeexitsthereplicationscheme,itcanre-enter onlybya switchtest ,andthattooifthe
exitwasviaa contractiontest . Butthen,nofurther expansiontest can succeed. Hence,anodecan
exitthereplicationschemeatmostoncemore–viaa switchtest . Eachnodecanexitthereplication
schemeatmosttwice,andaftertheﬁrst switchtest ,noexpansioncanoccur. Hencethereplication
schemestabilizes.
It can be seen that the replication scheme ﬁrst expands where ver possible, and then contracts.
Ifit becomesa singleton,then theonlychanges possibleareswitches.
Arbitrary graphs: The algorithm so far assumes the graph was a tree, on which the replication
scheme “amoeba” moves into optimal position. For arbitrary graphs, a tree overlay can be used.
However, the tree structure also has to change dynamically b ecause the shortest path in the span-
ning tree between two arbitrary nodes is not always the short est path between the nodes in the
graph. Modiﬁedversionsofthethreetestscannowbeused,bu tthestructureofthegraphdoesnot
guaranteetheglobaloptimumsolution,but onlythataloal o ptimumis reached.
5.13 ChapterSummary
Thischapterﬁrstexaminedvariousviewsofthedistributed systematdifferentlevelsofabstraction
ofthetopologyofthesystemgraph. Itthenintroducedbasic terminologyforclassifyingdistributed
algorithms and distributed executions. This covered failu re models of nodes and links. It then
examinedseveralperformancemetricsfordistributedalgo rithms.
The chapter then examined several traditional distributed algorithms on graphs. The most ba-
sicofsuch algorithmsare thespanningtree, minimumweight spanningtree, and theshortestpath
algorithms - both single source and multi-source. The impor tance of these algorithms lies in the
factthatspanningtreesareusedforinformationdistribut ionandcollectionvia broadcast andcon-
vergecast , respectively, and these functions need to be performed by a wide range of distributed
applications. The convergecast and broadcast performed on the spanning trees also allow the re-
peated computation of a global function such as min,max, and/summationtext. Some of the shortest path
routingalgorithmsstudiedare seen to beused intheInterne t at thenetwork layer. In all cases, the
synchronousversionand thentheasynchronousversionofth ealgorithmswere examined.
The various examples of algorithm design showed that it is of ten easier to construct an algo-
rithm for a synchronous system than it is for an asynchronous system. The chapter then studied
synchronizers,whicharetransformationsthatallowanyal gorithmdesignedforasynchronoussys-
tem to run in an asynchronous system. Speciﬁcally, four sync hronizers, in the order of increasing
169
complexity, were studied – the simple synchronizer, the αsynchronizer, the βsynchronizer, and
theγsynchronizer.
AdistributedrandomizedalgorithmfortheMaximalIndepen dentSetproblemwasstudied,and
then the problem of determining a a Connected Dominating Set was examined. The chapter then
examined several compact routing schemes. These aim to trad e-off routing table size for slightly
longer routes. The chapter concluded by taking a look at some of the challenges introduced in
re-engineeringorre-designingthesedistributedgraphal gorithmsinthefaceofmobilityaswellas
thewirelesscommunicationmodel.
5.14 BibliographicNotes
The discussion on the classiﬁcation of distributed algorit hms is based on the vast literature, and
manyofthedeﬁnitionsaredifﬁculttoattributetoaparticu larsource. Thediscussiononexecution
inhibition is based on Critchlow and Taylor [3]. The discuss ion on failure models is based on
Hadzilacos and Toueg [14]. Crash failures were proposed by L amport and Fischer [21]. Failstop
failures were introduced by Schlichting and Schneider [24] . Send omission failures were intro-
ducedbyHadzilacos[16]. Generalomissionfailuresandtim ingfailureswereintroducedbyPerry
and Toueg [25] and Christian et al.[8], respectively. The no tion of wait-freedom was introduced
byLamport[18]andlaterdevelopedbyHerlihy[18]. Thenoti onsofthespace,message,andtime
complexities appear to be part of the folklore. The time and m essage complexity measures were
formalizedby Peterson and Fischer[24]and laterbyAwerbuc h [3].
The various spanning tree algorithms are common knowledge a nd have used informally in
many contexts. Broadcast, convergecast, and distributed s panning trees are listed as part of a
suiteofelmentary algorithms[13]. Segall [28] formallypr esented thebroadcast and convergecast
algorithms, and the breadth-ﬁrst search spanning tree algo rithm, on which Algorithm 0 is based.
Algorithms II and III which compute ﬂooding-based and depth -ﬁrst search based spanning trees,
respectively, in the face of concurrent initiators, use the technique of supressing lower priority
initiations. Thistechniquehasbeenusedinmanyothercont extsincomputerscience(e.g.,database
transaction serialization, deadlock detection). An async hronous DFS algorithm with a speciﬁed
root was given by Cheung [7]. Algorithm III adapts this to han dle concurrent initiators. The
solutiontoProblem 9 whichasks foralinear-timeDFStree wa sgivenbyAwerbuch [2].
The synchronous Bellman-Ford algorithm is derived from the Bellman-Ford shortest path al-
gorithm [4, 12]. The asynchronous Bellman-Ford was formali zed by Chandy and Misra [5]. The
Distance Vector Routing algorithm and Synchronous ﬂooding algorithm of Figure 5.17 are based
ontheArpanetprotocols[29]. TheFloyd-Warshallalgorith misfrom[9]anditsdistributedversion
was given by Toueg [30]. The asynchronous ﬂooding algorithm outlined in Figure 5.16 is based
on thetheLinkStateRoutingprotocolused intheInternet[2 9].
Thesynchronousdistributedminimumspanningtreealgorit hmwasgivenbyGallagher, Hum-
blet, and Spira [14]. Its asynchronous version was also prop osed by the same authors. The notion
of synchronizers, and the α,β, andγsynchronizers were introduced by Awerbuch [3]. The ran-
170
domized algorithm for the Independent Maximal Set (MIS) was proposed by Luby [23]. Several
distributed algorithms to create connected dominating set s with a low approximation factor are
surveyedby Wan, Alzoubiand Frieder [32]. Therandomizedal gorithmforconnected dominating
setbyDubhashi,Mei,Panconesi,Radhakrishnan,andSriniv asan[11]hasanapproximationfactor
ofO(log∆), where ∆is the maximum degree of the network. This algorithm also has a stretch
factor ofO(logn). Compact routing based on the tree topology was introduced b y Santoro and
Khatib [27]. Its generalization to interval routing was int roduced by van Leeuwen and Tan [31].
A surveyofinterval routingmechanismsis givenby Gavoille [15]. TheLCR algorithmfor leader
electionwasproposedbyLeLann[22]andChangandRobertswh oprovidedseveraloptimizations
[6]. TheO(nlogn )alogrithm for leader election was given by Hirschberg and Si nclair [19]. The
resultontheimpossibilityofelectiononanonymousringsw asshownbyAngluin[1]. Theadaptive
replicationalgorithmwas proposedby Wolfson,Jajodia,an d Huang[31].
171
(variables)
array ofinteger Neighbours [1... bi]; // bineighbours intree Ttopology
array ofinteger Read_Received [1...|bi|]; // jth element gives #reads from Neighbours [j]
array ofinteger Write_Received [1...|bi|]; // jth element gives #writes from Neighbours [j]
integer write i,read i; //#writes and #reads issued locally
boolean success;
(1)Pidetermines which tests to execute at theend of each epoch:
(1a)ifiisR-neighbour andR-fringethen
(1b) ifexpansion test failsthen
(1c) reduction test
(1d)else if iisR-neighbour andsingleton then
(1e) ifexpansion test failsthen
(1f) switchtest
(1g)else if iisR-neighbour and notR-fringeand notsingleton then
(1h) expansion test
(1i)else if iisR−neighbour andR-fringethen
(1j) contraction test .
(2)Piexecutesexpansion test:
(2a)forjfrom1tobido
(2b) ifNeighbours [j]not in Rthen
(2c) ifRead_Received [j]>(write i+/summationtext
k=1...bi,k/ne}ationslash=jWrite_Received [k])then
(2d) send acopy of the object to Neighbours [j];success←−1;
(2e)return(success).
(3)Piexecutescontraction test:
(3a) let Neighbours [j]bethe only neighbour in R;
(3b)ifWrite_Received [j]>(read i+/summationtext
k=1...bi,k/ne}ationslash=jRead_Received [k])then
(3c) seek permission from Neighbours [j]to exitfrom R;
(3d) ifpermission received then
(3e) success←−1; inform all neighbours;
(3f)return(success).
(4)Piexecutesswitch test:
(4a)forjfrom1tobido
(4b) if(Read_Received [j] +Write_Received [j])>
[/summationtext
k=1...bi,k/ne}ationslash=j(Read_Received [k] +Write_Received [k]) +read i+write i]then
(4c) transfer object copy to Neighbours [j];success←−1;inform all neighbours;
(4d)return(success).
Figure5.30: AdaptiveData Replicationalgorithmexecuted by a nodePiin replicationscheme R.
All variablesexcept Neighbours are reset at theend ofeach epoch. Rstabilizesin diameter + 1
epochs aftertheread-writerates stabilize.
172
Bibliography
[1] D. Angluin, Local and global properties in networks of pr ocessors, Proc. 12th ACM Sympo-
siumonTheory ofComputing,82-93,1980.
[2] B. Awerbuch, Optimal distributed algorithms for minimu m weight spanning tree, counting,
leaderelection,andrelatedproblems,Proc.19thACMSympo siumonPrinciplesofTheoryof
Computing(STOC), 230-240,1987.
[3] B. Awerbuch, Complexity of network synchronization, Jo urnal of the ACM, 32(4): 804-823,
October1985.
[4] R. Bellman, DynamicProgramming,Princeton,NJ, Prince tonUniversityPress, 1957.
[5] K. M. Chandy, J. Misra, Distributed computationson grap hs: Shortest path algorithms, Com-
municationsoftheACM, 25(11): 833-838,1982.
[6] E. Chang, R. Roberts, An improved algorithm for decentra lized extrema-ﬁnding in circular
conﬁgurationsofprocesses,CommunicationsoftheACM, 22( 5): 281-283,1979,
[7] T.-Y. Cheung, Graph traversal techniques and themaximu mﬂow problemin distributedcom-
putation,IEEE TransactionsonSoftware Engineering,9(4) : 504-512,July1983.
[8] F.Christian,H.Aghili,H.Strong,D.Dolev,Atomicbroa dcast: Fromsimplemessagediffusion
to Byzantine agreement, Proc. 15th International Symposiu m on Fault-Tolerant Computing,
200-206,1985.
[9] T. Cormen, C. Lieserson, R. Rivest, C. Stein, An Introduc tion to Algorithms, 2nd edition,
2001.
[10] C. Critchlow, K. Taylor, The inhibitionspectrum and th e achievementof causal consistency,
DistributedComputing,10(1): 11-27,1996.
[11] D. Dubhashi, A. Mei, A. Panconesi, J. Radhakrishnan, A. Srinivasan, Fast distributed algo-
rithms for (weakly) connected dominating sets and linear-s ize skeletons, Proc. 14th Annual
SymposiumonDiscreteAlgorithms,717-724,2003.
[12] L.Ford, D. Fulkerson,FlowsinNetworks, Princeton,NJ , Princeton UniversityPress, 1962.
173
[13] E. Gafni, Perspectives on distributed network protoco ls,: A case for building blocks, Proc.
IEEE MILCOM,1986.
[14] R. Gallagher, P. Humblet, P. Spira, A distributed algor ithm for minimum-weight spanning
trees, ACM Transactionson ProgrammingLanguagesand Syste ms,5(1): 66-77, Jan.1983.
[15] C. Gavoille, A survey on interval routing, Theoretical Computer Science, 245(2): 217-253,
2000.
[16] V. Hadzilacos, Issues of Fault Tolerance in Concurrent Computations, Ph.D. dissertation,
Harvard University,ComputerScience Tech. Report 11-84,1 984.
[17] V.Hadzilacos,S.Toueg,Fault-tolerantbroadcastsan drelatedproblems,pp.97-146,In: Dis-
tributedSystems,Ed: S. Mullender,Addison-Wesley,1993.
[18] M. Herlihy, Wait-free synchronization, ACM Transacti ons on Programming Languages and
Systems,15(5): 745-770,Nov.1991.
[19] D. Hirschberg, J. Sinclair, Decentralized extrema-ﬁn ding in circular conﬁgurations of pro-
cessors.CommunicationsoftheACM, 23(11): 627-628,1980.
[20] L.Lamport,Concurrentreadingandwriting,Communica tionsoftheACM,20(11): 806-811,
1977.
[21] L. Lamport, M. Fischer, Byzantine Generals and Transac tion Commit Protocols, SRI Inter-
national,TechnicalReport 62,1982.
[22] G. LeLann, Distributed Systems, Towards a formal appro ach, IFIP Congress Proceedings,
155-160,1977.
[23] M. Luby, A simple parallel algorithm for the maximal ind ependent set problem, SIAM J.
Comput.15(4): 1036-1053(1986)
[24] R. Schlichting, F. Schneider, Fail-stop processors: A n approach to designing fault-tolerant
computingsystems,ACM TransactionsonComputerSystems,1 (3): 222-238,1983.
[25] K. Perry, S. Toueg, Distributed agreement in the presen ce of processor and communication
faults,IEEE Transactionson SoftwareEngineering,12(3): 477-482,March 1986.
[26] G.Peterson,M.Fischer,Economicalsolutionsforthec riticalsectionprobleminadistributed
system,Proc. 9thACM Symposiumon TheoryofComputing,91-9 7, 1977.
[27] N. Santoro, R. Khatib, Labelling and implicit routing i n networks, The Computer journal,
Vol.28, 5-8,1985.
[28] A. Segall, Distributed network protocols, IEEE Transa ctions on Information Theory, 29(1):
23-35,1983.
174
[29] A.Tanenbaum, ComputerNetworks,3rd edition,Prentic e-Hall PTR, NJ, 1996.
[30] S. Toueg, An all-pairs shortest path distributed algor ithm, IBM Technical Report RC 8327,
1980
[31] J.van Leeuwen, R. Tan, Intervalrouting,TheComputerJ ournal,Vol.30, 298-307,1987.
[32] P.Wan,K.Alzoubi,O.Frieder,Distributedconstructi onofconnecteddominatingsetinwire-
lessad-hocnetworks,Proc. IEEEInfocom 2002.
5.15 ExerciseProblems
1. Adapt the synchronous BFS spanning tree algorithm shown i n Figure 5.2 to satisfy the fol-
lowingproperties.
•The root node can detect after the entire algorithm has termi nated. The root should
then terminate.
•Each nodeisableto identifyitschildnodeswithoutusingan y additionalmessages.
What istheresultingspace, time,and messagecomplexity?
2. What is the exact number of messages sent in the spanning tr ee algorithm shown in Fig-
ure 5.4. You may want to use additional parameters to charact erize the graph. Is it possible
toreduce thenumberofmessagestoexactly 2l?
3. ModifythealgorithmofFigure5.4toobtainaBFStreewint heasynchronoussystem,while
retainingtheframeworkoftheﬂoodingmechanism.
4. Modify the asynchronous spanning tree algorithm of Figur e 5.4 to eliminate the use of RE-
JECT messages. Whatis themessageoverheadofthemodiﬁedal gorithm?
5. What is the maximum distance between any two nodes in the tr ee obtained by running the
algorithmin Figure5.6?
6. For the algorithm in Figure 5.6, show each of the performan ce complexities introduced in
Section 5.3.
7. For the algorithm in Figure 5.8, show each of the performan ce complexities introduced in
Section 5.3.
8. (based onCheung [7]) Simplifythealgorithmin Figure5.8 to deal withonlyasingleinitia-
tor. What isthemessagecomplexityandthetimecomplexityo ftheresultingalgorithm?
9. (based on [2]) Modify the algorithmderived in Exercise 8 t o obtain a depth-ﬁrst search tree
but with time complexity O(n). (Assuming a single intiator for simplicity does not reduce
thetimecomplexity. A differentstrategyneeds tobeused.)
175
10. Formally write the convergeecast algorithm of Section 5 .5.5 using the style for the other
algorithmsinthischapter.
Modifyyouralgorithmtosatisfythefollowingproperty. Ea chnodehasasensedtemperature
reading. Themaximumtemperaturereading istobecollected bytheroot.
11. Modify the synchronous ﬂooding algorithm of Figure 5.17 so as to reduce the complexity,
assuming that all the processes only need to know the highest process identiﬁer among all
the processes in the network. For this adapted algorithm, wh at are the lowered complexity
measures?
12. Adapt Algorithms 5.10 and 5.17 to design a synchronous al gorithm that achieves the fol-
lowing property: “In each round, each node may or may not gene rate a new update that it
wants to distribute throughout the network. If such an updat e is locally generated within a
round,itshouldbesynchronouslypropagatedinthenetwork .”
13. In thesynchronous distributedBellman-Ford algorithm in Figure 5.10, the terminationcon-
dition for the algorithm assumed that each process knew the n umber of nodes in the graph.
Ifthisnumberis notknown,what can bedonetoﬁnd it?
14. In the asynchronous Bellman-Ford algorithm of Figure 5. 11 what can be said about the
terminationconditionswhen (i) nisnot known,and when (ii) nis known?
For each of these two cases, modify the asynchronous Bellman -Ford algorithm of Fig-
ure5.11to alloweach process todeterminewhen toterminate .
15. Modify the asynchronous Bellman-Ford algorithm to devi se the Distance Vector Routing
algorithmoutlinedinSection ??.
16. FortheasynchronousBellman-FordalgorithmofFigure5 .11showthatithasanexponential
Ω(cn)numberofmessagesandexponential Ω(cn·d)timecomplexityintheworstcase,where
cissomeconstant
17. For the asynchronous Bellman-Ford algorithm of Figure 5 .11, if all links are assumed to
have equal weight, the algorithm effectively computes the m inimum-hop path. Show that
under this assumption, the minimum-hop routing tables to al l destinations are computed
usingO(n2·l)messages.
18. FortheasynchronousBellman-FordalgorithmofFigure5 .11,
(a) if some of the links may have negative weights, what would be the impact on the
shortestpaths? Explainyouranswer.
(b) if the link weights can keep changing (as in theInternet) , can cycles be formed during
routingbased onthecomputednexthop?
176
19. InthedistributedFloyd-WarshallalgorithmofFigure5 .14,consideriteration katnodeiand
iterationk+ 1at nodej. Examine the dependencies in the code of iandjin these two
iterations.
20. In thedistributedFloyd-WarshallalgorithmofFigure5 .14,
(a) showthattheparameter pivotis redundantonallthemessagetypeswhen thecommu-
nicationchannels areFIFO.
(b) showthattheparameter pivotisrequiredonallthemessagetypeswhenthecommuni-
cation channelsare non-FIFO.
21. InthesynchronousdistributedGHSalgorithm,itwasass umedthatalltheedgeweightswere
unique. Explain why this assumption was necessary, and give a way to make the weights
uniqueiftheyarenotso.
22. InthesynchronousGHSMSTalgorithm,provethatwhensev eralcomponentsjointoforma
singlecomponent,theremustexistacycleoflengthtwointh ecomponentgraph ofMWOE
edges.
23. IdentifyhowthecomplexityofthesynchronousGHSalgor ithmcanbereducedfrom O((n+
|L|)logn)toO((nlogn ) +|L|). Explainand proveyouranswer.
24. Considerthesimple,the α,andtheβsynchronizers. Identifysomealgorithmsorapplication
areas where youcan identifyonesynchronizeras beingmoree fﬁcient thantheothers.
25. For the γ-synchronizer, signiﬁcant ﬂexibilitycan be achieved by va rying a parameter kthat
isusedtogiveaboundon Lc(sumofthenumberoftreeedges andclusteringedges)and hc
(maximumheightofanytreeinanycluster). Visually,thisp arameterdeterminestheﬂatness
oftheclusterhierarchy.
Show that for every k,2≤k < n, a clustering scheme can be designed so as to satisfy the
followingbounds: (1) Lc<k·n, and(2)hc≤(logn)/(logk).
26. (a) Forthetreelabelingschemeforcompactrouting,sho wthatapre-ordertraversalofthe
tree generates anumberingthatalwayspermitstree-labele d routing.
(b) Will post-ordertraversalalways generateavalidtreel abelingscheme?
(c) Will in-ordertraversal alwaysgenerate avalidtree-la beling scheme?
27. (a) For the tree labeling schemes, show that there is no uniformbound on the dialation,
which is deﬁned as the ratio of thelength of the tree path to th eoptimal path, between
any pairofnodes and an arbitrarytree.
(b) Is it possible to bound the dialation by choosing a tree fo r any given graph? Explain
youranswer.
177
28. Examine all the algorithms in this chapter, and classify them using the classiﬁcations intro-
duced inSection 5.2(5.2.1-5.2.10).
29. Examinetheimpactofbothfail-stopprocessfailuresan d ofcrash processfailuresonallthe
algorithmsdescribed inthischapter. Explainyouranswers ineach case.
30. (AdaptiveDataReplication.) Intheadaptivedatarepli cationscheme(Section5.12),consider
anodethatisbothan R-neighbour and aR-fringenode.
•Can theexpansiontest andthereductiontest both besuccessful? Proveyouranswer.
•The algorithm ﬁrst performs the expansion test , and if it fails, then it performs the
reduction test . Is it possible to restructure the algorithm to perform the reduction test
ﬁrst, and then the expansiontest ? Proveyouranswer.
31. Modify the rules of the expansion ,contraction , andswitchtests in the adaptive dynamic
replication algorithm of Section 5.12 to adapt to tree overl ays on arbitrary graphs, rather
thanto treegraphs. Justifythecorrectness ofthemodiﬁedt ests.
178
Chapter6
Message Orderingand Group
Communication
Inter-process communication via message-passing is at the core of any distributed system. In this
chapter, we will study the non-FIFO, the FIFO, causal order, and synchronous order communica-
tionparadigmsfororderingmessages. Wewillthenexaminep rotocolsthatprovidethesemessage
orders. We will also examine several semantics for group com munication with multicast – in
particular, causal ordering and total ordering. We will the n look at how exact semantics can be
speciﬁed for the expected behaviour in the face of processor or link failures. Multicasts are re-
quired at the application layer when superimposed topologi es or overlays are used, as well as at
the lower layers of the protocol stack. We will examine some p opular multicast algorithms at the
network layer. An example of such an algorithm is the Steiner tree algorithm, which is useful for
settingupmulti-partyteleconferencing and videoconfere ncingmulticastsessions.
Notations: Asbefore,wemodelthedistributedsystemasagraph (N,L). Thefollowingnotations
are usedtorefer to messagesand events.
•When referring to a message without regard for the identity o f the sender and receiver pro-
cesses, we use mi. For message mi, its send and receive events are denoted as siandri,
respectively.
•More generally, send and receive events are denoted simply a ssandr. When the relation-
ship between the message and its send and receive events is to be stressed, we also use M,
send(M), andreceive (M), respectively.
For any two events aandb, where each can be either a send event or a receive event, the n otation
a∼bdenotes that aandboccur at the same process, i.e., a∈Eiandb∈Eifor some process
i. The send and receive event pair for a message is said to be a pa ir ofcorresponding events. The
send event corresponds to the receive event, and vice-versa . For a given execution E, let the set
of all send-receive event pairs be denoted as T={(s,r)∈Ei×Ej|scorresponds to r}. When
dealing with message ordering deﬁnitions, we will consider only send and receive events, but not
internalevents,becauseonlycommunicationeventsare rel evant.
179
6.1 MessageOrderingParadigms
The order of delivery of messages in a distributed system is a n important aspect of system ex-
ecutions because it determines the messaging behavior that can be expected by the distributed
program. Distributedprogramlogicgreatlydependson this orderofdelivery. Tosimplifythetask
of the programmer, programming languages in conjunction wi th the middleware provide certain
well-deﬁned message delivery behavior. The programmer can then code her logic with respect to
thisbehavior.
Several orderings on messages have been deﬁned: (i) non-FIF O, (ii) FIFO, (iii) causal order,
and (iv) synchronous order. There is a natural hierarchy amo ng these orderings. This hierarchy
representsatrade-offbetweenconcurrencyandeaseofusea ndimplementation. Afterstudyingthe
deﬁnitions of and the hierarchy among the ordering models, w e will study some implementations
oftheseorderingsinthemiddlewarelayer.
6.1.1 Asynchronous Executions
Deﬁnition 6. (A-execution. ) An asynchronousexecution (or A-execution) is an execution (E,≺)
forwhich thecausalityrelationisa partialorder.
Therecannotexistanycausalitycyclesinanyrealasynchro nousexecutionbecausecycleslead
to the absurdity that an event causes itself. On any logical l ink between two nodes in the system,
messages may be delivered in any order, not necessarily First-In First-Out. Such executions are
also known as non-FIFO executions . Although each physical link typically delivers the messag es
sentonitinFIFOorderduetothephysicalpropertiesofthem edium,alogicallinkmaybeformed
as a composite of physical links and multiple paths may exist between the two end points of the
logicallink. Asanexample,themodeoforderingattheNetwo rkLayerinconnectionlessnetworks
such asIPv4 isnon-FIFO. Figure6.1(a)illustratesan A-executionundernon-FIFO ordering.
sr
sPPr r r r
s s smm m mm1 2
1 212
1 2 32 1 3
3121
2
(a) (b)
Figure 6.1: Illustrating FIFO and non-FIFO executions. (a) anA-execution that is not a FIFO
execution. (b)an A-executionthatisalsoaFIFO execution.
6.1.2 FIFOExecutions
Deﬁnition 7. (FIFOexecutions. ) AFIFO execution isan A-execution inwhich:
forall (s,r)and(s′,r′)∈T, (s∼s′andr∼r′ands≺s′)=:r≺r′
180
ssr r
r
(a) (b) (c) (d)s r r
r
ss ss
s ss
ss
rr
r
rrmm
m
mmm
mm
m
mmP1
P2
P31 2313
3
2
2
13 1 3 1 1 3 r
333111 3
3 3
22
2
2
2 222
m2
1 1 1
Figure 6.2: Illustrationof causallyordered executions. ( a) Not a CO execution. (b,c,d) CO execu-
tions.
On any logical link in the system, messages are necessarily d elivered in the order in which
they are sent. Althoughthelogical link is inherently non-F IFO, mostnetwork protocolsprovidea
connection-oriented service at the transport layer. There fore, FIFO logical channels can be realis-
tically assumed when designing distributed algorithms. A s imple algorithm to implement a FIFO
logicalchanneloveranon-FIFO channel woulduseaseparate numberingschemetosequencethe
messages on each logical channel. The sender assigns and app ends a∝a\}⌊ra⌋k⌉tl⌉{tsequence_num, connec-
tion_id∝a\}⌊ra⌋k⌉tri}httuple to each message. The receiver uses a buffer to order the incoming messages as per
the sender’s sequence numbers, and accepts only the “next” m essage in sequence. Figure 6.1(b)
illustratesan A-executionunderFIFO ordering.
6.1.3 Causally Ordered (CO)Executions
Deﬁnition 8. (Causalorder (CO)) . A CO execution isan A-execution inwhich,
forall (s,r)and(s′,r′)∈T, (r∼r′ands≺s′)=:r≺r′
If two send events sands′are related by causality ordering (not physical time orderi ng), then
a causally ordered execution requires that their correspon ding receive events randr′occur in the
same order at all common destinations. Note that if sands′are not related by causality, then CO
isvacuouslysatisﬁedbecuasetheantecedent oftheimplica tionis false.
Example:
Figure6.2(a)showsanexecutionthatviolatesCObecause s1≺s3andatthecommondestination
P1, wehaver3≺r1.
Figure6.2(b) showsanexecutionthatsatisﬁesCO.Only s1ands2arerelatedbycausalitybutthe
destinationsofthecorrespondingmessagesare different.
Figure6.2(c) showsan executionthatsatisﬁes CO. No sendeventsarerelat ed by causality.
Figure6.2(d) shows an execution that satisﬁes CO. s2ands1are related by causality but the
destinationsofthecorrespondingmessagesare different. Similarlyfor s2ands3.
181
Causal order is useful for applications requiring updates t o shared data, implementing dis-
tributed shared memory, and fair resource allocation such a s granting of requests for distributed
mutualexclusion. Someoftheseuseswillbediscussedindet ailinSection6.5onorderingmessage
broadcastsand multicasts.
ToimplementCO,wedistinguishbetweenthearrivalofamess ageanditsdelivery. Amessage
mthat arrives in the local OS buffer at Pimay have to be delayed until the messages that were
sent toPicausally before mwas sent (the “overtaken” messages) have arrived and are pro cessed
by the application. The delayed message mis then given to the application for processing. The
event of an applicationprocessing an arrived message is ref erred to as a deliveryevent (instead of
as areceiveevent)foremphasis.
Example: Figure 6.2(a)showsan executionthat violatesCO. Toenforc e CO, message m3should
bekeptpendingin thelocal bufferafteritarrivesat P1,untilm1arrivesandm1is delivered.
Deﬁnition9. (Deﬁnitionofcausalorder(CO)forimplementa tions). Ifsend(m1)≺send(m2)
then for each common destination dof messages m1andm2,deliver d(m1)≺deliver d(m2)must
besatisﬁed.
Observethatifthedeﬁnitionofcausalorderisrestricteds othatm1andm2aresentbethesame
process, then the property degenerates into the FIFO proper ty. In a FIFO execution, no message
can be overtaken by another message between the same (sender , receiver) pair of processes. The
FIFO property which applies on a per-logical channel basis c an be extended globally to give the
COproperty. InaCOexecution,nomessagecanbeovertakenby achainofmessagesbetweenthe
same(sender, receiver)pairofprocesses.
Example: Figure 6.2(a) shows an execution that violates CO. Message m1is overtaken by the
messagesin thechain ∝a\}⌊ra⌋k⌉tl⌉{tm2,m3∝a\}⌊ra⌋k⌉tri}ht.
COexecutionscanalsobealternativelycharacterizedbyDe ﬁnition10bysimultaneouslydrop-
pingtherequirementfromtheimplicandofDeﬁnition8thatt hereceiveeventsbeonthesamepro-
cess, and relaxing the consequence from (r≺r′)to¬(r′≺r), i.e., the message m′sent causally
later thanmis not received causally earlier at the commondestination. This ordering is knownas
MessageOrdering (MO).
Deﬁnition 10. (Messageorder (MO)) . A MO executionis an A-execution in which,
forall (s,r)and(s′,r′)∈T,s≺s′=:¬(r′≺r)
Example: Consider any messagepair, say m1andm3in Figure 6.2(a). s1≺s3but¬(r3≺r1)is
false. hence, theexecutiondoesnot satisfyMO.
You are asked to prove the equivalence of MO executions and CO executions in Exercise 1.
Thiswillshowthatina CO execution,amessagecannotbeover takenbya chainofmessages.
AnothercharacterizationofaCOexecutionintermsofthepa rtialorder (E,≺)isknownasthe
Empty-Interval(EI)property.
Deﬁnition 11. (Empty-Interval execution .) An execution (E,≺)is an Empty-Interval (EI) exe-
cutionifforeachpairofevents (s,r)∈T,theopenintervalset {x∈E|s≺x≺r}inthepartial
order isempty.
182
P
P
P1
2
3
(b)r rr
r rs s s s s
mmm
mm
ss s
m3 3 2
22
2 66
6
6r4
445
55s4
11r1
1 4 1s rr5
(a)5s3r4
62m356
s
mr1
m2r3
mmm3
Figure 6.3: Illustration of a synchronous communication. ( a) Execution in an asynchronous sys-
tem. (b)Equivalentinstantaneouscommunication.
Example: Considerany message, say m2, in Figure 6.2(b). There does not existanyevent xsuch
thats2≺x≺r2. Thisholdsforallmessagesin theexecution. Hence, theexe cutionisEI.
You are asked to prove the equivalence of EI executions and CO executions in Exercise 1.
A consequence of the EI-property is that for an empty interva l∝a\}⌊ra⌋k⌉tl⌉{ts,r∝a\}⌊ra⌋k⌉tri}ht, there exists some linear
extension1<such that the corresponding interval {x∈E|s< x< r}is also empty. An empty
∝a\}⌊ra⌋k⌉tl⌉{ts,r∝a\}⌊ra⌋k⌉tri}htinterval in a linear extension indicates that the two events may be arbitrarily close and can
be represented by a vertical arrow in a timing diagram, which is a characteristic of a synchronous
message exchange. Thus, an execution Eis CO if and only if for each message, there exists
somespace-time diagram in which that message can be drawn as a ver tical message arrow. This,
however,does notimplythat allmessages can bedrawn as vertical arrows inthe samespace-time
diagram. If all messages could be drawn vertically in an exec ution, all the∝a\}⌊ra⌋k⌉tl⌉{ts,r∝a\}⌊ra⌋k⌉tri}htintervals would
beemptyinthe samelinearextensionandtheexecutionwouldbesynchronous.
Anothercharacterization ofCO executionsis in termsof the causal past/futureof asend event
anditscorrespondingreceiveevent. Thefollowingcorolla rycanbederivedfromtheEIcharacter-
izationabove(Deﬁnition11).
Corollary3. An execution (E,≺)isCO ifand onlyiffor eachpairof events (s,r)∈Tandeach
evente∈E,
•Weakcommonpast: e≺r=:¬(s≺e)
•Weakcommonfuture: s≺e=:¬(e≺r)
Example: Corollary 3 can beobservedfortheexecutionsinFigures 6.2 (b)–(d).
If we require that the past of both the sandrevents are identical (and analogously for the
future), viz., e≺r= :e≺sands≺e= :r≺e, we get a subclass of CO executions, called
synchronousexecutions .
1Alinearextensionofapartialorder (E,≺)isanytotalorder (E, <)suchthateachorderingrelationofthepartial
orderispreserved.
183
6.1.4 Synchronous Execution(SYNC)
When allthecommunicationbetween pairsofprocesses usess ynchronoussendand receiveprim-
itives,theresultingorder is thesynchronousorder. As eac h synchronouscommunicationinvolves
a handshake between the receiver and the sender, the corresp onding send and receive events can
be viewed as occuring instantaneously and atomically. In a t iming diagram, the “instantaneous”
messagecommunicationcanbeshownbybidirectionalvertic almessagelines. Figure6.3(a)shows
a synchronous execution on an asynchronous system. Figure 6 .3(b) shows the equivalent timing
diagramwiththecorrespondinginstantaneousmessagecomm unication.
The “instantaneous communication” property of synchronou s executions requires a modiﬁed
deﬁnition of the causality relation because for each (s,r)∈T, the send event is not causally
ordered before the receive event. The two events are viewed a s being atomic and simultaneous,
and neithereventprecedes theother.
Deﬁnition 12. (Causality in a synchronous execution.) The synchronous causality relation ≪
onEis thesmallesttransitiverelationthatsatisﬁesthefollo wing.
S1.Ifxoccurs before yat thesameprocess,then x≪y
S2.If(s,r)∈T, thenfor all x∈E, [(x≪s⇐:x≪r) and (s≪x⇐:r≪x)]
S3.Ifx≪yandy≪z, thenx≪z
We can nowformallydeﬁneasynchronousexecution.
Deﬁnition 13. (Synchronous execution. ) A synchronousexecution (or S-execution) is an execu-
tion(E,≪)forwhich thecausalityrelation ≪is apartialorder.
We nowshowhowto timestampeventsin synchronousexecution s.
Deﬁnition14. (Timestampingasynchronousexecution. ) Anexecution (E,≺)issynchronousif
andonlyifthereexistsa mappingfrom EtoT(scalartimestamps)suchthat
•foranymessage M,T(s(M)) =T(r(M))
•foreach process Pi, ifei≺e′
ithenT(ei)<T(e′
i)
By assuming that a send event and its corresponding receive e vent are viewed atomically, i.e.,
s(M)≺r(M)andr(M)≺s(M), it follows that for any events eiandejthat are not the send
eventandthereceiveeventofthesamemessage, ei≺ej=:T(ei)<T(ej).
6.2 Asynchronous Execution with Synchronous Communica-
tion
Whenallthecommunicationbetweenpairsofprocessesisbyu singsynchronoussendandreceive
primitives, the resulting order is synchronous order. The s end and receive events of a message
appearinstantaneous,seetheexamplein Figure6.3. Wenowa ddress thefollowingquestion.
184
Processi Processj
... ...
Send(j) Send(i)
Receive (j) Receive (i)
... ...
Figure 6.4: A communication program for an asynchronous sys tem deadlocks when using syn-
chronousprimitives.
•If a program is written for an asynchronous system, say a FIFO system, will it still exe-
cute correctly if the communication is done by synchronous p rimitives instead? There is a
possibilitythattheprogrammay deadlock,as shownbythecodeinFigure6.4.
Charron-Bostetal. observedthatadistributedalgorithmd esignedtoruncorrectlyonasynchronous
systems (called A-executions ) may not run correctly on synchronous systems. An algorithm that
runson an asynchronoussystemmay deadlock on asynchronoussystem.
Examples. The asynchronous executionof Figure 6.4, illustrated in Fi gure 6.5(a) using a timing
diagram, will deadlock if run with synchronous primitives. The executions in Figure 6.5(b)–(c)
willalsodeadlock when runon asynchronoussystem.
1r3
(c) (b) (a)1 112
2
2 22
33 2
s3
3
1m11
m m2 2 2 m mm
m
m3s
1P
P1
r
rr r
rrr s
s
s sss
321
P
Figure 6.5: Illustrations of asynchronous executions and o f crowns. (a) Crown of size 2. (b)
Anothercrown ofsize2. (c) Crownofsize3.
6.2.1 ExecutionsRealizable withSynchronous Communicati on (RSC)
An execution can be modeled (using the interleaving model) a s a feasible schedule of the events
to givea total order that extends the partial order (E,≺). In an A-execution, the messages can be
madetoappearinstantaneousifthereexistsalinearextens ionoftheexecution,suchthateachsend
eventis immediatelyfollowedby itscorresponding receive event in thislinear extension. Such an
185
A-execution can be realized under synchronous communicati on and is called a Realizable with
SynchronousCommunication (RSC) execution.
Deﬁnition 15. (Non-separated linear extension .) A non-separated linear extension of (E,≺)is
a linearextension of (E,≺)suchthatforeach pair (s,r)∈T, theinterval{x∈E|s≺x≺r}
isempty.
Examples:
Figure6.2(d).∝a\}⌊ra⌋k⌉tl⌉{ts2,r2,s3,r3,s1,r1∝a\}⌊ra⌋k⌉tri}htisalinearextensionthatisnon-separated. ∝a\}⌊ra⌋k⌉tl⌉{ts2,s1,r2,s3,r3,s1∝a\}⌊ra⌋k⌉tri}ht
isalinearextensionthat isseparated.
Figure6.3(b).∝a\}⌊ra⌋k⌉tl⌉{ts1,r1,s2,r2,s3,r3,s4,r4,s5,r5,s6,r6∝a\}⌊ra⌋k⌉tri}htisalinearextensionthatisnon-separated.
∝a\}⌊ra⌋k⌉tl⌉{ts1,s2,r1,r2,s3,s4,r4,r3,s5,s6,r6,r5∝a\}⌊ra⌋k⌉tri}htisalinearextensionthat isseparated.
Deﬁnition 16. (RSC execution .) An A-execution (E,≺)is an RSC execution if and only if there
existsa non-separatedlinearextensionofthepartialorde r(E,≺).
In the non-separated linear extension, if the adjacent send event and its corresponding receive
event are viewed atomically, then that pair of events shares a common past and a common future
witheach other. Thevariousothercharacterizations of S-e xecutionsseen in Section 6.1.4 are also
seen tohold.
To use Deﬁnition 16 requires checking for all the linear exte nsions, incurs exponential over-
head. Youcan verifythisbytryingtocreateandexamineallt helinearextensionsoftheexecution
in Figure 6.5(b) or (c). Thus, Deﬁnition 16 does not providea practical test to determine whether
a program written for a nonsynchronous system, say a FIFO sys tem, will still execute correctly if
thecommunicationis doneby synchronousprimitives.
We now study a characterization of theexecution in terms of a graph structurecalled a crown;
thecrownleads toafeasibletestforaRSC execution.
Deﬁnition17. (Crown.) LetEbeanexecution. A crownofsize kinEisasequence∝a\}⌊ra⌋k⌉tl⌉{t(si,ri),i∈
{ 0,..., k-1 }∝a\}⌊ra⌋k⌉tri}htof pairs of corresponding send and receive events such that: s0≺r1,s1≺r2,...
...sk−2≺rk−1,sk−1≺r0.
Examples:
•Figure 6.5(a): The crown is ∝a\}⌊ra⌋k⌉tl⌉{t(s1,r1),(s2,r2)∝a\}⌊ra⌋k⌉tri}htas we have s1≺r2ands2≺r1. This
executionrepresents theprogramexecutionin Figure6.4.
•Figure6.5(b): Thecrownis ∝a\}⌊ra⌋k⌉tl⌉{t(s1,r1),(s2,r2)∝a\}⌊ra⌋k⌉tri}htas wehaves1≺r2ands2≺r1.
•Figure 6.5(c): The crown is ∝a\}⌊ra⌋k⌉tl⌉{t(s1,r1),(s3,r3),(s2,r2)∝a\}⌊ra⌋k⌉tri}htas we haves1≺r3ands3≺r2and
s2≺r1.
•Figure 6.2(a): The crown is ∝a\}⌊ra⌋k⌉tl⌉{t(s1,r1),(s2,r2),(s3,r3)∝a\}⌊ra⌋k⌉tri}htas we haves1≺r2ands2≺r3and
s3≺r1.
186
1. Deﬁne the ֒→:T ×Trelation on messages in the execution (E,≺)as follows. Let ֒→
([s,r],[s′,r′])if and only if s≺r′. Observe that the condition s≺r′(which has the form
used in the deﬁnition of a crown) is implied by all the four con ditions: (i)s≺s′, or (ii)
s≺r′, or(iii)r≺s′,and (iv)r≺r′.
2. Now deﬁne a directedgraphG֒→(= T,֒→), where the vertex set is the set of messages T
and theedgesetisdeﬁned by ֒→.
Observe that the relation ֒→:T ×Tis a partial order if and only if G֒→has no cycle, i.e.,
theremustnotbeacyclewithrespect to ֒→on theset ofcorresponding (s,r)events.
3. It can be seen from the deﬁnition of a crown (Deﬁnition 17) t hatG֒→has a directed cycleif
and onlyif (E,≺)hasa crown.
Figure6.6: Thecrown testtodeterminetheexistenceofcycl icdependenciesamongmessages.
In a crown, the send event siand receive event ri+1may lie on the same process (e.g., Fig-
ure 6.5(c)) or may lieon different processes (e.g., Figure 6 .5(a)). We can also makethe following
observations.
•InanexecutionthatisnotCO(seetheexampleinFigure6.2(a )),theremustexistpairs (s,r)
and(s′,r′)such thats≺r′ands′≺r. We will show that it is possible to genralize this to
statethat a non-CO executionmust havea crown ofsize at leas t 2. (Exercise4 askes you to
provethatina non-COexecution,theremustexistacrownofs izeexactly2.)
•COexecutionsthatarenotsynchronous,alsohavecrowns,e. g.,theexecutioninFigure6.2(b)
has acrownofsize3.
Intuitively, the cyclic dependencies in a crown indicate th at it is not possible to ﬁnd a linear
extension in which all the (s,r)event pairs are adjacent. In other words, it is not possible t o
scheduleentiremessagesin aserial manner,and hencetheex ecutionis notRSC.
To determine whether the RSC property holds in (E,≺), we need to determine whether there
existanycyclicdependenciesamongmessages. Ratherthani ncurringtheexponentialoverheadof
checking all linear extensions of E, we can check for crowns by using the test in Figure 6.6. On
thesetofmessages T, wedeﬁnean ordering ֒→suchthatm֒→m′ifandonlyif s≺r′.
Example: By drawing the directed graph (T,֒→)for each of the executions in Figures 6.2, 6.3,
and 6.5, it can be seen that the graphs for Figures 6.2(d) and F igure 6.3 are acyclic. The other
graphs haveacycle.
Thistest leadsto thefollowingtheorem.
Theorem 6. Crown criterion. Thecrown criterion states that an A-computation is RSC, i.e., it
can berealizedona system withsynchronouscommunication, ifand onlyifit containsno crown.
187
Example: Using the directed graph (T,֒→)for each of the executions in Figures 6.2, 6.3(a), and
6.5, it can be seen that the executions in Figures 6.2(d) and F igure 6.3(a) are RSC. The others are
notRSC.
Althoughcheckingforanon-separatedlinearextensionof (E,≺)hasexponentialcost,check-
ing for the presence of a crown based on the message schedulin g test of Figure 6.6) can be per-
formedintimethatislinearinthenumberofcommunicatione vents(seeExercise3). Anexecution
is not RSC and its graph G֒→contains a cycle if and only if in the corresponding space-ti me dia-
gram,itispossibletoformacyclebymoving(i)alongmessag earrowsineitherdirection,but(ii)
always goingleft to rightalongthetimelineofanyprocess.
AsanRSCexecutionhasanon-separatedlinearextension,it ispossibletoassignscalartimes-
tampstoevents,as itwas assignedforasynchronousexecuti on(Deﬁnition14),as follows.
Deﬁnition 18. (Timestamps for a RSC execution. ) An execution (E,≺)is RSC if and only if
thereexistsa mappingfrom EtoT(scalartimestamps)suchthat
•foranymessage M,T(s(M)) =T(r(M))
•foreach (a,b)in(E×E)/T,a≺b=:T(a)<T(b)
From the acyclic message scheduling criterion (Theorem 6) a nd the timestamping property
above, it can be observed that an A-execution is RSC if and onl y if its timing diagram can be
drawnsuch thatall themessagearrowsare vertical.
6.2.2 Hierarchy of Ordering Paradigms
LetSYNC(orRSC),CO,FIFO,andAdenotethesetofallpossibleexecutionsorderedbysyn-
chronousorder,causalorder,FIFOorder,andnon-FIFOorde r,respectively. Wehavethefollowing
results.
SYNC
COFIFO
AA
FIFOCO
SYNC
(b) (a) 
Figure6.7: Hierarchyofexecutionclasses.(a) Venndiagra m. (b)Exampleexecutions.
188
•Foran A-execution,A isRSC ifand onlyifAis an S-execution.
•RSC⊂CO⊂FIFO⊂A . This hierarchy is illustrated in Figure 6.7(a), and exampl e
executionsofeach class areshownside-by-sideinFigure6. 7(b).
Figure 6.1(a) shows an execution that belongs to Abut not toFIFO. Figure 6.2(a) shows
an execution that belongs to FIFObut not toCO. Figures 6.2(b) and (c) show executions
thatbelongtoCObutnottoRSC.
•Theabovehierarchy impliesthat someexecutionsbelonging to a classXwillnot belongto
any of the classes included in x. Thus, there are more restrictions on the possible message
orderingsinthesmallerclasses. Hence,weinformallysayt hattheincludedclasseshaveless
concurrency. Thedegreeofconcurrencyis mostin Aand least inSYNC.
•A program using synchronous communication is easiest to dev elop and verify. A program
usingnon-FIFOcommunication,resultinginan A-execution,ishardesttodesignandverify.
This is because synchronous order offers the most simplicit y due to the restricted number
of possibilities, whereas non-FIFO order offers the greate st difﬁculties because it admits a
muchlarger setofpossibilitiesthatthedeveloperand veri ﬁerneed toaccount for.
Thus, there is an inherent trade-off between the amount of co ncurrency provided, and the ease of
designingand verifyingdistributedprograms.
6.2.3 Simulations
Asynchronous programs on synchronous systems: Theorem 6 indicates that an A-execution
can be run using synchronous communication primitives if an d only if it is an RSC execution.
The events in the RSC execution are scheduled as per some nons eparated linear extension, and
adjacent (s,r)eventsinthislinearextensionareexecutedsequentiallyi nthesynchronoussystem.
Thepartialorderoftheasynchronousexecutionremainsunc hanged.
If an A-execution is not RSC, then there is no way to schedule t he events to make them RSC,
withoutactuallyalteringthepartialorderofthegivenA-e xecution. However,thefollowingindirect
strategy that does not alter the partial order can be used. Ea ch channel Ci,jis modeled by a
controlprocess Pi,jthatsimulatesthechannelbuffer. Anasynchronouscommuni cationfrom itoj
becomes a synchronous communicationfrom itoPi,jfollowed by a synchronous communication
fromPi,jtoj. Thisenablesthedecouplingofthesenderfromthereceiver ,afeaturethatisessential
in asynchronoussystems. Thisapproach is illustratedin Fi gure6.8. Thecommunicationeventsat
the application processes PiandPjare encircled. Observe that it is expensive to implement the
channel processes.
Synchronous programs on asynchronous systems: A (valid) S-execution can be trivially real-
ized on an asynchronous system by scheduling the messages in the order in which they appear in
the S-execution. The partial order of the S-execution remai ns unchanged but the communication
189
PPi
Pji,j
j,iPm
m
m’m’
Figure 6.8: Modeling channels as processes to simulate an ex ecution using asynchronous primi-
tiveson an synchronoussystem.
occursonanasynchronoussystemthatusesasynchronouscom municationprimitives. Onceames-
sage send event is scheduled, the middleware layer waits for an acknoweldgment; after the ack is
received,thesynchronoussend primitivecompletes.
6.3 SynchronousProgramOrderonanAsynchronousSystem
There do not exist real systems with instantaneous communic ation that allows for synchronous
communication to be naturally realized. We need to address t he basic question of how a sys-
tem with synchronous communication can be implemented. We ﬁ rst examine nondeterminism
in program execution, and CSP as a representative synchrono us programming language, before
examiningan implementationofsynchronouscommunication .
Non-determinism. The discussions on the message orderings and their characte rizations so far
assumed a given partial order. This suggests that the distri buted programs are deterministic , i.e.,
repeatedrunsofthesameprogramwillproducethesameparti alorder. Inmanycases,programsare
non-deterministic inthefollowingsenses. (Wearenotconsideringheretheunp redictablemessage
delays which cause different runs to non-deterministicall y have different global orderings of the
eventsin physicaltime.)
1. Areceivecallcanreceiveamessagefromanysenderwhohas sentamessage,iftheexpected
sender is not speciﬁed. The receive calls in most of the algor ithms in Chapter 5 are nonde-
terministic in this sense – the receiver is willing to perfor m a rendezvous with any willing
and ready sender.
2. Multiple send and receive calls which are enabled at a proc ess can be executed in an inter-
changeableorder.
Ifisends toj, andjsends toiconcurrently using blocking synchronous calls, there resu lts
a deadlock, similar to the one in Figure 6.4. However, there i s no semantic dependency
190
between the send and the immediately following receive at ea ch of the processes. If the
receive call at one of the processes can be scheduled before t he send call, then there is no
deadlock. In this section, we considerscheduling synchron ous communicationevents (over
an asynchronoussystem).
6.3.1 Rendezvous
Oneformofgroupcommunicationiscalled multiwayrendezvous ,whichisasynchronouscommu-
nication among an arbitrary numberof asynchronous process es. All theprocesses involved“meet
with each other”, i.e., communicate “synchronously” with e ach other at one time. The solutions
to this problem are fairly complex, and we will not consider t hem further as this model of syn-
chronous communication is not popular. Here, we study rende zvous between a pair of processes
at atime,whichis called binaryrendezvous as opposedtothe multiwayrendezvous .
Support for binary rendezvous communication was ﬁrst provided by programming languages
such as CSP and Ada. We consider here a subset of CSP. In these l anguages, the repetitive com-
mand (the⋆operator) over the alternative command (the ||operator) on multiple guarded com-
mands(each havingtheform Gi−→CLi) isused,as follows.
∗[G1−→CL1||G2−→CL2|| ··· ||Gk−→CLk]
Each communication command may be a part of a guard Gi, and may also appear within the
statementblock CLi. AguardGiisabooleanexpression. Ifaguard Gievaluatestotruethen CLi
is said to be enabled, otherwiseCLiis said to be disabled. A send command of local variable x
to processPkis denoted as “ x!Pk”. A receive from process Pkinto local variable xis denoted as
“Pk?x”. Some typical observations about synchronous communicat ion under binary rendezvous
are asfollows.
•For the receive command, the sender must be speciﬁed. Howeve r, multiple recieve com-
mandscan exist. Atypecheck on thedatais implicitlyperfor med.
•Send and received commands may be individually disabled or e nabled. A command is dis-
abled if it is guarded and the guard evaluates to false. The guard would likely contain an
expressionon somelocal variables.
•Synchronouscommunicationisimplementedby scheduling messagesunderthecoversusing
asynchronous communication. Scheduling involves pairing of matching send and receive
commandsthatarebothenabled. Thecommunicationeventsfo rthecontrolmessagesunder
thecoversdo notalterthepartialorderoftheexecution.
The concept underlying binary rendezvous , which provides synchronous communication, dif-
fers from the concept underlying the classiﬁcation of synch ronous send and receive primitives as
blockingornonblocking(studiedinChapter1). Binaryrendezvous explicitlyassumesthatmultiple
191
send and receives are enabled. Any send or receive event that can be “matched” with the corre-
sponding receive or send event can be scheduled. This is dyna mically scheduling the ordering of
eventsand thepartialorderoftheexecution.
Mack(M)permission(M)
M request(M)
(b) (a) higher
priority
lower
priorityjPiP
Figure 6.9: Messages used to implementsynchronous order. Pihas higherprioritythan Pj. (a)Pi
issuesSEND(M). (b) PjissuesSEND(M).
6.3.2 Algorithm forBinary Rendezvous
Variousalgorithmswereproposedtoimplement binaryrendezvous inthe1980s. Thesealgorithms
typically share the following features. At each process, th ere is a set of tokens representing the
currentinteractionsthatareenabledlocally. Ifmultiple interactionsareenabled,aprocesschooses
one of them and tries to “synchronize” with the partner proce ss. The problem reduces to one of
schedulingmessagessatisfyingthefollowingconstraints .
•Schedule on-line, atomically, and in a distributed manner, i.e., the scheduling code at any
process doesnotknowtheapplicationcodeofotherprocesse s.
•Scheduleinadeadlock-freemanner(i.e.,crown-free),suc hthatboththesenderandreceiver
areenabled foramessagewhen itisscheduled.
•Schedule to satisfy the progress property (i.e., ﬁnd a sched ule within a bounded number of
steps)in additionto thesafety (i.e., correctness)proper ty.
Additional features of a good algorithm are: (i) symmetry or some form of fairness, i.e., not
favoring particular processes over others during scheduli ng, and (ii) efﬁciency, i.e., using as few
messagesas possible,and involvingas lowatimeoverheadas possible.
We nowoutlineasimplealgorithmthat makesthefollowingas sumptions.
1. Receivecommandsare foreverenabled from allprocesses.
2. A send command, once enabled, remains enabled until it com pletes, i.e., it is not possible
thatasendcommandgetsdisabled(byitsguardgettingfalsi ﬁed)beforethesendisexecuted.
3. To prevent deadlock, process identiﬁers are used to intro duce asymmetry to break potential
crownsthatarise.
192
(message types)
M,ack(M),request(M) ,permission(M)
1.Piwantsto execute SEND(M)toalower priority process Pj:
Piexecutes send(M)and blocks until it receives ack(M)fromPj. The send event SEND(M) now
completes.
AnyM’message(fromahigherpriorityprocesses)and request(M’) requestforsynchronization (from
alower priority processes) received during theblocking pe riod are queued.
2.Piwantsto execute SEND(M)toahigher priority process Pj:
(a)Piseeks permission from Pjby executing send(request(M)) .
//toavoid deadlock in which cyclically blocked processes q ueue messages.
(b) While Piiswaiting for permission, itremains unblocked.
i. If amessage M′arrives from ahigher priority process Pk,Piaccepts M′by scheduling a
RECEIVE(M’)event and then executes send(ack(M’)) toPk.
ii. If a request(M’) arrives from a lower priority process Pk,Piexecutes
send(permission(M’)) toPkand blocks waiting for the message M′. When M′
arrives, the RECEIVE(M’)event is executed.
(c) Whenthe permission(M) arrives, Piknowspartner Pjissynchronizedand Piexecutessend(M).
TheSEND(M)now completes.
3.Request(M) arrival at Pifrom a lowerpriority process Pj:
At the time a request(M) is processed by Pi, process Piexecutes send(permission(M)) toPjand
blocks waiting for the message M. When Marrives, the RECEIVE(M) event is executed and the
process unblocks.
4.Message Marrival at Pifrom ahigherpriority process Pj:
At the time a message Mis processed by Pi, process Piexecutes RECEIVE(M) (which is assumed
to bealways enabled) and then send(ack(M)) toPj.
5.Processing when Piis unblocked:
When Piis unblocked, it dequeues the next (if any) message from the q ueue and processes it as a
message arrival (as per Rules 3or4).
Figure 6.10: A simpliﬁed implementation of synchronous ord er. Code shown is for process Pi,
1≤i≤n.
4. Each process attemptsto scheduleonlyone sendeventatany time.
Thealgorithmillustrateshowcrown-free messagescheduli ngisachievedon-line.
The message types used are: (i) M, (ii)ack(M), (iii)request(M) , and (iv) permission(M) . A
process blocks when it knows for sure that it can successfull y synchronize the current message
with the partner process. Each process maintains a queue tha t is processed in FIFO order only
when theprocess is unblocked. When a process is blocked wait ingfor a particularmessagethat it
iscurrently synchronizing,anyothermessagethatarrives isqueued up.
193
Executioneventsinthesynchronousexecutionareonlythe sendofthemessage Mandreceive
ofthemessage M. Thesend andreceiveeventsfortheothermessagetypes– ack(M),request(M) ,
andpermission(M) which are control messages – are under the covers, and are not included in
thesynchronousexecution. Themessages request(M) ,ack(M),andpermission(M) useM’sunique
tag;themessageMisnotincludedinthesemessages. Weuseca pitalSEND(M)andRECEIVE(M)
to denote the primitives in the application execution, the l ower case send and receive are used for
thecontrolmessages.
The algorithm to enforce synchronous order is given in Figur e 6.10. The key rules to prevent
cyclesamongthemessagesare summarizedas follows.
•To send to a lower priority process, messages Mandack(M)are involved in that order.
The sender issues send(M)and blocks until ack(M)arrives. Thus, when sending to a lower
priority process, the sender blocks waiting for the partner process to synchronize and send
an acknowledgement.
•To send to a higher priority process, messages request(M) ,permission(M) andMare in-
volved, in that order. The sender issues send(request(M)) , do not block, and awaits permis-
sion. When permission(M) arrives,thesenderissues send(M).
Thus, when sending to a higher priority process, the sender a sks the higher priority pro-
cess via the request(M) to give permission to send. When the higher priority process gives
permissiontosend, thehigherpriorityprocess,which isth eintendedreceiver,blocks.
In either case, a higher priority process blocks on a lower pr iority process. So cyclic waits are
avoided.
Pi
Pj
kP(highest priority)
(lowest priority)
(a) (b)M, sent to lower
      priority process
request(M)
ack(M)
permission(M)
M, sent to higher
      priority process
blocking period
Figure6.11: Examplesshowinghowtoschedulemessagessent withsynchronousprimitives.
In more detail, a cyclic wait is prevented because before sen ding a message Mto a higher
priority process, a lower priority process requests the hig her priority process for permission to
synchronize on M, in a nonblocking manner. While waiting for this permission , there are two
possibilities.
194
1. Ifamessage M′fromahigherpriorityprocessarrives,itisprocessedbyar eceive(assuming
receivesare alwaysenabled)and ack(M’)isreturned. Thus,acyclicwait isprevented.
2. Also,whilewaitingforthispermission,ifa request(M’) fromalowerpriorityprocessarrives,
apermission(M’) isreturned and theprocess blocksuntil M′actuallyarrives.
Notethatthe receive(M’) eventeffectivelygetspermutedbeforethe send(M)event(steps2(b)iand
2(b)ii). Thisis achangetothepartialorder embodiedin the program.
Examples: Figure6.11showstwoexamplesofhowthealgorithmbreaks cy clicwaitstoschedule
messages. Observe that in all cases in the algorithm, a highe r priority process blocks on lower
priority processes, irresepctive of whether the higher pri ority process is the intended sender or
the receiver of the message beign scheduled. In Figure 6.11( a), at process Pk, the receive of the
message from Pjeffectively gets permuted before Pk’s ownsend(M)event due to step 2(b)i. In
Figure 6.11(b), at process Pj, the receive of the request(M’) message from Pjeffectively causes
M′to be permuted before Pj’s own message that it was attempting to schedule with Pi, due to
step2(b)ii.
6.4 GroupCommunication
Processesacrossadistributedsystemcooperatetosolveaj ointtask. Often,theyneedtocommuni-
cate witheach otheras a group,and therefore thereneeds to b esupportfor groupcommunication .
Amessagebroadcast isthesendingofamessagetoallmembersinthedistributeds ystem. Theno-
tionofasystemcan beconﬁnedonlytothosesites/processes participatinginthejointapplication.
Reﬁning the notion of broadcasting , there is multicasting wherein a message is sent to a certain
subset, identiﬁed as a group, of the processes in the system. At the other extreme is unicasting
whichis thefamiliarpoint-to-pointmessagecommunicatio n.
Broadcast and multicast support can be provided by the netwo rk protocol stack using variants
of the spanning tree. This is an efﬁcient mechanism for distr ibuting information. However, the
hardware-assistedorNetworkLayerprotocolassistedmult icastcannotefﬁcientlyprovidefeatures
such asthefollowing.
•Application-speciﬁcorderingsemanticson theorderofdel iveryofmessages.
•Adaptinggroupstodynamicallychangingmembership.
•Sendingmulticaststo an arbitrary setofprocesses at each s end event.
•Providingvariousfault-tolerancesemantics.
If a multicast algorithm requires the sender to be a part of th e destination group, the multicast
algorithm is said to be a closed group algorithm. If the sender of the multicast can be outside the
destinationgroup,themulticastalgorithmissaidtobean opengroup algorithm. Opengroupalgo-
rithms are more general, and therefore more difﬁcult to desi gn and more expensiveto implement,
195
thanclosedgroupalgorithms. Closedgroupalgorithmscann otbeusedinseveralscenariossuchas
in a large system (e.g., on-line reservation or Internet ban king system) where client processes are
short-livedandinlargenumbers. Alsoworthnotingisthatf ormulticastalgorithms,thenumberof
groupsmay bepotentiallyexponential,i.e., O(2n), and algorithmsthat havetoexplicitlytrack the
groupscan incurthishighoverhead.
In the remainder of this chapter, we will examine multicast a nd broadcast mechanisms under
varying degrees of strictness of assumptions on the order of delivery of messages. Two popular
orders forthedeliveryofmessages wereproposed inthecont extofgroup communication: causal
orderandtotal order . Much of the seminal work on group communication was initiat ed by the
ISIS project.
6.5 CausalOrder(CO)
Causal order has many applications such as updating replica ted data, allocating requests in a fair
manner, and synchronizingmultimediastreams. We explainh ere the useof causal order in updat-
ing replicas of a data item in the system. Consider Figure 6.1 2(a) which shows two processes P1
andP2that issue updates to the three replicas R1(d),R2(d), andR3(d)of data item d. Message
mcreates a causality between send(m1)andsend(m2). IfP2issues its update causally after P1
issued its update, then P2’s update should be seen by the replicas after they see P1’s update, in
order to preserve the semantics of the application. (In this case, CO is satisﬁed.) However, this
may happen at some, all, or none of the replicas. Figure 6.12( b) shows that R1seesP2’s update
ﬁrst, whileR2andR3seeP1’s update ﬁrst. Here, CO is violated. Figure 6.12(b) shows th at all
replicas see P2’s update ﬁrst. However, CO is still violated. If message mdid not exist as shown,
thentheexecutionsshowninFigure6.12(b)and(c) wouldsat isfyCO.
P1P2P
P1R1 R2 R3
R3
2R1
R2m mm1 m1
m2 m2
(c) (b) (a)
Figure6.12: Updatesto objectreplicas areissuedby twopro cesses.
GivenasystemwithFIFOchannels,causalorderneedstobeex plicitlyenforcedbyaprotocol.
Thefollowingtwocriteriamustbemetby acausal orderingpr otocol.
•Safety:In order to prevent causal order from being violated, a messa geMthat arrives at a
196
(local variables)
array ofint SENT [1... n,1... n]
array ofint DELIV [1... n] //DELIV [k]=#messages sent by kthat aredelivered locally
(1)sendevent , where Piwants tosend message MtoPj:
(1a)send(M,SENT )toPj;
(1b)SENT [i,j]←−SENT [i,j] + 1.
(2)message arrival, when(M,ST )arrives at PifromPj:
(2a)deliver MtoPiwhenfor eachprocess x,
(2b) DELIV [x]≥ST[x,i];
(2c)∀x,y, SENT [x,y]←−max(SENT [x,y],ST[x,y]);
(2d)DELIV [j]←−DELIV [j] + 1.
Figure 6.13: Canonical algorithm by Raynal-Schiper-Toueg (RST) to implement causal ordering
ofmessages. Codefor Pi,1≤i≤n.
processmayneedtobebuffereduntilallsystemwidemessage ssentinthecausalpastofthe
send(M)eventto thatsamedestinationhavealready arrived.
Therefore, we distinguish between the arrival of a message a t a process (at which time it is
placedinalocalsystembuffer)andtheeventatwhichthemes sageisgiventotheapplication
process(whentheprotocoldeemsitsafetodosowithoutviol atingcausalorder). Thearrival
ofamessageistransparenttotheapplicationprocess. Thed eliveryeventcorrespondstothe
receiveeventin theexecutionmodel.
•Liveness: A messagethatarrivesat aprocess musteventuallybedelive redtotheprocess.
Both the algorithms we will study in this section allow each s end event to unicast, multicast, or
broadcast amessagein thesystem.
6.5.1 The Raynal-Schiper-Toueg Algorithm
Intuitively,it seems logical that each message Mshould carry with it, a log of all other messages,
ortheiridentiﬁers,sentcausallybefore M’ssendevent,andsenttothesamedestination dest(M).
Thislogcanthenbeexaminedtoensurewhetheritissafetode liveramessage. Allalgorithmsaim
toreducethislogoverhead,andthespaceandtimeoverheado fmaintainingtheloginformationat
the processes. Figure 6.13 gives a canonical algorithm that is representative of several algorithms
thattrytoreducethesizeofthelocalspaceandmessagespac eoverheadbyvarioustechniques. In
ordertoimplementsafety,themessagespiggybackthecontr olinformationthathelpstodetermine
whenitissafetodeliverthemessagetothedestination. FIF Ochannelsareassumedinthesystem.
Eachprocessmaintainsan n×narraySENTandasizenarrayDELIV.SENT i[j,k]atprocess
Pigives the number of messages sent by PjtoPk, as known to Pi.DELIV i[j]gives the number
of messages from Pjthat have been delivered to Pi. Safety is implemented primarily by step
197
(2a). Liveness is implemented under the assumption that the re are no failures, and that message
propagation/transmissiontimesareﬁnite.
Complexity: This algorithm takes O(n2)integers space at each process, and the message space
overhead is also n2integers. The time complexityat each process for each send a nd deliverevent
isO(n2).
6.5.2 The Kshemkalyani-Singhal OptimalAlgorithm
The space and time optimal algorithm of Kshemkalyani and Sin ghal (KS) uses the following no-
tation. The athmulticast message sent by process iis denotedMi,a, and the set of destinations
of this multicast is denoted Mi,a.Dests. The algorithm uses the following Delivery Condition for
correctness: A message M∗that carries information “ d∈M.Dests ", where message Mwas sent
todinthecausal pastof Send(M∗), isnot deliveredto difMhasnot yetbeen deliveredto d.
A natural question to address to obtain optimality is: For ho w long should the information “ d
∈Mi,a.Dests”bestoredinthelogataprocess,andpiggybackedonmessage s? Thefollowingare
thenecessary and sufﬁcientconditionsonhowlongthisinfo rmationshouldbestored.
AnoptimalCOalgorithmstoresinlocalmessagelogsandprop agatesonmessages,information
of the form “ dis a destination of M” about a message Msent in the causal past, as long as and
onlyas longas
(PropagationConstraintI: )it isnotknownthatthemessage Misdeliveredto d, and
(PropagationConstraintII: )itisnotknownthatamessagehasbeensentto dinthecausalfuture
ofSend(M), and hence it is not guaranteed using a reasoning based on tra nsitivitythat the
messageMwillbedeliveredto dinCO.
The Propagation Constraints also imply that if either (I) or (II) is false, the information “ d∈
M.Dests ” mustnotbe stored or propagated, even to remember that (I) or (II) has been falsiﬁed.
Stateddifferently,theinformation“ d∈Mi,a.Dests”mustbeavailableinthecausalfutureofevent
ei,a, but
•notin thecausal futureof Deliver d(Mi,a), and
•not in the causal future of ek,c, whered∈Mk,c.Destsand there is no other message sent
causallybetween Mi,aandMk,ctothesamedestination d.
Inthecausalfutureof Deliver d(Mi,a),andSend(Mk,c),theinformationisredundant;elsewhere,it
isnecessary. Additionally,tomaintainoptimality,nooth erinformationshouldbestored,including
informationabout what messages havebeen delivered. As inf ormationabout what messages have
been delivered (or are guaranteed to be delivered without vi olating causal order) is necessary for
theDeliveryCondition,thisinformationisinferred using aset-operationbased logic.
The Propagation Constraints are illustrated with the help o f Fig. 6.14. The message Mis sent
by processiat eventetoprocessd. Theinformation“ d∈M.Dests ”
198
e6e8d
i
e4e7e1
MDeliver(M)
event on any causal path between event e and this eventmessage sent to d
info "d is a dest. of M" must not exist for optimalityinfo "d is a dest. of M" must exist for correctnessevent at which message is sent to d, and there is no suchborder of causal future of corresponding evente
e‘‘e‘e5
e2e3
Figure6.14: Illustratingthenecessary and sufﬁcientcond itionsforcausal ordering.
•mustexistat e1ande2because(I)and (II) aretrue.
•mustnotexistat e3because(I) isfalse
•mustnotexistat e4,e5,e6because (II)is false
•mustnotexistat e7,e8because(I)and (II) arefalse
Information about messages (i) not known to be delivered and (ii) not guaranteed to be deliv-
ered in CO, is explicitly tracked by the algorithm using ( source, timestamp, destination )informa-
tion. The informationmustbe deleted as soonas either(i) or (ii)becomes false. The key problem
in designing an optimal CO algorithm is to identify the event s at which (i) or (ii) becomes false.
Information about messages already delivered and messages guaranteed to be delivered in CO is
implicitly tracked without storing or propagating it, and is derived fr om the explicit information.
Such implicit information is used for determining when (i) o r (ii) becomes false for the explicit
informationbeing storedorcarried in messages.
The algorithm is given in Figures 6.15 and 6.16. Procedure SN D is executed atomically. Pro-
cedure RCV is executed atomically except for a possible inte rruption in step RCV(1) where a
nonblocking wait is required to meet the Delivery Condition . Note that the pseudo-code can be
restructuredtocompletetheprocessingofeachinvocation ofSNDandRCVproceduresinasingle
pass of the data structures, by always maintaining the data s tructures sorted row-major and then
column-major.
1.Explicit Tracking: Tracking of (source, timestamp, destination) information for messages
(i)notknowntobedeliveredand(ii)notguaranteedtobedel iveredinCO,isdoneexplicitly
using thel.Destsﬁeld of entries in local logs at nodes and o.Destsﬁeld of entries in mes-
sages. Sets li,a.Destsandoi,a.Destscontain explicit information of destinations to which
199
(local variables)
clock j←−0; //localcounterclockat node j
SRj[1...n]←−0; // SRj[i]isthe timestampoflast msg. from ideliveredto j
LOG j={(i,clock i,Dests )}←−{∀ i,(i,0,∅)};
//Eachentrydenotesa messagesentin thecausalpast,by iatclock i.Destsis theset of remaining
destinations
//forwhichit isnotknownthat Mi,clock i(i)hasbeendelivered,or(ii)isguaranteedtobedelivered inCO.
SND: jsendsamessage M toDests :
1.clock j←−clock j+ 1;
2.for all d∈M.Dests do:
OM←−LOG j; //OMdenotes OMj,clockj
forall o∈OM,modify o.Destsasfollows:
ifd∝\⌉}atio\slash∈o.Deststheno.Dests←−(o.Dests\M.Dests );
ifd∈o.Deststheno.Dests←−(o.Dests\M.Dests )/uniontext{d};
//Do notpropagateinformationaboutindirectdependenciest hatare
//guaranteedtobetransitivelysatisﬁed whendependencieso fMaresatisﬁed.
forall os,t∈OMdo
ifos,t.Dests =∅/logicalandtext(∃o′
s,t′∈OM|t < t′)thenOM←−OM\{os,t};
//donotpropagateolderentriesforwhich Destsﬁeld is∅
send(j,clock j,M,Dests,O M)tod;
3.for all l∈LOG jdol.Dests←−l.Dests\Dests;
//Donotstoreinformationaboutindirectdependenciesthata reguaranteed
//tobetransitivelysatisﬁed whendependenciesof Maresatisﬁed.
Execute PURGE _NULL_ENTRIES (LOG j); // purge l∈LOG jifl.Dests =∅
4.LOG j←−LOG j/uniontext{(j,clock j,Dests )}.
Figure 6.15: The algorithm by Kshemkalyani-Singhal to opti mally implement causal ordering of
messages. Codefor Pj,1≤j≤n. (Part 1 of2)
Mi,aisnotguaranteedtobedeliveredinCO andisnotknowntobede livered. Theinforma-
tion about “d∈Mi,a.Dests" is propagated up to the earliest events on all causal paths f rom
(i,a)at which it is known that Mi,ais delivered to dor is guaranteed to be delivered to din
CO.
2.Implicit Tracking: Tracking of messages that are either (i) already delivered, or (ii) guar-
anteed tobedeliveredinCO, is performed implicitly.
The information about messages (i) already delivered or (ii ) guaranteed to be delivered in
CO, is deleted and not propagated because it is redundant as f ar as enforcing CO is con-
cerned. However, it is useful in determining what informati on that is being carried in other
messages and that is being stored in logs at othernodes has be come redundant and thus can
bepurged. Thissemanticsisimplicitlystoredandpropagat ed. Thisinformationofmessages
that are (i) already delivered or (ii) guaranteed to be deliv ered in CO, is tracked without ex-
200
RCV: jreceives amessage (k,tk,M,Dests,O M)fromk:
1. //DeliveryCondition;ensurethatmessagessent causallybef oreM aredelivered.
for all om,tm∈OMdo
ifj∈om.tm.Destswait until tm≤SRj[m];
2. Deliver M; SRj[k]←−tk;
3.OM←−{(k,tk,Dests )}/uniontextOM;
for all om,tm∈OMdoom,tm.Dests←−om,tm.Dests\{j};
//deletethenowredundantdependencyofmessagerepresented byom,t msent to j
4. //Merge OMandLOG jbyeliminatingallredundantentries.
//Implicitlytrack“alreadydelivered”&“guaranteedtobede liveredinCO” messages.
for all om,t∈OMandls,t′∈LOG jsuch that s=mdo
ift < t′/logicalandtextls,t∝\⌉}atio\slash∈LOG jthenmarkom,t;
//ls,thadbeendeletedorneverinserted,as ls,t.Dests=∅inthecausalpast
ift′< t/logicalandtextom,t′∝\⌉}atio\slash∈OMthenmarkls,t′;
//om,t′∝\⌉}atio\slash∈OMbecause ls,t′hadbecome∅atanotherprocessinthecausalpast
Delete all marked elements in OMandLOG j; // deleteentriesaboutredundantinformation
for all ls,t′∈LOG jandom,t∈OM,such that s=m/logicalandtextt′=tdo
ls,t′.Dests←−ls,t′.Dests/intersectiontextom,t.Dests; // deletedestinationsforwhichDelivery
//Conditionissatisﬁed orguaranteedtobe satisﬁedasper om,t
Delete om,tfromOM; // informationhasbeenincorporatedin ls,t′
LOG j←−LOG j/uniontextOM; // mergenonredundantinformationof OMintoLOG j
5.PURGE _NULL_ENTRIES (LOG j). // Purgeolderentries lforwhich l.Dests =∅
PURGE_NULL_ENTRIES( Logj)://Purgeolderentries lforwhich l.Dests =∅isimplicitlyinferred
for all ls,t∈Logjdo
ifls,t.Dests =∅/logicalandtext(∃l′
s,t′∈Logj|t < t′)thenLogj←−Logj\{ls,t}.
Figure 6.16: (contd.) The algorithm by Kshemkalyani-Singh al to optimally implement causal
orderingofmessages. Code for Pj,1≤j≤n. (Part 2 of2)
plicitly storing it! Rather, the algorithm derives it from t he existing explicit information
about messages (i) not known to be delivered and (ii) not guar anteed to be delivered in CO,
byexaminingonly oi,a.Destsorli,a.Dests, whichis apart oftheexplicitinformation.
Thereare twotypesofimplicittracking.
•The absence of a node id from destination information – i.e., ∃d∈Mi,a.Dests|d∝\⌉}atio\slash∈
li,a.Dests/logicalortextd∝\⌉}atio\slash∈oi,a.Dests–implicitlycontainsinformationthatthemessagehasbeen
already delivered or is guaranteed to be delivered in CO to d. Clearly,li,a.Dests=∅
oroi,a.Dests=∅implies that message Mi,ahas been delivered or is guaranteed to
be delivered in CO to alldestinations in Mi,a.Dests. An entry whose .Dests =∅
is maintained because of the implicit information in it, viz ., that of known delivery or
guaranteedCOdeliverytoalldestinationsofthemulticast ,isusefultopurgeredundant
201
informationas perthePropagationConstraints.
•As the distributed computation evolves, several entries li,a1,li,a2, ... such that∀p,
li,ap.Dests=∅may exist in a node’s log and a message may be carrying several en-
triesoi,a1,oi,a2, ... such that∀p,oi,ap.Dests=∅. The second implicit tracking uses a
mechanismtopreventtheproliferationofsuchentries. The mechanismisbasedonthe
following observation: “For any two multicasts Mi,a1,Mi,a2such thata1<a2, ifli,a2
∈LOG j, thenli,a1∈LOG j. (Likewisefor anymessage.)"
Therefore, if li,a1.Destsbecomes∅at a nodej, then it can be deleted from LOG j
provided∃li,a2∈LOG jsuch thata1< a2. The presence of such li,a1s inLOG jis
automatically implied by the presence of entry li,a2inLOG j. Thus, for a multicast
Mi,z, ifli,zdoesnot existin LOG j,thenli,z.Dests =∅implicitlyexistsin LOG jiff∃
li,a∈LOG j|a>z.
As a result of the second implicit tracking mechanism, a node does not keep (and
a message does not carry) entries of type li,a.Dests =∅in its log. However, note
that a node must always keep at least one entry of type li,a(the one with the highest
timestamp)initslogforeach sendernode i. Thesameholdsformessages.
Theinformationtrackedimplicitlyisusefulinpurginginf ormationexplicitlycarriedinother
OM′′s and stored in LOGentries about “yet to be delivered to" destinations for the s ame
messageMi,aas well as for messages Mi,a′, wherea′< a. Thus, whenever oi,ain some
OM′propagates to node j, in step RCV(4), (i) theimplicitinformationin oi,a.Destsis used
to eliminate redundant information in li,a.Dests∈LOG j; (ii) the implicit information in
li,a.Dests∈LOG jisusedtoeliminateredundantinformationin oi,a.Dests;(iii)theimplicit
informationin oi,ais used to eliminateredundant information li,a′∈LOG jif∝\⌉}atio\slash∃oi,a′∈OM′
anda′< a; (iv) the implicit information in li,ais used to eliminate redundant information
oi,a′∈OM′if∝\⌉}atio\slash∃li,a′∈LOG janda′<a;(v)onlynonredundantinformationremainsin OM′
andLOG j;thisis mergedtogetherintoan updated LOG j.
Anexample
In the example in Figure 6.17, the timing diagram illustrate s (i) the propagation of explicit in-
formation “P6∈M5,1.Dests” and (ii) the inference of implicit information that “ M5,1has been
delivered to P6, or is guaranteed to be delivered in causal order to P6with respect to any future
messages”. A thick arrow indicates that thecorresponding m essage contains the explicitinforma-
tionpiggybackedonit. Athicklineduringsomeintervaloft hetimelineofaprocessindicatesthe
durationin which this informationresides in thelog local t o that process. Thenumber“ a” nextto
an eventindicatesthatitis the atheventatthat process.
MulticastsM5,1andM4,2.MessageM5,1sent to processes P4andP6contains the piggybacked
information “ M5,1.Dests ={P4,P6}.” Additionally, at the send event (5,1), the informa-
tion “M5,1.Dests ={P4,P6}” is also inserted in the local log Log5. WhenM5,1is de-
livered toP6, the (new) piggybacked information “ P4∈M5,1.Dests” is stored in Log6as
202
22 3
2
4 3 1 2
causal past contains event (6,1)1
1
1
1
1M5,14,2M4,22,2
4,34,3M
MM
5,16,2 5,2M3,3M
5
6information about P   as a destination
as piggybacked information and in Logsof multicast at event (5,1) propagates2 33 23 4
3,3M2,3
M MM
M
6P5P4P3P2P1P
M5,1to P
M4,2to P3,P2
2,2M to P1
M6,2to P1
M4,3to P6
M4,3to P3
M5,2to P6
M2,3to P
M1
3,3to P2,P6{P4
{P6
{P6
{P4
{P6
{}
{P ,4P6
{P
{}}
}
}
}
}64P }Message to dest.piggybacked
M5,1.Dests
,6,P
}6
Figure6.17: An exampletoillustratethepropagationconst raints.
“M5,1.Dests ={P4}”;informationabout“ P6∈M5,1.Dests”whichwasneededforrouting
mustnotbe stored in Log6because of Constraint I. Symmetrically, when M5,1is delivered
to processP4at event (4,1), onlythe new piggybacked information “ P6∈M5,1.Dests” is
insertedinLog4as “M5,1.Dests ={P6}”, whichis laterpropagatedduringmulticast M4,2.
MulticastM4,3.Atevent(4,3),theinformation“ P6∈M5,1.Dests”inLog4ispropagatedonmul-
ticastM4,3only to process P6to ensure causal delivery using the Delivery Condition. The
piggybackedinformationonmessage M4,3senttoprocess P3mustnotcontainthisinforma-
tionbecauseofConstraintII.(Thepiggybackedinformatio ncontains“M4,3.Dests ={P6}”.
Aslongasanyfuturemessagesentto P6isdeliveredincausalorderw.r.t. M4,3senttoP6,it
willalsobedeliveredincausalorderw.r.t. M5,1senttoP6.) AndasM5,1isalreadydelivered
toP4, the information “ M5,1.Dests =∅” is piggybacked on M4,3sent toP3. Similarly, the
information “ P6∈M5,1.Dests” must be deleted from Log4as it will no longer be needed,
because of Constraint II. “ M5,1.Dests =∅” is stored in Log4to remember that M5,1has
been deliveredoris guaranteed tobedeliveredincausal ord erto allitsdestinations.
Learning implicitinformationat P2andP3.When message M4,2is received by processes P2
andP3, they insert the (new) piggybacked information in their loc al logs, as information
“M5,1.Dests ={P6}”. Theybothcontinuetostorethisin Log2andLog3andpropagatethis
informationon multicastsuntil they “learn” at events (2,4 )and (3,2) on receipt of messages
M3,3andM4,3, respectively, that any future message is guaranteed to be d elivered in causal
order to process P6, w.r.t.M5,1sent toP6. Hence by Constraint II, this informationmust be
deletedfrom Log2andLog3. Thelogicby whichthis“learning”occurs isas follows.
•WhenM4,3withpiggybackedinformation“ M5,1.Dests =∅”isreceivedby P3at(3,2),this
isinferredtobevalidcurrent implicitinformationaboutmulticast M5,1becausethelog Log3
203
alreadycontainsexplicitinformation“ P6∈M5,1.Dests”aboutthatmulticast. Thereforethe
explicit information in Log3is inferred to be old and must be deleted to achieve optimalit y.
M5,1.Destsisset to∅inLog3.
•Thelogicbywhich P2learns implicitknowledgeon thearrivalof M3,3isidentical.
Processing at P6.Recallfromstep(1)thatwhenmessage M5,1isdeliveredto P6,only“M5,1.Dests =
{P4}” is added to Log6. Further,P6propagates only “ M5,1.Dests ={P4}” (fromLog6) on
messageM6,2,and thisconveysthecurrent implicitinformation“ M5,1hasbeen deliveredto
P6”, by itsveryabsencein theexplicitinformation.
•Whentheinformation“ P6∈M5,1.Dests”arrivesonM4,3,piggybackedas“ M5,1.Dests =
{P6}”, it is used only to ensure causal delivery of M4,3using the Delivery Condition, and
is not inserted in Log6(Constraint I) – further, the presence of “ M5,1.Dests ={P4}” in
Log6implies the implicitinformation that M5,1has already been delivered to P6. Also, the
absence ofP4inM5,1.Destsin the explicit piggybacked information implies the implicit
information that M5,1has been delivered or is guaranteed to be delivered in causal order to
P4, and therefore, M5,1.Destsisset to∅inLog6.
•Whentheinformation“ P6∈M5,1.Dests”arrivesonM5,2,piggybackedas“ M5,1.Dests =
{P4,P6}”,itisusedonlytoensurecausaldeliveryof M4,3usingtheDeliveryCondition,and
is not inserted in Log6becauseLog6contains “M5,1.Dests =∅”, which gives the implicit
information that M5,1has been delivered or is guaranteed to be delivered in causal order to
bothP4andP6. (Note that at event (5,2), P5changesM5,1.DestsinLog5from{P4,P6}to
{P4}, as perConstraintII, and inserts“ M5,2.Dests ={P6}”inLog5.)
Processing at P1.Wehavethefollowingprocessing.
•WhenM2,2arrives carrying piggybacked information “ M5,1.Dests ={P6}”, this (new)
informationis insertedin Log1.
•WhenM6,2arrives with piggybacked information “ M5,1.Dests ={P4}”,P1“learns”
implicitinformation “ M5,1has been delivered to P6” by the very absence of explicit infor-
mation “P6∈M5,1.Dests” in the piggybacked information, and hence marks informati on
“P6∈M5,1.Dests” fordeletionfrom Log1. Simultaneously,“ M5,1.Dests ={P6}”inLog1
implies the implicitinformation that M5,1has been delivered or is guaranteed to be deliv-
ered in causal order to P4. Thus,P1also “learns” that the explicit piggybacked information
“M5,1.Dests ={P4}”is outdated. M5,1.DestsinLog1isset to∅.
•Analogously, the information “ P6∈M5,1.Dests” piggybacked on M2,3that arrives at P1
is inferred to be outdated (and hence ignored) using the implicitknowledge derived from
“M5,1.Dests =∅”inLog1.
204
(1) When process Piwants to multicast amessage Mto group G:
(1a)sendM(i,G)tocentral coordinator.
(2) When M(i,G)arrives from Piatthe central coordinator:
(2a)sendM(i,G)toall members ofthe group G.
(3) When M(i,G)arrives at Pjfrom the central coordinator:
(3a)deliver M(i,G)tothe application.
Figure6.18: Acentralized algorithmtoimplementtotalord erand causal orderofmessages.
6.6 TotalOrder
Whilecausalorderhasmanyuses,thereareotherorderingst hatarealsouseful. Totalorder issuch
an ordering. Consider the example of updates to replicated d ata, as shown in Figure 6.12. As the
replicasareofjustonedataitem d,itwouldbelogicaltoexpectthatallreplicas seetheupdat esin
the same order, whether or not the issuing of the updates are c ausally related. This way, the issue
of coherence and consistency of the replica values goes away . Such a replicated system would
stillbeuseful for fault-tolerance, as well as for easy avai labilityfor“read” operations. Total order
whichrequiresthatallmessagesbereceivedinthesameorde rbytherecipientsofthemessagesis
formallydeﬁned as follows.
Deﬁnition 19. (Total order.) For each pairof processes PiandPjand foreach pair of messages
MxandMythataredeliveredtoboththeprocesses, Piisdelivered MxbeforeMyifandonlyif Pj
isdelivered MxbeforeMy.
Example: Theexecutionin Figure6.12(b)does notsatisfytotalorder . Evenifthemessage mdid
notexist,totalorderwouldnotbesatisﬁed. Theexecutioni n Figure6.12(c)satisﬁestotalorder.
6.6.1 Centralized Algorithm for TotalOrder
Assuming all processes broadcast messages, the following c entralized solution (Figure 6.18) en-
forces total order in a system with FIFO channels. Each proce ss sends the message it wants to
broadcast to a centralized process, which simply relays all the messages it receives to every other
process over FIFO channels. It is straightforward to see tha t total order is satisﬁed. Furthermore,
thisalgorithmalso satisﬁescausal messageorder.
Complexity: Each message transmission takes 2 message hops, and exactly nmessages in a
systemofnprocesses.
Drawbacks: A centralized algorithmhas asinglepointoffailure andcon gestion,and istherefore
notan elegantsolution.
205
6.6.2 Three-Phase Distributed Algorithm
A distributed algorithm that enforces total and causal orde r for closed groups is given in Fig-
ure 6.19. The three phases of the algorithm are ﬁrst describe d from the viewpoint of the sender,
and thenfrom theviewpointofthereceiver.
Sender: Phase1: In the ﬁrst phase, a process multicasts (line 1b) the message Mwith a locally
uniquetagand thelocaltimestampto thegroup members.
Phase2: Inthesecondphase,thesenderprocessawaitsareplyfromal lthegroupmembers
who respond with a tentative proposal for a revised timestam p for that message M.
Theawaitcall in line (1d) is nonblocking, i.e., any other messages re ceived in the
meanwhileareprocessed. Onceallexpectedrepliesarerece ived,theprocesscomputes
the maximum of the proposed timestamps for M, and uses the maximum as the ﬁnal
timestamp.
Phase3: In the third phase, the process multicasts the ﬁnal timestam p to the group in line
(1f).
Receivers: Phase1: In the ﬁrst phase, the receiver receives the message with a te ntative/ pro-
posed timestamp. It updates the variable prioritythat tracks the highest proposed
timestamp (line 2a), then revises the proposed timestamp to thepriority, and places
the message with its tag and the revised timestamp at the tail of the queue temp_Q
(line2b). Inthequeue, theentryismarked as undeliverable .
Phase2: In the second phase, the receiver sends the revised timestam p (and the tag) back
to the sender (line 2c). The receiver then waits in a nonblock ing manner for the ﬁnal
timestamp(correlated bythemessagetag).
Phase3: In the third phase, the ﬁnal timestamp is received from the mu lticaster (line 3).
The corresponding message entry in temp_Qis identiﬁed using the tag (line 3a), and
ismarkedasdeliverable(line3b)aftertherevisedtimesta mpisoverwrittenbytheﬁnal
timestamp(line3c). Thequeueisthenresortedusingthetim estampﬁeldoftheentries
asthekey(line3c). Asthequeueisalreadysortedexceptfor themodiﬁedentryforthe
messageunderconsideration,thatmessageentryhas tobepl aced in itssortedposition
in the queue. If the message entry is at the head of the temp_Q, that entry, and all
consecutive subsequent entries that are also marked as deli verable, are dequeued from
temp_Q, and enqueued in deliver_Qinthat order(loopinlines 3d-3g).
Complexity: This algorithm uses three phases, and to send a message to n−1processes, it uses
3(n−1)messages andincurs adelay ofthreemessagehops.
Example: Anexampleexecutiontoillustratethealgorithmisgivenin Figure6.20. Here, AandB
multicastto asetofdestinationsand Cand D arethecommonde stinationsforbothmulticasts.
Figure6.20(a): Themainsequenceofstepsisas follows.
206
recordQ_entry
M:int; // the application message
tag:int; //unique message identiﬁer
sender_id:int; //sender ofthe message
timestamp :int; //tentative timestamp assigned tomessage
deliverable :boolean; //whether message is ready for delivery
(local variables)
queueof Q_entry:temp_Q,delivery _Q
int:clock // Usedas avariant ofLamport’s scalar clock
int:priority //Usedto track the highest proposed timestamp
(message types)
REVISE_TS (M,i,tag,ts ) //Phase 1message sent by Pi,withinitial timestamp ts
PROPOSED_TS (j,i,tag,ts ) // Phase 2message sent by Pj, withrevised timestamp, to Pi
FINAL_TS (i,tag,ts) //Phase 3message sent by Pi, withﬁnaltimestamp
(1) When process Piwants to multicast amessage Mwith atag tag:
(1a)clock=clock+ 1;
(1b)sendREVISE_TS (M,i,tag,clock ) toall processes;
(1c)temp_ts=0;
(1d)awaitPROPOSED_TS (j,i,tag,ts j)from each process Pj;
(1e)∀j∈N,dotemp_ts= max( temp_ts,ts j);
(1f)sendFINAL_TS (i,tag,temp _ts)toall processes;
(1g)clock=max(clock,temp _ts).
(2) When REVISE_TS (M,j,tag,clk ) arrives from Pj:
(2a)priority =max(priority + 1,clk);
(2b)insert (M,tag,j,priority,undeliverable )intemp_Q; //at end ofqueue
(2c)sendPROPOSED_TS (i,j,tag,priority )toPj.
(3) When FINAL_TS (j,tag,clk ) arrives from Pj:
(3a) Identify entry Q_entry(tag)intemp_Q, corresponding to tag;
(3b)mark qtagasdeliverable;
(3c) Update Q_entry.timestamp toclkand re-sort temp_Qbased on the timestamp ﬁeld;
(3d)ifhead(temp_Q) =Q_entry(tag)then
(3e) move Q_entry(tag)fromtemp_Qtodelivery_Q;
(3f) while head(temp_Q)is deliverable do
(3g) movehead(temp_Q)fromtemp_Qtodelivery_Q.
(4) When Piremoves amessage (M,tag,j,ts,deliverable )fromhead(delivery_Qi):
(4a)clock= max( clock,ts ) + 1.
Figure6.19: A distributedalgorithmto implementtotalord er and causal order ofmessages. Code
atPi,1≤i≤n.
207
A BC D
77710
9
999temp_Q delivery_Q temp_Q(9,u)(10,u) (7,u)(9,u)
delivery_Q
PROPOSED_TS(a)
REVISE_TS
C D
9temp_Q delivery_Q temp_Q delivery_Q
10109(9,u)(10,d) (10,u) (9,d)
max(7,9)=9 max(7,10)=10FINAL_TS(b) 
B A
Figure 6.20: An example to illustrate the 3-phase total orde ring algorithm. (a) A snapshot for
PROPOSED_TS and REVISE_TS messages. The dashed lines show t he further execution after
thesnapshot. (b)TheFINAL_TSmessagesintheexample.
1. A sends a REVISE_TS (7) message, having timestamp 7. B sends a REVISE_TS (9)
message, havingtimestamp9.
2. CreceivesA’s REVISE_TS (7),entersthecorrespondingmessagein temp_Q,andmarks
it as undeliverable. priority=7. Cthen sends PROPOSED_TS (7)messagetoA.
3. DreceivesB’s REVISE_TS (9),entersthecorrespondingmessagein temp_Q,andmarks
it as undeliverable. priority=9. D thensends PROPOSED_TS (9)messagetoB.
4. CreceivesB’s REVISE_TS (9),entersthecorrespondingmessagein temp_Q,andmarks
it as undeliverable. priority=9. Cthen sends PROPOSED_TS (9)messagetoB.
5. DreceivesA’s REVISE_TS (7),entersthecorrespondingmessagein temp_Q,andmarks
it as undeliverable. priority= 10. D assigns a tentative timestamp value of 10, which
is greater than all of the timestampson REVISE_TS s seen so far, and then sends PRO-
POSED_TS (10)messageto A.
208
Thestateofthesystemis as shownin theﬁgure.
Figure6.20(b): Thecontinuingsequenceofmainsteps isas follows.
6. WhenAreceives PROPOSED_TS (7)fromCand PROPOSED_TS (10)fromD,itcom-
putes theﬁnal timestampas max(7,10) = 10, and sends FINAL_TS (10) toC andD.
7. When B receives PROPOSED_TS (9) from C and PROPOSED_TS (9) from D, it com-
putes theﬁnal timestampas max(9,9) = 9,and sends FINAL_TS (9) to Cand D.
8. Creceives FINAL_TS (10)fromA,updatesthecorrespondingentryin temp_Qwiththe
timestamp, resorts the queue, and marks the message as deliv erable. As the message
is not at the head of the queue and some entry ahead of it is stil l undeliverable, the
messageisnot movedto delivery_Q .
9. Dreceives FINAL_TS (9)fromB,updatesthecorrespondingentryin temp_Qbymark-
ingthecorrespondingmessageasdeliverable,andresortst hequeue. Asthemessageis
at thehead ofthequeue,it ismovedto delivery_Q .
ThisisthesystemsnapshotshowninFigure6.20(b). Thefoll owingfurtherstepswilloccur.
10. WhenCreceives FINAL_TS (9)fromB,itwillupdatethecorrespondingentryin temp_Q
by marking the corresponding message as deliverable. As the message is at the head
of the queue, it is moved to the delivery_Q and the next message (of A) which is also
deliverable,isalso movedtothe delivery_Q .
11. When D receives FINAL_TS (10) from A, it will update the corresponding entry in
temp_Qby marking the corresponding message as deliverable. As the message is at
thehead ofthequeue,it ismovedto the delivery_Q .
The algorithm in Figure 6.19 is closely structured along the lines of Lamport’s algorithm for
mutual exclusion. We will later see that Lamport’s mutual ex clusion algorithm has the property
that when a process is at the head of its own queue and has recei ved a REPLY from all other
processes, the REQUEST of that process is at the head of all th e queues. This can be exploited
to deliver the message by all the processes in the same total o rder (instead of entering the critical
section).
6.7 ANomenclatureForMulticast
In this section, we systematically classify the various kin ds of multicast algorithms possible. Ob-
serve that there are four classes of source-destination rel ationships, as illustrated in Figure 6.21,
foropen groups.
SSSG:Singlesourceand singledestinationgroup
MSSG:Multiplesources and singledestinationgroup
209
(a) Single Source Single Group (c) Single Source Multiple Groups
(b) Multiple Sources Single Group (d) Multiple Sources Multiple Groups/0/0/1/1
/0/0/1/1 /0/0/1/1
/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1 /0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1 /0/0/1/1 /0/0/1/1
/0/0/1/1
/0/0/1/1
Figure 6.21: Four classes of source-destination relations hips for open-group multicasts. For
closed-groupmulticasts,thesenderneedsto bepartofther ecipient group.
SSMG:Singlesourceand multiple,possiblyoverlapping,groups
MSMG: Multiplesources and multiple,possiblyoverlapping,grou ps
The SSSG and SSMG classes are straightforward to implement, assuming the presence of
FIFO channels between each pair of processes. Both total ord er and causal order are guaranteed.
The MSSG class is also straightforward to handle; the centra lized implementation in Figure 6.18
provides both total and causal order. The central coordinat or effectively converts this class to the
SSSG class. FortheMSMGclass, an algorithmsuch asthat inFi gure6.19 can beused.
We now consider another design approach for the MSMG class. T his approach, commonly
termed as the propagationtree approach, uses a semi-centralized structurethat adapts th e central-
ized algorithmofFigure6.18.
6.8 PropagationTrees ForMulticast
Tomanagethecomplicationsofdeliveryorderacrossmultip leoverlappinggroups G={G1...G g},
the algorithm ﬁrst identiﬁes a set of meta-groupsMG={MG 1,...MG h}with the following
properties. (1) Each process belongs to a single meta-group , and has the exact same group mem-
bership as every other process in that meta-group. (2) No oth er process outside that meta-group
has thatexact groupmembership.
Example: Figure 6.22(a) shows some groups and their meta-groups. ∝a\}⌊ra⌋k⌉tl⌉{tABC∝a\}⌊ra⌋k⌉tri}ht,∝a\}⌊ra⌋k⌉tl⌉{tAB∝a\}⌊ra⌋k⌉tri}ht,∝a\}⌊ra⌋k⌉tl⌉{tAC∝a\}⌊ra⌋k⌉tri}ht, and
∝a\}⌊ra⌋k⌉tl⌉{tA∝a\}⌊ra⌋k⌉tri}htarethemeta-groupsofusergroup ∝a\}⌊ra⌋k⌉tl⌉{tA∝a\}⌊ra⌋k⌉tri}ht.
The deﬁnition of meta-groups transforms the problem of MSMG multicast to groups, to the
problemofMSSG multicastto meta-groups,whichiseasier to solve.
A distinguished node in each meta-group acts as the manager f or that meta-group. For each
user groupGi, one of its meta-groups is chosen to be its primary meta-group (PM) and denoted
210
ABCAB
A
AC
CCEED B
CDBD
BCBCD
DE
FEFABC
A B C AB AC BC BCD
BD CD D DE
E CE EF
FPM(C) PM(D)
PM(E)
PM(F)
(a) (b)PM(A),PM(B),
A
E
FCBD
Figure 6.22: Example illustrating a propagation tree. Meta groups are shown in boldface. (a)
GroupsA,B,C,D,E andF, and their meta-groups. (b) A propagation tree , with the primary
meta-groupslabeled.
asPM(Gi). All the meta-groups are organized in a propagationforest ortreestructure satisfying
the property: For user group Gi, its primary metagroup PM(Gi)is at the lowest possible level
(i.e.,farthestfromtheroot)ofthetreesuchthatalltheme tagroupswhosedestinationscontainany
nodesofGibelongto thesubtreerootedat PM(Gi).
Example (with respect to Figure 6.22): ∝a\}⌊ra⌋k⌉tl⌉{tABC∝a\}⌊ra⌋k⌉tri}htis the primary metagroup of A, B, and C.
∝a\}⌊ra⌋k⌉tl⌉{tB,C,D∝a\}⌊ra⌋k⌉tri}htis the primary meta-group of D. ∝a\}⌊ra⌋k⌉tl⌉{tD,E∝a\}⌊ra⌋k⌉tri}htis the primary meta-group of E. ∝a\}⌊ra⌋k⌉tl⌉{tE,F∝a\}⌊ra⌋k⌉tri}htis the
primarymeta-group ofF.
Thefollowingpropertiescan beseen to besatisﬁedby the propagationtree .
1. The primary meta-group PM(G), is the ancestor of all the other meta-groups of Gin the
propagationtree.
2.PM(G)isuniquelydeﬁned.
3. For any meta-group MG, there is a unique path to it from the P M of any of the user groups
ofwhichthemeta-groupMGis asubset.
4. In addition, for any two primary meta-groups PM(G1)andPM(G2), they should either
lie on the same branch of a tree, or be in disjoint trees. In the latter case, their groups
membershipsets arenecessarily disjoint.
Key idea: The meta-group PM(Gi)of user group Gi, is useful for multicasts, as follows. Mul-
ticasts toGiare sent ﬁrst to the meta-group PM(Gi)as only the subtree rooted at PM(Gi)can
containthenodes in Gi.Themessageis thenpropagateddownthesubtreerooted at PM(Gi).
Thefollowingdeﬁnitionsareuseful tounderstandand expla inthealgorithm.
•MG 1subsumesMG 2(whereMG 1∝\⌉}atio\slash=MG 2) if for each group Gsuch that a member of
MG 2isamemberof G,wehavethatsomememberof MG 1isalsoamemberof G. Inother
words,MG 1is asubsetofeach usergroup GofwhichMG 2is asubset.
211
Example: InFigure6.22,∝a\}⌊ra⌋k⌉tl⌉{tAB∝a\}⌊ra⌋k⌉tri}htsubsumes∝a\}⌊ra⌋k⌉tl⌉{tA∝a\}⌊ra⌋k⌉tri}ht. Anymemberof MG 2=∝a\}⌊ra⌋k⌉tl⌉{tA∝a\}⌊ra⌋k⌉tri}htisamemberof
Aand each memberof ∝a\}⌊ra⌋k⌉tl⌉{tAB∝a\}⌊ra⌋k⌉tri}htisalso amemberof A. Similarly,∝a\}⌊ra⌋k⌉tl⌉{tAB∝a\}⌊ra⌋k⌉tri}htsubsumes∝a\}⌊ra⌋k⌉tl⌉{tB∝a\}⌊ra⌋k⌉tri}ht.
•MG 1is joint with MG 2if neither meta-group subsumes the other and there is some gr oup
GsuchthatMG 1,MG 2⊂G.
Example: In Figure6.22,∝a\}⌊ra⌋k⌉tl⌉{tABC∝a\}⌊ra⌋k⌉tri}htis joint with∝a\}⌊ra⌋k⌉tl⌉{tCD∝a\}⌊ra⌋k⌉tri}ht. Neithersubsumesthe otherand both
area subsetof C.
Example: Figure 6.22 shows some groups, their meta-groups, and their propagation tree . Meta-
group∝a\}⌊ra⌋k⌉tl⌉{tABC∝a\}⌊ra⌋k⌉tri}htis the primary meta-group PM(A),PM(B),PM(C). Meta-group∝a\}⌊ra⌋k⌉tl⌉{tBCD∝a\}⌊ra⌋k⌉tri}htis the
primarymeta-group PM(D). Thus,amulticasttogroup Dwillbesentto∝a\}⌊ra⌋k⌉tl⌉{tBCD∝a\}⌊ra⌋k⌉tri}ht.
Wenotethatthepropagationtreeisnotuniquebecauseitdep endsontheorderinwhichmeta-
groupsareprocessed. Variousoptimizationsonthepropaga tiontreecanalsobeperformed,butwe
requirethatfeatures (1)–(4)aboveshouldbesatisﬁedby th etree. Exercise10 asksyouto design
an algorithm to construct a propagation tree. A metagroup th at has members from multiple user
groupsisdesirableinorder tohavea treewithlowheight.
Correctness: Therulesforforwardingmessagesduringamulticastaregiv eninFigure6.23. Each
process needs to know the propagation tree, computed at a cen tral location. Each meta-group has
adistinguishedprocess which actsas the manager orrepresentativeofthat meta-group.
ThearraySV[1...h]keptbyeachprocess PitracksinSV[k],thenumberofmessagesmulticast
byPithatwilltraversethroughprimarymeta-group PM(Gk). Thisarrayispiggybackedon
each messagemulticastbyprocess Pi.
The manager of each primary meta-group keeps an array RV[1...n]that tracks in RV[k], the
numberofmessagessentbyprocess Pkthathavebeenreceivedbythisprimarymeta-group.
As in the CO algorithms, a message from Pican be processed by a primary meta-group jif
RVj[i] =SVi[j]; otherwise it buffers the message until this condition is sa tisﬁed (lines 2a-2c).
At a non-primary meta-group, this check need not be performe d because it never receives a mes-
sage directly from the sender of the multicast. The multicas t sender always sends the message to
the primary meta-group ﬁrst. At the non-primary meta-group , the relative order of messages has
already been determined by some ancestor meta-group; so it s imply forwards the message as per
(2d-2g).
•Thelogicbehindwhytotalorderismaintainedisstraightfo rward. Foranymetagroups MG 1
andMG 2, and any groups GxandGyof which the metagroups are a subset, the primary
meta-groups PM(Gx)andPM(Gy)both subsume MG 1andMG 2, and both lie on the
samebranchofthe propagationtree toeitherMG 1orMG 2. Theprimarymeta-groupthatis
lowerinthetreewillnecessarilyreceivethetwomulticast sinsomeorder. Theassumptionof
FIFOchannelsguaranteesthatallprocessesinmeta-groups subsumedbythislowerprimary
meta-groupwillreceivethemessagessent tothetwogroupsi n acommonorder.
212
(local variables)
array ofintegers: SV[1... h]; //kept by each process. his#(primary meta-groups), h≤|G|
array ofintegers: RV[1... n]; //kept by each primary metagroup manager. nis#(processes)
set ofintegers: PM_set; //set ofprimary meta-groups through whichmessage must tr averse
(1) When process Piwants to multicast message Mto group G:
(1a)sendM(i,G,SV i)to manager of PM(G), primary meta-group of G;
(1b)PM_set←−{primary meta-groups through which Mmust traverse};
(1c)for all PMx∈PM_setdo
(1d) SVi[x]←−SVi[x] + 1.
(2) When Pi, the manager of ameta-group MGreceives M(k,G,SV k)fromPj:
//Note: Pimay not beamanager ofany meta-group
(2a)ifMGisaprimary meta-group then
(2b) bufferthe message until(SVk[i] =RVi[k]);
(2c) RVi[k]←−RVi[k] + 1;
(2d)for eachchild meta-group that issubsumed by MGdo
(2e) sendM(k,G,SV k)to themanager of that child meta-group;
(2f)ifthere are nochild meta-groups then
(2g) sendM(k,G,SV k)to each process in this meta-group.
Figure6.23: Protocolto enforcetotaland causal orderusin gpropagationtrees.
•Causal orderis guaranteed becauseofthecheck madeby manag ers ofprimarymeta-groups
in lines (2a-2c). Assume that messages MandM′are multicast to GandG′, respectively.
Fornodesin G∩G′,therearetwocases,asshowninFigure6.24. Ineachcase,th esequence
numbersnexttomessagesindicatetheorder inwhichthemess agesare sent.
CaseFigure6.24(a,b): Here, the senders of MandM′are different. PksendsMtoG.
AfterPi∈GreceivesM,PisendsM′toG′. Thus, we have the causal chain
Send k(k,M,G ),Deliver i(k,M,G ),Send i(i,M′,G′). Foranydestination MG qsuch
thatMG q⊂G∩G′, the primary meta-group of GandG′must both be ancestors of
themeta-groupof Pibecauseoftheassumptionof closedgroups .
Case(a):PM(G′)will have already received and processed M(ﬂow (2)) before it
receivesM′(ﬂow (4)).
Case(b):PM(G)willhavealreadyreceivedandprocessed M(ﬂow(1))beforeitre-
ceivesM′(ﬂow(4)). AssumingFIFOchannels,COisguaranteedforallp rocesses
inG∩G′.
CaseFigure6.24(c,d): PisendsMtoGand thenPisendsM′toG′. Thus, we have the
causal chain Send i(i,M,G ),Send i(i,M′,G′).
Case(c): Thecheckinlines(2a-2c)by PM(G′)ensuresthat PM(G′)willnotprocess
M′beforeit processes M.
213
/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1PkPk
P P
i iPM(G’)PM(G)
i iP12
3
41
23 4
PM(G)
PM(G’)1
22 3
1Case(a) Case (b)
Case (c) Case (d)PM(G)PM(G’)
PM(G’)
PM(G) P2
Figure 6.24: The four cases for the correctness of causal ord ering using propagation trees . The
sequencenumbersdindicatetheorderinwhich themessages a resent.
Case(d): Thecheckinlines(2a-2c)by PM(G)ensuresthat PM(G)willnotprocess
M′before it processes M. Assuming FIFO channels, CO is guaranteed for all
processes in G∩G′.
6.9 ClassiﬁcationofApplication-LevelMulticastAlgorit hms
We have seen some algorithmically challenging techniques i n the design of multicast algorithms.
Themostgeneralscenarioallowseachprocesstomulticastt oanarbitraryanddynamicallychang-
ing group of processes at each step. As this generality incur s more overhead, algorithms imple-
mented on real systems tend to be more ‘centralized’ in one se nse or another. Many multicast
protocols have been developed and deployed, but they can all be classiﬁed as belonging to one of
thefollowingﬁveclasses.
Communicationhistory basedalgorithms: Algorithmsin this class use a part of the communi-
cationhistorytoguaranteeordering requirements.
TheRST andKSalgorithmsbelongtothisclass,and provideon lycausal ordering. Theydo
notneed to track separategroups,and henceworkfor open-gr oupmulticasts.
Lamport’s algorithm, wherein messages are assigned scalar timestamps and a process can
deliver a message only when it knows that no other message wit h a lower timestamp can
be multicast, also belongs to this class. The NewTop protoco l which extends Lamport’s al-
gorithm to overlapping groups guarantees both total and cau sal ordering, unlike Lamport’s
algorithm that guarantees only total ordering. Both these a lgorithms use closed-group con-
ﬁgurations.
214
Destinations
(c) Fixed sequencer(b) Moving sequencer (a) Privilege−based
(d) Destination agreementDestinationsSenders
sequencerFixed
DestinationsSendersSequencers
token
rotatesSenders
DestinationsSenders
privilege rotates
/0/0/1/1/0/0/1/1
/0/0/1/1
Figure 6.25: Models for sequencing messages. (a) Privilege -based algorithms. (b) Moving se-
quenceralgorithms. (c) Fixedsequenceralgorithms. (d)De stinationagreementalgorithms.
Privilegebased algorithms: The operation of such algorithms is illustrated in Figure 6. 25(a). A
token circulates among the sender processes. The token carr ies the sequence number for
thenext messageto be multicast,and only thetoken-holderc an multicast. After a multicast
send event, the sequence number is updated. Destination pro cesses deliver messages in the
orderofincreasingsequencenumbers. Sendersneedtoknowt heothersenders,henceclosed
groups are assumed. Such algorithms can provide total order ing, as well as causal ordering
usingaclosedgroup conﬁguration(See Exercise12.)
ExamplesofspeciﬁcalgorithmsareOn-Demand,andTotem. Th eydifferinimplementation
detailssuchaswhetheratokenringtopologyisassumed(Tot em)ornot(On-Demand). Such
algorithms are not scalable because they do not permit concu rrent send events. Hence they
areoflimitedusein largesystems.
Movingsequencer algorithms: TheoperationofsuchalgorithmsisillustratedinFigure6. 25(b).
The original algorithm was proposed by Chang and Maxemchuck ; various variants of it
were given by the Pinwheel and RMP algorithms. These algorit hms work as follows. (1)
To multicast a message, the sender sends the message to all th e sequencers. (2) Sequencers
circulate a token among themselves. The token carries a sequ ence number and a list of all
215
themessagesforwhich asequencenumberhas already been ass igned-such messageshave
been sent already. (3) When a sequencer receives the token, i t assigns a sequence number
to all received but unsequenced messages. It then sends the n ewly sequenced messages to
the destinations, inserts these messages in to the token lis t, and passes the token to the next
sequencer. (4)Destinationprocessesdeliverthemessages receivedintheorderofincreasing
sequencenumber.
Movingsequenceralgorithmsworkwithopengroups. Theygua ranteetotalorderingbutnot
causal ordering. (See Exercise12.)
Fixedsequencer algorithms: The operation of such algorithms is illustrated in Figure 6. 25(c).
Thisclass is asimpliﬁedversion ofthepreviousclass. Ther e is a singlesequencer (unless a
failureoccurs), whichmakes thisclassofalgorithmsessen tiallycentralized.
Thepropagationtreeapproachstudiedearlier,belongstot hisclass. Otheralgorithmsare: the
ISIS sequencer, Amoeba, Phoenix, and Newtop’sasymmetrica lgorithm. Let us brieﬂy look
at Newtop’s asymmetric algorithm. All processes maintain l ogical clocks, and each group
has an independent sequencer. The unicast from the sender to the sequencer, as well as the
multicast from the sequencer are timestamped. A process tha t belongs to multiple groups
must delay the sending of the next message (to the relevant se quencer) until it has received
and processed all messages, from the various sequencers, co rresponding to the previous
messages it sent. AssumingFIFO channels, it can beshown tha t both total orderand causal
orderare maintained. (See Exercise12.)
Destinationagreement algorithms: TheoperationofsuchalgorithmsisillustratedinFigure6. 25(d).
Inthisclassofalgorithms,thedestinationsreceivetheme ssageswithsomelimitedordering
information. They then exchange information among themsel ves to deﬁne an order. There
are two sub-classes here: (1) the ﬁrst sub-class uses timest amps. Lamport’s 3-phase algo-
rithm(Figure6.19)belongstothissub-class. (2)Thesecon dsub-classusesanagreementor
‘consensus’protocolamongtheprocesses. Wewillstudyagr eementprotocolsinChapter14.
6.10 SemanticsofFault-TolerantGroupCommunication
A failure-free system can be assumed only in an ideal world. W hen a system component fails in
the midst of the multicast operation, which is a non-atomic o peration that spans across time and
acrossmultiplelinksandnodes,thebehaviorofamulticast protocolmustadheretoawell-deﬁned
speciﬁcation,andcorrespondingly,theprotocolmustensu rethatthespeciﬁcationunderthefailure
mode is also implemented. This enables well-deﬁned actions during recovery after the failure.
Questionssuch as thefollowingneed to beaddressed.
•For a multicast, if one correct process delivers the message M, what can be said about the
othercorrect processes andfaulty processesbeing deliver edM?
216
•For a multicast, if one faulty process delivers the message M, what can be said about the
othercorrect processes andfaulty processesbeing deliver edM?
•For causal or total order multicast, if one correct or faulty process delivers M, what can be
saidabout othercorrect processesand faultyprocesses bei ngdelivered M?
There are two broad ﬂavors of the speciﬁcations. In the regul ar ﬂavor, there are no conditions
on the messages delivered to faulty processors (because the y are faulty). However, assuming the
benign failure model, under some conditions, it may be usefu l to specify and control the behavior
ofsuchfaultyprocessesalso. Therefore,thesecondﬂavoro fspeciﬁcations,termedasthe Uniform
speciﬁcations, also states the expected behavior of faulty processes. In the following description
of the speciﬁcations, the regular ﬂavor and the uniform ﬂavo r are stated. To parse for the regular
ﬂavor, the parenthesized words should be omitted. To parse f or theuniformﬂavor, the italicized
and parenthesizedmodiﬁers tothedeﬁnitionsoftheregular ﬂavor areincluded.
Uniform ReliableMulticastof M.
Validity. Ifacorrectprocessmulticasts M,thenallcorrectprocesseswilleventuallydeliver
M.
(Uniform Agreement. Ifacorrect ( orfaulty)processdelivers M,thenallcorrectprocesses
willeventuallydeliver M.
(Uniform)Integrity. Every correct ( or faulty)processdelivers Mat mostonce,and onlyif
Mwas previouslymulticastby sender (M).
The Validity property states that once the multicast is init iated by a correct process, it will go
to completion. The Agreement property states that all corre ct processes get the same view of a
message, irrespective of whether a correct process or a faul ty process broadcasts it. The Integrity
propertystatesthatcorrectprocesseshavenonduplicated eliveryofmessages,andthattheyarenot
delivered spurious messages. While the regular Agreement p roperty permits a faulty process to
deliver a message that is never delivered to any correct proc ess, this undesirable behavior can be
problematic in applications such as Atomic Commit in databa se protocols, and is explicitly ruled
outbyUniformAgreement. WhiletheregularIntegrityprope rtypermitsafaultyprocesstodeliver
a message multipletimes, and to deliver a message that was ne ver sent, this behavior is explicitly
ruled outbyUniformAgreement.
Theorderings: FIFOorder,causalorder,andtotalorder,ar enowdeﬁnedformulticasts,inboth
theregular and uniformﬂavors. The uniformﬂavor requires that even faulty processes do not vio-
latetheorderingproperties. Thesedeﬁnitionsoftheregul aranduniformﬂavors are superimposed
on the basic deﬁnition of a ( uniform) reliable multicast, given above. The regular ﬂavor and the
uniform ﬂavor of each deﬁnition is read using the semantics a bove for parsing the corresponding
ﬂavors of multicast. In these deﬁnitions which deal with the relative order of messages, it is im-
portantthatthemulticastgroupsareidentical,inwhichca sethemessagesgetbroadcastwithinthe
commongroup.
217
(Uniform)FIFOordeer. If a process broadcasts Mbefore it broadcasts M′, then no correct ( or
faulty)process delivers M′unlessitpreviouslydelivered M.
(Uniform)CausalOrder. If a process broadcasts Mcausally before it broadcasts M′, then no
correct (or faulty)process delivers M′unlessitpreviouslydelivered M.
(Uniform)TotalOrder. If correct ( or faulty) processes aandbboth deliver MandM′, thena
deliversMbeforeM′ifand onlyif bdeliversMbeforeM′.
It is time to remember the folklore result that any protocol o r implementation that deals with
fault-toleranceincursagreatercostthanwhatitwouldina failure-freeenvironment. Insomecase,
this extra cost can be substantial. Nevertheless, it is impo rtant to formally specify the behavior in
the face of faults, and to provide the implementations that c an realize such behavior. We will not
deal withimplementationsoftheabovefault-tolerantspec iﬁcations ofmulticasts.
Excessive delay in delivering a multicast message can also b e viewed as a fault. Applications
with real-time constraints require that if a message is deli vered, it should be within a bounded
period ∆, termed the latency, after it was multicast. This speciﬁcat ion can be based on either
a global observer’s notion of time, or the local time at each p rocess, leading to Real-time ∆-
TimelinessandLocal-time ∆-Timeliness,respectively.
(Uniform)Real-time ∆-Timeliness. For some known constant ∆, ifMis multicast at real-time
t, thenno correct ( or faulty)process delivers Mafterreal-time t+ ∆.
(Uniform)Local ∆-Timeliness. For some known constant ∆, ifMis multicast at local time tm,
thenno correct ( or faulty)process delivers Mafteritslocal time tm+ ∆.
Specifyinglocal-time ∆-Timelinessrequirescarebecausethelocalclocksatproce ssescanvary. It
isassumedthatthesendertimestampsthemessagemulticast withitslocaltime tm,andanyreceiver
should receive the message within tm+ ∆on its local clock. The efﬁcacy of this speciﬁcation
dependsonhowcloselythelocalclocksaresynchronized. Af ewprotocolstosynchronizephysical
clockswillbestudiedina laterchapter.
6.11 DistributedMulticastAlgorithmsAtTheNetworkLayer
Several applications can interface directly with the netwo rk layer and the lower hardware-related
layers to exploit the physical connectivity and the physica l topology for group communication.
Thenetworkisviewedasagraph (N,L),andvariousgraphalgorithms–centralizedordistributed
– arerun toestablishand maintainefﬁcient routingstructu res. Forexample,
•LANs connected by bridges maintain spanning trees for distr ibuting information and for
forward/backward learningofdestinations.
•TheNetworkLayeroftheInternet hasa richsuiteofmulticas talgorithms.
218
(1) When process Piwants to multicast message Mto group Dests:
(1a)sendM(i,Dests )on all outgoing links.
(2) When anode ireceives message M(x,Dests )from node j:
(2a)ifNext_hop(x) =jthen//this willnecessarily bea newmessage
(2b) forward M(x,Dests )on all other incident links besides (i,j);
(2c)elseignore the message.
Figure6.26: ReversePathForwarding (RPF).
In this section, we will study the principles underlying sev eral such algorithms. Some of the
algorithmsin this section may not be distributed. Neverthe less,they are intended for a distributed
setting,namelytheLAN ortheWAN.
6.11.1 Reverse PathForwarding (RPF) For Constrained Flood ing
As studied in Chapter 5, broadcasting data using ﬂooding in a network (N,L)requires up to 2|L|
messages. Reverse Path Forwarding is a simple but elegant te chnique that brings down the over-
headsigniﬁcantlyatverylittlecost. Networknodesareass umedtoruntheDistanceVectorRouting
(DVR)algorithm(Chapter5)whichwasusedintheInternetti ll1983. (After1983,theLSR-based
algorithms(Chapter 5) areused. Theseare moresophisticat edand providemoreinformationthan
thatrequired by DVR.)
The simple DVR algorithm assumes that each node knows the nex t hop on the path to each
destinationx. This path is assumed to be the approximation to the ‘best’ pa th. LetNext_hop(x)
denote the function that gives the next hop on the ‘best’ path tox. The RPF algorithm leverages
theDVRalgorithmforpoint-to-pointrouting,toachieveco nstrainedﬂooding. TheRPFalgorithm
forconstrainedﬂoodingis shownin Figure6.26.
ThissimpleRPFalgorithmhasbeenexperimentallyshowntob eeffectiveinbringingthenum-
ber of messages for a multicastcloser to |N|than to|L|. Actually, thealgorithm does a broadcast
to all the nodes, and this broadcast is smartly curtailed to a pproximate a spanning tree. The cur-
tailed broadcast is effective because, implicitly, an appr oximation to a tree rooted at the source is
identiﬁed,withoutitbeingcomputedorstoredat anynode.
Pruningof the implicit broadcast tree can be used to deal with unwant ed multicast packets.
If a node receives the packets but the application running on it does not need the packets, and all
‘downstream’ (in the implicit tree) nodes also do not need th e packets, the node can send a prune
message to the parent in the tree indicating that packets sho uld not be forwarded on that edge.
Implementingthisinadynamicnetworkwherethetreeperiod icallychanges andtheapplication’s
nodemembershipalsochanges dynamicallyissomewhattrick y(see Exercise14).
219
Input: weightedgraph G= (N,L), andN′⊆N, whereN′isthesetofSteinerpoints
1. Constructthecompleteundirected distancegraph G′=(N′,L′)as follows.
L′={(vi,vj)|vi,vjinN′}, andwt(vi,vj)is the length of the shortest path from vitovjin
(N,L).
2. LetT′be the minimal spanning tree of G′. If there are multiple minimum spanning trees,
select onerandomly.
3. Construct a subgraph GsofGby replacing each edge of the MST T′ofG′, by its corre-
spondingshortestpath in G. Ifthereare multipleshortestpaths,selectonerandomly.
4. Find the minimum spanning tree TsofGs. If there are multiple minimum spanning trees,
select onerandomly.
5. UsingTs, delete edges as necessary so that all the leaves are the Stei ner pointsN′. The
resultingtree, TSteiner, is theheuristic’ssolution.
Figure6.27: TheKou-Markowsky-Bermanheuristicforamini mumSteiner tree.
6.11.2 Steiner Trees
The problem of ﬁnding an optimal ‘spanning’ tree that spans o nly all nodes participating in a
multicastgroup,knownas the Steinertreeproblem,isformalized as follows.
Steiner tree problem: Given a weighted graph (N,L)and a subset N′⊆N, identify a subset
L′⊆Lsuchthat (N′,L′)isasubgraphof (N,L)thatconnects allthenodesof N′.
AminimalSteinertree is aminimalweightsubgraph (N′,L′). TheminimalSteiner treeprob-
lem has been well-studied and is known to be NP-complete. Whe n the link weights change, the
tree has to be recomputed to obtain the new minimalSteiner tr ee, making it even moredifﬁcult to
useindynamicnetworks.
Several heuristics have been proposed to construct an appro ximation to the minimal Steiner
tree. AsimpleheuristicconstructsaMST,anddeletesedges thatarenotnecessary. Thisalgorithm
isgivenbytheﬁrstthreestepsofFigure6.27. Theworstcase costofthisheuristicistwicethecost
oftheoptimalsolution. ThealgorithminFigure6.27,cansh owbetterperformancewhenusingthe
heuristic by Kou, Markowsky, and Berman, given by steps 4 and 5. in Figure 6.27. The resulting
Steinertreecostisalsoatmosttwicethecostoftheminimal Steinertree,butbehavesbetteronthe
average.
Cost:Thetimecomplexityoftheheuristicalgorithmforeachofth e5stepsisasfollows. Step(1):
O(|N′|·|N|2), Step (2):O(|N′|2), Step (3):O(|N|), Step (4):O(|N|2), Step (5):O(|N|). Step
(1)dominates,hence thetimecomplexityis O(|N′|·|N|2).
220
6.11.3 Multicast CostFunctions
Consider a source node sthat has to do a multicast to Steiner nodes. As before, we are g iven the
weighted graph (N,L)and the Steiner node set N′. We can deﬁne several cost functions. For
example,let cost(i)bethecostofthepath from stoiintheroutingscheme R.
Thenetwork cost ofRis deﬁned as/summationtext
i∈N′cost(i). This cost accounts for the weighted cost
incurred on the path from sto eachi∈N′. As a variant, a link is counted only once even if it is
used on the minimum cost path to multiple destinations. This variant reduces to the Steiner tree
problemofSection 6.11.2.
Thedestination cost ofRis deﬁned as This represents the average cost of the routing. If the
cost is measured in time delay, this routing function metric givesthe shortest average time for the
multicastto reach nodes in N′.
6.11.4 Delay-Bounded Steiner Trees
Multimedianetworksandinteractiveapplicationshavegiv enrisetotheneedforaminimumSteiner
treethatalsosatisﬁesdelayconstraintsonthetransmissi on. Thusnow,thegoalisnotonlytomin-
imizethecostofthetree(measuredintermsofaparametersu chasthelinkweight,whichmodels
the available bandwidth or a similar cost measure) but also t o minimize the delay (propagation
delay). Theproblemisformalizedas follows.
Delay-Bounded Minimal Steiner Tree Problem: Given a weighted graph (N,L), there are two
weight functions C(l)andD(l)for each edge in L.C(l)is a positivereal cost function on l∈L
andD(l)is a positive integer delay function on l∈L. For a given delay tolerance ∆, a given
sourcesand a destination set Dest, where{s}∪Dest =N′⊆N, identify a spanning tree T
covering all the nodes in N′, subject to the constraints below. Here, we let path(s,v)denote the
pathfromstovinT.
•/summationtext
l∈TC(l)isminimized,subjectto
•∀v∈N′,/summationtext
l∈path(s,v)D(l)<∆
Finding such a minimal Steiner tree, subject to another para meter, is at least as difﬁcult as
ﬁnding a Steiner tree. It can be shown that this problem reduc es to the Steiner Tree problem. A
detailed study of two heuristics to solve this problem is pre sented by Kompella, Pasquale, and
Polyzos. A constrained cheapest path betweenxandyis the cheapest path between xandythat
has delay less than ∆. The cost and delay on such a path are denoted by C(x,y)andD(x,y),
respectively. If two or more paths havethe lowestcost, the l owestdelay path is chosen. The steps
to computethe constrainedSteiner tree are shownin Figure6 .29. Step (1)computes thecomplete
closure graph G′on nodes in N′. The two heuristics given below are used in Step (2) to greedi ly
builda constrainedSteiner tree on G′. Step (3) expandsthetree edges in G′totheiroriginal paths
inG.
HeuristicCST CD:This heuristic tries to choose low-cost edges, while also tr ying to pick edges
that maximize the remaining allowable delay. The motivatio n is to try to reduce the tree
221
B
EF
G(9,2)
(5,1)
(1,2)(4,2)
(8,3) (1,1)
(2,1)(5,3)
(5,3)(2,2)
source node non−Steiner node
Steiner node (x,y)(cost, delay)(2,1) (1,2)
H DC
A A
DC B
EF
G(9,2)
(5,1)
(1,2)(4,2)
(8,3)
(2,1)(5,3)
(5,3)(2,2)
source node non−Steiner node
Steiner node (x,y)(cost, delay)(2,1)
H(1,2)(1,1)
Figure 6.28: Constrained Steiner tree example. (a) Network graph. (b,c) MST and Steiner tree
(optimal)arethesameandshowninthicklines.
cost by path sharing, by extending thepath beyond the select ed edge. This heuristichas the
tendencytooptimizeondelay also,whileaddingtothecost.
HeuristicCST C:Thisheuristicsimplyminimizesthecostwhileensuringtha tthedelayboundis
met.
Complexity. Assuming integer-valued ∆, step (1) which ﬁnds the constrained cheapest shortest
paths over all the nodes has O(n3∆)time complexity. This is because all pairs of end and in-
termediate nodes have to be examined, for all integer delay v alues from 1 to ∆. Step (2) which
constructs the constrained MST on the closure graph having knodes hasO(k3)time complexity.
Step (3) which expands the constrained spanning tree, invol ves expanding the kedges to up to
n−1edgeseach andtheneliminatingloops. Thishas O(kn)timeoverhead. Thedominatingstep
isstep (1).
6.11.5 Core-BasedTrees
In the core-based tree approach, each group has a center node , orcorenode. A multicast tree is
constructed dynamically, and grows on-demand, as follows. (1) A node wishing to join the tree
as a receiver sends a unicast ‘join’ message to the core node. (2) The join message marks the
edges as it travels; it either reaches the core node, or some n ode which is already a part of the
multicast tree. The path followed by the ‘join’ message from its source till the core/multicast tree
isgrafted tothemulticasttree, and deﬁnes thepathto the‘c ore’. (3)A nodeon thetreemulticasts
amessagebyusingaﬂoodingonthecoretree. (4)Anodenotont hetreesendsamessagetowards
the core node; as soon as the message reaches any node on the tr ee, the message is ﬂooded on
the tree. In a network with a dynamically changing topology, care needs to be taken to maintain
thetree structureand preventmessagesfrom looping. Thisp roblem alsoexistsfor normalrouting
algorithms,such astheLSR andDVR algorithms(Module2), in dynamicnetworks.
222
CurrentsystemsdonotwidelyimplementtheSteinertreefor groupmulticast,eventhoughitis
moreefﬁcientaftertheinitialcosttoconstructtheSteine rtree. Theypreferthesimplercore-based
tree(CBT) approach.
Core-based trees have various variants. A multi-core-base d tree has more than one core node.
For all CBT algorithms, high-bandwidth links can be special ly chosen over others for forming
the tree. Core-based trees have a natural analog in wireless networks, wherein it is reasonable to
constitutethecoretree ofhigh-bandwidthwired linksorhi gh-powerwireless links.
6.12 ChapterSummary
At the core of distributed computing is the communication by message-passing among the pro-
cesses participating in the application. This chapter stud ied several message ordering paradigms
for communication, such as the synchronous, the FIFO, the ca usally ordered, and the non-FIFO
orderings. These orders form a hierarchy. The chapter then e xamined several algorithms to im-
plement these orderings. Group communication is an importa nt aspect of communication in dis-
tributedsystems. Causalorderandtotalorderarethepopul arformsoforderingwhendoinggroup
multicastsandbroadcasts. Algorithmstoimplementtheseo rderingsingroupcommunicationwere
alsostudied.
Maintainingcommunicationinthepresenceoffaultsisnece ssaryinreal-worldsystems. Faults
and their impacts are unpredictable. However, the behaviou r in the presence of faults needs to be
clearly speciﬁed so that the application knows what to expec t in terms of message delivery and
message ordering in the presence of potential faults. The ch apter studied some formal speciﬁca-
tionsoftheexpected behaviourofgroupcommunicationwhen faultsmightoccur.
This chapter also studied some distributed multicast algor ithms at the Network layer. These
algorithms include Reverse Path Forwarding, multicast alo ng Steiner Trees and delay-bounded
Steiner trees, and multicast based on core-based trees over the network graph. The solutions to
someoftheseproblemsareNP-complete. Henceonlyheuristi csforpolynomialtimesolutionsare
examinedassumingacentralized settingtoperform thecomp utation.
6.13 BibliographicNotes
Thediscussiononsynchronous,asynchronous,andRSC-exec utionsisbasedonCharron-Bost,Tel,
and Mattern [7]. The CSP language for synchronous communica tion was ﬁrst proposed and for-
malized by Hoare [15]. The discussion on implementingsynch ronous order is based on Bagrodia
[1]. The discussion on the group communication paradigm, as well as on total order and causal
orderisbased on Birmanand Joseph[4, 5]. Thealgorithmforc ausal orderinFigure6.13is given
by Raynal, Schiper, and Toueg [21]. The space and time optima l algorithm for causal order is
given by Kshemkalyani and Singhal [19, 20]. The example to il lustrate this algorithm is taken
from [6]. The algorithm for total order in Figure 6.19 is take n from the ISIS project by Birman
andJoseph[4,5]. Thealgorithmfortotalorderusingpropag ationtreesisbasedonGarcia-Molina
223
and Spauster [12], Jia [16], and Chiu and Hsiao [9]. The movin g sequencer algorithms were pro-
posed by Chang and Maxemchuk [8]. An efﬁcient fault-toleran t group communication protcol is
given in [11]. A comprehensive survey of group communicatio n speciﬁcations given by Chock-
ler, Keidar, and Vitenberg [10] discusses the systems Totem , Pinwheel, RMP, On-Demand, Isis,
Amoeba, Phoenix, and Newtop. The Steiner tree problem was na med after Steiner and developed
in [13]. TheSteiner tree heuristicdiscussed was proposed b y Kou, Markowsky,and Berman [18].
The network cost and destination cost metrics were introduc ed by [3]. They further showed a
detailed analysis of the bounds on the metrics. The discussi on on the delay-bounded minimum
SteinertreeisbasedonKompella,Pasquale,andPolyzos[17 ]. Thediscussiononthesemanticsof
fault-tolerantgroupcommunicationisgivenbyHadzilacos andToueg[14]. Core-basedtreeswere
proposedby Ballardieet al. [2].
6.14 ExerciseProblems
1. (Characterizing causal ordering)
(a) Prove that the CO property (Deﬁnition 8) and the Message O rder property (Deﬁni-
tion10)characterize an identicalclass ofexecutions.
(b) Prove that the CO property (Deﬁnition 8) and the Empty Int erval property (Deﬁni-
tion11)characterize an identicalclass ofexecutions.
2. Draw thedirected graph (T,֒→)foreach oftheexecutionsinFigures 6.2, 6.3,and 6.5.
3. Givea lineartimealgorithmtodeterminewhetheran A-exe cution (E,≺)isRSC.
Hint: Usethedeﬁnitionofacrownandperformatopologicals ortonthemessagesusingthe
֒→relation.
4. Showthat anon-CO executionmusthaveacrown ofsize2.
5. Synchronous systems were deﬁned in Chapter 5. Synchronou s send and receive primitives
were also introduced in Chapter 1. Synchronous executions w ere deﬁned formally in Deﬁ-
nition13.
These concepts are closely related. Explain carefully the d ifferences and relationships be-
tween: (i) a synchronous execution, (ii) an (asynchronous) execution that uses synchronous
communication,and(iii)asynchronoussystem.
6. Rewritethe spanningtree algorithmofFigure 5.6 usingCS P-like notation. You can assume
awildcard operatorin areceivecall to specifythat anysend ercan bematched.
7. The algorithm to implement synchronous order by scheduli ng messages, as given in Fig-
ure6.10,uses processidentiﬁers tobreak cyclicwaits.
(a) Analyzethefairness ofthisalgorithm.
224
(b) If thealgorithmisnotfair, suggestsomeways tomakeitf air.
(c) Will theuseofrotatinglogicalidentiﬁersin creasethe fairness oftheralgorithm?
8. Show the followingcontainment relationshipsbetween ca usally ordered and totally ordered
executions. (Hint: Youmay useFigure6.12.)
(a) Show thatacausally ordered multicastneed notbeatotal order multicast.
(b) Show thatatotalordermulticastneed notbeacausal orde rmulticast.
9. Assumethatallmessagesarebeingbroadcast. Justifyyou ranswerstoeachofthefollowing.
(a) ModifythecausalmessageorderingalgorithminFigure6 .13sothatprocessesuseonly
two vectorsofsize n, ratherthanthe n×narray.
(b) Is it possibleto implementtotalorderusingavectorofs izen?
(c) Is it possibleto implementtotalorderusingavectorofs izeO(1)?
(d) Is it possibleto implementcausalorder usinga vectorof sizeO(1)?
10. Design a (centralized) algorithm to create a propagatio n tree satisfying the properties given
inSection 6.8.
11. Forthemulticastalgorithmbased onpropagationtrees, answerthefollowing.
(a) Abouta tightupperboundonthenumberofmulticastgroup s.
(b) Abouta tightupperboundonthenumberofmeta-groupsoft hemulticastgroups.
(c) Examine and justify in detail, the impact (to the propaga tion tree) of (i) an existing
process departing from one of the multiple groups of which it is a member. (ii) an
existing process joining another group. (iii) the formatio n of a new group containing
new processes. (iv)theformationofanewgroupcontainingp rocesses thatarealready
part ofvariousothergroups.
12. Formulticastalgorithms,showthefollowing.
(a) Privilege-based multicast algorithms provide (i) caus al ordering if closed groups are
assumed,and (ii)totalordering.
(b) Moving sequencer algorithms, which work with open group s, provide total ordering
but notcausal ordering.
(c) Fixed sequenceralgorithmsprovidebothtotalordering and causal ordering.
13. IntheexampleofFigure6.22,drawthepropagationtreet hatresultsif:∝a\}⌊ra⌋k⌉tl⌉{tCE∝a\}⌊ra⌋k⌉tri}htwereconsidered
before∝a\}⌊ra⌋k⌉tl⌉{tBCD∝a\}⌊ra⌋k⌉tri}htas achild of∝a\}⌊ra⌋k⌉tl⌉{tABC∝a\}⌊ra⌋k⌉tri}ht.
14. ConsidertheReversePath ForwardingalgorithmofFigur e6.26fordoingamulticast.
225
(a) Modifythecodetoperform pruningofthemulticasttree.
(b) Nowmodifythecodeof(1)toalsodealwithdynamicchange stothenetworktopology
(usethealgorithmsin Module2).
(c) Now modifythecode todeal withdynamicchanges in themem bershipoftheapplica-
tionat thevariousnodes.
15. Givethe(centralized)algorithmforcreating apropaga tiontree, forany setofgroups.
16. Provethat thepropagationtreeforagivenset ofgroupsi snotunique.
17. Forthegraph inFigure 6.28,computethefollowingspann ingtrees.
(a) Steiner tree(based ontheKMBheuristic)
(b) Delay-bounded Steiner(heuristic CST CD), withadelay boundof8units.
(c) Delay-bounded Steiner(heuristic CST C), withadelay boundof8units.
18. Design a graph for which the CST CDandCST Cheuristics yield different delay-bounded
Steinertrees.
19. The algorithms for creating the propagation tree, the St einer tree, and the delay-bounded
Steiner tree are centralized. Identify the exact challenge s in making these algorithms dis-
tributed.
226
C(∝arrow⌊oth⊑); //cost of edge l
D(⌉); //delay of edge l
T; //constrained spanning tree to beconstructed
P(x,y); // path from xtoy
PC(x,y); //cost ofconstrained cheapest path from xtoy
PD(x,y); // delay on constrained cheapest path from xtoy
Cd(x,y); // cost ofthe cheapest path withdelay exactly d
Input: weighted graph G= (N,L), andN′⊆N,where N′isthe set ofSteiner points and source s
and∆isthe constraint on the delay.
1. Compute the closure graph G′on(N′,L), to be the complete graph on N′. The closure graph is
computed using the all-pairs constrained cheapest paths us ing a dynamic programming approach
analogous to Floyd’s algorithm. Foranypair of nodes x,y∈N′:
• Pc(x,y)=mind<∆Cd(x,y)Thisselectsthecheapest constrained path,satisfying the condition
of∆,amongthevariouspathspossiblebetween xandy. ThevariousCd(x,y)canbecalculated
using DPas follows.
• Cd(x,y) = min z∈N{Cd−D(z,y)(x,z) +C(z,y)}For a candidate path from xtoypassing
through z, thepath with weight exactly dmusthave adelay of d−D(z,y)forxtozwhenthe
edge(z,y)has delayD(z,y).
Inthismanner,the complete closure graph G′iscomputed.PD(x,y)istheconstrained cheapest path
that corresponds to PC(x,y).
2. Construct a constrained spanning tree of G′using a greedy approach that sequentially adds edges to
the subtree of the constrained spanning tree T(thus far) until all the Steiner points are included. The
initialvalueof Tisthesingleton s. Considerthatnode uisinthetreeandweareconsideringwhether
to add edge (u,v).
The following two edge selection criteria (heuristics) can be used to decide whether to include edge
(u,v)in the tree.
•Heuristic CST CD:fCD(u,v) =/braceleftBigg
C(u,v)
∆−(PD(s,u)+D(u,v)),ifPD(s,u) +D(u,v)<∆
∞, otherwise
The numerator is the "incremental cost" of adding (u,v)and the denominator is the "residual
delay" that could be afforded. The goal is to minimize the inc remental cost, while also maxi-
mizing the residual delay by choosing an edge that has low del ay. Thus, the heuristic picks the
neighbour vthat minimizes fCD, forall uinTand alladjacent vadjacent to T.
•Heuristic CST C:fc=/braceleftbiggC(u,v),ifPD(s,u) +D(u,v)<∆
∞,otherwise
This heuristic picks the lowest cost edge between the alread y included tree edges and their
nearest neighbour, as long as thetotal delay is less than ∆.
Thechosen node visincluded in T. This step 2isrepeated until Tincludes all|N′|nodes in G′.
3. Expand the edges of the constrained spanning tree TonG′into the constrained cheapest paths they
represent inthe original graph G. Delete/break any loops introduced by this expansion.
Figure6.29: TheconstrainedminimumSteinertreealgorith musingthe CST CDandCST Cheuris-
tics. 227
Bibliography
[1] R. Bagrodia, Synchronization of asynchronous processe s in CSP, ACM Trans. Programming
Languagesand Systems,11(4): 585-597,1989.
[2] T.Ballardie, P. Francis, J.Crowcroft, Corebased trees (CBT), ACM Sigcomm,85-95,1993.
[3] K. Bharath-Kumar, J. Jaffe, Routing to multiple destina tions in computer networks, IEEE
Transactionson Communications,31(3):343-351,March 198 3.
[4] K. Birman, T. Joseph, Reliable communicationin thepres ence offailures, ACM Trans. Com-
puterSystems,5(1): 47-76,Feb. 1987.
[5] K. Birman, A. Schiper, P. Stephenson, Lightweight causa l and atomic group multicast, ACM
Trans.ComputerSystems,9(3): 272-314,Aug.1991.
[6] P. Chandra, P. Gambhire, A. D. Kshemkalyani, Performanc e of the Optimal Causal Multicast
Algorithm: A Statistical Analysis, IEEE Transactions on Pa rallel and Distributed Systems,
15(1): 40-52, January2004.
[7] B. Charron-Bost, G. Tel, F. Mattern, Synchronous, async hronous, and causally ordered com-
munication,DistributedComputing,9(4): 173-191,1996.
[8] J.-M. Chang, N. Maxemchuk, Reliable broadcast protocol s, ACM Trans. Computer Systems,
2(3): 251-273,1984.
[9] G.-M. Chiu, C.-M. Hsiao, A Note on total ordering multica st using propagation trees, IEEE
Trans.Parallel and DistributedSystems,9(2): 217-223,Fe b. 1998.
[10] G.Chockler,I.Keidar,R.Vitenberg,Groupcommunicat ionspeciﬁcations: Acomprehensive
study,ACM ComputingSurveys,33(4): 1-43,Dec. 2001.
[11] P. Ezhilchelvan, R. Macdo, S. Shrivastava, Newtop: A fa ult-tolerant group communication
protocol, 15th IEEE International Conference on Distribut ed Computing Systems, 296-306,
1995.
[12] H. Garcia-Molina, A. Spauster, Ordered and reliable mu lticast communication,ACM Trans.
ComputerSystems,9(3): 242-271,Aug.1991.
228
[13] E. Gilbert, H. Pollack, Steiner minimal trees, SIAM J. A pplied Mathematics, 16(1): 1-29,
1968.
[14] V.Hadzilacos,S.Toueg,Fault-tolerantbroadcastsan drelatedproblems,pp.97-146,In: Dis-
tributedSystems,Ed: S. Mullender,Addison-Wesley,1993.
[15] C.A.R. Hoare, Communicating Sequential Processes, Co mmunications of the ACM, 21(8):
666-677(1978)
[16] X. Jia, A total ordering multicast protocol using propa gation trees, IEEE Trans. Parallel and
DistributedSystems,6(6): 617-627,June1995.
[17] V. Kompella, Pasquale, G. Polyzos, Multcast routing fo r multimedia communication,
IEEE/ACMTransactionsonNetworking,1(3): 86-92,June199 3.
[18] L. Kou, G. Markowsky,L. Berman, A fast algorithm for Ste iner trees, Acta Informatica, 15:
141-145,1981.
[19] A.D. Kshemkalyani, M. Singhal, An optimal algorithm fo r generalized causal message or-
dering,15thACM Symposiumon PrinciplesofDistributedCom puting,87,May1996.
[20] A.D. Kshemkalyani, M. Singhal, Necessary and sufﬁcien t conditions on information for
causalmessageorderingandtheiroptimalimplementation, DistributedComputing,11(2): 91-
111,April1998.
[21] M.Raynal,A.Schiper,S.Toueg,Thecausalorderingabs tractionandasimplewaytoimple-
mentit,InformationProcessing Letters,39:343-350,1991 .
229
Chapter7
Termination Detection
7.1 Introduction
In distributed processing systems, a problem is typically s olved in a distributed manner with the
cooperation of a numberof processes. In such an environment ,inferring if a distributedcomputa-
tion has ended is essential so that the results produced by th e computation can be used. Also, in
some applications, the problem to be solved is divided into m any subproblems, and the execution
of a subproblemcannot begin until the execution of the previ ous subproblem is complete. Hence,
it is necessary to determine when the execution of a particul ar subproblem has ended so that the
execution of the next subproblem may begin. Therefore, a fun damental problem in distributed
systemsis todetermineifadistributedcomputationhaster minated.
The detection of the termination of a distributed computati on is non-trivial since no process
has complete knowledgeof the global state, and global time d oes not exist. A distributed compu-
tationis consideredto begloballyterminated ifeveryproc ess islocally terminatedand thereisno
message in transit between any processes. “Locally termina ted"state is a state in which a process
has ﬁnished its computation and will not restart any action u nless it receives a message. In the
termination detection problem, a particular process (or al l of the processes) must infer when the
underlyingcomputationhasterminated.
When we are interested in inferring when the underlying comp utation has ended, a termina-
tion detection algorithm is used for this purpose. In such si tuations, there are two distributed
computations taking place in the distributed system, namel y,the underlying computation andthe
termination detection algorithm . Messages used in the underlying computation are called basic
messages, and messagesused forthe purposeof terminationd etection(by a terminationdetection
algorithm)arecalled controlmessages.
A terminationdetection (TD)algorithmmustensurethefoll owing:
1. Execution of a TD algorithm cannot indeﬁnitely delay the u nderlying computation; that is,
executionoftheterminationdetectionalgorithmmustnotf reezetheunderlyingcomputation.
2. Theterminationdetectionalgorithmmustnotrequireadd itionofnewcommunicationchan-
nelsbetween processes.
230
7.2 SystemModelof aDistributedComputation
A distributed computation consists of a ﬁxed set of processe s which communicate solely by mes-
sage passing. All messages are received correctly after an a rbitrary but ﬁnite delay. Communi-
cation is asynchronous , i.e., a process never waits for the receiver to be ready befo re sending a
message. Messages sentoverthesamecommunicationchannel maynotobey theFIFO ordering.
Thedistributedcomputationhas thefollowingcharacteris tics:
1. At any given timeduring execution of the distributed comp utation,a process can be in only
oneofthetwostates: active,whereitisdoinglocalcomputationand idle,wheretheprocess
has(temporarily)ﬁnishedtheexecutionofitslocalcomput ationandwillbereactivatedonly
on the receipt of a message from another process. The active a nd idle states are also called
thebusyandpassivestates,respectively.
2. An active process can become idle at any time. This corresp onds to the situation where the
process hascompleteditslocal computationand hasprocess ed all receivedmessages.
3. An idle process can become active only on the receipt of a me ssage from another process.
Thus,anidleprocesscannotspontaneouslybecomeactive(e xceptwhenthedistributedcom-
putationbeginsexecution).
4. Onlyactiveprocessescansendmessages. (Sincewearenot concernedwiththeinitialization
problem, we assume that all processes are initially idle and a message arrives from outside
thesystemto startthecomputation.)
5. A message can be received by a process when the process is in either of the two states, i.e.,
activeoridle. Onthereceipt ofamessage,an idleprocessbe comes active.
6. Thesendingofa messageand thereceipt ofamessageoccura s atomicactions.
We restrict to executions in which every process eventually becomes idle, although this prop-
erty is in general undecidable. If a termination detection a lgorithm is applied to a distributed
computationin whichsomeprocesses remainin theiractives tates forever, theTD algorithmitself
willnotterminate.
Deﬁnition ofTerminationDetection
Letpi(t) denote the state (active or idle) of process piat instanttandci,j(t) denote the number
of messages in transit in the channel at instant tfrom process pito processpj. A distributed
computationissaid tobeterminatedat timeinstant t0iff:
(∀i::pi(t0)= idle)∧(∀i,j::ci,j(t0)=0).
231
7.3 TerminationDetectionUsingDistributedSnapshots
Thealgorithmusesthefact thataconsistentsnapshotofadi stributedsystemcapturesstableprop-
erties. Terminationofadistributedcomputationisastabl eproperty. Thus,ifaconsistentsnapshot
ofadistributedcomputationistakenafterthedistributed computationhasterminated,thesnapshot
willcapturetheterminationofthecomputation.
The algorithm assumes that there is a logical bidirectional communication channel between
every pair of processes. Communication channels are reliab le but non-FIFO. Message delay is
arbitrary butﬁnite.
7.3.1 InformalDescription
The main idea behind the algorithm is as follows: When a compu tation terminates, there must
exist a unique process which became idle last. When a process goes from active to idle, it issues
a request to all other processes to take a local snapshot, and also requests itself to take a local
snapshot. When a process receives the request, if it agrees t hat the requester became idle before
itself, it grants the request by taking a local snapshot for t he request. A request is said to be
successful if all processes have taken a local snapshot for it. The reque ster or any external agent
may collect all thelocal snapshotsof a request. If a request is successful, a global snapshotof the
request can thus be obtained and the recorded state will indi cate termination of the computation,
viz.,intherecorded snapshot,alltheprocessesareidlean dthereisnomessageintransittoanyof
theprocesses.
7.3.2 FormalDescription
The algorithm needs logical time to order the requests. Each processimaintains an logical clock
denoted byx, which is initialized to zero at the start of the computation . A process increments its
xby one each time it becomes idle. A basic message sent by a proc ess at its logical time xis of
the formB(x). A control message that requests processes to take local sna pshot issued by process
iat its logical time xis of the form R(x, i). Each process synchronizes its logical clock xloosely
withthelogicalclocks x’sonotherprocessesinsuchaway thatitisthemaximumofclock values
ever received or sent in messages. Besides logical clock x, a process maintains a variable ksuch
thatwhentheprocessisidle, (x,k)isthemaximumofthevalues (x, k)onallmessages R(x,k)ever
received or sent by the process. Logical time is compared as f ollows:(x, k)>(x’, k’)iff(x>x’)
or((x=x’) and (k >k’)), i.e., a tie between xandx’is broken by the process identiﬁcation numbers
kandk’.
Thealgorithmisdeﬁnedbythefollowingfourrules. Weusegu ardedstatementstoexpressthe
conditionsand actions. Each process iappliesoneoftheruleswheneverit isapplicable.
(R1): When process iisactive,itmay sendabasicmessageto process jat any timebydoing
send aB(x)toj.
232
(R2): Uponreceiving a B(x’), processidoes
letx:=x’+1;
if(iis idle)→goactive.
(R3): When process igoes idle,itdoes
letx:=x+1;
letk:=i;
sendmessage R(x, k)to allotherprocesses;
takealocal snapshotfortherequestby R(x, k).
(R4): Uponreceiving message R(x’, k’), processidoes
[((x’, k’)>(x,k))∧(i isidle)→let(x,k):= (x’, k’);
takealocal snapshotfortherequest by R(x’, k’);
2
((x’, k’)≤(x,k))∧(iis idle)→donothing;
2
(iisactive)→letx:=max(x’, x)].
7.3.3 Discussion
As per Rule R1, when a process sends a basic message to any othe r process, it sends its logical
clockvalueinthemessage. FromRuleR2, whenaprocessrecei vesabasicmessage,itupdatesits
logicalclock basedontheclockvaluecontainedinthemessa ge. Rule3statesthatwhenaprocess
becomesidle,itupdatesitslocalclock,sendsarequestfor snapshotR(x,k)toeveryotherprocess,
and takesa localsnapshotforthisrequest.
RuleR4 isthemostinteresting. Onthereceipt ofamessage R(x’, k’), theprocesstakes alocal
snapshotifitisidleand (x’,k’)>(x,k),i.e.,timinginthemessageislaterthanthelocaltimeatth e
process, implyingthat thesender of R(x’, k’)terminated after this process. In this case, it is likely
that the sender is the last process to terminate and thus, the receiving process takes a snapshot for
it. Because of this action, every process will eventually ta ke a local snapshot for the last request
when the computation has terminated, that is, the request by the latest process to terminate will
becomesuccessful.
In the second case, (x’, k’)≤(x,k), implying that the sender of R(x’, k’) terminated before
this process, hence, the sender of R(x’, k’) can not be the last process to terminate. Thus, the
receiving process does not take a snapshot for it. In the thir d case, the receiving process has not
even terminated. Hence, the sender of R(x’, k’) can not be the last process to terminate and no
snapshotistaken.
The last process to terminate will have the largest clock val ue. Therefore, every process will
takeasnapshotforit,however,it willnot takeasnapshotfo rany otherprocess.
233
7.4 TerminationDetectionbyWeightThrowing
Interminationdetectionbyweightthrowing,aprocesscall edcontrollingagent1monitorsthecom-
putation. Acommunicationchannelexistsbetweeneachofth eprocessesandthecontrollingagent
and alsobetween everypairofprocesses.
BasicIdea
Initially,allprocessesareintheidlestate. Theweightat eachprocessiszeroandtheweightatthe
controllingagentis1. Thecomputationstartswhenthecont rollingagentsendsabasicmessageto
one of the processes. The process becomes active and the comp utation starts. A non-zero weight
W (0<W≤1) is assigned to each process in the active state and to each m essage in transit in the
following manner: When a process sends a message, it sends a p art of its weight in the message.
When a process receivesa message,it add theweight received in themessageto itsweight. Thus,
the sum of weights on all the processes and on all the messages in trasit is always 1. When a
process becomes passive, it sends its weight to the controll ing agent in a control message, which
the controlling agent adds to its weight. The controlling ag ent concludes termination if its weight
becomes1.
Notations
Theweightonthecontrollingagent and aprocess isingenera l represented by W.
B(DW)-abasicmessageBsentas apartofthecomputation,whe reDWistheweightassignedto
it.
C(DW)-acontrolmessageCsentfromaprocesstothecontroll ingagentwhereDWistheweight
assignedtoit.
7.4.1 FormalDescription
Thealgorithmis deﬁned bythefollowingfourrules:
Rule 1:The controlling agent or an active process may send a basic me ssage to one of the pro-
cesses,sayP,bysplittingitsweightWintoW1andW2suchtha tW1+W2=W,W1 >0andW2>0.
It thenassignsitsweightW:=W1 and sendsabasicmessageB(D W:=W2) to P.
Rule2:Onthereceipt ofthemessageB(DW), processPaddsDW toitswe ightW(W:=W+DW).
Ifthereceivingprocess isintheidlestate, itbecomes acti ve.
1Thecontrollingagentcanbeoneoftheprocessesinthecompu tation.
234
Rule 3:A process switches from the active state to the idle state at a ny time by sending a control
messageC(DW:=W) to thecontrollingagentand makingitswei ghtW:=0.
Rule4:OnthereceiptofamessageC(DW),thecontrollingagentadds DWtoitsweight(W:=W+DW).
IfW=1, then itconcludesthat thecomputationhas terminate d.
7.4.2 Correctnessof the Algorithm
To provethecorrectness ofthealgorithm,thefollowingset s aredeﬁned:
A: setofweightsonall activeprocesses
B: set ofweightson allbasicmessagesin transit
C: set ofweightson allcontrol messagesintransit
Wc: weighton thecontrollingagent.
Two invariants I1andI2aredeﬁned for thealgorithm:
I1: Wc+/summationdisplay
W∈(A∪B∪C)W =1
I2:∀W∈(A∪B∪C), W>0
InvariantI1states that sum of weights at the controllingprocess, at all activeprocesses, on all
basic messages in transit, and on all control messages in tra nsit is always equal to 1. Invariant
I2states that weight at each active process, on each basic mess age in transit, and on each control
messagein transitisnon-zero.
Hence,
Wc=1
:/summationtext
W∈(A∪B∪C)W =0 (byI1)
:(A∪B∪C)=φ(byI2)
:(A∪B)=φ.
Note that (A∪B) =φimplies the computation has terminated. Therefore, the alg orithm never
detects afalsetermination.
Further,
(A∪B)=φ
:Wc+/summationtext
W∈CW =1(byI1)
Since the message delay is ﬁnite, after the computation has t erminated, eventually W c=1. Thus,
thealgorithmdetects aterminationinﬁnitetime.
235
7.5 ASpanning-Tree-BasedTerminationDetectionAlgorith m
The algorithm assumes there are N processes Pi, 0≤i≤N, which are modeled as the nodes i,
0≤i≤N, ofa ﬁxed connected undirected graph. Theedges ofthegrap h represent thecommunica-
tionchannels,throughwhichaprocesssendsmessagestonei ghboringprocessesinthegraph. The
algorithmusesaﬁxedspanningtreeofthegraphwithprocess P0atitsrootwhichisresponsiblefor
terminationdetection. Process P0communicateswithotherprocessestodeterminetheirstate sand
themessagesused forthispurposeare called signals. Allle af nodesreport to theirparents, ifthey
haveterminated. Aparentnodewillsimilarlyreporttoitsp arentwhenithascompletedprocessing
and all of its immediate children have terminated, and so on. The root concludes that termination
has occurred, ifithas terminatedand allofitsimmediatech ildrenhavealso terminated.
The termination detection algorithm generates two waves of signals moving inward and out-
ward through the spanning tree. Initially, a contracting wa ve of signals, called tokens, moves
inward from leaves to the root. If this token wave reaches the root withoutdiscoveringthat termi-
nationhasoccurred,therootinitiatesasecondoutwardwav eofrepeatsignals. Asthisrepeatwave
reaches leaves, the token wave gradually forms and starts mo vinginward again. This sequence of
eventsis repeated untiltheterminationisdetected.
7.5.1 Deﬁnitions
1. Tokens: A contractingwaveofsignalsthatmoveinwardfro m theleaves totheroot.
2. Repeat signal: Ifatokenwavefailsto detecttermination ,nodeP0 initiatesanotherroundof
terminationdetectionby sendingasignalcalled Repeat, to theleaves.
3. Thenodeswhichhaveoneormoretokensat anyinstantform a setS.
4. AnodejissaidtobeoutsideofsetSifjdoesnotbelongtoSa ndthepath(inthetree)from
the root to j contains an element of S. Every path from the root to a leaf may not contain a
nodeofS.
5. Notethat all nodes outsideS are idle. This is because, any nodethat terminates, transmitsa
tokento itsparent. When anodetransmitsthetoken,itgoes o utofthesetS.
We ﬁrst give a simple algorithm for termination detection an d discuss a problem associated
withit. Then weprovidethecorrect algorithm.
7.5.2 ASimple Algorithm
Initially, each leaf process is given a token. Each leaf proc ess, after it has terminated sends its
token to its parent. When a parent process terminates and aft er it has received a token from each
of itschildren, it sends atoken to itsparent. This way, each process indicates to its parent process
that the subtree below it has become idle. In a similar manner , the tokens get propagated to the
236
root. Therootofthetreeconcludesthatterminationhasocc urred, afterithasbecomeidleandhas
receivedatoken fromeach ofitschildren.
AProblem with the algorithm
This simple algorithm fails under some circumstances. Afte r a process has sent its token to its
parent, it shouldremain idle. However,this is nottrue. The problemarises when aprocess after it
has sent atoken to itsparent, receives amessagefrom someot herprocess. Notethatthismessage
couldcause theprocess (thathas already senta tokento itsp arent)to againbecomeactive. Hence
the simple algorithm fails since the process that indicated to its parent that it has become idle, is
now active because of the message it received from an active p rocess. Hence, the root node just
becauseitreceivedatokenfromachild,can’tconcludethat allprocessesinthechild’ssubtreehave
terminated. Thealgorithmhas tobereworked toaccommodate such message-passingscenarios.
0
1 2
3 4 5 6T1
T5 T6m
denotes a token
Figure7.1: AnExampleoftheProblem.
The problem is explained with the example shown in Figure 7.1 . Assume that process 1 has
sentitstoken(T1)toitsparent,namely,process0. Onrecei vingthetoken,process0concludesthat
process1anditschildrenhaveterminated. Process0ifitis idle,canconcludethatterminationhas
occurred, whenever it receives a token from process 2. But no w assume that just before process 5
terminates,itsendsamessagemtoprocess1. Onthereceptio nofthismessage,process1becomes
activeagain. Thus,theinformationthatprocess0hasabout process1(thatitisidle)becomesvoid.
Therefore, thissimplealgorithmdoes notwork.
7.5.3 The Correct Algorithm
We now present the correct algorithm that works even when mes sages such as above are present.
The main idea is to color the processes and tokens and change t he color when messages such as
aboveareinvolved.
237
The BasicIdea
In order to enable the root node to know that a node in its child ren’s subtree, that was assumed
to be terminated, has become active due to a message, a colori ng scheme for tokens and nodes is
used. The root can determine that an idle process has been act ivated by a message, based on the
colorofthetokenitreceivesfromitschildren. Alltokensa reinitializedtowhitecolor. Ifaprocess
had sent a message to some other process, it sends a black toke n to its parent on termination;
otherwise, it sends a white token on termination. Hence, the parent process on getting the black
tokenknowsthatitschildhad sentamessageto someotherpro cess. Theparent,when sendingits
token (on terminating)to its parent, sends a black token onl y ifit received a black token from one
of its children. This way, the parent’s parent knows that one of the processes in its child’s subtree
had sent a message to some other process. This gets propagate d and ﬁnally the root node knows
that message-passingwas involvedwhen it receives a black t oken from oneof its children. In this
case, the root asks all nodes in the system to restart the term ination detection. For this, the root
sends a repeat signal to all other process. After receiving t he repeat signal, all leaves will restart
theterminationdetectionalgorithm.
The Algorithm Description
Thealgorithmworks asfollows:
1. Initially, each leaf process is provided with a token. The set S is used for book-keeping to
knowwhichprocesses havethetoken. HenceS willbetheset of allleaves inthetree.
2. Initially,all processes and tokens are colored white. As explained above, coloring helps the
rootknowifamessage-passingwas involvedin oneofthesubt rees.
3. When aleafnodeterminates,itsendsthetokenitholdsto i tsparentprocess.
4. A parent process will collect the token sent by each of its c hildren. After it has received a
token from all of its children and after it has terminated, th eparent process sends a token to
itsparent.
5. Aprocessturnsblackwhenitsendsamessagetosomeotherp rocess. Thiscoloringscheme
helps aprocess remember that ithas senta message. When a pro cess terminates,if itscolor
isblack, itsendsa blacktoken toitsparent.
6. A blackprocess turnsback to white,afterit hassent ablac k tokentoitsparent.
7. A parent process holding a black token (from one of its chil dren), sends only a black token
toitsparent, to indicatethatamessage-passingwas involv edinitssubtree.
8. Tokens are propagated to the root in this fashion. The root , upon receiving a black token,
will know that a process in the tree had sent a message to some o ther process. Hence, it
restartsthealgorithmby sendingaRepeat signalto allitsc hildren.
238
9. Each child of the root propagates the Repeat signal to each of its children and so on, until
thesignalreaches theleaves.
10. Theleafnodesrestart thealgorithmon receivingtheRep eat signal.
11. Therootconcludesthat terminationhas occurred, if
(a) it iswhite,
(b) it isidle,and
(c) it receivedawhitetokenfromeach ofitschildren.
7.5.4 AnExample
Wenowpresent an exampletoillustratetheworkingofthealg orithm.
1. Initially,all nodes0 to6 are coloredwhite(Figure7.2). Leaf nodes3, 4,5 and 6 areeach given
atoken. Node3hastokenT3,node4hastokenT4,node5hastoke nT5,andnode6hastokenT6.
Hence, S is{3,4, 5, 6}.
0
1 2
3 4 5 6
T5 T6 T4 T3
Figure7.2: Allleafnodes havetokens. S={3,4,5,6}.
2. When node 3 terminates, it transmits T3 to node 1. Now S chan ges to 1, 4, 5, 6. When node 4
terminates,ittransmitsT4 tonode1 (Figure7.3). Hence, Sc hanges to{1, 5,6}.
3. Node 1 has received a token from each of its children and whe n it terminates, it transmits a
tokenT1 toitsparent (Figure7.4). Schanges to {0, 5,6}.
4. After this, suppose node 5 sends a message to node 1, causin g node 1 to again become ac-
tive (Figure 7.5). Since node 5 had already sent a token to its parent node 0 (thereby, making
node0assumethatnode5had terminated),thenewmessagemak esthesysteminconsistentas far
asterminationdetectionisconcerned. Todealwiththis,th ealgorithmexecutesthefollowingsteps.
239
0
1 2
3 4 5 6
T5 T6T3T4
Figure7.3: Nodes3 and 4becomeidle. S={1,5,6}.
0
1 2
3 4 5 6
T5 T6T1
Figure7.4: Node1 becomesidle. S={0,5,6}.
0
1 2
3 4 6
T5 T6T1
5 
Figure7.5: Node5 sendsamessagetonode1.
240
5. Node5 iscolored black, sinceit sentamessagetonode1.
6. When node 5 terminates, it sends a black token T5 to node 2. S o, S changes to{0, 2, 6}. After
node5sendsitstoken,itiscoloredwhite(Figure7.6). When Node6terminates,itsendsthewhite
tokenT6 tonode2. Hence, Schanges to {0, 2}.
0
1 2
3 4 6T1
5T6T5
Figure7.6: Nodes5 and 6 becomeidle. S={0,2}.
7. When node 2 terminates, it sends a black token T2 to node 0, s ince it holds a black token T5
from node5 (Figure7.7).
0
1 2
3 4 6T1
5T2
Figure7.7: Node2 becomesidle. S={0}. Node0 initiatesarep eat signal.
8. Sincenode0hasreceivedablacktokenT2fromnode2,itkno wsthattherewasamessagesent
by oneormoreofitschildrenin thetreeand henceit sendsare peat signalto each ofitschildren.
9. Therepeatsignalispropagatedtotheleafnodesandtheal gorithmisrepeated. Node0concludes
that termination has occurred, if it is white, it is idle, and it has received a white token from each
ofitschildren
241
7.5.5 Performance
The best case message complexity of the algorithm is O(N), wh ere N is the number of processes
inthecomputation. Thebestcaseoccurswhenallnodessenda llcomputationmessagesintheﬁrst
round. Therefore, thealgorithmexecutesonlytwiceand the messagecomplexitydependsonlyon
thenumberofnodes.
However, the worst case complexity of the algorithm is O(N*M ), where M is the number
of computation messages exchanged. The worst case occurs wh en only computation message
is exchanged every time the algorithm is executed. This caus es the root to restart termination
detection as many times as there are no computationmessages . Hence, the worst case complexity
isO(N*M).
7.6 Message-OptimalTerminationDetection
Nowwediscussamessageoptimalterminationdetectionalgo rithmbyChandrasekaranandVenkate-
san [2]. The network is represented by a graph G = (V, E), where V is the set of nodes, and E ⊆
V×V is the set of edges or communication links. The communicati on links are bidirectional and
exhibitFIFOproperty. Theprocessorsandcommunicationli nksincurarbitrarybutﬁnitedelaysin
executing their functions. The algorithm assumes the exist ence of a leader and a spanning tree in
the network. If a leader is not available, the minimum spanni ng tree algorithm of Gallager et al.
can beused toelect aleader andﬁnd aspanningtreeusingO( |E|+|V|log|V|)messages.
7.6.1 The MainIdea
Let us consider the following method for termination detect ion due to Topor: The root of the tree
initiatesonephaseofterminationdetectionbyturningwhi te. Aninteriornode,onreceivingawhite
tokenfromitsparent,turnswhiteandtransmitsawhitetoke ntoallofitschildren. Eventuallyeach
leaf receives a white token and turns white. When a leaf node b ecomes idle, it transmits a token
to its parent and thetoken has thesame coloras that ofthe lea f node. An interiornodewaits for a
tokenfromeachofitschildren. Italsowaitsuntilitbecome sidle. Itthensendsawhitetokentoits
parent ifits color is whiteand it received a whitetoken from each of itschildren. Finally, the root
node infers the termination of the underlying computation i f it receives a white token from each
child,itscoloriswhite,and itis idle.
This simple algorithm is inefﬁcient in terms of message comp lexity due to the following rea-
sons: Consider the scenario shown in Figure 7.8, where node psends a message mto nodeq.
Before node qreceived the message m, it had sent a white token to its parent (because it was idle
and it had received a white token from each of its children). I n this situation, node pcan not send
a white token to its parent until node qbecomes idle. To insure this, in Topor’s algorithm, node
pchanges its color to black and sends a black token to its paren t so that termination detection is
performed once again. Thus, every message of the underlying computation can potentially cause
242
the execution of one more round of the termination detection algorithm, resulting in signiﬁcant
messagetrafﬁc.
pwhite token’s parentq
qm
Figure7.8: Node psendsa message mto nodeqthathas already sent awhitetokento itsparent.
The main idea behind the message-optimal algorithm is as fol lows: When a node psends a
messagemtonodeq,pshouldwaituntil qbecomesidleandonlyafterthat, pshouldsendawhite
token to its parent. This rule ensures that if an idle node qis restarted by a message mfrom from
a nodep, then thesender pwaitstillqterminatesbefore pcan send awhitetoken to itsparent. To
achieve this, when node qterminates, it sends an acknowledgement (a control message ) to node
pinforming node pthat the set of actions triggered by message mhas been completed and that
nodepcan send a white token to its parent. However, note that node q, after being woken up by
messagemfromnode p,maywakeupanotheridlenode r,whichinturnmaywakeupothernodes.
Therefore, node qshould not send an acknowledgement to puntil it receives acknowledgement
messages for all of the messages it sent after it received mes sagemfrom node p. This restriction
alsoappliestonode randothernodes. Clearly,boththesenderandthereceiverke eptrackofeach
message, and a node sends a white token to its parent only afte r it receives an acknowledgement
foreverymessageitsentand ithas received awhitetokenfro m each ofitschildren.
7.6.2 FormalDescription ofthe Algorithm
Initially, all nodes in the network are in state NDT (not dete cting termination) and all links are
uncolored. Forterminationdetection,therootnodechange sitsstatetoDT(detectingtermination)
and sends a warning message on each of its outgoing edges. Whe n a nodepreceives a warning
message from its neighbor, say q, it colors2the incoming link ( q,p) and if it is in state NTD, it
changesitsstatetoDT,colorseach ofitsoutgoingedges,an dsendsawarningmessageoneachof
itsoutgoingedges.
When a node pin state DT sends a basic message to its neighbor q, it keeps track of this
informationby pushingtheentry TO( q)onitslocal stack.
When a node xreceives a basic message from node yon the link ( y,x) that is colored by x,
nodexknowsthatthesendernode ywillneed an acknowledgementforthismessagefrom it. The
2All linksareuncoloredorcolored. Theshadeofthe colordoe snotmatter.
243
receiver node xkeeps track of this information by pushing the entry FROM( y) on its local stack.
Procedure receive_messageisgivenbelow:
Procedure receive_message( y: neighbor);
(* performed when a node xreceives a message from its neighbor yon the link ( y,x) that was
colored byx*)
begin
receivemessagefrom yonthelink( y,x)
if(link(y,x)hasbeen colored by x)then
pushFROM( y)onthestack
end;
Eventually,everynodeinthenetworkwillbeinthestateDTa sthenetworkisconnected. Note
thatbothsenderand receiverkeep track ofeverymessagein t hesystem.
When a node pbecomes idle, it calls procedure stack_cleanup which is deﬁ ned below. Pro-
cedure stack_cleanup examines its stack from the top, and fo r every entry of the form FROM( q),
it deletes the entry and sends the remove_entry message to node q. Nodeprepeats this until it
encounters an entry of the form TO( x) on the stack. The idea behind this step is to inform those
nodesthat sentamessageto pthattheactionstriggeredby theirmessagesto parecomplete.
Procedure stack_cleanup;
begin
while(topentry onstack isnot oftheform “TO()")do
begin
poptheentry onthetopofthestack;
let theentry beFROM( q);
send aremove_entry messageto q
end
end;
When a node xreceives a remove_entry message from its neighbour y, nodexinfers that the
operations triggered by its last message to yhave been completed and hence it no longer needs to
keep track of this information. Node xon receipt of the control message remove_entry from node
y, examines its stack from the top and deletes the ﬁrst entry of the form TO( y) from the stack. If
nodexisidle,italsoperformsthe stack_cleanupoperation. Theprocedure receive_remove_entry
isdeﬁned asfollows:
Procedure receive_remove_entry( y: neighbor);
(* performed whena nodex receivesaremove_entry messagefr om itsneighbor y*)
244
begin
scan thestackand deletetheﬁrst entry oftheformTO( y);
ifidlethen
stack_cleanup
end;
A nodesendsaterminatemessagetoitsparent when itsatisﬁe s allthefollowingconditions:
1. It isidle.
2. Each of its incoming links is colored (it has received a war ning message on each of its
incominglinks).
3. Itsstack isempty.
4. Ithasreceiveda terminate messagefromeachofitschildren(thisruledoesnotapplyto leaf
nodes).
When theroot nodesatisﬁes all ofthe aboveconditions,it co ncludes that theunderlyingcom-
putationhas terminated.
7.6.3 Performance
We analyze the number of control messages used by the algorit hm in the worst case. Each node
in the network sends one warning message on each outgoing lin k. Thus, each link carries two
warning messages, one in each direction. Since there are |E|links, the total number of warning
messages generated by the algorithm is 2* |E|. For every message generated by the underlying
computation (after the start of the termination detection a lgorithm), exactly one remove_message
issentonthenetwork. IfMisthenumberofmessagessentbyth eunderlyingcomputation,thenat
mostMremove_entry messagesareused. Finally,eachnodesendsexactlyone terminate message
toitsparent(onthetreeedge)andsincethereareonly |V|nodesand|V|−1treeedges,only|V|−
1terminate messagesaresent. Hence, thetotalnumberofmessages gener ated bythealgorithmis
2*|E|+|V|−1+M.Thus,themessagecomplexityofthealgorithmisO( |E|+M)as|E|>|V|−
1foranyconnectednetwork. Thealgorithmisasymptoticall yoptimalinthenumberofmessages.
7.7 TerminationDetectioninaVeryGeneralDistributedCom -
putingModel
So far we assumed that the reception of a single message is eno ugh to activate a passive process.
Now we consider a general model of distributed computing whe re a passive process does not
necessarily become active on the receipt of a message. Inste ad, the condition of activation of a
passiveprocessismoregeneraland apassiveprocessrequir esasetofmessagestobecomeactive.
245
Thisrequirementisexpressedbyan activationcondition deﬁnedoverthesetD Siofprocessesfrom
which a passive process Piis expecting messages. The set D Siassociated with a passive process
Piis called the dependent set ofPi. A passive process becomes active only when its activation
conditionis fulﬁlled.
7.7.1 ModelDeﬁnition andAssumptions
The distributed computation consists of a ﬁnite set P of proc essesPi,i=1, ...,n, interconnected
by unidirectionalcommunicationchannels. Communication channels are reliable, but they do not
obeyFIFO property. Messagetransferdelay isﬁnitebutunpr edictable.
A passiveprocessthathas terminateditscomputationby exe cutingforexamplean endorstop
statement is said to be individually terminated; its depend ent set is empty and therefore, it can
neverbeactivated.
AND, OR,andANO-ORModels
There are several request models, such as AND, OR, AND-OR mod els. In the AND model, a
passive process Pican be activated only after a message from every process belo nging to DSi
has arrived. In the OR model, a passive process Pican be activated when a message from any
processbelongingtoD Sihasarrived. IntheAND-ORmodel,therequirementofapassiv eprocess
Piis deﬁned by a set Riof setsDSi1,DSi2,...DSiqi, such that for all r, 1≤r≤qi,DSir⊆P.
The dependent set of PiisDSi=DSi1∪DSi2∪...DSiqi. ProcessPiwaits for messages from all
processes belonging to DSi1or for messages from all processes belonging to DSi2or...or for
messagesfrom allprocesses belongingto DSiqi.
The kout ofn Model
In the k out of n model, the requirement of a passive process Piis deﬁned by the set DSiand an
integerki, 1≤ki≤|DSi|=niand process Pibecomes active when it has received messages from
kidistinct processes in DSi. Note that a more general k out of n model can be constructed as
disjunctionsofseveralk outofn requests.
Predicate fulﬁlled
To abstract the activation condition of a passiveprocess Pi, a predicate fulﬁlledi(A)is introduced,
where A is a subset of P. Predicate fulﬁlledi(A)is true if and only if messages arrived (and not yet
consumed)from allprocesses belongingto setA are sufﬁcien ttoactivateprocess Pi.
7.7.2 Notations
Thefollowingnotationswillbeusedto deﬁneterminationof adistributedcomputation:
•passive i: trueiffPiis passive
246
•empty(j,i): true iff all messages sent by PjtoPihave arrived at Pi; the messages not yet
consumedby Piare initslocal buffer.
•arri(j): trueiffamessagefrom PjtoPihasarrivedat Piandhasnotyetbeenconsumedby
Pi.
•ARR i= {processes Pjsuch thatarri(j)}.
•NEi={processes Pjsuchthat¬empty(j,i)}.
7.7.3 TerminationDeﬁnitions
Two differenttypesofterminationsare deﬁned, dynamicter minationand statictermination:
•Dynamictermination: The set of processes Pis said to be dynamically terminated at some
instantifand onlyifthepredicate Dtermistrueat thatmomentwhere:
Dterm≡∀Pi∈P:passive i∧¬fulfilled i(ARR i∪NEi).
Dynamic termination means that no more activity is possible from processes, though mes-
sagesoftheunderlyingcomputationcanstillbeintransit. Thisdeﬁnitionisusefulin"early"
detection of termination as it allows concluding a computat ion has terminated even if some
ofitsmessageshavenotyetarrived.
Note that dynamic termination is a stable property because o nceDtermis true, it remains
true.
•Statictermination: The set of processes Pis said to be statically terminated at some instant
ifandonlyifthepredicate Stermis trueat that momentwhere:
Sterm≡∀Pi∈P:passive i∧(NEi=∅)∧¬fulfilled i(ARR i)
Static termination means all channels are empty and none of t he processes can be acti-
vated. Thus,staticterminationisfocusedonthestateofbo thchannelsandprocesses. When
compared to Dterm, the predicate Stermcorresponds to “late" detection as, additionally, all
channelsmustbeempty.
7.7.4 AStatic TerminationDetection Algorithm
InformalDescription
Acontrolprocess Ci,calledcontroller ,isassociatedwitheachapplicationprocess Pi. Itsroleisto
observethebehaviorofprocess Piandto cooperatewithothercontrollers Cjtodetect occurrence
247
ofthepredicate Sterm. Inordertodetectstatictermination,acontroller,say Ca,initiatesdetection
by sending a control message queryto all controllers (including itself). A controller Ciresponds
with a message reply(ldi), whereldiis a Boolean value. Cacombines all the Boolean values
received in replymessages to compute td:=/logicalanddisplay
1≤i≤nldi. Iftdis true,Caconcludes that termination
has occurred. Otherwise, it sends new querymessages. The basic sequence of sending of query
messagesfollowedbythereception ofassociated replymessagesiscalled a wave.
Thecoreofthealgorithmisthewayacontroller Cicomputesthevalue ldisentbackina reply
message. To ensuresafety,thevalues ld1,...ldnmustbesuch that:
/logicalanddisplay
1≤i≤nldi:Sterm
:∀Pi∈P:passive i∧(NEi=∅)∧¬fulfilled i(ARR i).
Acontroller Cidelaysaresponsetoa queryaslongasthefollowinglocallyevaluablepredicate
is false:passive i∧(notack i= 0)∧¬fulfilled i(ARR i). When this predicate is false, the static
terminationcannot beguaranteed.
Forcorrectness,thevaluesreportedbyawavemustnotmissa ctivityofprocesses“intheback"
of the wave. This is achieved in the following manner: each co ntrollerCimaintains a Boolean
variablecpi(initializedtotrueiff Piisinitiallypassive)in thefollowingway:
•WhenPibecomesactive, cpiisset tofalse.
•WhenCisends a reply message to Ca, it sends the current value of cpiwith this message,
and thensets cpito true.
Thus,ifareplymessagecarriesvaluetruefrom CitoCa,itmeansthat Pihasbeencontinuously
passivesincethepreviouswave, and themessages arrivedan d not yet consumedare not sufﬁcient
toactivatePi, and alloutputchannelsof Piare empty.
FormalDescription
The algorithm for static termination detection is as follow s. By amessage, we mean any message
oftheunderlyingcomputation; queriesandrepliesare called controlmessages.
S1: WhenPisendsamessageto Pj
notack i:=notack i+1
S2: When amessagefrom PjarrivestoPi
send ack toCj
S3: WhenCireceives ack from Cj
notack i=notack i-1
248
S4: WhenPibecomesactive
cpi:=false
(*Apassiveprocesscanonlybecomeactivewhenitsactivati onconditionistrue;thisactivationis
underthecontroloftheunderlyingoperatingsystem,andth eterminationdetectionalgorithmonly
observesit. *)
S5: WhenCireceives query from Cα
(* Executedonlyby Cα*)
Wait until
((passive i∧(notack i=∅)¬fulfilled i(ARR i));
ldi:=cpi;
cpi:=true;
sendreply(ldi)toCα
S6: When controller Cadecides todetect statictermination
repeat send querytoallCi;
receivereply(ldi)from allCi;
td:=/logicalanddisplay
1≤i≤nldi;
untiltd;
claimstatictermination
Performance
Theefﬁciencyofthisalgorithmdependsontheimplementati onofwaves. Twowavesareingeneral
necessary to detect static termination. A wave needs two typ es of messages: nqueries and n
replies, each carrying one bit. Thus, 4 ncontrol messages of two distinct types carrying at most
one bit each are used to detect the termination once it has occ urred. If waves are supported by
a ring, this complexity reduces to 2 n. The detection delay is equal to duration of two sequential
waveexecutions.
7.7.5 ADynamic TerminationDetection Algorithm
Recall that a dynamic terminationcan occur before all messa ges of the computationhave arrived.
Thus,terminationofthecomputationcan bedetected sooner than instatictermination.
249
InformalDescription
LetCαdenotethecontrollerthatlaunches thewaves. In additiont ocpi, each controller Cihas the
followingtwovectorvariables,denotedas siandri, thatcountmessages, respectively,sent toand
receivedfrom everyotherprocess.
si[j]denotes thenumberofmessages sentby PitoPj.
ri[j]denotes thenumberofmessages receivedby PifromPj.
Let S denote an n ×n matrix of counters used by Cα; entry S[i,j] represents Cα’s knowledge
aboutthenumberofmessagessent by PitoPj.
First,Casends to each Cia query message containingthevector(S[1, i],...,S[n,i]), denoted by
S[.,i]. Upon receiving this query message, Cicomputes the set ANE iof its non-empty channels.
This is an approximate knowledge but is sufﬁcient to ensure c orrectness. Then Cicomputesldi
which is true if and only if Pihas been continuously passive since the previous wave and it s
requirement cannot be fulﬁlled by all the messages arrived a nd not yet consumed ( ARR i) and
all messages potentially in its input channels ( ANE i).Cisends toCαa reply message carrying
the valuesldiand vectorsi. Vectorsiis used byCαto update row S[ i,.] and thus gain more
accurateknowledge. If/logicalanddisplay
1≤i≤nldievaluatestotrue, Caclaimsdynamicterminationoftheunderlying
computation. Otherwise, Cαlaunches anewwaveby sending querymessages.
Vector variables siandriallowCαto update its (approximate) global knowledge about mes-
sages sent by each Pito eachPjand get an approximateknowledgeof the set of non-emptyinpu t
channels.
FormalDescription
All controllers Ciexecutestatements S1 to S4. Only the initiator Cαexecutes S5. Local variables
si,riand Sare initializedto0.
S1: WhenPisendsamessageto Pj
si[j]:=si[j]+ 1
S2: When amessagefrom PjarrivesatPi
ri[j]:=ri[j] +1
S3: WhenPibecomesactive
cpi:=false
S4: WhenCireceives query(VC[1.. n])fromCα
(* VC[1...n]=S[1...n,i] isthei-thcolumnofS*)
ANE i:={Pj: VC[j]>ri[j]};
250
ldi:=cpi∧¬fulfilled i(ARR i∪NEi);
cpi:=(state i=passive);
send reply(ldi,si)toCα
S5: When controller Cαdecides todetect dynamictermination
repeat foreach Ci
sendquery(S[1..n,i])toCi;
(* thei-thcolumnofSissent to Ci*)
receivereply( ldi,si)fromallCi;
∀i∈[1..n]: S[i,.]:=si;
td:=/logicalanddisplay
1≤i≤nldi
untiltd;
claimdynamictermination
Performance
The dynamic termination detection algorithm needs two wave s after dynamic termination has oc-
curred to detect it. Thus, its message complexity is 4 nwhich is lower than the static termination
detection algorithmsince no acknowledgementsare necessa ry. However, messages are composed
ofnmonotonicallyincreasing counters. As waves are sequentia l,query(andreply) messages be-
tweenCαand eachCiare received and processed in their sending order; this FIFO property can
beusedinconjunctionwiththeSinghal-Kshemkalyani’sdif ferentialtechniquetodecreasethesize
of control messages. The detection delay is two waves but is s horter than the delay of the static
terminationalgorithmas acknowledgementsarenotused.
7.8 TerminationDetectionin theAtomicComputationModel
Mattern [12] developed several algorithm for termination d etection in the atomic computation
model.
Assumptions
1. Processes communicate solely by messages. Messages are r eceived correctly after an arbi-
trary but ﬁnite delay. Messages sent over the same communica tion channel may not obey
theFIFO rule.
2. Atime cutis a line crossing all process lines. A time line can be a strai ght vertical line or
a zigzag line, crossing all process lines. Time cut of a distr ibuted computation is a set of
actions characterized by a fact that whenever an action of a p rocess belongs to that set, all
previousactions ofthesameprocessalso belongstotheset.
251
3. We assume that all atomic actions are totally globally ord ered i.e., no two actions occur at
thesametimeinstant.
7.8.1 The Atomic ModelofExecution
In theatomic model of the distributed computation, a process may at any time tak e any message
fromoneofitsincomingcommunicationchannels,immediate lychangeitsinternalstateandatthe
same instant send out zero or more messages. All local action s at a process are performed in zero
time. Thus,considerationofprocessstates iseliminatedw hen performingterminationdetection.
Intheatomicmodel,adistributedcomputationhasterminat edattimeinstant tifatthisinstant
allcommunicationschannelsareempty. Thisisbecauseexec utionofaninternalactionataprocess
isinstantaneous.
Adedicatedprocess, P1,theinitiator,determinesifthedistributedcomputation hasterminated.
The initiator P1starts termination detection by sending control messages d irectly or indirectly to
allotherprocesses. Letusassumethatprocesses P1,...,Pnareorderedinsequenceofthearrivalof
thecontrolmessage.
7.8.2 ANaive Counting Method
To ﬁnd out if there are any messages in transit, an obvious sol ution is to let every process count
the number of basic messages sent and received. We denote the total number of basic messages
Pihas sent at (global) time instant tbysi(t), and the number of messages received by ri(t). The
values of the two local counters are communicated to the init iator upon request. Having directly
or indirectly received these values from all processes, the initiator can accumulate the counters.
Figure 7.9 shows an example, where the time instants at which the processes receive the control
messages and communicate the values of their counters to the initiator are symbolized by striped
dots. Theseareconnected by alinerepresentinga “controlw ave",whichinduces atimecut.
/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1Control Wave
P
P
Pn
3
2
1P
Figure7.9: An exampleshowingacontrolwavewithabackward communication.
If the accumulated values at the initiatorindicate that the sum of all the messages received by
252
allprocessesisthesameasthesumofallmessagessentbyall processes,itmaygiveanimpression
thatall themessagessenthavebeen received,i.e.,there is nomessageintransit.
Unfortunatelybecauseofthetimedelayofthecontrolwave, thissimplemethodisnotcorrect.
The example in Figure 7.9 shows that the counters can become c orrupted by messages “from the
future",crossingfrom therightsideofthecontrolwaveto i tsleft.
The accumulated result indicates that one message was sent a nd one received although the
computation has not terminated. This misleading result is c aused by the fact that the time cut is
inconsistent. A time cut is considered to be inconsistent, i f when the diagonal line representing it
ismadevertical,bycompressingorexpandingthelocaltime scales, amessagecrosses thecontrol
wavebackwards.
However, this naive method for termination detection works if the time cut representing the
controlwaveisconsistent.
Various strategiescan beapplied tocorrect thedeﬁciencie s ofthenaivecountingmethod:
•Ifthetimecutis inconsistent,restart thealgorithmlater .
•Designtechniquesthatwillonlyprovideconsistenttimecu ts.
•Do not lump the count of all messages sent and all messages rec eived. Instead, relate the
messagessentand received betweenpairs ofprocesses.
•Usetechniqueslikefreezing theunderlyingcomputation.
7.8.3 The Four Counter Method
Averysimplesolutionconsistsofcountingtwiceusingthen aivecountingmethodandcomparing
theresults. After theinitiatorhas received theresponsef rom thelast process and accumulated the
values of the counters R* and S* (where R*:=/summationdisplay
∀iri(ti)and S*:=/summationdisplay
∀isi(ti)), it starts a second
controlwave(seeFigure7.10),resultinginvaluesR’*andS ’*. Thesystemisterminated,ifvalues
ofthefourcountersareequal,i.e.,R*=S*=R’*=S’*. Infact ,aslightlystrongerresultexists: If
R* =S’*, then thesystemhad terminatedat theend oftheﬁrst w ave(t2in Figure7.10).
Lett2denote the time instant at which the ﬁrst wave is ﬁnished, and t3(≥t2) denote the
startingtimeofthesecond wave(seeFigure7.10).
1. Local message counters are monotonic, t≤t′impliessi(t)≤si(t′) andri(t)≤ri(t′). This
followsfrom thedeﬁnition.
2. Thetotalnumberofmessagessentorreceivedismonotonic ,thatis,t≤t′impliesS(t)≤S(t′)
andR(t)≤R(t′).
3. R*≤R(t2). Thisfollowsfrom (1)and thefact that allvalues riare collectedbefore t2.
253
t4/0/0/1/1
/0/0/1/1
/0/0/1/1
/0/0/1/1/0/0/1/1
/0/0/1/1
/0/0/1/1
/0/0/1/1/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0
/1/1/1First Wave Second Wave
PPPPn
3
2
1
t1t3t2
Figure7.10: An exampleshowingtwocontrolwaves.
4. S’*≥S(t3). Thisfollowsfrom (1)and thefact that allvalues siare collectedafter t3.
5. Forallt: R(t)≤S(t). Thisis becausethenumberofmessagesin transitD( t):= S(t) -R(t)≥
0.
NowweshowthatifR*=S’*,thenthecomputationhadterminat edattheendoftheﬁrstwave.
R∗=S′∗:R(t2)≥S(t3)
:R(t2)≥S(t2)
:R(t2)= S(t2)
That is,thecomputationterminatedat t2(at theend oftheﬁrst wave).
If the system terminated before the start of the ﬁrst wave, it is trivial that all messages arrived
beforethestartoftheﬁrstwave,andhencethevaluesofthea ccumulatedcounterswillbeidentical.
Therefore, termination is detected by the algorithm in two “ rounds" after it had occurred. Note
that the second wave of an unsuccessful termination test can be used as the ﬁrst wave of the next
termination test. However, a problem with this method is to d ecide when to start the next wave
afteran unsuccessfultest -thereisadangerofan unbounded controlloop.
7.8.4 The Sceptic Algorithm
Note that the values of the counters obtained by the ﬁrst wave of the four counter method can
become corrupted if there is some activity at the right of the wave. To detect such activity, we
useﬂagswhich are initialized by the ﬁrst wave, and set by the process es when they receive (or
alternativelywhentheysend)messages. Thesecondwaveche cksifanyoftheﬂagshavebeenset,
inwhich caseapossiblecorruptionisindicated. A general d rawback isthatat least twowavesare
necessary to detectthetermination.
Itispossibletodeviseseveralvariantsbasedonthe logicalcontroltopology . Iftheinitiatorasks
everyprocessindividually,itcorrespondstoastartopolo gy. Itispossibletoimplementthesceptic
algorithmona ring,however,symmetryisnot easilyachieve d sincedifferentwaves may interfere
whensingleﬂag isusedateachprocess. Spanningtreeisalso aninterestingcontrolconﬁguration.
254
Echo algorithms used as a parallel graph traversal method in duce two phases. The “down" phase
ischaracterizedbythereceiptofaﬁrstcontrolmessagewhi chispropagatedtoallotherneighbors,
and the “up" phase by the receipt of the last of the echoes from its neighboring nodes. These two
phases can beusedas twonecessary wavesofthescepticemeth odforterminationdetection.
7.8.5 The TimeAlgorithm
The time algorithm is a single wave detection algorithm wher e termination can be detected in
one single wave after its occurrence at the expense of increa sed amount of control information or
augmentingeverymessagewithatimestamp. Inthetimealgor ithm,eachprocesshasa localclock
represented by acounterinitializedto0.
A control wave started by the initiator at time i, accumulates the values of the counters and
“synchronizes" the local clocks by setting them to i+1. Thus, the control wave separates “past"
from “future". Ifa processreceives amessagewhose timestamp is greaterthan itsownlocal time,
the process has received a message from the future (i.e., the message crossed the wave from right
to left) and the message has corrupted the counters. After su ch a message has been received, the
current controlwaveisnulliﬁedon arrivalat theprocess.
FormalDescription
Everyprocess Pj(1≤j≤n)hasalocalmessagecounterCOUNT(initializedto0)thatho ldsthe
valuesj-rj, a local discrete CLOCK (initialized to 0), and a variable TM AX (also initialized to
0)thatholdsthelatestsendtimeofall messagesreceivedby Pj.
Thepsuedocodeforprocess Pjisas follows:
(a)When sendingabasicmessageto Pi:
1. COUNT ←COUNT+1;
2. send<CLOCK,...>toPi;
/*time-stampedbasicmessage*/
(b)When receivingabasicmessage <TSTAMP,...>:
3. COUNT ←COUNT-1;
4. TMAX ←max(TSTAMP,TMAX);
5. /*process themessage*/
(c)When receivinga controlmessage <TIME,ACCU, INVALID,INIT >:
6. CLOCK ←max(TIME,CLOCK): /* synchronizethelocalclosk*/
7. ifINIT =j/* completeround? */
8. then ifACCU =0 and notINVALID
9. then"terminated" else"tryagain";
10. endif;
11. elsesend<TIME,ACCU +COUNT,INVALID orTMAX ≥TIME,INIT>
255
toP(j mod n )+1;
12. end_if;
(d)When startingacontrolround:
13. CLOCK ←CLOCK +1;
14. send<CLOCK, COUNT, false,j>toP(j mod n )+1;
A controlmessageconsistsoffourparameters, the(local)t imeatwhichthecontrolroundwas
started, the accumulatorfor themessage counters, a ﬂag whi ch is set when a process has received
a basic message from future (TMAX ≥TIME) and the identiﬁcation of the initiating process. The
ﬁrst componentofa basicmessageisalways thetimestamp.
For each single control wave, any basic message that crosses the wave from the right side of
its induced cut to its left side is detected. Note that differ ent control waves do not interfere; they
merely advance the local clocks further. Once the system is t erminated, the values of the TMAX
variables remain ﬁxed and since forevery process Pj,TMAX j≤maxCLOCK i(1≤i≤n), the
processwiththemaximumclockvaluecandetectglobaltermi nationinoneround. Otherprocesses
mayneed morerounds.
7.8.6 Vector Counters Method
Vectorcountersmethodofterminationdetectionconsistso fcountingmessagesinsuchaway,that
itis notpossibleto misleadtheaccumulated counters.
The conﬁguration used is the ring with nprocesses where every process Pj(1≤j≤n) has
a COUNT vector of length n, where COUNT[ i] (1≤i≤n) denotes the i-th component of the
vector. A circulating control message also consists of a vec tor of length n. For each process Pj,
thelocal variableCOUNT[ i] (i∝\⌉}atio\slash=j) holdsthe numberofbasic messageswhich havebeen sent to
processPisince the last visit of the control message. Likewise, the ne gativevalue of COUNT[ j]
indicates how many messages have been received from any othe r process. At any (global) time
instant, the sum of the k-th components of all nCOUNT vectors including the circulating control
vectorequalsthenumberofmessagescurrentlyontheirwayt oprocessPk,1≤k≤n. Thisprop-
erty ismaintainedinvariantbytheimplementationgivenbe low. Forsimplicity,weassumethatno
process communicates with itself, Pn+1is identical to P1, an operation on a vector is deﬁned by
theoperatingoneach ofitscomponents,and 0*denotes thenu llvector.
Thepsuedocodeforprocess Pjisas follows:
COUNT isinitializedto0*
(a)When sendingabasicmessageto Pi(i∝\⌉}atio\slash=j):
1. COUNT[ i]←COUNT[i]+1;
(b) The following instructions are executed at the end of all local actions triggered by the receipt
ofabasicmessage:
256
2. COUNT[ j]←COUNT[j]-1;
3. ifCOUNT[j] =0 then
4. ifCOUNT = 0*
then"systemterminated"
5. elsesend accumulate <COUNT>toPj+1;
6. COUNT ←0*;
7. end_if;
8. end_if;
(c)When receivinga controlmessage’accumulate <ACCU>’:
9. COUNT←COUNT+ACCU;
10. ifCOUNT [j]≤0then
11. ifCOUNT =0*
then“systemterminated"
12. elsesend accumulate <COUNT>toPj+1;
13. COUNT ←0*;
14. end_if;
15. end_if;
Aninitiator Pistartsthealgorithmbysendingthecontrolmessage’accumu late<0*>’toPi+1. A
mechanism is needed to ensure that every process is visited a t least once by the control message,
i.e., thatthecontrolvectormakes atleast onecompleterou ndafter thestart ofthealgorithm.
Everyprocesscountsthenumberofoutgoingmessagesindivi duallybyincrementingthecounter
indexedbythereceiver’sprocessnumber(line1);thecount erindexedbyitsownnumberisdecre-
mented onreceipt ofamessage(line2). When aprocess receiv es thecirculatingcontrol message,
itaccumulatesthevaluesinthemessagetoitsCOUNT vector( line9). Acheck isthenmade(line
10)todeterminewhetheranybasicmessagesknowntothecont rolmessagehavestillnotarrivedat
Pj. If this is the case (COUNT[ j]>0), the control messageis removed from the ring and regener-
ated at latertime(line 5) when all expected messages have be en received by Pj. For this purpose,
everytimeabasicmessageisreceivedbyaprocess Pj,atestismadetocheckwhetherCOUNT[ j]
isequal to 0 (line3). Notethatlines 4-15are onlyexecutedw hen thecontrolvectoris at Pj. Note
that there is at most one process Pjwith COUNT[ j]>0, and if this is the case at Pj, the control
vector“waits"at process Pj(lines 11to 13are notexecutedand thecontrolvectorremain satPj).
Ifitisnotrequired thatthecontrolmessagewaitsatnodesf oroutstandingbasicmessages,the
algorithmcan besimpliﬁedconsiderablyby removinglines3 -8 aswell as lines10and 15.
257
Performance
The number of control messages exchanged by this algorithm i s bounded by n(m+1),mdenotes
thenumberofbasicmessages,becauseatleastonebasicmess ageisreceivedineveryroundofthe
control message, excluding the ﬁrst round. Therefore, the w orst case communication complexity
forthisalgorithmis O( mn).
7.8.7 AChannel Counting Method
Thechannelcountingmethodisareﬁnementofthevectorcoun termethodinthefollowingway: a
processkeepstrackofthenumberofmessagessenttoeachpro cessandkeepstrack ofthenumber
ofmessagesreceivedfrom each process, usingappropriatec ounters.
Eachprocess Pjhasncounters,C+
j1,...,C+
jn,foroutgoingmessagesand ncounters,C−
1j,...,C−
nj,
for incomingmessages. C−
ijis incremented when Pjreceives a messagefrom process Pi, andC+
jk
isincremented when Pjsendsamessageto Pk. Upondemand,each processinformsthevaluesof
thecountersto theinitiator. Theinitiatorreports termin ationifC−
ij=C+
ijforalli,j.
The method becomes more practical if it is combined with the e cho algorithm, where test
messagesﬂowdownoneveryedgeofthegraphandechoes procee dintheoppositedirection. The
value ofC−
ijis transmitted upwards from process PjtoPiin an echo; whereas, a test message
sent byPitoPjcarries the value of C+
ijwith it. A process receiving a test message from another
process(theactivator),propagatesitinparalleltoanyot herprocesstowhichitsentbasicmessages
whose receipts have not yet been conﬁrmed. If it has already d one this, or if all basic messages
sent out have been conﬁrmed, an echo is immediately sent to th e activator. There are no special
acknowledgement messages. A process Pireceiving the value of C−
ijin an echo, knows that all
messages it sent to Pjhave arrived if the valueof C−
ijequals the value of its own counter C+
ij. An
echo is only propagated towards the activator if an echo has b een received from each subtree and
all channelsinthesubtreesare empty.
FormalDescription
Each process Pjhas thefollowingarrays ofcounters:
1. OUT[i]: countsthenumberofbasicmessagessent to Pi.
2. IN[i]: countsthenumberofbasicmessagesreceivedfrom Pi.
3. REC[i]: records thenumberofitsmessages Pjis awarehavebeen received by Pi.
OUT[i] corresponds to C+
jiand IN[i] toC−
ij. A variable ACTIVATOR is used to hold the in-
dex number of the activating process and a counter DEGREE ind icates how many echoes are still
missing.
Thepsuedocodeforprocess Pjisas follows:
258
{OUT,IN, REC areinitializedto0*and DEGREE to 0.}
(a)When sendingabasicmessageto Pi:
1. OUT[ i]→OUT[i]+1;
(b)When receivingabasicmessagefrom Pi:
2. IN[ i]←IN[i]+1;
(c)On thereceipt ofacontrolmessagetest <m>fromPiwherem≤IN[i]:
3. ifDEGREE>0 orOUT=REC /*already engagedorsubtreeis quiet*/
4. then send echo<IN[i]>toPi;
5. elseACTIVATOR←i; /* traceactivatingprocess */
6. PROPOGATE /* andtest allsubtrees */
7. end_if;
(d)On thereceipt ofacontrol messageecho <m>fromPi:
8. REC[ i]←m;
9. DEGREE ←DEGREE-1; /*decrease missingechoes counter*/
10. ifDEGREE=0 then
/*last echo checks whetherall subtreesare quiet*/
11. PROPAGATE;
12. end_if;
13. ifDEGREE=0 then/*allechoes arrived,everythingquiet*/
14. sendecho<IN[ACTIVATOR] >toPACTIV ATOR ;
15. end_if;
(e)Theprocedure PROPAGATE called at lines6to 11is deﬁned a s follows:
16.procedure PROPAGATE:
17. loopforK =1tondo
18. ifOUT[K]∝\⌉}atio\slash=REC[K]then/* conﬁrmationmissing*/
19. sendtest<OUT[K]>toPk; /* check subtree*/
20. DEGREE ←DEGREE +1;
21. end_if;
22. end_loop ;
23.end_procedure ;
Varibale DEGREE is incremented when a process sends a test me ssage (line 20) and it is decre-
mentedwhen aprocess receivesan ECHO message(line9). IfDE GREE>0,it meansthenodeis
“engaged"andatestmessageisimmediatelyrespondedtowit hanechomessage(line4). Anecho
is also returned for a test message if OUT = REC (line 3), i.e., if process sent no messages at all
259
or if all messages sent out by it have been acknowledged. Line s 10-15 insure that an echo is only
returnedifthearrivalofallbasicmessageshasbeenconﬁrm edandallcomputationsinthesubtree
ﬁnished. Thisisdonebysendingfurthertestmessages(viap rocedurePROPAGATE)afterthelast
echo has arrived (lines 10-12). These test messages visit an y of the subtree root processes which
havenotyetacknowledgedallbasicmessagessenttothem. Th eprocedurePROPAGATEincreases
the value of the variable DEGREE if any processes are visited , thus preventing the generation of
an echo (lines13-15).
To minimize the number of control messages, test messages sh ould not overtake basic mes-
sages. Toachievethis,testmessagescarrywiththemacount ofthenumberofbasicmessagessent
overthe communicationchannel (line19). If a test messages overtakessomebasicmessages (and
itis notovertakenby basicmessages),itscount willbegrea terthan thevalueoftheIN-counterof
thereceiverprocess. Inthiscase,thetestmessageisputon holdanddeliveredlaterwhenallbasic
messageswithlowercount havebeen received (guard m≤IN[i]in point(c)insuresthis).
The initiator starts the termination test only once, as if it had received a test <0>message
fromsomeimaginaryprocess P0. On terminationdetection,insteadofeventuallysendinga n echo
toP0, it reports termination. Test messages only travel along ch annels which were used by basic
messages; processes that did not participate in the distrib uted computation are not visited by test
messages. Foreach test message,an echo iseventuallysent i ntheoppositedirection.
Performance
At least one basic message must have been sent between the sen d of two test messages along the
samechannel. Thisresultsinanupperboundof2 mcontrolmessages,where mdenotesthenumber
ofbasicmessages. Hence,theworstcasecommunicationcomp lexityisO(m). However,Theworst
case should rarely occur, specially, if the termination tes t is started well after the computation
started. In many situations, the number of control messages should be much smaller than m. The
exact number of control messages involved in channel counti ng is difﬁcult to estimate because it
ishighlydependenton communicationpatternsoftheunderl yingcomputation.
7.9 TerminationDetectionin aFaultyDistributedSystem
Analgorithmispresentedthatdetectsterminationindistr ibutedsystemsinwhichprocessesfailin
a fail-stop manner. The algorithm is based on the weight-thr owing method. In such a distributed
system,a computationis said tobe terminatedifand onlyife ach healthyprocess is idleand there
isnobasicmessageintransitwhosedestinationisahealthy process. Thisisindependentoffaulty
processes and undeliverable messages (i.e., whose destina tion is a faulty process). Based on the
weight-throwing scheme, a scheme called ﬂow detecting sche me is developed by Tseng [20]to
deriveafault-tolerantterminationdetectionalgorithm.
260
Assumptions
LetS=P1,P2,...,Pnbethesetofprocessesinthedistributedcomputation. Cijrepresentsthebidi-
rectional channelbetween PiandPj. Communicationnetwork isasynchronous. Communications
channels are reliable, but they are non-FIFO. At any time, an arbitrary number of processes may
fail. However, the network remains connected in the presenc e of faults. Fail-stop model implies
that a failed process stops all activities and can not rejoin the computation in the current session.
Detectionoffaultstakes aﬁniteamountoftime.
7.9.1 FlowDetecting Scheme
Weightsmaybelostbecauseaprocessholdingnon-zeroweigh tmaycrashoramessagedestinedto
a crashed process is carrying a weight. Thus, due to faulty pr ocesses and undeliverable messages
carrying weights, it may not be possible for the leader to acc umulate the total weight of 1 to
declare termination. Thus, in case of a process crash, thelo st weight mustbe calculated. To solve
thisproblem,conceptofﬂow invariantisused.
The Concept of FlowInvariant
DeﬁneH⊆Sthe set of all healthy processes. Deﬁne subsystemHto be part of the system con-
tainingallprocessesin Handcommunicationchannelsconnectingtwoprocessesin H. According
to theconcept ofﬂow invariant, weightchange ofthe subsyst emduring thetimeintervalI, during
which the system is doing computation, is equal to (weights ﬂ owing intoHduring I)−(weights
ﬂowing out of Hduring I). To implement this concept, a variable called net iis assigned to each
processPibelongingto H. This variablerecords the total weight ﬂowing into and out o f the sub-
systemH. Initially,∀ineti=0. Thefollowingﬂow-detectingrulesare deﬁned.
Rule 1: Whenever a process Piwhich belongs to Hreceives a message with weight xfrom
anotherprocess Pjwhichdoes notbelongto H,xisadded to net i.
Rule 2:Whenever a process Piwhich belongs to Hsends a message with weight xto a pro-
cessPjwhich doesnotbelongto H,xissubtractedfrom net i.
Let W Hbe the sum of the weights of all processes in Hand all in-transit messages transmitted
between processes in H.
WH=/summationdisplay
Pi∈H(neti+ 1/n)
where, 1/nistheinitialweightheld byeach process Pi.
LetH=S–Hbe the set of faulty processes. The distribution of weights i s divided into four
261
parts:
WH: weightsofprocessesin H.
WH: weightsofprocessesin H.
WH→H: weightsheld byin-transitmessagesfrom HtoH.
WH→H: weightsheld byin-transitmessagesfrom HtoH.
H
HHWHW
HH
H
HW
W
Figure7.11: Healthyand faulty processsets andmessageﬂow between them.
This is shown in Figure 7.11. WHand WH→Hare lost and can not be used in the termination
detection.
7.9.2 Taking Snapshots
Indistributedsystems,duetothelackofaperfectlysynchr onizedglobalclock,itisnotpossibleto
get a global view of the subsystem Hand hence it may not possibleto determine W H. We obtain
WH,whichisanestimatedvalueofW Hbytakingsnapshotsonthesubsystem Handbyusingthe
aboveequationforW H.
However, note that weights in WH→Hcarried by in-transit messages may join Hand change
WH. To obtain a stable value of W H, channels from HtoHare disconnected before taking
snapshots of H. Once a channel is disconnected, a healthy process can no lon ger send or receive
messagesalongthischannel.
A snapshot on His the collection of net i’s from all processes in H. A snapshot is said to be
consistentifallchannelsfrom HtoHare disconnectedbeforetakingthesnapshot(i.e.,recordi ng
thevaluesof neti).
A snapshot is taken upon a snapshot request by the leader proc ess. The leader uses the in-
formation in a consistent snapshot and equation to compute W Hto calculate WH. Snapshots are
requested when a new faulty process is found or when a new lead er is elected. It should be noted
thatWHisanestimateoftheweightthatisremaininginthesystem. T hisisbecauseprocessescan
failandstopanytimeandtheremaynotexistanypointinreal timeinthecomputationwhere His
thehealthysetofprocesses. Suppose H′isthesetofhealthyprocessesatsomepointintimeinthe
computation after taking the snapshot. If H=H′, thenWH= W H′; otherwise, WH≥WH′must
262
be true, because of the fail stop model of processes. This eli minates the possibility of declaring
termination falsely. Thus, the leader can safely declare te rmination after it has collected WHof
weight.
7.9.3 Description ofthe Algorithm
The algorithm combines the weight-throwing scheme, the ﬂow detecting scheme and a snapshot-
recording scheme. Process Pielects itself the leader if it knows that all Pj,j < i, are faulty. The
leaderprocess takes snapshotsand estimatesremainingwei ghtin thesystem.
Data Structures
Thefollowingdatastructuresareused at processa Pi,i=1, ...,n:
•liistheidoftheleaderknownto Pi. Initiallyl i=1
•wiistheweightcurrently heldby Pi. Initiallyw i=1/n.
•siis the systems total weight assumed by Pi.Piwill try to collect this amount of weight.
Initially,s i=1.
•NET i[1,...,n]isanarrayreal numbers. NET i[j]keepstrackofthetotalweightﬂowinginto
PifromPj. Initially,NET i[j]=0 forallj=1,...,n.
•Fiis a set of faulty processes. A process Pjbelongs to F iif and only if Piknows thatPjis
faultyandPihas disconnecteditschannelto Pj. Initially,F iis anullset.
•SNiisasetofprocesses. When Piinitiatesasnapshot,SN iisasetofprocesses towhich Pi
sends snapshot requests. A process Pjbelonging to SN iis removed from SN iifPireceives
areplyfrom PjorifPiﬁndsPjisfaulty. NonewsnapshotisstartedunlessSN iisanempty
set. Initially,SN iisanullset, whichimpliesno snapshotis inprogress.
•tiis used for temporarily calculating the total remaining wei ght while a snapshot is in
progress.
•ciaboolean, usedfortemporarilycalculatingtheconsistenc yofasnapshot.
Types ofMessages
Thefollowingfourtypesofmessagesareexchanged bythealg orithm:
•B(x) isa basicmessageBwithweight x.
•C(x) isa controlmessagethatis usedto report weight xtotheleaderprocess.
263
•Request(F i) is a snapshot requesting message sent by the leader process Pi. The set F iis to
informthereceivertheset offaulty processesknownto Pi.
•Reply(F j, NET j) is thestate reporting messagesent by Pjin reply to the leader’s Request()
message.
The Algorithm
The algorithm is described for process Pi. The algorithm consists of nine event-drivenatomicac-
tions, each having the format “(guard) →(actions)”. Actions are triggered by sending/receiving
messages,changinglocalstates,ordetectingnewfaultypr ocesses. ThefollowingactionsfromA1
toA5 implementweightthrowingand ﬂow detectingschemes.
A1:(PisendingabasicmessageBto Pj)→
wiispartitionedinto xandysuch thatx>0,y>0andx+y=wi;
B(x) issent toPj;
NET i[j]:=NET i[j]–x;
wi:=y;
A2:(PireceivingabasicmessageB( x) fromPj)→
NET i[j]:=NET i[j]+x;
wi:=w i+x;
passthebasicmessageto theunderlyingsystem;
A3:(Pibecomingidle)→
ifli∝\⌉}atio\slash=ithen
send C(w i)toPli;
NET i[li]:=NET i[li]– w i;
wi:=0;
end if;
A4:(PireceivingacontrolmessageC( x) fromPj)→
NET i[j]:=NET i[j]+x;
wi:=w i+x;
A5:(Piisidle)∧(si=wi)→
announce“termination”;
A1 is activated when Pisends a basic message to another process. A2 is triggered by r eceiv-
ing a basic message. A3 is the weight reporting action. When Piis not the leader, it sends its
weight to the leader process in a control message. A4 describ esPi’s response on receiving a con-
264
trol message. In all actions A1-A4, NET i[1...n] records the weight ﬂowing information. In A5,
leaderPiannounces thetermination.
ThefollowingactionsfromF1 toF4 deal withfaultsand takes napshotsofthesystem.
(* Actionsfordetectingafault whenno snapshotis inprogre ss *)
F1:(PidetectingPjfaulty)∧(Pj∝\⌉}atio\slash∈Fi)∧(SNi=∅)→
disconnectthechannelfrom PitoPj;
Fi:=Fi∪{Pj};
li=min{k|Pk∈S– F i};
if(li=i), then callsnapshot();end if;
(* Actionsonreceivinga snapshotrequest *)
F2:(PireceivingRequest(F j)from P j)→
li:=j;
foreveryP fbelongingto F j−Fi,disconnectthechannel C i,f;
Fi:=Fi∪Fj;
Send aReply(F i,NET i[1...n])toPj;
(* Actionsonreceivinga snapshotresponse*)
F3:(PireceivingReply(F j, NET j[1...n]fromPj)→
if(F i∝\⌉}atio\slash=Fj)∨¬cithen
foreveryP fbelongingto F j−Fi,disconnectthechannel C i,f;
Fi= Fi∪Fj;
ci=false;
else
ti=ti+1/n+/summationtext
Pf∈FjNET j[f];
end if;
SNi= SN i– {Pj};
ifSN i=∅then
ifcithen s i:=tielsecall snapshot();end if;
end if;
(* Actionsfordetectingafault whenasnapshotisin progres s*)
F4:(PidetectingPjfaulty)∧(SNi∝\⌉}atio\slash=∅)→
Disconnectthechannel C i,j;
Fi:=Fi∪{Pj};
ci:=false;
SNi:=SN i–{Pj};
ifSN i=∅thencall snapshot();end if;
265
(* Snapshottakingprocedure*)
Procedure snapshot()(* assumingthecalleris Pi*)
Begin
SNi=S– Fi– {Pi};(* processes thatwillreceiverequests*)
∀Pk∈SNi, senda Request(F i)to P k;
ti:=1/n+/summationdisplay
Pf∈FiNET i[f];
ci:=true;
end;
F1 is triggered when Pidetects for the ﬁrst time that a process Pjis faulty and no snapshot is
currentlyinprogress. Thechannelfrom PitoPjisdisconnected. Then Pielectsahealthyprocess
with least id as its leader. If process Piitself is the leader, then it invokes snapshot procedure to
initiateasnapshot.
In the snapshot() procedure, ﬁrst SN iis set to the set of processes to which Request()’s are
to be sent and sends a Request() to these processes. This prev ents F1 from being executed until
the snapshot ﬁnishes. Assuming that the current healthy pro cess set is S – F iand this snapshot is
consistent,moreweightisadded to t iasPireceives Reply()messagesfrom otherprocesses.
F2describes Pi‘sresponseonreceivingaRequest()messagefrom Pj.Pidisconnectschannels
tofaulty processesand sendsa Reply()messageto Pj, thatsent theRequest() message.
Theinitiatorofthesnapshot Piwaitsforeach PjbelongingtoSN iforeitheraReply()coming
fromPjorPjbeingdetected as faulty.
If a Reply() is received from Pj, F3 is executed. F3 describes Pi’s actions on receiving such a
snapshot response. The consistency of the snapshot is check ed. If the snapshot is still consistent,
tiis updated. Then thebarrier SN iisreduced by one. Ifthebarrier becomes nulland thesnapsho t
isconsistent,s iisupdatedto t i. If thesnapshotisnotconsistent,anothersnapshotisinit iated.
The snapshot initiator Piexecutes F4 when it detects a process Pj∈SNi, is faulty and a
snapshotisinprogress. Anothersnapshotisstartedonlywh enSN i=∅. Suchaprocedureisrepeated
untilaconsistentsnapshotisobtained. Because ofthefail stopmodel ofprocesses, thenumberof
healthyprocessesisanon-increasingfunctionoftimeande ventuallytheprocedurewillterminate.
7.9.4 PerformanceAnalysis
Ifkprocessesbecomefaulty,atmost2 ksnapshotswillbetaken. Each snapshotcostsatmost n–1
Request()s and n–1 Reply()s. Thus,themessageoverheaddueto snapshotsis b oundedby4 kn.
266
IfMbasic messages are issued, processes will be activated by at mostMtimes. So processes
willnotturnidlemorethan M+ntimes. Soatmost M+ncontrolmessagesC( x)willbeissued.
Thus,themessagecomplexityofthealgorithmisO( M+kn+n).
The termination detection delay is bounded by O( k+1). The termination detection delay is
deﬁned as the maximum number of message hops needed, after th e remination has occurred, by
thealgorithmtodetect thetermination.
7.10 BibliographicNotes
The termination detection problem was brought to prominenc e in 1980 by Francez [5] and by
Dijkstra and Scholten [4]. Since then, a large number of term ination detection algorithms hav-
ing different features and for a variety of logical system co nﬁgurations have been developed. A
termination detection algorithm that uses distributed sna pshot is discussed in [8]. A termination
detection algorithm based on weight throwing is discussed i n [9]. A termination detection algo-
rithm based on weight throwing was ﬁrst developed by Mattern [13]. Dijkstra et al. [3] present
a ring-based termination detection algorithm. Topor [19] a dapts this algorithm to a spanning tree
conﬁguration. Chandrasekaran and Venkatesan [2] present a message optimal termination detec-
tion algorithm. Brzezinski et al. [1] deﬁne a very general mo del of the termination problem,
introduce the concept of static and dynamic terminations, a nd develop algorthms to detect static
and dynamic terminations. Mattern developed [12] several a lgorithms for termination detection
for the atomic model of computation. An algorithm for termin ation detection under faulty pro-
cesses is given by Tseng [20]. Mayo and Kearns [14, 15] presen t efﬁcient termination detection
based on roughly synchronized clocks. Other algorithms for termination detction can be found in
[6, 10, 11, 16, 17, 18, 21].
Many termination detection algorithms use a spanning tree c onﬁguration. An efﬁcient dis-
tributedalgorithmto constructaminimumweightspanningt reeis givenin[7].
7.11 ExerciseProblems
1. Haung’s termination detection algorithm could be redesi gned using a counter to avoid the
need of splitting weights. Present an algorithm for termina tion detection that uses counters
insteadofweights.
2. Design a termination detection algorithm that is based on the concept of weight throwing
and istolerantto messagelosses. Assumethatprocessedo no tcrash.
3. Termination detection algorithms assume that an idle pro cess can only be activated on the
reception of a message. Consider a system where an idle proce ss can become active spon-
taneously without receiving a message. Do you think a termin ationdetection algorithm can
bedesignedforsucha system? Givereasons foryouranswer.
267
4. Designanefﬁcientterminationdetectionalgorithmfora systemwherecommunicationdelay
iszero.
5. Design an efﬁcient termination detection algorithm for a system where computation at a
process isinstantaneous(that is,allproceses are always i ntheidlestate.)
268
Bibliography
[1] J. Brzezinski, J.M. Helary and M. Raynal, "Termination d etection in a very general dis-
tributed computing model". in Proc. of International Conf. on Distributed Computing Sys-
tems,Poland,1993,pp. 374-381.
[2] S. Chandrasekaran and S. Venkatesan, “A Message-Optima l Algorithm for Distributed Ter-
minationDetection".J.ofParallel and DistributedComput ing,1990,pp. 245-252.
[3] E.W.Dijikstra,WH.J.FeijenandA.J.M.vanGasteren,“D erivationsofaterminationdetection
algorithm for distributed computations". Information Pro cessing Letters, 16, 5, June 1983,
pp.217-219.
[4] E.W. Dijkstraand C.S. Scholten, “Termination Detectio n for DistributedComputations",In-
formationProcessingLetters, 11,1, 1980,pp.1-4.
[5] N.Francez,“DistributedTermination",ACMTrans.onPr ogrammingLangauges,2(1),1980,
pp.42-55.
[6] N.FrancezandM.Rodeh,“Achievingdistributedtermina tionwithoutfreezing",IEEETrans.
onSoftware Engineering,May1982,pp. 287-292.
[7] R.G. Gallager, P. Humblet, and P. Spira, “A Distributed A lgorithm for Minimum Weight
Spanning Trees", ACM Trans. on Programming Langauges and Sy stems, January 1983, pp.
66-77.
[8] Shing-Tsaan Huang, “Termination detection by using dis tributed snapshots". Information
ProcessingLetters, 32,August1989,pp.113-119.
[9] S.T.Huang,“DetectingTerminationofDistributedComp utationsbyExternalAgents",Proc.
ofthe9th InternationalConf. onDistributedComputingSys tems,1989,pp.79-84.
[10] D.Kumar,“AClassofTerminationDetectionAlgorithms forDistributedComputations",5th
Conf.onFoundationofSoftwareTechnologyandTheoretical ComputerScience,NewDelhi,
Springer-Verlag, LNCS206, 1985,pp.73-100.
[11] T.H.Lai,“TerminationDetectionforDynamicallyDist ributedSystemswithnon-ﬁrst-in-ﬁrst-
outCommunication",J.ofParallelandDistributedComputi ng,December1986,pp.577-599.
269
[12] Friedemann Mattern, “Algorithms for distributed term ination detection". Distributed Com-
puting,Vol 2,1987,pp. 161-175.
[13] F. Mattern, “Global quiescence detection based on cred it distribution and recovery", Infor-
mationProcessing Letters,30, 4, 1989,pp.195-200.
[14] Jean Mayo and Phil Kearns, Distributed Termination Det ection with Roughly Synchronized
Clocks.Inf. Process. Letters, 52(2), 105-108,(1994).
[15] Jean Mayo and Phil Kearns, Efﬁcient Distributed Termin ation Detection with Roughly Syn-
chronizedClocks, Parallel and DistributedComputingand S ystems,1995,305-307.
[16] J.MisraandK.M.Chandy,“TerminationDetectionofDif fusingComputationsinCommuni-
cationSequentialProcesses",ACMTrans.onProgrammingLa nguagesandSystems,January
1982,pp.37-42.
[17] S.P. Rana, “A Distributed Solution of the Distributed T ermination Problem", Information
ProcessingLetters, 17,1, pp.43-46.
[18] Stefan Ronn and Heikki Saikkonen, “Distributed Termin ation Detection with Counters". In-
formationProcessingLetters, 34,5, 1990,pp.223-227.
[19] Rodney W. Topor, “Termination detection for distribut ed computations". Information Pro-
cessingLetters,18, 1,January 1984,pp. 33-36.
[20] Yu-Chee Tseng, “Detecting Termination by Weight-Thro wing in a Faulty Distributed Sys-
tem".J.Parallel Distrib.Computing,25(1),(1995), pp.7- 15.
[21] Yu-Chee Tseng, Cheng-Chung Tan, “On Termination Detec tion Protocols in a Mobile Dis-
tributedComputingEnvironment",Proc. ofICPADS, 1998,pp .156-163.
270
Chapter8
Reasoning with Knowledge
In a distributed system, processes make local decisions bas ed on their limited view of the system
state. Aprocesslearnsofnewfactswhenitreceivesmessage sfromotherprocesses,andcanreason
only with the additional knowledge available to it. This cha pter provides a formal framework in
whichitiseasiertounderstandtheroleofknowledgeinthes ystem,andhowprocessescanreason
withsuch knowledge. Thelogicofknowledge,classicallyte rmed asepistemiclogic ,is theformal
logicalanalysisofreasoningaboutknowledge. Epistemick nowledgeﬁrstreceivedmuchattention
from philosophersinthemid-twentiethcentury.
8.1 TheMuddyChildrenPuzzle
Consider the classical “muddy children” puzzle of Halpern a nd Moses. Imagine there are nchil-
dren who return from playing outdoors, and k,k≥1, of thenchildren have mud on their fore-
heads. Let Ψdenote the fact “at least one child has a muddy forehead.” Ass ume that each child
can see all other children and their foreheads, but not his/h er own forehead. We also assume that
the children are intelligent and truthful, and answer any qu estion asked of them, simultaneously.
Wenowconsidertwoscenarios.
In Scenario A, the father who now shows up on thescene, ﬁrst ma kes a statement announcing
Ψ. We assume that this announcement is heard by everyone, and t hat everyone is aware that
the announcement is being made in their common presence. The father now repeatedly asks the
children, “Do you have mud on your forehead?” The ﬁrst k−1times that the father asks the
question, all the children will say “No” and the kthtime the father asks the question, the children
with mud on their foreheads (henceforth, referred to as the m uddy children) will all say “Yes.”
Thiscan beprovedbyinductionon k.
•Ifk= 1,thesinglemuddychild,seeingnoothermuddychildrenandk nowingtheannounce-
mentof Ψ,willconcludeonhearingthefather’squestionthathehims elfisthemuddychild.
•Ifk= 2, let the two muddy children be m1andm2. The ﬁrst time the question is asked,
neithercananswerintheafﬁrmative. Butwhen m1hearsthenegativeanswerof m2,m1can
271
reason thatm1himself must be muddy because otherwise m2would have answered “Yes”
in the ﬁrst round using the logic for the k= 1case. Hence, m1answers “Yes” the second
time,andm2whouses analogousreasoning, alsoanswers “Yes.”
•Weassumetheinductionhypothesisistruefor k=xmuddychildren.
•Fork=x+ 1muddy children, the proof is as follows. Each muddy child rea sons in the
followingmanner. “Iftherewere xmuddychildren,thentheywouldallhaveanswered‘Yes’
whenthequestionisaskedforthe xthtime. Asthatdidnothappen,theremustbemorethan
xmuddy children, and as I can see only xother muddy children, I myself must also be
muddy. So Iwillanswer‘Yes’when thequestionis askedforth ex+ 1thtime.”
In Scenario B, the father who now shows up on the scene, does notmake the announcement
ofΨ, but repeatedly asks the children, “Do you have mud on your fo rehead?” All the children
repeatedly respond with a “No.” This can be shown by inductio n onq, the number of times the
father asks the question, that “no matter how many muddy chil dren there are, all children answer
‘No’ to the ﬁrst qquestions.” For q= 1, each child answers “No” because he cannot distinguish
the two situations wherein he has and does not have mud on his f orehead. Assumethe hypothesis
is true forq=x. Forq=x+ 1, the situation is unchanged because each child has no furthe r
knowledgetodistinguishthetwosituationswhereinhehasa nddoesnothavemudonhisforehead.
In Scenario A, the father announced Ψwhereas in Scenario B, the father did not announce Ψ,
andtheresponsesofthechildrenwereverydifferent. Thean nouncementof Ψeffectivelymade Ψ
common knowledge among the children, and this enabled the children to reason d ifferently. The
abovepuzzleintroducesthenotionsofknowledge,levelsof knowledge,andcommonknowledgein
asystem. Wenowdeﬁnetheseformallyandconsiderhowsuchlo giccanbeadaptedtocomputing
systems.
8.2 Logicof Knowledge
8.2.1 Knowledge Operators
A deﬁnitionofknowledgerequirestheidentiﬁcationofanap propriatesetof possibleworlds (also
called possible universes or possible conﬁgurations), and a family of possible relations between
those worlds. In a given global state, the possible worlds at a process denote all the global states
that the process believes may be consistent with its local st ate. These states are expressible as
logicalformulas.
Factφcan bea primitivepropositionor a formulausing theusual lo gical connectives(∧,∨,¬
on primitive propositions, the “knowledge operator” K, and the “everyone knows” operator E.
Propositional logic is adequate to cover many interesting s cenarios that occur in distributed exe-
cutions, although ﬁrst-order and higher-order logics can a lso be used. The traditional semantics
of knowledge, using the KandEoperators, were ﬁrst based on timed executions . Intuitively, a
272
processithat knows a fact φis said to have knowledge Ki(φ), and if “every process in the sys-
tem knowsφ”, then the system exhibits knowledge E1(φ)=/logicalandtext
i∈NKi(φ). A knowledge level of
E2(φ)indicates that every process knows E1(φ), i.e.,E2(φ)=E(E1(φ)). Inductively, Ek(φ)=
Ek−1(E1(φ)) fork >1. Thus, a hierarchy of levels of knowledge Ej(φ) (j∈Z∗)gets deﬁned,
whereZ∗is used to denote the set of whole numbers {0,1,2,3,...}. It can be seen that Ek+1(φ)
=:Ek(φ). Each level in the hierarchy represents a different level of group knowledge among the
processes.
In the limiting case, we have the/logicalandtext
j∈Z∗Ej(φ). Informally, this knowledge of a fact φstands
for ”everyone knows that everyone knows that everyone knows ...(inﬁnitely often) the fact φ.”
This limit is informally called common knowledge of φ. Strictly speaking, the epistemic logic
is ﬁnitary and hence does not allow such inﬁnite conjunction s. On a more formal note, common
knowledgeof φ, denoted as C(φ), is deﬁned as theknowledge Xwhich is the greatest ﬁxed point
ofE(φ∧X). Stated differently, common knowledge is a state of knowled geXsatisfying the
equality,X=E(φ∧X). The theory of ﬁxed points is quite intricate. For our purpos es, it
sufﬁces if we informally view the ﬁxed point as implying the i nﬁnite conjunction/logicalandtext
j∈Z∗Eaj(φ).
Commonknowledgeofafactcapturesthenotionofeveryoneag reeingonthefact,andistherefore
an importantnotionindistributedsystems.
8.2.2 The Muddy Children Puzzle Again
indexmuddychildren puzzle We now revisit the muddy childre n puzzle. Assume there are kchil-
drenm1,...mkwithmudon theirforehead. Inthissystem, Ek−1(Ψ)is true, butnot Ek(Ψ).
In Scenario A,we havethefollowing.
•Considerk= 1. Here,thechildwiththemudontheforeheaddoesnotseeanym uddychild,
and henceE(Ψ)isfalse.
•Considerk= 2. Here,E1(Ψ)is true because every child can see at least one muddy child,
andthus∧i∈NKi(Ψ). However,m1canseeonlyonemuddychild m2andthereforeinsome
possibleworld, m1believesthatat m2,Km2(Ψ)maybefalse,i.e.,¬Km1Km2(Ψ),andhence
E2(Ψ)isfalse.
•Generalizingthisreasoningfor kmuddychildren, Ek−1(Ψ)istruebecause Ki1...K ik−1(Ψ)
is true for all instantations of i1,...i k−1. This is so because everyone can see at least k−
1muddy children. However, Ek(Ψ)is false because Ki1...K ik(Ψ)is false when i1is
instantiatedbyanyof m1,...mk. Thisissobecauseeveryonecansee k−1muddychildren,
and onlythe n−kclean children can seethe kmuddychildren.
In Scenario B, the only knowledge available in the system is Ek−1(Ψ), and this is not enough
forthechildrenwithmudontheirforeheadtoeverrespondaf ﬁrmativelytothefather. Inorderthat
the children with mud be able to respond afﬁrmatively, Ek(Ψ)needs to be true in the system so
that thechildren can usetheknowledgeprogressivelystep- by-stepand answercorrectly in the kth
roundofquestioning. Howwas this Ek(Ψ)achievableinScenario A?When thefatherannounced
273
Ψin everyone’s common presence, he provided the system C(Ψ)and henceEk(Ψ). Thus, every
child knew Ψ, and every child knew that every child knew Ψ, and every child knew that every
child knew that every child knew Ψ, and so on. With this Ek(Ψ)being present in the system, the
children could use it progressively round-by-round until i n thekthround, they could answer the
father’s questioncorrectly.
8.2.3 Kripke Structures
A popularapproach todeﬁning semanticsis interms of possibleworlds . Thisapproach isformal-
ized using Kripkestructures .
Deﬁnition 20. (Kripke structure.) A Kripke structure Mfornagents and a set of primitive
propositions Φisa tuple (S,π,K1,...Kn), wherethecomponentsofthistupleareas follows.
1.Sisthesetof allconsistentstates(or possibleworlds),wit h respect toan execution.
2.πis an interpretationthat associates a truth assignment to e ach primitive propositionin Φ,
foreach state s∈S. Thus,∀s∈S,π(s) : Φ→{0,1}.
3.Kiisa binaryrelationon Sgivingallthepairsof statesthatareindistinguishableby Pi.
A Kripkestructureis convenientlyviewedas a graph withlab eled nodes connected by labeled
edges. The set of nodes is the set of states S; the label of node s∈Salso gives the primitive
propositions that are true and false at s. In our simple example, we assume that Φcontains a
singleproposition. Thelogiccanbeextendedtomultiplepr opositionsinastraightforwardmanner.
The edge (s,t)is labeled by the identity of every process Pisuch that (s,t)∈ K i, i.e., every
processPithat cannot distinguish between states sandt. We assume (for simplicity) that edges
are bidirectional and that the Krelations are reﬂexive, i.e., there is a self-loop at each no de. In
Section 8.2.4, the Muddy Children puzzle is used to illustra te the deﬁnitions and concepts of this
section.
The formal deﬁnition of knowledgeis now given in Figure 8.1. Here, “|=” denotes the “satis-
faction”operator.
This deﬁnition of levels of knowledge has a very convenient a nd useful graph-theoretic repre-
sentation,aswe willillustratefortheMuddyChildren puzz le.
Deﬁnition 21. (Reachability ofstates.)
1. A statetis reachablefromstate sinksteps if there exist states s0,s1,...,s ksuch thats0=
s,sk=t, andforall j∈[0,k−1], thereexistssome Pisuchthat (sj,sj+1)∈K i.
2. A statetisreachablefromstate siftis reachablefrom sinksteps,forsome k>1.
Deﬁnition 21 deﬁnes state reachability in the Kripke struct ure. The following deﬁnitions of
knowledgeare expressed in terms of reachability of states w ithin the Kripke structure, and can be
readily seen tomirrortheoriginaldeﬁnitionofknowledge.
274
(M,s)|=φifand onlyif φis truein state sin Kripkestructure M, i.e.,π(s)(φ)=true.
Analogously,we can deﬁne formulaeusing conjunctionsand n egationsoverprimitivepropo-
sitions.
(M,s)|=Ki(φ)ifand onlyif (M,t)|=φ,forall states tsuch that (s,t)∈K i
(M,s)|=E1(φ)ifand onlyif (M,s)|=/logicalandtext
i∈NKi(φ)
(M,s)|=Ek+1(φ)fork≥1ifand onlyif (M,s)|=/logicalandtext
i∈NKi(Ek(φ)),fork≥1
(M,s)|=C(φ)ifand onlyif (M,s)|=/logicalandtext
k∈Z∗Ek(φ)
(Distributed Knowledge D.)(M,s)|=D(φ)if and only if (M,t)|=φfor each state tsuch that
(s,t)∈∩iKi
Figure8.1: Thedeﬁnitionsofregularknowledge.
Theorem 7. (Knowledgeinterms ofreachability ofstates.)
1.(M,s)|=Ek(φ)ifand onlyif (M,t)|=φforeach state tthatisreachablefromstate sink
steps.
2.(M,s)|=C(φ)ifand onlyif (M,t)|=φforeach state tthatisreachablefromstate s.
8.2.4 Muddy Children Puzzle using Kripke Structures
WenowillustratetheKripkestructurefortheMuddyChildre npuzzle. Thedeﬁnitionsandconcepts
oftheprevioussectionwillbeclariﬁed by theexample.
Let us assumethere are n= 3children; and k= 2children havemud on their forehead. Each
of the 8 states can be described by a boolean n-vector, where a clean child is denoted by a 0 and
a child with mud on the forehead is denoted by a 1. Let us furthe r assume that the actual state is
(1,1,0). TheKripkestructure MisillustratedinFigure8.2(a).
In the world (1,1,0), each child can see that there is at least one other child who h as mud on
the forehead, and hence (M,(1,1,0))|=E(ψ). From Theorem 7, it follows that (M,(1,1,0))|=
¬E2(Ψ)because the world (0,0,0)is 2-reachable from (1,1,0)andΨis not true in this world.
Generalizing this observation in terms of Kripke structure s assumingkmuddy children, we have
thatEk−1(Ψ)is true because each world reachable in k−1hops has at least one′′1′′, implying
there is at least one child with a muddy forehead. However, Ek(Ψ)is false because the world
(0,...,0)isreachable in khops.
Scenario A . Fact Ψis already known to all children in the state (1,1,0). Still, when the father
announces Ψin Scenario A, the state of knowledge changes. Before the fat her’s announcement,
Child 1 believes the state (1,0,0)possible, and in that state (1,0,0), child 2 considers the state
(0,0,0)possible. Afterthefather announces Ψ, it becomes common knowledge thatone childhas
275
(1,0,0) (1,1,0)(0,0,1)
(1,0,1)(1,1,1)(0,1,0)(0,1,1)
23 3
3 31 12
2
21 1
(a)(0,0,0)
(1,0,0) (1,1,0)(0,0,1)
(1,0,1)(1,1,1)(0,1,0)(0,1,1)
3
3 31 12
2
21
(b)(0,0,0)
(c)21
3(0,1,1)
(0,1,0)
(1,1,1)
(1,0,1)(0,0,1)
(1,1,0) (1,0,0)(0,0,0)
Figure8.2: Kripkestructurefor n= 3muddychildrenpuzzle. Notethattheactual stateis(1,1,0) .
(a) The entire Kripke structure. (b) After the father announ cesΨ. (c) After the ﬁrst round of
questioningand itsanswers.
a muddy forehead - this change in the group’s state of knowled ge can be graphically depicted by
deleting all the edges connecting state (0,0,0). After the father has announced Ψ, even if one
child has a muddy forehead, he will not consider the state (0,0,0)possible. When the father asks
the question the ﬁrst time and all children respond “No”, the n all edges connecting to all possible
worlds with a single “1” in the state tuple get deleted – this i s because if there were only a single
child with mud on his forehead, he would have answered “yes” i n response to the ﬁrst question.
Thus, it is now common knowledge that there are at least two ch ildren with muddy foreheads.
Generalizing this by induction, when the father askes the qu estion thexthtime and all children
respond “No”, then all edges connecting to all possible worl ds withxor fewer than x“1”s in the
state tuple get deleted – this is because if there were only xchildren with mud on their forehead,
theywouldall haveanswered “yes”in responseto the xthquestion. It is nowcommonknowledge
thatthereareatleast x+ 1childrenwithmudontheirforehead. Ifthereareexactly x+ 1children
with mud on their forehead, those children will all answer “Y es” thex+ 1thtime the question is
asked because they can see exactly xother children with mud on their foreheads. They could not
answer“Yes”earlierbecausetheyconsideredaworldpossib le,inwhichtheydidnothavemudon
theirownforehead.
Graphically, the Kripke structure gets modiﬁed in each iter ation as follows. If in the iteration,
itbecomescommonknowledgethatworld tisimpossible,thenforeachnode sreachablefromthe
actualstater,anyedge (s,t)isdeleted. TheKripkestructureshowninFigure8.2(a)gets modiﬁed
to that shown in part (b) after the father’s announcement. Th at further gets modiﬁed as shown in
part (c), after theﬁrst timethequestionis asked andall the children reply “No”.
Scenario B . In Scenario B, thechildrens’stateofknowledgeneverchan ges and hence theKripke
structure in Figure 8.2(a) neverchanges, no matterhow ofte n the father askes the question. When
thefatherasksthequestiontheﬁrsttime,allchildrenansw er“No”becausetheyeachconsiderboth
worldspossible-oneinwhichtheyhavemudon theirforehead , and oneinwhichtheydonot. As
it is common knowledge even before the father asks the questi on that the answer is going to be
276
“No”,noknowledgeisaddedbythequestionortheresponse. I nductively,thisargumentholdsfor
each round ofquestioning. Hence, theKripkestructureneve rchanges.
8.2.5 Properties ofKnowledge
Inaformalframeworktoreasonaboutknowledge,thepropert iesofknowledgemustalsobespec-
iﬁed formally. Althoughtheseproperties can be speciﬁed wi th different semantics, themostcom-
mon semantics that are adequate for modeling real distribut ed systems are given by the axiom
system that is historically termed as the S5 system. We ﬁrst c haracterize the formulae that are
always true. A formula ψisvalidin Kripke structure M, denotedM|=ψ, if(M,s)|=ψ, for all
s∈S. A formula ψissatisﬁable inMif(M,s)|=ψ, for somes∈S. A formula is validif it is
valid in all structures, and it is satisﬁable if it is satisﬁable in some structure. The ﬁve axioms of
modallogicS5, givenin Figure8.3,are satisﬁedforall form ulas,allstructures, andall processes.
•DistributionAxiom: Kiψ∧Ki(ψ=:φ) =:Kiφ
Eachprocessknowsthelogicalconsequencesofitslocalkno wledge. Theknowledgeoperator
gets distributedovertheimplicationrelation.
•KnowledgeAxiom: Kiψ=:ψ
If a process knows a fact, then the fact is necessarily true. I fKiψis true in a particular state,
thenψis trueinall statesthattheprocess considersas possible.
•PositiveIntrospectionAxiom: Kiψ=:KiKiψ
A process knowswhat itknows.
•NegativeIntrospectionAxiom: ¬Kiψ=:Ki¬Kiψ
A process knowswhat itdoes notknow.
•KnowledgeGeneralizationRule: Foravalidformulaorfact ψ,Kiψ
Ifψis true in all possible worlds, then ψmust be true in all the possible worlds with respect
to any process and any given world. Hence, Kiψmust be true in all possibleworlds. Here, it
is assumed that a process knows all validformulas, which are necessarily true. Note that this
ruleisdifferent fromtherule“ ψ=:Kiψ”.
Figure8.3: TheaxiomsoftheS5 modallogic.
8.3 KnowledgeinSynchronousSystems
indexknowledge!synchronous system Classical problems su ch as the “muddy children” problem
and the “cheating husbands” problem which are widely used to illustrate the theory of knowl-
277
edge have been explained in the synchronous system model. Th e deﬁnitions and the treatment of
knowledgewehaveseen thusfar wasagain forsynchronoussys tems.
Common knowledge captures the notion of agreement in distri buted systems. What are the
variouswaysby whichcommonknowledgecan beattainedinasy nchronoussystem?
•By initializingalltheprocesses withcommonknowledgeoft hefact.
•By broadcasting the fact to every process in a round of commun ication, and having all the
processesknowthatthefactisbeingbroadcast. Eachproces scanbeginsupportingcommon
knowledgefrom thenextround. This is themechanismthatwas usedby thefather when he
announced Ψin theMuddyChildren puzzlein Scenario A.
8.4 KnowledgeinAsynchronousSystems
Here, weadapt thedeﬁnitionsofknowledgegivenin Figure8. 1toasynchronoussystems.
8.4.1 Logicand Deﬁnitions
In the system model, the possible worlds are the consistent c uts of the set of possible executions
in an asynchronous system. Let (a,c)denote a cutcinasynchronous execution a. As each cut
also identiﬁesa globalstate, (a,c)is alsoused to denotethestateofthesystemafter (a,c).(a,c)i
denotestheprojectionof conprocessi,andisalsousedtodenotethestateofprocess iafter(a,c).
Two cutscandc′are indistinguishableby process i, denoted (a,c)∼i(a′,c′), if and onlyif (a,c)i
=(a′,c′)i. The semantics of knowledge are based on asynchronous executions , instead of timed
executions.
The modal operator Ki(φ)means “φis true in all possible consistent global states (cuts) that
includeprocess i’slocalstate”. Observethat Ki(φ)isimplicitlyquantiﬁedoverallconsistentstates
over all runs, that include i’s local state. Similar meanings hold for E(φ)andEk(φ), fork >1.
We also deﬁne E0(φ)to beφfor simplicity. Formal deﬁnitions of knowledge for asynchr onous
distributedsystemsaregivenin Figure8.4.
As knowledge can be known by a process only in a speciﬁc local s tate, we also say that “ i
knowsφin statesx
i”, denotedsx
i|=φ, as a shorthand for (∀(a,c))((a,c)i=sx
i= : (a,c)|=φ).
Analogously,wedeﬁne sx
i|=Ki(φ)tobe(∀(a,c))((a,c)i=sx
i=: (a,c)|=Ki(φ)). Recall that φ
can beoftheform Ek(ψ), foranyfact ψ.
Deﬁnition23. (Learning.) Processilearnsφinstatesx
iofexecution aifiknowsφinsx
iand,for
allstatessy
iin execution asuchthaty<x,idoes notknow φ.
We also say that a process attains φ(in somestate) if the process learns φin the present or an
earlierstate. A fact φisattainedin anexecution aif∃c,(a,c)|=φ. Observethataprocesscannot
attain a fact before the fact is attained in an execution. Thi s corresponds to the intuitionthat even
though a fact becomes true in an execution, information may n eed to be propagated for a process
tolearn thefact.
278
Deﬁnition 22. (Knowledgeinasynchronous systemsdeﬁned us ing consistent cuts)
(a,c)|=φifand onlyif φis trueincut cofasynchronousexecution a.
(a,c)|=Ki(φ)if andonlyif∀(a′,c′),((a′,c′)∼i(a,c) =:(a′,c′)|=φ)
(a,c)|=E0(φ)ifandonlyif (a,c)|=φ
(a,c)|=E1(φ)ifandonlyif (a,c)|=/logicalandtext
i∈NKi(φ)
(a,c)|=Ek+1(φ)fork≥1ifandonlyif (a,c)|=/logicalandtext
i∈NKi(Ek(φ)),fork≥1
(a,c)|=C(φ)ifandonlyif (a,c)|=thegreatestﬁxedpointknowledge XsatisfyingX=E(X∧φ).
C(φ)implies∧k∈Z∗Ek(φ).
Figure8.4: Thedeﬁnitionofknowledgefor asynchronousdis tributedsystems.
Deﬁnition 24. (Local fact.) A factφislocaltoprocessiin systemAifA|= (φ=:Kiφ)
Afactthatisnotlocalisa globalfact . Thestateofaprocess,thelocalclockvalueofaprocess,
andthelocalcomponentofthetimestampofaneventataproce ssareexamplesoflocalfacts. The
globalstateofa systemand thetimestampofacutare example sofglobalfacts.
8.4.2 Agreement inAsynchronous Systems
Weconsiderthefollowingproblem: “Twoprocessesthatcomm unicatebyasynchronousmessage-
passing need to agree on a binary value. Does there exist a pro tocol that they can follow to reach
consensus?” Reaching consensus among a group of processes i mplies the attainment of common
knowledgeamongthatgroupofprocesses. Weﬁrstconsideras ystemwherecommunicationisnot
reliable, implyingthat messagesmaybelostin transit.
Theorem8. Theredoesnotexistanyprotocolfortwoprocessestoreachc ommonknowledgeabout
a binaryvaluein anasynchronousmessage-passingsystemwi th unreliablecommunication.
Aninformalargumentisasfollows. Withoutlossofgenerali ty,weassumethatthefactistrueat
Pi,andtheprocesses PiandPjfollowaprotocolinwhichtheysendmessagestoeachotherse rially.
Thus,Piﬁrst sends a messageMto Pjinformingit ofthefact, and because communicationis not
reliable,PineedsanacknowledgementACK1backtoknowthat Pjhasreceivedthemessage. But
then,Pjdoes not know whether Pihas received the acknowledgement ACK1. Hence, it does not
knowwhetherorwhen Piwillbeginsupportingthecommonknowledge,andhenceitits elfcannot
begin supporting the commonknowledge. Therefore, Pineeds to send back an acknowledgement
ACK2toPjtoacknowledgethereceiptofACK1. However, Pinowneedsanacknowledgementof
thedeliveryofACK2,similartoitsneedforanacknowledgem entforM.Thisisanon-terminating
argument,and hencethisprotocolwillnotwork toachieveco mmonknowledge.
279
More generally, let there exist a protocol with kmessages being sent between PiandPj, and
letthisbethe minimalprotocolinthesenseofusingtheminimumnumberofmessages . Then,the
senderofthelastmessageassertscommonknowledgeofthefa ctevenifitdoesnotknowwhether
themessagewasdelivered. Hence,the kthmessageisredundant,whichimpliesthereisaprotocol
withk−1messagestoattaincommonknowledge. Thiscontradictsthea ssumptionthattheminimal
protocol requires kmessages. Hence, such a protocol does not exist. Using simil arreasoning, we
alsohavethefollowingsimilarimpossibilityresult forre liableasynchronoussystems.
Theorem 9. There does not exist any protocol for two processes to reach c ommon knowledge
about a binary value in a reliable asynchronous message-pas singsystem without an upper bound
on messagetransmissiontimes.
Even though the upper bound on message transmission time is g uaranteed, a process does not
know when to support the common knowledge and hence requires an acknowledgement, and the
senderofthatacknowledgementwillitselfrequirean ackno wledgement,andso on.
8.4.3 Variants ofCommonKnowledge
Common knowledge captures the notion of agreement among the processes, and hence attain-
ing common knowledge is a fundamental problem in distribute d systems. Common knowledge
requires the notion of simultaneity of action across the pro cesses. The instantaneous simultane-
ity attained by tightly synchronized clocks has some margin of error. Given the impossibility of
achieving simultaneity, and hence of attaining common know ledge in reliable asynchronous sys-
tems, what hope is there? Fortunately, there are weaker vers ions of common knowledge that can
besubstitutedforregularcommonknowledge.
Epsiloncommonknowledge. This form of common knowledge corresponds to the processes
reaching agreement within ǫtime units. This deﬁnition implicitly assumes timed runs as
it is not possible to exactly deﬁne time units in an asynchron ous system. This common
knowledge is deﬁned using Eǫwhich denotes “everyone knows within a time duration of ǫ
units”. Epsilon common knowledge Cǫ(φ)is the greatest ﬁxed point of X=Eǫ(φ∧X),
whereXisthefree variableinthegreatest ﬁxed-pointoperator.
Eventual commonknowledge. This form of common knowledge corresponds to the processes
reachingagreementatsome(notnecessarilyconsistent)gl obalstateintheexecution. E⋄de-
notes“everyonewilleventuallyknow(atsomepointintheir execution)”. Eventualcommon
knowledgeC⋄(φ)is thegreatest ﬁxed pointof X=E⋄(φ∧X).
Timestamped commonknowledge. This form of common knowledge corresponds to the pro-
cesses reaching agreement at local states having the same lo cal clock value. It is applicable
to asynchronous systems. Let KT
i(φ)denote the fact that process iknowsφat local clock
valueT. ThenET(φ)=∧iKT
i(φ)andtimestampedcommonknowledge CT(φ)isthegreat-
est ﬁxed point of X=ET(φ∧X). If it is common knowledge that all clocks are always
280
perfectlysynchronized,thentimestampedcommonknowledg eisequivalenttoregularcom-
monknowledge.
Concurrent commonknowledge. Thisformofcommonknowledgecorrespondstotheprocesses
reaching agreement at local states that belong to a consiste ntcut. When a process Piattains
concurrentcommonknowledgeofafact φ,italsoknowsthateach otherprocess Pjhasalso
attained the same concurrent common knowledge in its local s tate which is consistent with
Pi’slocal state.
Thisformofknowledgeisapplicabletoasynchronoussystem sandisthemostpopularform
of common knowledge in real systems. Hence, we deﬁne it in det ail below, and give two
protocolsforattainingsuchcommonknowledge. Here, wenot ethatthisvariantofcommon
knowledgeis incomparablewith Cǫ,C⋄, andCT.
8.4.4 Concurrent CommonKnowledge
Concurrent commonknowledgeisbased onthenotionofthevar iousprocessesattainingthecom-
monknowledgeonaconsistentcut. The possiblyoperator1Piinconjunctionwiththe Kioperator
is used to formally deﬁne such knowlege. Pi(φ)means “φis true in someconsistent state in the
sameasynchronousrun,thatincludesprocess i’slocalstate”. EC(φ)isdeﬁnedas/logicalandtext
i∈NKi(Pi(φ)).
EC(φ)meansthateveryprocessatthe(given)cutknowsonlythat φistrueinsomecutthatiscon-
sistentwithitsownlocalstate. Byinduction,similarmean ingscanbeassignedforhigherlevelsof
knowledge. Theformaldeﬁnitionoflevelsofconcurrentkno wledgeECisasshowninFigure8.5.
(a,c)|=φifand onlyif φis truein cut cofexecution a.
(a,c)|=Ki(φ)ifand onlyif∀(a′,c′),((a′,c′)∼i(a,c) =:(a′,c′)|=φ)
(a,c)|=Pi(φ)ifand onlyif∃(a,c′),((a,c′)∼i(a,c)∧(a,c′)|=φ)
(a,c)|=EC0(φ)ifandonlyif (a,c)|=φ
(a,c)|=EC1(φ)ifandonlyif (a,c)|=/logicalandtext
i∈NKiPi(φ)
(a,c)|=ECk+1(φ)fork≥1ifand onlyif (a,c)|=/logicalandtext
i∈NKiPi(ECk(φ)),fork≥1
(a,c)|=CC(φ)if and only if (a,c)|=the greatest ﬁxed point knowledge XsatisfyingX=
EC(X∧φ).
CC(φ)implies∧k∈Z∗(EC)k(φ).
Figure8.5: Thedeﬁnitionofconcurrent knowledgeforasync hronousdistributedsystems.
1The notation Pifor this operator is not to be confused with Piused to denote process i. Also, the semantics of
thisoperatorisdifferentfromthe Possibly modalitydeﬁnedonglobalpredicates.
281
Theconcurrentknowledgedeﬁnitionsareweakerthanthecor respondingknowledgedeﬁnitions
in Deﬁnition 22 (Figure 8.4). But for a local,stablefact, and assuming other processes learn the
fact viamessagechains, itcan beseen thatthetwodeﬁnition sbecomeequivalent.
Ifconcurrentcommonknowledge CC(φ)isattainedataconsistentcut,then(informallyspeak-
ing) each process at its local cut state knows that “in some st ate consistent with its own local cut
state,φistrueandthatallotherprocessknowallthissameknowledge(describedwi thinquotes)”.
Concurrent commonknowledgeisanecessary andsufﬁcientco nditionforperformingconcur-
rent actions in asynchronous distributed systems, analogo us to simultaneousactions and common
knowledge in synchronous systems. The form of knowledge und erlying many existing protocols
involves processes reaching agreement about some property of a consistent global state, deﬁned
usinglogical time andcausality, and can be easily understood in terms of concurrent common
knowledge.
Global snapshot algorithms can be run concurrently with the underlying computation and can
beusedtoachieveconcurrentcommonknowledge. Snapshotal gorithmstypicallyrequire |L|mes-
sages anddtime steps, where dis the diameter of the network. More message-efﬁcient snaps hot
algorithms that need only O(|N|)messages use certain forms of computation inhibition – loca l
or global inhibition, and send inhibition and/or receive in hibition based on network characteris-
tics such as availability of FIFO channels, to reduce the num ber of messages to take a snapshot.
Nevertheless, each snapshot requires at least O(|N|)messages and possibly inhibitory delay as
overhead.
Speciﬁcally, concurrent common knowledge can be attained i n an asynchronous system, as
shown by the protocols in Figure 8.6– 8.9. In these protocols , each process Pimust attainCC(φ)
onaconsistentcut,(i)bylearning φ,and(ii)bylearningthateachotherprocess Pjwillalsoattain
that exact state of knowledge in a local state that is consist ent withPi’s local state in which Pi
attainsCC(φ).
Snapshot-based algorithm. Protocol 1 (Figure 8.6) is a form of a global snapshot algorit hm,
where each process knows that all processes are participati ng in the same algorithm. It can
also be viewed as a variant of the distributed asynchronous b readth-ﬁrst search algorithm
(seeninModule2). Observethatthesetofstatesdenotedas cutstateateachprocess,andat
whichtheprocesses beginsupporting CC(φ),indeedform aconsistentsetofstates.
Complexity: Protocol 1 uses 2lmessages and a time complexity equal to the diameter of
thenetwork.
Three-phase send-inhibitory algorithm. Protocol2(Figure8.7)hasthreephasesandusessend-
inhibition. It also assumes that the predicate φthat becomes true when the protocol is initi-
ated remains true for the duration of the protocol. Observe t hat send inhibition is necessary
toensurethatthesetof cutstates atwhichtheprocessesbeginsupporting CC(φ)areconsis-
tent. A process Pidoesnotsend anymessagebetweenreceiving the PREPARE and sending
theCUT(when it reaches its cut state), and receiving the RESUME control messages, and
anymessagesentby Piafterreceivingthe RESUME messagewillnecessarilybereceivedby
282
any other process PjafterPjhas reached its cut state. Hence the cut states are guaranteed
tobeconsistentwitheach other.
Complexity: Protocol 2 uses 3(n−1)messages and a time complexity of three message
hops. However,it issend-inhibitoryandrequires FIFO chan nels.
The three-phase send-inhibitory tree algorithm. Protocol3(Figure8.8)isavariantofProtocol
2. It protocol uses a (Broadcast - Convergecast - Broadcast) sequence on a spanning tree
(ST)on thenetworktopologyto record theglobalstatealong aconsistentcut.
Complexity: This message-send inhibitoryalgorithm requires a total of 3(n−1)messages
and worksina systemwithnon-FIFO channels.
Inhibitory Ring algorithm: Protocol 4 (Figure 8.9) assumes that a logical ring is superi mposed
onthenetworktopology.
Complexity. This message-send inhibitoryalgorithm requires 2nmessages, and works in a
systemwithFIFO channels. Thetimecomplexityis 2nhops.
Thereforetheprocess can infer (EC)i(φ)(foranyi)isattainedby processes alongaconsis-
tentcut includingthecurrent localstate.
Protocol 1 (Snapshot-based algorithm).
1. At sometimewhen theinitiator Iknowsφ:
•itsendsamarker MARKER (I,φ,CCK )toeachneighbour Pj,andatomicallyreaches
itscutstate.
2. When a process Pireceives for the ﬁrst time, a message MARKER (I,φ,CCK )from a
processPj:
•processPiforwards the message to all of its neighbours except Pj, and atomically
reaches its cut state.
Figure 8.6: Snapshot-based protocol to attain concurrent c ommon knowledge. A process attains
CC(φ)whenit reaches its cut state.
Algorithmssuch as the abovevariants of the classical snaps hot algorithm require at least O(l)
messages, or O(n)messages and varying degrees of message inhibition eachtime there is a need
toachieveconcurrentknowledgeofsomefact.
8.5 KnowledgeTransfer
Formalizinghowprocesseslearnfactsisdonebyrelatingkn owledgegaintomessagechainsinthe
execution.
283
Protocol 2 (Three-phase send-inhibitory algorithm).
1. At sometimewhen theinitiator Iknowsφ:
•itsendsamarker PREPARE (I,φ,CCK )toeach process Pj.
2. When a(non-initiator)process receivesa marker PREPARE (I,φ,CCK ):
•itbeginssend-inhibitionfornon-protocolevents.
•sendsamarker CUT(I,φ,CCK )to theinitiator I.
•itreaches its cutstateat which itattains CC(φ).
3. When theinitiator Ireceivesamarker CUT(I,φ,CCK )from each otherprocess:
•theinitiatorreaches its cut state
•sendsamarker RESUME (I,φ,CCK )to allotherprocesses.
4. When a(non-initiator)process receivesa marker RESUME (I,φ,CCK ):
•itresumessendingitsnonprotocolmessageswhichhad been i nhibitedin step2.
Figure 8.7: Three-phase send-inhibitory protocol to attai n concurrent common knowledge. A
process attains CC(φ)when itreaches its cut state.
Protocol 3 (Three-phase send-inhibitory tree algorithm).
PhaseI (broadcast): The root initiates PREPARE control messages down the ST; when a process
receives such a message, it inhibits computation message se nds and propagates the received
controlmessagedowntheST.
PhaseII (convergecast): A leaf node initiates this phase after it receives the PREPARE control
messagebroadcastinphaseI.Theleafreachesandrecordsit scutstate,andsendsa CUTcon-
trol message up the ST. An intermediate (and the root) node re aches and records its cut state
when it receives such a CUTcontrol message from each of its children, and then propagat es
thecontrolmessageup theST.
PhaseIII(broadcast): The root initiates a broadcast of a RESUME control message down the ST
afterPhaseIIterminates. Onreceivingsucha RESUME message,aprocessresumesinhibited
computationmessagesendactivityand propagatesthecontr olmessagedowntheST.
Figure 8.8: Three-phase send-inhibitorytree protocol to a ttain concurrent common knowledge. A
process attains CC(φ)when itreaches its cut state.
284
Protocol 4 (Send-inhibitory ring algorithm).
1. Onceafact φaboutthesystemstateisknowntosomeprocess,theprocessa tomicallyreaches
itscut stateand begins supporting C(φ), beginssend inhibition,and sends a control message
CUT(φ)alongthering.
2. ThisCUT(φ)message announces φ. When a process receives the CUT(φ)message, it
reaches its cut state and begins supporting C(φ), begins send inhibition, and forwards the
messagealongthering.
3. When the initiator gets back CUT(φ), it stops send inhibition, and forwards a RESUME
messagealongthering.
4. When a process receives the RESUME message, it stops send-inhibition, and forwards the
RESUME message along the ring. The protocol terminates when the ini tiator gets back the
RESUME it initiated.
Figure 8.9: Send-inhibitory ring protocol to attain concur rent common knowledge. A process
attainsCC(φ)whenit reaches its cut state.
Deﬁnition 25. (Message chain.) Amessage chain in an execution is a sequence of messages
∝a\}⌊ra⌋k⌉tl⌉{tmik,mik−1,mik−2,...,mi1∝a\}⌊ra⌋k⌉tri}htsuch that for all 0<j≤k,mijis sent by process ijto processij−1
andreceive (mij)≺send(mij−1). A message chain identiﬁes the corresponding process chain
∝a\}⌊ra⌋k⌉tl⌉{ti0,i1,...,i k−2,ik−1,ik∝a\}⌊ra⌋k⌉tri}ht.
The above deﬁnition adopts the convention that a process cha in lists the processes in an order
which is the reverse of the order in which they send the messag es in the corresponding message
chain. Furthermore, a process chain includes the recipient of the last message sent in the corre-
sponding message chain, and this is the ﬁrst process in the pr ocess chain. A message chain with
kmessages thus identiﬁes a process chain with k+ 1processes. Knowledge can be transferred
among processes only if a process chain exists among those pr ocesses. Ifφis false in an execu-
tion and later P1knows thatP2knows that...P kknowsφ, then there must exist a process chain
∝a\}⌊ra⌋k⌉tl⌉{ti1,i2,...i k∝a\}⌊ra⌋k⌉tri}ht.
In the system model used thus far, (a,c)idenotes the projection of con process i, and is
also used to denote the state of process iafter(a,c). Two cutscandc′are indistinguishable by
processi, denoted (a,c)∼i(a′,c′), if and only if (a,c)i=(a′,c′)i. In theinterleaving model of
the distributed system execution, wherein all the events at the different processes are interleaved
to form a global total order, the indistinguishability of di fferent views can be expressed using
isomorphism of executions . In the following explanation, we assume x,y,zdenote executions or
execution preﬁxes in the interleaving model. We let xpdenote the projection of execution xon
processp.
indexexecutionisomorphism
Deﬁnition 26. (Isomorphismofexecutions.)
285
1. Forallexecutions xandy,relationx[p]yis deﬁnedto betrueifand onlyif xp=yp.
2. Forallexecutions xandyandaprocessgroup G,relationx[G]yisdeﬁnedtobetrueifand
onlyif, forall p∈G,xp=yp.
3. LetGibeprocessgroup iandletk>1. Then,x[G0,G1,...,G k]zifandonlyif x[G0,G1,...,G k−1]y
andy[Gk]z.
Two executions are isomorphic with respect to a group of proc esses if and only if none of the
processes in the group can distinguishbetween the two execu tions. For Deﬁnition 26.1 and 26.2,
drawing an analogy with Kripke structures (Deﬁnition 21), t he edge connecting two state nodes
(whichwouldcorrespondtothestatesafterexecutions xandy)arelabeledbyalltheprocessesthat
cannotdistinguishbetweenthetwostates. Thus,forall isuchthat (x,y)∈Ki,theedgeconnecting
(x,y)is labeled with Pi. For Deﬁnition 26(3), analogously in Kripke structures (De ﬁnition 21),
the set of states reachable from xinksteps, denoted z, can be expressed in terms of the set of
statesreachable from xink−1steps,denoted y,andtheset ofstates zreachablefrom statesin y
inonestep. Thedeﬁnitionofisomorphismofexecutionsallo wsanalternatewayofreasoningwith
local views of processes, tailored more for asynchronous di stributed computing systems. When a
message is received in an execution, the set of executions th at are isomorphic can only decrease
because now executions that do not contain the correspondin g send event can be ruled out. The
knowledgeoperatorin theinterleavingmodelis deﬁned as fo llows.
Deﬁnition27. (Knowledgeoperatorintheinterleavingmode l.)pknowsφatexecution xifand
onlyif, forallexecutions ysuchthatx[p]y,φistrueaty.
The following theorem formally shows in the interleaving mo del that knowledge is gained
sequentially.
Theorem 10. (Knowledgetransfer.) Forprocessgroups G1,...,Gk,and executions xandy,
(KG1KG2...K Gk(φ)atxandx[G1,...G k]y)=:KGk(φ)aty.
The theorem can be shown to be true by inductionon k, along the lines of the following argu-
ment. Fork= 1,theresultisstraightforward. Assumetheinductionhypot hesisfork−1. Fork,we
caninferthereexistssome zsuchthatx[G1,...G k−1]zandz[Gk]y. FromKG1KG2...K Gk−1[KGk(φ)]
atx,andfromtheinductionhypothesis,itcanbeinferredthat KGk−1[KGk(φ)]atz. Hence,KGk(φ)
atz. Asz[Gk]y,KGk(φ)aty.
In terms of Kripke structures, Theorem 10 states that there i s a path from statenode x=s0to
statenodey=sk, viastatenodes s1,s2,...,sk−1, such thatthe kedges (si,si+1),0≤i≤k−1,
on thepath arelabeled by Gi+1.
Theorem 11 formalizes the observation that there must exist a message chain∝a\}⌊ra⌋k⌉tl⌉{tmik,mik−1,
mik−2,...,mi1∝a\}⌊ra⌋k⌉tri}htinorderthatafact φthatbecomesknownto Pkafterexecutionpreﬁx xofy,leads
tothestateofknowledge K1K2...K k(φ)afterexecution y.
Theorem 11. (Knowledge gain theorem.) For processes P1,...,Pk, and executions xandy,
wherexisa preﬁxof y,let
286
•¬Kk(φ)atxandK1K2...K k(φ)aty.
Then thereisa processchain ∝a\}⌊ra⌋k⌉tl⌉{ti1,...i k−1,ik∝a\}⌊ra⌋k⌉tri}htin(x,y).
8.6 KnowledgeandClocks
Weassumeallfactsaretimestamped(physicallyorlogicall y)bytheoftheirbecomingtrueandby
the process at which they became true. A full-informationprotocol (FIP) is a protocol in which a
processpiggybacksalltheknowledgeithasonoutgoingmess ages,andinwhichaprocessaddsto
itsknowledgealltheknowledgethatispiggybackedon anyme ssageitreceives. Thus,knowledge
always increases when a message is received. The amount of kn owledge would keep increas-
ing as the execution proceeds, which may not make FIP protoco ls a practical way to distributed
knowledge.
Factscanalwaysbeappropriatelyencodedasintegers. Mono tonicfactsarefactsaboutaprop-
erty that keep increasing monotonically (e.g., the latest t ime of taking a checkpoint at a process).
By using a mapping between logical clocks and monotonic fact s, information about the mono-
tonic facts can be communicated between processes using log ical clock values piggybacked on
messages. Being monotonic,all earlierfacts can beinferre d fromtheﬁxed amountofinformation
that is maintained and piggybacked on messages. As a speciﬁc example, the vector clock Clki[j]
indicates the local time at each process Pj, and implicitly that all lower clock values at Pjhave
occurred. With appropriate encoding, facts about a monoton ic property can be represented using
vectorclocks.
Matrix clocks are an extensionof theidea behind vectorcloc ks and contain informationabout
other processes’ views of the system execution. A matrix clo ck is an array of size n×n. Matrix
clocks are used to design distributed database protocols, f ault-tolerant protocols, and protocols to
discard obsolete information in distributed databases. Th ey are also used to solve the distributed
dictionaryand distributedlogproblems. Therulesthat pro cessPiexecutesatomicallytomaintain
itsmatrixclock usingthe matrixclockprotocol are givenin Figure8.10.
Vector clocks can be thought of as imparting knowledge to a pr ocess: when Clk[i] =xat
processh,processhknowsthatprocess ihas executedat least xevents. Matrixclocksimpartone
more level of knowledge: when Clk[i,j] =xat processh, processhknows that process iknows
thatprocess jhas executedatleast xevents.
1. Thejthrow of the matrix clock at process Pi, indicated by Clki[j,·], gives the latest vector
clock valueof Pj’sclock, as knownto Pi.
2. Thejthcolumn of the matrix clock at process Pi, indicated by Clki[·,j], gives the latest
scalarclock valuesofprocess Pj, i.e.,Clk[j,j], asknowntoeach process inthesystem.
For a vector clock Clki, thejthentryClki[j]represents the knowledge KiKj(φj), whereφj
is the local component of process Pj’s clock. For a matrix clock Clki, the[j,k]thentryClki[j,k]
287
(local variables)
array ofint Clki[1...n,1...n]
MC0.Clki[j,k]is initializedto0 forall jandk
MC1.Before process iexecutesan internal event,it doesthefollowing.
Clki[i,i]=Clki[i,i] + 1
MC2.Before process iexecutesa sendevent,itdoes thefollowing: Clki[i,i]=Clki[i,i] + 1
Send messagetimestampedby Clki.
MC3.Whenprocess ireceivesamessagewithtimestamp Tfromprocess j,itdoesthefollowing.
(k∈N)Clkj[i,k]=max(Clki[i,k],T[j,k]);
(l∈N\{i}) (k∈N),Clki[l,k]=max(Clki[l,k],T[l,k]);
Clki[i,i]=Clki[i,i] + 1;
deliverthemessage.
Figure8.10: Matrixclocks.
represents the knowledge KiKjKk(φk), whereφkis the local component Clkk[k,k]of process
Pk’sclock.
Vector and matrix clocks are convenient because they are upd ated without sending any addi-
tional messages; knowledge is imparted via the inhibition-free ambient message-passing that (i)
eliminates protocol messages by using piggybacking, and (ii) diffusesthe latest knowledge using
onlymessages,wheneversent, bytheunderlyingexecution.
Observethatthevectorclockataprocessprovidesknowledg eE0(φ),whereφisapropertyof
theglobalstate(namely,thelocalscalarclockvalueofeac h process). Analogously,observethata
matrixclock at aprocess Pjgivestheknowledge
Kj(E1(φ)) =Kj(∧i∈NKi(φ)),
whereφisaproperty oftheglobalstate, namely,thelocal scalarcl ock valueofeach process.
8.7 ChapterSummary
Processes in a distributed system can reason only with the pa rtial view they have of the computa-
tion. Theknowledgeataprocessisbasedonthevaluesofitsv ariablesandanymessagesreceived
by the process. The chapter ﬁrst discussed the role of knowle dge by using the Muddy Children
puzzle of Halpern and Moses. To formalizethe role ofknowled ge, several knowledgeoperators –
E(every process knows), K(the process knows), and C(common knowledge) were introduced,
Kripke structures were introduced to formalize these seman ticvs in terms of possibleworlds . The
MuddyChildrenpuzzlewas recast in termsofthemoreformal K ripkestructures.
288
The deﬁnitions of knowledgein synchronous systemsand in as ynchronous systems were then
studied. The ﬁndamemtal result that common knowledge canno t be attained in an error-free
message-passing asynchronous system was then examined. FO ur weaker versions of common
knowledge – epsilion common knowledge, eventual common kno wledge, timestamped common
knowledge, and concurrent common knowledge – that are achie vable in asynchronous were then
examined. Concurrent common knowledge underlies most of th e protocols in asynchronous sys-
tems. Several algorithmsto achieveconcurrent commonknow ledgewere then studied – thesnap-
shot based algorithm, a 3-phase send-inhibitory algorithm , an algorithm that use the tree overlay,
and one algorithm that uses a logical ring. A section on how pr oesses learn new information
(viz,gainnewknowledge)consideredknowledgetransferan d knowledgegainintermsofprocess
chains and isomorphismof execution views. Finally, the rel ationship between the level of knowl-
edgeinmessage-passsingasynchronoussystemsand sizeofm atrixlogicalclocks was studied.
8.8 BibliographicNotes
ThemuddychildrenexampleistakenfromHalpernandMoses[6 ]andHalpernandFagin[5]. The
discussions on Kripke structures, S5 modal logic, and the de ﬁnitions of regular knowledge and
(regular) common knowledge in synchronous systems (Figure 8.1) are based on an excellent text
byFagin,Halpern,Moses,andVardi[4]. Thediscussiononlo calfacts,learning,knowledgetrans-
fer,andisomorphismsisbasedontheworkbyChandyandMisra [1]. Theresults(Theorems8and
9) on agreement in asynchronous message-passing systems ap pear to be folklore. The notion of
inhibition was formalized by Critchlow and Taylor [3]. Conc urrent common knowledge and pro-
tocols to attain it for asynchronous systems were formalize d by Panangaden and Taylor [10]. The
deﬁnitions of epsilon, eventual, and timestamped common kn owledge for asynchronous systems
arealsobasedon[10]. Thedeﬁntionofknowledgeforasynchr onoussystems(Figure8.4)isbased
on Kshemkalyani [8, 9]. Matrix clocks are ﬁrst used by Krishn akumar and Bernstein [7], Wuu
and Bernstein [13], and Sarin and Lynch [12], and also studie d by Ruget [11]. The relationship
between clocksofvariousdimensionsandknowledgewas form alizedby Kshemkalyani[8, 9].
8.9 ExerciseProblems
1. In the Muddy Children puzzle (Section 8.1), if Ψ= “At most kchildren have mud on the
forehead,” will the muddy children be able to identify thems elves? If yes, in how many
roundsofquestioning? Ifnot,whynot? Analyzethisscenari o in detail.
2. Therearetwoblackhatsand twowhitehats. Oneofthesehat sishiddenaway andthecolor
of this hat is not known to anybody. The remaining three hats a re placed on the heads of
three persons A, B, and C in such a way that none of thepersons k nows thecolor of the hat
placed onhis/herhead. Draw aKripkestructurethat describ esthissituation.
289
3. In a failure-free asynchronous message-passing system o fnprocesses, process Pilearns a
factφ.
(a) Devisesimplenoninhibitoryprotocolsusingalogicalr ing alongwhich topass control
messages to achieve the following, and justify your answers . Use timing diagrams to
illustrateyouranswers.
i. A protocoltoattain E2(φ)in thesystem.
ii. A protocolsothat each process knows E2(φ).
(b) What is the earliest global time at which all processes kn ow that everyone knows
E2(φ)? Howcan all theprocesses knowaboutthistime?
4. In Theorem 9, assume that there exists an upper bound on mes sage transmissiontimes.
Which (if any) variant of concurrent common knowledge can ho ld in the system? please
stateyourassumptionsclearly to justifyyourreasoningus ed inyouranswer.
5. Consider the matrix clocks given in Figure 8.10. At any poi nt in time after the execution of
atomicstepsMC0, MC1,MC2,orMC3,what istheminimumnumber ofentries amongthe
n2entries ofClkithat are guaranteed to be replicas of other entries in Clki? Identify the
exactset(s)ofelementsofthearray Clkithat willnecessarilybeidentical.
6. Provethefollowing. Fortheequalities,youneed toprove theimplicationinbothdirections.
For each part, ﬁrst provethe results usingthe interleaving model, and then provethe results
usingthepartial ordermodel.
(a)Ki¬φimpliesthat¬Kiφ
(b)Kiφ∨¬Kiφ
(c)Kiφ∨Ki¬φ, ifφisaconstant.
(d)Kiφ∧Kiψ=Ki(φ∧ψ)
(e)Kiφ∨Kiψ=Ki(φ∨ψ)
(f)Ki(¬Kiφ) =¬Kiφ
290
Bibliography
[1] K.M. Chandy,J. Misra,Howprocesses learn, Distributed Computing,1: 40-52,1986.
[2] K. M. Chandy, L. Lamport, Distributed snapshots: Determ ining global states of distributed
systems,ACM Transactionson ComputerSystems,3(1): 63-75 ,1985.
[3] C. Critchlow, K. Taylor, The inhibitionspectrum and the achievementof causal consistency,
DistributedComputing,10(1): 11-27,1996.
[4] R. Fagin,J. Halpern, Y.Moses,M. Vardi,Reasoning about Knowledge,MITPress, 1995.
[5] J. Halpern, R. Fagin, Modeling knowledge and action in di stributed systems, Distributed
Computing,3(4): 139-179,1989.
[6] J.Halpern,Y.Moses,Knowledgeandcommonknowledgeina distributedenvironment,Jour-
naloftheACM, 37(3): 549-587,1990.
[7] A.Krishnakumar,A.Bernstein,Boundedignorance: Atec hniqueforincreasingconcurrency
inareplicated system,ACMTransactionson DatabaseSystem s,19(4): 586-625,Dec. 1994.
[8] A. Kshemkalyani, The power of logical clock abstraction s, Distributed Computing, 17(2):
131-151,August2004.
[9] A. Kshemkalyani, Concurrent knowledge and logical cloc k abstractions, Proc. 20th Confer-
ence on Foundations of Software Technology and Theoretical Computer Science, Lecture
Notes in Computer Science 1974, Editors: S. Kapoor, S. Prasa d, Springer-Verlag, 489-502,
2000.
[10] P. Panangaden, K. Taylor, Concurrent common knowledge : Deﬁning agreement for asyn-
chronoussystems,DistributedComputing,6(2): 73-94,Sep t. 1992.
[11] F.Ruget, Cheapermatrixclocks,Proc. 8thWorkshoponD istributedAlgorithms,Editors: G.
Tel,P. Vitanyi,LectureNotesin ComputerScience, Springe r-Verlag, 355-369,1994.
[12] S. Sarin, N. Lynch, Discarding obsolete information in a distributed database system, IEEE
Transactionson SoftwareEngineering,13(1): 39-46, 1987.
291
[13] G.Wuu,A.Bernstein,Efﬁcientsolutionstothereplica tedloganddictionaryproblems,Proc.
3rdACM Symposiumon PrinciplesofDistributedComputing,2 32-242,1984.
292
Chapter9
DistributedMutualExclusion Algorithms
9.1 Introduction
Mutual exclusion is a fundamental problem in distributed co mputing systems. Mutual exclusion
ensures that concurrent access of processes to a shared reso urce or data is serialized, that is, exe-
cuted in mutually exclusivemanner. Mutual exclusion in a di stributedsystem states that only one
process is allowed to execute the critical section (CS) at an y given time. In a distributed system,
shared variables (semaphores) or a local kernel cannot be us ed to implement mutual exclusion.
Message passing is the sole means for implementing distribu ted mutual exclusion. The decision
as to which process is allowed access to the CS next is arrived at by message passing, in which
each process learns about the state of all other processes in some consistent way. The design of
distributedmutualexclusionalgorithmsiscomplexbecaus ethesealgorithmshavetodealwithun-
predictable message delays and incomplete knowledge of the system state. There are three basic
approaches forimplementingdistributedmutualexclusion :
1. Tokenbased approach
2. Non-tokenbased approach
3. Quorumbased approach
In the token-based approach, a unique token (also known as th e PRIVILEGE message) is shared
among the sites. A site is allowed to enter its CS if it possess es the token and it continues to
hold the token until the execution of the CS is over. Mutual ex clusion is ensured because the
token is unique. The algorithms based on this approach essen tially differ in the way a site carries
out the search for the token. In the non-token based approach , two or more successive rounds of
messages are exchanged among the sites to determine which si te will enter the CS next. A site
enters the critical section (CS) when an assertion, deﬁned o n its local variables, becomes true.
Mutualexclusionisenforcedbecausetheassertionbecomes trueonlyatonesiteatanygiventime.
In the quorum based approach, each site requests permission to execute the CS from a subset of
sites (called a quorum). The quorums are formed in such a way t hat when two sites concurrently
293
requestaccess totheCS, onesitereceivesboththerequests and whichisresponsibletomakesure
thatonlyonerequest executestheCS at anytime.
In this chapter, we describe severaldistributedmutual exc lusionalgorithmsand comparetheir
features and performance. We discuss relationship among va rious mutual exclusion algorithms
and examinetrade-offsamongthem.
9.2 Preliminaries
In this section, we describe the underlying system model, di scuss the requirements that mutual
exclusion algorithms should satisfy, and discuss what metr ics we use to measure the performance
ofmutualexclusionalgorithms.
9.2.1 SystemModel
The system consistsof N sites, S1,S2, ...,SN. Without loss of generality, we assumethat a single
process is running on each site. The process at site Siis denoted by pi. All these processes
communicate asynchronously over an underlying communicat ion network. A process wishing to
entertheCS,requestsallotherorasubsetofprocessesbyse ndingREQUESTmessages,andwaits
for appropriate replies before entering the CS. While waiti ng the process is not allowed to make
further requests to enter the CS. A site can be in one of the fol lowing three states: requesting the
CS, executingtheCS, orneitherrequestingnorexecutingth eCS (i.e., idle). In the‘requestingthe
CS’ state, the site is blocked and can not make further reques ts for the CS. In the ‘idle’ state, the
siteisexecutingoutsidetheCS. Inthetoken-basedalgorit hms,asitecanalsobeinastatewherea
site holding the token is executing outsidethe CS. Such stat e is refereed to as the idle token state.
At any instant, a site may have several pending requests for C S. A site queues up these requests
and servesthemoneat atime.
We do not make any assumption regarding communication chann els if they are FIFO or not.
This is algorithm speciﬁc. We assume that channels reliably deliver all messages, sites do not
crash, and the network does not get partitioned. Some mutual exclusion algorithms are designed
tohandlesuchsituations. ManyalgorithmsuseLamport-sty lelogicalclockstoassignatimestamp
to critical section requests. Timestamps are used to decide the priority of requests in case the of
a conﬂict. A general rule followed is that the smaller the tim estamp of a request,the higher its
prioritytoexecutetheCS.
Weusethefollowingnotations: Ndenotesthenumberofprocessesorsitesinvolvedininvok-
ing the critical section, Tdenotes the average message delay, and Edenotes the average critical
sectionexecutiontime.
9.2.2 Requirements ofMutual ExclusionAlgorithms
A mutualexclusionalgorithmshouldsatisfythefollowingp roperties:
294
Last site exits the CS
Synchronization delaytimeNext site enters the CS
Figure9.1: SynchronizationDelay
1.SafetyProperty: Thesafetypropertystatesthatatanyinstant,onlyoneproc esscanexecute
thecriticalsection. Thisis anessentialproperty ofamutu alexclusionalgorithm.
2.Liveness Property: This property states the absence of deadlock and starvation . Two or
moresitesshouldnotendlesslywaitformessageswhichwill neverarrive. Inaddition,asite
must not wait indeﬁnitely to execute the CS while other sites are repeatedly executing the
CS. Thatis,every requestingsiteshouldget an opportunity toexecutetheCS inﬁnitetime.
3.Fairness: Fairness in the context of mutual exclusion means that each p rocess gets a fair
chance to execute the CS. In mutual exclusion algorithms, th e fairness property generally
meanstheCSexecutionrequestsareexecutedintheorderoft heirarrival(timeisdetermined
bya logicalclock)inthesystem.
Theﬁrstpropertyisabsolutelynecessaryandtheothertwop ropertiesareconsideredimportant
inmutualexclusionalgorithms.
9.2.3 PerformanceMetrics
Theperformanceofmutualexclusionalgorithmsisgenerall ymeasuredbythefollowingfourmet-
rics:
•Message complexity: It the number of messages that are required per CS execution b y a
site.
•Synchronization delay: After a site leaves the CS, it is the time required and before t he
nextsiteenters theCS (seeFigure 9.1). Notethatnormally o neormoresequentialmessage
exchangesmay berequired afterasiteexitstheCSand before nextsitecan entertheCS.
•Responsetime: ItisthetimeintervalarequestwaitsforitsCSexecutionto beoverafterits
request messages have been sent out (see Figure 9.2). Thus, r esponse timedoes not include
thetimearequestwaits ata sitebeforeitsrequest messages havebeen sentout.
295
messages sent out 
time
Response TimeCS execution timeThe site exits the CSThe site enters
the CSCS Request arrives
Its request
Figure9.2: ResponseTime
•System throughput: It is the rate at which the system executes requests for the CS . IfSD
is the synchronization delay and Eis the average critical section execution time, then the
throughputisgivenbythefollowingequation:
systemthroughput=1/( SD+E)
Generally,thevalueofaperformancemetricﬂuctuatesstat isticallyfromrequesttorequestand
wegenerally considertheaveragevalueofsuch ametric.
Low and High Load Performance: The load is determined by the arrival rate of CS execution
requests. Performance ofa mutual exclusionalgorithmdepe nds upon the load and we often study
the performance of mutual exclusion algorithms under two sp ecial loading conditions, viz., “low
load" and “high load". Under low load conditions, there is seldom more than one request for the
criticalsectionpresentinthesystemsimultaneously. Und erheavyload conditions,thereisalways
apendingrequestforcriticalsectionatasite. Thus,inhea vyloadconditions,afterhavingexecuted
a request, a site immediately initiates activities to execu te its next CS request. A site is seldom in
the idle state in heavy load conditions. For many mutual excl usion algorithms, the performance
metricscanbecomputedeasilyunderlowandheavyloadsthro ughasimplemathematicalreason-
ing.
Best and WorstCasePerformance: Generally,mutualexclusionalgorithmshavebest and worst
cases for the performance metrics. In the best case, prevail ing conditions are such that a perfor-
mancemetricattainsthebestpossiblevalue. Forexample,i nmostmutualexclusionalgorithmsthe
bestvalueoftheresponsetimeisaround-tripmessagedelay plustheCSexecutiontime, 2T+E.
Often formutualexclusionalgorithms,thebestand worstca ses coincidewithlowand highloads,
respectively. Forexamples,thebestand worstvaluesofthe responsetimeare achievedwhenload
is,respectively,lowandhigh;insomemutualexclusionalg orithmsthebestandtheworsemessage
trafﬁcis generated at lowandheavy load conditions,respec tively.
296
9.3 Lamport’sAlgorithm
Lamportdevelopedadistributedmutualexclusionalgorith masanillustrationofhisclocksynchro-
nization scheme [12]. The algorithm is fair in the sense that a request for CS are executed in the
orderoftheirtimestampsandtimeisdeterminedbylogicalc locks. Whenasiteprocessesarequest
for the CS, it updates its local clock and assigns the request a timestamp. The algorithm executes
CS requests in the increasing order of timestamps. Every sit eSikeeps a queue, request_queue i,
which contains mutual exclusion requests ordered by their t imestamps. (Note that this queue is
different from the queue that contains local requests for CS execution awaiting their turn.) This
algorithmrequires communicationchannelsto delivermess ages theFIFO order.
TheAlgorithm
Requesting the criticalsection:
•When a site Siwants to enter the CS, it broadcasts a REQUEST( tsi,i) message to all other
sites and places the request on request_queue i. ((tsi,i) denotes the timestamp of the re-
quest.)
•When a site Sjreceives the REQUEST( tsi,i) message from site Si,places siteSi’s request
onrequest_queue jandit returnsatimestampedREPLY messageto Si.
Executing the criticalsection: SiteSienters theCS when thefollowingtwo conditionshold:
L1:Sihas receivedamessagewithtimestamplargerthan ( tsi,i) fromall othersites.
L2:Si’s requestis at thetopof request_queue i.
Releasingthe critical section:
•SiteSi, upon exiting the CS, removes its request from the top of its r equest queue and
broadcastsatimestampedRELEASE messageto allothersites .
•When a site Sjreceives a RELEASE message from site Si, it removes Si’s request from its
requestqueue.
When a site removes a request from its request queue, its own r equest may come at the top of the
queue,enablingittoentertheCS.Clearly,whenasiterecei vesaREQUEST,REPLYorRELEASE
message,it updatesitsclock usingthetimestampin themess age.
Correctness
Theorem 1: Lamport’salgorithmachievesmutualexclusion.
Proof:Proof is by contradiction. Suppose two sites SiandSjare executing the CS concur-
rently. For this to happen conditions L1 and L2 must hold at bo th the sites concurrently . This
297
S
SS1
2
3(1,1)
(1,2)
Figure9.3: Sites S1andS2areMakingRequests fortheCS.
implies that at some instant in time, say t, bothSiandSjhave their own requests at the top of
theirrequest_queuesand condition L1 holds at them. Without loss of generality, a ssume that
Si’s request has smaller timestamp than the request of Sj. From condition L1 and FIFO prop-
erty of the communication channels, it is clear that at insta nttthe request of Simust be present
inrequest_queue jwhenSjwas executing its CS. This implies that Sj’s own request is at the
top of its own request_queuewhen a smaller timestamp request, Si’s request, is present in the
request_queue j– acontradiction!! Hence, Lamport’salgorithmachievesmu tualexclusion.
Theorem 2: Lamport’salgorithmis fair.
Proof:A distributed mutual exclusion algorithm is fair if the requ ests for CS are executed in the
order oftheir timestamps. Theproof is by contradiction. Su pposea site Si’s request has a smaller
timestamp than the request of another site SjandSjis able to execute the CS before Si. ForSj
to execute the CS, it has to satisfy the conditions L1 and L2. T his implies that at some instant in
time say t,Sjhas its own request at the top of its queue and it has also recei ved a message with
timestamplargerthanthetimestampofitsrequestfromallo thersites. But request_queueatasite
isorderedbytimestamp,andaccordingtoourassumption Sihaslowertimestamp. So Si’srequest
must be placed ahead of the Sj’s request in the request_queue j. This is a contradiction. Hence
Lamport’salgorithmisafair mutualexclusionalgorithm.
An Example
InFigures9.3to9.6,weillustratetheoperationofLamport ’salgorithm. InFigure9.3,sites S1and
S2aremakingrequestsfortheCSandsendoutREQUESTmessagest oothersites. Thetimestamps
of the requests are (1, 1) and (1, 2), respectively. In Figure 9.4, both the sites S1andS2have
received REPLY messages from all other sites. S1has its request at the top of its request_queue
but siteS2does not have its request at the top of its request_queue. Consequently, site S1enters
the CS. In Figure 9.5, S1exits and sends RELEASE mesages to all other sites. In Figure 9.6,
siteS2has received REPLY from all other sites and also received a RE LEASE message from site
S1. SiteS2updates itsrequest_queueand its request is now at the top of its request_queue.
Consequently,it enterstheCS next.
298
Site S1 enters the CS
S
2
3(1,1)
(1,2)
S
S1
Figure9.4: Site S1enters theCS.
S
SS1
2
3(1,1), (1,2)
(1,1), (1,2)(1,1)
(1,2)Site S1 enters the CS Site S1  exits the CS
(1,2)
Figure9.5: Site S1exitstheCS andsends RELEASE messages.
S
SS1
2
3(1,1), (1,2)
(1,1), (1,2)(1,1)
(1,2)
Site S2  enters the CSSite S1 enters the CS Site S1  exits the CS
Figure9.6: Site S2enterstheCS
299
Performance
For each CS execution, Lamport’s algorithm requires (N−1)REQUEST messages, (N−1)
REPLYmessages,and (N−1)RELEASEmessages. Thus,Lamport’salgorithmrequires 3(N−1)
messagesperCS invocation. Synchronizationdelay in theal gorithmisT.
An Optimization
In Lamport’s algorithm, REPLY messages can be omitted in cer tain situations. For example, if
siteSjreceives a REQUEST message from site Siafter it has sent its own REQUEST message
withtimestamphigherthanthetimestampofsite Si’srequest,thensite SjneednotsendaREPLY
message to site Si. This is because when site Sireceives site Sj’s request with timestamp higher
thanitsown,itcanconcludethatsite Sjdoesnothaveanysmallertimestamprequestwhichisstill
pending(becausecommunicationchannels preservesFIFO or dering).
Withthisoptimization,Lamport’salgorithmrequiresbetw een3(N−1)and2(N−1)messages
perCS execution.
9.4 Ricart-AgrawalaAlgorithm
The Ricart-Agrawala [21] algorithm assumes the communicat ion channels are FIFO. The algo-
rithmusestwotypesofmessages: REQUESTandREPLY.Aproces ssendsaREQUESTmessage
to all other processes to request their permission to enter t he critical section. A process sends a
REPLY message to a process to give its permission to that proc ess. Processes use Lamport-style
logicalclockstoassignatimestamptocriticalsectionreq uests. Timestampsareusedtodecidethe
priority of requests in case of conﬂict – if a process pithat is waiting to execute the critical sec-
tion, receives a REQUEST message from process pj, then if the priority of pj’s request is lower,
pidefers the REPLY to pjand sends a REPLY message to pjonly after executing the CS for its
pendingrequest. Otherwise, pisendsaREPLYmessageto pjimmediately,provideditiscurrently
not executing the CS. Thus, if several processes are request ing execution of the CS, the highest
priorityrequestsucceedsincollectingalltheneededREPL YmessagesandgetstoexecutetheCS.
Each process pimaintains the Request-Deferred array, RDi, the size of which is the same as
the number of processes in the system. Initially, ∀i∀j:RDi[j]=0. Whenever pidefer the request
sentbypj, it setsRDi[j]=1 and afterit hassent aREPLY messageto pj,it setsRDi[j]=0.
9.4.1 Description ofthe Algorithm
Requesting the criticalsection:
(a)When a site Siwants to enter the CS, it broadcasts a timestamped REQUEST me ssage to all
othersites.
300
(b)When siteSjreceives a REQUEST message from site Si, it sends a REPLY message to site
SiifsiteSjisneitherrequestingnorexecutingtheCS,orifthesite Sjisrequestingand Si’s
request’s timestamp is smaller than site Sj’s own request’s timestamp. Otherwise, the reply
isdeferred and SjsetsRDj[i]=1
Executing the criticalsection:
(c)SiteSienterstheCSafterithasreceivedaREPLYmessagefromevery siteitsentaREQUEST
messageto.
Releasingthe critical section:
(d)When siteSiexits the CS, it sends all the deferred REPLY messages: ∀jifRDi[j]=1, then
senda REPLY messageto Sjand setRDi[j]=0.
When a sitereceivesa message,it updatesitsclock usingthe timestampinthemessage. Also,
when a site takes up a request for the CS for processing, it upd ates its local clock and assigns a
timestamp to the request. In this algorithm, a site’s REPLY m essages are blocked only by sites
which are requestingtheCS withhigherpriority(i.e., smal lertimestamp).Thus,when a sitesends
out deffered REPLY messages, site with the next highest prio rity request receives the last needed
REPLYmessageandenterstheCS.ExecutionoftheCSrequests inthisalgorithmisalwaysinthe
orderoftheirtimestamps.
Correctness
Theorem 3: Ricart-Agrawalaalgorithmachievesmutualexclusion.
Proof:Proof is by contradiction. Suppose two sites SiandSjare executing the CS concurrently
andSi’s request has higher priority (i.e., smaller timestamp) th an the request of Sj. Clearly,Si
receivedSj’s request after it has made its own request. (Otherwise, Si’s request will have lower
priority.) Thus, Sjcan concurrently execute the CS with Sionly ifSireturns a REPLY to Sj(in
response to Sj’s request) before Siexits the CS. However, this is impossiblebecause Sj’s request
has lowerpriority.Therefore,Ricart-Agrawalaalgorithm achievesmutualexclusion. 2
In Ricart-Agrawala algorithm, for every requesting pair of sites, the site with higher priority
requestwillalwaysdefertherequestofthelowerprioritys ite. Atanytimeonlythehighestpriority
request succeeds ingettingalltheneeded REPLY messages.
An Example
Figures 9.7 to 9.10 illustrate the operation of Ricart-Agra wala algorithm. In Figure 9.7, sites
S1andS2are making requests for the CS and send out REQUEST messages t o other sites. The
timestampsoftherequestsare(2,1)and(1,2),respectivel y. InFigure9.8, S2hasreceivedREPLY
messagesfromallothersitesandconsequently,itentersth eCS. InFigure9.9, S2exitstheCSand
sends aREPLY mesageto site S1. In Figure9.10, site S1has received REPLY from all othersites
and enters theCS next.
301
(1,2)S1
S
S2
3(1,1)
Figure9.7: Sites S1andS2are makingrequestfortheCS
enters the CS
S1
S
S2
3(1,1)
(1,2) Request is deferred Site S1
Figure9.8: Site S1enters theCS
Request is deferred
S1
S
S2
3(1,1)
(1,2) Site S1enters the CS Site S1exits the CS
Figure9.9: Site S1exitstheCSand sendsa REPLY messageto S2’s deferred request
302
2S1
S
S2
3(1,1)
(1,2) Site S1enters the CS Site S1exits the CS Request is deferred
Site S enters the CS
Figure9.10: Site S2enters theCS
Performance
For each CS execution, Ricart-Agrawala algorithm requires (N−1)REQUEST messages and
(N−1)REPLYmessages. Thus,itrequires 2(N−1)messagesperCSexecution. Synchronization
delay inthealgorithmis T.
9.5 Singhal’sDynamicInformation-StructureAlgorithm
Most mutual exclusion algorithms use a static approach to in voke mutual exclusion; i.e., they
always take the same course of actions to invoke mutual exclu sion no matter what is the state of
the system. A problem with these algorithms is the lack of efﬁ ciency because these algorithms
fail to exploit the changing conditions in the system. Note t hat an algorithm can exploit dynamic
conditionsofthesystemto optimizetheperformance.
For example, if few sites are invoking mutual exclusionvery frequently and other sites invoke
mutualexclusionmuchlessfrequently,thenafrequentlyin vokingsiteneednotaskforthepermis-
sionoflessfrequentlyinvokingsiteeverytimeitrequests anaccesstotheCS.Itonlyneedstotake
permission from all other frequently invoking sites. Singh al [29] developed an adaptive mutual
exclusionalgorithmbasedon thisobservation. Theinforma tion-structureofthealgorithmevolves
with time as sites learn about the state of the system through messages. Dynamic information-
structure mutual exclusion algorithms are attractive beca use they can adapt to ﬂuctuating system
conditionstooptimizetheperformance.
The design of such adaptive mutual exclusion algorithms is c hallenging and we list some of
thedesignchallengesnext:
•Howdoesasiteefﬁcientlyknowwhatsitesarecurrentlyacti velyinvokingmutualexclusion?
•When alessfrequently invokingsiteneeds toinvokemutuale xclusion,howdoes itdoit?
303
•Howdoesalessfrequentlyinvokingsitemakesatransitiont omorefrequentlyinvokingsite
and vice-versa.
•How to insure that mutual exclusion is guaranteed when a site does not take the permission
ofeveryothersite.
•Howtoinsurethatadynamicmutualexclusionalgorithmdoes notwasteresourcesandtime
incollectingsystemsstate,offsettingany gain.
SystemModel
We consider a distributed system consisting of n autonomous sites, sayS1,S2, ...,Sn, which are
connected by a communication network. We assume that the sit es communicate completely by
message passing. Message propagation delay is ﬁnite but unp redictable and between any pair of
sites, messages are delivered in the order they are sent. For the ease of presentation, we assume
that the underlying communication network is reliable and s ites do not crash. However, methods
havebeen proposedforrecoveryfrom messagelossesand site failures.
Data Structures
Information-structureat a site Siconsists of two sets. The ﬁrst set Ri, calledrequest set , contains
the sites from which Simust acquire permission before executing CS. The second set Ii, called
informset ,containsthesitestowhich SimustsenditspermissiontoexecuteCSafterexecutingits
CS.
Every siteSimaintains a logical clock Ci, which is updated according to Lamport’s rules.
Every request for CS execution is assigned a timestamp which is used to determine its priority.
The smaller the timestamp of a request, the higher its priori ty. Every site maintains three boolean
variables to denote the state of the site: Requesting, Executing, and My_priority . Requesting and
executingaretrueifandonlyifthesiteisrequestingorexe cutingCS, respectively. My_priorityis
trueifpendingrequestof Sihas priorityoverthecurrent incomingrequest.
Initialization
Thesystemstarts inthefollowinginitialstate:
ForasiteSi(i=1 to n),
Ri:={S1,S2,...,Si−1,Si}
Ii:=Si
Ci:=0
Requesting=Executing:=False
304
Thus, initially site Si, 1≤i≤n, sends request messages only to sites Si,Si−1, ...,S1. If
we stagger sites SntoS1from left to right, then the initial system state has the foll owing two
properties:
1. Each site requests permission from all the sites to its rig ht and from no site to its left. Con-
versely, for a site, all the sites to its left asks for its perm ission and no site to its right asks
for its permission. Or putting together, for a site, only all the sites to its left will ask for its
permission and it will ask for the permission of only all the s ites to its right. Therefore, ev-
ery siteSidividesallthesitesintotwodisjointgroups;all thesites intheﬁrst grouprequest
permission from SiandSirequests permission from all the sites in the second group. T his
propertyis importantforenforcing mutualexclusion.
2. The cardinality of Ridecreases in stepwise manner from left to right. Due to this r eason,
thisconﬁgurationhas been called"staircasepattern"in to pologicalsense[27].
9.5.1 The Algorithm
SiteS iexecutesthefollowingthreestepstoinvokemutualexclusi on:
Step 1: (Request Critical Section)
Requesting=true;
Ci=Ci+1;
Send REQUEST(C i, i)messageto allsitesin R i;
Wait untilR i=∅; /*Wait untilall sitesinR ihavesent areply toS i*/
Requesting=false;
Step 2: (ExecuteCritical Section)
Executing=true;
ExecuteCS;
Executing=false;
Step 3: (Release CriticalSection)
ForeverysiteS kin Ii(except S i)do
Begin
Ii=Ii–{S k};
Send REPLY(C i,i)messageto S k;
Ri=Ri+{S k}
End
305
REQUEST messagehandler
REQUEST message handler at a site processes incoming REQUES T messages. It takes actions
such as updating information-structure and sending REQUES T/REPLY messages to other sites.
REQUEST messagehandlerat site Siisgivenbelow:
/* SiteS iishandlingmessageREQUEST(c, j)*/
Ci:=max{C i,c};
Case
Requesting = true:
BeginifMy_prioritythen I i:=Ii+{j}
/*My_PriorityistrueifthependingrequestofS ihaspriorityovertheincomingrequest */
Else
Begin
Send REPLY(C i, i)messagetoS j;
If not(S j∈Ri)then
Begin
Ri=Ri+{S j};
Send REQUEST(C i, i)messagetositeS j;
End;
End;
End;
Executing = true : Ii=Ii+{S j};
Executing = false ∧Requesting =false: Begin
Ri=Ri+{S j};
Send REPLY(C i,i)messagetoS j;
End;
REPLY messagehandler
The REPLY message handler at a site processes incoming REPLY messages. It updates the
information-structure. REPLY messagehandleratsite Siisgivenbelow:
/* SiteS iishandlingamessageREPLY(c, j)*/
Begin
Ci:=max{C i, c};
Ri=Ri– {S j};
End;
NotethatREQUESTandREPLYmessagehandlersandthestepsof thealgorithmaccessshared
data structures, viz., Ci,Ri, andIi. To guarantee the correctness, it’s important that executi on of
REQUEST and REPLY messagehandlersand allthreestepsofthe algorithm(except "waitfor Ri
306
=∅tohold"inStep 1)mutuallyexcludeeach other.
An Explanationof the Algorithm
At high level, Siacquires permission to execute the CS from all sites in its re quest setRiand it
releases theCS bysendingaREPLY messagetoall sitesinitsi nform setIi.
IfsiteSiwhichitselfisrequestingtheCS, receivesahigherpriorit yREQUEST messagefrom
a siteSj, thenSitakes the following actions: (i) Siimmediately sends a REPLY message to Sj,
(ii) ifSjis not inRi, then1Sialso sends a REQUEST message to Sj, and (iii)Siplaces an entry
forSjinRi. Otherwise, (i.e., if the request of Sihas priority over the request of Sj),Siplaces an
entryforSjintoIisothatSjcanbesentaREPLYmessagewhen Siﬁnisheswiththeexecutionof
theCS.
IfSireceives a REQUEST message from Sjwhen it is executing the CS, then it simply puts
SjinIiso thatSjcan besent aREPLY messagewhen Siﬁnisheswith theexecutionof theCS. If
SireceivesaREQUESTmessagefrom SjwhenitisneitherrequestingnorexecutingtheCS,then
itplaces an entry for SjinRiand sendsSja REPLY message.
Rulesforinformationexchangeandupdatingrequestandinf ormsetsaresuchthatthestaircase
pattern is preserved in the system even after the sites have e xecuted the CS any number of times.
However, the positions of sites in the staircase pattern cha nge as the system evolves. (For a proof
ofthis,see[28]). ThesitetoexecuteCSlastpositionsitse lfattherightendofthestaircasepattern.
9.5.2 Correctness
We informallydiscusswhy thealgorithmachieves mutualexc lusionand why itis free from dead-
locks. Foraformal proof,thereaders are referred to[28].
Achieving Mutual Exclusion: Note that the initial state of the information-structuresa tisﬁes the
following condition: for every SiandSj, eitherSj∈RiorSi∈Rj. Therefore, if two sites re-
quest CS, one of them will always ask for the permission of the another. However, this is not
sufﬁcient formutualexclusion[18]; However, wheneverthe re is aconﬂict between two sites(i.e.,
they concurrently invoke mutual exclusion), the sites dyna mically adjust their request sets such
that both request permission of each other satisfying the co ndition for mutual exclusion. This is
a nice feature of the algorithm because if the information-s tructures of sites satisfy the condition
for mutualexclusionall the time,sites will exchangemorem essages. Instead, it is moredesirable
to dynamically adjust the request set of the sites as and when needed to insure mutual exclusion
becauseit optimizesthenumberofmessagesexchanged.
1Absenceof SjfromRiimpliesthat SihasnotpreviouslysentaREQUESTmessageto Sj. Thisisthereasonwhy
Sialso sends a REQUEST message to Sjwhen it receives a REQUEST message from Sj. This step is also required
topreservethestaircase patternoftheinformation-struc tureofthesystem.
307
FreedomfromDeadlocks: Inthealgorithm,eachrequestisassignedagloballyunique timestamp
which determines its priority. The algorithm is free from de adlocks because sites use timestamp
ordering(whichisuniquesystemwide)todeciderequestpri orityandarequestisblockedbyonly
higherpriorityrequests.
An Example
Considerasystemwithﬁvesites S1,...,S 5. SupposeS2andS3wanttoentertheCSconcurrently,
andtheybothsendappropriaterequestmessages. S3sendsarequestmessagetositesinitsRequest
set - {S1,S2} andS2sends a request messageto the only sitein its Request set – { S1}. There are
threepossiblescenarios:
1. If timestamp of S3’s request is smaller, then on receiving S3’s request,S2sends a REPLY
message to S3.S2also addsS3to its Request set and sends S3a REQUEST message.
On receiving a REPLY message from S2,S3removesS2from its Request set. S1sends a
REPLY to both S2andS3because its neither requesting to enter the CS nor executing the
CS.S1addsS2andS3to its Request set because any one of these sites could possib ly be
in the CS when S1requests for an entry into CS in the future. On receiving S1’s REPLY
message,S3removesS1from itsRequest set and sinceithas got REPLY messages froma ll
sitesinits(initial)Request Set, itenters theCS.
2. If timestamp of S3is larger, then on receiving S3’s request,S2addsS3to its Inform set.
WhenS2gets a REPLY from S1, it enters the CS. When S2relinquishes the CS, it informs
S3(idofS3ispresentin S2’sInformset)aboutitsconsenttoentertheCS.Then, S2removes
S3from its Inform set and add S3to its Request set. This is logical because S3could be
executingin CSwhen S2requests an ‘CS entry’permissioninthefuture.
3. IfS2receivesaREPLY from S1and starts executingCS before S3’s REQUEST reaches S2,
S2simplyadds S3to itsInformset, and sends S3aREPLY afterexitingtheCS.
9.5.3 PerformanceAnalysis
The synchronization delay in the algorithm is T. Below, we co mpute the message complexity in
lowand heavyloads.
Lowloadcondition: IncaseoflowtrafﬁcofCSrequests,mostofthetimeonlyoneo rnorequest
for the CS will be present in the system. Consequently, the st aircase pattern will reestablish be-
tweentwosucssiverequestsforCSandtherewillseldombean interferenceamongtheCSrequests
from different sites. In the staircase conﬁguration, cardi nality of the request sets of the sites is 1,
2, ..., (n-1), n, respectively, from right to left. Therefor e, when trafﬁc of requests for CS is low,
sites will send 0, 1, 2, ..., (n-1) number of REQUEST messages with equal likelihood (assuming
uniform trafﬁc of CS requests at sites). Therefore, the mean number of REQUEST messages sent
308
per CS execution for this case is =(0+1+2+ ........+(n-1))/ n = (n-1)/2. Since a REPLY message is
returnedforeveryREQUESTmessage,theaveragenumberofme ssagesexchangedperCSexecu-
tionis2*(n-1)/2= (n-1).
Heavy load condition: When the rate of CS requests is high, all the sites always have a pending
request for CS execution. In this case, a site on the average r eceives (n-1)/2 REQUEST messages
from other sites while waiting for its REPLY messages. Since a site sends REQUEST messages
onlyinresponsetoREQUEST messagesofhigherpriority,ont heaverageitwillsend(n-1)/4RE-
QUESTmessageswhilewaitingforREPLYmessages. Therefore ,theaveragenumberofmessages
exchangedper CSexecutioninhighdemandis 2*[(n-1)/2+(n- 1)/4]=3*(n-1)/2.
9.5.4 Adaptivity in HeterogeneousTrafﬁc Patterns
An interesting feature of the algorithm is that its informat ion-structure adapts itself to the envi-
ronments of heterogeneous trafﬁc of CS requests and to stati stical ﬂuctuations in trafﬁc of CS
requests to optimize the performance (the number of message s exchanged per CS execution). In
non-uniformtrafﬁc environments,siteswith highertrafﬁc of CS requests willpositionthemselves
towards the right end of the staircase pattern. That is, site s with higher trafﬁc of CS requests will
tendtohavelowercardinalityoftheirrequestsets. Also,a tahightrafﬁcsite Si,ifSj∈Ri,thenSj
isalsoahightrafﬁcsite(thiscomesintuitivelybecauseal lhightrafﬁcsiteswillclustertowardsthe
right end of the staircase). Consequently, high trafﬁc site s will mostly send REQUEST messages
only to other high trafﬁc sites and will seldom send REQUEST m essages to sites with low trafﬁc.
Thisadaptivityresultsinareductioninthenumberofmessa gesas wellas indelayingrantingCS
inenvironmentsofheterogeneoustrafﬁc.
9.6 Lodha and Kshemkalyani’s Fair Mutual Exclusion Algo-
rithm
LodhaandKshemakalyani’salgorithm[13]decreasesthemes sagecomplexityofRicart-Agrawala
algorithmbyusingthefollowinginterestingobservation: WhenasiteiswaitingtoexecutetheCS,
it need not receive REPLY messages from every other site. To e nter the CS, a site only needs to
receive a REPLY message from the site whose request just prec edes its request in priority. For
example,ifsites Si1,Si2, ..Sinhaveapendingrequestfor CSand therequestof Si1has thehighest
priority and that of Sinhas the lowest priority and the priority of requests decreas es fromSi1to
Sin,then asite SikonlyneedsaREPLY messagefrom site Sik−1, 1<k≤n toenter theCS.
9.6.1 SystemModel
Each request is assigned a priority ReqIDand requests for the CS access are granted in the order
of decreasing priority. We will defer the details of what ReqIDis composed of to later sections.
309
Theunderlyingcommunicationnetwork isassumedtobeerror free.
Deﬁnition 1: RiandRjareconcurrentiff Pi’s REQUESTmessageisreceived by PjafterPjhas
madeitsrequestand Pj’sREQUESTmessageisreceivedby PiafterPihasmadeitsrequest.
Deﬁnition 2: Given R i, we deﬁnetheconcurrencyset ofR ias follows:
CSet i={R j|Riisconcurrent withR j}/uniontext{Ri}.
9.6.2 The Algorithm
Thealgorithmuses threetypesofmessages: REQUEST,REPLY a nd FLUSH and obtainssavings
on the number of messages exchanged per CS access by assignin g multiplepurposes to each. For
the purpose of blocking a mutual exclusion request, every si teSihas a data structure called lo-
cal_request_queue (denotedasLRQ i)whichcontainsallconcurrentrequestsmadewithrespectt o
Si’srequest andtheserequestsare ordered withrespect to the priority.
All requests are totally ordered by their priorities and the priority is determined by the timestamp
of the request. Hence, when a process receives a REQUEST mess age from some other process, it
can immediatelydetermineifit isallowedtheCS access befo retherequestingprocess orafterit.
In thisalgorithm,messagesplay multiplerolesand thatis d iscussednext.
•Multipleuses ofa REPLY message
1. A REPLY messageacts as areply fromaprocess thatis notreq uesting.
2. A REPLY message acts as a collective reply from processes t hat have higher priority
requests.
AREPLY(R j)fromaprocessP jindicatesthatR jistherequestmadebyP jforwhichithas
executed the CS. It also indicates that all the requests with priority≥priority of R jhave
ﬁnishedexecutingCSand are nolongerincontention.
Thus, in such situations, a REPLY message is a logical reply a nd denotes a collective re-
plyfromallprocessesthathadmadehigherpriorityrequest s.
•Usesofa FLUSH message
Similar to a REPLY message, a FLUSH message is a logical reply and denotes a collec-
tive reply from all processes that had made higher priority r equests. After a process has
exited the CS, it sends a FLUSH message to a process requestin g with the next highest pri-
ority, which is determined by lookingup the process’s local request queue. When a process
Piﬁnishes executingtheCS, it mayﬁnd aprocess P jinoneofthefollowingstates:
310
1. R jis in the local queue of P iand located in somepositionafter R i, which implies that
Rjis concurrent withR i.
2. P jhad replied to R iand P jis now requesting with a lower priority. (Note that in this
case R iand R jare notconcurrent).
3. P j’s requst had higher priority than P i’s (implying that it had ﬁnished the execution of
the CS) and is now requesting with a lower priority. (Note tha t in this case R iand R j
are notconcurrent).
A process P iafter executing the CS, sends a FLUSH message to a process ide ntiﬁed in the
Case 1 above, which has the next highest priority, whereas it sends REPLY messages to
the processes identiﬁed in Cases 2 and 3 as their requests are not concurrent with R i(the
resuests of processes in Cases 2 and 3 were deferred by P itill it exits the CS). Now it is up
to the process receiving the FLUSH message and the processes recieving REPLY messages
inCases 2and 3 todeterminewhoisallowedto entertheCS next .
Consider a scenario where we have a set of requests R 3R0R2R4R1ordered in decreasing
prioritywhere R 0R2R4are concurrentwithoneanother,thenP 0maintainsalocalqueueof
[R0, R2,R4]and when itexitstheCS, itsendsa FLUSH (only)to P 2.
•Multipleuses ofa REQUEST message
Consideringtwoprocesses P iand P j, therecan betwocases:
Case1:Piand P jare not concurrently requesting. In this case, the process w hich requests
ﬁrst willget aREPLY messagefrom theotherprocess.
Case2:Piand P jare concurrentlyrequesting. In thiscase, therecan betwo s ubcases:
1. P iis requesting with a higher priority than P j. In this case, P j’s REQUEST mes-
sage serves as an implicit REPLY message to P i’s request. Also, P jshould wait
forREPLY/FLUSH messagefrom someprocess toentertheCS.
2. P iisrequestingwithalowerprioritythanP j. Inthiscase,P i’sREQUESTmessage
serves as an implicit REPLY message to P j’s request. Also, P ishould wait for
REPLY/FLUSH messagefrom someprocessto entertheCS.
The Algorithm
•Initiallocal stateforprocessP i
-intMy_Sequence_Number i=0
-array ofboolean RVi[j]=0,∀j∈{1...N}
-queue ofReqID LRQ iis NULL
-intHighest_Sequence_Number_Seen i=0
311
•InvMutEx: Process P iexecutesthefollowingtoinvokemutualexclusion:
1.My_Sequence_Number i=Highest_Sequence_Number_Seen i+ 1
2.LRQ i=NULL
3. MakeREQUEST(R i)message, where Ri=(My_Sequence_Number i,i).
4. Insert thisREQUEST in the LRQ iinsortedorder.
5. Send thisREQUEST messageto allotherprocesses.
6.RVi[k]=0∀k∈{1...N}-{i}. RVi[i]=1.
•RcvReq:Process P ireceivesREQUEST(R j), whereR j=(SN, j), from processP j:
1.Highest_Sequence_Number_Seen i=max(Highest_Sequence_Number_Seen i, SN).
2. ifP iisrequesting:
(a)ifRVi[j]=0, theninsertthisrequest inthe LRQ i(in sortedorder) and mark RVi[j]
=1. If(CheckExecuteCS ), then executeCS.
(b)ifRVi[j] = 1, then defer the processing of this request, which will be processed
afterP iexecutesCS.
3. IfP iisnotrequesting,thensendaREPLY(R i)messagetoP j. RidenotestheReqID of
thelastrequest madebyP ithatwas satisﬁed.
•RcvReply : Process P ireceives REPLY(R j) messagefrom process P j: Rjdenotes theReqID
ofthelast requestmadeby P jthat was satisﬁed.
1. RV i[j]=1
2. Removeall requestsfrom LRQ ithat haveapriority ≥thepriorityofR j
3. If(CheckExecuteCS ), then executeCS.
•FinCS:Process P iﬁnishes executingCS.
1. Send FLUSH(R i) message to the next candidate in the LRQ i. Ridenotes the ReqID
that was satisﬁed.
2. Send REPLY(R i) to the deferred requests. R iis the ReqID corresponding to which P i
justexecutedtheCS.
•RcvFlush : Process P ireceives aFLUSH(R j)messagefrom aprocessP j:
1. RV i[j]=1
2. Removeall requestsin LRQ ithathavethepriority ≥thepriorityofR j.
3. If (CheckExecuteCS ) then executeCS.
•CheckExecuteCS : if (RV i[k]=1,∀k∈{1..N}) and P i’s request is at the head of LRQ i, then
return true,elsereturn false.
312
2P1
P
P3
Figure9.11: Processes P1andP2sendout REQUESTs
9.6.3 Safety, Fairnessand Liveness
Prrofs for safety, fairness and liveness are quite involved and interested readers are referred to the
originalpaperfordetailedproofs.
9.6.4 AnExample
Figure9.11: ProcessesP1andP2are concurrent and they send out REQUESTs to all other pro-
cesses. The REQUEST sent by P1toP3is delayed and hence is not shown until in Figure
9.13.
Figure9.12: WhenP3receivestheREQUEST from P2, itsendsREPLY to P2.
Figure9.13: The delayed REQUEST of P1arrives atP3and at the same time, P3sends out its
REQUEST forCS, whichmakes itconcurrent withtherequestof P1.
Figure9.14: P1exitstheCS and sendsoutaFLUSH messageto P2.
Figure9.15: Since the requests of P2andP3are not concurrent, P2 sends a FLUSH message to
P3.P3removes(1,1)from itslocal queueand enters theCS.
ThedatastructuresLRQ and RV areupdatedin each step as disc ussedpreviously.
9.6.5 MessageComplexity
To execute the CS, a process P isends N-1 REQUEST messages. It receives (N- |CSet i|) REPLY
messages. Thereare twocases to consider:
1.|CSet i|≥2. Thereare twosubcases here.
a.There is at least onerequest in CSet iwhose priorityis smallerthan that of R i. So P iwill
send one FLUSH message. In this case the total number of messa ges for CS access is
2N-|CSet i|. When all therequests areconcurrent, thisreduces toN mess ages.
313
2P1
P
P3
Figure9.12: P3sends outREPLY to just P2
1
P1
P
P32enters the CSP
Figure9.13: P3sendsoutREQUEST
2P1
P
P32enters the CSP
1
1P sends a FLUSH message to P
Figure9.14: P1exitstheCS and sendsoutaFLUSH messageto P2
314
2P1
P
P32enters the CSP
1
enters the CSP3
REQUEST from P
REPLY from PREQUEST from P1
REQUEST from P2
3
3
FLUSH messageP2 sends a FLUSH 
message to P3Psends a FLUSH 
1message to P
Figure9.15: P3enters theCS
315
b.There is no request in CSet i, whose priority is less than the priority of R i. Piwill not
send a FLUSH message. In this case, the total number of messag es for CS access is
2N-1-|CSet i|. When alltherequests areconcurrent, thisreduces toN-1 me ssages.
2.|CSet i|=1. Thisistheworstcase,implyingthatallrequestsaresat isﬁedserially. P iwillnot
send a FLUSH message. In this case, the total number of messag es for CS access is 2(N-1)
messages.
9.7 Quorum-BasedMutualExclusionAlgorithms
Quorum-basedmutualexclusionalgorithmsrespresented ad eparturefrom thetrend inthefollow-
ingtwo ways:
1. A site does not request permission from all other sites, bu t only from a subset of the sites.
This is a radically different approach as compared to Lampor t and Ricart-Agrawala algo-
rithms where all sites participate in conﬂict resolution of all other sites. In quorum-based
mutualexclusionalgorithm,therequestsetofsitesarecho sensuchthat∀i∀j:1≤i,j≤N
::Ri∩Rj∝\⌉}atio\slash= Φ. Consequently,everypairofsiteshasasitewhichmediates conﬂictsbetween
thatpair.
2. In quorum-based mutual exclusionalgorithm, a sitecan se nd out only one REPLY message
at any time. A site can send a REPLY message only after it has re ceived a RELEASE
message for the previous REPLY message. Therefore, a site Silocksall the sites in Riin
exclusivemodebeforeexecutingits CS.
Quorum-based mutual exclusion algorithms signiﬁcantly re duce the message complexity of
invokingmutualexclusionby havingsitesask permissionfr omonlyasubsetofsites.
Since these algorithms are based on the notion of ‘Coteries’ and ‘Quorums’, we ﬁrst describe
the idea of coteries and quorums. A coterie Cis deﬁned as a set of sets, where each set g ∈C is
called aquorum. Thefollowingproperties holdforquorumsi n acoterie:
•Intersection property: Foreveryquorumg, h ∈C, g∩h∝\⌉}atio\slash=∅.
For example, sets{1,2,3},{2,5,7}and{5,7,9}cannot be quorums in a coterie because the
ﬁrst and thirdsetsdo nothaveacommonelement.
•Minimality property: There should be no quorums g, h in coterie C such that g ⊇h. For
example, sets {1,2,3} and {1,3} cannot be quorums in a coteri e because the ﬁrst set is a
supersetofthesecond.
Coteries and quorums can be used to develop algorithms to ens ure mutual exclusion in a dis-
tributed environment. A simple protocol works as follows: L et ‘a’ is a site in quorum ‘A’. If ‘a’
wants to invoke mutual exclusion, it requests permission fr om all sites in its quorum ‘A’. Every
316
site does the same to invoke mutual exclusion. Due to the Inte rsection Property, quorum ‘A’ con-
tains at least one site that is common to the quorum of every ot her site. These common sites send
permissionto onlyonesiteat anytime. Thus,mutualexclusi onisguaranteed.
Note that the Minimality property ensures efﬁciency rather than correctness. In the simplest
form,quorumsareformedassetsthatcontainamajorityofsi tes. Thereexistsavarietyofquorums
and a variety of ways to construct quorums. For example, Maek awa used the theory of projective
planesto developquorumsofsize√
N.
9.8 Maekawa’sAlgorithm
Maekawa’s algorithm [14] was the ﬁrst quorum-based mutual e xclusion algorithm. The request
sets for sites (i.e., quorums)in Maekawa’s algorithm are co nstructed to satisfy the following con-
ditions:
M1:(∀i∀j:i∝\⌉}atio\slash=j,1≤i,j≤N:: Ri∩Rj∝\⌉}atio\slash=φ)
M2:(∀i:1≤i≤N::Si∈Ri)
M3:(∀i:1≤i≤N::|Ri|=K)
M4:AnysiteS jiscontainedin KnumberofR is,1≤i,j≤N.
Maekawa used the theory of projective planes and showed that N=K(K−1) + 1. This
relationgives|Ri|=√
N.
Since there is at least one common site between the request se ts of any two sites (condition
M1), every pair of sites has a common site which mediates conﬂ icts between the pair. A site
can have only one outstanding REPLY message at any time; that is, it grants permission to an
incoming request if it has not granted permission to some oth er site. Therefore, mutual exclusion
isguaranteed. Thisalgorithmrequiresdeliveryofmessage stobeintheordertheyaresentbetween
everypairofsites.
ConditionsM1 and M2 are necessary for correctness; whereas conditionsM3 and M4 provide
otherdesirablefeaturestothealgorithm. ConditionM3sta testhatthesizeoftherequestssetsofall
sitesmustbeequalimplyingthatallsitesshouldhavetodoe qualamountofworktoinvokemutual
exclusion.ConditionM4 enforces that exactly thesamenumb erofsites shouldrequest permission
from any site implying that all sites have “equal responsibi lity” in granting permission to other
sites.
9.8.1 The Algorithm
In Maekawa’salgorithm,asite Siexecutesthefollowingstepsto executetheCS.
Requesting the criticalsection
317
(a)AsiteSirequestsaccesstotheCSbysendingREQUEST( i)messagestoallsitesinitsrequest
setRi.
(b)When a site Sjreceives the REQUEST( i) message, it sends a REPLY( j) message to Sipro-
vided it hasn’t sent a REPLY message to a site since its receip t of the last RELEASE mes-
sage. Otherwise,itqueues uptheREQUEST( i) forlaterconsideration.
Executing the criticalsection
(c)SiteSiexecutestheCS onlyafterithas received aREPLY messagefro meverysitein Ri.
Releasingthe critical section
(d)AftertheexecutionoftheCSisover,site SisendsaRELEASE( i)messagetoeverysitein Ri.
(e)Whenasite SjreceivesaRELEASE( i)messagefromsite Si,itsendsaREPLYmessagetothe
next site waiting in the queue and deletes that entry from the queue. If the queue is empty,
then thesiteupdatesits stateto reﬂect that ithas not sento ut anyREPLY messagesincethe
receipt ofthelast RELEASE message.
Correctness
Theorem 3: Maekawa’s algorithmachievesmutualexclusion.
Proof:Proof is by contradiction. Suppose two sites SiandSjare concurrently executing the CS.
This means site Sireceived a REPLY message from all sites in Riand concurrently site Sjwas
able to receive a REPLY message from all sites in Rj. IfRi∩Rj= {Sk}, then siteSkmust have
sentREPLY messagestoboth SiandSjconcurrently,whichisa contradiction. 2
Performance
Note that the size of a request set is√
N. Therefore, an execution of the CS requires√
NRE-
QUEST,√
NREPLY, and√
NRELEASE messages, resulting in 3√
Nmessages per CS execu-
tion. Synchronization delay in this algorithm is 2T. This is because after a site Siexits the CS, it
ﬁrst releases all thesitesin Riand thenone ofthosesites sendsa REPLY messagetothenext si te
that executes theCS. Thus, two sequential messagetransfer s are required between two successive
CS executions. As discussed next, Maekawa’s algorithm is de adlock-prone. Measures to handle
deadlocksrequireadditionalmessages.
9.8.2 Problem ofDeadlocks
Maekawa’salgorithmcan deadlockbecauseasiteisexclusiv elylockedbyothersitesandrequests
arenotprioritizedby theirtimestamps [14, 22]. Thus,asit emay sendaREPLY messageto asite
and laterforceahigherpriorityrequestfrom anothersitet owait.
318
Without theloss ofgenerality, assumethree sites Si,Sj, andSksimultaneouslyinvokemutual
exclusion. Suppose Ri∩Rj={Sij},Rj∩Rk={Sjk},andRk∩Ri={Ski}. Sincesitesdonotsend
REQUEST messages to the sites in their request sets in any par ticular order and message delays
are arbitrary, the following scenario is possible: Sijhas been locked by Si(forcingSjto wait at
Sij),Sjkhasbeenlockedby Sj(forcingSktowaitatSjk), andSkihasbeen lockedby Sk(forcing
Sitowait atSki). Thisstaterepresents adeadlockinvolvingsites Si,Sj, andSk.
Handling Deadlocks
Maekawa’s algorithm handles deadlocks by requiring a site t o yield a lock if the timestamp of
its request is larger than the timestamp of some other reques t waiting for the same lock (unless
the former has succeeded in acquiring locks on all the needed sites) [14, 22]. A site suspects a
deadlock(andinitiatesmessageexchangestoresolveit)wh eneverahigherpriorityrequestarrives
and waitsat asitebecausethesitehas sent aREPLY messageto alowerpriorityrequest.
Deadlock handlingrequiresthefollowingthreetypesofmes sages:
FAILED: A FAILED message from site Sito siteSjindicates that Sican not grant Sj’s request
becauseithas currently grantedpermissionto asitewitha h igherpriorityrequest.
INQUIRE: An INQUIRE message from SitoSjindicates that Siwould like to ﬁnd out from Sj
ifithas succeeded inlockingall thesitesin itsrequestset .
YIELD: A YIELD message from site SitoSjindicates that Siis returning the permission to Sj
(toyield toahigherpriorityrequest at Sj).
DetailsofhowMaekawa’salgorithmhandlesdeadlocksare as follows:
•When a REQUEST( ts,i) from siteSiblocks at site SjbecauseSjhas currently granted
permission to site Sk, thenSjsends a FAILED( j) message to SiifSi’s request has lower
priority. Otherwise, Sjsendsan INQUIRE( j) messageto site Sk.
•In response to an INQUIRE( j) message from site Sj, siteSksends a YIELD( k) message to
SjprovidedSkhas received a FAILED message from a site in its request set or if it sent a
YIELD toanyofthesesites,buthas notreceivedanew GRANT fr omit.
•In response to a YIELD( k) message from site Sk, siteSjassumes as if it has been released
bySk, places the request of Skat appropriate location in the request queue, and sends a
GRANT(j)to thetoprequest’s siteinthequeue.
Thus,Maekawa-typealgorithmsrequireextramessagestoha ndledeadlocksandmayexchange
thesemessageseventhoughthereisnodeadlock. Maximumnum berofmessagesrequiredperCS
executionin thiscaseis5√
N.
319
9.9 Agarwal-ElAbbadiQuorum-BasedAlgorithm
Agarwal and El Abbadi [1] developed a simple and efﬁcient mut ual exclusion algorithm by in-
troducing tree quorums. They gave a novel algorithm for cons tructing tree-structured quorums in
the sense that it uses hierarchical structure of a network. T he mutual exclusion algorithm is inde-
pendent of the underlying topology of the network and there i s no need for a multicast facility in
the network. However, such facility will improve the perfor mance of the algorithm. The mutual
exclusion algorithm assumes that sites in the distributed s ystem can be organized into a structure
such as tree, grid, binary tree, etc. and there exists a routi ng mechanism to exchange messages
between differentsitesin thesystem.
Agarwal-El Abbadi quorum-based algorithm, however, const ructs quorums from trees. Such
quorums are called ‘tree-structured quorums’. The followi ng sections describe an algorithm for
constructing tree-structured quorums and present an analy sis of the algorithm and a protocol for
mutualexclusionindistributedsystemsusingtree-struct uredquorums.
9.9.1 Constructing a tree-structuredquorum
Allthesitesinthesystemarelogicallyorganizedintoacom pletebinarytree. Tobuildsuchatree,
any site could be chosen as the root, any other two sites may be chosen as its children and so on.
For a complete binary tree with level ‘k’, we have 2k+1– 1 sites with its root at level k and leaves
at level 0. The number of sites in a path from the root to a leaf i s equal to the level of the tree
k+1 which is equal to O(log n). There will be 2kleaves in the tree. A path in a binary tree is the
sequencea 1, a2...ai, ai+1.... a ksuchthata iistheparent ofa i+1.
The algorithm for constructing structured quorums from the tree is given in Figure 9.16. For
thepurposeofpresentation,weassumethatthetreeiscompl ete,however,thealgorithmworksfor
anyarbitrary binary tree.
The algorithm for constructing tree-structured quorums us es two functions called GetQuo-
rum(tree) and GrantsPermission(site) and assumes that the re is a well-deﬁned root for the tree.
GetQuorumisarecursivefunctionthattakesatreenode‘x’a stheparameterandcallsGetQuorum
for its child node provided that the GrantsPermission(x) is true. The GrantsPermission(x) is true
onlywhen thenode‘x’agrees tobein thequorum. If thenode‘x ’is downdueto afailure, then it
may not agree to be in the quorum and the value of GrantsPermis sion(x) will be false. The algo-
rithm tries to construct quorums in a way that each quorum rep resents any path from the root to a
leaf, i.e., in this case (no failures) quorum is any set a 1, a2...ai, ai+1..... a kwhere a 1is the root
and a kis a leaf, and for all i <k, aiis the parent of a i+1. If it fails to ﬁnd such a path (say, because
node ’x’ has failed), the control goes to the ELSE block which speciﬁes that the failed node‘x’ is
substituted by two paths both of which start with the left and right children of ‘x’ and end at leaf
nodes. Note that each path must terminate in a leaf site. If th e leaf site is down or inaccessible
due to any reason, then the quorum cannot be formed and the alg orithm terminates with an error
320
FUNCTIONGetQuorum (Tree: NetworkHierarchy): QuorumSet; (*line 1*)
VARleft, right : QuorumSet; (*line 2*)
BEGIN (*line 3*)
IF Empty(Tree) THEN (*line 4*)
RETURN({}); (*line 5*)
ELSEIF GrantsPermission(Tree ↑.Node) THEN (*line 6*)
RETURN((Tree↑.Node)∪GetQuorum (Tree↑.LeftChild)); (*line 7*)
OR (*line 8*)
RETURN((Tree↑.Node)∪GetQuorum (Tree↑.RightChild));(*line 9*)
ELSE (*line 10*)
left←GetQuorum(Tree↑.left); (*line 11*)
right←GetQuorum(Tree↑.right); (*line 12*)
IF(left =∅∨right =∅)THEN (*line 13*)
(* Unsuccessful in establishing aquorum *) (*line 14*)
EXIT(-1); (*line 15*)
ELSE (*line 16*)
RETURN(left∪right); (*line 17*)
END;(*IF *) (*line 18*)
END;(* IF*) (*line 19*)
END;(* IF*) (*line 20*)
ENDGetQuorum (*line 21*)
Figure9.16: Algorithmforconstructingatree-structured quorum.
condition. Thesetsthat areconstructedusingthisalgorit hmare termed as tree quorums .
9.9.2 Analysisof the algorithm forconstructing tree-stru cturedquorums
ThebestcasescenarioofthealgorithmtakesO(logn)sitest oformatreequorum. Therearecertain
cases where even in the event of a failure, O(log n) sites are s ufﬁcient to form a tree quorum. For
example, if the site that is parent of a leaf node fails, then t he number of sites that are necessary
for a quorumwill be stillO(log n). Thus, thealgorithmrequi res very few messages in a relatively
fault-freeenvironment. Itcantoleratethefailureupton- O(logn)sitesandstillformatreequorum.
In the worst case, the algorithm requires the majority of sit es to construct a tree quorum and the
number of sites is same for all cases (faults or no faults). Th e worst case tree quorum size is
determinedas O ((n+1)/2)byinduction.
9.9.3 Validation
The tree quorums constructed by the above algorithm are vali d, i.e., they conform to the coterie
properties such as Intersection property and Minimality Pr operty. To prove the correctness of the
algorithm,considerabinarytreewithlevelk+1. Assumetha trootofthetreeisa 1. Thetreecanbe
viewed as consisting of a root, a left subtree and a right subt ree. According to algorithm in ﬁgure
QBA1,theconstructedquorumscontainoneofthefollowing:
321
1
2 3
4 56 7
8 9 10 11  12 13 14 15
Figure9.17: Atree of15sites
1. a1∪sitesfromtheleft subtree
2. a1∪sitesfromtherightsubtree
3. sitesfromthequorumset ofleft subtree ∪sitesfrom thequorumset ofrightsubtree
Clearly, the quorum of type (1) has non-empty intersection w ith those quorums formed using
types (2) or (3) which shows that the Intersection Property h olds true. Also, the members in
the quorum of type (1) are not contained in quorums of types (2 ) and (3). Thus, the Minimality
Property holds true. Similar conditions exist for quorums o f types (2) and (3). This forms as the
basisforprovingcorrectness ofthealgorithmbased on indu ction.
9.9.4 ExamplesofTree-Structured Quorums
Now we present examples of tree-structured quorums for a bet ter understanding of the algorithm.
In the simplest case, when there is no node failure, the numbe r of quorums formed is equal to the
numberofleafsites.
Consider the tree of height 3 show in Figure 9.17 constructed from 15 (23+1-1) sites. Now, a
quorum has all sites along any path from root to leaf. In this c ase 8 quorums are formed from 8
possible root-leaf paths: 1-2-4-8, 1-2-4-9, 1-2-5-10, 1-2 -5-11, 1-3-6-12, 1-3-6-13, 1-3-7-14 and
1-3-7-15. If any site fails, the algorithm substitutes for t hat site two possible paths starting from
the site’s two children and ending in leaf nodes. For example , when node 3 fails, we consider
the possible paths starting from children 6 and 7 and ending a t the leaf nodes. The possible paths
starting from child 6 are 6-12 and 6-13, while the possible pa ths starting from child 7 are 7-14
and 7-15. So, when node 3 fails, the following eight quorums c an be formed:{1,6,12,7,14},
{1,6,12,7,15},{1,6,13,7,14},{1,6,13,7,15},{1,2,4,8},{1,2,4,9},{1,2,5,10},{1,2,5,11}.
If afailed siteisaleaf node,theoperationhas tobeaborted and atree-structured quorumcan-
not beformed (see lines13-15 ofthealgorithmabove). Howev er,quorumformationcan continue
withotherworkingnodes. Sincethenumberofnodesfromroot toleafinan‘n’nodecompletetree
322
islogn, thebestcase forquorumformation,i.e,theleastnumberof nodesneeded foraquorumis
log n. In theworst case, a majorityofsites(similarto quorumpro tocol[6]) are needed formutual
exclusion. For example, if sites 1 and 2 are down in Figure QBA 1, the quorums that are formed
must include either {4, 8}or{4, 9}and either{5, 10}or{5, 11}and one of the four paths {3, 6,
12},{3,6,13}{3,7,14}or{3,7,15}. Inthiscase, thefollowingarethecandidatesforquorums:
{4,5,3, 6,8,10,12},{4,5, 3,6,8,10, 13},{4, 5,3,6,8, 11,12},{4,5,3,6, 8,11,13},{4,5,3,
6,9, 10,12},{4,5,3,6, 9,10,13},{4,5,3,6, 9,11,12},{4,5,3, 6,9,11,13},{4,5, 3,7,8,10,
14},{4,5,3, 7,8,10,15},{4,5,3, 7,8,11,14},{4,5, 3,7,8,11,15},{4,5, 3,7,9,10, 14},{4,
5, 3,7, 9, 10,15},{4, 5,3, 7, 9,11, 14 }and{4,5, 3,7, 9, 11,15}.
When the number of node failures is greater than or equal to log n, the algorithm may not be
able to form tree-structured quorum. For example when sites 1, 2, 4 and 8 are inaccessible, the
set of sites{3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 }form a majority of sites but not a structured
quorum. So, as long as the number of site failures is less than log n, the tree quorum algorithm
gurantees the formation of a quorum and it exhibits the prope rty of ‘graceful degradation’, which
is useful in distributed fault tolerance. As failures occur and increase, the probability of forming
quorumsdecreasesandmutualexclusionisachievedatincre asingcostsbecausewhenanodefails,
instead of one path from node, the quorum must include two pat hs starting from node’s children.
Forexample,inatreeoflevelk,thesizeofquorumis(k+1). I fanodefailureoccursatleveli >0,
then the quorum size increases to (k-i) +2i. The penalty is se vere when the failed node is near the
root. Thus,thetreequorumalgorithmmaystillallowquorum stobeformedevenafterthefailures
ofn -|logn |sites.
9.9.5 The Algorithm for Distributed MutualExclusion
We now describe the algorithm for achieving distributed mut ual exclusion using tree-structured
quorums. Suppose a site s wants to enter the critical section (CS). The following events should
occurin thegivenorder:
1. Sitessends a‘Request’messagetoall othersitesin thestructure d quorumit belongsto.
2. Each site in the quorum stores incoming requests in a request queue , ordere by their times-
tamps.
3. A sitesends a ‘Reply’ message, indicatingits consent to e nter CS, only to therequest at the
head ofits requestqueue , havingthelowesttimestamp.
4. If the site sgets a ‘Reply’ message from all sites in the structured quoru m it belongs to, it
enters theCS.
5. After exiting the CS, ssends a ‘Relinquish’ message to all sites in the structured q uorum.
On the receipt of the ‘Relinquish’ message, each site remove ss’s request from the head of
itsrequest queue .
323
6. If a new request arrives with a timestamp smaller than the r equest at the head of the queue,
an ‘Inquire’ message is sent to the process whose request is a t the head of the queue and
waitsfora‘Yield’or‘Relinquish’message.
7. When asite sreceivesan ‘Inquire’message,it actsas follows:
Ifshas acquired all of its necessary replies to access the CS, th en it simply ignores the
‘Inquire’messageandproceedsnormallyandsendsa‘Relinq uish’messageafterexitingthe
CS.
Ifshas not yet collected enough replies from its quorum, then it sends a ‘Yield’messageto
theinquiringsite.
8. When a site gets the ‘Yield’ message, it puts the pending re quest (on behalf of which the
‘Inquire’ message was sent) at the head of the queue and sends a ‘Reply’ message to the
requestor.
9.9.6 Correctnessproof
Mutualexclusionisguaranteedbecausethesetofquorumssa tisfytheIntersectionproperty. Proof
for freedom from deadlock is similar to that of Maekawa’s alg orithm. The readers are referred to
theoriginalsource.
9.9.7 AnExample
ConsideracoterieC whichconsistsofquorums {1,2,3},{2,4,5}and{4,1,6}. Supposenodes3, 5
and6wanttoenterCS,andtheysendrequeststosites(1,2),( 2,4)and(1,4),respectively. Suppose
site 3’s request arrives at site 2 before site 5’s request. In this case, site 2 will grant permission to
site3’srequestandrejectsite5’srequest. Similarly,sup posesite3’srequestarrivesatsite1before
site6’srequest. So site1 willgrant permissionto site3’s r equest and reject site6’s request. Since
sites5and6didnotgetconsentfromallsitesintheirquorum s,theydonotentertheCS.Sincesite
3alonegetsconsentfromallsitesinitsquorum,itentersth eCSandmutualexclusionisachieved.
9.10 Token-BasedAlgorithms
In token-based algorithms, a unique token is shared among th e sites. A site is allowed to enter its
CS if it possesses the token. A site holding the token can ente r its CS repeatedly until it sends
the token to some other site. Depending upon the way a site car ries out the search for the token,
there are numerous token-based algorithms. Next, we discus s two token-based mutual exclusion
algorithms.
Before we start with the discussion of token-based algorith ms, two comments are in order:
First, token-based algorithms use sequence numbers instea d of timestamps. Every request for the
tokencontainsasequencenumberandthesequencenumbersof sitesadvanceindependently. Asite
324
increments its sequence number counter every time it makes a request for the token. (A primary
function of the sequence numbers is to distinguish between o ld and current requests.) Second,
correctness proof oftoken-based algorithms,that theyenf orce mutualexclusion,is trivialbecause
an algorithmguarantees mutualexclusionsolongas asiteho ldsthetokenduringtheexecutionof
the CS. Instead, the issues of freedom from starvation, free dom from deadlock, and detection of
thetokenlossand itsregenerationbecomemoreprominent.
9.11 Suzuki-Kasami’sBroadcastAlgorithm
In Suzuki-Kasami’s algorithm [30], if a site that wants to en ter the CS, does not have the token,
it broadcasts a REQUEST message for the token to all other sit es. A site which possesses the
tokensends itto therequestingsiteuponthereceipt ofitsR EQUEST message. Ifasitereceives a
REQUEST messagewhen itisexecutingtheCS, itsendsthetoke n onlyafter ithascompletedthe
executionoftheCS.
The basic idea underlying this algorithm may sound rather si mple, however, there are the fol-
lowingtwo designissuesmustbeefﬁcientlyaddressed:
1.HowtodistinguishinganoutdatedREQUESTmessagefromacur rentREQUESTmes-
sage:Due to variable message delays, a site may receive a token req uest message after the
corresponding request has been satisﬁed. If a site can not de termined if the request corre-
sponding to a token request has been satisﬁed, it may dispatc h the token to a site that does
not need it. This will not violate the correctness, however, this may seriously degrade the
performance by wasting messages and increasing the delay at sites that are genuinely re-
questingthe token. Therefore, appropriatemechanismssho uld implementedto determineif
atokenrequest messageis outdateded.
2.How to determine which site has an outstanding request for th e CS:After a site has
ﬁnished the execution of the CS, it must determine what sites have an outstanding request
for the CS so that the token can be dispatched to one of them. Th e problem is complicated
because when a site Sireceives a token request message from a site Sj, siteSjmay have
an outstanding request for the CS. However, after the corres ponding request for the CS has
been satisﬁedat Sj, anissueishowtoinformsite Si(and allothersites)efﬁciently aboutit.
OutdatedREQUEST messagesaredistinguishedfromcurrent R EQUEST messages
inthefollowingmanner: AREQUESTmessageofsite SjhastheformREQUEST(j,n)where
n (n=1, 2,...) isasequencenumberwhichindicatesthat site Sjisrequestingits nthCS execution.
A siteSikeeps an array of integers RNi[1..N] where RNi[j] denotesthe largest sequence number
received in a REQUEST message so far from site Sj. When site Sireceives a REQUEST(j, n)
message,itsets RNi[j]:=max(RNi[j],n). Thus,whenasite SireceivesaREQUEST(j,n)message,
therequestis outdatedif RNi[j]>n.
Sites with outstandingrequests for the CS are determined in the followingmanner: The token
consists of a queue of requesting sites, Q, and an array of int egers LN[1..N], where LN[j] is the
325
sequencenumberoftherequestwhichsite Sjexecutedmostrecently. AfterexecutingitsCS,asite
SiupdatesLN[i]:= RNi[i]toindicatethatitsrequestcorrespondingtosequencen umberRNi[i]has
beenexecuted. TokenarrayLN[1..N]permitsasitetodeterm ineifasitehasanoutstandingrequest
fortheCS. Notethatatsite SiifRNi[j]=LN[j]+1,thensite Sjiscurrentlyrequestingtoken. After
executing the CS, a site checks this condition for all the j’s to determine all the sites which are
requesting the token and places their id’s in queue Q if these id’s are not already present in the Q.
Finally,thesitesendsthetokentothesitewhoseidisat the head oftheQ.
TheAlgorithm
Requesting the criticalsection
(a)If requesting site Sidoes not have the token, then it increments its sequence numb er,RNi[i],
andsendsaREQUEST(i, sn)messagetoallothersites. (‘ sn’istheupdatedvalueof RNi[i].)
(b)When a site Sjreceives this message, it sets RNj[i] to max(RNj[i],sn). IfSjhas the idle
token,then itsendsthetokento SiifRNj[i]=LN[i]+1.
Executing the criticalsection
(c)SiteSiexecutestheCS afterithas receivedthetoken.
Releasingthe critical section HavingﬁnishedtheexecutionoftheCS, site Sitakesthefollowing
actions:
(d)Itsets LN[i]element ofthetoken array equal to RNi[i].
(e)For every site Sjwhose id is not in the token queue, it appends its id to the toke n queue if
RNi[j]=LN[j]+1.
(f)Ifthetokenqueueisnonemptyaftertheaboveupdate, Sideletesthetopsiteidfromthetoken
queueandsends thetoken tothesiteindicatedby theid.
Thus, after executing the CS, a site gives priority to other s ites with outstanding requests for the
CS (over its pending requests for the CS). Note that Suzuki-K asami’s algorithm is not symmetric
because a site retains the token even if it does not have a requ est for the CS, which is contrary to
thespiritofRicart and Agrawala’s deﬁnitionofsymmetrica lgorithm: “no sitepossessestheright
toaccess itsCS when ithasnot been requested” .
326
Correctness
Mutual exclusion is guaranteed because there is only one tok en in the system and a site holds the
tokenduringtheCS execution.
Theorem: ArequestingsiteenterstheCS inﬁnitetime.
Proof:Tokenrequest messagesofasite Sireach othersitesinﬁnitetime. Sinceoneofthesesites
will have token in ﬁnite time, site Si’s request will be placed in the token queue in ﬁnite time.
Since there can be at most N−1requests in front of this request in the token queue, site Siwill
get thetoken andexecutetheCS inﬁnitetime. 2
Performance
BeautyofSuzuki-Kasamialgorithmliesinitssimplicityan defﬁciency. Nomessageisneededand
the synchronization delay is zero if a site holds the idle tok en at the time of its request. If a site
does not hold the token when it makes a request, the algorithm requiresNmessages to obtain the
token. Synchronizationdelay inthisalgorithmis 0 or T.
9.12 Raymond’sTree-BasedAlgorithm
Raymond’s Tree-Based mutual exclusion algorithm [19] uses a spanning tree of the computer
networktoreducethenumberofmessagesexchangedpercriti calsectionexecution. Thealgorithm
exchangesonlyO(logN)messagesunderlightload,andappro ximatelyfourmessagesunderheavy
loadto executetheCS, where Nis thenumberofnodesinthenet work.
The algorithm assumes that the underlying network guarante es message delivery. The time or
order of message arrival cannot be predicted. All nodes of th e network are ’completely reliable.
(Only for the initial part of the discussion, i.e., until nod e failure is discussed.). If the network
is viewed as a graph, where the nodes in the network are the ver tices of the graph, and the links
betweennodesaretheedgesofthegraph,aspanningtreeofan etworkofNnodeswillbeatreethat
containsall theN nodes. A minimalspanningtree is onesuch t ree withminimumcost. Typically,
thiscostfunctionisbasedonthenetworklinkcharacterist ics. Thealgorithmoperatesonaminimal
spanningtreeofthenetwork topologyoralogicalstructure imposedon thenetwork.
The algorithm considers the network nodes to be arranged in a n unrooted tree structure as
shown in Figure 9.18. Messages between nodes traverse along the undirected edges of the tree in
theFigure9.18. Thetree isalsoaspanningtreeofthesevenn odes A,B, C, D, E,F, and G. It also
turnsouttobeaminimalspanningtreebecauseitistheonlys panningtreeofthesesevennodes. A
node needs to hold informationabout and communicateonly to its immediate-neighboringnodes.
In Figure 9.18, for example, node C holds information about a nd communicates only to nodes B,
D, and G; it does not need to know about the other nodes A, E, and F for the operation of the
algorithm.
327
BC D
E FGA
Figure9.18: Nodes withan unrootedtreestructure.
Similar to the concept of tokens used in token-based algorit hms, this algorithm uses a concept of
privilegetosignifywhichnodehastheprivilegetoenterth ecriticalsection. Onlyonenodecanbe
in possession of the privilege (called the privileged node) at any time, except when the privilege
is in transit from one node to another in the form of a PRIVILEG E message. When there are no
nodesrequestingfortheprivilege,itremains inpossessio nofthenodethat lastusedit.
9.12.1 The HOLDERVariables
Each node maintains a HOLDER variable that provides informa tion about the placement of the
privilegeinrelationtothenodeitself. Anodestoresinits HOLDERvariabletheidentityofanode
thatitthinkshastheprivilegeorleadstothenodehavingth eprivilege. TheHOLDERvariablesof
allthenodesmaintaindirectedpathsfromeachnodetotheno deinthepossessionoftheprivilege.
For two nodes X and Y, if HOLDER X= Y, we could redraw the undirected edge between the
nodes X and Y as a directed edge from X to Y. Thus, for instance, if node G holds the privilege,
Figure9.18can beredrawn withlogicallydirected edgesas s hownintheFigure.
Theshaded nodeaboverepresents theprivilegednode. Thefo llowingwillbethevaluesofthe
HOLDERvariablesofvariousnodes:
HOLDER A=B (Since theprivilegeislocated inasub-treeofA denotedb yB.)
Proceeding withsimilarreasoning,wehave
HOLDER B=C
HOLDER C=G
HOLDER D=C
HOLDER E= A
HOLDER F=B
HOLDER G=self
Now suppose node B that does not hold the privilege wants to ex ecute the critical section.
ThenBsendsaREQUEST messageto HOLDER B, i.e.,C, whichinturn forwardstheREQUEST
messagetoHOLDER C,i.e.,G.SoaseriesofREQUESTmessagesﬂowbetweenthenode making
therequestfortheprivilegeand thenodehavingtheprivile ge.
TheprivilegednodeG,ifitnolongerneedstheprivilege,se ndsthePRIVILEGEmessagetoits
328
BC D
E FGA
Figure 9.19: Tree with logically directed edges, all pointi ng in a direction towards node G - the
privilegednode.
GC D
E FAB
Figure 9.20: Tree with logically directed edges, all pointi ng in a direction towards node G - the
privilegednode.
neighbor C, which made a request for the privilege, and reset s HOLDER Gto C. Node C, in turn,
forwards the PRIVILEGE to node B, since it had requested the p rivilege on behalf of B. Node C
alsoresets HOLDER Cto B. ThetreeinFigure9.19 willnowlookasin Figure9.20
Thus, at any stage, except when the PRIVILEGE message is in tr ansit, the HOLDER variables
collectively make sure that directed paths are maintained f rom each of the N - 1 nodes to the
privilegednodein thenetwork.
9.12.2 The Operationof the Algorithm
Data Structures
Thealgorithmrequires each nodetomaintainthefollowingv ariables:
VariableName PossibleValues Comments
HOLDER“self”ortheidentityofoneof
theimmediateneighbours.Indicates the location of the
privileged node in relation to
thecurrent node.
329
USING Trueorfalse.Indicatesifthecurrentnodeis
executingthecritical section.
REQUEST_QA FIFO queue thatcould con-
tain “self” or the identities of
immediate neighbors as ele-
ments.The REQUEST_Q of a node
consists of the identities of
those immediate neighbors
that have requested for privi-
legebuthavenotyetbeensent
theprivilege.
ASKED Trueorfalse.Indicatesifnodehassentare-
quest fortheprivilege.
Thevalue“self”isplaced inREQUEST_Qifthenodemakesareq uestfortheprivilegeforits
ownuse. ThemaximumsizeofREQUEST_Qofanodeisthenumbero fimmediateneighbors+1
(for “self”). ASKED preventsthe sendingof duplicatereque sts for privilege,and also makes sure
thattheREQUEST_Qs ofthevariousnodesdo notcontainany du plicateelements.
The Algorithm
Thealgorithmconsistsofthefollowingparts:
•ASSIGN_PRIVILEGE
•MAKE_REQUEST
•Events
•MessageOvertaking
ASSIGN_PRIVILEGE
This is a routine to effect the sending of a PRIVILEGE message . A privileged node will send a
PRIVILEGE messageif
•itholdstheprivilegebutisnot usingit,
•itsREQUEST_Q isnotempty,and
•the element at the head of its REQUEST_Q is not “self.” That is , the oldest request for
privilegemusthavecomefromanothernode.
330
A situation where “self” is at the head of REQUEST_Q may occur immediately after a node
receivesaPRIVILEGEmessage. Thenodewillenterintothecr iticalsectionafterremoving“self”
from the head of REQUEST_Q. If the id of another node is at the h ead of REQUEST_Q, then it
is removed from the queue and a PRIVILEGE message is sent to th at node. Also, the variable
ASKED is set to false since the currently privileged node wil l not have sent a request to the node
(called HOLDER-to-be)whichis abouttoreceivethePRIVILE GE message.
MAKE_REQUEST
This is a routine to effect the sending of a REQUEST message. A n unprivilegednode will send a
REQUEST messageif
•itdoes notholdtheprivilege,
•its REQUEST_Q is not empty, i.e., it requires the privilegef or itself, or on behalf of one of
itsimmediateneighboringnodes,and
•ithas notsent aREQUEST messagealready.
ThevariableASKEDissettotruetoreﬂectthesendingoftheR EQUESTmessage. TheMAKE_REQUEST
routinemakes no change to anyother variables. The variable ASKED will betrue at a nodewhen
it has sent REQUEST message to an immediate neighbor and has n ot received a response. The
variablewillbefalseotherwise. AnodedoesnotsendanyREQ UESTmessages,ifASKEDistrue
at that node. Thus thevariableASKED makes surethat unneces sary REQUEST messages are not
sentfromtheunprivilegednode,andconsequentlyensurest hattheREQUEST_Qofanimmediate
neighbordoesnotcontainduplicateentriesofaneighbouri ngnode. ThismakestheREQUEST_Q
ofanynodebounded,evenwhenoperating underheavy load.
Events
Below weshowfoureventsthatconstitutethealgorithm.
Event AlgorithmFunctionality
A nodewishesto executecriticalsection.Enqueue(REQUEST_Q, self); AS-
SIGN_PRIVILEGE; MAKE_REQUEST
A node receives a REQUEST message from
oneofitsimmediateneighborsX.Enqueue(REQUEST_Q, X); AS-
SIGN_PRIVILEGE; MAKE_REQUEST
331
A nodereceivesa PRIVILEGE message.HOLDER := self; ASSIGN_PRIVILEGE;
MAKE_REQUEST
A nodeexitsthecritical section.USING := false; ASSIGN_PRIVILEGE;
MAKE_REQUEST
A node wishes critical section entry: If it is the privileged node, the node could enter the
critical section using the ASSIGN_PRIVILEGE routine. If no t, the nodecould send a REQUEST
messageusingtheMAKE_REQUESTroutinein ordertoget thepr ivilege.
AnodereceivesaREQUESTmessagefromoneofitsimmediatene ighbors: Ifthisnodeis
thecurrentHOLDER,itmaysendthePRIVILEGEtoarequesting nodeusingtheASSIGN_PRIVILEGE
routine. Ifnot,it couldforward therequestusingtheMAKE_ REQUESTroutine.
A node receives a PRIVILEGE message: The ASSIGN_PRIVILEGE routine could result
in the execution of the critical section at the node, or may fo rward the privilege to another node.
Aftertheprivilegeisforwarded, theMAKE_REQUESTroutine couldsendaREQUESTmessage
toreacquire theprivilege,forapendingrequestat thisnod e.
A node exits the critical section: On exit from the critical section, this node may pass the
privilege on to a requesting node using the ASSIGN_PRIVILEG E routine. It may then use the
MAKE_REQUESTroutineto get back theprivilege,forapendin grequest at thisnode.
MessageOvertaking
Thisalgorithmdoesawaywiththeuseofsequencenumbersbec auseofitsinherentoperation. The
algorithm works such that message ﬂow between any two neighb oring nodes sticks to a logical
pattern asshownintheFigure9.21.
If at all message overtaking occurs between the nodes A and B, it can occur when a PRIVI-
LEGEmessageissentfromnodeAtonodeB,whichisthenverycl oselyfollowedbyaREQUEST
messagefromnodeAtonodeB.Inotherwords,nodeAsendsthep rivilegeandimmediatelywants
itback. Suchmessageovertakingasdescribedabovewillnot affecttheoperationofthealgorithm.
IfnodeBreceivestheREQUESTmessagefromnodeAbeforerece ivingthePRIVILEGEmessage
from node A, A’s request will be queued in REQUEST_Q B. Since B is not a privileged node, it
will not be able to send a privilege to node A in reply. When nod e B receives the PRIVILEGE
messagefromAafterreceivingtheREQUESTmessage,itcould enterthecriticalsectionorcould
sendaPRIVILEGEmessagetoanimmediateneighboratthehead ofREQUEST_Q B,whichneed
notbenodeA. So messageovertakingdoes notaffect thealgor ithm.
332
       <pattern repeats>Node A    <−−−−  REQUEST   −−−−     Node B 
Node A    −−−−   PRIVILEGE −−−−>   Node B 
Node A    −−−−    REQUEST   −−−−>   Node B 
Node A    <−−−− PRIVILEGE −−−−     Node B
Figure9.21: Logical patternofmessageﬂow between neighbo ringnodes Aand B
9.12.3 Correctness
Thealgorithmprovidesthefollowingguarantees:
•Mutualexclusionisguaranteed
•Deadlock isimpossible
•Starvationisimpossible
Mutual ExclusionisGuaranteed
Thealgorithmensuresthatatanyinstantoftime,notmoreth anonenodeholdstheprivilege,which
isanecessityformutualexclusion. Wheneveranodereceive saPRIVILEGEmessage,itbecomes
privileged. Similarly, whenever a node sends a PRIVILEGE me ssage, it becomes unprivileged.
Between the instants one node becomes unprivileged and anot her node becomes privileged, there
isnoprivilegednode. Thus,thereisatmostoneprivilegedn odeatanypointoftimeinthenetwork.
Deadlock is Impossible
When the critical section is free, and one or more nodes want t o enter the critical section but are
notableto doso,a deadlockmay occur. Thiscouldhappen duet oany ofthefollowingscenarios:
1. Theprivilegecannotbetransferred toanodebecauseno no deholdstheprivilege.
2. The node in possession of the privilege is unaware that the re are other nodes requiring the
privilege.
333
3. ThePRIVILEGE messagedoesnotreach therequestingunpri vilegednode.
Noneoftheabovethreescenarioscanoccurinthisalgorithm ,thusguardingagainstdeadlocks.
The scenario 1 can never occur in this algorithm because we ha ve assumed that nodes do not fail
andmessagesarenotlost. Therecanneverbeasituationwher eREQUESTmessagesdonotarrive
at the privileged node. The logical pattern established usi ng HOLDER variables ensures that a
nodethat needs theprivilegesends aREQUEST messageeither to anodeholdingtheprivilegeor
to a node that has a path to a node holding the privilege. Thus s cenario 2 can never occur in this
algorithm. TheseriesofREQUESTmessagesareenqueuedinth eREQUEST_Qsofvariousnodes
suchthattheREQUEST_Qsofthosenodescollectivelyprovid ealogicalpathforthetranferofthe
PRIVILEGE message from the privilegednode to the requestin g unprivilegednodes. So scenario
3 can neveroccurin thisalgorithm.
Starvationis Impossible
When a node A holds the privilege, and another node B requests for the privilege, the identity of
B or the id’s of proxy nodes for node B will be present in the REQ UEST_Qs of various nodes
in the path connecting the requesting node to the currently p rivileged node. So depending upon
the position of the id of node B in those REQUEST_Qs, node B wil l sooner or later receive the
privilege. Thus once node B’s REQUEST message reaches the pr ivileged node A, node B,is sure
toreceivetheprivilege.
To better illustrate, let us consider Figure 9.20. Node B is t he current holder of the privilege.
Suppose that node C is already at the head of REQUEST_Q B. Assume that the REQUEST_Qs
of all other nodes are empty. Now if node E wants to enter the cr itical section, it will send a RE-
QUEST message to its immediate neighbor, node A. We will show that node E does not starve.
AssumethatBisexecutingthecriticalsectionbythetimeE’ sREQUESTispropagatedtonodeB.
At thisinstance, theREQUEST_Qs ofE, A,and Bwillbeas follo ws:
REQUEST_Q E=self,
REQUEST_Q A=E,
REQUEST_Q B=C, A
When node B exits the critical section, it removes the node at the head of REQUEST_Q B, i.e.,
nodeC, andsendtheprivilegetonodeC.NodeBwillthensenda REQUEST tonodeConbehalf
ofnodeA, which requested privilegeon behalf ofnodeE. Afte r nodeC receivesthe privilegeand
completes executing the critical section, the REQUEST_Qs o f nodes C, B, A, and E will look as
follows:
REQUEST_Q C=B,
REQUEST_Q B=A,
REQUEST_Q A=E,
334
REQUEST_Q E=self
Now, the next node to receive the privilege will be node E, a fa ct that is represented by the logi-
cal path “BAE” that the REQUEST_Qs of nodes C, B, and A form. Si nce node B had requested
privilege on behalf of node A, and node A on behalf of node E, th e PRIVILEGE ultimately gets
propagatedtonodeE. Thus,anodeneverstarves.
9.12.4 Cost andPerformance Analysis
Thealgorithmexhibitsthefollowingworst-casecost: (2*l ongestpathlengthofthetree)messages
per critical section entry. This happens when the privilege is to be passed between nodes at either
ends of the longest path of the minimal spanning tree. Thus th e worst possible network topology
for this algorithm will be one where all nodes are arranged in a straight line. In a straight line
the longest path length will be N – 1, and thus the algorithm wi ll exchange 2 * (N – 1) messages
per CS execution. However, if all nodes generate equal numbe r of REQUEST messages for the
privilege,the average numberof messages needed per critic al section entry will beapproximately
2N/3becausetheaveragedistancebetweena requestingnode and aprivilegednodeis (N +1)/3.
The best topology for the algorithm is the radiating star top ology. The worst case cost of this
algorithmforthistopologyisO(log K−1N).Evenamongradiatingstartopologies,treeswithhigher
fan-outs are preferred. The longest path length of such tree s is typically O(log N). Thus, on an
average, thisalgorithminvolvestheexchangeofO(logN)me ssagespercriticalsectionexecution.
When under heavy load, the algorithm exhibits an interestin g property. “As the number of
nodesrequestingfortheprivilegeincreases,thenumberof messagesexchangedpercriticalsection
entry decreases.” In fact, it requires the exchange of only f our messages per CS execution as
explainedbelow.
When all nodes are sending privilege requests, PRIVILEGE me ssages travel along all N – 1
edgesoftheminimalspanningtreeexactlytwicetogivethep rivilegetoallNnodes. Eachofthese
PRIVILEGE messages travel in response to a REQUEST message. Thus, a total of 4 * (N – 1)
messagestravelacrosstheminimalspanningtree. Hence,th etotalnumberofmessagesexchanged
percritical sectionexecutionis4(N-1)/N, whichis approx imately4.
9.12.5 Algorithm Initialization
Algorithminitializationbeginswithonenodebeingchosen astheprivilegednode. Thisnodethen
sendsINITIALIZE messagestoitsimmediateneighbors. Onre ceivingtheINITIALIZE message,
a node sets its HOLDER variable to the node that sent the INITI ALIZE message, and send INI-
TIALIZE messages to its own immediate neighbors. Once INITI ALIZE message is received, a
nodecan startmakingprivilegerequestseveniftheentiret reeisnotinitialized.
Theinitializationofthefollowingvariablesis thesameat allnodes:
USING:=false
335
ASKED:=false
REQUEST_Q :=empty.
9.12.6 Node Failures and Recovery
If a node fails, lost information can be reconstructed on res tart. Once a node restarts, it enters
into a recovery phase and selects a delay period for the recov ery phase in order to get back all the
lost information. It sends RESTART messages to its immediat eneighbors and waits for ADVISE
messages. During the recovery phase, the node can still rece ive REQUEST and PRIVILEGE
messages; it acts as any normal node would act in response to t hose messages except that AS-
SIGN_PRIVILEGE and MAKE_REQUESTroutinesarenot executed .
TheADVISEmessagethatarecoveringnodeAreceivesfromeac himmediateneighborBwill
contain information on the HOLDER, ASKED, and REQUEST_Q var iables of B, from which A
can reconstruct itsownHOLDER, ASKED,and REQUEST_Q variab les.
For example, if HOLDER B= A for all immediate neighbors B of node A, it means node A
holds the privilege, and hence HOLDER A= self. Similar reasoning can be applied to determine
value of ASKED Aand the elements of REQUEST_Q A. REQUEST_Q Acan be reconstructed but
the elements may not be in proper order. To ensure proper orde r, the ADVISE messages could
providereal orlogicaltimestampsforitsREQUEST messages . USING Acan besetto false.
The recovering node’s REQUEST_Q can have duplicates if it pr ocesses REQUEST messages
sent currently and the ones it receives in the ADVISE message s. However, this does not affect
the working of the algorithm as long as the REQUEST_Q is large enough to accommodate such
situations. A node can also possibly fail when recovering fr om an earlier failure. In such a case,
ASSIST messages related to the ﬁrst recovery phase can be ide ntiﬁed by making use of the delay
chosen forrecoveryoruniqueidentiﬁers,and thosemessage s can bediscarded.
9.13 BibliographicNotes
Singhal gives a taxonomy on distributed mutual exclusion in [24]. Raynal presents a survey of
mutualexclusionalgorithmsinn[20]. Alargenumberoftoke n-basedmutualexclusionalgorithms
haveappearedinlastseveralyears,e.g.,mutualexclusion algorithmsbyAhamadandBernabeu[2],
Helaryetal.[10],NaimiandTrehel[15],Chang-Singhal-Li u[6],andNeilsenandMizuno[16]. In
[23],SaxenaandRaipresentasurveyofpermission-baseddi stributedmutualexclusionalgorithms.
Nishio et al. [18] presented a technique for generation of un ique token in case of a token loss.
A dynamic heuristic-based token mutual exclusion algorith m is given in [27]. Snepscheut [31]
extended tree-based algorithmsto handlea connected netwo rk of any topology(i.e., graphs). Due
to network topology, such algorithm is fault-tolerant to si te and link failures. Chang-Singhal-Liu
[7]presentafault-tolerantmutualexclusionalgorithm. G oscinski[8]haspresentedtwomutualex-
clusion algorithms for real-time distributed systems. Cot erie based mutual exclusion algorithms,
which are a generalization of Maekawa’s√
Nalgorithm, have lately attracted considerable at-
336
tention. Barbara and Garcia-Molina [9] and Ibaraki and Kame da [11] have discussed theoretical
aspects of coteries. Cao and Singhal developed a delay optim al coterie-based mutual exclusion
algorithm[5].
Sanders[22]gavetheconceptofinformationstructurestod evelopageneralizedmutualexclu-
sionalgorithm.
9.14 ExerciseProblems
1. Consider the following simple method to enforce mutual ex clusion: All sites are arranged
in a logical ring fashion and a unique token circulates aroun d the ring hopping from a site
to another site. When a site needs to executes its CS, it waits for the token, grabs the token,
executes the CS, and then dispatches the token to the next sit e on the ring. If a site does
notnnedthetokenonitsarrival,itimmediatelydispatches thetokentothenextsite(in zero
time).
(i)What isthereponsetimewhen theloadislow?
(ii)Whatis thereponsetimewhen theload isheavy?
AssumethereareN sites,themessage/tokendelay isT, andCS axecutiontimeisE.
2. In Lamport’s algorithm Condition L1 can hold concurrentl y at several sites. Then why do
weneed thisconditionforguaranteeing mutualexclusion.
3. Show that in Lamport’s algorithm if a site Siis executing the critical section, then Si’s
requestneed notbeat thetopofthe request_queueatanothersite Sj. Isthisstilltruewhen
thereareno messagesin transit?
4. WhatisthepurposeofaREPLY messageinLamport’salgorit hm? Notethatitis notneces-
sary that a site must always return a REPLY message in respons e to a REQUEST message.
State the condition under which a site does not have to return REPLY message. Also, give
thenewmessagecomplexitypercritical sectionexecutioni n thiscase.
5. Show that in Ricart-Agrawala algorithm the critical sect ion is accessed in the increasing
orderoftimestamps. Doesthesamehold inMaekawa’salgorit hm?
6. Mutualexclusioncanbeachievedusingthefollowingsimp lemethodinadistributedsystem
(called the“centralized"mutualexclusionalgorithm):
To access the shared resource, a site sends the request to the site that contains the re-
source. Thissiteexecutestherequestsusinganyclassical methodsformutualexclusion(like
semaphores). Discuss what prompted Lamport’s mutual exclu sionalgorithm even though it
requires manymoremessages(3( N−1)ascompared to only3).
337
7. Show that in Lamport’s algorithm the critical section is a ccessed in the increasing order of
timestamps.
8. Show by examples that the staircase conﬁguration among si tes is preserved in Singhal’s
dynamic mutual exclusion algorithm when two or more sites re quest the CS concurrently
and haveexecutedtheCSs.
338
Bibliography
[1] D.AgrawalandA.E. Abadi, AnefﬁcientsolutiontothedistributedMutualExclusionpr oblem,
Proc. ACM Symp. PrinciplesDistributedComput.(PODC’89)
[2] Bernabeu-Auban, J.M., and M.Ahamad, “ApplyingaPath-c ompressionTechniqueto Obtain
an Effective Distributed Mutual Exclusion Algorithm”, Proc. of 3rdInternational Workshop
onDistributedAlgorithms ,Sept. 1989.
[3] Buckley, G, and A. Silberschatz, “ A Failure Tolerant Cen tralized Mutual Exclusion Algo-
rithm”,Proc. of the 4thInternational Conference on Distributed Computing System s, May
1984.
[4] Carvalho, O. S. F., and G. Roucairol, “On Mutual Exclusio n in Real-Time Distributed Com-
putingSystems,Technical Correspondence", Communicatio nsoftheACM, Feb 1983.
[5] G. Cao and M. Singhal, “A Delay-Optimal Quorum-Based Mut ual Exclusion Algorithm for
DistributedSystems", IEEETransactionsonParallelandDistributedSystems ,Vol12,No.12,
pp.1256-1268,Dec. 2001.
[6] Y.Chang,M.Singhal,andMikeLiu,“ADynamicToken-Base dDistributedMutualExclusion
Algorithm”,intheProc.ofthe10thIEEEInternationalPhoe nixConferenceonComputerand
Communications,March 1991,pp.240-246.
[7] Y. Chang, M. Singhal, and Mike Liu, “A Fault-Tolerant Mut ual ExclusionAlgorithm for Dis-
tributed Systems”, in the Proc. of the 9th Symposium on Relia ble Distributed Software and
Systems,October1990,pp.146-154.
[8] A. Goscinski, “Two Algorithms for Mutual Exclusion in Re al-Time Distributed Computing
Systems”,JournalofParallel and DistributedComputing,V ol. 9,1990.
[9] Garcia-Molina, H., and D. Barbara, “How to Assign Votes i n a Distributed System”, Journal
oftheACM, 1985.
[10] Helary M, Plouzeau N, and Raynal M, A Distributed algori thm for mutual exclusion in an
arbitrary network,Comput.J. 31,4(1988).
339
[11] Ibaraki, T., and T. kameda, “Theory of Coteries”, Techn ical Report, CSS/LCCR TR90-09,
UniversityofKyoto,Kyoto,Japan, 1990.
[12] Lamport, L., “Time, Clocks and Ordering of Events in Dis tributed Systems”, Communica-
tionsoftheACM, July1978.
[13] Sandeep Lodha and Ajay Kshemkalyani, A Fair Distribute d Mutual Exclusion Algorithm,
IEEE Transactions on Parallel and Distributed Systems, Vol ume 11 , Issue 6 (June 2000),
Pages: 537 -549.
[14] Maekawa, M., “A sqrtNAlgorithm for Mutual Exclusion in Decentralized Systems”, ACM
Transactionson ComputerSystems,May 1995.
[15] Naimi, M., and M. Trehel, “An Improvementof the logNDistributed Algorithmfor Mutual
Exclusion”, Proc. of the 7th International Conference on Di stributed Computing Systems”,
Sept. 23-25,1987.
[16] NeilsenM.L.,andM.Mizuno,“ADAG-BasedAlgorithmfor DistributedMutualExclusion,
“ Proc. of the 11th International Conference on Distributed Computing Systems, May 21-23,
1991.
[17] MikhailNesterenkoandMasaakiMizuno,AQuorum-Based Self-StabilizingDistributedMu-
tual Exclusion Algorithm,Journal of Parallel and Distribu tedComputing, Volume 62, Issue 2
, February 2002,Pages 284-305.
[18] Nishio, S., K. F. Li, and E. G. Manning, “ A Resilient Mutu al Exclusion Algorithm for
ComputerNetworks”, IEEETrans. onParallel and Distribute dSystems,July1990.
[19] Raymond, K., “ Tree-Based Algorithm for Distributed Mu tual Exclusion”, ACM Transac-
tionsonComputerSystems,vol.7,Feb. 1989,pp.61-77.
[20] Raynal, M., “ A SimpleTaxonomy ofDistributedMutualEx clusionAlgorithms”,Operating
SystemsReview.April1991.
[21] G.Ricart and A.K.Agrawala, An optimal algorithm for Mu tual Exclusion in Computer Net-
works,CommunicationsoftheACM,1981
[22] Sanders,B.,“TheinformationStructureofDistribute dMutualExclusionAlgorithms”,ACM
Trans.on ComputerSystems,Aug.1987.
[23] P. C. Saxena and J. Rai, A survey of permission-based dis tributed mutual exclusion algo-
rithms,ComputerStandards &Interfaces, Volume25,Issue2 ,May 2003,Pages 159-181.
[24] M. Singhal, “A Taxonomy of Distributed Mutual Exclusio n”,Journal on Parallel and Dis-
tributedComputing ,May 1993,Vol18 no.1, pp.94-101.
340
[25] Mukesh Singhal, A Dynamic Information-Structure Mutual Exclusion Algorit hm for Dis-
tributed Systems , IEEE Transactions on Parallel and Distributed Systems, Vo l. 3, No. 1, Jan
1992.
[26] Mukesh Singhal, “A Class of Deadlock-Free Maekawa Type Mutual Exclusion Algorithms
forDistributedSystems”, DistributedComputing ,February 1991, Vol4, No3, pp.131-138.
[27] MukeshSinghal,“AHeuristically-AidedAlgorithmfor MutualExclusioninDistributedSys-
tems”,IEEE Transactionson Computers ,May1989,Vol 38,No. 5,pp. 651-662.
[28] Mukesh Singhal, “A Dynamic Information Structure Mutu al Exclusion Algorithm for Dis-
tributedSystems”,intheProceedingsofthe9thInternatio nalConferenceonDistributedCom-
putingSystems,June5-9, 1989,NewportBeach, CA, pp.70-78 .
[29] Mukesh Singhal, A Dynamic Information-Structure Mutu al Exclusion Algorithm for Dis-
tributed Systems, IEEE Transactions on Parallel and Distri buted Systems, Vol. 3, No. 1, Jan
1992
[30] Suzuki, I., and T. Kasami, “A Distributed Mutual Exclus ion Algorithm”, ACM Trans. on
ComputerSystems,Nov,1985.
[31] Vas de Snepscheut, J. L. A., “Fair Mutual Exclusion on a G raph of Processes”, Distributed
Computing,vol.2, Aug.1987,pp. 113-115.
[32] R.H Thomas, A majority consensus approach to concurren cy control for multiple copy
databases, ACMTransactionon DatabaseSystems,1979.
341
Chapter10
Deadlock Detectionin DistributedSystems
10.1 Introduction
Deadlocks is a fundamental problem in distributed systems a nd deadlock detection in distributed
systems has received considerable attention in the past. In distributed systems, a process may re-
quest resources in any order, which may not be knowna priori a nd a process can request resource
while holding others. If the sequence of the allocations of r esources to the processes is not con-
trolledinsuchenvironments,deadlockscanoccur. Adeadlo ckcanbedeﬁnedasaconditionwhere
aset ofprocessesrequest resources thatare heldby otherpr ocessesin theset.
Deadlock deals with various components like deadlock preve ntion, deadlock avoidance other
then deadlock detection. Deadlock prevention is commonly a chieved by either having a process
acquire all the needed resources simultaneously before it b egins execution or by preempting a
processthatholdtheneededresource. Inthedeadlockavoid anceapproachtodistributedsystem,a
resource is granted to a process if the resultingglobal syst em is safe. Deadlock detection requires
an examination of the status of the process-resources inter action for the presence of a deadlock
condition. To resolvethedeadlock,wehavetoabort adeadlo ckedprocess.
In this chapter, we study several distributed deadlock dete ction techniques based on various
strategies.
10.2 SystemModel
A distributed system consists of a set of processors that are connected by a communication net-
work. The communication delay is ﬁnite but unpredictable. A distributed program is composed
of a set of n asynchronous processes p 1, p2, ..., p i, ..., p nthat communicates by message pass-
ing over the communication network. Without loss of general ity we assume that each process is
runningonadifferentprocessor. Theprocessorsdonotshar eacommonglobalmemoryandcom-
municatesolelybypassingmessagesoverthecommunication network. Thereisnophysicalglobal
clock in the system to which processes have instantaneous ac cess. The communication medium
maydelivermessagesoutoforder, messagesmaybelostgarbl edorduplicatedduetotimeoutand
342
retransmission, processors may fail and communication lin ks may go down. The system can be
modeledasadirectedgraphinwhichverticesrepresentthep rocessesandedgerepresentunidirec-
tionalcommunicationchannels.
We makethefollowingassumptions:
•Thesystemshaveonlyreusableresources.
•Processes are allowedtomakeonlyexclusiveaccess toresou rces.
•Thereisonly onecopy ofeach resource.
A process can be in two states: runningorblocked. In the running state (also called active
state), a process has all the needed resources and is either e xecuting or is ready for execution. In
theblockedstate,a processis waitingto acquiresomeresou rce.
10.2.1 Wait-For-Graph(WFG)
In distributed systems, the state of the system can be modele d by directed graph, called a wait for
graph(WFG). In a WFG , nodes are processes and there is a directed ed ge from node P 1to mode
P2if P1is blocked and is waiting for P 2to release some resource. A system is deadlocked if and
onlyifthereexistsadirected cycleorknotintheWFG.
Figure 10.1 shows a WFG, where process P 11of site 1 has an edge to process P 21of site 1
and P 32of site 2 is waiting for a resource which is currently held by p rocess P 21. At the same
time process P 32is waiting on process P 33to release a resource. If P 21is waiting on process P 11,
then processes P 11, P32and P 21form a cycle and all the four processes are involved in a deadl ock
dependingupontherequestmodel.
10.3 Preliminaries
10.3.1 Deadlock Handling Strategies
There are three strategies for handling deadlocks, viz., de adlock prevention, deadlock avoidance,
and deadlock detection. Handling ofdeadlock becomes highl ycomplicatedin distributedsystems
because no sitehas accurate knowledgeofthecurrent stateo fthesystem and because everyinter-
site communication involves a ﬁnite and unpredictable dela y. Deadlock prevention is commonly
achievedeitherbyhavingaprocessacquirealltheneededre sourcessimultaneouslybeforeitbegins
executing or by preempting a process which holds the needed r esource. This approach is highly
inefﬁcientand impracticalin distributedsystems.
Indeadlockavoidanceapproachtodistributedsystems,are sourceisgrantedtoaprocessifthe
resultingglobalsystemstateissafe(notethataglobalsta teincludesalltheprocessesandresources
ofthedistributedsystem). However,duetoseveralproblem s,deadlockavoidanceisimpracticalin
distributedsystems.
343
Deadlockdetectionrequiresexaminationofthestatusofpr ocess-resourceinteractionsforpres-
ence of cyclic wait. Deadlock detection in distributed syst ems seems to be the best approach to
handledeadlocksindistributedsystems. Inthischapter,w elimitthediscussiontodeadlockdetec-
tiontechniquesindistributedsystems.
10.3.2 IssuesinDeadlock Detection
Deadlock handling using the approach of deadlock detection entails addressing two basic issues:
First, detectionofexistingdeadlocks and secondresoluti onofdetected deadlocks.
Detection ofDeadlocks
Detection of deadlocks involves addressing two issues: mai ntenance of the WFG and searching
of the WFG for the presence of cycles (or knots). Since in dist ributed systems, a cycle or knot
may involveseveral sites, the search for cycles greatly dep ends upon how the WFG of the system
is represented across the system. Depending upon the way WFG information is maintained and
search for cycles is carried out, there are centralized, dis tributed, and hierarchical algorithms for
deadlock detectionindistributedsystems [44].
Correctness Criteria: A deadlock detectionalgorithmmustsatisfythefollowingt wo conditions:
(i)Progress (No undetected deadlocks): The algorithm must detect all existing deadlocks in ﬁ-
nitetime. Onceadeadlockhasoccurred,thedeadlockdetect ionactivityshouldcontinuously
progress until the deadlock is detected. In other words, aft er all wait-for dependencies for a
deadlock have formed, the algorithm should not wait for any m ore events to occur to detect
thedeadlock.
(ii)Safety (No falsedeadlocks): The algorithm should not report deadlocks which do not exist
(calledphantomorfalse deadlocks). Indistributedsystemswherethereisnoglobal memory
and there is no global clock, it is difﬁcult to design a correc t deadlock detection algorithm
because sites may obtain out of date and inconsistent WFG of t he system. As a result, sites
may detect a cycle which never existed but whose different se gments existed in the system
atdifferenttimes. Thisisthemainreasonwhymanydeadlock detectionalgorithmsreported
intheliteratureare incorrect.
Resolution ofa DetectedDeadlock
Deadlock resolution involves breaking existing wait-for d ependencies between the processes to
resolve the deadlock. It involves rolling back one or more de adlocked processes and assigning
theirresourcestoblockedprocessessothattheycanresume execution. Notethatseveraldeadlock
detection algorithms propagate information regarding wai t-for dependencies along the edges of
344
P11
P21P32
P54
P24 P44P33site 1 site 2
site 4
site 3
Figure10.1: ExampleofaWFG
the wait-for graph. Therefore, when a wait-for dependency i s broken, the corresponding informa-
tion should be immediately cleaned from the system. If this i nformation is not cleaned in timely
manner, it may result in detection of phantom deadlocks. Unt imely and inappropriate cleaning of
brokenwait-fordependenciesisthemainreasonwhymanydea dlockdetectionalgorithmsreported
intheliteratureareincorrect.
10.4 ModelsofDeadlocks
Distributed systems allow many kinds of resource requests. A process might require a single
resource or a combination of resources for its execution. Th is section introduces a hierarchy of
requestmodelsstartingwithveryrestrictedformstotheon eswithnorestrictionswhatsoever. This
hierarchy shall be used to classify deadlock detection algo rithms based on the complexity of the
resourcerequests theypermit.
10.4.1 The Single Resource Model
Thesingleresourcemodel isthesimplestresource modelin a distributedsystem,where aprocess
can have at most one outstanding request for only one unit of a resource. Since the maximum
out-degree of a node in a WFG for the single resource model can be 1, the presence of a cycle in
theWFG shall indicatethat there is adeadlock. In a latersec tion, an algorithmto detect deadlock
inthesingleresourcemodelis presented.
345
10.4.2 The ANDModel
In the AND model, a process can request for more than one resou rce simultaneously and the
request is satisﬁed only after all the requested resources a re granted to the process. The requested
resources may exist at different locations. The out degree o f a node in the WFG for AND model
can be more than 1. The presence of a cycle in the WFG indicates a deadlock in the AND model.
Each nodeoftheWFG in sucha modeliscalled an ANDnode.
Consider the example WFG described in the Figure 10.1. Proce ss P11has two outstanding
resource requests. In case of the AND model, P 11shall become active from idle state only after
both the resources are granted. There is a cycle P 11->P21->P24->P54->P11which corresponds to a
deadlock situation.
In the AND model, if a cycle is detected in the WFG, it impliesa deadlock but not vice versa.
That is, a process may not be a part of a cycle, it can still be de adlocked. Consider process P 44
in Figure 10.1. It is not a part of any cycle but is still deadlo cked as it is dependent on P 24which
is deadlocked. Since in the single-resource model, a proces s can have at most one outstanding
request, theAND modelismoregeneral thanthesingle-resou rcemodel.
10.4.3 The ORModel
In the OR model, a process can make a request for numerous reso urces simultaneously and the
request is satisﬁed if any one of the requested resources is g ranted. The requested resources may
exist at different locations. If all requests in the WFG are O R requests, then the nodes are called
OR nodes. Presence of a cycle in the WFG of an OR model does not i mply a deadlock in the OR
model. To make it more clear, consider Figure 10.1. If all nod es are OR nodes, then process P 11
is not deadlocked because once process P 33releases its resources, P 32shall become active as one
of its requests is satisﬁed. After P 32ﬁnishes execution and releases its resources, process P 11can
continuewithitsprocessing.
In the OR model, the presence of a knot indicates a deadlock [2 0]. In a WFG, a vertex v is in
a knot iffor all u:: u is reachable from v :v is reachable from u. No paths originatingfrom a knot
shallhavedead ends.
A deadlockintheORmodelcan beintuitivelydeﬁned asfollow s [6]: A processP iisblocked
if it has a pending OR request to be satisﬁed. With every block ed process, there is an associated
setofprocessescalleddependentset. Aprocessshallmovef romidletoactivestateonreceivinga
grant messagefrom any oftheprocesses initsdependent set. A process ispermanently blockedif
it never receives a grant message from any of the processes in its dependent set. Intuitively, a set
of processes S is deadlocked if all the processes in S are perm anently blocked. To formally state
thataset ofprocesses isdeadlocked, thefollowingconditi onsholdtrue:
1. Each oftheprocess is theset Sisblocked,
2. Thedependentset foreach process inS isasubsetofS, and
3. No grantmessageisintransitbetween anytwo processesin setS.
346
We now show that a set of processes S shall remain permanently blocked in the OR model if
theaboveconditionsare met. AblockedprocessPistheset Sb ecomesactiveonlyafterreceiving
a grant message from a process in its dependent set, which is a subset of S. Note that no grant
message can be expected from any process in S because they are all blocked. Also, the third
condition states that no grant messages in transit between a ny two processes in set S. So, all the
processes inset Sare permanentlyblocked.
Hence, deadlock detection in the OR model is equivalent to ﬁn ding knots in the graph. Note
that, there can be a process deadlocked which is not a part of a knot. Consider the Figure 10.1
where P 44can be deadlocked even though it is not in a knot. So, in an OR mo del, a blocked
process Pisdeadlocked ifitiseitherin aknotoritcan onlyr each processeson aknot.
10.4.4 The AND-OR Model
A generalizationoftheprevioustwomodels(ORmodelandAND model)is theAND-ORmodel.
In the AND-OR model, a request may specify any combination of andandorin the resource
request. For example, in the AND-OR model, a request for mult ipleresources can be of the form
xand(yorz). The requested resources may exist at different location s. To detect the presence
of deadlocks in such a model, there is no familiar construct o f graph theory using WFG. Since a
deadlockisastableproperty(i.e.,onceitexists,itdoesn otgoawaybyitself),thispropertycanbe
exploitedandadeadlockintheAND-ORmodelcanbedetectedb yrepeatedapplicationofthetest
for OR-model deadlock. However, this is a very inefﬁcient st rategy. Efﬁcient algorithmsto detect
deadlocksin AND-ORmodelarediscussedin Herman[17].
10.4.5 The/parenleftbigp
q/parenrightbig
Model
AnotherformoftheAND-ORmodelisthe/parenleftbigp
q/parenrightbig
model(calledtheP-out-of-Qmodel)whichallows
a request to obtain any k available resources from a pool of n r esources. Both the models are the
same in expressivepower. However,/parenleftbigp
q/parenrightbig
model lends itself to a much more compact formation of
arequest.
Every request in the/parenleftbigp
q/parenrightbig
model can be expressed in the AND-OR model and vice-versa. No te
that AND requests for p resources can be stated as/parenleftbigp
p/parenrightbig
and OR requests for p resources can be
statedas/parenleftbigp
1/parenrightbig
.
10.4.6 Unrestricted Model
In theunrestrictedmodel,noassumptionsaremaderegardin gtheunderlyingstructureofresource
requests. Inthismodel,onlyoneassumptionthatthedeadlo ckisstableismadeandhenceitisthe
mostgeneralmodel. Thiswayoflookingatthedeadlockprobl emhelpsinseparationofconcerns:
Concerns about properties of the problem (stability and dea dlock) are separated from underly-
ingdistributedsystemscomputations(e.g., messagepassi ngversussynchronouscommunication).
Hence, thesealgorithmscanbeusedtodetectotherstablepr opertiesastheydealwiththisgeneral
347
model. But, these algorithms are of more theoretical value f or distributed systems since no fur-
ther assumptions are made about the underlying distributed systems computations which leads to
agreat deal ofoverhead(which can beavoidedinsimplermode lslikeAND orORmodels).
10.5 Knapp’sClassiﬁcationof Distributed DeadlockDetect ion
Algorithms
Distributed deadlock detection algorithms can be divided i nto four classes [23]: path-pushing,
edge-chasing,diffusioncomputation,andglobalstatedet ection.
10.5.1 Path-Pushing Algorithms
In path-pushing algorithms, distributed deadlocks are det ected by maintaining an explicit global
WFG. Thebasicideais tobuildaglobalWFG foreach siteofthe distributedsystem. In thisclass
ofalgorithms,ateachsitewheneverdeadlockcomputationi sperformed,itsendsitslocalWFGto
all the neighboring sites. After the local data structure of each site is updated, this updated WFG
is then passed along to other sites, and the procedure is repe ated until some site has a sufﬁciently
complete picture of the global state to announce deadlock or to establish that no deadlocks are
present. This feature of sending around the paths of global W FG has led to theterm path-pushing
algorithms.
Examples of such algorithms are Menasce-Muntz [34], Gligor and Shattuck [12], Ho and
Ramamoorthy[19]and Obermarck [39].
10.5.2 Edge-Chasing Algorithms
In anedge-chasing algorithm,thepresenceofacycleinadis tributedgraphstructureisbeveriﬁed
by propagating special messages called probes, along the ed ges of the graph. These probe mes-
sages are different than the request and reply messages. The formation of cycle can be deleted by
asiteifitreceives thematchingprobesentby itpreviously .
Wheneveraprocessthatisexecutingreceivesaprobemessag e,itsimplydiscardsthismessage
and continues. Only blocked processes propagateprobe mess ages along theiroutgoing edges. An
interesting variation of this method can be found in Mitchel l [36], where probes are sent upon
request andin theoppositedirectionoftheedges.
Main advantage of edge-chasing algorithms is that probes ar e ﬁxed size messages which is
normallyvery short. Examplesof suchalgorithmsincludeCh andy et al. [6], Choudharyet al. [7],
Kshemkalyani-Singhal[28], and Sinha-Natarajan [43]algo rithms.
10.5.3 Diffusing Computations BasedAlgorithms
Indiffusioncomputation baseddistributeddeadlockdetectionalgorithms,deadloc kdetectioncom-
putationisdiffusedthroughtheWFGofthesystem. Thesealg orithmsmakeuseofechoalgorithms
348
to detect deadlocks [5]. This computation is superimposed o n the underlying distributed compu-
tation. If this computation terminates, the initiator decl ares a deadlock. The main feature of the
superimposed computation is that the global WFG is implicit ly reﬂected in the structure of the
computation. Theactual WFG isneverbuiltexplicitly.
To detect a deadlock, a process sends out query messages alon g all the outgoing edges in the
WFG. These queries are successively propagated (i.e., diff used) through the edges of the WFG.
Queries are discarded by a running process and are echoed bac k by blocked processes in the
following way: When a blocked process receives ﬁrst query me ssage for a particular deadlock
detection initiation, it does not send a reply message until it has received a reply message for
every query it sent (to its successors in the WFG). For all sub sequent queries for this deadlock
detection initiation, it immediatelysends back a reply mes sage. The initiatorof a deadlock detec-
tion detects a deadlock when it receives reply for every quer y it had sent out. Examples of these
types of deadlock detection algorithms are Chandy-Misra-H aas algorithm for OR model [6] and
Chandy-Herman algorithm [17].
10.5.4 Global State DetectionBasedAlgorithms
Globalstatedetectionbaseddeadlockdetectionalgorithm sexploitthefollowingfacts: (i)Aconsis-
tentsnapshotofadistributedsystemcan beobtainedwithou tfreezing theunderlyingcomputation
and (ii) a consistent snapshot may not represent the system s tate at any moment in time, but if a
stable property holds in the system before the snapshot coll ection is initiated, this property will
stillholdin thesnapshot.
Therefore, distributeddeadlockscan bedetectedbytaking asnapshotofthesystemandexam-
ining it for the condition of a deadlock. Examples of these ty pes of algorithms include Bracha-
Toueg [2], Wang et al. [46], and Kshemkalyani-Singhal [27]a lgorithms.
10.6 MitchellandMerritt’sAlgorithmfortheSingle-Resou rce
Model
MitchellandMerritt’salgorithmbelongstotheclassofedg e-chasingalgorithmswhereprobesare
sent in opposite direction of the edges of WFG. When a probe in itiated by a process comes back
toit, theprocess declares deadlock. Thealgorithmhas many goodfeatures like:
1. Only one process in a cycle detects the deadlock. This simp liﬁes the deadlock resolution –
this process can abort itself to resolve the deadlock. This a lgorithm can be improvised by
includingprioritiesand thelowestpriorityprocessin acy cledetects deadlock andaborts.
2. Inthisalgorithmprocesswhichisdetectedindeadlockis abortedspontaneously,eventhough
under this assumption phantom deadlocks cannot be excluded . It can be shown, however,
thatonlygenuinedeadlockswillbedetected intheabsenceo fspontaneousaborts.
349
Activate
TransmitBlock
u z
zv v
v u
uu v
u < vzz
Detectu v v
Figure10.2: Thefourpossiblestatetransitions
Each node of the WFG has two local variables, called labels: a private label, which is unique
to the node at all times, though it is not constant, and a publi c label, which can be read by other
processes and which may not be unique. Each process is repres ented as u/v where u and u are
the public and private labels, respectively. Initially, pr ivate and public labels are equal for each
process.
A global WFG is maintained and it deﬁnes the entire state of th e system.The Algorithm is
deﬁned by thefourstatetransitionsshownin Figure10.2, wh erez= inc(u,v), and inc(u, v)yields
a unique label greater than both u and v labels that are not sho wn do not change. Block creates
anedgeintheWFG. Twomessagesareneeded, oneresourcerequ estandonemessageback tothe
blockedprocesstoinformitofthepubliclabeloftheproces sitiswaitingfor. Activatedenotesthat
aprocesshasacquiredtheresourcefromtheprocessitwaswa itingfor. Transmitpropagateslarger
labels in the opposite direction of the edges by sending a pro be message. Whenever a process
receivesaprobewhichislessthenitspubliclabel,thenits implyignoresthatprobe. Detectmeans
thattheprobewiththeprivatelabel ofsomeprocesshas retu rned toit, indicatingadeadlock.
MitchellandMerrittshowedthateverydeadlockisdetected . Next,weshowthatintheabsence
of spontaneous aborts, only genuine deadlocks are detected . As there are no spontaneous aborts,
wehavefollowinginvariant:
Forall processes u/v: u<= v
Proof.Initiallyu=u forall processes. Theonlyrequeststhat chan geu orvare
350
(1)Block: u andv are setsuch thatu =v.
(2)Transmit: u isincreased.
Hence, theinvariant.
From thepreviousinvariant,wehavethefollowinglemmas.
Lemma 12. Foranyprocessu/v,ifu >u, thenu was set bya Transmitstep.
Theorem 13. Ifa deadlockisdetected, acycle ofblocked nodesexists.
Proof.A deadlock isdetected ifthefollowingedgep →p’exists:
u u
u
We willprovethefollowingclaims:
(1)u has been propagatedfromp to p’viaasequenceofTransmi ts.
(2)P hasbeen continuouslyblockedsinceittransmittedu.
(3) All intermediate nodes in the transmit path of (l), inclu ding p’, have been continuously
blockedsincetheytransmittedu.
From theaboveclaims,theproofforthetheoremfollowsas di scussedbelow:
From the invariant and the uniqueness of private label u of p’ : u < v. By Lemma 4.1, u was
set by a Transmit step. From the semantics of Transmit, there is some p” with private label u
and public label w. If w = u, then p” = p, and it is a success. Othe rwise, if w <u, we repeat the
argument. Since there are only processes, one of them is p. If p is active then it indicates that it
has transmitted u else it is blocked if it detects deadlock. H ence upon blocking it incremented its
private label. But then private and public labels cannot be e qual. Consider a process which has
been active since it transmitted u. Clearly, its predecesso r is also active, as Transmits migrate in
oppositedirection. By repeating thisargument,wecan show p hasbeen activesinceittransmitted
u.
The above algorithm can be easily extended to include priori ties where whenever a deadlock
occurs, the lowest priority process gets aborted. This algo rithm has two phases. The ﬁrst phase is
almost identical to the algorithm. In the second phase the sm allest priority is propagated around
thecircle, Thepropagationstopswhenoneprocess recogniz es thepropagatedpriorityas itsown.
MessageComplexity
Now we calculate the complexity of the algorithm. If we assum e that a deadlock persists long
enough to be detected, the worst-case complexity of the algo rithm is s(s - 1)/2 Transmit steps,
wheres isthenumberofprocesses inthecycle.
351
10.7 Chandy-Misra-HaasAlgorithmfor theANDModel
We now discuss Chandy-Misra-Haas’s distributed deadlock d etection algorithm for AND model
[6]thatis based onedge-chasing.
The algorithm uses a special message called probe, which is a triplet (i, j, k), denoting that it
belongs to a deadlock detection initiated for process Piand it is being sent by the home site of
processPjto the home site of process Pk. A probe message travels along the edges of the global
WFG graph, and a deadlock isdetected when a probemessageret urns tothe process thatinitiated
it.
A processPjis said to be dependent on another process Pkif there exists a sequence of pro-
cessesPj,Pi1,Pi2, ...,Pim,Pksuch that each process except Pkin the sequence is blocked and
each process, except the Pj, holds a resource for which the previous process in the seque nce is
waiting. Process Pjis said to be locally dependent upon process PkifPjis dependent upon Pk
and boththeprocesses are onthesamesite.
Data Structures
Each process Pimaintains a boolean array, dependent i, wheredependent i(j) is true only if Pi
knowsthatPjis dependentonit. Initially, dependent i(j)is falseforalli and j.
The Algorithm
Thefollowingalgorithmisexecutedto determineifablocke dprocess isdeadlocked:
ifPiislocallydependent onitself
thendeclare adeadlock
elseforallPjandPksuchthat
(a)Piis locallydependentupon Pj, and
(b)Pjis waitingon Pk, and
(c)PjandPkareon differentsites,
senda probe(i, j, k)to thehomesiteof Pk
On thereceipt ofa probe(i, j,k), thesitetakes
thefollowingactions:
if
(d)Pkis blocked,and
(e)dependent k(i)isfalse, and
(f)Pkhasnot repliedto allrequests Pj,
then
begin
352
dependent k(i)=true;
ifk=i
thendeclare that Piis deadlocked
elseforallPmandPnsuch that
(a’)Pkislocallydependent upon Pm, and
(b’)Pmiswaitingon Pn, and
(c’)PmandPnare on differentsites,
senda probe(i, m,n)to thehomesiteof Pn
end.
Therefore,aprobemessageiscontinuouslycirculatedalon gtheedgesoftheglobalWFGgraph
and adeadlockis detected whena probemessagereturnsto its initiatingprocess.
PerformanceAnalysis
Inthealgorithm,oneprobemessage(perdeadlockdetection initiation)issentoneveryedgeofthe
WFG which that two sites. Thus, the algorithmexchanges at mo stm(n−1)/2 messages to detect
adeadlockthatinvolves mprocessesandthatspansover nsites. Thesizeofmessagesisﬁxedand
isvery small(only3 integerwords). Delay indetectinga dea dlockisO(n).
10.8 Chandy-Misra-HaasAlgorithmfor theORModel
We now discuss Chandy-Misra-Haas distributed deadlock det ection algorithm for OR model [6]
thatis basedon theapproach ofdiffusion-computation.
A blocked process determines if it is deadlocked by initiati ng a diffusion computation. Two
typesofmessagesareusedinadiffusioncomputation: query (i,j,k)andreply(i,j,k),denotingthat
they belong to a diffusion computation initiated by a proces sPiand are being sent from process
Pjto processPk.
BasicIdea
A blocked process initiates deadlock detection by sending q uery messages to all processes in its
dependent set (i.e., processes from which it is waiting to re ceive a message). If an active process
receives a query or reply message, it discards it. When a bloc ked process Pkreceives a query(i, j,
k)message,it takesthefollowingactions:
1. If this is the ﬁrst query message received by Pkfor the deadlock detection initiated by Pi
(calledthe engagingquery ),thenitpropagatesthequerytoalltheprocessesinitsdep endent
setand sets alocalvariable num k(i)to thenumberofquerymessagessent.
353
2. If this is not the engaging query, then Pkreturns a reply message to it immediately pro-
videdPkhasbeencontinuouslyblockedsinceitreceivedthecorresp ondingengagingquery.
Otherwise,itdiscards thequery.
ProcessPkmaintainsabooleanvariable wait k(i)thatdenotesthefact thatithasbeen continu-
ously blocked since it received the last engaging query from processPi. When a blocked process
Pkreceivesareply(i,j,k)message,itdecrements num k(i)onlyifwait k(i)holds. A processsends
a reply message in response to an engaging query only after it has received a reply to every query
messageit hadsent outforthisengagingquery.
The initiatorprocess detects a deadlock when it receives re ply messages to all the query mes-
sages ithad sentout.
The Algorithm
Thealgorithmworks asfollows:
Initiatea diffusioncomputation forablocked process Pi:
sendquery(i, i,j)to allprocesses Pjin thedependent set DSiofPi;
num i(i):=|DSi|;wait i(i):=true;
When a blocked process Pkreceives a query(i, j, k):
ifthisistheengagingquery forprocess Pi
thensend query(i,k, m)toall Pminitsdependent set DSk;
num k(i):=|DSk|;wait k(i):=true
elseifwait k(i)then senda reply(i,k, j)toPj.
When a process Pkreceives a reply(i, j, k):
ifwait k(i)
thenbegin
num k(i):=num k(i)−1;
ifnum k(i)= 0
thenifi=k then declare a deadlock
elsesendreply(i, k,m)totheprocess Pm
whichsent theengagingquery.
For ease of presentation, we assumed that only one diffusion computation is initiated for a
process. In practice, several diffusion computations may b e initiated for a process (A diffusion
computation is initiated every time the process gets blocke d), but, at any time only one diffusion
computation is current for any process. However, messages f or outdated diffusion computations
may stillbein transit. Thecurrent diffusioncomputationc an bedistinguishedfrom outdatedones
by usingsequencenumbers.
354
PerformanceAnalysis
For every deadlock detection, the algorithm exchanges e que sry messages and e reply messages,
wheree=n(n-1) isthenumberofedges.
10.9 Kshemkalyani-SinghalAlgorithmforP-out-of-QModel
Kshemkalyani-Singhalalgorithm [27]todetectdeadlocksi ntheP-out-of-Qmodel(alsocalledthe
generalized distributeddeadlocks)isbasedontheglobals tatedetectionapproach. Kshemkalyani-
Singhalalgorithm [27]isasinglephasealgorithm,whichco nsistsofafan-outsweepofmessages
outwardsfromaninitiatorprocessandafan-insweepofmess agesinwardstotheinitiatorprocess.
Asweepof a WFG is a traversal of the WFG in which all messages are sent in the direction
of the WFG edges (outward sweep) or all messages are sent agai nst the direction of the WFG
edges (inward sweep). In the outward sweep, the algorithm re cords a snapshot of a distributed
WFG.Intheinwardsweep,therecordeddistributedWFGisred ucedtodetermineiftheinitiatoris
deadlocked. Both the outward and the inward sweeps are execu ted concurrently in the algorithm.
Complications are introduced because the two sweeps can ove rlap in time at a process, i.e., the
reduction of the WFG at a process can begin before theWFG at th at process has been completely
recorded. Thealgorithmdeals withthesecomplications.
SystemModel
The system has nnodes, and every pair of nodes is connected by a logical chann el. An event in
a computationcan be an internal event, a message send event, or a message receive event. Events
are assignedtimestampsusingLamport’sclocks [30].
The computation messages can be either REQUEST, REPLY or CAN CEL messages. To ex-
ecute api-out-of-qirequest, an active node isendsqiREQUESTs to qiother nodes and remains
blocked until it receives sufﬁcient number of REPLY message s. When node iblocks on node j,
nodejbecomes asuccessorofnode iand nodeibecomes apredecessorofnode jin theWFG. A
REPLYmessagedenotesthegrantingofarequest. Anode iunblockswhen pioutofitsqirequests
havebeengranted. Whenanodeunblocks,itsendsCANCELmess agestowithdrawtheremaining
qi−pirequests ithad sent.
SendingandreceivingofREQUEST,REPLY,andCANCELmessage sarecomputationevents .
The sending and receiving of deadlock detection algorithm m essages are algorithmic or control
events.
Data Structures
A nodeihasthefollowinglocalvariables:
wait i: boolean(:= false); /*records thecurrent status.*/
355
ti: integer(:=0); /*denotesthecurrent time.*/
t_block i: real; /*denotesthelocal timewhen iblockedlast.*/
in(i): set ofnodes whoserequests areoutstandingat node i.
out(i): set ofnodesonwhich node iiswaiting.
pi: integer(:=0); /*thenumberofrepliesrequired forunbloc king.*/
wi: real (:=1.0); /*keepsweightto detect theterminationoft healgorithm.*/
ComputationEvents
REQUEST_SEND( i)
/*Executed by node iwhen itblocks on a pi-out-of- qirequest.*/
Foreverynode jon whichiisblockeddo
out(i)←out(i)/uniontext{j};
sendREQUEST( i)toj;
setpitothenumberofrepliesneeded;
t_block i:=ti;
wait i←true;
REQUEST_RECEIVE( j)
/*Executed by node iwhen itreceives arequest madeby j*/
in(i)←in(i)/uniontext{j}.
REPLY_SEND( j)
/*Executed by node iwhen itreplies to arequest by j.*/
in(i)←in(i)−{j};
sendREPLY(i) toj.
REPLY_RECEIVE( j)
/*Executed by node iwhen itreceives areply from jto itsrequest.*/
ifvalidreply forthecurrent request
thenbegin
out(i)←out(i)−{j};
pi←pi−1;
pi= 0→
{wait i←false;
∀k∈out(i),sendCANCEL(i) tok;
out(i)←∅.}
356
end
CANCEL_RECEIVE( j)
/*Executed by node iwhen itreceives acancel from j.*/
ifj∈in(i)thenin(i)←in(i)−{j}.
10.9.1 InformalDescription ofthe Algorithm
When a node initblocks on a P-out-of-Qrequest, it initiates the deadlock detection algorithm.
The algorithm records part a of the WFG that is reachable from init(henceforth, called the init’s
WFG)inadistributedsnapshot[4];thedistributedsnapsho tincludesonlythosedependencyedges
and nodesthatform init’sWFG.
The distributedWFG is recorded using FLOOD messages in theo utward sweep and recoeded
WFGisexaminedfordeadlocksusingECHOmessagesintheinwa rdsweep. Todetectadeadlock,
theinitiator initrecordsitslocalstateandsendsFLOODmessagesalongallof itsoutwarddepen-
dencies. When node ireceives the ﬁrst FLOOD message along an existing inward dep endency, it
records its local state. If node iis blocked at this time, it sends out FLOOD messages along all
of its outward dependencies to continue the recording of the WFG in the outward sweep. If node
iis active at this time, (i.e., it does not have any outward dep endencies and is a leaf node in the
WFG), then it initiates reduction of theWFG by returning an E CHO message along the incoming
dependency even before the states of all incoming dependenc ies have been recorded in the WFG
snapshotattheleafnode.
ECHOmessagesperformreductionoftherecordedWFGbysimul atingthegrantingofrequests
in the inward sweep. A node iin the WFG is reduced if it receives ECHOs along piout of itsqi
outgoingedgesindicatingthat piofitsrequestscan begranted. An edgeisreduced ifan ECHO is
receivedontheedgeindicatingthattherequestitrepresen tscanbegranted. Afteralocalsnapshot
has been recorded at node i, any transition made by ifrom idle to active state is captured in the
process of reduction. The nodes that can be reduced do not for m a deadlock whereas the nodes
thatcannotbereducedaredeadlocked. Theorderinwhichred uctionofthenodesandedgesofthe
WFGisperformeddoesnotaltertheﬁnalresult. Node initdetectsthedeadlockifitisnotreduced
when thedeadlock detectionalgorithmterminates.
Ingeneral,WFGreductioncanbeginatanon-leafnodebefore recordingoftheWFGhasbeen
completed at that node; this happens when an ECHO message arr ives and begins reduction at a
non-leaf node before all the FLOODs have arrived at it and rec orded the complete local WFG at
that node. Thus, theactivitiesofrecording and reducing th eWFG snapshotare doneconcurrently
in a single phase. Unlike the algorithm in [46], no serializa tion is imposed between the two
activities. Sinceareductionisdoneonanincompletelyrec ordedWFGatnodes,thelocalsnapshot
ateachnodehastobecarefullymanipulatedsoastogivethee ffectthatWFGreductionisinitiated
afterWFG recordinghas been completed.
When multiple nodes block concurrently, they may each initi ate the deadlock detection algo-
357
rithm concurrently. Each invocation of the deadlock detect ion algorithm is treated independently
and is identiﬁed by the initiator’s identity and initiator’ s timestamp when it blocked. Every node
maintainsalocalsnapshotforthelatestdeadlockdetectio nalgorithminitiatedbyeveryothernode.
Wewilldescribeonlyasingleinstanceofthedeadlock detec tionalgorithm.
The Problem of TerminationDetection
Thealgorithmrequiresaterminationdetectiontechniques othattheinitiatorcandeterminedthatit
will not receive any more ECHO messages. Thealgorithm uses a termination detection technique
based on weights [21] in cojunction with SHORT messages to de tect the terminationof the algo-
rithm. A weight of 1.0 at the initiator node, when the algorit hm is initiated, is distributed among
all FLOOD messages sent out by the initiator. When the ﬁrst FL OOD is received at a non-leaf
node,theweightofthereceivedFLOODisdistributedamongt heFLOODssentoutalongoutward
edgesatthatnodetoexpandtheWFGfurther. Sinceanysubseq uentFLOODarrivingatanon-leaf
nodedoesnotexpandtheWFGfurther,itsweightisreturnedt otheinitiatorinaSHORTmessage.
WhenaFLOODisreceivedataleafnode,itsweightispiggybac kedtotheECHOsentbytheleaf
node to reduce the WFG. When an ECHO that arrives at a node unbl ocks the node, the weight of
theECHO isdistributedamongtheECHOsthataresentbythatn odealongtheincomingedgesin
itsWFGsnapshot. WhenanECHOarrivingatanodedoesnotunbl ockthenode,itsweightissent
directlyto theinitiatorinaSHORT message.
Notethatthefollowinginvariantholdsinanexecutionofth ealgorithm: thesumoftheweights
inFLOOD,ECHO,andSHORTmessagesplustheweightattheinit iator(receivedinSHORTand
ECHOmessages)isalways1.0. Thealgorithmterminateswhen theweightattheinitiatorbecomes
1.0,signifyingthat allWFG recording and reductionactivi tyhas completed.
FLOOD,ECHO , andSHORT messages carry weights for termination detection. Variabl e
w,areal numberintherange [0,1],denotes theweightin amessage.
10.9.2 The Algorithm
A nodeistores the local snapshot for snapshots initiatedby other nodes in a data structure LSi
(Local Snapshot),which isan array ofrecords.
LSi: array [1..n]ofrecord;
A record has several ﬁelds to record snapshot related inform ation and is deﬁned below for an
initiatorinit:
LSi[init].out: setofintegers(:= ∅); /*nodesonwhich iiswaitinginthesnapshot.*/
LSi[init].in: setofintegers(:= ∅); /*nodeswaitingon iinthesnapshot.*/
LSi[init].t: integer(:=0); /*timewhen initinitiatedsnapshot.*/
LSi[init].s: boolean(:= false); /*localblockedstateasseen by snapshot.*/
358
LSi[init].p: integer; /*valueofpias seenin snapshot.*/
The deadlock detection algorithm is deﬁned by the following procedures. These procedures
are executedatomically.
SNAPSHOT_INITIATE
/*Executed by node ito detect whether it isdeadlocked. */
init←i;
wi←0;
LSi[init].t←ti;
LSi[init].out←out(i);
LSi[init].s←true;
LSi[init].in←∅;
LSi[init].p←pi;
sendFLOOD (i,i,t i,1/|out(i)|)to eachjinout(i). /*1/|out(i)|is the fraction of weight
sent in aFLOODmessage. */
FLOOD_RECEIVE( j,init,t_init,w)
/*Executed by node ion receiving aFLOODmessage from j. */
LSi[init].t <t_init/logicalandtextj∈in(i)→ /*Valid FLOODfor anew snapshot. */
LSi[init].out←out(i);
LSi[init].in←{j};
LSi[init].t←t_init;
LSi[init].s←wait i;
wait i=true→ /*Node isblocked. */
LSi[init].p←pi;
sendFLOOD (i,init,t_init, w/|out(i)|)toeachk∈out(i);
wait i=false→ /*Node isactive. */
LSi[init].p←0;
sendECHO (i,init,t_init,w )toj;
LSi[init].in←LSi[init].in−{j}.
2
LSi[init].t <t_init/logicalandtextj∝\⌉}atio\slash∈in(i)→ /*Invalid FLOODfor anew snapshot. */
sendECHO (i,init,t_init,w )toj.
2
LSi[init].t=t_init/logicalandtextj∝\⌉}atio\slash∈in(i)→ /*Invalid FLOODfor current snapshot. */
sendECHO (i,init,t_init,w )toj.
2
LSi[init].t=t_init/logicalandtextj∈in(i)→ /*Valid FLOODfor current snapshot. */
LSi[init].s=false→
sendECHO (i,init,t_init,w )toj;
359
LSi[init].s=true→
LSi[init].in←LSi[init].in/uniontext{j};
sendSHORT (init,t_init,w )toinit.
2
LSi[init].t >t_init→discardtheFLOOD message. /*Out-dated FLOOD.*/
ECHO_RECEIVE( j,init,t_init,w)
/*Executed by node ion receiving anECHOfrom j. */
[
/*Echo for out-dated snapshot. */
LSi[init].t >t_init→discardtheECHO message.
2
LSi[init].t <t_init→cannothappen. /*ECHOfor unseen snapshot. */
2
LSi[init].t=t_init→ /*ECHOfor current snapshot. */
LSi[init].out←LSi[init].out−{j};
LSi[init].s=false→sendSHORT (init,t_init,w )toinit.
LSi[init].s=true→
LSi[init].p←LSi[init].p−1;
LSi[init].p= 0→ /* getting reduced */
LSi[init].s←false;
init=i→declare notdeadlocked;exit.
sendECHO (i,init,t_init,w/|LSi[init].in|)to allk∈LSi[init].in;
LSi[init].p∝\⌉}atio\slash= 0→
sendSHORT (init,t_init,w )toinit.
]
SHORT_RECEIVE( init,t_init,w)
/*Executed by node i(which isalways init)on receiving aSHORT.*/
[
/*SHORTfor out-dated snapshot. */
t_init <t_block i→discardthemessage.
2
/*SHORTfor uninitiated snapshot. */
t_init >t_block i→notpossible.
2
/*SHORTfor currently initiated snapshot. */
t_init=t_block i/logicalandtextLSi[init].s=false→discard. /*initisactive. */
t_init=t_block i/logicalandtextLSi[init].s=true→
wi←wi+w;
360
REQUEST
FLOOD
REPLY
ECHO/0/0/0/0/0/0
/1/1/1/1/1/1
B
1/2C
2/3
D
2/4 E
1/2
F G HI1/2A (initiator)
Figure10.3: AnExample-run oftheAlgorithm.
wi= 1→declare a deadlock .
]
10.9.3 An Example
We now illustrate the operation of the algorithm with the hel p of an example [27] shown in Fig-
ures10.3and10.4). Figure10.3showsinitiationofdeadloc kdetectionbynodeAandFigure10.4
shows the state after node D is reduced. The notation x/ybeside a node in the ﬁgures indicates
thatthenodeisblockedand needs repliesto xoutoftheyoutstandingrequeststo unblock.
In Figure 10.3, node A sends out FLOOD messages to nodes B and C . When node C receives
FLOODfromnodeA,itsendsFLOODstonodesD,E,andF.Iftheno dehappenstobeactivewhen
it receives a FLOOD message, it initiates reduction of thein coming wait-foredge by returning an
ECHOmessageonit. Forexample,inFigure10.3,nodeHreturn sanECHOtonodeDinresponse
toaFLOODfromit. Notethatnodecan initiatereduction(bys endingbackan ECHOinresponse
toaFLOODalonganincomingwait-foredge)evenbeforethest atesofallotherincomingwait-for
361
edges have been recorded in the WFG snapshot at that node. For example, node F in Figure 10.3
startsreductionafterreceivingaFLOODfromCevenbeforei thasreceivedFLOODsfromDand
E.
Note that when a node receives a FLOOD, it need not have an inco ming wait-for edge from
thenodethatsenttheFLOODbecauseitmayhavealreadysentb ackaREPLY tothenode. Inthis
case, the node returns an ECHO in response to the FLOOD. For ex ample, in Figure 10.3, when
nodeIreceivesaFLOOD from nodeD, itreturns an ECHO tonodeD .
ECHO messages perform reduction of the nodes and edges in the WFG by simulating the
grantingofrequestsintheinwardsweep. Anodethatiswaiti ngap-out-of-qrequest,getsreduced
after it has received pECHOs. When a node is reduced, it sends ECHOs along all the inc oming
wait-foredges incidenton itin theWFG snapshotto continue theprogress oftheinward sweep.
Ingeneral,WFGreductioncanbeginatanon-leafnodebefore recordingoftheWFGhasbeen
completed at that node. This happens when ECHOs arrive and be gin reduction at a non-leaf node
before FLOODs have arrived along all incoming wait-for edge s and recorded the complete local
WFG at that node. For example, node D in Figure 10.3 starts red uction (by sending an ECHO
to node C) after it receives ECHOs from H and G, even before FLO OD from B has arrived at D.
WhenaFLOODonanincomingwait-foredgearrivesatanodewhi chisalreadyreduced,thenode
simply returns an ECHO along that wait-for edge. For example , in Figure 10.4, when a FLOOD
from nodeB arrivesatnodeD, nodeD returns an ECHO toB.
In Figure 10.3, node C receives a FLOOD from node A followed by a FLOOD from node
B. When node C receives a FLOOD from B, it sends a SHORT to the in itiator node A. When a
FLOOD is received at a leaf node, its weight is returned in the ECHO message sent by the leaf
nodetothesenderoftheFLOOD.NotethatanECHOislikearepl yinthesimulatedunblockingof
processes. When an ECHO arriving at a node does not reduce the node, its weight is sent directly
to theinitiatorthrough aSHORT message. Forexample, in Fig ure10.3, when node D receives an
ECHO from node H, it sends a SHORT to the initiator node A. When an ECHO that arrives at a
node reduces that node, theweight ofthe ECHO is distributed among theECHOs that are sent by
that nodealong theincomingedges in itsWFG snapshot. Forex ample,in Figure 10.4,at thetime
nodeCgetsreduced(afterreceivingECHOsfromnodesDandF) ,itsendsECHOstonodesAand
B.(WhennodeAreceivesanECHOfromnodeC,itisreducedandi tdeclaresnodeadlock.) When
an ECHO arrives at a reduced node, its weight is sent directly to the initiator through a SHORT
message. Forexample,inFigure10.4,whenanECHOfromnodeE arrivesatnodeCafternodeC
has been reduced (by receiving ECHOs from nodes D and F), node C sends a SHORT to initiator
nodeA.
Correctness
Provingthecorrectnessofthealgorithminvolvesshowingt hatitsatisﬁesthefollowingconditions:
1. Theexecutionofthealgorithmterminates.
362
REQUEST
FLOOD
REPLY
ECHO/0/0/0/0/0/0
/1/1/1/1/1/1
B
1/2C
2/3
D
E
1/2
FA (initiator)
1/2
Figure10.4: AnExample-runoftheAlgorithm(continued).
363
2. Theentire WFG reachable from theinitiatoris recorded in aconsistent distributedsnapshot
intheoutwardsweep.
3. In theinward sweep, ECHO messagescorrectly reducethere corded snapshotoftheWFG.
The algorithmis initiated withina timeoutperiod after a no deblocks on a P-out-of-Q request.
On theterminationofthealgorithm,onlyallthenodesthat a renot reduced, aredeadlocked. Fora
correctness proofofthealgorithm,thereaders arereferre d to theoriginalsource[27].
Complexity Analysis
Themessagecomplexityofthealgorithmhasbeenanalyzedin [27]. Thealgorithmhasamessage
complexityof 4e−2n+ 2land atimecomplexity1of2dhops,where eisthenumberofedges, n
thenumberofnodes, lthenumberofleafnodes,and dthediameteroftheWFG.Thisisbetterthan
two-phase algorithms for detecting generalized deadlocks and gives the best time complexity that
canbeachievedbyanalgorithmthatreducesadistributedWF Gtodetectgeneralizeddeadlocksin
distributedsystems.
10.10 Summary
Out of the three approaches to handledeadlocks, deadlock de tection is the most promising in dis-
tributed systems. Detection of deadlocks requires perform ingtwo tasks: ﬁrst, maintainingor con-
structing whenever needed a WFG; second, searching the WFG f or a deadlock condition (cycles
orknots).
In distributed deadlock-detection algorithms, every site maintains a portion of the global state
graph and every siteparticipates in thedetectionofa globa lcycleorknot. Dueto lack ofglobally
shared memory, design of distributed deadlock-detection a lgorithms is difﬁcult because sites may
report the existence of a global cycle after seeing its segme nts at different instants (though all the
segmentsneverexistedsimultaneously).
Distributeddeadlockdetectionalgorithmscanbedividedi ntofourclasses: path-pushing,edge-
chasing, diffusion computation, and global state detectio n. In path-pushing algorithms, wait-for
dependency information of the global WFG is disseminated in the form of paths (i.e., a sequence
of wait-for dependency edges). In edge-chasing algorithms , special messages called probes are
circulated along the edges of the WFG to detect a cycle. When a blocked process receives a
probe,itpropagatestheprobealongitsoutgoingedgesinth eWFG.Aprocessdeclaresadeadlock
when it receives a probe initiated by it. Diffusion computat ion type algorithms make use of echo
algorithms to detect deadlocks. Deadlock detection messag es are successively propagated (i.e,
“diffused”through)throughtheedges oftheWFG. Globalsta tedetectionbased algorithmsdetect
deadlocksby takingasnapshotofthesystemand byexamining itfortheconditionofadeadlock.
1Time complexitydenotesthedelayindetectinga deadlockaf teritsdetectionhasbeeninitiated.
364
10.11 BibliographicNotes
Two survey articles on distributed deadlock detection can b e found in papers by Knapp [23] and
Singhal [44]. Theliteratureisfullofdistributeddeadloc kdetectionalgorithms. Path-pushingdis-
tributeddeadlockdetectionalgorithmscan befound inpape rsby Gligor-Shattuck [12], Menasce-
Muntz [34], HoandRamamoorthy[19],andandObermarck [39]. Otheredge-chasingdistributed
deadlock detection algorithmscan befound in papers by Chou dary et al. [7], and Kshemkalyani-
Singhal [28]. Herman and Chandy [17] discuss detection of de adlocks in AND/OR model. In
[25], Kshemkalyani and Singhal give an optimal algorithm to detect distributed deadlocks under
the generalized request model. Other algorithms to detect g eneralized deadlocks include Bracha-
Toueg [2]and Wang etal. [46].
In[26],KshemkalyaniandSinghalgiveacharacterizationo fdistributeddeadlocks. Arigorous
correctness proof of a distributed deadlock detection algo rithm is given in Kshemkalyani-Singhal
[28]. Brezezinski et al. [3] discuss the deadlock models und er a very generalized blocking condi-
tions. Two knot detection algorithms in distributed system s are given in Chandy-Misra [35] and
Manivannan-Singhal[32].
10.12 ExerciseProblems
1. Considerthefollowingsimpleapproachtohandledeadloc ksindistributedsystemsbyusing
“time-outs”: a process that has waited for a speciﬁed period for a resource declares that it
is deadlocked and aborts to resolve the deadlock. What are th e shortcomings of using this
method?
2. Suppose all the processes in the system are assigned prior ities which can be used to totally
order the processes. Modify the Chandy et al.’s algorithm fo r the AND model so that when
aprocess detectsadeadlock, italso knowsthelowestpriori tydeadlocked process.
3. Show that in the AND model, false deadlocks can occur due to deadlock resolution in dis-
tributedsystems [44]. Can somethingbedoneaboutitorthey are boundtohappen?
4. ShowthatinKshemkalyani-SinghalalgorithmfortheP-ou t-of-Qmodel,iftheweightatthe
initiatorprocess becomes1.0, thentheintiatorisinvolve din adeadlock.
365
Bibliography
[1] B. Awerbuch and S. Micali, Dynamic deadlock resolutionp rotocols. In Proc. of theFounda-
tionsofComputerScience, Toronto,Canada, 1986,pp.196-2 07.
[2] G. Bracha and S. Toueg,DistributedDeadlock Detection, DistributedComputing,2(3), 127-
138,1987.
[3] J. Brezezinski, J.M.Helary, M. Raynal, and M. Singhal,“ Deadlock Modelsand Generalized
AlgorithmforDistributedDeadlockDetection”, JournalofParallelandDistributedComput-
ing,December1995,Vol 31,No 2,pp. 112-125.
[4] K. M. Chandy and L. Lamport, Distributed snapshots: Dete rmining global states of dis-
tributedsystems,ACM Trans.Program. Lang.Syst. 3, 1(Feb. ), 1985,pp.63-75.
[5] K. M. Chandy and J. Misra, A distributed algorithm for det ecting resource deadlocks in dis-
tributed systems, In Proc. of the ACM Symposium on Principle s of Distributed Computing,
Ottawa,Canada, Aug 1982,pp.157-164.
[6] K.M.Chandy,J.MisraandL.M.Haas,Distributeddeadloc kdetection,ACMTrans.Comput.
Syst.1,2 ,May 1983,144-156.
[7] A.Choudhary,W.Kohler,J.Stankovic,andD.Towsley,AM odiﬁedPriorityBasedProbeAl-
gorithm for Distributed Deadlock Detection and Resolution , IEEE Trans. on Software Eng.,
Jan1989.
[8] JoseRamon Gonzalezde Mendivil, Federico Farina, JoseG aritagoitia, Carlos F. Alastruey
,J.M.Bernabeu-Auban, ADistributedDeadlockResolutionA lgorithmfortheANDModel,
IEEETransactionsonParallel and DistributedSystems,v.1 0n.5,p.433-447,May1999.
[9] E. W. Dijkstra and C. S. Scholten, Termination detection for diffusing computations, Znf.
Process. Lett.11, 1,Aug 1980.
[10] Ahmed K. Elmagarmid, Neelam Soundararajan, Ming T. Liu : A Distributed Deadlock De-
tection and Resolution Algorithm and Its Correctness Proof , IEEE Trans. on Software Eng.,
Volume14,Number10,October1988,pp.1443-1452.
366
[11] Mitchell Flatebo , Ajoy Kumar Datta, Self-stabilizing deadlock detection algorithms, Pro-
ceedingsofthe1992ACMannualconferenceonCommunication s,p.117-122,March03-05,
1992,KansasCity,Missouri.
[12] V.GligorandS.Shattuck,Ondeadlockdetectionindist ributeddatabases,IEEETrans.Softw.
Eng.SE-6, 5 (Sept.), 1980
[13] J. N. Gray, P. Homan, H. F. Korth and R. L. Obermarck, A str aw man analysis of the prob-
ability of waiting and deadlock in a database system, Tech. R ep. RJ 3066, IBM Research
Laboratory,San Jose,Calif, 1981
[14] L.M.Haas,Twoapproachestodeadlockdetectionindist ributedsystems.Ph.D.dissertation,
Dept.ofComputerSciences, Univ.ofTexas,Austin,Tex,198 1
[15] L. M. Haas, and C. Mohan, A distributed deadlock detecti on algorithm for a resource-based
system,Res. Rep. RJ 3765,IBM Research Laboratory,San Jose ,Calif, 1983
[16] J. Helary, C. Jard, N. Plouzeau and M. Raynal, Detection of stable properties in distributed
applications,InProc. oftheACMSymposiumonPrinciplesof DistributedComputing,Van-
couver,Canada, Aug1987,pp. 125-136.
[17] T. Herman, and K. M. Chandy, A distributed procedure to d etect AND/OR deadlock, Tech.
Rep. TRLCS-8301, Dept. ofComputerSciences, Univ.ofTexas ,Austin,Tex, 1983
[18] Beverly A. Sanders , Philipp A. Heuberger, Distributed Deadlock Detection and Resolu-
tion with Probes, Proceedings of the 3rd International Work shop on Distributed Algorithms,
p.207-218,September26-28, 1989.
[19] G. S. Ho and C. V. Ramamoorthy, Protocols for deadlock de tection in distributed database
systems,IEEE Trans.Softw.Eng. SE-8, 6(Nov.),1982,pp 554 -557.
[20] R.C.Holt,Somedeadlockpropertiesoncomputersystem s,ACMComput.Surv.4,3(Sept.),
1972,pp179-196.
[21] Shing-TsaanHuang,DetectingTerminationofDistribu tedComputationsbyExternalAgents,
ICDCS 1989,pp. 79-84.
[22] J.R.JagannathanandR.Vasudevan,Adistributeddeadl ockdetectionandresolutionscheme;
performancestudy,In Proc. oftheThirdInternationalConf erence onDistributedComputing
Systems,Miami,Florida, 1982,pp.496-501.
[23] Edgar Knapp, Deadlock detection in distributed databa ses, ACM Computing Surveys, Vol-
ume19, Issue4, December1987,pp. 303-328.
367
[24] Murali Krishnamurthi , Amar Basavatia , Sanjeev Thalli kar, Deadlock detection and resolu-
tion in simulation models, Proceedings of the 26th conferen ce on Winter simulation, p.708-
715,December11-14, 1994,Orlando,Florida.
[25] Ajay Kshemkalyani and Mukesh Singhal, “A One-Phase Alg orithm to Detect Distributed
DeadlocksinReplicated Databases”, IEEETrans.onKnowledgeandDataEngineering ,Vol
11,No 6,Nov/Dec1999,pp.880-895.
[26] Ajay Kshemkalyani and Mukesh Singhal, “On Characteriz ation and Correctness of Dis-
tributed Deadlocks”, Journal of Parallel and Distributed Computing , July 1994, No 22, pp.
44-59.
[27] AjayKshemkalyaniandMukeshSinghal,“EfﬁcientDetec tionandResolutionofGeneralized
DistributedDeadlocks”, IEEETrans.onSoftwareEngineering ,January 1994,Vol20, No.1,
pp.43-54.
[28] Ajay Kshemkalyaniand MukeshSinghal, “An Invariant-B ased Veriﬁcation ofa Probe Algo-
rithm for Distributed Deadlock Detection and Resolution”, IEEE Transactions on Software
Engineering ,August1991,pp.789-799.
[29] NatalijaKrivokapic,AlfonsKemper,EhudGudes,Deadl ockdetectionindistributeddatabase
systems: A new algorithm and a comparative performance anal ysis, VLDB Journal: Very
LargeDataBases. vol 8,number2,pages 79–100,1999.
[30] L. Lamport, Time, clocks, and the ordering of events in d istributed systems, Comm. ACM
21,7 (July),1978,pp 558-565.
[31] Soojung Lee, Junguk L. Kim, Performance Analysis of Dis tributed Deadlock Detection Al-
gorithms,IEEE TransactionsonKnowledgeandDataEngineer ing,v.13n.4,p.623-636,July
2001.
[32] D. Manivannan and M. Singhal, “An Efﬁcient Distributed Algorithm for Detection of Knots
and Cycles in a Distributed Graph", IEEE Trans. on Parallel and Distributed Systems , Vol
14,No 10,October2003,pp. 961-972.
[33] Jean Mayoand Phil Kearns,DistributedDeadlockDetect ion and ResolutionBased on Hard-
wareClocks, ICDCS 1999,208-215.
[34] D.E.MenasceandR.Muntz,LockingandDeadlockDetecti oninDistributeddatabases,IEEE
Trans.onSoftware Eng.,May 1979.
[35] J. Misra and K. M. Chandy, A distributed graph algorithm : Knot detection, ACM Trans.
Program. Lang.Syst. 4,4(Oct.), 1982,pp 678-686.
[36] D.P.MitchellandM.JMerritt,Adistributedalgorithm fordeadlockdetectionandresolution,
In-Proc.oftheACMSymposiumonPrinciplesofDistributedC omputing,1984,pp.282-284.
368
[37] N. Natarajan, A distributed scheme for detecting commu nication deadlock, IEEE Trans.
Softw.Eng.SE-12, 4 (Apr.), 1986,531-537.
[38] R.Obermarck,Deadlockdetectionforallresourseclas ses,Res.Rep.RJ2955,IBMResearch
Laboratory,San Jose,Calif, 1980
[39] R. Obermarck, Distributed deadlock detection algorit hm, ACM Trans. Database Syst. 7, 2
(June), 1982,187-208.
[40] YoungChulPark, PeterScheuermann,andHsiangLungTun g,Adistributeddeadlockdetec-
tionandresolutionalgorithmbasedonahybridwait-forgra phandprobegenerationscheme,
Proceedings of the fourth international conference on Info rmation and knowledge manage-
ment,Baltimore,Maryland,Pages: 378-386,1995.
[41] Young Chul Park, Peter Scheuermann, Sang H. Lee, A Perio dic Deadlock Detection and
Resolution Algorithmwith a New Graph Model for Sequential T ransaction Processing, Pro-
ceedings of the Eighth International Conference on Data Eng ineering, Pages: 202 - 209,
1992.
[42] M. Roesler , W. A. Burkhard, Resolution of Deadlocks in O bject-Oriented Distributed Sys-
tems,IEEETransactionsonComputers, v.38n.8, p.1212-122 4,August1989.
[43] M. K. Sinha and N. Natarajan, A distributed deadlock det ection algorithm based on times-
tamps,InProc.ofthe4thInternationalConferenceonDistr ibutedComputingSystems,1984,
pp.546-556.
[44] Mukesh Singhal, “Deadlock Detection in Distributed Sy stems”,IEEE Computer , November
1989,pp.37-48.
[45] Jesus Villadangos, Federico Farina, Jose Ramon Gonzal ez de Mendivil, Jose Garitagoitia,
andAlbertoCordoba,ASafeAlgorithmforResolvingORDeadl ocks,IEEETransactionson
SoftwareEngineering,v.29n.7,p.608-622,July2003.
[46] J. Wang, S. Huang, and N. Chen, A Distributed Algorithm f or Detecting generalized Dead-
locks,Tech. Report, Dept.ofComputerScience, NationalTs ing-HuaUniversity,1990.
[47] Hui Wu, Wei-Ngan Chin, Joxan Jaffar, An Efﬁcient Distri buted Deadlock Avoidance Algo-
rithm for the AND Model, IEEE Transactions on Software Engin eering, v.28 n.1, p.18-29,
January2002.
[48] D.Zobel,Thedeadlockproblem: Aclassifyingbibliogr aphy,Operat.Syst.Rev.17,2(Oct.),
1983,pp6-15.
369
Chapter11
Global PredicateDetection
11.1 StableandUnstablePredicates
Specifying predicates on the system state provides an impor tant handle to specify, observe, and
detect the behavior of a system. This is useful in formally re asoning about the system behavior.
By being able to detect a speciﬁed predicate in the execution , we gain the ability to monitor the
execution. Predicatespeciﬁcationanddetectionhasusesi ndistributeddebugging,sensornetworks
used for sensing in various applications, and industrial pr ocess control. As an example in the
manufacturingprocess,asystemmaybemonitoringthepress ureofReagentAandthetemperature
of Reagent B. Only when ψ1= (Pressure a>240KPa)∧(Temperature b>300◦C) shouldthe
two reagents be mixed. As another example, consider a distri buted execution where variables x,
y, andzare local to processes Pi,PjandPk, respectively. An application might be interested in
detecting the predicate ψ2=xi+yj+zk<−125. In a nuclear power plant, sensors at various
locationswould monitortherelevant parameters such as the radioactivityleveland temperatureat
multiplelocationswithinthereactor.
Observethatthe“predicatedetection”problemisinherent lydifferentfromtheglobalsnapshot
problem. A global snapshot gives one of the possible states t hatcould have existed during the
periodofthesnapshotexecution. Thus,asnapshotalgorith mcanobserveonlyoneofthepredicate
valuesthat could haveexisted duringthealgorithmexecution.
Predicates can be either stable or unstable. A stablepredicate is a predicate that remains true
once it becomes true. In traditionalsystems, a predicate φis stableifφ=:φ, where “ ” is
the“henceforth”operatorfromtemporallogic. Indistribu tedexecutions,amoreprecisedeﬁnition
is needed, due to the absence of global time. Formally, a pred icateφat a cutCis stable if the
followingholds.
(C|=φ) =: (∀C′|C⊆C′,C′|=φ)
Deadlock in a system is a stable property because the deadloc ked processes continue to remain
deadlocked(untildeadlockresolutionisperformed). Term inationofanexecutionisanotherstable
property. Speciﬁcalgorithmstodetectterminationofthee xecution,andtodetectdeadlockwillbe
consideredin separatechapters. Here, welookat ageneral t echniquetodetect astablepredicate.
370
11.1.1 Stable Predicates
Deadlock: A deadlock represents a system state where a subset of the pro cesses are blocked on
one another, waiting for a reply from the other processes in t hat subset. The waiting relationship
is represented by a Wait-For Graph (WFG) where an edge from itojindicates that process iis
waitingfor areply from process j. GivenaWait-ForGraph G= (V,E), adeadlock is a subgraph
G′= (V′,E′)such thatV′⊆VandE′⊆Eand for each process iinV′, the process iremains
blocked unless it receives a reply from some process(es) in V′. There are two conditions that
characterize thedeadlockstateoftheexecution.
•(local condition:) each deadlocked processis locallybloc ked,and
•(globalcondition:) thedeadlockedprocesswillnotreceiv eareplyfromsomeprocess(es)in
V′.
Termination: Termination of an execution is another stable property, and is best understood by
viewing a process as alternating between two states: active state andpassive state . Anactive
process spontaneously becomes passivewhen it has no further work to do; a passive process can
becomeactiveonlywhenitreceivesamessagefromsomeotherprocess. Ifsu chamessagearrives,
thentheprocessbecomes activebydoingCPUprocessingandmaybesendingmessagesasaresul t
oftheprocessing. Anexecutionis terminated ifeachprocessis passive,andwillnotbecomeactive
unless it receives more messages. There are two conditions t hat characterize the termination state
oftheexecution.
•(local condition:) each process isin passivestate,and
•(globalcondition:) thereis nomessageintransitbetween a nypairofprocesses.
Generalizing from the above two most frequently encountere d stable properties, we assume
that each stable property can be characterized by a local pro cess state component, and a channel
componentoraglobalcomponent. Recallfromourdiscussion ofglobalsnapshotsthatanychannel
property can be observed by observing the local states at the two endpoints of the channel, in a
consistentmanner. Thus,anyglobalconditioncan beobserv edbyobservingthelocalstatesofthe
processes.
We now address the question: “What are the most effective tec hniques for detecting a stable
property?” Clearly, repeatedly or periodically taking a gl obal snapshot will work; if the property
is true in some snapshot, then it can be claimed that the prope rty is henceforth true. However,
recording a snapshot is expensive; recall that it can requir e up toO(n2)control messages without
inhibition, or O(n)messages with inhibition. The approach that has been widely adopted is the
two-phase approach of observing potentially inconsistent global states. In each state observation,
all the local variables necessary for deﬁning the local cond itions, as well as the global condi-
tions, are observed. Two potentially inconsistent global s tates are recorded consecutively, such
that the second recording is initiated after the ﬁrst record ing has completed. This is illustrated in
Figure11.1. Thestableproperty can bedeclared to betrueif thefollowingholds.
371
P
P
P
P21
n−1
n
phase 2 phase 1time
event at which local  variables are sampled
Figure 11.1: Two-phase detection of a stable property. If th e values of the relevant local variables
thatcapturethepropertyhavenotchangedbetweenthetwoph ases,thenthestablepropertyistrue.
•Thevariablesonwhichthelocalconditionsaswellastheglo balconditionsaredeﬁnedhave
notchanged inthetwoobservations,as well as betweenthetw oobservations.
If none of the variables changes between the two observation s, it can be claimed that after the
terminationoftheﬁrstobservationandbeforethestartoft hesecondobservation,thereisaninstant
inphysicaltimewhenthevariablesstillhavethesamevalue . Eventhoughthetwoobservationsare
eachinconsistent,iftheglobalpropertyistrueatacommon physicaltime,thenthestableproperty
willnecessarilybetrue.
The most common ways of taking a pair of consecutive, not nece ssarily consistent, snapshots
usingO(n)controlmessagesare as follows.
•Each process randomly records its state variables and sends them to a central process via
control messages. When the central process receives this me ssage from each other process,
thecentral processinformseach otherprocess tosend its(u ncoordinated)local stateagain.
•A token is passed around a ring, and each process appends its l ocal state to the contents of
thetoken. Whenthetokenreachestheinitiator,itpassesth etokenaroundforasecondtime.
Each process againappendsitslocal stateto thecontentsof thetoken.
•On a predeﬁned spanning tree, the root (coordinator) sends a query message in the fan-out
sweep ofthetreebroadcast. Inthefan-in sweepoftheensuin gtree convergecast,each node
collectsthelocalstatesofthenodesinitssubtreerooteda titselfandforwardsittoitsparent.
When the root gets the local states from all the nodes in its tr ee, the ﬁrst phase completes.
Thesecondphase,whichcontainsanotherbroadcastfollowe dbyaconvergecast,isinitiated.
11.1.2 Unstable Predicates
Anunstablepredicate isapredicatethat isnot stableand hencemay hold onlyintermittently. The
followingaresomeoftheseveralchallenges indetectingun stablepredicates.
372
•Due to unpredictable message propagation times, and unpred ictable scheduling of the vari-
ousprocessesontheprocessorsundervariousloadconditio ns,evenfordeterministicexecu-
tions,multipleexecutionsofthesamedistributedprogram maypassthroughdifferentglobal
states. Further, thepredicatemaybetrueinsomeexecution sandfalsein others.
•Duetothenonavailabilityofinstantaneoustimein adistri butedsystem,
–Evenifamonitorﬁndsthepredicatetobetrueinaglobalstat e,itmaynothaveactually
held intheexecution.
–Even if a predicate is true for a transient period, it may not b e detected by intermittent
monitoring.
Hence, periodicmonitoringoftheexecutionisnot adequate .
These challenges are faced by snapshot-based algorithms as well as by a central monitor that
evaluates data collected from the monitored processes. To a ddress these challenges, we can make
twoimportantobservations.
•It seems necessary to examine all the states that arise in the execution, so as not to miss the
predicatebeingtrue. Hence,itseemsusefultodeﬁnepredic ates,notonindividualstates,but
ontheobservationoftheentireexecution.
•For the same distributed program, even given that it is deter ministic, multiple observations
may pass through different global states. Further, a predic ate may be true in some of the
program observations but not in others. Hence it is more usef ul to deﬁne the predicates on
alltheobservationsofthedistributedprogramand notjust on asingleobservationofit.
11.2 ModalitiesonPredicates
Toaddresstheabovecomplications,predicatesaredeﬁned, notonglobalstatesoronanindividual
observation of an execution, but on all the possible observa tionsof the distributedexecution. The
followingtwomodalitieson anypredicate φaredeﬁned.
•Possibly (φ): There exists a consistent observation of the execution suc h that predicate φ
holdsinaglobalstateoftheobservation.
•Definitely (φ): Foreveryconsistentobservationoftheexecution,theree xistsaglobalstate
ofitinwhich predicate φholds.
ConsidertheexampleinFigure11.2(a). Theexecutionisrun atprocesses P1andP2. Eventek
i
denotesthektheventatprocess Pi. VariableaislocaltoP1andvariable bislocaltoP2. Thestate
latticefortheexecutionisshowninFigure11.2(b). Each st ateis labeledbyatuple (c1,c2), where
c1andc2are the event counts at P1andP2, respectively. The execution shown in part (a) goes
through the following sequence of global states, and events causing the state transitions between
373
theglobalstates.
(0,0),e1
2,(0,1),e1
1,(1,1),e2
2,(1,2),e2
1,(2,2),e3
2,(2,3),e4
2,(2,4),e3
1,(3,4),e4
1,(4,4),e5
2,(4,5),e5
1,
(5,5),e6
1,(6,5),e6
2,(6,6),e7
2,(6,7)
When the same distributed program is run again, observe that it may not pass through the same
intermediatestatesas thestatetransitionsfrom theiniti alstate(0,0)to theﬁnal state(6,7).
•Now observe that Definitely (a+b= 10)holds by the following reasoning. When bis
assigned7atevent e1
2, processP1’sexecutionmaybeinanystatefrom theinitialstateupto
the state preceding event e3
1, in whicha= 3. However, before the value of bchanges from
7 to5 atevent e4
2, andin fact before P2executesevent e3
2,P1musthaveexecutedevent e1
1at
whichtimea= 3. Thisistrueforallequivalentexecutions. Hence, Definitely (a+b= 10)
holds. With respect to the state lattice in Figure 11.2(b), t he states in which a+b= 10is
true are marked therein. From the state lattice, it can be see n that in every execution, the
state(2,2)mustoccur, and inthisstate a+b= 10.
•Observethat Possibly (a+b= 5)holdsbythefollowingreasoning. Thepredicate a+b= 5
can be true only if: (i) a= 3∧b= 2, which is true in states (2,5) and (3,5), or (ii)
a= 0∧b= 5, which is true in state (6,4), or (iii) a= 8∧b=−3which is true
in state (5,7), in some equivalent execution. State (i) is po ssible in physical time after the
occurrence of event e5
2and before the occurrence of e4
1. In the execution shown, e5
2occurs
aftere4
1. However, in an equivalent execution, event e4
1may be delayed to occur after event
e5
2, in which case bchanges to a value other than 2 after abecomes 8. Hence, the predicate
is true in this equivalent execution. It so happens that a sim ilar argument also holds for (ii)
and (iii).
•PredicateDefinitely (a+b= 5)is not true in the shown execution because there exists at
least one path through the state lattice such that a+b= 5is never true in any state along
thatpath.
11.2.1 Complexity of Predicate Detection
As we suspect from the examples in this section, the predicat e detection problem is complex. For
nprocesses and a maximum of mevents per process, we need to examine up to an exponential
numbermnstates. Theglobalpredicatedetectionproblemcanbereadi lyshowntobeNP-complete
usingastandardreduction fromthesatisﬁabilityproblem( seeExercise4).
11.3 CentralizedAlgorithmforRelationalPredicates
To detect predicates, we ﬁrst assume that the state lattice i s available. A global state GS=
{sk1
1,sk2
2,...,sknn}isabbreviatedas GSk1,k2,...kn.
374
3 1
1111 11
76 5 32
22 2 24
(a)local
var.var.local
2
21b = 7 b = 5 b = 2 b = −3a = 0 a = 8 a = 3
465
2 2e e ee e eeee e
ee
timee
p
2p
1
5,4
6,44,3
5,3
6,3 4,53,5
6,65,54,43,32,3
2,4
2,53,2
4,2
3,4
(b)1P2Pa+b = 10
a+b = 5a+b = 5a+b = 5
a+b = 10initial state
final state 6,75,75,6 6,55,2
6,22,11,11,0
2,0
2,21,20,20,10,0
Figure 11.2: Example to illustrate Possibly (φ)andDefinitely (φ). (a) The example execution.
(b)Thestatelatticefortheexecution. Each labelin thelat ticegivestheeventcount at P1,P2.
•Possibly (φ): To detect Possibly (φ), an exhaustive search of the state lattice for any one
state that satisﬁes φneeds to be done. The search can terminate as soon as such a sta te is
found. Presumably, there is particular interest in ﬁnding t he ‘earliest’ state that satisﬁes φ.
The level of a global state ∝a\}⌊ra⌋k⌉tl⌉{tski
i(∀i)∝a\}⌊ra⌋k⌉tri}htis/summationtexti=n
i=1ki. The algorithm in Figure 11.3 examines the
state lattice level-by-level, beginning from the initial s tate at level 0 and going to the ﬁnal
state. Each level is examined to ﬁnd a state in which φis true. If such a state is found, the
algorithmterminates.
•Definitely (φ): ForDefinitely (φ)to be true, thereshould exista set of states satisfying φ
such that every path through the lattice goes through one of t hese states. It is sufﬁcient but
not necessary that all the states at any particular level in t he lattice satisfy φ. To see this,
consider the executionin Figure 11.4. Here, Definitely (φ)is true, yet the states satisfying
φareat differentlevels.
AsDefinitely (φ)maybetruebuttheremaynotexistanylevelinwhichallthest atessatisfy
φ, the algorithm in Figure 11.3 to detect Definitely (φ)cannot use an approach similar to
that used for Possibly (φ). In particular, replacing the loop condition in line (1a) by the
followingwillnotwork: “(somestatein Reach φsatisﬁes¬φ)”. Thealgorithmexaminesthe
statelatticelevel-by-levelbutdiffers inthefollowingt worespects.
1. Ratherthantrackthestates(atalevel)inwhich φistrue,ittracksthestatesinwhich φ
isnottrue.
375
(variables)
setofglobalstates Reach φ,Reach_Next φ←−{GC0,0,...0}
intlvl←−0
(1)Possibly (φ)
(1a)while(no stateinReach φsatisﬁesφ)do
(1b) if(Reach φ={final state})then return false;
(1c)lvl←−lvl+ 1;
(1d)Reach φ←−{statesatlevel lvl};
(1e)returntrue.
(2)Definitely (φ)
(2a) removefrom Reach φthosestatesthatsatisfy φ
(2b)lvl←−lvl+ 1;
(2c)while(Reach φ∝\⌉}atio\slash=∅)do
(2d)Reach_Next φ←−{statesoflevel lvlreachable from astatein Reach φ};
(2e) removefrom Reach_Next φallthestatessatisfying φ;
(2f) ifReach_Next φ={ﬁnal state} then return false;
(2g)lvl←−lvl+ 1;
(2h)Reach φ←−Reach_Next φ;
(2i)returntrue.
Figure11.3: Detectingarelational predicatebyexamining thestatelattice(on-line,centralized).
2. Additionally, the set of states tracked at a level have to b e reachable from the set of
thosestatesatthepreviouslevel,thatareknowntosatisfy (1)andrecursivelythissame
property (2).
The variable Reach_Next φis used to track such states at level lvl, as constructed from the
statesatthepreviouslevel. Thus, Reach_Next φatlevellvlcontainsthesetofstatesatlevel
lvlthatarereachablefromtheinitialstate withoutpassingthroughanystatesatisfying φ. The
algorithmterminates successfully when Reach_Next φbecomes theempty set; otherwise it
terminatesunsuccessfullyafter examiningtheﬁnal state.
Example: Figure11.4showsan exampleexecutionandthecorrespondin gstatelattice. The
statesbelongingto Reach_Next φ(line(2d))atanylevelareeithermarkedbyshadedcircles
orclearcircles. Thestatesbelongingto Reach_Next φ(line(2f))atanylevelaremarkedby
clear circles. In line (2b), when lvl= 11,Reach φbecomes∅and the algorithm exits from
theloop.
The centralized algorithms in Figure 11.3 assumed that the s tates at any level were readily
available. But in an on-line algorithm, these global states need to be assembled from local states,
ontheﬂy. Howcanthatbeaccomplished? Eachprocess Picansendalocaltraceofitslocalstates
ski
i, with theirvector timestamps,to thecentral process P0.P0maintainsnqueues,Q1...Q n, for
376
76
15
114 3
1121
1
21P
P1
(a)27
26
254
223 1
22
218
ee e e e e eeeeeeeee2,3
5,2
4,63,43,2
4,22,21,1state lattice labelled using event numbers
5,5
(b)0
1
2
3
4
5
6
987
10
11
12
13
14
15levels
state reachable without predicate being truestate in which predicate is truep2 p1initial0,0
7,46,5/0/0/1/1/0/0/1/1/0/0/1/1/0/0/1/1
/0/0/1/1/0/0/1/1/0/0/1/1/0/0/1/1/0/0/1/1/0/0/1/1
/0/0/1/1
/0/0/1/1
Figure 11.4: Example to show that states in which Definitely (φ)is satisﬁed need not be at the
samelevelin thestatelattice. (a) Execution. (b)Correspo ndingstatelattice.
P2
PQ1
Q2
QnZ1X1 X2
Y1 Y2 Y3 Y4X1X2
Y4 Y3 Y2 Y1
Z11
nP
Figure11.5: Queues Q1toQnforeach ofthe nprocesses.
theeventsofeachoftheprocesses,asshowninFigure11.5. E achlocalstatereceivedfromprocess
Piis enqueued in Qi. As global state GS={sk1
1,sk2
2,...,sknn}, also abbreviated as GSk1,k2,...kn,
isassembledfromthecorrespondinglocalstates,howlongd oesalocalstateneed tobekeptinits
queue? Thisisanswered bythefollowingtwoobservations,b ased onthevectorclocks.
•The earliest global state GSk1,k2,...kn
mincontainingski
iis identiﬁed as follows. The jthcompo-
nent ofVC(ski
i)is the local value of Pjin its local snapshot state skj
j. This is expressed as
Equation11.1.
(∀j)VC(skj
j)[j] =VC(ski
i)[j] (11.1)
Itnowfollowsthatthelowestlevelofthestatelattice,inw hichlocalstate ski
i(kthlocalstate
ofPi)participates,isthesumofthecomponentsof VC(ski
i)–thisassumesthatinthevector
clock operation,thelocal componentisincrementedby onef oreach local event.
377
•Thelatestglobalstate GSk1,k2,...knmaxcontainingski
iisidentiﬁedasfollows. The ithcomponent
ofVC(skj
j)should be the largest possible value but cannot exceed or equ alVC(ski
i)[i]for
consistencyofthetwostates ski
iandskj
j.VC(ski
i)isidentiﬁedasperEquation11.2;butnote
thattheconditionon VC(skj+1
j)[i]isapplicableif skj
jisthelaststateat Pj.
(∀j)VC(skj
j)[i]<VC (ski
i)[i]≤VC(skj+1
j)[i] (11.2)
Hence,thehighestlevelofthestatelattice,inwhichlocal stateski
iparticipates,is/summationtextn
j=1VC(skj
j[j])
subjecttotheaboveequation.
FromExpressions11.1and11.2,wehavethat/summationtextn
j=1VC(ski
i)[j]isthelowestlevel,and/summationtextn
j=1VC(skj
j[j]),
whereskj
j∈GSmax, is the highest level, between which local state ski
iis useful in constructing a
globalstate.
Given the states of level lvl, the set of states at level lvl+ 1can be constructed as fol-
lows. For each state GSk1,k2,...,k n, construct the nglobal states GSk1+1,k2,...,k n,GSk1,k2+1,...,k n...
GSk1,k2,...,k n+1.
Deterministicversusnondeterministic programs: Weneedtorememberthattheentireanalysis
of predicates, their modalities, and detection algorithms , applies only to deterministic programs.
Fornon-deterministicprograms,differentexecutionsmay havedifferentpartial orders.
11.4 ConjunctivePredicates
The predicates considered so far are termed relational predicates because the predicate can be an
arbitrary relation on the variables in the system. A predica teφis aconjunctive predicate if and
onlyifφcanbeexpressedastheconjunction ∧i∈Nφi,whereφiisapredicatelocaltoprocess i. For
a wide range of applications, the predicate of interest can b e modeled as a conjunctive predicate.
Conjunctivepredicates havethefollowingproperty.
•Ifφis false in any cut C, then there is at least one process isuch that the local state of iin
cutCwill never form part of any other cut C′such thatφis true inC′. More formally, a
conjunctivepredicate φis deﬁned as thefollowing.
C∝\⌉}atio\slash|=φ=:∃i∈N,∀C′∈Cuts,C′∝\⌉}atio\slash|=φ,whereC′[i] =C[i]
Here,thestate C[i]isaforbiddenstate becauseitwillneverformpartofanycutthatsatisﬁes
the predicate. Given a conjunctive predicate, if it is evalu ated as false in some cut C, we
can advance the local state of at least one process to the next event, and then evaluate the
predicateintheresultingcut.
This givesa O(mn)timealgorithm, where mis thenumber of eventsat any process, to check for
alinearpredicate, as opposedtoan exponentialalgorithm.
Consider the following example on modalities on conjunctiv e predicates, shown for the same
executionconsidered earlierin Figure11.2.
378
P21P0P
Figure 11.6: For a conjunctivepredicate, the shaded durati ons indicate the periods when the local
predicates aretrue.
•Thepredicate Possibly (a= 3∧b= 2)holdsbythefollowingreasoning. Thepredicatecan
betrueonly ifa= 3∧b= 2simultaneously in the execution. This is possible in physic al
timeaftertheoccurrenceofevent e5
2andbeforetheoccurrenceof e4
1. Intheexecutionshown,
e4
1occurs before e5
2. However, in an equivalent execution, event e4
1may be delayed to occur
after evente5
2, in which case, achanges to a value other than 3 after bbecomes 2. Hence,
Possibly (a= 3∧b= 2)istrue. NotethatinFigure11.2, a+b= 5wastrueinstates (2,5),
(3,5),(6,4),and(5,7). Amongthese, a= 3∧b= 2istrueonlyin (2,5)and(3,5).
•Definitely (a= 3∧b= 7)holds by the following reasoning. When ais assigned 3 at
evente1
1, processP2’s execution may be at any event from e0
2up to but not including e3
2.
However,beforethevalueof achangesfrom3to8atevent e4
1,P2musthaveexecutedevent
e2
2at which time b= 7. This is true for all equivalent executions. Note that in Fig ure 11.2,
a+b= 10was true in states (1,1),(2,1),(1,2),(2,2),(3,2),(2,3),(3,3),(4,5),(5,5),
and(5,6). Amongthese, a= 3∧b= 7is trueonlyin allexcept (4,5),(5,5),and(5,6).
11.4.1 Interval-basedCentralized Algorithm for Conjunct ive Predicates
Conjunctivepredicatesareapopularclassofpredicates. C onjunctivepredicateshavetheadvantage
thateachprocesscanlocallydeterminewhetherthelocalco mponentφiissatisﬁed;ifnot,thelocal
state cannot be part of any global state satisfying φ! This has the following implication: starting
with the initial state, we examine global states. If φis not satisﬁed, then the local state of at least
one process can be advanced and the next global state is exami ned. Either φis satisﬁed, or we
repeat the step. Within mnsteps, we will have examined all necessary global states, gi ving a
O(mn)upperboundon thetimecomplexity.
There are two broad approaches to detecting conjunctive pre dicates: the global state based
approach, and the intervalbased approach. The global state based approach involves ex amining
theglobalstates,as suggestedaboveand also seenin thepre viousSection 11.3.
In the interval-based approach, each process identiﬁes alt ernating time durations when the
localpredicatealternatesbetween trueandfalse. ThisisillustratedinFigure11.6. Letusconsider
any two processes PiandPj, and let the intervals at these processes when the local pred icates
φiandφjare true be denoted XiandYj, respectively. Let the start and end of an interval Xbe
379
max(X)
max(Y) min(Y)min(X) min(X) max(X)
min(Y) max(Y)X
Y YX
(a) Definitely(phi) (b) Possibly(phi)
Figure 11.7: Illustratingconditionsfor Definitely (φ)and¬Possibly (φ),for twoprocesses.
denoted asmin(X)andmax(X), respectively. Assume the global predicate is deﬁned on the se
two processes. We can observethe followingdeﬁnitions of Definitely (φ)andPossibly (φ)with
theaidofFigure11.7.
Definitely (φ) :min(X)≺max(Y)/logicalanddisplay
min(Y)≺max(X) (11.3)
Possibly (φ) :max(X)≺min(Y)/logicalordisplay
max(Y)≺min(X) (11.4)
When the global predicate is deﬁned on more than two processe s, the following results for
Possibly andDefinitely are expressible in terms of Possibly andDefinitely for pairs of pro-
cesses. Theresultscan beobservedtobetruewiththehelpof Figure11.6.
Definitely (φ)if and only if∧i,j∈NDefinitely (φi∧φj) (11.5)
Possibly (φ)if and only if∧i,j∈NPossibly (φi∧φj) (11.6)
Figure 11.8 gives an algorithm that is run by a central server P0to detectPossibly (φ)or
Definitely (φ)for a conjunctive predicate φ. Whenever an interval completes, a process could
send the vector timestamp of the start and of the end events of that interval as a Logentry to the
central server process. But observe that for any two local in tervalsYandY′, if there is no send
or receive event between the start of the previous interval a nd the end of the latter interval, then
YandY′have the exact same relation with respect to all other interv als at all other processes.
Hence, an interval needs to be sent to P0if there is a send or receive event since the start of the
previous interval and the end of this interval. Each executi on message thus causes at most four
controlmessagesto P0– twoat thesenderand two atthereceiver.
Thealgorithmusestwoqueues, updatedQueues andnewUpdatedQueues . TheupdatedQueues
stores the indices of all the queues whose heads got updated. The latter is a temporary variable
for updating updatedQueues . A queuegets updated when a new intervalpotentiallybecome s the
head of the queue; such a new interval becomes a ‘candidate’ i nterval for the solution. A queue
gets updatedunder twosituations: (1)anew intervalis enqu eued on to an emptyqueue, or(2)the
currentheadofaqueuegetsdeletedbecauseitisdetermined thatitcannotpossiblybeapartofthe
solution. Each new candidate interval (i.e., head of some qu eue) is examined with respect to the
380
headsofallotherqueues,inaccordancewithEquations 11.3 and 11.4,todetermineifthedesired
modality is satisﬁed. In each comparison, if the desired mod ality is not satisﬁed, one of the two
intervalsexaminedis markedfordeletion(and thecorrespo ndingqueueissaidto beupdated).
•Speciﬁcally, statements (12)-(15) can be used to check for Definitely (φ)in accordance
withEquation11.3.
•Statements (12’)-(15’) can be used to check for Possibly (φ)in accordance with Equa-
tion11.4.
ThesetupdatedQueues storestheindicesofallthequeueswhoseheadsgetupdated. Ineachitera-
tionofthe whileloop,theindexofeachqueuewhoseheadisupdatedisstoredi nsetnewUpdatedQueues
(lines(12)-(15) or(12’)-(15’)). Inlines(16)and(17),theheadsofalltheseq ueuesaredeletedand
indices ofthe updated queues are stored in theset updatedQueues . Thus, an intervalgets deleted
only if it cannot be part of the solution. Now observe that eac h interval gets processed unless a
solution is found using an interval from each process. From E quations 11.5 and 11.6, if every
queueisnon-emptyandtheirheadscannotbepruned,thenaso lutionexistsandthesetofintervals
at thehead ofeach queueformsasolution.
Termination: Ifa solutionexists,it is eventuallydetected by lines (18) -(19). Otherwise, P0waits
to receive an interval from some process. The code can be modi ﬁed to detect the end of the
executionat aprocess, and tonotify P0aboutit.
Complexity: Letpbethenumberofintervalsperprocess,and Mbethenumberofmessagessent
intheexecution.
Messagecomplexity: Thenumberofcontrolmessagessentbythe nprocessesto P0ismin(pn,4M).
The ﬁrst term denotes a message being sent for each interval c ompleted. The second term
denotes that at most 4 control messages get sent for each exec ution message, in accordance
with the observation made earlier. Each control message con tains the vector timestamp,
whichhas size nintegers.
Space complexity: Thespacecomplexityat P0ismin(pn,4M)·2nbecausealltheintervalsmay
haveto bequeuedup amongthequeues Q1,...Q n.
Timecomplexity: When an interval is compared with others (loop in lines (9)-( 15)), there are
O(n)steps in one such comparison. Any interval participates in a t mostnsuch compar-
isons before at least one interval gets deleted (otherwise a solution is found). As there are
min(pn,4M)·2nintervals,thetimecomplexityis O(n·n·(min(pn,4M))).
11.4.2 Global State based Centralized Algorithm for Possibly (φ), whereφ
is conjunctive
A moreefﬁcient algorithmto detect Possibly (φ)than thegenericalgorithmin Figure11.8can be
devisedbytailoringan algorithmto thisspeciﬁc modality.
381
queueof Log:Q1,Q2,... Q n⇐=⊥
set ofint:updatedQueues ,newUpdatedQueues ⇐={}
Onreceiving interval from process PzatP0:
(1) Enqueue the interval onto queue Qz
(2)if(number ofintervals on Qzis1)then
(3) updatedQueues←−{z}
(4)while(updatedQueues isnot empty)
(5) newUpdatedQueues ←−{}
(6) foreachi∈updatedQueues
(7) if(Qiis non-empty) then
(8) X←−head of Qi
(9) forj= 1ton
(10) if(Qjis non-empty) then
(11) Y←−head of Qj
(12) if(min(X)∝\⌉}atio\slash≺max(Y))then //Definitely
(13) newUpdatedQueues ←−{j}∪newUpdatedQueues
(14) if(min(Y)∝\⌉}atio\slash≺max(X))then //Definitely
(15) newUpdatedQueues ←−{i}∪newUpdatedQueues
(12’) if(max(X)≺min(Y))then //Possibly
(13’) newUpdatedQueues ←−{i}∪newUpdatedQueues
(14’) if(max(Y)≺min(X))then //Possibly
(15’) newUpdatedQueues ←−{j}∪newUpdatedQueues
(16) Delete heads ofall Qkwhere k∈newUpdatedQueues
(17) updatedQueues←−newUpdatedQueues
(18)if(all queues arenon-empty) then
(19) solution found. Heads ofqueues identify intervals tha t form the solution.
Figure 11.8: Detecting a conjunctive predicate (centraliz ed, on-line) for Possibly orDefinitely
modality. For Definitely (φ), lines(12)-(15) are executed. For Possibly (φ),lines (12’)-(15’) are
executed. Todetect both,disjointdatastructuresare requ ired.
Observethat Possibly (φ)holdsifandonlyifthereisaconsistentglobalstateinthee xecution
inwhichφholds. Thus,detecting Possibly (φ)isequivalenttoidentifyingaconsistentglobalstate
in which the local state at each process Pisatisﬁesφi. In this consistent global state, for any two
local statessiandsjatPiandPj, respectively,thefollowingmusthold.
(mutuallyconcurrent) ∀i,∀j, si∝\⌉}atio\slash≺sj∧sj∝\⌉}atio\slash≺si (11.7)
Each process Pisends the vector timestamp of the local state when φibecomes true, to the server
processP0. Infact,suchamessageneedstobesentonlyeachtimethatth elocalpredicatebecomes
truefor theﬁrst timesincethepreviouscommunicationeven t. Thisis because internal eventsthat
arenotseparatedbycommunicationeventsareequivalentin termsofconsistentglobalstates. The
algorithminFigure11.9tracksthemostrecentglobalstate thatcanpotentiallysatisfy Possibly (φ)
usingatwo-dimensionalarray GS[1...n,1...n],whererow GS[i]storesthevectortimestampof
382
typeLog
start: array [1... .n]ofinteger;
end: array [1... .n]of integer;
array ofinteger :GS[1... n,1... n]; // ith row tracks vector time of Pi
array ofboolean :V alid [1... n]; // V alid [j] = 0implies PjstateGS[j,·]needs to beadvanced
queueof Log:Q1,Q2,... Q n←−⊥; // Qistores timestamp info from Pi
(1)while(∃j|V alid [j] = 0)do //Pj’sstate GS[j,·]is not consistent withothers
(2) if(Qj=⊥andPjhas terminated) then
(3) return(0) ;
(4) else
(5) await Qjbecomes non-empty;
(6) GS[j,1... n]←−head(Qj); //Consider next state of Pjfor consistency
(7) dequeue (head(Qj));
(8) V alid [j]←−1;
(9) fork= 1tondo //Check Pj’sstate w.r.t. Pk’sstate (for every Pk)
(10) ifk∝\⌉}atio\slash=jandV alid [k] = 1then
(11) ifGS[j,j]≤GS[k,j]then //Pj’sstate is inconsistent with Pk’s state
(12) V alid [j]←−0; //next state of Pjneeds tobe considered
(13) else if GS[k,k]≤GS[j,k]then //Pk’sstate isinconsistent with Pj’s state
(14) V alid [k]←−0; //next state of Pkneeds to beconsidered
(15)return(1) .
Figure 11.9: Global state based detection of a conjunctive p redicate (centralized, on-line,
Possibly).
thelocal stateofprocess Pi. AtP0, thequeuingofthevectortimestampsreceivedfrom PiintoQi
is not shownexplicitly. The algorithm run by P0picks any process Pjsuch thatValid [j] = 0and
dequeues the head of Qjfor consideration of consistency with respect to the curren t states of all
processes (lines (6-8)). The main check is in lines (9)-(14) wherePj’s stateis checked for mutual
consistencywith Pk’sstate, forall k.
•IfPj’sstateisoldandhencecausesinconsistency,itismarkeda sinvalid(lines(11-12)). See
Fig 11.10(a).
•IfPk’s state is old and hence causes inconsistency, it is marked a s invalid (lines (13-14)).
See Fig11.10(b).
After this main check, the algorithm continues in the main whileloop and picks another process
Pjsuch thatValid [j] = 0. A consistentstateisdetected when Valid [j] = 1forallj.
Termination: Thealgorithmterminatessuccessfully(line(15))if Valid [j] = 1forallj,indicating
asolutionisfound. Itterminatesunsuccessfully(line(3) )ifsomeprocessterminatesanditsqueue
isempty.
383
(b) (a)kj
GS[k,j]GS[j,j] GS[j,k]
GS[k,k]
Figure11.10: InthealgorithmofFigure11.9, P0testswhether Pj’sandPk’scandidatelocalstates
are consistentwitheach other. (a) Pj’s oldstateis invalid. (b) Pk’s oldstateisinvalid.
Complexity: Letmbe the number of local states at any process. Let Mdenote the total number
ofmessagessentin theexecution.
Timecomplexity: Asthereareatmost mnlocalstatesthatareprocessedby P0,andforeachsuch
local state, the forloop in line(9) is invoked once and requires 2ninteger comparisons, the
timecomplexityofthealgorithmis O(n2m).
Space complexity: The space complexity at P0isO(n2m)because there are at most mnstates,
each represented as avectortimestamp,thatcan bequeued am ongthenqueuesQ1toQn.
Messagecomplexity: The number of control messages sent by the nprocesses to P0is2M, and
each messagecontainsthevectortimestamp,whichhas size nintegers.
11.5 DistributedAlgorithmsfor ConjunctivePredicates
11.5.1 DistributedState-basedTokenAlgorithmfor Possibly (φ),whereφis
Conjunctive
ThealgorithminFigure11.11isa distributedversionofthe algorithminFigure11.9. Each queue
Qiismaintainedlocallyat Pi. Thedatastructure GSnolongerneedstobea n×narray. Instead,a
uniquetokenispassedamongtheprocessesserially. Thetok encarries avector GScorresponding
tothevectortimestampoftheearliest globalstateunderco nsiderationasa candidatesolution.
A processPireceives a token only when Token.Valid [i] = 0. All local states of Piup to
Token.GS [i]will necessarily be notconsistent with the earliest possible candidate local stat e of
some other process. So Pihas to now consider from its local queue Qi, the ﬁrst local state with
timestamp greater than Token.GS [i](lines (3)-(6)). Based on such a state of Pi, now written to
Token.GS [i]in line (4), for each j,Pinow determines in line (8) whether Pj’s candidate local
stateToken.GS [j]isconsistentwith Token.GS [i]. ThistestisillustratedinFigure11.12.
•Iftheconditioninline(8)istrue(Figure11.12(a)), Pj’sstateisnotconsistent. Token.Valid [j]
isreset. Thisimpliesthatthetokenmustvisit Pjbeforeterminationofthealgorithmand Pj
needs toﬁnd alocal statethat ismutuallyconsistentwith al ltheotherstates in Token.GS .
384
structtoken{
arrayofinteger :GS[1. . .n]; //Earliestpossibleglobalstate asa candidatesolution
arrayofboolean :V alid [1. . .n];}Token ;//V alid [j] = 0indicates Pj’sstate GS[j]isinvalid
queue of Log:Qi←−⊥
Initialization. Tokenis ata randomlychosenprocess.
Onreceiving TokenatPi
(1)while(Token.V alid [i] = 0)do//Token.GS [i]isthelatest state of Piknowntobe inconsistent
(2)await(Qitobenonempty); //with othercandidatelocalstate of Pj, forsome j
(3)if((head(Qi))[i]> Token.GS [i])then
(4) Token.GS [i]←−(head(Qi))[i]; // earliest possiblestate of Pithat canbepartofsolution
(5) Token.V alid [i]←−1; //is writtento Tokenanditsvalidityis set.
(6)else dequeue head(Qi);
(7)forj= 1ton(j∝\⌉}atio\slash=i)do// foreachotherprocess Pj: basedon Pi’slocalstate, determinewhether
(8)ifj∝\⌉}atio\slash=iand(head(Qi))[j]≥Token.GS [j]then //Pj’scandidatelocalstate (in Token)
(9) Token.GS [j]←−(head(Qi))[j]; // isconsistent. Ifnot, Pjneedsto considera
(10) Token.V alid [j]←−0; // latercandidatestate witha timestamp > head ((Qi)[j]
(11)dequeue head(Qi);
(12)ifforsome k,Token.V alid [k] = 0then
(13)sendTokentoPk;
(14)else return(1) .
Figure 11.11: Global state based detection of a conjunctive predicate (distributed, on-line,
Possibly). Code shownisfor Pi,1≤i≤n.
•Iftheconditioninline(8)isfalse(Figure11.12(b)), Pj’s stateisconsistent.
Termination: The algorithm ﬁnds a solution when Token.Valid [j]is 1, for all j(line (14)).
If a solution is not found, the code hangs in line (2). The code can be modiﬁed to terminate
unsuccessfullyin line(2)by modelingan explicit‘process terminated’stateinthiscase.
Complexity:
Timecomplexity: Each time a token is received by Pi, at least one local state is examined and
deleted. This involves O(n)comparisons in the main loop (lines (7)-(10)). Assuming a
total ofmstates at a process, the time overhead at a process is O(mn). The time overhead
across processes is cumulativeas the token travels seriall y. Hence, total time complexity is
O(mn2).
Space complexity: In theworstcase, all thelocal statesmayget queuedin Qi,leadingto aspace
requirementof O(mn). Acrossall processesthespacerequirementbecomes O(mn2).
Messagecomplexity: Thetokenmakes O(mn)hops,andthesizeofthetoken is 2nintegers.
385
Token.GS[j]Token.GS[j]
head(Q_i)[j]head(Q_i) head(Q_i)
head(Q_i)[j]i
j
(b) (a)
Figure 11.12: In the algorithm of Figure 11.11, Pitests whether Pj’s candidate local state
Token.GS [j]is consistent with head(Qi)[i], which is assigned to Token.GS [i]. The two pos-
sibilitiesareillustrated. (a) Notconsistent. (b)Consis tent.
11.5.2 DistributedInterval-basedTokenAlgorithmfor Definitely (φ),where
φisConjunctive
We now study an interval-based distributedtoken-based alg orithmto detect Definitely (φ)based
on thetestsin Equations11.3and 11.5. Deﬁne Ii֒→Ijas:min(Ii)≺max(Ij).
ProblemStatement. Inadistributedexecution,identifyasetofintervals Icontainingoneinterval
from each process, such that (i) the local predicate φiis true inIi∈I, and (ii) for each pair of
processesPiandPj,Definitely (φi,j)holds,i.e.,Ii֒→IjandIj֒→Ii.
ThealgorithmisgiveninFigure11.14. Thevectortimestamp softhestartofandoftheendof
an interval form a data type Log, as shown in Figure 11.13. When an interval completes at pro-
cessPi, the interval’s Logis added to a local queue Qiselectively , as shown in Figure 11.13.
An interval YatPjis deleted if on comparison with some interval XonPi,X∝\⌉}atio\slash֒→Y, i.e.,
Vi(min(X))[i]∝\⌉}atio\slash≤Vj(max(Y))[i]. Thus the interval ( Y) being deleted or retained depends on
its value of Vj(max(Y))[i]. The value Vj(max(Y))[i]changes only when a message is received.
Hence an interval needs to be stored only if a receive has occu rred since the last time a Logof a
local intervalwas queued.
Thetoken-basedalgorithmusesthreetypesofmessages(see Figure11.14)thataresentamong
theprocesses. Requestmessagesoftype REQUEST ,replymessagesoftype REPLY ,andtoken
messagesoftype TOKEN , aredenoted REQ,REP, andT, respectively. Onlythetoken-holder
processcan send REQsand receive REPs. Theprocess( Pi)havingthetokensends REQs toall
other processes (line 3f). Logi.start[i]andLogi.end[j]for the interval at the head of the queue
Qiare piggybacked on the request REQsent to process Pj(lines 3c-3e). On receiving a REQ
fromPi, processPjcompares the piggybacked interval Xwith the interval Yat the head of its
queueQj(line 4e). The comparisons between intervals on process PiandPjcan result in these
outcomes. (1) Definitely (φi,j)is satisﬁed. (2) Definitely (φi,j)is not satisﬁed and interval X
can be removed from the queue Qi. The process index iis stored inREP.updated (line 4f). (3)
Definitely (φi,j)is not satisﬁed and interval Ycan be removed from the queue Qj. The interval
386
typeLog
start: array [1....n]ofinteger;
end: array [1....n]ofinteger;
typeQ:queueofLog;
When an intervalbegins:
Logi.start←−Vi.
When an intervalends:
Logi.end←−Vi
if(areceiveeventhasoccurred sincethelasttimea Logwas queuedon Qi)then
EnqueueLogion tothelocalqueue Qi.
Figure 11.13: Maintaining intervals for detection of a conj unctive predicate (distributed, on-line,
Definitely ).
at the head of Qjis dequeued and process index jis stored inREP.updated (lines 4g, 4h). Note
that outcomes (2) and (3) may occur together. After the compa risons,PjsendsREPtoPi. Once
the token-holder process Pireceives aREPfrom all other processes, it stores the indices of all
the updated queues in the set T.updatedQueues (lines 3h, 3i). A solution, identiﬁed by the set I
formed by the interval Ikat the head of each queue Qk, is detected if the set updatedQueues is
empty. Otherwise, if index iis contained in T.updatedQueues , processPideletes the interval at
the head of its queue Qi(lines 3m, 3n). As the set T.updatedQueues is non-empty, the token is
sentto aprocess selectedrandomlyfrom theset (line3o).
ThecruxofthecorrectnessofthisalgorithmisbasedonEqua tions11.3and11.5for Definitely (φ).
Wecan makethefollowingobservationsfromthealgorithm.
•IfDefinitely (φi,j)is not true for a pair of intervals XiandYj, then either iorjis inserted
intoT.updatedQueues .
•An interval is deleted from queue Qiat processPiif and only if the index iis inserted into
T.updatedQueues .
•When a solutionIis detected by the algorithm, the solution is correct, i.e., for each pair
Pi,Pj∈N, the intervals Ii=head(Qi)andIj=head(Qj)are such that Ii֒→Ijand
Ij֒→Ii(and henceby Equations11.3and 11.5, Definitely (φ)mustbetrue).
•If a solutionIexists, i.e., for each pair Pi,Pj∈N, the intervals Ii,Ijbelonging toIare
suchthatIi֒→IjandIj֒→Ii(and henceDefinitely (φ)mustbetrue), thenthesolutionis
detected bythealgorithm.
Complexity: The complexity analysis can be done in terms of two parameter s – the maximum
numberofmessagessent perprocess ( m)and themaximumnumberofintervalsperprocess ( p).
387
typeREQUEST //usedby Pito sendarequesttoeach Pj
start: integer; //contains Logi.start[i]forthe intervalat thequeueheadof Pi
end: integer; //contains Logi.end[j]fortheintervalat thequeueheadof Pi, whensendingto Pj
typeREPLY //usedtosenda responsetoa receivedrequest
updated: set ofinteger; //containstheindicesoftheupdatedqueues
typeTOKEN //usedtotransfercontrolbetweentwoprocesses
updatedQueues : set ofinteger; //containstheindexofall theupdatedqueu es
(1)Process Piinitializeslocal state
(1a) Qiisempty.
(2)Tokeninitialization
(2a) A randomlyelectedprocess Piholdsthetoken T.
(2b) T.updatedQueues ←−{1,2, . . ., n}.
(3)RcvToken :When Pireceivesa token T
(3a) Removeindex ifromT.updatedQueues
(3b)waituntil (Qiisnonempty)
(3c) REQ.start←−Logi.start[i], where Logiisthe logat headof Qi
(3d)forj=1 to n
(3e) REQ.end←−Logi.end[j]
(3f) Sendtherequest REQtoprocess Pj
(3g)waituntil (REP jisreceivedfromeachprocess Pj)
(3h)forj=1 to n
(3i) T.updatedQueues ←−T.updatedQueues ∪REP j.updated
(3j)if(T.updatedQueues isempty) then
(3k) Solutiondetected. Headsofthequeuesidentifyinterv alsthatformthe solution.
(3l)else
(3m) if(i∈T.updatedQueues )then
(3n) dequeuetheheadfrom Qi
(3o) Sendtokento Pkwhere kisrandomlyselectedfromthe set T.updatedQueues .
(4)RcvReq :Whena REQfromPiis receivedby Pj
(4a)waituntil (Qjisnonempty)
(4b) REP.updated←−φ
(4c) Y←−headoflocalqueue Qj
(4d) V−
i(X)[i]←−REQ.start andV+
i(X)[j]←−REQ.end
(4e) Determine X ֒→YandY ֒→X
(4f)if(Y∝\⌉}atio\slash֒→X)thenREP.updated←−REP.updated∪{i}
(4g)if(X∝\⌉}atio\slash֒→Y)then
(4h) REP.updated←−REP.updated∪{j}
(4i) Dequeue Yfromlocalqueue Qj
(4j) Sendreply REPtoPi.
Figure 11.14: Interval based detection of a conjunctive pre dicate (distributed, on-line,
Definitely ).
388
Space complexity: Thisisanalyzed foreach process,and fortheentiresystem.
•Theworst-casespaceoverheadacross alltheprocessesis 2mn2. Theworst-casespace
overhead atany processis O(mn2).
•The total number of Logs stored at each process is pbecause in the worst case, the
Logfor each interval may need to be stored. As each Loghas size 2n, the worst-case
overheadis 2npintegersoverall Logsperprocess,andtheworst-casespacecomplexity
across all processes is 2n2p=O(n2p).
Asthetotalnumberof Logsstoredonalltheprocessesis min(np,mn ),theworst-casespace
overheadacross alltheprocessesis min(2n2p,2n2m). Thisisequivalentto min(2np,2nm)
perprocessifthe mnmessagedestinationsaredividedequallyamongtheprocess es(imply-
ingthateachprocesshasupto min(p,m)Logs). Theworst-casespaceoverheadataprocess
ismin(2np,2n(n−1)m).
Timecomplexity: Thetwocomponentscontributingtotimecomplexityare RcvReqandRcvToken .
RcvReq:In the worst case, the number of REQs received by a process is equal to the
number ofLogs on all other processes, because a REQis sent only once for each
Log. The total number of Logs overall the queues is min(np,mn ), hence the number
of interval pairs compared per process is min((n−1)p,m(n−1)). As it takes O(1)
time to execute RcvReq, the worst-case time complexity per process for RcvReqis
O(min(np,mn )). As the processes execute RcvReqin parallel, this is also the total
timecomplexityfor RcvReq.
RcvToken :The token makes at most min(np,mn )hops serially and each hop requires
O(n)timecomplexity. Hencetheworst-casetimecomplexityfor RcvToken acrossall
processes is O(min(pn2,mn2)). In the worst case, a process receives the token each
time its queue head is deleted, and this can happen as many tim es as the number of
Logs at the process. As the number of Logs at a process is min(p,m(n−1)), the
worst-casetimecomplexityperprocess is O(min(pn,mn2)).
Theworst-casetimecomplexityacrossalltheprocessesis O(min(pn2,mn2)). Thisisequiv-
alent toO(min(pn,mn ))per process if the mnmessage destinations are divided equally
among the processes (implying that each process has up to min(p,m)Logs). The worst-
casetimecomplexityat aprocess is O(min(pn,mn2)).
Messagecomplexity: For eachLog, either no messages are sent, or n−1REQs,n−1REPs
and onetoken Tare sent.
•As the total numberof Logs overall the queues is min(np,mn ), hence the worst-case
numberofmessagesoveralltheprocesses is O(nmin(np,mn )).
389
•The size of each Tis equal toO(n), while the size of each REPand eachREQis
O(1). Thusforeach Log,themessagespaceoverheadis O(n)ifanymessagesaresent
for thatLog. Hence the worst-case message space overhead over all the pr ocesses is
equal toO(nmin(np,mn )).
i
j
klog entry
Least_Sol Current_Conc_Ints
(b) (a)interval
Figure 11.15: Illustrations of deﬁnitions used by the algor ithm in Figure 11.16. (a) Deﬁnition of
an interval. (b)Deﬁnitionsofintervalvectors Least_Sol ,Current_Conc_Ints ,andLogentries.
11.5.3 Distributed Interval-basedPiggybacking Algorith m forPossibly (φ),
whereφis Conjunctive
Unlike the previous algorithm which was a token-based algor ithm to detect Definitely (φ), we
nowlookatadistributedalgorithmfordetecting Possibly (φ)withoutusinganycontrolmessages.
Instead, the algorithm piggybacks the necessary informati on on the application messages. The
algorithmtherefore illustratesadifferent designapproa ch.
In this algorithm, the semantics of an interval is that each interval at a process represents the
duration between two consecutive communication events at t he process. Intervals are sequen-
tially numbered at any process Pi, asI0
i,I1
i,I2
i,.... Two intervals at PiandPjare concurrent if
Possibly (φ)is true as determined by using Equation 11.4, and assuming φiis true inIiandφjis
trueinIj.
Thefollowingvariablesare usedat each process.
•not_yet_logged [1...n], a boolean, is used to determine whether in the current inter val, the
‘sequence number’ of the interval is logged when the predica te ﬁrst became true in this
interval. This variable helps to minimize the number of inte rvals logged, by ensuring that
in any interval, the interval is logged only once in the local log (see below) when the local
predicate ﬁrst becomes true in the interval (lines 1a-1b). L ogging just once is important
when thepredicatemay toggleitstruthvaluemultipletimes withinan interval.
390
•Current_Conc_Ints[1...n], an array ofintegers,is used tokeep track ofthelatestknow n
concurrent set of intervals (as per Equations 11.4 and 11.6) . However, it is not necessar-
ily known whether the local predicates at the various proces ses are true in these intervals,
becausethisarray is updatedat thestartofan interval.
•Least_Sol[1...n], an array of integers, is used to track the least possible glo bal state (i.e.,
set of intervals) that could possibly satisfy Possibly (φ). In other words, no interval at any
process, that precedes that process’s interval in Least_Sol, can ever be part of the solution
globalstate.
Wehavethat(∀k)Current_Conc_Ints[k]≥Least_Sol[k].
•Valid [1...n], a boolean array, tells whether the corresponding interval inLeast_Solis
valid, i.e., whether the local predicate is ever satisﬁed in that interval. Valid [j] = 1means
φjis necessarily satisﬁed in Least_Sol[j]; if 0, it is not yet known whether φjis satisﬁed
becausetheintervalhasnotyet completed.
It follows that Possibly (φ)is true andφis satisﬁed in the state identiﬁed by Least_Sol
when alltheentriesin array Validare true.
•The queueLogat each process tracks the various values (vectors) of inter vals (one interval
per process) that are locally generated, one for each local c ommunication event. In some
sense, this tracks the intermediate states Current_Conc_Intsas they are generated, be-
tween globalstate Least_Soland the‘current’ globalstate Current_Conc_Ints.
Atthetimethelocalpredicatebecomestrueand not_yet_logged isfalse,(i)Current_Conc_Ints
isenqueuedlocally,and(ii)if Current_Conc_Ints[i] =Least_Sol[i],thenValid [i]issettotrue
(lines1c-1d).
ThearrayCurrent_Conc_Ints’slocalcomponentisalwaysupdatedforeachsendandreceiv e
event. The array is also piggybacked on each message sent. Th e receiver takes the maxima of its
local array and thesender’sarray (line3a). Thus,thisglob alstateis alwayskept upto date.
The arrayLeast_Solplays ‘catch up’ with Current_Conc_Ints. At a send event at Pi,
Least_Sol[i]is set toCurrent_Conc_Int[i]if the logLogiis empty (lines 2c-2d). The arrays
Least_SolandValidare also piggybacked on the message sent (line 2e). At a recei ve event, the
receiverPitakesthemoreuptodateinformation(line3b)on Least_SolandValid,thatithasand
whatitreceivesfrom Pj. (Assumingasolutionisnotfoundhere,i.e., Validisnotall1,furtherpro-
cessing is necessary to advance Least_Sol.) In this step, the previous value of Least_Sol[i]may
advance. As a result, entries of Current_Conc_Intsin the logLogithat are older than the new
valueofLeast_Sol[i]aredequeuedanddeleted(lines3e-3f). If Logibecomesempty, Least_Sol
catches up completely with Current_Conc_Intsand all the entries in the vector Validare reset
as we no longer know whether the local predicates were true in the corresponding intervals of
Current_Conc_Ints(lines 3g-3h). If Logiis nonempty (line 3i), then the current head of the
Logrepresents one of the earlier values of Current_Conc_Ints. The information of this queue
head and associated validity vector of all 0s, is combined wi th the value of (Least_Soli,Valid i)
391
arrayofinteger :Least_Sol[1. . .n];
arrayofboolean :V alid [1. . .n];
arrayofinteger :Current_Conc_Ints[1. . .n];
queue of Current_Conc_Ints:Log←−⊥
boolean:not_yet_logged i←−1;
(1)Whenlocalpredicate φibecomestrueat Pi:
(1a)ifnot_yet_logged ithen
(1b) enqueue (Logi, Current _Conc_Ints i);not_yet_logged i←−false;
(1c) ifLeast_Soli[i] =Current_Conc_Ints i[i]then
(1d) V alid i[i]←−true.
(2)Pisendsamessage,with ∝a\}⌊ra⌋k⌉tl⌉{tCurrent_Conc_Ints i,Least_Soli,V alid i∝a\}⌊ra⌋k⌉tri}htappended
(2a) Current_Conc_Ints i[i]←−Current_Conc_Ints i[i] + 1;
(2b)not_yet_logged i←−true;
(2c)ifempty (Logi)then
(2d) Least_Soli[i]←−Current_Conc_Ints i[i];
(2e)sendthemessagewithvectors ∝a\}⌊ra⌋k⌉tl⌉{tCurrent_Conc_Ints i, Least_Soli, V alid i∝a\}⌊ra⌋k⌉tri}htpiggybacked.
(3)When Pireceivesa messagefrom Pjwith∝a\}⌊ra⌋k⌉tl⌉{tCurrent_Conc_Ints j, Least_Solj, V alid j∝a\}⌊ra⌋k⌉tri}htpiggybacked
(3a) Current_Conc_Ints i←−max(Current_Conc_Ints i, Current _Conc_Ints j);
(3b) (Least_Soli, V alid i)←−Combine _Maxima ((Least_Soli, V alid i),(Least_Solj, V alid j));
(3c) Current_Conc_Ints i[i]←−Current_Conc_Ints i[i] + 1;
(3d)not_yet_logged i←−true;
(3e)while((not empty (Logi))and((head(Logi))[i]< Least_Soli[i])do
(3f) dequeue (Logi);
(3g)ifempty (Logi)then
(3h) Least_Soli←−Current_Conc_Ints i;V alid i←−[0,0, . . .,0];
(3i)else
(3j) (Least_Soli, V alid i)←−Combine _Maxima ((Least_Soli, V alid i),(head(Logi),[0,0, . . .,0]));
(3k) V alid i[i]←−1;
(3l)ifV alid i←−[1,1, . . .,1]then
(3m) Possibly (φ)istruein globalstate Least_Soli;
(3n) Deliverthemessage.
(4)function Combine _Maxima ((C1, A1),(C2, A2))
arrayofinteger :C[1. . .n];
arrayofboolean :A[1. . .n];
(4a)forx= 1tondo
(4b) case:
(4c) C1[x]> C2[x]−→(C[x]←−C1[x];A[x]←−A1[x]);
(4d) C1[x]< C2[x]−→(C[x]←−C2[x];A[x]←−A2[x]);
(4e) C1[x] =C2[x]−→(C[x]←−C1[x];A[x]←−(A1[x]or A2[x]));
(4f)return (C, A).
Figure11.16: Intervalbased detectionofaconjunctivepre dicate (distributed,on-line, Possibly).
(line3j)and Valid [i]is setto 1 (line3k)becausetheglobalstatefrom head(Logi)impliesthat φi
was true in the local interval in that global state. At this st age, ifValid i[k]is true for all k, then a
solutionstateisgivenby Least_Sol.
392
Termination: IfValid [k] = 1forallk,thealgorithmﬁndsasetofintervalssatisfying Possibly (φ).
Notethat forthistohappen, someprocessmusthavereceived informationaboutallsuchintervals
and that they were valid. It may happen that such a set of inter vals indeed exists but no process
is able to see all these intervals under two related conditio ns: (i) there is not enough communica-
tion on which such information can be piggybacked, and (ii) t he underlying execution terminates
shortlyaftersuch a setofintervalscomeintoexistence. Ex ercise8 asks youto analyzethis termi-
nationconditionfurther.
Complexity: LetMsandMcdenotethenumberofmessagessentbyaprocess,andthenumbe rof
communicationeventsat aprocess, respectively.
Timecomplexity: Each message send and message receive requires O(n)processing. The time
complexityata processis O(Mcn)and across allprocesses, thisis O(Mcn2) =O(Msn2).
Space complexity: TheLogat a process may haveto hold up to Mcintervals,each ofsize O(n).
The other data structures are integer or boolean arrays of si zenand require O(n)space
locally. Hence, thesystemspacecomplexityis O(/summationtextn
i=1Mcn)=O(Mcn2)=O(Msn2).
Messagecomplexity: On each message sent by the application, O(3n)data is piggybacked. No
controlmessagesareused. Ifaprocesssendsupto Msmessages,thetotalspaceoverheadis
O(Msn2).
Fault-tolerance: The algorithm is resilient to message losses because it uses piggybacking of
controlinformation(See Exercise9).
11.6 FurtherClassiﬁcationof Predicates
We have thus far seen relational predicates, conjunctive predicates, localpredicates (in an earlier
chapter), and stablepredicates. Here we formally deﬁne local predicates, and th en consider two
moretypesofpredicates.
Local predicate: A local predicate is a predicate whose value is fully control led by a single pro-
cess.
Disjunctivepredicates: If a predicate φcan be expressed as the disjunction ∨i∈Nφi, whereφiis
a predicate local to process i, thenφis a disjunctive predicate. Disjunctive predicates are
straightforward to detect; each process monitors the local disjunct, and when it becomes
true, informstheotherprocesses. Ifthedisjunctat Pibecomes trueafter the xthlocalevent,
then inthestatelatticediagram, φwillbetrueinall globalstates having xeventsatPi. It is
noweasy toseethat foradisjunctivepredicate, Possibly (φ)=Definitely (φ).
Observer-independent predicates: Different observers may observe different cuts of the execu -
tion;anobservercanonlydetermineifthepredicate φbecametrueinthecutsitcanobserve.
393
Ifφisobserver-independent,differentobserverswillallagr eeonwhetherthepredicate φbe-
cametrue.
We have seen that Definitely (φ) = :Possibly (φ). If the predicate φalso satisﬁes the
conditionPossibly (φ) = :Definitely (φ), and thusPossibly (φ) =Definitely (φ), then
it is an observer-independent predicate. The predicate wil l be seen to hold or to not hold
independentoftheobserver.
Stablepredicates as wellas disjunctivepredicates arebot hobserver-independent.
The modalities PossiblyandDeﬁnitely are coarse-grained. Predicates can also be detected
underarich, ﬁne-grained suiteofmodalitiesbased ontheca usalityrelation.
11.7 ChapterSummary
Observing global states is a fundamental problem in asynchr onous distributedsystems, as studied
in Chapter ??. A natural extension of this problem is to detect global stat es that satisfy a given
predicateonthevariablesofthedistributedprogram. Thec hapterﬁrstconsidered stablepredicates,
which are predicates that remain true once they become true. Deadlock detection and termination
detectionare basedon stablepredicatedetection.
Unstable predicates on the program variables are difﬁcult t o detect because the values of vari-
ablesthatmakethepredicatetruecanchangesandfalsifyth epredicate. Hence,unstablepredicates
aredeﬁnedundermodalities: PossiblyandDeﬁnitely . Furthermore,apredicatecanbebroadlyclas-
siﬁed asconjunctive orrelational . A relational predicate is a predicate using any relation of the
distributedvariables,whereasaconjuctivepredicateisd eﬁnedtobeaconjunctoflocalpredicates.
The chapter studied a centralized algorithm for detecting r elational predicates, having expo-
nential complexity. This complexity seems to be inherent fo r relational predicates. The next cen-
tralized algorithms considered for conjunctive predicate s were: (i) an interval-based algorithm
for detecting both modalities PossiblyandDeﬁnitely , and (ii) a global state based algorithm for
detectingunder Posssibly modality.
The chapter then covered three distributed algorithms for c onjunctive predicates, all having
polynomialcomplexity. Theﬁrst was a state-based token-ba sed algorithmforthe Possiblymodal-
ity. Thesecondwasaninterval-basedtoken-basedalgorith mforthe Deﬁnitely modality. Thethird
was an interval-based piggybacking algorithm for the Possiblymodality. These representative al-
gorithmsillustratedifferenttechniquesforconjunctive predicatedetection. Thechapterconcluded
by mentioningothermoresophisticatedpredicatemodaliti es.
11.8 BibliographicNotes
Thediscussiononstableand unstablepredicatesisbased on Chandy and Lamport[6]. Pnueliﬁrst
introduced a temporal logic for programs with the ‘hencefor th’ operator [21]. The discussion on
detectingdeadlocksisbasedonKshemkalyaniandSinghal[1 6]andthediscussionontermination
394
detection is based on Mattern [20]. The challenges in detect ing unstable predicates, the Possibly
andDefinitely modalities, and the notion of the state lattice were formula ted by Cooper and
Marzullo [8] and Marzullo and Neiger [18]. The centralized a lgorithms to detect Possibly and
Definitely for relational predicates are based on Cooper and Marzullo [ 8]. Various techniques
to improve the efﬁciency are given by Alagar and Venkatesan [ 1]. Conjunctive predicates were
discussed by Venkatesan and Dathan [22], Garg and Waldecker [11] and Kshemkalyani [14]. The
discussion on the conditions to detect conjunctive predica tes is based on Kshemkalyani [14] and
Chandra and Kshemkalyani [4]. The centralized algorithm fo rPossibly (φ)andDefinitely (φ)
whereφis conjunctive, in Figure 11.8, is adapted from Chandra and K shemkalyani [2] and Garg
andWaldecker[11,12]. Thecentralizedalgorithmfor Possibly (φ)whereφisconjunctive,inFig-
ure11.9,isbasedonthetestforconsistentstatesusingvec torclocksofMattern[19]andFidge[9].
The distributed state-based algorithm for Possibly (φ)whereφis conjunctive, in Figure 11.11, is
basedon Garg andChase[10]. Thedistributedinterval-base dalgorithmfor Definitely (φ)where
φis conjunctive, in Figure 11.14, is based on Chandra and Kshe mkalyani [3]. The distributed
interval-based algorithm for Possibly (φ)whereφis conjunctive, in Figure 11.16, is based on
Hurﬁn, Mizuno, Raynal,and Singhal [13]. Observer-indepen dent predicates were introduced by
Charron-Bost, Delporte-Gallet, and Fauconnier [7]. A ﬁne- grained set of modalities was intro-
duced by [14]. Their mapping to the Possibly/Deﬁnitely modalities was proposed in [15]. Algo-
rithmstodetect predicates undertheseﬁne-grained modali tieswere givenin[4, 2, 5].
11.9 ExerciseProblems
1. StatewhetherTrueorFalseforeach ofthefollowing. Just ifyyouranswers.
(a)Possibly (φ) =:¬Definitely (φ)
(b)Possibly (φ) =:Definitely (φ)
(c)Possibly (φ) =:Definitely (¬φ)
(d)Possibly (φ) =:¬Definitely (¬φ)
(e)Definitely (φ) =:Possibly (φ)
(f)Definitely (φ) =:Possibly (¬φ)
(g)Definitely (φ) =:¬Possibly (φ)
(h)Definitely (φ) =:¬Possibly (¬φ)
2. Aconjunctive predicateφ=∧i∈Nφi, whereφiis a predicate deﬁned on variables local to
processPi.
In a distributed execution (E,≺), letFirst_Cut(φ)be denote the earliestorsmallestcon-
sistentcut inwhich theglobalconjunctivepredicate φbecomestrue.
395
Recall that in different equivalent executions, a differen t “path” may be traced through the
state lattice. Therefore, for different re-executions of t his (deterministic) distributed pro-
gram, is the state First_Cut(φ)well-deﬁned? i.e., is it uniquelyidentiﬁed? Worded equiv-
alently,is theset ofcuts C(φ)closedunderintersection?
3. Somewhatsimilartotheearlierproblem,wenowneedtosho wastrongerpropertyforlinear
predicates. Usingthestandardnotation,let Cuts(φ)denotethesetofcutssatisfying φ. Prove
thefollowing. “Cuts(φ)isclosed underintersectionifand onlyif φis linear.”
4. Provethat thepredicatedetectionproblemis NP-complet e.
(Hint: Showareductionfrom thesatisﬁability(SAT)proble m.)
5. Ifitisknownthat Possibly (φ)istrueandDefinitely (φ)isfalseinanexecution,thenwhat
can be said about Possibly (φ)and aboutDefinitely (φ)in terms of the paths of the state
latticeofthat execution?
6. ForthealgorithminFigure11.3,answerthefollowing.
(a) When can thealgorithmbeginconstructingtheglobalsta tes oflevellvl?
(b) When are alltheglobalstatesoflevel lvlconstructed?
7. Can the algorithm for global state based detection of a con junctive predicate (centralized,
on-line,Possibly) of Figure 11.9 be modiﬁed to detect Definitely (φ)? If yes, give the
modiﬁedalgorithmand showitis correct.
8. Determinewhethertheinterval-baseddistributedalgor ithm(Figure11.16)todetect Possibly (φ)
will always detect Possibly (φ), even though the algorithm is correct in principle. If it wil l
not,extendthealgorithmtoensurethat asolutionisalways detected ifit exists.
Hint: Consider the termination of the execution and the Possibly modality holding just a
littlebefore thetermination.
9. Analyzethedegreeto whichthealgorithmin Figure11.16i sresilienttomessagelosses.
10. Showthefollowingrelationshipsamongthevariousclas ses ofpredicates.
(a) Thesetofstablepredicatesisapropersubsetoftheseto fobserver-independentpredi-
cates.
(b) The set of disjunctive predicates is a proper subset of th e set of observer-independent
predicates.
396
Bibliography
[1] S. Alagar, S. Venkatesan, Techniques to tackle state exp losion in global predicate detection,
IEEE Trans.SoftwareEngg.,27(8): 704-714,2001.
[2] P.Chandra,A.D.Kshemkalyani,Algorithmsfordetectin gglobalpredicatesunderﬁne-grained
modalities,Proc. ASIAN 2003,LNCS, Springer, p. 91-109,De cember2003.
[3] P.Chandra,A.D.Kshemkalyani,Distributedalgorithmt odetectstrongconjunctivepredicates,
InformationProcessingLetters, 87(5): 243-249,Septembe r2003.
[4] P. Chandra, A.D. Kshemkalyani, Detection of orthogonal interval relations, Proc. High-
Performance ComputingConference, 323-333,LNCS 2552,Spr inger, 2002.
[5] P. Chandra, A. D. Kshemkalyani, Causality-based predic ate Detection across space and time,
IEEE Transactionson Computers,54(11): 1438-1453,Novemb er2005
[6] K. M. Chandy, L. Lamport: Distributed snapshots: Determ ining global states of distributed
systems,ACM TransactionsonComputerSystems,3(1): 63-75 ,1985.
[7] B. Charron-Bost, C. Deloprte-Gallet, H. Fauconnier, Lo cal and temporal predicates in dis-
tributed systems, ACM Trans. on Programming Languages and S ystems, 17(1): 157-179,
1995.
[8] R.Cooper,K.Marzullo,Consistentdetectionofglobalp redicates,Proc.ACM/ONRWorkshop
onParallel & DistributedDebugging,163-173,May 1991.
[9] C.J.Fidge,Timestampsinmessage-passingsystemsthat preservepartialordering,Australian
ComputerScience Communications,10(1): 56-66,1988.
[10] V.K. Garg, C. Chase, Distributed algorithms for detect ing conjunctive predicates, Proceed-
ings 15th IEEE International Conference on Distributed Com puting Systems, p. 423-430,
1995.
[11] V.K. Garg, B. Waldecker, Detection of weak unstable pre dicates in distributed programs,
IEEE Trans.Parallel &DistributedSystems,5(3):299-307, Mar.1994.
[12] V.K. Garg, B. Waldecker, Detection of strong unstable p redicates in distributed programs,
IEEE Trans.Parallel &DistributedSystems,7(12):1323-13 33,Dec. 1996.
397
[13] M.Hurﬁn,M.Mizuno,M.Raynal,M.Singhal,Efﬁcientdis tributeddetectionofconjunctions
oflocalpredicates, IEEE Trans.Software Engg.,24(8): 664 -677,1998.
[14] A.D. Kshemkalyani, Temporal interactions of interval s in distributed systems, Journal of
Computerand SystemSciences, 52(2): 287-298,April1996.
[15] A.D.Kshemkalyani,Aﬁne-grainedmodalityclassiﬁcat ionforglobalpredicates,IEEETrans.
Parallel &DistributedSystems,14(8): 807-816,August200 3.
[16] A.D. Kshemkalyani, M. Singhal, Correct two-phase and o ne-phase deadlock detection al-
gorithms for distributed systems, Proceedings of 2nd IEEE S ymposium on Parallel and Dis-
tributedProcessing,p. 126-129,Dec. 1990.
[17] L.Lamport,Time,clocks,andtheorderingofeventsina distributedsystem,Communications
oftheACM, 21(7): 558-565,July1978.
[18] K. Marzullo, G. Neiger, Detection of global state predi cates, Proc. 5th Workshop on Dis-
tributedAlgorithms,LNCS 579,Springer-Verlag, 254-272, October1991.
[19] F.Mattern,Virtualtimeandglobalstatesofdistribut edsystems,Proc.InternationalWorkshop
onParallel and DistributedAlgorithms,North-Holland,pp . 215-226,October1998.
[20] F.Mattern,Algorithmsfordistributedterminationde tection,DistributedComputing,2: 161-
175,1987.
[21] A.Pnueli,Thetemporallogicofprograms,Proc. IEEESy mposiumonFoundationsofCom-
puterScience, p. 46-57,1977.
[22] S. Venkatesan, B. Dathan, Testing and debugging distri buted programs using global predi-
cates, IEEE Trans.SoftwareEngg.,21(2): 163-177,Feb. 199 5.
398
Chapter12
DistributedShared Memory
12.1 AbstractionandAdvantages
Distributed shared memory (DSM) is an abstraction provided to the programmer of a distributed
system. It gives the impression of a single monolithic memor y, as in a traditional von Neumann
architecture. The programmer accesses the data across the n etwork using only readandwrite
primitives, as he would in a uniprocessor system. The progra mmer does not have to deal with
sendandreceivecommunication primitivesand the ensuing complexityof dea ling explicitly with
synchronizationandconsistencyinthemessage-passingmo del. TheDSMabstractionisillustrated
inFigure12.1. Apartofeachcomputer’smemoryisearmarked forsharedspace,andtheremainder
is private memory. To provide the programmers the illusion o f a single shared address space, a
memorymappingmanagementlayerisrequired tomanagethe sharedvirtualmemory space.
Shared Virtual MemoryMemory Memory Memory
manager manager managerCPU CPU CPU
Memory Memory Memory
Figure12.1: AbstractviewofDSM
Thefollowingare theadvantagesofDSM.
1. Communication across the network is achieved by the read/ write abstraction that simpliﬁes
thetaskoftheprogrammer.
399
Shared Virtual MemoryMemory Memory Memory
manager manager manager
Distributed shared memory invocationresponse
invocationresponse
invocationresponseprocess process process
Figure12.2: Detailed abstractionofDSM andinteractionwi thapplicationprocesses.
2. Asingleaddressspaceisprovided,therebyprovidingthe possibilityofavoidingdatamove-
ment across multiple address spaces by using passing-by-reference , instead of passing-by-
value.
3. If a block of data needs to be moved, the system can exploit l ocality of reference to reduce
thecommunicationoverhead.
4. DSM is often cheaper than using dedicated multiprocessor systems, because it uses simpler
softwareinterfaces and off-the-shelfhardware.
5. Thereisno bottleneckpresented byasinglememoryaccess bus.
6. DSM effectivelyprovidesalarge(virtual)main memory.
7. DSM provides portability of programs written using DSM. T his portability arises due to a
commonDSMprogramminginterface,thatisindependentofth eoperatingsystemandother
low-levelsystemcharacteristics.
Althoughafamiliar(i.e.,read/write)interfaceisprovid edtotheprogrammer,thereisacatchto
it. Underthecovers,thereisinherentlyadistributedsyst emandanetwork,andthedataneedstobe
sharedinsomefashion. Thereisnosilverbullet. Moreover, withthepossibilityofdatareplication
and/ortheconcurrent access todata,concurrency controln eedstobeenforced. Speciﬁcally,when
multipleprocessorswishtoaccessthesamedataobject,ade cisionabouthowtohandleconcurrent
accesses needs to be made. As in traditional databases, if a l ocking mechanismbased on read and
write locks for objects is used, concurrency is severely res trained, defeating one of the purposes
of having the distributedsystem. On the other hand, if concu rrent access is permitted by different
processorstodifferentreplicas,theproblemofreplicaco nsistency(whichisageneralizationofthe
problem of cache consistency in computer architecture stud ies) needs to be addressed. The main
pointofallowingconcurrent access (by different processo rs)to thesamedataobject isto increase
throughput. But in the face of concurrent access, the semant ics of what value a read operation
400
returns to the program needs to be speciﬁed. The programmer u ltimately needs to understand
this semantics, which may differ from the Von Neumann semant ics, because the program logic
depends greatly on this semantics. This compromises the ass umptionthat the DSM is transparent
totheprogrammer.
Beforeexaminingthechallengesinimplementingreplicaco herencyinDSMsystems,welook
at thedisadvantages.
1. The programmer is not shielded from having to know about va rious replica consistency
modelsandcodinghis distributedapplicationaccording to thesemanticsofthesemodels.
2. As DSM is implemented under the covers using asynchronous message-passing, the over-
heads incurred are at least as high as those of a message-pass ing implementation. As such,
DSM implementationscannot be more efﬁcient than asynchron ous message-passing imple-
mentations. ThegeneralityoftheDSMsoftwaremay makeit le ssefﬁcient.
3. ByyieldingcontroltotheDSMmemorymanagementlayer,th eprogrammerlosestheability
to use his own message-passing solutions for accessing shar ed objects. It is likely that the
standardvanillaimplementationsofDSMhaveahigheroverh eadthanaprogrammer-written
implementationtailoredfor aspeciﬁcapplicationandsyst em.
Themainissuesin designingaDSM systemarethefollowing.
•Determining what semantics to allow for concurrent access t o shared objects. The seman-
tics needs to be clearly speciﬁed so that the programmer can c ode his program using an
appropriatelogic.
•Determining the best way to implement the semantics of concu rrent access to shared data.
One possibility is to use replication. One decision to be mad e is the degree of replication –
partial replication at some sites, or full replication at al l the sites. A further decision then
is todecideon whetherto useread-replication (replicatio n fortheread operations)orwrite-
replication(replicationforthewriteoperations)orboth .
•Selecting the locations for replication (if full replicati on is not used), to optimize efﬁciency
fromthesystem’sviewpoint.
•Determining the location of remote data that the applicatio n needs to access, if full replica-
tionisnotused.
•Reducing communication delays and the number of messages th at are involved under the
coverswhileimplementingthesemanticsofconcurrent acce ss to shareddata.
There is a wide range of choices on how these issues can be addr essed. In part, the solution
depends on the system architecture. Recall from Chapter 1 th at DSM systems can range from
tightly-coupled (hardware and software) multicomputers t o wide-area distributed systems with
heterogenoushardwareandsoftware. Therearefourbroaddi mensionsalongwhichDSMsystems
can beclassiﬁed and implemented.
401
Typeof DSM Examples Management Caching Remote access
single-bus multiprocessor Fireﬂy, Sequent byMMU hardware control by hardware
switched multiprocessor Alewife, Dash byMMU hardware control by hardware
NUMAsystem Butterﬂy, CM* byOS software control by hardware
Page-based DSM Ivy, Mirage byOS software control by software
Shared variable DSM Midway, Munin bylanguage software control by software
runtime system
Shared object DSM Linda, Orca bylanguage software control by software
runtime system
Table12.1: ComparisonofDSM systems
•Whetherdataisreplicated orcached
•Whetherremoteaccess isby hardwareorby software
•Whetherthecaching/replicationiscontrolledby hardware orsoftware
•Whether the DSM is controlled by the distributed memory mana gers, by the operating sys-
tem,orby thelanguageruntimesystem.
The various options for each of these four dimensions, and th eir comparison, are shown in Fig-
ure12.1.
12.2 MemoryConsistencyModels
Memory coherence is the ability of the system to execute memory operations cor rectly. Assume
nprocesses and simemory operations per process Pi. Also assume that all the operations issued
by a process are executed sequentially (that is, pipelining is disallowed), as shown in Figure 12.3.
Observethat thereareatotalof
(s1+s2+...+sn)!/(s1!s2!...s n!)
possible permutations or interleavings of the operations i ssued by the processes. The problem of
ensuringmemorycoherencethenbecomestheproblemofident ifyingwhichoftheseinterleavings
are“correct”,whichofcourserequiresacleardeﬁnitionof “correctness”. The memoryconsistency
modeldeﬁnes the set of allowable memory access orderings. While a traditional deﬁnition of
correctness says that a correct memory execution is one that returns to each Readoperation, the
value stored by the most recent Writeoperation, the very deﬁnition of “most recent” becomes
ambigiousinthepresenceofconcurrentaccessandmultiple replicasofthedataitem. Thus,aclear
deﬁnitionof correctness is required in such a system;the ob jectiveis to disallowtheinterleavings
that make no semantic sense, while not being overly restrict ive so as to permit a high degree of
concurrency.
402
response responseinvocation
response responseinvocation invocation invocationprocess
local 
memory managerop3 opk op2 op1
Figure12.3: Sequential invocationsand responsesin aDSMs ystem,withoutany pipelining.
TheDSM systemenforces aparticularmemoryconsistencymod el;theprogrammerwriteshis
program keeping in mind the allowable interleavings permit ted by that speciﬁc memory consis-
tency model. A program written for one model may not work corr ectly on a DSM system that
enforces adifferent model. The modelcan thusbeviewed as a contractbetween theDSM system
and the programmer using that system. We now consider six con sistency models, that are related
as shownin Figure12.12.
Notation: Awriteofvalue atovariablexisdenotedas Write(x,a) . Areadofvariable xthatreturns
valueais denoted as Read(x,a) . A subscript on these operations is sometimes used to denote the
processorthatissuestheseoperations.
12.2.1 Strict consistency/Atomic consistency/Lineariza bility
The strictest model, corresponding to the notion of correct ness on the traditional Von Neumann
architecture or the uniprocessor machine, requires that an yReadto a location (variable) should
return the value written by the most recent Writeto that location (variable). Two salient features
of such a system are the following. (i) A common global time ax is is implicitly available in
a uniprocessor system. (ii) Each write is immediately visib le to all processes. Adapting this
correctnessmodeltoaDSMsystemwithoperationsthatcanbe concurrentlyissuedbythevarious
processes gives the strict consistency model , also known as the atomic consistency model . The
modelismoreformallyspeciﬁed as follows.
1. AnyReadto a location (variable) is required to return the value writ ten by the most recent
Writeto thatlocation(variable)as pera globaltimereference.
Foroperationsthatdo notoverlapas pertheglobaltimerefe rence, thespeciﬁcation isclear.
For operations that overlap as per the global timereference , the following further speciﬁca-
tionsarenecessary.
2. Alloperationsappearto beexecutedatomicallyand seque ntially.
3. Allprocessorsseethesameorderingofevents,whichiseq uivalenttotheglobal-timeoccur-
renceofnon-overlappingevents.
An alternate way of specifying this consistency model is in t erms of the ‘invocation’ and ‘re-
sponse’ to each ReadandWriteoperation, as shown in Figure 12.3. Recall that each operati on
403
takes a ﬁnite time interval and hence different operations b y different processors can overlap in
time. However, the invocation and the response to each invoc ation can both be separately viewed
asbeingatomicevents. Anexecutionsequenceinglobaltime isviewedasasequence Seqofsuch
invocationsand responses. Clearly, Seqmustsatisfytheconditions:
•(Liveness:) Each invocationmusthaveacorrespondingresp onse,and
•(Correctness:) The projection of Seqon any processor i, denotedSeqi, must be a sequence
ofalternatinginvocationsand responsesifpipeliningisd isallowed.
Despite the concurrent operations, a linearizable executi on needs to generate an equivalent global
order on the events, that is a permutation of Seq, satisfying the semantics of linearizability . More
formally, a sequence Seqof invocations and responses is linearizable (LIN) if there is a permuta-
tionSeq′ofadjacent pairsofcorresponding ∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}hteventssatisfying:
1. Foreveryvariable v, theprojectionof Seq′onv,denotedSeq′
v, issuchthat
•everyRead(adjacent∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}htevent pair) returns the most recent Write(adjacent
∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}hteventpair)that immediatelypreceded it.
2. Iftheresponse op1(resp)ofoperation op1occurredbeforetheinvocation op2(invoc)ofop-
erationop2inSeq, thenop1(adjacent∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}hteventpair) occurs before op2(adjacent
∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}hteventpair)in Seq′.
Condition 1 speciﬁes that every processor sees a common orde rSeq′of events, and that in this
order, thesemantics is that each Readreturns themost recent completed Writevalue. Condition2
speciﬁes that the common order Seq′must satisfy the global time order of events, viz., the order
ofnon-overlappingoperationsin Seqmustbepreserved in Seq′.
Examples: Figure12.4showsthreeexecutions.
Figure12.4(a): The execution is not linearizable because although the ReadbyP2begins after
Write(x,4), theReadreturns the value that existed before the Write. Hence, a permutation
Seq′satisfyingtheabovecondition(2)on globaltimeorderdoes not exist.
Figure12.4(b): The execution is linearizable. The global order of operatio ns (corresponding to
∝a\}⌊ra⌋k⌉tl⌉{tresponse,invocation ∝a\}⌊ra⌋k⌉tri}htpairsinSeq′),consistentwiththereal-timeoccurrenceis: Write(y,2),
Write(x,4),Read(x,4),Read(y,2). Thispermutation Seq′satisﬁestheconditions(1and2).
Figure12.4(c): The execution is not linearizable. The two dependencies: Read(x,0)before
Write(x,4), andRead(y,0)beforeWrite(x,2)cannot both be satisﬁed in a global order
while satisfying the local order of operations at each proce ssor. Hence, there does not exist
anypermutation Seq′satisfyingconditions(1 and 2).
404
Read(y,2)
Read(x,4)Read(x,0)
Write(x,4)
Write(y,2) Read(x,0)Read(y,0)(b) Sequentially consistent and linearizable
(c) Not sequentially consistent (and hence not linearizable)(a)Sequentially consistent but not linearizable
PPPPPP
1
221
12Read(y,2) Write(x,4)
Write(y,2)
Write(x,4)
Write(y,2)
Figure 12.4: Examples to illustrate deﬁnitions of lineariz ability and sequential consistency. The
initialvaluesofvariablesare zero.
12.2.1.1 Implementations
Implementing linearizability is expensive because a globa l time scale needs to be simulated. As
all processors need to agree on a common order, the implement ation needs to use total order.
For simplicity, we assume full replication of each data item at all the processors. Hence, total
ordering needs to be combined with a broadcast. Figure 12.5 g ives the implementation assuming
the existence of a total order broadcast primitive that broadcasts to all processors including the
sender. Hence, the Memory Manager software has to be placed b etween the application above it
and thetotalorder broadcastlayerbelowit.
Although the algorithm in Figure 12.5 appears simple, it is a lso subtle. The total order broad-
cast ensures thatallprocessors seethesameorder.
•Fortwononoverlappingoperationsatdifferentprocessors ,bytheverydeﬁnitionofnonover-
lapping, the response to the former operation precedes the i nvocation of the latter in global
time.
•Fortwooverlappingoperations,thetotalorder ensuresaco mmonviewby allprocessors.
For aReadoperation, when the Memory Managers systemwide receive the total order broadcast,
they do not perform any action. Why is the broadcast then nece ssary? The reason is this. If
Readoperations do not participate in the total order broadcasts , they do not get totally ordered
with respect to the Writeoperations as well as withrespect to the other Readoperations. This can
lead to a violation of linearizability, as shown in Figure 12 .6. TheReadbyPkreturns the value
written byPi. The later ReadbyPjreturns the initial value of 0. As per the global time orderin g
requirement of linearizability, the ReadbyPjthat occurs after the ReadbyPkmust also return
405
(shared var)
int:x;
(1) When the MemoryManager receives a ReadorWritefrom application:
(1a)total_order_broadcast theReadorWriterequest toall processors;
(1b)awaitownrequest that wasbroadcast;
(1c)perform pending response to the application as follows
(1d) caseRead: return value from local replica;
(1e) caseWrite: writeto local replica and return ack toapplication.
(2) Whenthe Memory Manager receives a total_order_broadcast (Write, x,val ) from network:
(2a)writevaltolocal replica of x.
(3) When the MemoryManager receives a total_order_broadcast (Read, x)from network:
(3a)nooperation .
Figure 12.5: Implementing Linearizability (LIN) using tot al order broadcasts. Code shown is for
Pi,1≤i≤n.
broadcasttotal order
P_kP_jP_iWrite(x,4)
Read(x,0)
Read(x,4)
Figure 12.6: A violation of linearizability (LIN) ifReadoperations do not participate in the total
orderbroadcast.
the value 4. However, that is not the case in this example, whe rein theReadoperations do not
participatein thetotal orderbroadcast.
12.2.2 Sequential Consistency
Linearizabilityorstrict/atomicconsistencyisdifﬁcult toimplementbecausetheabsenceofaglobal
timereferenceinadistributedsystemnecessitatesthatth etimereferencehastobesimulated. This
is very expensive. Programmers can deal with weaker models. The ﬁrst weaker model, that of
sequential consistency (SC) was proposed by Lamport and uses logical time reference instead of
theglobaltimereference.
Sequential consistencyisspeciﬁed asfollows.
•The result of any execution is the same as if all operations of the processors were executed
insomesequentialorder.
406
•The operations of each individual processor appear in this s equence in the local program
order.
Although any possible interleaving of the operations from t he different processors is possible, all
theprocessorsmustsee thesame interleaving. Inthismodel,eveniftwooperationsfromdif ferent
processors (on the same or different variables) do not overl ap in a global time scale, they may
appearin reverseorderin the commonsequentialorderseen byall theprocessors.
More formally, a sequence Seqof invocation and response events is sequentially consiste nt if
thereisa permutation Seq′ofadjacent pairsofcorresponding ∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}hteventssatisfying:
1. Foreveryvariable v, theprojectionof Seq′onv,denotedSeq′
v, issuchthat:
•everyRead(adjacent∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}htevent pair) returns the most recent Write(adjacent
∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}hteventpair)that immediatelypreceded it.
2. If the response op1(resp)of operation op1at processPioccurred before the invocation
op2(invoc)of operation op2by processPiinSeq, thenop1(adjacent∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}htevent
pair)occurs before op2(adjacent∝a\}⌊ra⌋k⌉tl⌉{tinvoc,resp∝a\}⌊ra⌋k⌉tri}hteventpair)in Seq′.
Condition(1)isthesameasthatforlinearizability. Condi tion(2)differsfromthatforlinearizabil-
ity. It speciﬁes thatthecommonorder Seq′mustsatisfyonlythelocalorderofeventsat each pro-
cessor, instead of the global order of nonoverlapping event s. Hence the order of non-overlapping
operationsissuedbydifferent processorsin Seqneed not bepreservedin Seq′.
Examples: Threeexamplesare consideredin Figure12.4.
Figure12.4(a): The execution is sequentially consistent: the global order Seq′is:Write(y,2),
Read(x,0),Write(x,4),Read(y,2).
Figure12.4(b): As the execution is linearizable (seen in Section 12.2.1), i t is also sequentially
consistent. The global order of operations (corresponding to∝a\}⌊ra⌋k⌉tl⌉{tresponse, invocation ∝a\}⌊ra⌋k⌉tri}htpairs
inSeq′), consistent with the real-time occurrence is: Write(y,2),Write(x,4),Read(x,4),
Read(y,2).
Figure12.4(c): Theexecutionisnotsequentiallyconsistent(andhencenot linearizable). Thetwo
dependencies: Read(x,0)beforeWrite(x,4),andRead(y,0)beforeWrite(x,2)cannotboth
besatisﬁedinaglobalorderwhilesatisfyingthelocalorde rofoperationsateach processor.
Hence, theredoes notexistanypermutation Seq′satisfyingconditions(1 and2).
12.2.2.1 Implementations
As sequential consistency (SC) is less restrictive than lin earizability (LIN), it should be easier
to implement it. As all processors are required to see the sam e global order, but global time
orderingneednotbepreservedacrossprocesses,itissufﬁc ienttousetotalorderbroadcastsforthe
Writeoperations only. In the simpliﬁed algorithm, no total order broadcast is required for Read
operations,because:
407
(shared var)
int:x;
(1) When the MemoryManager at Pireceives a ReadorWritefrom application:
(1a)caseRead:returnvalue from local replica;
(1b)caseWrite(x,val) :total_order_broadcast i(Write(x,val) ) toall processors including itself.
(2) When the MemoryManager at Pireceives a total_order_broadcast j(Write, x, val ) from network:
(2a)writevaltolocal replica of x;
(2b)ifi=jthenreturn acknowledgement to application.
Figure12.7: ImplementingSequentialConsistency(SC)usi nglocalReadoperations. Codeshown
isforPi,1≤i≤n.
1. all consecutive operations by the same processor are orde red in that same order because of
notusingpipelining,and
2.Readoperationsbydifferentprocessorsareindependentofeach otherandneedtobeordered
onlywithrespect tothe Writeoperationsin theexecution.
In Exercise 1, you will be asked to reason this more thoroughl y. Two algorithms for SC are next
given,that exhibitatrade-offoftheinhibitionof ReadversusWriteoperations.
Local-Readalgorithm: TheﬁrstalgorithmforSC,giveninFigure12.7,isadirectsi mpliﬁcation
of the algorithm for linearizability,given in Figure 12.5. In the algorithm, a Readoperation
completesatomically,whereasa Writeoperationdoesnot. Betweentheinvocationofa Write
byPi(line 1e) and its acknowledgement (lines 2a,2b), there may b e multiple Writeopera-
tionsinitiatedbyotherprocessorsthattakeeffectat Pi(line2a). Thus,a Writeissuedlocally
has its completion locally delayed. Such an algorithm is acc eptable for Read-intensivepro-
grams.
Local-Writealgorithm: ThealgorithminFigure12.8doesnotdelayacknowledgement ofWrites.
ForWrite-intensive programs, it is desirable that a locally issued Writegets acknowledged
immediately(as in lines 2a-2c), even though the total order broadcast for the Write, and the
actual update for the Writemay not go into effect by updating the variable at the same tim e
(line3a). Thealgorithmachievesthisatthecostofdelayin gaReadoperationbyaprocessor
until all previously issued local Writeoperations by that same processor have locally gone
intoeffect (i.e., previous Writes issuedlocallyhaveupdated theirlocalvariables beingwr it-
tento). Thevariable counterisused totrack thenumberof Writeoperationsthat havebeen
locally initiated but not completed at any time. A Readoperation completes only if there
are no prior locally initiated Writeoperations that have not written to their variables (line
1a),i.e.,therearenopendinglocallyinitiated Writeoperationstoanyvariable. Otherwise,a
Readoperationisdelayeduntilafterallpreviouslyinitiated Writeoperationshavewrittento
408
(shared var)
int:x;
(1) When the MemoryManager at Pireceives a Read(x)from application:
(1a)ifcounter = 0then
(1b) return x
(1c)elseKeep the Readpending.
(2) When the MemoryManager at Pireceives a Write(x,val) from application:
(2a)counter←−counter + 1;
(2b)total_order_broadcast itheWrite(x,val);
(2c)returnacknowledgement to the application.
(3) When the MemoryManager at Pireceives a total_order_broadcast j(Write, x, val ) from network:
(3a)writevaltolocal replica of x.
(3b)ifi=jthen
(3c) counter←−counter−1;
(3d) if(counter = 0and anyReads are pending) then
(3e) perform pending responses for the Reads to the application.
Figure12.8: ImplementingSequentialConsistency(SC)usi nglocalWriteoperations. Codeshown
isforPi,1≤i≤n.
their local variables (lines 3b-3d), which happens after th e total order broadcasts associated
withtheWritehavedeliveredthebroadcastmessagelocally.
This algorithm performs fast (local) Writes and slow Reads. The algorithm pipelines all
Writeupdatesissued by aprocessor. The Readoperations havetowait for all Writeupdates
issued earlier by that processor to complete (i.e., take eff ect) locally before the value to be
read is returnedto theapplication.
12.2.3 CausalConsistency
For the sequential consistency model, it is required that Writeoperations issued by different pro-
cessors must necessarily be seen in some common order by all p rocessors. This requirement can
be relaxed to require only that Writes that are causally related must be seen in that same order by
allprocessors,whereas‘concurrent’ Writesmaybeseenbydifferentprocessorsindifferentorders.
The resulting consistency model is the causal consistency model. We have seen the deﬁnition of
causal relationships among events in a message passing syst em. What does it mean for two Write
operationstobecausally related?
Thecausalityrelation forshared memorysystemsisdeﬁned as follows.
Local order: Ataprocessor, theserialorderoftheeventsdeﬁnes theloca l causal order
409
PP
R(x,2)R(x,7)
R(x,7) R(x,4)
(c) Not causally consistent but PRAM consistent(a)Sequentially consistent and causally consistent
(b) Causally consistent but not sequentially consistent
R(x,7) R(x,4)R(x,7)R(x,2)W(x,7)R(x,4)W(x,2) W(x,4)R(x,7)
W(x,7)W(x,2)P
4P4
33
22
114321
P
PPPPPPP
W(x,4)R(x,4)R(x,7)R(x,2)W(x,7)R(x,4)W(x,2) W(x,4)
Figure 12.9: Examples to illustrate deﬁnitions of sequenti al consistency (SC), causal consistency
(CC), and PRAM consistency. Theinitialvaluesofvariables arezero.
Inter-process order: AWriteoperation causally precedes a Readoperation issued by another
processorifthe Readreturnsavaluewrittenbythe Write.
Transitiveclosure: The transitive closure of the above two relations deﬁnes the (global) causal
order.
Examples: TheexamplesinFigure12.9illustratecausal consistency.
Figure12.9(a): Theexecutionissequentiallyconsistent(andhencecausal lyconsistent). Both P3
andP4seetheoperationsat P1andP2insequentialorderand incausal order.
Figure12.9(b): The executionis not sequentiallyconsistentbut it iscausa lly consistent. Both P3
andP4seetheoperationsat P1andP2incausalorderbecausethelackofacausalityrelation
between the Writes byP1and byP2allows the values written by the two processors to be
seen in different orders in the system. The execution is not s equentially consistent because
there is no global satisfyingthe contradictory ordering re quirements set by the Reads byP3
410
and byP4. What can be said if the two Readoperations of P4returned 7 ﬁrst and then 4?
(See Exercise4.)
Figure12.9(c): Theexecutionisnot causallyconsistentbecausethesecond ReadbyP4returns4
afterP4hasalready returned 7 isan earlier Read.
12.2.3.1 Implementation
We ﬁrst examinethedeﬁnitionof sequentialconsistency. Ev en thoughall processors only need to
seesometotal order of the Writeoperations, observe that if two Writeoperations are related by
causality(i.e.,thesecond Writebeginscausallyaftera Readthatreadsthevaluewrittenbytheﬁrst
Write),thentheorderofthetwo Writesseenbyalltheprocessorsalsosatisﬁescausalorder! Inthe
implementation, even though a total-order-broadcast prim itive is used, observe that it implicitly
provides causal ordering on all the Writeoperations. Thus, due to the nature of the deﬁnition
of causal ordering in shared memory systems, a total-order- broadcast also provides causal order
broadcast, unlikethecase formessage-passingsystems. (E xactly whyisitso?)
In contrasttotheSCrequirement,causal consistencyimpli citlyrequires onlythatcausal order
beprovided. Thus,a causal-order-broadcast can be used in t heimplementation. Thedetails ofthe
implementationare left as Exercise5.
12.2.4 PRAM (Pipelined RAM) or ProcessorConsistency
Causal consistency requires all causally-related Writesto be seen in the same order by all pro-
cessors. This may be viewed as being too restrictive for some applications. A weaker form of
consistency requires only that Writeoperations issued by the same (any one) processor are seen
by all other processors in that same order in which they were i ssued, but Writeoperations issued
by different processors nay be seen in differing orders by di fferent processors. In relation to the
‘causality’ relation between operations, only the local ca usality relation, as deﬁned by the local
orderofWriteoperations,needstobeseenbyotherprocessors. Hence, thi sformofconsistencyis
termedprocessor consistency . An equivalent name for this consistency model is Pipelined RAM
(PRAM), to capture the behavior that all operations issued b y any processor appear to the other
processorsin aFIFO pipelinedsequence.
Examples:
•In Figure 12.9(c), the execution is PRAM consistent (even th ough it is not causally consis-
tent) because (trivially) both P3andP4see the updates made by P1andP2in FIFO order
alongthechannels P1toP3andP2toP3, andalongP1toP4andP2toP4, respectively.
•While PRAM consistency is more permissive than causal consi stency, this model must be
used with care by the programmer because it can lead to rather unintuitive results. For
example,examinethecodeinFigure12.10,where xandyaresharedvariables. Itispossible
thatonaPRAMsystem,bothprocesses P1andP2getkilled. Thiscanhappenasfollows. (i)
P1writes4toxinline(1a)and P2writes6toyinline(2a)ataboutthesametime. (ii)Before
411
(shared variables)
int:x,y;
Process 1 Process 2
... ...
(1a)x←−4; (2a) y←−6;
(1b)ify= 0thenkill(P2). (2b) ifx= 0thenkill(P1).
Figure 12.10: A counter-intuitivebehaviour of a PRAM-cons istent program. The initial values of
variablesare zero.
these written values propagate to the other processor, P1readsy(as being 0) in line (1b)
andP2readsx(as being 0) in line (2b). Here, a Read(e.g., in (1b) or (2b)) can effectively
‘overtake’apreceding Write(of(2a)or(1a),resp.) ifthetwoaccessesbythesameproces sor
are to different locations. However, this would not be expec ted on a conventional machine,
whereat mostoneprocess may getkilled,dependingontheint erleavingofthestatements.
•The execution in Figure 12.11(a) violates PRAM consistency . An explanation is given in
Section 12.2.5.
12.2.4.1 Implementations
PRAMconsistencycanbeimplementedusingFIFObroadcast. T heimplementationdetailsareleft
an Exercise6.
12.2.5 Slow Memory
The next weaker consistency model is that of slow memory . This model represents a location-
relative weakening of the PRAM model. In this model, only all Writeoperations issued by the
same processor and to the same memory location must be observ ed in the same order by all the
processors.
Examples: TheexamplesinFigure12.11illustrateslowmemoryconsist ency.
Figure12.11(a): The updates to reach of the variables are seen pipelined sepa rately in a FIFO
fashion. The‘ x’ pipelinefrom P1toP2is slowerthan the‘ y’ pipelinefrom P1toP2. Thus,
theovertakingeffect is allowed. However,PRAM consistenc y is violated because theFIFO
property is violated over the single common ‘pipeline’ from P1toP2– the update to yis
seen byP2butthemuch oldervalueof x= 0isseen byP2later.
Figure12.11(b): Slow memory consistencyis violated because theFIFO proper ty is violated for
thepipelineforvariable x. ‘x= 7’isseenbyP2beforeitsees‘ x= 0’and‘x= 2’although
7 waswritten to xafter thevaluesof0 and 2.
412
2W(y,4)
R(y,4)W(x,7)
R(x,7) R(x,0)
P1
P2(a) Slow memory but not PRAM consistent
W(x,2)
R(y,4)W(x,7)
(b) Violation of slow memory consistencyR(x,7) R(x,0) R(x,2)R(x,0)
W(y,4)1W(x,2)P
P
Figure 12.11: Examples to illustrate deﬁnitions of PRAM con sistency and slow memory. The
initialvaluesofvariablesare zero.
no consistency model
pipelined RAM (PRAM)
Slow memoryCausal consistencySequential consistency
Strict consistencyAtomic consistency/Linearizability/
Figure12.12: A stricthierarchyofthememoryconsistencym odels.
12.2.5.1 Implementations
Slow memory can be implemented using a broadcast primitivet hat is weaker than even the FIFO
broadcast. Whatisrequired isaFIFO broadcastpervariable inthesystem,i.e.,theFIFO property
should be satisﬁed only for updates to the same variable. The implementation details are left as
Exercise7.
12.2.6 Hierarchy ofConsistency Models
Based on the deﬁnitions of the memory consistency models see n so far, there exists a hierarchy
amongthemodels,as depicted inFigure12.12.
413
12.2.7 Other Models basedonSynchronization Instructions
Wehaveseen severalpopularconsistencymodels. Based onth econsistencymodel,thebehaviour
of the DSM differs, and the programmer’s logic therefore dep ends on the underlying consistency
model. It isalsopossiblethatnewerconsistencymodelsmay arisein thefuture.
Theconsistencymodelsseen sofarapplytoalltheinstructi onsinthedistributedprogram. We
nowbrieﬂymentionsomeotherconsistencymodelsthatareba sedonadifferentprinciple,namely
that the consistency conditions apply only to a set of distin guished ‘synchronization’ or ‘coordi-
nation’ instructions. These synchronization instruction s are typically from some run-time library.
A common example of such a statement is the barrier synchroni zation. Only the synchronization
statements across the various processors must satisfy the c onsistency conditions; other program
statementsbetween synchronizationstatementsmay beexec uted by the different processors with-
outanyconditions. Examplesofconsistencymodelsbasedon thisprincipleare: entryconsistency ,
weakconsistency ,andreleaseconsistency . Thesynchronizationstatementsareinsertedinthepro-
gram based on the semantics of the types of accesses. For exam ple, accesses may be conﬂicting
(tothesamevariable)ornon-conﬂicting(todifferentvari ables),conﬂictingaccesses maybecom-
peting (a Readand aWrite, or twoWrites) or non-conﬂicting (two Reads), and so on. We outline
thedeﬁnitionsoftheseconsistencymodelsbutskipfurther implementationdetailsofsuchmodels.
WeakConsistency:
Some applications do not require even seeing all writes, let alone seeing them in some order.
Consider the case of a process executing a CS, repeatedly rea ding and writing some variables in
a loop. Other processes are not supposed to read or write thes e variables until the ﬁrst process
has exited its CS. However, if the memory has no way of knowing when a process is in a CS and
when itisnot, theDSM has topropagateall writesto allmemor iesin theusualway. But byusing
synchronizationvariables,processes can deducewhethert heCSis occupied.
A synchronization variable in this model has the following semantics : it is used to propagate
all writes to other processors, andto perform local updates with regard to changes to global dat a
that occurred elsewhere in the distributed system. When syn chronization occurs, all Writesare
propagated to otherprocesses, and all Writes done by others are brought locally. In an implemen-
tation speciﬁcally for the CS problem, updates can be propag ated in the system only when the
synchronizationvariableisaccessed (indicatingan entry orexitintotheCS).
Weakconsistencyhasthefollowingthreepropertieswhichg uaranteethatmemoryisconsistent
at thesynchronizationpoints.
1. Accesses tosynchronizationvariablesaresequentially consistent.
2. No access to a synchronization variable is allowed to be pe rformed until all previous writes
havecompletedeverywhere.
3. No data access (either ReadorWrite)is allowed to be performed untilall previous accesses
tosynchronizationvariableshavebeen performed.
414
An access to the synchronization variable forces Writeoperations to complete, and effectively
ﬂushesthepipelines. Beforereadingshareddata,aprocess can performsynchronizationtoensure
itaccesses themostrecent data.
ReleaseConsistency:
Thedrawback of weak consistency isthat when a synchronizationvariableis accessed, the mem -
ory does not know whether this is being done because the proce ss is ﬁnished writing the shared
variables(exitingtheCS)orabouttobeginreadingthem(en teringtheCS).Hence,itmusttakethe
actionsrequired inbothcases.
1. Ensuring that all locally initiated Writeshave been completed, i.e., propagated to all other
processes.
2. Ensuringthatall Writesfrom othermachineshavebeen locallyreﬂected.
If the memory could differentiate between entering the CS an d leaving the CS, a more efﬁcient
implementationispossible. Toprovidethisinformation,t wokindsofsynchronizationvariablesor
operationsareneeded insteadofone.
Release consistency provides these two kinds. Acquireaccesses are used to tell the memory
system that a critical region is about to be entered. Hence, t he actions for Case (2). above need
to be performed to ensure that local replicas of variables ar e made consistent with remote ones.
Releaseaccesses say that a critical region has just been exited. Hen ce, the actions for Case (1).
aboveneedtobeperformedtoensurethatremotereplicasofv ariablesaremadeconsistentwiththe
localonesthathavebeenupdated. The AcquireandReleaseoperationscanbedeﬁnedtoapplytoa
subsetofthevariables. Theaccessesthemselvescan beimpl ementedeitherasordinaryoperations
on specialvariablesoras special operations.
IfthesemanticsofaCSisnotassociatedwiththe AcquireandReleaseoperations,thentheop-
erations effectivelyprovidefor barrier synchronization . Until all processes completetheprevious
phase, nonecan enterthenextphase.
Thefollowingrules arefollowedbytheprotected variables inthegeneral case.
•Allpreviouslyinitiated Acquireoperationsmustcompletesuccessfullybefore aprocess can
access aprotected shared variable.
•Allaccesses toaprotectedshared variablemustcompletebe foreaReleaseoperationcan be
performed.
•TheAcquireandReleaseoperationseffectivelyfollowthePRAM consistencymodel.
A relaxation of the release consistency model is called the lazy release consistency model.
Rather than propagating the updated values throughout the s ystem as soon as a process leaves a
critical region (or enters the next phase in the case of barri er synchronization), the updated values
415
arepropagatedtotherestofthesystemonlyondemand,i.e., onlywhentheyareneeded. Changes
toshared dataare onlycommunicatedwhen an Acquireaccess isperformed by anotherprocess.
Entry Consistency:
Entry consistency requires the programmer to use AcquireandReleaseat the start and at the end
of each CS, respectively. But unlike release consistency, e ntry consistency requires each ordinary
shared variable to be associated with some synchronization variable such as a lock or barrier.
Whenan Acquireisperformedonasynchronizationvariable,onlyaccesstot hoseordinaryshared
variablesthatare guarded bythat synchronizationvariabl eis regulated.
12.3 SharedMemoryMutualExclusion
Operating systems have traditionally dealt with multi-pro cess synchronization using algorithms
based on ﬁrst principles (e.g., the well-known bakery algor ithm), high-level constructs such as
semaphores andmonitors, and special ‘atomically executed’ instructions supporte d by special-
purpose hardware (e.g., Test-&-Set ,Swap, andCompare-&-Swap ). These algorithms are appli-
cable to all shared memory systems. In this section, we will r eview the bakery algorithm which
requiresO(n)accesses in the entry section, irrespective of the level of c ontention. We will then
studyfast mutual exclusion which requires O(1)accesses in the entry section in the absence of
contention. This algorithm also illustrates an interestin g technique in resolving concurrency. As
hardware primitives have the in-built atomicity that helps to easily solve the mutual exclusion
problem,wewillthenexaminemutualexclusionbased onthes eprimitives.
12.3.1 Lamport’sBakery Algorithm
Lamportproposedtheclassical bakeryalgorithm forn-processmutualexclusioninsharedmemory
systems. Thealgorithmissocalledbecauseitmimicstheact ionsthatcustomersfollowinabakery
store. A process wanting to enterthe critical section picks a token numberthat is one greater than
the elements in the array choosing [1...n]. Processes enter the critical section in the increasing
orderofthetoken numbers. In case ofconcurrent accesses to choosing by multipleprocesses,the
processes may have the same token number. In this case, a uniq uelexicographic order is deﬁned
on the tuple∝a\}⌊ra⌋k⌉tl⌉{ttoken,pid∝a\}⌊ra⌋k⌉tri}ht, and this dictates the order in which processes enter the cri tical section.
The algorithm for process iis given in Figure 12.13. The algorithm can be shown to satisf y the
three requirements of the critical section problem: (i) mut ual exclusion, (ii) bounded waiting, and
(iii)progress.
Intheentrysection,aprocesschoosesatimestampforitsel f,andresetsitto0intheexitsection.
In steps(1a)-(1c), each process choosesatimestampforits elf,as themax ofthelatesttimestamps
of all processes, plus one. These steps are non-atomic; thus multipleprocesses could be choosing
timestamps in overlapping durations. When process ireaches (1d), it has to check the status of
each other process j, to deal with the effects of any race conditions in selecting timestamps. In
(1d)-(1f), process iserially checks thestatus of each otherprocess j. Ifjis selecting a timestamp
416
(shared vars)
array ofboolean :choosing [1... n];
array ofinteger :timestamp [1... n];
repeat
(1)Piexecutes the following for the entrysection :
(1a)choosing [i]←−1;
(1b)timestamp [i]←−max k∈[1...n](timestamp [k]) + 1;
(1c)choosing [i]←−0;
(1d)forcount = 1tondo
(1e) while choosing [count]dono-op;
(1f) while timestamp [count]∝\⌉}atio\slash= 0and(timestamp [count],count )<(timestamp [i],i)do
(1g) no-op.
(2)Piexecutes the critical section (CS) after theentry section
(3)Piexecutes the following exit section after theCS:
(3a)timestamp [i]←−0.
(4)Piexecutes the remainder section after theexit section
untilfalse;
Figure 12.13: Lamport’s n-process bakery algorithm for shared memory mutual exclusi on. Code
shownisforprocess Pi,1≤i≤n.
for itself,j’s selection interval may have overlapped with that of i, leading to an unknown order
of timestamp values. Process ineeds to make sure that any other process j(j < i) that had
begintoexecute(1b)concurrentlywithitselfandmaystill beexecuting(1b)doesnotassignitself
the same timestamp. Otherwise mutual exclusion could be vio lated asiwould enter the CS, and
subsequently, j, having a lower process identiﬁer and hence a lexicographic ally lower timestamp,
would also enter the CS. Hence, iwaits forj’s timestamp to stabilize, i.e., choosing [j]to be set
tofalse. Oncej’s timestampis stabilized, imoves from (1e) to (1f). Either jis not requesting (in
whichcasej’stimestampis0)or jisrequesting. Step(1f)determinestherelativepriorityb etween
iandj. The process with a lexicographically lower timestamp has higher priority and enters the
CS; theotherprocesshas to wait(step (1g)). Hence, mutualexclusion issatisﬁed.
Bounded waiting is satisﬁed because each other process jcan “overtake” process iat most
once afterihas completed choosing its timestamp. The second time jchooses a timestamp, the
valuewillnecessarily belargerthan i’stimestampif ihas notyet entered itsCS.
Progress isguaranteedbecausethelexicographicorderisatotalord erandtheprocesswiththe
lowesttimestampatany timeintheloop(1d)-(1g)isguarant eed to entertheCS.
Attemptstoimprovethebakery algorithmhavelead to severa limportantresults.
•Spacecomplexity: Alowerboundof nregisters,speciﬁcally,the timestamp array,hasbeen
shown for the shared memory critical section problem. Thus, one cannot hope to have a
morespace-efﬁcient algorithmfordistributedshared memo rymutualexclusion.
•Time complexity: In many environments, the level of contention may be low. The O(n)
417
overhead of the entry section does not scale well for such env ironments. This concern is
addressed by the ﬁeld of fast mutual exclusion that aims to have O(1)time overhead for
the entry and exit sections of the algorithm, in the absence o f contention. Although this
algorithmguarantees mutualexclusionandprogress, unfor tunately,thisfast algorithmhas a
price–intheworstcase,itdoesnotguaranteeboundeddelay . Next,wewillstudyLamport’s
algorithmforfastmutualexclusioninasynchronousshared memorysystems. Thisalgorithm
isnotableinthatitistheﬁrstalgorithmforfastmutualexc lusion,andusestheasynchronous
sharedmemorymodel. Further,itillustratesanimportantt echniqueforresolvingcontention.
Theworst-caseunboundeddelayinthepresenceofpersistin gcontentionhasbeenaddressed
subsequently, by using a timed model of execution, wherein t here is an upper bound on the
time it takes to execute any step. We will not discuss mutual e xclusion under the timed
modelofexecution.
12.3.2 Lamport’sWRWRMechanism andFastMutual Exclusion
Lamport’s fast mutual exclusion algorithm is given in Figure 12.14. The algorithm illustrat es an
importanttechnique–the ∝a\}⌊ra⌋k⌉tl⌉{tW−R−W−R∝a\}⌊ra⌋k⌉tri}htsequencethatisanecessaryandsufﬁcientsequence
of operations to check for contention and to ensure safety in the entry section, using only two
registers.
Steps(1b),(1c),(1g),and(1h)representabasic ∝a\}⌊ra⌋k⌉tl⌉{tW(x)−R(y)−W(y)−R(x)∝a\}⌊ra⌋k⌉tri}htsequencewhose
necessity in identifying a minimal sequence of operations f or fast mutual exclusion is justiﬁed as
follows.
1. Theﬁrstoperationneedstobea Write,saytovariable x. Ifitwerea Read,thenallcontend-
ingprocesses couldﬁnd thevalueofthevariableevenoutsid etheentry section.
2. The second operation cannot be a Writeto another variable, for that could equally be com-
bined withtheﬁrst Writeto alarger variable. Thesecond operationshould notbeaReadof
xbecauseitfollows Writeofxandifthereisnointerleavedoperationfromanotherproces s,
theReaddoes notprovideany new information. So thesecond operatio n mustbe a Readof
anothervariable,say y.
3. The sequence must also contain Read(x)andWrite(y)because there is no point in reading a
variablethat isnotwrittento, awritinga variablethatis n everread.
4. The last operation in the minimal sequence of the entry sec tion must be a Read, as it will
help determine whether the process can enter CS. So the last o peration should be Read(x),
and thesecond-lastoperation shouldbethe Write(y).
In the absence of contention, each process writes its own id t oxand then reads y. Then ﬁnding
thatyhas its initial value, the process writes its own id to yand then reads x. Findingxto still
be its own id, it enters CS. Correctness needs to be shown in th e presence of contention – let us
discussthisafterconsideringthestructureoftheremaini ngentry and exitsectioncode.
418
(shared variables among the processes)
integer:x,y; // shared register initialized
array ofboolean b[1... n]; //ﬂags toindicate interest in critical section
repeat
(1)Pi(1≤i≤n)executes entry section:
(1a) b[i]←−true;
(1b) x←−i;
(1c)ify∝\⌉}atio\slash= 0then
(1d) b[i]←−false;
(1e) await y= 0;
(1f) goto(1a);
(1g) y←−i;
(1h)ifx∝\⌉}atio\slash=ithen
(1i) b[i]←−false;
(1j) forj= 1toNdo
(1k) await¬b[j];
(1l) ify∝\⌉}atio\slash=ithen
(1m) await y= 0;
(1n) goto(1a);
(2)Pi(1≤i≤n)executes critical section:
(3)Pi(1≤i≤n)executes exit section:
(3a) y←−0;
(3b) b[i]←−false;
forever.
Figure 12.14: Lamport’sdeadlock-free fast mutualexclusi onsolution,using Ω(n)registers. Code
isforprocess Pi, where 1≤i≤n.
In theexitsection,theprocessmustdoaWritetoindicateit scompletionoftheCS. TheWrite
cannotbeto xwhichisalsotheﬁrstvariablewrittenintheentrysection. Sotheoperationmustbe
Write(y).
Now consider the sequence of interleaved operations by proc essesi,j, andkin the entry
section, as shown in Figure 12.15. Process ienters its critical section, but there is no record of its
identity or that it had written any variables at all, because the variables it wrote (shown boldfaced
above) have been overwritten. In order that other processes can discover when (and who) leaves
the CS, there needs to be another variable that is set before t he CS and reset after the CS. This is
theboolean, flag[i]. Additionally, yneedsto bereset onexitingtheCS.
The code in lines (1c)-(1f) has the following use. If a proces spﬁndsy∝\⌉}atio\slash= 0, then another
process has executed at least line (1g) and not yet executed l ine (3a). So process presets its own
ﬂag, and before retrying again, it awaits for y= 0. If process pﬁndsy= 0in line (1c), it sets
y=pin line(1g)and checks if x=p.
•Ifx=p, then no other process has executed line (1b), and any later p rocess would be
blocked in the line (1c)-(1f) loop now because y=p. Thus, ifx=p, processpcan safely
419
Process PiProcess PjProcess Pkvariables
Wj(x) ∝a\}⌊ra⌋k⌉tl⌉{tx=j,y= 0∝a\}⌊ra⌋k⌉tri}ht
Wi(x) ∝a\}⌊ra⌋k⌉tl⌉{tx=i,y= 0∝a\}⌊ra⌋k⌉tri}ht
Ri(y) ∝a\}⌊ra⌋k⌉tl⌉{tx=i,y= 0∝a\}⌊ra⌋k⌉tri}ht
Rj(y) ∝a\}⌊ra⌋k⌉tl⌉{tx=i,y= 0∝a\}⌊ra⌋k⌉tri}ht
Wi(y) ∝a\}⌊ra⌋k⌉tl⌉{tx=i,y=i∝a\}⌊ra⌋k⌉tri}ht
Wj(y) ∝a\}⌊ra⌋k⌉tl⌉{tx=i,y=j∝a\}⌊ra⌋k⌉tri}ht
Ri(x) ∝a\}⌊ra⌋k⌉tl⌉{tx=i,y=j∝a\}⌊ra⌋k⌉tri}ht
Wk(x)∝a\}⌊ra⌋k⌉tl⌉{tx=k,y=j∝a\}⌊ra⌋k⌉tri}ht
Rj(x) ∝a\}⌊ra⌋k⌉tl⌉{tx=k,y=j∝a\}⌊ra⌋k⌉tri}ht
Figure12.15: An exampleshowingtheneed foraboolean vecto rforfast mutualexclusion.
entertheCS.
•Ifx∝\⌉}atio\slash=p, then another process, say q, has overwritten xin line (1b) and there is a potential
race. Twobroad cases are possible.
–Processqﬁndsy∝\⌉}atio\slash= 0in line (1c). It resets its ﬂag, and stays in the (1d)-(1f) sec tion
at least until phas exited the CS. Process pon the other hand resets its own ﬂag (line
(1i))andwaitsforallotherprocessessuchas qtoresettheirownﬂags. Asprocess qis
trapped in lines(1d)-(1f), process pwillﬁndy=iinline(1l)and entertheCS.
–Processqﬁndsy= 0in line (1c). It sets ytoqin line (1g), and enters the race, even
closer to process pwhich is at line(1h). Of the processes such as pandqthat contend
at line(1h),there willbea uniquewinner.
∗If no other process rhas since written to xin line (1b), the winner is the process
amongpandqthat executedline(1b)last, i.e., wroteits ownid to x. That winner
will enter the CS directly from line (1h), whereas the losers will reset their own
ﬂags, awaitthe winnerto exitand reset its ﬂag, and also awai t othercontenders at
line (1h) and newer contenders to reset their own ﬂags. The lo sers will compete
againfrom line(1a)after thewinnerhas reset y.
∗If some other process rhas since written its id to xin line (1b), both pandqwill
enter code in lines (1i)-(1n). Both pandqreset their ﬂags, await for rwhich will
betrappedinlines(1d)-(1f)toreset itsﬂag, andthenboth pandqcheck thevalue
ofy. Betweenpandq,theprocessthatlastwroteto yinline(1g)willbecomethe
unique winner and enter the CS directly. The loser will then a wait for the winner
toresety,and thencompeteagainfrom line(1a).
Thus, mutual exclusion is guaranteed, and progress is also g uaranteed. However, a process
maybestarved,althoughwithdecreasing probability,asit s numberofattemptsincreases.
420
(sharedvariablesamongthe processesaccessingeachofthe differentobjecttypes)
register:Reg←−initial value; // sharedregisterinitialized
(localvariables)
integer:old←−initial value; // valuetobe returned
(1)Test&Set(Reg)returns value:
(1a)old←−Reg;
(1b)Reg←−1;
(1c)return(old).
(2)Swap(Reg,new)returns value:
(2a)old←−Reg;
(2b)Reg←−new;
(2c)return(old).
Figure12.16: Deﬁnitionsofsynchronizationoperations Test&SetandSwap.
(shared variables)
register:Reg←−false; // shared register initialized
(local variables)
integer:blocked←−0; // variable tobe checked before entering CS
repeat
(1)Piexecutes the following for the entrysection :
(1a)blocked←−true;
(1b)repeat
(1c) Swap(Reg,blocked );
(1d)untilblocked =false;
(2)Piexecutes the critical section (CS) after theentry section
(3)Piexecutes the following exit section after theCS:
(3a)Reg←−false;
(4)Piexecutes the remainder section after theexit section
untilfalse;
Figure12.17: Mutualexclusionusing Swap. Codeshownisforprocess Pi,1≤i≤n.
12.3.3 Hardware support for mutualexclusion
Hardware support can allow for special instructions that pe rform two or more operations atom-
ically. Two such instructions, Test&SetandSwap, are deﬁned and implemented as shown in
Figure 14.22. The atomic execution of two actions (a Readand aWriteoperation) can greatly
simplify a mutual excluison algorithm, as seen from the mutu al exclusion code in Figure 12.17
and Figure 12.18, respectively. The algorithm in Figure 12. 17 can lead to starvation. The algo-
rithm in Figure 12.18 is enhanced to guarantee bounded waiti ng by using a “round-robin” policy
toselectivelygrant permissionwhen releasingthecritica l section.
421
(shared variables)
register:Reg←−false; // shared register initialized
array ofboolean :waiting [1... n];
(local variables)
integer:blocked←−initial value; // value tobe checked before entering CS
repeat
(1)Piexecutes the following for the entrysection :
(1a)waiting [i]←−true;
(1b)blocked←−true;
(1c)while waiting [i]andblockeddo
(1d) blocked←−Test&Set(Reg);
(1e)waiting [i]←−false;
(2)Piexecutes the critical section (CS) after theentry section
(3)Piexecutes the following exit section after theCS:
(3a)next←−(i+ 1)modn;
(3b)while next∝\⌉}atio\slash=iandwaiting [next] =falsedo
(3c) next←−(next+ 1)modn;
(3d)ifnext=ithen
(3e) Reg←−false;
(3f)elsewaiting [j]←−false;
(4)Piexecutes the remainder section after theexit section
untilfalse;
Figure12.18: Mutualexclusionwithboundedwaiting,using Test&Set. Codeshownisforprocess
Pi,1≤i≤n.
12.4 Wait-freedom
Processes that interact with each other, whether by message passing or by shared memory, need
to synchronize their interactions. Traditional solutions to synchronize asynchronous processes
via shared memory objects (also called concurrent objects ) use solutions based on locking, busy
waiting, critical sections, semaphores, or conditional wa iting. An arbitrary delay of a process or
itscrashfailurecan preventotherprocessesfrom completi ngtheiroperations. Thisisundesirable.
Wait-freedom is a property that guarantees that any process can complete a ny synchroniza-
tion operation in a ﬁnite number of lower-level steps, irres pective of the execution speed of other
processes. More precisely, a wait-free implementation of a concurrent object guarantees that any
process can complete an operation on it in a ﬁnite number of st eps, irrespective of whether other
processes crash or encounter unexpected delays. Thus, proc esses that crash, or encounter un-
expected delays (such as delays due to high processor load, s wapping out of memory, or CPU
schedulngpolicies)shouldnotdelayotherprocessesinawa it-freeimplementationofaconcurrent
object.
Not all synchronizations have wait-free solutions. As a tri vial example, a producer-consumer
synchronization between two processes cannot be implement ed in a wait-free manner if the pro-
422
ducerprocesscrashesbeforepostingitsvalue–theconsume risnecessarilyblocked. Nevertheless,
the notion of wait-freedom is an important concept in design ing fault-tolerant systems and algo-
rithms whenever possible. An alternate view of wait-freedo m in terms of fault-tolerance is as
follows.
•Anf-resilient system is a systemin which up to fof thenprocesses can fail, and theother
n−fprocessescan completealltheiroperationsinaﬁnitenumbe rofsteps,independentof
thestatesofthe fprocesses thatmayfail.
•Whenf=n−1, any process is guaranteed to be able to complete its operati ons in a ﬁnite
number of steps, independent of all other processes. A proce ss does not depend on other
processes, and its execution is therefore said to be wait-free. Wait-freedom provides inde-
pendencefrom thebehaviorofotherprocesses, and istheref orea verydesirableproperty.
Intheremainderofthischapterwhichdealswithsharedregi steraccesses,onlywait-freesolutions
are considered.
12.5 RegisterHierarchyandWait-freeSimulations
Observe from our analysis of DSM consistency models that an u nderlying assumption was that
any memory access takes a ﬁnite time interval, and the operat ion, whether a ReadorWrite, takes
effect at some point during this time duration. In the face of concurrent accesses to a memory
location, we cannot predict the outcome. In particular, in t he face of a concurrent ReadandWrite
operation, the value returned by the Readis unpredictable. This observation is true even for a
simplermultiprocessormemory,withoutthecontextofaDSM .Thisobservationledtotheresearch
area that tried to deﬁne the properties of access orderings f or the most elementary memory unit,
hereafter called a register. The access orderings depend on the properties of the regist er. An
implicit assumption is that of the availability of global ti me. This is a reasonable assumption
because weare studyingaccess to asingleregister. Whether thatregistervalueisreplicated in the
systemornotisalowerdetailthatis notrelevanttotheleve lofabstractionofthisanalysis.
In keeping with the semantics of the ReadandWriteoperations, the following register types
have been identiﬁed to specify the value returned to a Readin the face of a concurrent Write
operation. For the time being, we assume that there is a singl e reader process and a single writer
process.
Safe register: AReadoperationthat does not overlapwith a Writeoperation returns themostre-
centvaluewrittentothatregister. A Readoperationthatdoesoverlapswitha Writeoperation
returnsanyoneofthevaluesthat theregistercouldpossiblycontainat any time.
Consider the example of Figure 12.19 which shows several ope rations on an integer-valued
register. We considertwocases, withoutand withthe WritebyP3.
423
2 2 2 Read3  (x,?) Read2  (x,?) Read1  (x,?)Write2  (x,6) Write1  (x,4)11
3Write1  (x,−6)
3P
P1
2
P
Figure 12.19: Examples to illustratedeﬁnitionsof safe,regular, andatomicregisters. Theregular
linesassumeaSRSWregister. Ifthedashedlineisalsoused, theregisterisassumedtobeSRMW.
NoWritebyP3:If the register is safe,Read1 2must return the value 4, whereas Read2 2
andRead3 2can return any possibleinteger(up to MAXINT)because these operations
overlapwitha Write, andthevaluereturned istherefore ambiguous.
WritebyP3:Sameas forthe“no Write”case.
Ifmultiplewriters areallowed,orif Writeoperationsare allowedtobepipelined,thenwhat
deﬁnes the most recent value of the register in the face of con currentWriteoperations be-
comes complicated. We explicitly disallow pipelining in th is model and analysis. In the
face ofWriteoperations from different processors that overlap in time, the notion of a seri-
alization point is deﬁned. Observe that each WriteorReadoperation has a ﬁnite duration
between its invocation and its response. In this duration, t here is effectively a single time
instant at which the operation takes effect. For a Readoperation, this instant is the one at
which the instantaneous value is selected to be returned. Fo r aWriteoperation, this instant
is the one at which the value written is ﬁrst ‘reﬂected’ in the register. Using this notion of
theserializationpoint,the‘mostrecent’operationis una mbiguouslydeﬁned.
Regularregister: In addition to being a saferegister, a Readthat is concurrent with a Write
operation returns either the value before the Writeoperation, or the value written by the
Writeoperation.
In the example of Figure 12.19, we consider the two cases, wit h and without the Writeby
P3.
NoWritebyP3:Read1 2mustreturn4,whereas Read2 2canreturneither4or6,and Read3 2
can alsoreturn either4or6.
WritebyP3:Read1 2must return 4, whereas Read2 2can return either 4 or -6 or 6, and
Read3 2can alsoreturn either4or-6 or6.
Atomicregister: In addition to being a regularregister, the register is linearizable (deﬁned in
Section 12.2.1)toasequentialregister.
In the example of Figure 12.19, we consider the two cases, wit h and without the Writeby
P3.
424
Type Value Writing Reading
safe binary Single-Writer Single-Reader
regular integer Multi-Writer Multi-Reader
atomic
Table 12.2: Classiﬁcation of registers by Type, Value, Writ ing Access, and Reading Access. The
strengthoftheregisterincreases downeach column.
NoWritebyP3:Read1 2must return 4, whereas Read2 2can return either 4 or 6. If Read2 2
returns 4, then Read3 2can return either 4 or 6, but if Read2 2returns 6, then Read3 2
mustalso return6.
WritebyP3:Read1 2mustreturn4,whereas Read2 2canreturneither4or-6or6,depending
on theserializationpointsoftheoperations.
1. IfRead2 2returns6andtheserializationpointof Write1 3precedestheserialization
pointofWrite2 1, thenRead3 2mustreturn 6.
2. IfRead2 2returns6andtheserializationpointof Write2 1precedestheserialization
pointofWrite1 3, thenRead3 2can return +6 or-6.
3. Cases (3)and (4)where Read2 2returns -6 aresimilartocases (1)and(2).
Thefollowingproperties,summarizedin Table12.2,charac terize registers.
•whethertheregisterissingle-valued(boolean)ormulti-v alued
•whethertheregisterisasingle-reader(SR) ormulti-reade r(MR) register
•whethertheregisterisasingle-writer(SW) ormulti-write r(MW)register
•whethertheregisteris safe,regular,oratomic
The above characteristics lead to a hierarchy of 24 register types, with the most elementary being
the boolean SRSW safe register and the most complex being the multi-valued MRMW atomic
register.
Astudyof registerconstruction dealswithdesigningthemorecomplexregistersusingsimpl er
registers. Such constructions allow us to construct any reg ister type from the most elementary
register – the boolean SRSW safe register. We will study such constructions by assuming the
following convention. R1...R qareqregisters that are used to construct a stronger register R, as
showninFigure12.20. Weassume nprocessesexist;notethatforvariousconstructions, qmaybe
differentfrom n.
Although the traditional memory architecture, based on ser ialized access via memory ports to
a memory location, does not require such an elaborate classi ﬁcation, the bigger picture needs to
bekeptinmind. Inadditiontoillustratingalgorithmicdes igntechniques,thisstudypavestheway
for accommodating newer technologies such as – quantum comp uting and DNA computing – for
constructingsystemmemory.
425
i
R Read from RWrite to R
iWrites to individual R
Reads from individual Rq R1R
Figure12.20: Registersimulations.
(shared variables)
SRSWsafe registers R1... R n←−0; // Riisreadable by Pi,writable by P0
(1)Write(R,val )executed by single writer P0
(1a)for all i∈{1... n}do
(1b) Ri←−val.
(2)Read i(R,val )executed by reader Pi,1≤i≤n
(2a)val←−Ri
(2b)return (val).
Figure 12.21: Construction 1: SRSW Safe register to MRSW Saf e registerR. This construction
can also beusedforSRSW Regularregisterto MRSW Regularreg isterR.
12.5.1 Construction 1: SRSW Safe to MRSW Safe
Figure 12.21 gives the construction of a MRSW saferegisterRusing only SRSW saferegisters.
Assume the single writer is process P0and thenreader processes are P1toPn. Each of the n
processesPican read only SRSW register Ri. As multiple readers are not allowed to access the
same register, in essence, the data needs to be replicated. S o in the construction, the writer P0
writes the same value to the nregisters. Register Riis read byPi. In Figure 12.20, the value of
qwould hence be n. When a ReadbyPiand aWritebyP0do not overlap their access to Ri, the
Readobtains the correct value. When a ReadbyPiand aWritebyP0overlap their access to Ri,
asRiis asaferegister,Pireads alegitimatevaluefrom Ri.
Complexity: This construction has a space complexity of ntimes the size of a single register,
whichmay beeitherbinaryorinteger-valued. Thetimecompl exityisnsteps.
426
(shared variables)
boolean MRSWsafe registers R1... R log(m)←−0; // Rireadable by all, writable by P0.
(local variable)
array ofboolean: V al[1... log (m)];
(1)Write(R,V al [1... log m ])executed bysingle writer P0
(1a)for all i∈{1... log (m)}do
(1b) Ri←−V al[i].
(2)Read i(R,V al [1... log (m)])executed by reader Pi,1≤i≤n
(2a)for all j∈{1... log m}doV al[j]←−Rj
(2b)return (V al[1... log (m)]).
Figure12.22: Construction3: booleanMRSWSaferegisterto integer-valuedMRSWSaferegister
R.
12.5.2 Construction 2: SRSW Regular to MRSW Regular
ThisconstructionisidenticaltoConstruction1(Figure12 .21)exceptthat regularregistersareused
instead of saferegisters. When a ReadbyPiand aWritebyP0do not overlap their access to Ri,
theReadobtains the correct value. When a ReadbyPiand aWritebyP0overlap their access to
Ri, asRiis aregularregister,Pireads fromRieithertheearliervalueorthevaluebeingwritten.
Complexity: This construction has a space complexity of ntimes the size of a single register,
whichmay beeitherbinaryorinteger-valued. Thetimecompl exityisnsteps.
12.5.3 Construction 3: BooleanMRSW Safe tointeger-valued MRSW Safe
Figure12.22givestheconstructionofaninteger-valuedMR SWsaferegisterR. Assumethesingle
writerisprocess P0andthenreaderprocessesare P1toPn. Theconstructioncanuseonlyboolean
MRSW registers – to construct an integer register of size m, at leastlog(m)boolean registers are
necessary. Sointheconstruction,thewriter P0writesthevalueinitsbinarynotationtothe log(m)
registersR1toRlog(m). Similarly,anyreaderreadsregisters RitoRlog(m). Whena ReadbyPiand
aWritebyP0do not overlap, the Readobtains the correct value. When a ReadbyPiand aWrite
byP0overlaptheiraccesstotheregisters,asthe Ri(i= 1tolog(m))registersare safe,Pireads a
legitimatevalue.
Complexity: This construction has a space complexity of log(m)times the size of an integer m.
Thetimecomplexityis O(log(m))steps.
12.5.4 Construction 4: BooleanMRSW Safe toboolean MRSW Reg ular
Figure 12.23 gives the construction of a boolean MRSW regularregisterRfrom a MRSW safe
register. Assumethesinglewriterisprocess P0and thereader processesare Pi(1≤i≤n). With
427
(shared variables)
boolean MRSWsafe register :R′←−0; // R′is readable by all, writable by P0.
(local variables)
boolean local towriter P0:previous←−0;
(1)Write(R,val )executed by single writer P0
(1a)ifprevious∝\⌉}atio\slash=valthen
(1b) R′←−val;
(1c) previous←−val.
(2)Read(R,val )process Pi,1≤i≤n
(2a)val←−R′;
(2b)return (val).
Figure 12.23: Construction 4: boolean MRSW Safe register to boolean MRSW Regular register
R.
respect toFigure12.20, qhas thevalue1. P0writesR1andall thenprocessesread R1.
When aReadbyPiand aWritebyP0do not overlap, the Readobtains the correct value.
When aReadbyPiand aWritebyP0overlap, the saferegister may not necessarily return the
overlappingorthepreviousvalue(asrequiredbya regularregister),butmayreturnavaluewritten
much earlier. If the value written before the Readbegins isα, and the value being written by the
concurrent Writeis alsoα, theReadcould return αor(1−α)from the saferegister, which is a
problem for the regularregister. The solution bypasses this problem by having the Writeuse a
local variable previous to track the previous value of val. If the previous value that was written
(line (1b)) and stored in previous (line (1c)) is the same as the new value to be written, then the
newvalueissimplynotwritten. Thisavoidsany concurrent a ccess toR.
Complexity: Thisconstructionuses O(1)space andtime.
Can theaboveconstructionalsoconstructabinarySRSW atomicregisterfroma saferegister?
No. Consider P1issuesaWrite1 1(α)thatcompletes;then Write2 1(1−α)beginsandoverlapswith
Read1 2andRead2 2ofP2. With the above construction, Read1 2could return 1−αwhereas the
laterRead2 2couldreturn α,thusviolatingtheproperty ofan atomicregister.
12.5.5 Construction 5: Boolean MRSW Regular to integer-val ued MRSW
Regular
Figure 12.24 gives the construction of an integer-valued MR SWregularregisterRusing boolean
MRSWregularregisters. Assumethesinglewriterisprocess P0andthenreaderprocessesare P1
toPn. Theconstructioncan useonlybooleanMRSWregisters–toco nstructanintegerregisterof
sizem, unary notation is used, so mboolean registers are necessary. In Figure 12.20, q=m, and
all thenprocesses can read allthe qregisters.
428
(shared variables)
boolean MRSWregular registers R1... R m−1←−0;Rm←−1;
//Rireadable by all, writable by P0.
(local variables)
integer:count;
(1)Write(R,val )executed by writer P0
(1a)Rval←−1;
(1b)forcount =val−1downto 1do
(1c) Rcount←−0.
(2)Read i(R,val) executed by Pi,1≤i≤n
(2a)count = 1;
(2b)while Rcount= 0do
(2c) count←−count + 1;
(2d)val←−count;
(2e)return (val).
Figure 12.24: Construction 5: boolean MRSW Regular registe rto integer-valued MRSW Regular
registerR.
When aReadbyPiand aWritebyP0do not overlap, the Readobtains the correct value. To
dealwitha ReadbyPiandaWrite(s)byP0overlappingtheiraccesstotheregisters,thefollowing
approach is used. A reader Piscans left-to-right looking for a ‘1’ whereas the P0writer process
writes ‘1’ to the Rvallocation and then zeros out entries right-to-left. The Readis guaranteed to
see a ‘1’ written by one of the Writeoperations it overlaps with, or the ‘1’ written by the Write
that completed just before the Readbegan. As each of the bits are regular, its current or previou s
valueisread;ifthevalueis‘0’,itisguaranteedthata‘1’h asbeenwrittentotheright. Animplicit
assumptionhereistheintegersize,boundedbythenumberof bitsinuse. Theregisterisinitialized
bythislargestvalue. Theconstructionisillustratedin Fi gure12.25. In theﬁgure, thereaderscans
from leftto rightas marked.
Complexity: This construction uses mbinary registers, where mis the largest integerthat can be
writtenby theapplication.
12.5.6 Construction 6: Boolean MRSW Regular to integer-val ued MRSW
Atomic
Cantheaboveconstruction(Figure12.24)alsoconstructan integer-valuedMRSW atomicregister
from boolean MRSW regularregisters? No. The problem is that when two successive Read
operations overlap Writeoperations, ‘inversion’ of values returned by the Readoperations can
occur.
Considerthefollowingsequence ofoperations,depicted in Figure12.26.
429
2 3Zero out entries
Scan for first "1"; then scan backwards 
and update pointer to lowest−rankedregister containing a "1"Rm valRR
Scan for "1"; return index. (bool MRSW reg to int MRSW reg)
(bool MRSW atomic to int MRSW atomic)
Read(     )RWrite val to R
Write 1
R1R R
Figure12.25: IllustratingConstructions5 and 6.
Write(R  ,1)3Write(R  ,0) Write(R  ,0)1
3Read(R  ,1) Read(R  ,0)2Read(R  ,0) Read(R  ,1)2Read(R  ,0)1
Read1  (R,?) returns 3 Read2  (R,?) returns 22
bbaa a
bWrite1  (R,2)
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1P
P1Write(R  ,1)2 1Write(R  ,0)Write2  (R,3)
Figure12.26: Exampleto illustrateinversionofvaluesrea d byPaandPb.
1.Write1 a(R,2): Thelow-leveloperation Write (R2,1)begins,i.e., R2←−1begins.
2.Read1 b(R,?): Thefollowinglow-leveloperationsgetexecuted. count←−1;Read(Rcount,0);
count←−2;Read(Rcount,0);count←−3;
3.Write1 a(R,2): The low-level operation Write (R2,1)from step 1 completes, i.e., the value
‘1’getswrittento R2;then theleft scan tozero out R1proceeds byexecuting Write(R1,0).
4.Write2 a(R,3): The low-level operation Write(R3,1)executes, i.e., R3←−1begins and
ends.
5.Read1 b(R,?): The low-level operation Read(Rcount=3,?)that was to begin after step 2 re-
turns1;thehigh-level Readcompletesandreturns avalueof3.
430
(shared variables)
boolean MRSWregular registers R1... R m−1←−0;Rm←−1.
//Rireadable by all;writable by P0.
(local variables)
integer:count,temp ;
(1)Write(R,val )executed by P0
(1a)Rval←−1;
(1b)forcount =val−1downto 1do
(1c) Rcount←−0.
(2)Read i(R,val) executed by Pi,1≤i≤n
(2a)count←−1;
(2b)while Rcount= 0do
(2c) count←−count + 1;
(2d)val←−count;
(2e)fortemp=countdownto1do
(2f) ifRtemp= 1then
(2g) val←−temp;
(2h)return (val).
Figure 12.27: Construction 6: boolean MRSW Regular registe r to integer-valued MRSW Atomic
registerR.
6.Read2 b(R,?): This operation’s left-to right scan for a ‘1’ ﬁnds R2= 1and returns 2.
This is because the low-level operation Write2 (R2,0)belonging to the high-level operation
Write2 a(R,3)has notyet zeroed out R2.
Here,Read2 b(R,2)returns the value written by Write1 a(R,2); whereas the earlier Read1 b(R,3)
returns thevaluewritten bythelater Write2 a(R,3). Hence, thisexecutionisnot linearizable.
Figure12.27givestheconstructionofainteger-valuedMRS WatomicregisterRbymodifying
the above solution as follows. The reader makes a right-to-l eft scan for a ‘1’ after its left-to-right
scan completes. If it ﬁnds a ‘1’ in a lower index, it updates th e value to be returned to this index.
The purpose is to make sure that the lowest index (say α) in which a ‘1’ is found in this second
‘right-to-left’ scan is returned by the Read. As the writer also zeros out entries ‘right-to-left’, it is
notpossiblethatalater Readwillﬁnda‘1’writtenearlierinapositionlowerthan α,byaWritethat
occurred earlier than the Writewhich wrote α. This allows a linearizable execution. With respect
to Figure 12.20, q=m, and all the nprocesses can read all the qregisters. This construction is
alsoillustratedinFigure12.25,as marked therein.
Aformalargumentthatthisconstructioniscorrectneedsto showthatanyexecutionislineariz-
able. Todoso,itwoulddeﬁnethe linearizationpoint ofaReadandWriteoperationtocapturethe
notionoftheexact instantat which thatoperationeffectiv elyappears totakeeffect.
•Thevalueof theMRSW register at anymomentis x, whereRx= 1and∀y <x,Ry= 0.
431
•Thelinearizationpointof a Write(R,x)operation istheﬁrst instant(line(1a) or(1c)) when
Rx= 1and∀y<x,Ry= 0.
•Thelinearizationpointofa Read(R,val )thatreturns (x)istheﬁrstinstant(line(2d)or(2g))
whenvalgetsassigned xin thelow-leveloperations.
The following observation can now be made from the construct ion and the deﬁnition of the lin-
earization pointofa Write.
•Thevalue of the MRSW register remains unchanged between the linearization points of any
twoconsecutive Writeoperations.
TheWriteoperations are naturally ordered in the linearization sequ ence. In order to determine
a complete linearization of the Readoperations in addition to the Writeoperations, observe the
following.
•AReadoperation returns the value written by that Writeoperation which has the latest
linearizationpointthatprecedes the Readoperation’slinearizationpoint.
It naturally follows that a later Readwill never return the value written by a earlier Write, and
hencetheconstructionis linearizable.
Complexity: This construction uses mbinary registers, where mis the largest integer that is
writtenby theapplicationprogram. Thetimecomplexityis O(m).
12.5.7 Construction 7: IntegerMRSW Atomicto integer MRMW A tomic
We are given MRSW atomicregisters, i.e., each register has only a single writer. To s imulate a
MRMWatomicregisterR, the variable has multiple copies, R1...R n, one per writer process.
WriterPican only writeto its copy Ri. ReaderPican read all the registers R1...R n. When con-
currentupdatesoccur, agloballinearizationordermustbe created somehow. The Readoperations
must be able to recognize such a global order, and then return the appropriate version as per the
semanticsoftheatomicregister. That isthechallenge.
The construction is shown in Figure 12.28. With respect to Fi gure 12.20, q=n, and all
thenprocesses can read all the qMRSW registers but only Pican write to Ri. The idea used
is similar to that used by the Bakery algorithm for mutual exc lusion (Section 12.3.1), wherein
each process competing for the critical section ﬁrst sets it s ﬂag (behaving as the writer process)
signalling its intention. The competing processes that mak e concurrent accesses (behaving as the
reader processes)thenread all theﬂags anddeduce aglobalo rderthatresolvesthecontention.
Each register Rihas two ﬁelds: Ri.dataandRi.tag, wheretag=∝a\}⌊ra⌋k⌉tl⌉{tseq_no,pid∝a\}⌊ra⌋k⌉tri}ht. Alexico-
graphicorder isdeﬁnedonthetags,using seq_noastheprimarykey,andthen pidasthesecondary
key. A common procedure invoked by the readers and writers is theCollectwhich reads all the
registers, in no particular order. The reader returns the da ta corresponding to the (lexicographi-
cally) most recent Write. A writer chooses a tag greater than the (lexicographically ) greatest tag
returned bythe Collect, whenit writesitsnewvalue.
432
(shared variables)
MRSWatomic registers of type∝a\}⌊ra⌋k⌉tl⌉{tdata,tag∝a\}⌊ra⌋k⌉tri}ht, where tag=∝a\}⌊ra⌋k⌉tl⌉{tseq_no,pid∝a\}⌊ra⌋k⌉tri}ht:R1... R n;
(local variables)
array ofMRSWatomic registers oftype∝a\}⌊ra⌋k⌉tl⌉{tdata,tag∝a\}⌊ra⌋k⌉tri}ht, where tag=∝a\}⌊ra⌋k⌉tl⌉{tseq_no,pid∝a\}⌊ra⌋k⌉tri}ht:Reg_Array [1... n];
integer:seq_no,j,k;
(1)Write i(R,val )executed by Pi,1≤i≤n
(1a)Reg_Array←−Collect (R1,... ,R n);
(1b)seq_no←−max(Reg_Array [1].tag.seq_no,... Reg _Array [n].tag.seq_no) + 1;
(1c)Ri←−(val,∝a\}⌊ra⌋k⌉tl⌉{tseq_no,i∝a\}⌊ra⌋k⌉tri}ht).
(2)Read i(R,val) executed by Pi,1≤i≤n
(2a)Reg_Array←−Collect (R1,... ,R n);
(2b)identify jsuch that for all k∝\⌉}atio\slash=j,Reg_Array [j].tag > Reg _Array [k].tag;
(2c)val←−Reg_Array [j].data;
(2d)return (val).
(3)Collect (R1,... ,R n)invoked by ReadandWriteroutines
(3a)forj= 1tondo
(3b) Reg_Array [j]←−Rj;
(3c)return (Reg_Array ).
Figure 12.28: Construction 7: integerMRSW Atomic register to integer MRMW Atomic register
R.
All theWriteoperations are lexicographically totally ordered. Each Readis ordered so that it
immediatelyfollowsthat Writewiththematchingtag. Thus,thisexecutionislinearizable .
Complexity: This construction uses mbinary registers, where mis the largest integer written by
theapplication. Thetimecomplexityis O(m).
12.5.8 Construction 8: IntegerSRSW Atomic tointeger MRSW A tomic
We are given SRSW atomicregisters. To simulate a MRSW atomicregisterR, the variable has
multiple copies, R1,...R n, one per reader process. The single writer can write to all of these
registers.
A ﬁrst attempt at this construction would have the writer wri te to all the registers R1...R n,
whereasreader PireadsRi. InFigure12.20, q=n,andeachRiisreadbyPiandwrittentobythe
single writer P0. However, such a construction does not give a linearizable e xecution. Consider
two reads Read1 iandRead2 jthat both overlap a WriteandRead2begins after Read1terminates.
It ispossiblethat:
1.Read1 ireadsRiaftertheWritehas writtento Ri
2. butRead2 jreadsRjbeforethewriterhashad achance toupdate Rj.
433
1,1 1,2 1,n
2,1 2,2 2,n
n,n n,1 n,2R1R2Rn
mailboxes Last_Read_Values[1..n,1..n]
(SRSW atomic registers)SRSW atomic registers, one per process
R
Figure12.29: IllustratingthedatastructuresforConstru ction8.
Thisresultsina non-linearizableexecution.
The problem above arose because a reader did not have access t o what other readers read; in
particular, areader Picannot tellifanother ReadbyPjthatcompletedbefore this Readbegangot
a value that is newer than the value that the writer has writte n toRi. In fact, performing multiple
reads by the Piprocesses, and/ormore writes by P0, and/orusing more registerscannot solvethis
problem.
To ﬁx this problem, a reader process Pimust choose the latest of the values that other reader
processeshavelastread,andthevaluein Ri. AsonlySRSW registersareavailable,unfortunately,
this requires communication between each pair of reader pro cesses, leading to O(n2)variables.
Thus, a reader process must also write! An array Last_Read_Values [1...n,1...n]is used for
this purpose. Last_Read_Values [i,j]is the value that Pi’s lastReadreturned, which Pihas
set aside for Pjto know about. Once a reader Pidetermines the latest of the values that other
readers read (lines 2(b-d)), and the value written for it by t he writer process (line 2a), the reader
publishesthisvaluein Last_Read_Values [i,∗](lines2e-2f). Asthereisasinglewriter,theformat
∝a\}⌊ra⌋k⌉tl⌉{tdata,seq_no∝a\}⌊ra⌋k⌉tri}htforeachregistervalueandeach Last_Read_Valueentryisadequatetogiveatotal
order on all the values written by it. The construction is sho wn in Figure 12.30 and illustrated in
Figure12.29. Here, q=n2+nasthereare n2SRSW registersthatact as personalizedmailboxes
between pairs of processes, and the nregisters that are the mailboxs between writer P0and each
readerPi.
Complexity: Thisconstructionuses O(n2)integerregisters. Thetimecomplexityis O(n).
Achieving linearizability: All theWriteoperations form a total order. A ReadbyPireturns the
value of the latest preceding Write, as observed directly from the register Ri, or indirectly from
the register Rjand communicated to PiviaLast_Read_Values. In a linearized execution, a
Readisplacedafterthe Writewhosevalueitreads. Fornonoverlapping Reads,theirrelativeorder
434
(shared variables)
SRSWatomic register oftype ∝a\}⌊ra⌋k⌉tl⌉{tdata,seq _no∝a\}⌊ra⌋k⌉tri}ht,where data,seq _noare integers :R1... R n←−∝a\}⌊ra⌋k⌉tl⌉{t0,0∝a\}⌊ra⌋k⌉tri}ht;
SRSW atomic register array of type ∝a\}⌊ra⌋k⌉tl⌉{tdata,seq _no∝a\}⌊ra⌋k⌉tri}ht,where data,seq _noare integers :
Last_Read_V alues [1... n,1... n]←−∝a\}⌊ra⌋k⌉tl⌉{t0,0∝a\}⌊ra⌋k⌉tri}ht;
(local variables)
array of∝a\}⌊ra⌋k⌉tl⌉{tdata,seq _no∝a\}⌊ra⌋k⌉tri}ht:Last_Read[0... n];
integer:seq,count ;
(1)Write(R,val )executed by writer P0
(1a)seq←−seq+ 1;
(1b)forcount = 1tondo
(1c) Rcount←−∝a\}⌊ra⌋k⌉tl⌉{tval,seq∝a\}⌊ra⌋k⌉tri}ht. //write toeach SRSWregister
(2)Read i(R,val) executed by Pi,1≤i≤n
(2a)∝a\}⌊ra⌋k⌉tl⌉{tLast_Read[0].data,Last _Read[0].seq_no∝a\}⌊ra⌋k⌉tri}ht←− Ri; // Last_Read[0]stores value of Ri
(2b)forcount = 1tondo//read into Last_Read[count], thelatest values stored for PibyPcount
(2c)∝a\}⌊ra⌋k⌉tl⌉{tLast_Read[count].data,Last _Read[count].seq_no∝a\}⌊ra⌋k⌉tri}ht←−
∝a\}⌊ra⌋k⌉tl⌉{tLast_Read_V alues [count,i ].data,Last _Read_V alues [count,i ].seq_no∝a\}⌊ra⌋k⌉tri}ht;
(2d)identify jsuch that for all k∝\⌉}atio\slash=j,Last_Read[j].seq_no≥Last_Read[k].seq_no;
(2e)forcount = 1tondo
(2f)∝a\}⌊ra⌋k⌉tl⌉{tLast_Read_V alues [i,count ].data,Last _Read_V alues [i,count ].seq_no∝a\}⌊ra⌋k⌉tri}ht←−
∝a\}⌊ra⌋k⌉tl⌉{tLast_Read[j].data,Last _Read[j].seq_no∝a\}⌊ra⌋k⌉tri}ht;
(2g)val←−Last_Read[j].data;
(2h)return (val).
Figure 12.30: Construction 8: integer SRSW Atomic register to integer MRSW Atomic register
R.
represents the order in a linearizable execution, because o f the indirect communication among
readers. For overlapping Reads, their ordering in a linearized execution is consistent wi th the
Writeswhosevaluestheyread. Hence, theconstructionisa validc onstruction.
12.6 Wait-freeAtomicSnapshotsofSharedObjects
Observingtheglobalstateofa distributedsystemisafunda mentalproblem. Formessage-passing
systems,wehavestudiedhowtorecordglobalsnapshotswhic hrepresentaninstantaneouspossible
global state that could have occurred in the execution. The s napshot algorithms used message-
passing of control messages, and were inherently inhibitio n-free, although some variants that use
fewercontrolmessagesdo requireinhibition.
Inthissection,weexaminethecounterpartoftheglobalsna pshotprobleminashared-memory
system, where only ReadandWriteprimitives can be used. The problem can be modeled as
follows.
Given a set of SWMR atomic registers R1...R n, whereRican be written only by Piand can
435
seq_no old_snapshot data seq_no old_snapshot
R1RnP P 1 n
UPDATEUPDATEScan Scan
snapshot object composed of n MRSW atomic registersdata
Figure12.31: Atomicsnapshotobject, usingMRSW atomicreg isters.
bereadbyallprocesses,andwhichtogetherformacompoundh igh-levelobject,devisea wait-free
algorithm to observe the state of the object at some instant i n time. The following actions are
allowedonthishigh-levelobject,as also illustratedin Fi gure12.31.
•Scan i: Thisactioninvokedby Pireturnstheatomicsnapshotwhichisaninstantaneousview
of the object (R1,...,R n)at some instant between the invocation and termination of th e
Scan.
•Update i(val): Thisactioninvokedby Piwritesthedata valtoregisterRi.
Clearly, any kind of locking mechanism is unacceptable beca use it is not wait-free. Consider
the following attempt at a wait-free solution. The format of each register Riis assumed to be the
tuple:∝a\}⌊ra⌋k⌉tl⌉{tdata,seq_no∝a\}⌊ra⌋k⌉tri}htin order to uniquelyidentify each Writeoperation to theregister. A scanner
would repeatedly scan the high-level object until two conse cutive scans, called double-collect in
thesharedmemorycontext,returnedidenticalcontent. Thi sprincipleof“double-collect”hasbeen
encounteredinmultiplecontexts,suchintwo-phasedeadlo ckdetectionandtwo-phasetermination
detection algorithms, and essentially embodies the two-ph ase observation rule (see Chapter 11.
However, this solution in not wait-free because between the two observations of each double-
collect,an Updatebyanotherprocesscan preventthe Scanfrombeingsuccessful.
A wait-free solution is given in Figure 12.33. Process Pican write to its MRSW register Ri
and can read all registers R1,...R n. To design a wait-free solution, it needs to be ensured that a
scanner is not indeﬁnitely prevented from getting identica l scans in the double-collect, by some
writer process periodically making updates. The problem ar ises because of the imbalance in the
rolesofthescannerandupdater–theupdaterisinherentlym orepowerfulinthatitcanpreventall
scanners frombeingsuccessful. Oneelegantsolutionthere foreneutralizestheunfairadvantageof
theupdaters by forcing theupdaters to followthesame rules as the scanner. Namely, theupdaters
also have to perform a double-collect, and only after perfor ming a double-collect can an updater
write the value it needs to! Additionally, an updater also wr ites the snapshot it collected in the
436
Double collect
Collect CollectPi
iPj j
changed[j]=1 changed[j]=2
P   writes in P   writes inj j
Pjthis period this period
P   writes P   writes j j
nested within P_j’s SCAN. And so on recursively, up to n times.(a) Double collect sees identical values in both Collects
(b) P_j’s Double−Collect nested within P_i’s SCAN. The Double−Collect
is successful, or P_j borrowed snapshot from P_k’s Double−Collectj j
Figure12.32: Nestingofdouble-collects,inScanning forA tomicsnapshotsofobject.
register, along with the new value of the data item. Now, if a s canner detects that an updater
has made an update after the scanner initiated its Scan, then the scanner can simply ‘borrow’ the
snapshotrecordedbytheupdaterinitsregister. Theupdate rhelpsthescannertoobtainaconsistent
value. This is the principle of “helping” that is often used i n designing wait-free solutions for
variousproblems.
Ascannerdetectsthatanupdaterhasmadeanupdateafterthe scannerinitiatedits Scan,byus-
ingthelocalarray changed. Thisarrayisresetto0whenthe Scanisinvoked. Location changed [k]
is incremented (line (2k)) if the Scanprocedure detects (line (2j)) that process Pkhas changed its
dataandseq_no(andimplicitlythe old_snapshot )ﬁeldsinRk. Basedonthevalueof changed [k],
differentinferences can bemade,as nowexplainedwiththeh elpofFigure12.32.
•Ifchanged [k] = 2(line (2l)), then two updates (line (1b)) were made by PkafterPibegan
itsScan. Between the ﬁrst and the second update, the Scanpreceding the second update
musthavecompletedsuccessfully,andthescannedvaluewas recordedinthe old_snapshot
ﬁeld. Thisoldsnapshotcan besafely borrowedbythescanner Pi(line(2m))becauseitwas
recorded after Pkﬁnished its ﬁrst double-collect, and hence after the scanne rPiinitiated its
Scan.
•However, if changed [k] = 1, it cannot be inferred that the old_snapshot recorded by Pk
was taken after Pi’sScanbegan. When Pkdoes itsUpdate(the ﬁrst ‘write’ shown in Fig-
ure 12.32(b)), the value it writes in old_snapshot is only the result of a double-scan that
preceded the‘write’and maybeavaluethat existedbefore Pi’sScanbegan.
There aretwocases bywhicha snapshotcan becaptured, as ill ustratedusingFigure12.32.
437
1. Ascannercancollectasnapshot(line(2g))ifthedouble- collect(lines(2d-2e))returnsiden-
tical views (line (2f)). See Figure 12.32(a). The returned s napshot represents an instanta-
neous state that existed at all times between the end of the ﬁr stcollect(line (2d)) and the
startofthesecond collect(line(2e)).
2. Otherwise the scanner returns a borrowed snapshot (line ( 2m)) fromPkifPkhas been no-
ticed to have made two updates (lines (2l)) and therefore Pkhas made a Scanembedded
insidePi’sScan. This borrowed snapshot itself (i) may have been obtained di rectly via a
double-collect , or (ii) indirectly been borrowed from another process (lin e (2l)). In case (i),
itrepresentsaninstantaneousstateinthedurationofthe double-collect . Incase(ii),arecur-
siveargument can be applied. Observethat there are nprocesses, so therecursiveargument
can hold at most ntimes. The n+ 1thtime, adouble-collect must have been successful.
See Figure 12.32(b). Note that between the two double-collect s ofPithat are shown, there
may be up to n−2other unsuccessful double-collect s ofPi. Each of these (n−2)other
double-collect scorresponds tosome Pkk∝\⌉}atio\slash=i,j, having‘changed’once.
The linearization of the ScanandUpdateoperations follows in a straightforward manner. For
example, nonoverlapping operations get linearized in the o rder of their occurrence. An operation
byPithat borrowsasnapshotfrom Pkgets linearized after Pk.
Complexity: The space complexity is O(n)integers. The shared space is O(n2)corresponding
to each of the nregisters of size O(n)each. The time complexity is O(n2). This is because the
main Scan loop has a complexity of O(n)and the loop may be executed at most (n+ 1)times –
then+ 1-thtime,at leastoneprocess Pkmusthavecaused Pi’slocalchanged [k]toreach avalue
oftwo,triggeringan end totheloop(lines(2k-2l)).
12.7 ChapterSummary
Distributed shared memory (DSM) is an abstraction whereby d istributed programs can communi-
cate with memory operations (Read and Write) as opposed to us ing message-passing. The main
motivation is to simplify the burden on the programmers. The chapter surveyed this and other
motivatingfactors for DSMs, as well as provided different w ays to classify DSMs. The DSM has
to be implemented by the middleware layer. Furthermore, in t he face of concurrent operations
on the shared variables, the expected behaviour seen by the p rogrammers should be well-deﬁned.
The chapter examined the following consistency models – lin earizability, sequential consistency,
causalconsistency,pipelinedRAM(PRAM),andslowmemory. Eachmodelisacontractbetween
theprogrammerandthesystemproviderbecausetheprograml ogicmustadheretotheconsistency
modelbeingprovidedbythemiddleware.
The chapter then examined the fundamental problem of mutal e xclusion. The well-known
Bakery algorithm was studied ﬁrst. Next, Lamport’s algorit hm for fast mutual exclusion – which
gives anO(1)complexity when there are no contentions – was studied. Mutu al exclusion using
hardware instructions– Test&Set andSwap– was then examined. Such hardware instructionscan
438
(shared variables)
MRSW atomic register of type ∝a\}⌊ra⌋k⌉tl⌉{tdata,seq _no,old_snapshot∝a\}⌊ra⌋k⌉tri}ht,where data,seq _noare of type integer,
andold_snapshot [1... n]isarray ofinteger :R1... R n;
(local variables)
array ofint :changed [1... n];
array oftype∝a\}⌊ra⌋k⌉tl⌉{tdata,seq _no,old_snapshot∝a\}⌊ra⌋k⌉tri}ht:v1[1... n],v2[1... n],v[1... n];
(1)Update i(x)
(1a)v[1... n]←−Scan i;
(1b)Ri←−(x,Ri.seq_no+ 1,v[1... n]).
(2)Scan i
(2a)forcount = 1tondo
(2b) changed [count]←−0;
(2c)while truedo
(2d) v1[1... n]←−collect ();
(2e) v2[1... n]←−collect ();
(2f) if(∀k,1≤k≤n)(v1[k].seq_no=v2[k].seq_no)then
(2g) return (v2[1].data,... ,v 2[n].data);
(2h) else
(2i) fork= 1tondo
(2j) ifv1[k].seq_no∝\⌉}atio\slash=v2[k].seq_nothen
(2k) changed [k]←−changed [k] + 1;
(2l) ifchanged [k] = 2then
(2m) return(v2[k].old_snapshot ).
Figure12.33: Wait-freeatomicsnapshotofashared MRSW obj ect.
perform a Readoperation and a Writeoperation atomically. Hence, they are powerful, are also
expensivetoimplementin amachine.
InthecontextofDSMmutualexclusion,andmoregenerally,D SMsynchronizationoperations,
fault-tolerance was then examined. The notion of wait freedom , which is the ability to complete
all the operations of a process, irrespective of the behavio r of other processes. This makes the
systemn−1fault tolerant. Next, wait-free register constructions we re considered. Registers can
be classiﬁed as being binary or multi-valued. An orthogonal classiﬁcation allows single-reader
or multiple reader, single-writer or multiple writer regis ters. Also orthogonally, registers cab be
safe,regular, oratomic. This allows 24 possible conﬁgurations. The chapter consid ered some
of these 24 possible wait-free constructions. The construc tions provide insight into how different
techniqescanbeusedintheDSMsetting. Lastly,wait-freea tomicsnapshotsofsharedobjectswas
considered. For an object, reading its value atomically in a wait-free manner (without locking)
givesa”instantaneous"snapshotofitsstate. Hence, thisi san importantproblemforDSMs.
439
12.8 BibliographicNotes
A good survey on distributed shared memory systems is given b y Protic, Tomasevic, and Miluti-
novic[25]. Thisincludes coverageofthevariousDSM system ssuchas Fireﬂy, Sequent, Alewife,
Dash, Butterﬂy,CM∗,Ivy, Mirage,Midway,Munin,Lindaand Orca.
ThesequentialconsistencymodelwasdeﬁnedbyLamport[16] . Thelinearizabilitymodelwas
formalized by Lamport [18] and developed by Herlihy and Wing [10]. The implementations of
linearizabilityandsequentialconsistencybasedonthebr oadcastprimitiveandassumingfullrepli-
cation are from Attiyaand Welch [5], whereas asimilarimple mentationofsequential consistency
is given by Bal, Kaashoek, and Tanenbaum [6]. The causal cons istency model was proposed by
[3]. The PRAM model was proposed by Liptonand Sandberg [22]. The slowmemory model was
proposed by Hutto and Ahamad [11]. Otherconsistencymodels such as weak consistency[8], re-
leaseconsistency[9],andentryconsistency[7]thatapply toselectedinstructionsinthecode,were
developedmainlyinthecomputerarchitectureresearch com munity,and are discussedin[2, 1].
The bakery algorithm for mutual exclusion was presented by L amport [21]. The fast mutual
exclusionalgorithmwas presented by Lamport[19]. Thetwo- processmutualexclusionalgorithm
was presented by Peterson [23]. Its modiﬁcation that is aske d as Exercise 11 is based on the
algorithmby Peterson and Fischer[24].
The notion of wait-freedom was proposed by Lamport [21] and d eveloped by Herlihy [12].
The deﬁnition and classiﬁcation of registers as safe, regul ar, and atomic were given by Lamport
[17, 18, 19]. Constructions 1 to 5 were proposed by Lamport [1 8]. Register Construction 6 was
proposed by Vidyasankar [26]. Register Construction 7 was p roposed by Vitanyi and Awerbuch
[27]. Register Construction 8 was proposed by Israeli and Li [13]. A construction of a MRMR
snapshot object using MRSW snapshot objects and MRMW regist ers was proposed by Anderson
[4].
12.9 ExerciseProblems
1. Why do the algorithms for sequential consistency (Sectio n 12.2.2) not require the Readop-
erationsto bebroadcast?
2. Giveaformalprooftojustifythecorrectnessofthealgor ithminFigure12.7thatimplements
sequentialconsistencyusinglocal Readoperations.
3. In the algorithm to implement sequential consistency usi ng localWriteoperations, as given
inFigure12.8,whyis asinglecounter countersufﬁcientforthealgorithm’scorrectness?
In other words, why is a separate counter counter xnot required to track the number of up-
datesissuedtoeachvariable x,wherea Readoperationon xgetsdelayedonlyif counter x>
0? If such a separate counter were used for every variable, wha t consistency model would
beimplemented?
440
4.•In Figure12.9(a), analyzewhethertheexecutionislineari zable.
•In Figure 12.9(b), what forms of memory consistency are sati sﬁed if the two Read
operationsof P4return7 ﬁrst and then4?
5. Give a detailed implementation of causal consistency, an d provide a correctness argument
foryourimplementation.
6. Give a detailed implementation of PRAM consistency, and p rovide a correctness argument
foryourimplementation.
7. Give a detailed implementation of slow memory, and provid e a correctness argument for
your implementation. Is the implementation less expensive than that of PRAM consistency
whichis astricterconsistencymodel?
8. Show thatConstructions1 and 2 (Figure 12.21)work for bin ary registersas well as integer-
valuedregisters.
9. Why are two passes needed by the reader in Construction 6, F igure 12.27, for a MRSW
atomicregister? Whydoes asingleright-to-leftpassnotsu fﬁce?
10. Assumethat the writer does a singlepass from left to righ t in Construction 6, Figure 12.27,
foraMRSWregister. Canthecodeforthereadersbemodiﬁedto deviseacorrectalgorithm?
Justifyyouranswer.
11. Peterson’smutualexclusionalgortihmfortwoprocesse s isshowninFigure12.34.
(a) Show thatitsatisﬁes mutualexclusion,progress,and bo undedwaiting.
(b) Use this algorithm as a building block to construct a hier archical mutual exclusion
algorithm for an arbitrary number of processes. (Hint: use a logarithmic number of
steps inthehierarchy.)
12. Determine the average case time complexity of the wait-f ree atomic snapshot of a shared
object,givenin Figure12.33.
441
(shared variables)
boolean:turn←−false; // shared register initialized
array ofboolean :want[0,1];
repeat
(1)Piexecutes the following for the entrysection :
(1a)wanting [i]←−true;
(1b)turn←−1−i;
(1c)while wanting [1−i]andturn= 1−ido
(1d) no-op;
(2)Piexecutes the critical section (CS) after theentry section
(3)Piexecutes the following exit section after theCS:
(3a)wanting [i]←−false;
(4)Piexecutes the remainder section after theexit section
untilfalse;
Figure 12.34: Peterson’s mutual exclusion for two processe sPi= 0,1. Modulo=2 artithmatic is
used.
442
Bibliography
[1] S. Adve, K. Gharachorloo, Shared memory consistency mod els: A tutorial, IEEE Computer
Magazine29(12): 66-76, 1996.
[2] S. Adve, M. Hill, A uniﬁed formalization of four shared-m emory models, IEEE Transactions
onParallel and DistributedSystems4(6): 613-624,1993.
[3] M. Ahamad, G. Neiger, J. Burns, P. Kohli, P. Hutto, Causal memory: Deﬁnitions, implemen-
tation,andprogramming,DistributedComputing,9(1): 37- 49,1995.
[4] J. Anderson,Multi-writercompositeregisters,Distri butedComputing,7(4): 175-196,1994.
[5] H.Attiya,J.Welch,Sequentialconsistencyversusline arizability,ACMTransactionsonCom-
puterSystems,12(2): 91-122,1994.
[6] H.Bal,F.Kaashoek,A.Tanenbaum,Orca: Alanguageforpa rallelprogrammingofdistributed
systems,IEEE Transactionson Software Engineering,18(3) : 180-205,1992.
[7] B.Bershad,M.Zekauskas,W.Sawdon,TheMidwaydistribu tedsharedmemorysystem,CMU
Technical Report CMU-CS-93-119. (Alsoin Proceedings ofCO MPCON 1993.)
[8] M. Dubois, C. Scheurich, Memory access dependencies in s hared-memory multiprocessors,
IEEE Transactionson SoftwareEngineering,16(6): 660-673 ,1990.
[9] K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gu pta, and J. L. Hennessy, Memory
consistencyandeventorderinginscalableshared-memorym ultiprocessors,Proceedingsofthe
Seventeenth International Symposium on Computer Architec ture, pages 15–26, Seattle, WA,
May1990.
[10] M. Herlihy, J. Wing, Linearizability: A correctness co ndition for concurrent objects, ACM
Transactionson ProgrammingLanguagesand Systems,12(3): 463-492,1990.
[11] P. Hutto, M. Ahamad, Slow memory: Weakening consistenc y to enchance oncurrency in
distributed shared memories, Proc. IEEE International Con ference on Distributed Computing
Systems,302-311,1990.
[12] M. Herlihy, Wait-free synchronization, ACM Transacti ons on Programming Languages and
Systems,13(1): 124-149,1991.
443
[13] A.Israeli, M. Li,Bounded timestamps,DistributedCom puting,6(4): 205-209,1993.
[14] L.Lamport,AnewsolutionofDijkstra’sconcurrentpro grammingproblem,Communications
oftheACM, 17(8): 453-455,1974.
[15] L. Lamport, Proving the correctness of multiprocess pr ograms, IEEE Transactions on Soft-
wareEngineering,3(2): 125-143,1977.
[16] L. Lamport, How to make a multiprocessor that correctly executes multiprocess programs,
IEEE Transactionson Computers,28(9): 690-691,1979.
[17] L. Lamport, On interprocess communication, Part I: Bas ic formalism, Distributed Comput-
ing,1(2): 77-85,1986.
[18] L. Lamport, On interprocess communication, Part II: Al gorithms, Distributed Computing,
1(2): 86-101, 1986.
[19] L. Lamport, The mutual exclusion problem, Part II: Stat ement and solutions, Journal of the
ACM, 33(2): 327-348,1986.
[20] L. Lamport, A fast mutual exclusion algorithm, ACM Tran sactions on Computer Systems,
5(1): 1-11, 1987.
[21] L.Lamport,Concurrentreadingandwriting,Communica tionsoftheACM,20(11): 806-811,
1977.
[22] R.Lipton,J.Sandberg,PRAM:Ascalablesharedmemory, TechnicalReportCS-TR-180-88,
Princeton University,DepartmentofComputerScience, Sep tember1988.
[23] G.L. Peterson, Myths about the Mutual exclision proble m, Information Processing Letters,
12: 115-116,1981.
[24] G.L. Peterson, M. Fischer, Economical solutions for th e mutual exclusion problem in a dis-
tributedsystem,Proceedings 9thACM Symposiumon Theory of Computing,91-97,1977.
[25] J.Protic,M.Tomasevic,V.Milutinovic,DistributedS haredMemory: ConceptsandSystems,
4(2): 63-79, IEEEConcurrency, ComputerSociety Press, 199 6.
[26] K. Vidyasankar, Converting Lamport’s regular registe r to atomic register, Information Pro-
cessingLetters, 28: 287-290,1988.
[27] P. Vitanyi, B. Awerbuch, Atomic shared register access byu asynchronous hardware, Pro-
ceedings27thIEEE Symposiumon FoundationsofComputerSci ence, pp.233-243,1986.
444
Chapter13
Checkpointing andRollback Recovery
13.1 Introduction
Distributed systems today are ubiquitous and enable many ap plications, including client-server
systems, transaction processing, World Wide Web, and scien tiﬁc computing, among many others.
Distributedsystemsarenotfault-tolerantandthevastcom putingpotentialofthesesystemsisoften
hampered by their susceptibility to failures. Many techniq ues have been developed to add relia-
bility and high availability to distributed systems. These techniques include transactions, group
communication, and rollback recovery. These techniques ha ve different tradeoffs and focus. This
Chapter covers therollback recovery protocols which resto re thesystemback to a consistentstate
aftera failure.
Rollbackrecoverytreatsadistributedsystemapplication asacollectionofprocessesthatcom-
municate over a network. It achieves fault tolerance by peri odically saving the state of a process
during the failure-free execution, and restarting from a sa ved state upon a failure to reduce the
amount of lost work. The saved state is called a checkpoint , and the procedure of restarting from
previouslycheckpointedstateiscalled rollbackrecovery. Acheckpointcanbesavedoneitherthe
stablestorageorthevolatilestoragedependingonthefail urescenarios tobetolerated.
Indistributedsystems,rollbackrecoveryiscomplicatedb ecausemessagesinduceinter-process
dependencies during failure-free operation. Upon a failur e of one or more processes in a system,
these dependencies may force some of the processes that did n ot fail to roll back, creating what
is commonlycalled a rollbackpropagation . To see whyrollback propagationoccurs, considerthe
situation where the sender of a message mrolls back to a state that precedes the sending of m.
The receiver of mmust also roll back to a state that precedes m’s receipt; otherwise, the states of
the two processes would be inconsistent because they would show that message mwas received
withoutbeingsent,whichisimpossibleinanycorrectfailu re-freeexecution. Thisphenomenonof
cascadedrollbackiscalledthedominoeffect. Insomesitua tions,rollbackpropagationmayextend
back totheinitialstateofthecomputation,losingall thew ork performed beforethefailure.
In a distributed system, if each participating process take s its checkpoints independently, then
the system is susceptible to the domino effect. This approac h is called independent oruncoor-
dinated checkpointing. It is obviously desirable to avoid the domino effect and ther efore several
445
P3m1
m2P1
P2m0
m3m4Input message Output message
Distributed systemOutside world
Figure13.1: An exampleofa distributedsystemwiththreepr ocesses.
techniques have been developed to prevent it. One such techn ique iscoordinated checkpointing
where processes coordinate their checkpoints to form a syst em-wide consistent state. In case of a
process failure, the system state can be restrored such a con sistent set of checkpoints, preventing
the rollback propagation. Alternatively, communication-induced checkpointing forces each pro-
cesstotakecheckpointsbasedoninformationpiggybackedo ntheapplicationmessagesitreceives
fromotherprocesses. Checkpointsaretakensuchthatasyst em-wideconsistentstatealwaysexists
on stablestorage,thereby avoidingthedominoeffect.
The approaches discussed so far implement checkpoint-based rollback recovery, which relies
onlyoncheckpointstoachievefault-tolerance. Log-based rollbackrecoverycombinescheckpoint-
ing with logging of nondeterministicevents. Log-based rol lback recovery relies on the piecewise
deterministic (PWD) assumption, which postulates that all nondeterministic e vents that a process
executescan beidentiﬁedand that theinformationnecessar y toreplay each eventduringrecovery
can be logged in the event’s determinant . By logging and replaying the nondeterministic events
in their exact original order, a process can deterministica lly recreate its pre-failure state even if
this state has not been checkpointed. Log-based rollback re covery in general enables a system to
recover beyond the mostrecent set of consistentcheckpoint s. It is therefore particularly attractive
for applicationsthat frequently interact with the outsideworld , which consistsofinputand output
devicesthat cannotrollback.
13.2 BackgroundandDeﬁnitions
13.2.1 System Model
A distributed system consists of a ﬁxed number of processes P 1, P2,...,PNthat communicate only
through messages. Processes cooperate to execute a distrib uted application and interact with the
outsideworldbyreceivingandsendinginputandoutputmess ages,respectively. Figure13.1shows
asystemconsistingofthreeprocessesand interactionswit htheoutsideworld.
Rollback-recovery protocols generally make assumptions a bout the reliability of the inter-
446
process communication. Someprotocolsassumethatthecomm unicationsubsystemdeliversmes-
sages reliably,in First-In-First-Out(FIFO) order, while otherprotocolsassumethat thecommuni-
cationsubsystemcan lose,duplicate,orreordermessages. Thechoicebetweenthesetwoassump-
tionsusuallyaffects thecomplexityofcheckpointingand f ailurerecovery.
Agenericcorrectnessconditionforrollback-recoverycan bedeﬁnedasfollows[35]: “Asystem
recoverscorrectlyifitsinternalstateisconsistentwith theobservablebehaviorofthesystembefore
the failure”. Rollback-recovery protocols therefore must maintain information about the internal
interactionsamongprocesses andalso theexternal interac tionswiththeoutsideworld.
13.2.2 A LocalCheckpoint
In distributed systems, all processes save their local stat es at certain instants of time. This saved
stateisknownasalocal checkpoint. A localcheckpointisas napshotofthestateoftheprocessat
agiveninstanceandtheeventofrecordingthestateofaproc essiscalledlocalcheckpointing. The
contentsofacheckpointdependupontheapplicationcontex tandthecheckpointingmethodbeing
used.
Dependinguponthecheckpointingmethodused,aprocessmay keepseverallocalcheckpoints
orjustasinglecheckpointatanytime. Weassumethataproce ssstoresalllocalcheckpointsonthe
stablestoragesothat theyare availableeven iftheprocess crashes. We also assumethat aprocess
is able to roll back to any of its existing local checkpoints a nd thus restore to and restart from the
correspondingstate.
LetCi,kdenotethekthlocalcheckpointatprocess Pi. Generally,itisassumedthataprocess Pi
takes a checkpoint Ci,0before it starts execution. A local checkpoint is shown in th e process-line
by thesymbol“|”.
13.2.3 Consistent SystemStates
A global state of a distributed system is a collection of the i ndividual states of all participating
processes and the states of the communication channels. Int uitively, a consistent global state is
onethat may occurduring a failure-free executionof a distr ibutedcomputation. Moreprecisely, a
consistentsystemstate isoneinwhichaprocess’sstatereﬂectsamessagereceipt,t henthestateof
the corresponding sender must reﬂect the sending of that mes sage [9]. For instance, Figure 13.2
showstwoexamplesofglobalstates. ThestateinFigure13.2 (a)isconsistentandthestateinFigure
13.2(b) is inconsistent. Note that the consistent state in F igure 13.2(a) shows message m1to have
been sent but not yet received, but that is alright. The state in Figure 13.2(a) is consistent because
it represents a situation in which every message that has bee n received, there is a corresponding
messagesendevent. ThestateinFigure13.2(b)isinconsist entbecauseprocess P2isshowntohave
receivedm2butthestateofprocess P1does notreﬂect tohavesentit. Such astateis impossiblein
any failure-free, correct computation. Inconsistent stat es occur because of failures. For instance,
the situation shown in Figure 13.2(b) may occur if process P1fails after sending message m2to
processP2and thenrestarts at thestateshownin theFigure13.2(b).
447
P0
P1
P2m1
m2m1
m2P0
P1
P2
(a)(b)Consistent state Inconsistent state
Figure13.2: Examplesofaconsistentandan inconsistentst ates.
Thus, a local checkpoint is a snapshot of a local state of a pro cess and a global checkpoint
is a set of local checkpoints, one from each process. A consis tent global checkpoint is a global
checkpoint such that no message is sent by a process after its local checkpoint that is received
by another process before its local checkpoint. The consist ency of global checkpoints strongly
dependsontheﬂow ofmessagesexchangedbyprocesses andan a rbitrarysetoflocalcheckpoints
at processes maynotform aconsistentglobalcheckpoint.
Fundamentalgoalofanyrollback-recoveryprotocolistobr ingthesystemto aconsistentstate
after a failure. The reconstructed consistent state is not n ecessarily one that occurred before the
failure. Itissufﬁcientthatthereconstructedstatebeone thatcouldhaveoccurredbeforethefailure
in a failure-free execution, provided that it is consistent with the interactions that the system had
withtheoutsideworld.
13.2.4 Interactions with the Outside World
A distributedapplication often interacts with the outside world to receiveinput data or deliverthe
outcomeofacomputation. Ifafailureoccurs, theoutsidewo rld cannotbeexpectedtoarollback.
For example, a printer cannot roll back the effects of printi ng a character, and an automatic teller
machinecannot recoverthemoneythatitdispensedtoacusto mer. To simplifythepresentationof
how rollback-recovery protocols interact with the outside world, we model the latter as a special
process that interacts with the rest of the system through me ssage passing. We call this special
process the “outside world process” ( OWP). It is therefore necessary that the outside world see
a consistent behavior of the system despite failures. Thus, before sending output to the OWP,
the system must ensure that the state from which the output is sent will be recovered despite any
future failure. This is commonly called the output commit pr oblem. Similarly, input messages
thatasystemreceivesfromtheOWPmaynotbereproducibledu ringrecovery,becauseitmaynot
be possible for the outside world to regenerate them. Thus, r ecovery protocols must arrange to
save these input messages so that they can be retrieved when n eeded for execution replay after a
448
m1m2
m5
m3
m4P1
P2
P3
P40000
32
3214
44 6
6
65 788
89X
recovery linefailure
Figure13.3: Different typesofMessages
failure. A common approach is to save each input message on th e stable storage before allowing
theapplicationprogram toprocess it.
An interactionwith theoutsideworld to delivertheoutcome of acomputationis shownonthe
process-lineby thesymbol“ ||”.
13.2.5 Different Typesof Messages
A procees failure and subsequent recovery may leave message s that were perfectly received (and
processed)beforethefailure,inabnormalstates. Thisisb ecausearollbackofprocessesforrecov-
ery may haveto rollbackthesendand receiveoperationsofse veralmessages.
In this section, we identify several types such messages usi ng the example shown in Figure
13.3. Figure 13.3 shows an example consisting of four proces ses. Process P1fails at the point
indicatedandthewholesystemrecoverstothestateindicat edbytherecoveryline;thatistoglobal
state{C1,8,C2,9,C3,8,C4,8}.
In-TransitMessages
InFigure13.3,theglobalstate{ C1,8,C2,9,C3,8,C4,8}showsthatmessage m1hasbeensentbut
not yet received. We call such a message an in-transit message. Message m2is also an in-transit
message.
Whenin-transitmessagesarepartofaglobalsystemstate,t hesemessagesdonotcauseanyin-
consistency. However, depending on whether the system mode l assumes reliable communication
channels, rollback-recovery protocols may have to guarant ee the delivery of in-transit messages
when failures occur. For reliable communication channels, a consistent state must include in-
transit messages because they will always be delivered to th eir destinationsin any legal execution
449
of thesystem. On theother hand, if a systemmodel assumes los sycommunicationchannels, then
in-transitmessagescan beomittedfrom systemstate.
Lostmessages
Messages whose send is not undone but receive is undone due to rollback are called lost mes-
sages. Thistypeofmessagesoccurswhentheprocessrollsba cktoacheckpointpriortoreception
of the message while the sender does not rollback beyond the s end operation of the message. In
theFigure13.3,messagem 1isa lostmessage.
Delayedmessages
Messages whose receive are not recorded because the receivi ng process was either down or
the message arrived after the rollback of the receiving proc ess, are called delayed messages. For
example,messagem 2and m 5inFigure13.3are delayed messages.
Orphan messages
Messageswithreceiverecordedbutmessagesendnotrecorde darecalledtheorphanmessages.
For example, a rollback might have undone the send of such mes sages, leaving the receive event
intact at thereceiving process. Orphan messages do not aris eifprocesses rollback to a consistent
globalstate.
Duplicatemessages
Duplicatemessagesariseduetomessageloggingandreplayi ngduringaprocessrecovery. For
example, in Figure 13.3, message m 4was sent and received before the rollback. However, due to
the rollback of process P 4to C4,8and process P 3to C3,8, both send and receipt of message m 4are
undone. When process P 3restarts from C 3,8, it will resend the message m 4. Therefore, P 4should
notreplay themessagem 4from itslog. If P 4replays themessagem 4, then messagem 4is called a
duplicatemessage.
Message m 5is an excellent example of a duplicate message. No matter wha t, the receiver of
m5willreceiveaduplicatem 5message.
13.3 Issuesin FailureRecovery
In a failure recovery, we must not only restore the system to a consistent state, but also appropri-
ately handlemessagesthat areleft inabnormalstateduetot hefailureand recovery[33].
We now describe the issues involved in a failure recovery wit h the help of a distributed com-
putation shown in the Figure 13.4. The computation comprise s of three processes P i, Pjand P k,
connected through a communication network. The processes c ommunicate solely by exchanging
messages over fault free, FIFO communication channels. Pro cesses P i, Pj, and P khave taken
checkpoints{C i,0,Ci,1},{C j,0,Cj,1, Cj,2},and{C k,0, Ck,1},respectively,and theseprocesseshave
exchangedmessages Ato J asshownintheFigure13.4.
450
iP
Pj
PkCi,1
Cj,1Cj,0Ci,0
Ck,0
Ck,1Ck,2Cj,2Failure
A B
F
E CI
GD
JH
Figure13.4: IllustrationofIssues inFailureRecovery
Suppose process P ifails at theinstanceindicated in theFigure. All theconten ts in thevolatile
memory of P iis lost and after P irecovers from the failure, the system needs to be restored to a
consistent global state from where the processes resume the ir execution. The process P i’s state
is restored to a valid state by rolling it back to its latest ch eckpoint C i,1. To restore the system
to a consistent state process P jrolls back to checkpoint C j,1because roll back of process Pito
checkpoint C i,1created an orphan message H (the receive event of H is recorde d at process P j
while the send event of H has been undone at process P i). Note that process P jdoes not roll
back to checkpoint C j,2but to checkpoint C j,1because rolling back to checkpoint C j,2does not
eliminate the orphan message H. Even this resulting state is not a consistent global state as an
orphan message I is created due to the roll back of process P jto checkpoint C j,1. To eliminate
thisorphanmessageprocessP krollsbacktocheckpointC k,1. Therestoredglobalstate{ Ci,1,Ci,1,
Ci,1} is a consistent state as it is free from orphan messages. Alt hough the system state has been
restoredtoaconsistentstate,severalmessagesareleftin anerroneousstatewhichmustbehandled
correctly.
Messages A, B, D, G, H, I, and J had been received at the points i ndicated in the Figure and
messages C, E and F were in transit when the failure occurred. Restoration of system state to
checkpoints{C i,1,Cj,1,Ck,1}automaticallyhandlesmessagesA,B,andJbecausesendand receive
events of messages A, B and J have been recorded and both the ev ents for G, H, and I have been
completely undone. These messages cause no problem and we ca ll messages A, B and J normal
messagesand messagesG, H andI asvanishedmessages[33].
MessagesC, D,E,andFarepotentiallyproblematic. Message Cisintransitduringthefailure
and it is a delayed message. The delayed message C has several possibilities: C might arrive at
process P ibefore it recovers, it might arrive while P iis recovering, or it might arrive after P ihas
completedrecovery. Each ofthesecases mustbedealt withco rrectly.
Message D is a lost message since the send event for D is record ed in the restored state for
processP jbutthereceiveeventhasbeenundoneatprocessP i. ProcessP jwillnotresendDwithout
451
additional mechanism, since the send D at P joccurred before the checkpoint and communication
systemsuccessfullydeliveredD.
Messages E and F are delayed orphan messages and pose perhaps the most serious problem
of all the messages. When messages E and F arrive at their resp ective destinations, they must be
discarded since their send events have been undone. Process es, after resuming execution from
their checkpoints, will generate both of these messages and recovery techniques must be able to
distinguishbetween messageslikeCand thoselikeE and F.
Lost messages like D can be handled by having processes keep a message log of all the sent
messages. Sowhenaprocessrestorestoacheckpoint,itrepl aysthemessagesfromitslogtohandle
the lost message problem. However, message logging and mess age replaying during recovery
can result in duplicate messages. In the example shown in the Figure, when process P jreplays
messagesfromitslog,itwillregeneratemessageJ.Process Pkwhichhasalreadyreceivedmessage
Jwillreceiveitagain,thereby,causinginconsistencyint hesystemstate. Therefore,theseduplicate
messagesmustbehandledproperly.
Overlapping failures further complicate the recovery proc ess. A process P jthat begins roll-
back/recovery in response to the failure of a process P ican itself fail and develop amnesia with
respect process P i’s failure; that is, process P jcan act in a fashion that exhibits ignorance of pro-
cess P i’s failure. If overlapping failures are to be tolerated, a me chanism must be introduced to
deal withamnesiaand theresultinginconsistencies.
13.4 CheckpointBasedRecovery
Inthecheckpointbasedrecoveryapproach,thestateofeach processandthecommunicationchan-
nelischeckpointedfrequentlysothatuponafailure,thesy stemisrestoredtoagloballyconsistent
setofcheckpoints. ItdoesnotrelyonthePWDassumption,an dsodoesnotneedtodetect,log,or
replay nondeterministicevents. Checkpoint-based protoc ols are therefore less restrictiveand sim-
plertoimplementthanlog-basedrollbackrecovery. Howeve r,checkpoint-basedrollbackrecovery
does not guarantee that pre-failure executioncan be determ inisticallyregenerated after a rollback.
Therefore, checkpoint-based rollback recovery may not be s uitable for applications that require
frequent interactions with the outside world. Checkpoint b ased rollback-recovery techniques can
be classiﬁed into three categories :uncoordinated checkpointing ,coordinated checkpointing , and
communication-inducedcheckpointing [13].
13.4.1 Uncoordinated Checkpointing
Inuncoordinatedcheckpointing,eachprocesshasautonomy indecidingwhentotakecheckpoints.
This eliminates synchronization overhead as there is no nee d for coordination between processes
and it allows processes to take checkpoints when it is most co nvenient or efﬁcient. The main ad-
vantage is the lower runtime overhead during normal executi on because no coordination among
processes is necessary. Autonomy in taking checkpoints als o allows each process to select ap-
452
P
Pijc
cj,y
c cc c c cj,0 j,1 j,y−1
i,0 i,1 i,x−1 i,xcI
Ii,xm(i,x)j,y
Figure13.5: CheckpointIndexand checkpointInterval
propriate checkpoints positions. However, uncoordinated checkpointing has several shortcomings
[13].
First, there is the possibilityof the domino effect during a recovery, which may cause the loss
of a large amount of useful work. Second, recovery from a fail ure is slow because processes need
toiteratetoﬁndaconsistentsetofcheckpoints. Sincenoco ordinationisdoneatthetimeofcheck-
pointistaken,checkpointstakenbyaprocessmaybe uselesscheckpoints. (Auselesscheckpointis
neverapartofanyglobalconsistentstate). Uselesscheckp ointsareundesirablebecausetheyincur
overheadanddonotcontributetoadvancingtherecoverylin e. Third,uncoordinatedcheckpointing
forces each process tomaintainmultiplecheckpoints,andt o periodicallyinvokeagarbagecollec-
tion algorithm to reclaim the checkpoints that are no longer required. Fourth, it is not suitable for
applications with frequent output commits because these re quire global coordination to compute
therecoveryline,negatingmuch oftheadvantageofautonom y.
As each process takes checkpoints independently, we need to determine a consistent global
checkpoint to rollback to, when a failure occurs. In order to determine a consistent global check-
point during recovery, the processes record the dependenci es among their checkpoints caused by
message exchange during failure-free operation. The follo wing direct dependency tracking tech-
niqueis commonlyusedin uncoordinatedcheckpointing.
Letci,xbe thexthcheckpoint of process Pi,where i is the process id and x is the checkpoint
index (we assume each process P istarts its execution with an initial checkpoint c i,0). LetIi,x
denote the checkpoint interval or simply intervalbetween checkpoints ci,x−1andci,x. Consider
the example shown in Figure 13.5. When process Piat interval Ii,xsends a message mtoPj, it
piggybacks thepair ( i,x) onm. WhenPjreceivesmduring interval Ij,y, it records the dependency
fromIi,xtoIj,y, which islatersavedontostablestoragewhen Pjtakes checkpoint cj,y.
When a failure occurs, the recovering process initiates rol lback by broadcasting a dependency
requestmessage to collect all the dependency information maintain ed by each process. When a
process receives this message, it stops its execution and re plies with the dependency information
savedonthestablestorageaswellaswiththedependencyinf ormation,ifany,whichisassociated
453
with its current state. The initiator then calculates the re covery line based on the global depen-
dency information and broadcasts a rollback request message containing the recovery line. Upon
receiving this message, a process whosecurrent statebelon gs to the recovery linesimply resumes
execution;otherwise,itrollsback to an earliercheckpoin tas indicatedby therecovery line.
13.4.2 Coordinated Checkpointing
In coordinated checkpointing, processes orchestrate thei r checkpointing activities so that all local
checkpoints form a consistent global state [13]. Coordinat ed checkpointing simpliﬁes recovery
andisnotsusceptibletothedominoeffect,sinceeveryproc essalwaysrestartsfromitsmostrecent
checkpoint. Also, coordinated checkpointing requires eac h process to maintain only one check-
point on the stable storage, reducing the storage overhead a nd eliminating the need for garbage
collection. The main disadvantage of this method is that lar ge latency is involved in committing
output, as a global checkpoint is needed before a message is s ent to OWP. Also, delays and over-
head are involvedeverytimeanew globalcheckpointistaken .
If perfectly synchronized clocks were availableat process es, the followingsimplemethod can
be used for checkpointing: all processes agree at what insta ntsof timethey will take checkpoints,
andtheclocksatprocessestriggerthelocalcheckpointing actionsatallprocesses. Sinceperfectly
synchronized clocks are not available, the following appro aches are used to guarantee checkpoint
consistency: either the sending of messages is blocked for t he duration of the protocol, or check-
pointindicesarepiggybackedto avoidblocking.
Blocking Coordinated Checkpointing
A straightforward approach to coordinated checkpointing i s to block communications while the
checkpointingprotocol executes. After a process takes a lo cal checkpoint, to preventorphan mes-
sages,itremainsblockeduntiltheentirecheckpointingac tivityiscomplete. Thecoordinatortakes
a checkpoint and broadcasts a request messageto all process es, asking them to take a checkpoint.
When a process receives this message, it stops its execution , ﬂushes all the communication chan-
nels,takesa tentativecheckpoint,andsendsan acknowledgmentmessageback tothe coordinator.
After the coordinator receives acknowledgments from all pr ocesses, it broadcasts a commit mes-
sagethat completesthetwo-phasecheckpointingprotocol. Afterreceivingthecommitmessage, a
processremovestheoldpermanentcheckpointandatomicall ymakesthe tentativecheckpointper-
manentandthenresumesitsexecutionandexchangeofmessag eswithotherprocesses. Aproblem
withthisapproachisthatthecomputationisblockedduring thecheckpointingand therefore,non-
blockingcheckpointingschemesare preferable.
Non-blocking Checkpoint Coordination
In this approach the processes need not stop their execution while taking checkpoints. A funda-
mental problem in coordinated checkpointing is to prevent a process from receiving application
messages that could make the checkpoint inconsistent. Cons ider the example in Figure 13.6(a)
454
checkpoint request
P
P0
1mc0,x
c1,xInitiator
checkpoint request
P
P0
1c0,xInitiator
m
c1,x
(a) (b)
Figure13.6: Non-blockingcoordinatedcheckpointing: (a) checkpointinconsistency;(b)asolution
withFIFO Channels.
[13]: message mis sent by P0afterreceiving a checkpoint request from the checkpoint coordin a-
tor. Assume mreachesP1beforethe checkpoint request. This situation results in an incons istent
checkpoint since checkpoint c1,xshows the receipt of message mfromP0, while checkpoint c0,x
does notshow mbeing sentfrom P0.
If channels are FIFO, thisproblem can beavoided by precedin g theﬁrst post-checkpointmes-
sage on each channel by a checkpoint request, forcing each pr ocess to take a checkpoint before
receivingtheﬁrst post-checkpointmessage,as illustrate din Figure13.6(b). An exampleofanon-
blockingcheckpointcoordinationprotocolusingthisidea isthesnapshotalgorithmofChandyand
Lamport[9]inwhich markersplaytheroleofthecheckpoint-requestmessages. Inthisal gorithm,
theinitiatortakesacheckpointandsendsamarker(acheckp ointrequest)onalloutgoingchannels.
Eachprocesstakesacheckpointuponreceivingtheﬁrstmark erandsendsthemarkeronalloutgo-
ing channels before sending any application message. The pr otocol works assuming the channels
are reliableand FIFO.
If the channels are non-FIFO, the following two approaches c an be used: ﬁrst, the marker
can be piggybacked on every post-checkpoint message. When a process receives an application
messagewithamarker,ittreatsitasifithasreceivedamark ermessage,followedbytheapplication
message. Alternatively,checkpointindicescanservethes ameroleasmarkers,whereacheckpoint
is triggered when the receiver’s local checkpoint index is l ower than the piggybacked checkpoint
index.
Coordinated checkpointing requires all processes to parti cipate in every checkpoint. This re-
quirement generates valid concerns about its scalability. It is desirable to reduce the number of
processesinvolvedinacoordinatedcheckpointingsession . Thiscan bedonesinceonlythosepro-
cesses that have communicated with the checkpoint initiato reither directly or indirectly since the
last checkpoint need to take new checkpoints. A two-phase pr otocol by koo and Toueg achieves
minimalcheckpointcoordination.
455
13.4.3 Impossibility ofMin ProcessNon-blocking Checkpoi nting
A min-process, non-blocking checkpointingalgorithm is on e that forces only a minimumnumber
ofprocessestotakeanewcheckpoint,andatthesametimeitd oesnotforceanyprocesstosuspend
its computation. Clearly, such checkpointing algorithms w ill be very attractive. Cao and Singhal
[7]showedthatitis impossible to designamin-process,non -blockingcheckpointingalgorithm.
Ofcourse,thefollowingtypeofmin-processcheckpointing algorithmsarepossible: Thealgo-
rithmconsistsoftwophases. Duringtheﬁrstphase,thechec kpointinitiatoridentiﬁesallprocesses
withwhich it has communicatedsincethelastcheckpoint and sends thema request. Upon receiv-
ing the request, each process in turn identiﬁes all processe s it has communicated with since the
last checkpoints and sends them a request, and so on, until no more processes can be identiﬁed.
During thesecond phase, all processes identiﬁed in theﬁrst phase takea checkpoint. The result is
aconsistentcheckpointthatinvolvesonlytheparticipati ngprocesses. In thisprotocol,after apro-
cesstakesacheckpoint,itcannotsendanymessageuntilthe secondphaseterminatessuccessfully,
althoughreceivingamessageafter thecheckpointhas been t aken isallowable.
Based on theconcept called ’Z-dependency’, Cao and Singhal provedthatthere does notexist
a non-blocking algorithm that allows a minimum number of pro cesses to take their checkpoints.
Here we give only a sketch of the proof and readers are referre d to the original source [7] for a
detailedproof.
Z-dependencyisdeﬁnedasfollows: ifaprocessP psendsamessagetoprocessP qduringitsith
checkpoint interval and process P qreceives themessage duringits jthcheckpoint interval, then P q
Z-dependsonP pduringP p’sithcheckpointintervalandP q’sjthcheckpointinterval,denotedbyP p
→ijPq. If P p→ijPqand P q→jkPr, then P rtransitively z-depends depends on P pduring P r’s kth
checkpointintervaland P p’sithcheckpointintervaland thisis denotedas P p∗→ikPr.
A min process algorithm is one that satisﬁes the following co ndition: when a process P pini-
tiates a new checkpoint and takes checkpoint C p,i, a process P qtakes a checkpoint C q,jassociated
withC p,iifand only ifP q∗→j−1i−1Pp. In a minprocess non-blockingalgorithm,process P piniti-
atesanewcheckpointandtakesacheckpointC p,iandifaprocessP rsendsamessagemtoP qafter
ittakesanewcheckpointassociatedwithC p,i,thenP qtakesacheckpointC q,ibeforeprocessingm
ifandonlyifP q∗→j−1i−1Pp. Accordingtominprocessdeﬁnition,P qtakes checkpointC q,jifand
onlyifP q∗→j−1i−1Ppbut P qshouldtakeC q,ibefore processingm. If ittakes C q,jafter processing
m, m becomes an orphan. Therefore, when a process receives a m essage m, it must know if the
initiatorof a new checkpoint transitivelyZ-depends on it d uring the previous checkpoint interval.
But it has been proved that there is not enough information at the receiver of a message to decide
whether the initiator of a new checkpoint transitively Z-de pends on the receiver. Therefore, no
min-processnon-blockingalgorithmexists.
13.4.4 Communication-Induced Checkpointing
Communication-induced checkpointing is another way to avoid the domino effect, while allowing
processes to take some of their checkpoints independently. Processes may be forced to take addi-
456
tionalcheckpoints(overandabovetheirautonomouscheckp oints)andthus,processindependence
is constrained to guarantee the eventual progress of the rec overy line. Communication induced
checkpointing reduces or completely eliminates the useles s checkpoints. In communication in-
duced checkpointing processes take two types of checkpoint s, namely, autonomous and forced
checkpoints. The checkpoints that a process takes independ ently are called localcheckpoints,
whilethosethataprocessisforcedtotakearecalled forcedcheckpoints. Communication-induced
checkpointingpiggybacksprotocol-relatedinformationo neachapplicationmessage. Thereceiver
ofeachapplicationmessageusesthepiggybackedinformati ontodetermineifithastotakeaforced
checkpoint to advance the global recovery line. The forced c heckpoint must be taken before the
application may process the contents of the message, possib ly incurring some latency and over-
head. It is therefore desirable in these systems to minimize the number of forced checkpoints. In
contrastwithcoordinated checkpointing,nospecial coord inationmessages areexchanged.
There are two types of communication-induced checkpointin g [13]: model-based checkpoint-
ing and index-based checkpointing. In model-based checkpointing , the system maintains check-
pointsandcommunicationstructuresthatpreventthedomin oeffectorachievesomeevenstronger
properties. In index-based coordination , the system uses an indexing scheme for the local and
forced checkpoints, such that the checkpoints of the same in dex at all processes form a consistent
state.
Model-based Checkpointing
Model-based checkpointing prevents patterns of communica tions and checkpoints that could re-
sult in inconsistent states among the existing checkpoints . A process detects the potential for
inconsistent checkpoints and independently forces local c heckpoints to prevent the formation of
undesirable patterns. A forced checkpoint is generally use d to prevent the undesirable patterns
from occurring. No control messages are exchanged among the processes during normal opera-
tion. All information necessary to execute the protocol is p iggybacked on application messages.
Thedecisiontotakeaforced checkpointisdonelocallyusin gtheinformationavailable.
There are severaldomino-effect-freecheckpoint and commu nicationmodels. The MRSmodel
avoids the domino effect by ensuring that within every check point interval all message-receiving
eventsprecede all message-sendingevents. This model can b emaintained by taking an additional
checkpoint before every message-receiving event that is no t separated from its previous message-
sending event by a checkpoint. Wu and Fuchs proposed another way to prevent the domino ef-
fect by avoiding rollback propagation completely by taking a checkpoint immediately after every
message-sendingevent. Recent workhas focusedonensuring thateverycheckpointcan belongto
aconsistentglobalcheckpointandtherefore isnotuseless .
Index-based Checkpointing
Index-based communication-induced checkpointing assign s monotonically increasing indexes to
checkpoints,suchthatthecheckpointshavingthesameinde xat differentprocessesformaconsis-
tent state. Inconsistency between checkpoints of the same i ndex can be avoided in a lazy fashion
457
0P
P1
P2m1m0
m4m3
m6m7 m5 m2
Figure13.7: Deterministicand NondeterministicEvents
if indexes are piggybacked on application messages to help r eceivers decide when they should
take a forced a checkpoint. For instance, the protocol by Bri atico et al. [5] forces a process to
takeacheckpointuponreceivingamessagewithapiggybacke dindexgreaterthanthelocalindex.
More sophisticated protocols piggyback more information o n application messages to minimize
thenumberofforced checkpoints.
13.5 Log-basedRollbackRecovery
A log-based rollback recovery makes use of deterministic an d nondeterministic events in a com-
putation. So ﬁrst wediscusstheseevents.
13.5.1 Deterministic andNondeterministic Events
Log-based rollback recovery exploits the fact that a proces s execution can be modeled as a se-
quenceofdeterministicstateintervals,eachstartingwit htheexecutionofanondeterministicevent.
Anondeterministiceventcanbethereceiptofamessagefrom anotherprocessoraneventinternal
to the process. Note that a message send event is nota nondeterministic event. For example, in
Figure13.7,theexecutionofprocess P0isasequenceoffourdeterministicintervals. Theﬁrstone
startswiththecreation oftheprocess,whiletheremaining threestartwiththereceipt ofmessages
m0,m3, andm7, respectively. Send eventofmessage m2is uniquelydeterminedby theinitialstate
ofP0and bythereceipt ofmessage m0, andis thereforenotanondeterministicevent.
Log-based rollback recovery assumes that all nondetermini stic events can be identiﬁed and
their corresponding determinants can be logged into the sta ble storage. During failure-free op-
eration, each process logs the determinants of all nondeter ministic events that it observes onto
the stable storage. Additionally, each process also takes c heckpoints to reduce the extent of roll-
back duringrecovery. Afterafailureoccurs,thefailedpro cesses recoverbyusingthecheckpoints
and logged determinants to replay the corresponding nondet erministic events precisely as they
458
occurred during the pre-failure execution. Because execut ion within each deterministic interval
depends only on the sequence of nondeterministic events tha t preceded the interval’s beginning,
the pre-failure execution of a failed process can be reconst ructed during recovery up to the ﬁrst
nondeterministiceventwhosedeterminantisnotlogged.
The No-Orphans ConsistencyCondition
Letebeanondeterministiceventthat occurs atprocess p. Wedeﬁnethefollowing[13]:
•Depend(e): the set of processes that are affected by a nondeterminist ic evente.This set
consistsof p,andanyprocesswhosestatedependsontheevent eaccordingtotheLamport’s
happenedbefore relation.
•Log(e): the set of processes that have logged a copy of e’s determinant in their volatile
memory.
•Stable(e): apredicatethat istrueif e’sdeterminantisloggedon thestablestorage.
Supposea set ofprocesses Ψcrashes. A process pinΨbecomesan orphan when pitselfdoes
not fail and p’s state depends on the execution of a nondeterministic even tewhose determinant
cannot be recovered from the stable storage or from the volat ile memory of a surviving process.
Formally,itcan bestatedas follows[13]:
∀e:¬Stable(e) :Depend(e)⊆Log(e)
This property is called the always-no-orphans condition [13]. It states that if any surviving
process depends on an event e, then either event eis logged on the stable storage, or the process
has a copy of thedeterminantof event e. If neitherconditionis true, then theprocess is an orphan
because it depends on an event ethat cannot begenerated during recovery sinceits determin ant is
lost.
Log-basedrollback-recoveryprotocolsguaranteethatupo nrecoveryofallfailedprocesses,the
systemdoesnotcontainanyorphanprocess,i.e.,aprocessw hosestatedependsonanondetermin-
istic event that cannot be reproduced during recovery. Log- based rollback-recovery protocols are
of three types: pessimistic logging, optimistic logging, a nd causal logging protocols. They differ
in their failure-free performance overhead, latency of out put commit, simplicity of recovery and
garbagecollection,and thepotentialfor rollingback surv ivingprocesses.
13.5.2 PessimisticLogging
Pessimistic logging protocols assume that a failure can occ ur after any nondeterministic event
in the computation. This assumption is “pessimistic” since in reality failures are rare. In their
most straightforward form, pessimisticprotocols log to th e stable storage the determinant of each
nondeterministicevent before the event affects the comput ation. Pessimisticprotocols implement
459
0P
P1
P2m0 m4 m1
m2 m3 m5m7
m6A
B
Cfailure
failureMaximum recoverable state
Figure13.8: Pessimisticlogging.
the following property, often referred to as synchronous logging , which is a stronger than the
always-no-orphanscondition[13].
∀e:¬Stable(e) :|Depend(e)|= 0
That is, if an event has not been logged on the stable storage, then no process can depend
on it. In addition to logging determinants, processes also t ake periodic checkpoints to minimize
the amount of work that has to be repeated during recovery. Wh en a process fails, the process
is restarted from the most recent checkpoint and the logged d eterminants are used to recreate the
pre-failure execution. Considerthe examplein Figure 13.8 . During failure-free operation the logs
ofprocesses P0,P1andP2containthedeterminantsneededtoreplaymessages m0,m4,m7,m1,m3,
m6andm2,m5, respectively. Suppose processes P1andP2fail as shown, restart from checkpoints
BandC, and roll forward using their determinant logs to deliver ag ain the same sequence of
messages as in the pre-failure execution. This guarantees t hatP1andP2will repeat exactly their
pre-failure execution and re-send the same messages. Hence , once the recovery is complete, both
processes will be consistent with the state of P0that includes the receipt of message m7fromP1.
In apessimisticloggingsystem,theobservablestateofeac h process isalways recoverable.
Thepricepaidfortheseadvantagesisaperformancepenalty incurredbysynchronouslogging.
Synchronous logging can potentially result in a high perfor mance overhead. Implementations of
pessimistic logging must use special techniques to reduce t he effects of synchronous logging on
the performance. This overhead can be lowered using special hardware. For example, fast non-
volatile semiconductor memory can be used to implement the s table storage. Another approach
is to limit the number of failures that can be tolerated. The o verhead of pessimistic logging is
reduced by delivering a message or executing an event and def erring its logging until the process
communicateswithanotherprocess orwiththeoutsideworld .
Synchronous logging in such an implementation is orders of m agnitude cheaper than with a
460
traditional implementation of stable storage that uses mag netic disk devices. Another form of
hardware support uses a special bus to guarantee atomic logg ing of all messages exchanged in
the system. Such hardware support ensures that the log of one machine is automatically stored
on a designated backup without blocking the execution of the application program. This scheme,
however,requires that allnondeterministiceventsbeconv ertedinto externalmessages.
Somepessimisticloggingsystemsreducetheoverheadofsyn chronousloggingwithoutrelying
on hardware. Forexample,the Sender-Based MessageLogging (SBML) protocolkeeps thedeter-
minantscorrespondingtothedeliveryofeachmessage minthevolatilememoryofitssender. The
determinantof m,whichconsistsofitscontentandtheorderinwhichitwasde livered,isloggedin
two steps. First, before sending m, the sender logs its content in volatilememory. Then, when t he
receiverof mrespondswith an acknowledgmentthat includestheorderin w hich themessagewas
delivered, the sender adds to the determinant the ordering i nformation. SBML avoids the over-
head of accessing stable storage but tolerates only one fail ure and cannot handlenondeterministic
events internal to a process. Extensions to this technique c an tolerate more than one failure in
special networktopologies.
13.5.3 Optimistic Logging
In optimistic logging protocols, processes log determinan tsasynchronously to the stable storage
[13]. These protocolsoptimisticallyassumethat loggingw ill be completebefore a failure occurs.
Determinantsarekeptinavolatilelog,andareperiodicall yﬂushedtothestablestorage. Thus,op-
timisticloggingdoesnotrequiretheapplicationtoblockw aitingforthedeterminantstobewritten
to thestablestorage, and thereforeincurs much lessoverhe ad duringfailure-free execution. How-
ever,thepricepaidismorecomplicatedrecovery,garbagec ollection,andsloweroutputcommit. If
a process fails, thedeterminants in its volatilelog are los t, and thestate intervals that were started
by thenondeterministiceventscorresponding to these dete rminants cannot be recovered. Further-
more,ifthefailedprocesssentamessageduringanyofthest ateintervalsthatcannotberecovered,
the receiver of the message becomes an orphan process and mus t roll back to undo the effects of
receivingthemessage.
Optimistic logging protocols do not implement the always-no-orphans condition. The pro-
tocols allow the temporary creation of orphan processes whi ch are eventually eliminated. The
always-no-orphans condition holds after the recovery is complete. This is achi eved by rolling
back orphan processes until their states do not depend on any message whose determinant has
been lost.
Consider the example shown in Figure 13.9. Suppose process P2fails before the determinant
form5is logged to the stable storage. Process P1then becomes an orphan process and must roll
back to undo the effects of receiving theorphan message m6. The rollback of P1furtherforces P0
toroll back toundotheeffects ofreceivingmessage m7.
To perform rollbacks correctly, optimisticlogging protoc ols track causal dependencies during
failurefreeexecution. Uponafailure,thedependencyinfo rmationisusedtocalculateandrecover
the latest global state of the pre-failure execution in whic h no process is in an orphan. Optimistic
461
0P
P1
P2m0 m4 m1
m2 m3 m5 m6m7A
B
CDX
Figure13.9: Optimisticlogging.
loggingprotocolsrequireanontrivialgarbagecollection scheme. Alsonotethatpessimisticproto-
colsneedonlykeepthemostrecentcheckpointofeachproces s,whereasoptimisticprotocolsmay
need tokeep multiplecheckpointsforeach process.
Since determinants are logged asynchronously, output comm it in optimisticlogging protocols
requires a guarantee that no failure scenario can revoke the output. For example, if process P0
needstocommitoutputatstate X,itmustlogmessages m4andm7tothestablestorageandask P2
to logm2andm5. In this case, if any process fails, the computation can be re constructed upto the
stateX.
13.5.4 CausalLogging
Causal loggingcombinestheadvantagesofbothpessimistic andoptimisticloggingattheexpense
ofamorecomplexrecoveryprotocol[13]. Likeoptimisticlo gging,itdoesnotrequiresynchronous
access to the stable storageexcept during output commit. Li ke pessimisticlogging, it allowseach
process to commit output independently and never creates or phans, thus isolating processes from
theeffectsoffailuresatotherprocesses. Moreover,causa llogginglimitstherollbackofanyfailed
process to the most recent checkpoint on the stablestorage, thus minimizingthe storage overhead
and theamountoflostwork.
Causalloggingprotocolsmakesurethatthe always-no-orphansproperty holdsbyensuringthat
thedeterminantofeachnondeterministiceventthatcausal lyprecedesthestateofaprocessiseither
stableoritisavailablelocallytothatprocess. Considert heexampleinFigure13.10. Messages m5
andm6arelikelytobelostonthefailuresofP 1andP 2attheindicatedinstants. Process P0atstate
Xwill have logged the determinants of the nondeterministic e vents that causally precede its state
accordingtoLamport’s happened-before relation. Theseeventsconsistofthedeliveryofmessages
m0,m1,m2,m3andm4. The determinant of each of these nondeterministicevents i s either logged
on the stable storage or is available in the volatile log of pr ocessP0. The determinant of each of
theseeventscontainstheorderinwhichitsoriginalreceiv erdeliveredthecorrespondingmessage.
Themessagesender,asinsender-basedmessagelogging,log sthemessagecontent. Thus,process
462
0P
P1
P2m0 m4 m1
m2 m3 m5 m6A
B
CXMaximum recoverable state
failure
failure
Figure13.10: Causal logging
P0will be able to “guide” the recovery of P1andP2since it knows the order in which P1should
replay messages m1andm3to reach the state from which P1sends message m4. Similarly, P0has
theorderinwhich P2shouldreplaymessage m2tobeconsistentwithboth P0andP1. Thecontent
ofthesemessagesisobtainedfromthesenderlogof P0orregenerateddeterministicallyduringthe
recovery of P1andP2. Note that information about messages m5andm6is lost due to failures.
Thesemessagesmayberesentafterrecoverypossiblyinadif ferentorder. However,sincetheydid
notcausally affect thesurvivingprocess ortheoutsidewor ld,theresultingstateis consistent.
Each process maintains information about all the events tha t have causally affected its state.
This information protects it from the failures of other proc esses and also allows the process to
make its state recoverable by simply logging the informatio n available locally. Thus, a process
does notneed torun amulti-hostprotocoltocommitoutput. I t can commitoutputindependently.
13.6 Koo-TouegCoordinatedCheckpointingAlgorithm
Koo and Toueg [22] ccordinated checkpointing and recovery t echnique takes a consistent set of
checkpoints and avoids the domino effect and livelock probl ems during the recovery. Processes
coordinate their local checkpointing actions such that the set of all checkpoints in the system is
consistent[9].
13.6.1 The Checkpointing Algorithm
The checkpoint algorithm makes the following assumptions a bout the distributed system: Pro-
cesses communicate by exchanging messages through communi cation channels. Communication
channels are FIFO. It is assumed that end-to-end protocols ( such as the sliding window protocol)
existtocopewithmessagelossduetorollbackrecoveryandc ommunicationfailure. Communica-
tionfailures donotpartitionthenetwork.
463
Thecheckpointalgorithmtakestwokindsofcheckpointsont hestablestorage: permanentand
tentative. A permanent checkpoint is a local checkpoint at a process and is a part of a consistent
global checkpoint. A tentative checkpoint is a temporary ch eckpoint that is made a permanent
checkpoint on the successful termination of the checkpoint algorithm. In case of a failure, pro-
cesses rollback onlyto theirpermanent checkpointsforrec overy.
Thecheckpointingalgorithmassumesthatasingleprocessi nvokesthealgorithmatanytimeto
takepermanentcheckpoints. Thealgorithmalsoassumestha tnoprocessfailsduringtheexecution
ofthealgorithm.
Thealgorithmconsistsoftwophases.
FirstPhase
An initiating process Pitakes a tentative checkpoint and requests all other process es to take
tentative checkpoints. Each process informs Piwhether it succeeded in taking a tentative check-
point. Aprocesssays“no”toarequestifitfailstotakeaten tativecheckpoint,whichcouldbedue
to several reasons, depending upon the underlying applicat ion. IfPilearns that all the processes
have successfully taken tentative checkpoints, Pidecides that all tentative checkpoints should be
madepermanent;otherwise, Pidecides thatallthetentativecheckpointsshouldbediscar ded.
Second Phase
Piinformsalltheprocessesofthedecisionitreachedattheen doftheﬁrstphase. Aprocess,on
receiving the message from Piwill act accordingly. Therefore, either all or none of the pr ocesses
advancethecheckpoint bytakingpermanentcheckpoints.
The algorithm requires that after a process has taken a tenta tive checkpoint, it can not send
messagesrelated to theunderlyingcomputationuntilit isi nformedofPi’s decision.
Correctness
A setofpermanent checkpointstakenby thisalgorithmiscon sistentbecauseofthefollowingtwo
reasons: First, either all or noneof theprocesses take perm anent checkpoints. Second, no process
sends a message after taking a tentative checkpoint until th e receipt of the initiating process’s
decision,bythenallprocesseswouldhavetakencheckpoint s. Thusasituationwillnotarisewhere
there is a record of a message being received but there is no re cord of sending it. Thus, a set of
checkpointstaken willalways beinconsistent.
An Optimization
Notethattheaboveprotocolmaycauseaprocesstotakeachec kpointevenwhenitisnotnecessary
forconsistency. Sincetakingacheckpointisanexpensiveo peration,wewouldliketoavoidtaking
checkpointsifitisnotnecessary.
Consider the example shown in Fig. 13.11. The set {x1,y1,z1}is a consistent set of check-
points. Supposeprocess X decides toinitiatethecheckpoin tingalgorithmafter receivingmessage
464
Take a tentative
checkpoint messagesTentative
checkpointx1
y1
z1x2
y2
z2X
Y
Zm
Time
Figure13.11: Exampleofcheckpointstakenunnecessarily.
m. It takes a tentativecheckpoint x2and sends “take tentativecheckpoint" messages to processe s
Yand Z,causingY andZtotakecheckpoints y2andz2,respectively. Clearly, {x2,y2,z2}formsa
consistentsetofcheckpoints. Note,however,that {x2,y2,z1}alsoformsaconsistentsetofcheck-
points. Inthisexample,thereisnoneedforprocessZtotake checkpointz2becauseZhasnotsent
any message since its last checkpoint. However, process Y mu st take a checkpoint since has sent
messagessinceitslastcheckpoint.
13.6.2 The Rollback RecoveryAlgorithm
The rollback recovery algorithm restores the system state t o a consistent state after a failure. The
rollback recovery algorithm assumes that a single process i nvokes the algorithm. It also assumes
that the checkpoint and the rollback recovery algorithms ar e not invoked concurrently. The roll-
back recoveryalgorithmhastwo phases.
FirstPhase
An initiating process Pisends a message to all other processes to check if they all are willing
torestartfromtheirpreviouscheckpoints. Aprocessmayre ply“no”toarestartrequestduetoany
reason (e.g., it is already participating in a checkpointin g or a recovery process initiated by some
otherprocess). If Pilearnsthatallprocessesarewillingtorestartfromtheirp reviouscheckpoints,
Pidecides that all processes should roll back to their previou s checkpoints. Otherwise, Piaborts
therollback attemptandit mayattemptarecovery ata latert ime.
Second Phase
Pipropagates its decision to all the processes. On receiving Pi’s decision, a process acts
accordingly.
Duringtheexecutionoftherecoveryalgorithm,aprocessca n notsendmessagesrelatedtothe
underlyingcomputationwhileitis waitingfor Pi’s decision.
465
x2
Timey2
z2x1
y1
z1X
Y
ZFailure
Figure13.12: Exampleofan unnecessary rollback.
Correctness
All processes restart from an appropriate state because if p rocesses decide to restart, then they
resume execution from a consistent state (the checkpointin g algorithm takes a consistent set of
checkpoints).
An Optimization
The above recovery protocol causes all processes to roll bac k irrespective of whether a process
needs to roll back or not. Consider the example shown in Fig. 1 3.12. The above protocol, in In
the event of failure of process X, the above protocol will req uire processes X, Y, and Z to restart
from checkpoints x2,y2, andz2, respectively. However, note that process Z need not roll ba ck
becausetherehasbeennointeractionbetweenprocessZandt heothertwoprocessessincethelast
checkpointat Z.
13.7 JuangandVenkatesanAlgorithmforAsynchronousCheck -
pointingandRecovery
WenowdescribethealgorithmofJuangandVenkatesan[18]fo rrecoveryinasystemthatemploys
asynchronouscheckpointing.
13.7.1 System ModelandAssumptions
Thealgorithmmakesthefollowingassumptionsabouttheund erlyingsystem: Thecommunication
channels are reliable, deliver the messages in FIFO order an d have inﬁnite buffers. The message
transmission delay is arbitrary, but ﬁnite. The processors directly connected to a processor via
communicationchannelsare called itsneighbors.
The underlying computation or application is assumed to be e vent-driven: a processor P waits
until a message mis received, it processes the message m, changes its state from stos′, and
sends zero or more messages to some of its neighbors. Then the processor remains idle until the
466
ex1 ex2
ey1 ey2 ey3
ez1 ez2 ez3
Timeex0
ey0
ez0X
Y
Zfailure
Figure13.13: An eventdrivencomputation.
receipt of the next message. The new state s′and the contents of messages sent to its neighbors
depends on state sand the contents of message m. The events at a processor are identiﬁed by
uniquemonotonicallyincreasingnumbers, ex0,ex1,ex2,...(seeFig. 13.13).
To facilitate recovery after a process failure and restore t he system to a consistent state, two
typesoflogstoragearemaintained,volatilelogandstable log. Accessingthevolatilelogtakesless
timethan accessing thestablelog, but the contentsof thevo latilelog are lost if thecorresponding
processorfails. Thecontentsofthevolatilelogare period icallyﬂushedto thestablestorage.
13.7.2 Asynchronous Checkpointing
After executing an event, a processor records a triplet {s,m,msgs _sent}in its volatile storage,
wheresis the state of the processor before the event, mis the message (including the identity of
the sender of m, denoted as m.sender) whose arrival caused the event, and msqs_sentis the set
of messages that were sent by the processor during the event. Therefore, a local checkpoint at a
processor consists of the record of an event occurring at the processor and it is taken without any
synchronization with other processors. Periodically, a pr ocessor independently saves the contents
of the volatile log in the stable storage and clears the volat ile log. This operation tantamounts to
takingalocal checkpoint.
13.7.3 The RecoveryAlgorithm
Notationsand data structure
Thefollowingnotationsand datastructureare usedby theal gorithm:
•RCVD i←j(CkPt i)represents the number of messages received by processor pifrom pro-
cessorpj, from thebeginningofthecomputationtillthecheckpoint CkPt i.
•SENT i→j(CkPt i)represents the numberof messages sent by processor pito processor pj,
fromthebeginningofthecomputationtillthecheckpoint CkPt i.
467
Basicidea
Since the algorithm is based on asynchronous checkpointing , the main issue in the recovery is to
ﬁnd a consistent set of checkpoints to which the system can be restored. The recovery algorithm
achieves this by making each processor keep track of both the number of messages it has sent to
otherprocessorsaswellasthenumberofmessagesithasrece ivedfromotherprocessors. Recovery
may involve several iterations of roll backs by processors. Whenever a processor rolls back, it is
necessary for all other processors to ﬁnd out if any message s ent by the rolled back processor
has become an orphan message. Orphan messages are discovere d by comparing the number of
messages sent to and received from neighboring processors. For example, if RCVD i←j(CkPt i)
> SENT j→i(CkPt j)(that is, the number of messages received by processor pifrom processor
pjis greater than the number of messages sent by processor pjto processor pi, according to the
current states the processors), then oneor more messages at processorpjare orphan messages. In
thiscase,processor pjmustrollbacktoastatewherethenumberofmessagesreceive dagreeswith
thenumberofmessagessent.
Consider an exampleshown in Fig. 13.13. Suppose processor Y crashes at the point indicated
and rolls back to a state corresponding to checkpoint ey1. According to this state, Y has sent only
onemessagetoX;however,accordingtoX’scurrentstate( ex2),Xhasreceivedtwomessagesfrom
Y.Therefore,Xmustrollbacktoastatepreceding ex2tobeconsistentwithY’sstate. Wenotethat
ifXrollsbacktocheckpoint ex1,thenitwillbeconsistentwithY’sstate, ey1. Likewise,processorZ
mustrollbacktocheckpoint ez2tobeconsistentwithY’sstate, ey1. Notethatsimilarlyprocessors
X and Zwillhavetoresolveany suchmutualinconsistencies( providedtheyareneighbors).
The Algorithm
When a processor restarts after a failure, it broadcasts a RO LLBACK message that it had failed1.
The recovery algorithm at a processor is initiated when it re starts after a failure or when it learns
ofafailureatanotherprocessor. Because ofthebroadcasto fROLLBACK messages,therecovery
algorithmis initiatedat all processors.
Procedure RollBack_Recovery
processorpiexecutesthefollowing:
STEP(a)
ifprocessorpiisrecoveringafter afailure then
CkPt i:=latesteventloggedinthestablestorage
else
CkPt i:= latest event that took place in pi{The latest event at pican be either in stable or in
volatilestorage.}
end if
STEP(b)
1Sucha broadcastcanbedoneusingonlyO(|E|)messageswhere |E|isthetotal numberofcommunicationlinks.
468
fork= 11 toN{Nisthenumberofprocessors inthesystem} do
foreach neighboringprocessor pjdo
computeSENT i→j(CkPt i)
sendaROLLBACK (i,SENT i→j(CkPt i))messagetopj
end for
foreveryROLLBACK (j,c)messagereceivedfrom aneighbor jdo
ifRCVD i←j(CkPt i)>c{Impliesthepresence oforphanmessages} then
ﬁndthelatestevent esuchthatRCVD i←j(e) =c{Suchanevent emaybeinthevolatile
storageorstablestorage.}
CkPt i:=e
end if
end for
end for{fork}
The rollback starts at the failed processor and slowly diffu ses into the entire system through
ROLLBACKmessages. Notethattheprocedurehas|N|iteratio ns. Duringthe kthiteration( k∝\⌉}atio\slash= 1),
a processor pidoes the following: (i) based on the state CkPt iit was rolled back in the ( k-
1)thiteration, it computes SENT i→j(CkPt i))for each neighbor pjand sends this value in a
ROLLBACK message to that neighbor and (ii) piwaits for and processes ROLLBACK mes-
sagesthatitreceivesfromitsneighborsin kthiterationanddeterminesanewrecoverypoint CkPt i
forpibased on information in these messages. At the end of each ite ration, at least one processor
willrollbackto itsﬁnal recoverypoint,unlessthecurrent recoverypointsare already consistent.
13.7.4 An Example
Consider an example shown in Figure 13.14 consisting of thre e processors. Suppose processor
Y fails and restarts. If event ey2is the latest checkpointed event at Y, then Y will restart fro m
the state corresponding to ey2. Because of the broadcast nature of ROLLBACK messages, the
recoveryalgorithmisalsoinitiatedatprocessorsXandZ.I nitially,X,Y,andZset CkPt X←ex3,
CkPt Y←ey2andCkPt Z←ez2, respectively, and X, Y, and Z send the following messages
duringtheﬁrstiteration: Ysends ROLLBACK (Y,2)toXand ROLLBACK (Y,1)toZ;X sends
ROLLBACK (X,2)toYand ROLLBACK (X,0)toZ;andZsends ROLLBACK (Z,0)toXand
ROLLBACK (Z,1)to Y.
SinceRCVD X←Y(CkPt X)= 3>2 (2 is the value received in the ROLLBACK (Y,2) mes-
sagefromY),Xwillset CkPt Xtoex2satisfyingRCVD X←Y(ex2)=1≤2. SinceRCVD Z←Y(CkPt Z)
=2>1,Zwillset CkPt Ztoez1satisfyingRCVD Z←Y(ez1)=1≤1. AtY,RCVD Y←X(CkPt Y)
= 1<2 andRCVD Y←Z(CkPt Y)= 1 =SENT Z←Y(CkPt Z). Hence, Y need not roll back fur-
ther. In the second iteration, Y sends ROLLBACK (Y,2) to X and ROLLBACK (Y,1) to Z; Z
sendsROLLBACK (Z,1) to Y and ROLLBACK (Z,0) to X; X sends ROLLBACK (X,0) to Z
andROLLBACK (X, 1) to Y. Note that if Y rolls back beyond ey3and loses the message from
X that caused ey3, X can resend this message to Y because ex2is logged at X and this message
availableinthelog. Thesecondandthirditerationwillpro gressinthesamemanner. Notethatthe
469
ex2
ey1 ey2
Timex1
y1
z1ey3ex3 ex0
ey0
ez0
ez2ex1
ez1X
Y
Zfailure
Figure13.14: AnexampleofJuan-Venkatesan algorithm.
set of recovery points chosen at the end of the ﬁrst iteration , {ex2,ey2,ez1}, is consistent, and no
furtherrollbackoccurs.
13.8 Manivannan-Singhal Quasi-Synchronous Checkpointin g
Algorithm
When processes independently take their local checkpoints , there is a possiblity that some local
checkpoints can never be included in any consistent global c heckpoint. (Recall that such local
checkpoints are called the useless checkpoints.) In the wor st case, no consistent checkpoint can
everbeformed.
Manivannan-singhalquasi-synchronouscheckpointingalg orithmimprovestheperformanceby
eliminating useless checkpoints. The algorithm is based on communication-induced checkpoint-
ing, where each process takes basic checkpoints asynchrono usly and independently, and in ad-
dition, to prevent useless checkpoints, processes take for ced checkpoints upon the reception of
messageswithacontrol variable.
Manivannan-singhal quasi-synchronous checkpointing alg orithm combines both the coordi-
nated andtheuncoordinatedcheckpointingapproaches to ge tthebestofboth:
•It allowsprocesses totakecheckpointsasynchronously.
•Usescommunication-inducedcheckpointingto eliminatest he“useless"checkpoints.
•Since every checkpoint lies on consistent checkpoint, dete rmination of the recovery line
duringarollbacka recoveryissimpleand fast.
Each checkpoint at a process is assigned a unique sequence nu mber. The sequence numbers
assigned to basic checkpoints are picked from the local coun ters which are incremented periodi-
cally.
When a process Pisends a message, it appends the sequence number of its latest checkpoint
to the message. When a process Pjreceives a message, if the sequence number received in the
470
messageisgreaterthanthesequencenumberofthelatestche ckpointof Pj,thenbeforeprocessing
themessage, Pjtakesa(forced)checkpointandassignsthesequencenumber receivedinthemes-
sageas thesequencenumberofthecheckpoint taken. When iti s timeforaprocess totakeabasic
checkpoint,itskipstakingabasiccheckpointifitslatest checkpointhasasequencenumbergreater
than or equal to the current value of its counter. This strate gy helps to reduce the checkpointing
overhead, i.e., the number of checkpoints taken. An alterna tive approach to reduce the number of
checkpointsistoallowaprocesstodelayprocessingarecei vedmessageuntilthesequencenumber
ofitslatestcheckpointis greaterthan orequal to theseque ncenumberreceived inthemessage.
13.8.1 Checkpointing Algorithm
Now, we present the quasi-synchronous checkpointing algor ithm formally. The variable next iof
processPirepresentsitslocalcounter. Itkeepstrackofthecurrentn umberofcheckpointintervals
atprocess Pi. Thevalueofthevariable snirepresentsthesequencenumberofthelatestcheckpoint
ofPiat any time. So, whenever a new checkpoint is taken, the check point is assigned a sequence
numberand sniisupdated accordingly. C.sndenotesthesequencenumberassignedto checkpoint
CandM.sndenotesthesequencenumberpiggybackedtomessage M.
DataStructures atProcessPi
sni:=0; {Sequence number of the current checkpoint, initializ ed to
0. This isupdatedeverytimea newcheckpointistaken.}
next i:=1; {Sequence number to be assigned to the next basic check-
point;initializedto1.}
WhenitistimeforprocessPitoincrementnext i
next i:=next i+1; { next iisincremented atperiodictimeintervalsof Xtimeunits}
WhenprocessPisendsamessageM
M.sn:=sni; {sequencenumberofthecurrent checkpointisappended to M}
send (M);
ProcessPjreceivesamessagefromprocessPi
ifsnj<M.snthen {ifsequencenumberofthecurrent checkpointislessth an
Takecheckpoint C; checkpointnumberreceivedinthemessage,then
C.sn:=M.sn; takeanew checkpointbeforeprocessingthemessage}
snj:=M.sn;
Process themessage.
WhenitistimeforprocessPitotakeabasiccheckpoint
ifnext i>snithen {skipstakingabasiccheckpointif next i≤sni(i.e., ifit
Takecheckpoint C; already tooka forcedcheckpointwithsequencenumber ≥
sni:=next i; next i)}
C.sn:=sni;
471
Properties
When processes take checkpoints in this manner, checkpoint s satisfy the following interesting
properties:
1. Checkpoint Ci,mof processpiis concurrent with checkpoints C∗,mof all other processes.
Forexample,inFigure13.15,checkpoint C2,3isconcurrent withcheckpoints C1,3andC3,3.
2. Checkpoints C∗,mofallprocessesformaconsistentglobalcheckpoint. Forex ample,inFig-
ure13.15,checkpoints{ C1,4,C2,4,C3,4}formaconsistentglobalcheckpoint. Aninteresting
application of this result is that if process P3crashes and restarts from checkpoint C3,5(in
Figure13.15), then P1will need to take acheckpoint C1,5(withoutrollingback) and theset
ofcheckpoints{ C1,5,C2,5,C3,5} willform aconsistentglobalcheckpoint.
Since there may be gaps in the sequence numbers assigned to ch eckpoints at a process, we
havethefollowingresult:
3. The checkpoint Ci,mof processpiis concurrent with the earliest checkpoint Cj,nat process
pjsuch thatm≤n. For example, in Figure 13.15, checkpoints { C1,3,C2,2,C3,2} form a
consistentglobalcheckpoint.
The following corollary gives a sufﬁcient condition for a se t of local checkpoints to be a part
ofaglobalcheckpoint.
Corollary 4. LetS={Ci1,mi1,Ci2,mi2,...,C ik,mik}be a set of local checkpoints from distinct
processes. Let m=min{mi1,mi2,...,m ik}. Then,Scan be extended to a global checkpoint if
∀l(1≤l≤k),Cil,milis theearliestcheckpointof Pilsuchthatmil≥m.
Thefollowingcorollary givesasufﬁcientconditionfor agl obalcheckpointtobeconsistent.
Corollary5. LetS={C1,m1,C2,m2,...,C N,m N}beasetoflocalcheckpointsoneforeachprocess.
Letm=min{m1,
m2,...,m N}. Then,Sisaglobalcheckpointif ∀i(1≤i≤N),Ci,miistheearliestcheckpointof
Pisuchthatmi≥m.
These properties have a strong implication on the failure re covery. The task of ﬁnding a con-
sistent global checkpoint after a failure is considerably s impliﬁed. If the failed process rolls back
to a checkpoint with sequence number m, then all other proces ses simply need to roll back to the
earliest localcheckpoint C∗,nsuchthatm≤n.
An Example
Weillustratethebasicideabehindthecheckpointsalgorit hmusingan example.
472
ConsiderasystemconsistingofthreeprocessesP 1,P2,andP 3showninFigure13.15. Thebasic
checkpointsareshownintheﬁgureas“ |”andforcedcheckpointsareshownas“ |∗”. Thesequence
numbers assigned to checkpoints are also shown in the ﬁgure. Each process P iincrements its
variablenext ieveryxtimeunits. ProcessP 3takesabasiccheckpointeveryxtimeunits,P 2takesa
basiccheckpointevery2xtimeunits,andP 1takesabasiccheckpointevery3xtimeunits. Message
M0forces P 3to take a forced checkpoint with sequencenumber 2 before pro cessing messageM 0.
AsaresultP 3skipstakingabasiccheckpointwithsequencenumber2. Mess ageM 1forcesprocess
P2to take a forced checkpoint with sequence number 3 before pro cessing M 1because M 1.sn<
sn2while receiving the message. Similarly message M 2forces P 1to take a checkpoint before
processing the message and M 4forces P 2to take a checkpoint before processing the message.
However M 3does not force process P 3to take a checkpoint before processing it. Note that there
maybegapsin thesequencenumbersassignedtocheckpointsa t aprocess.
13.8.2 Recovery Algorithm
The recovery process is asynchronous; that is, when a proces s fails, it just rolls back to its lat-
est checkpoint and broadcasts a rollback request message to every other process and continues
it’s processing without waiting for any reply message from t hem. The recovery is based on the
assumption that if a process P ifails, then no other process fails until the system is restor ed to a
consistentstate. Inadditiontothevariablesdeﬁnedinthe checkpointalgorithm,theprocessesalso
maintains two other variables; inc iand rec_line i. The inc iis the incarnation number for process
Pi. Itisincrementedeverytimeaprocessfailsandrestartsfr omitslatestcheckpoint. Therec_line i
is therecovery linenumber. These variables are stored in th e stablestorage, so that they are made
available for recovery. Initially, ∀i, inc i= 0 and rec_line i=0. With each message M, the current
values of the three variables inc i, sni, and rec_line iare piggybacked. The values of these variable
piggybackedtoMisdenotedbyM. inc,M.sn,andM. rec_line,respectively. Nowwepresentthebasic
recoveryalgorithmformally.
Data structures atprocess Pi
integersn i=0;
integernext i=1;
integerinc i=0;
integerrec_line i=0;
Checkpointing algorithm
WhenitistimeforprocessPitoincrement next i
next i= next i+1;
WhenitistimeforprocessPitotakeabasiccheckpoint
If (next i>sni) {
473
TakeacheckpointC;
Csn=next i;
sni=Csn;
}
WhenprocessPisendsamessageM
M.sn=sni;
M.rec_line=rec_line i;
M.inc=inc i;
send(M);
WhenprocessPjreceivesamessageM
if(M. inc>incj){
rec_line j=M. rec_line;
incj=M. inc;
Roll_Back(P j);
}
If (M sn>snj){
TakeacheckpointC;
Csn=M sn;
snj=Csn;
}
Process themessage;
BasicRecovery Algorithm (BRA)
Recovery initiatedbyprocessPiafterfailure
Restore thelatestcheckpoint;
inci=inc i+1;
rec_line i=sn i;
send rollback(inc i, rec_line i)to allotherprocesses;
resumenormalexecution;
ProcessPjuponreceiving rollback(inc i,rec_line i)fromPi
If (inc i>incj){
incj=inc i;
rec_lin j=rec_line i;
Roll_back(P j);
continueasnormal;
}
else
Ignoretherollback message;
Procedure Rollback(Pj
474
If (rec_line j>snj){
TakeacheckpointC;
C.sn=rec_line j;
snj=C. sn;
}
else
{
FindtheearliestcheckpointC withC. sn≥rec_line j;
snj=C.sn;
RestorecheckpointC;
Deleteall checkpointsafterC;
}
An Explanation
WhenprocessP ifails,itrollbackstoitslatestcheckpointandbroadcasts arollback(inc i,rec_line i)
message to all other processes and continues its normal exec ution. Upon receiving this rollback
message,aprocessP jrollsbacktoitsearliestcheckpointwhosesequencenumber ≥rec_line i,and
continues normal execution. If process P jdoes not have such a checkpoint, it takes a checkpoint
with the sequence number equal to rec_line i, and continues normally. Due to message delays, the
broadcastmessagemightbedelayedandaprocessP jmaycometoknowaboutarollbackindirectly
through some other process that has already seen the rollbac k message. Since every message is
piggybacked with M. inc, M. sn, and M. rec_line, the indirect application message that P jreceives
indicates a rollback incarnation by some other process. If p rocess P jreceives such a message M,
and M. inc>incj, then P jinfers that some failed process had initiated a rollback wit h incarnation
number M. incand P jrolls back to its earliest checkpoint whose sequence number ≥M.rec_line; if
Pjlater receives a rollback message corresponding to this inc arnation, it ignores it. Thus, after
knowingdirectlyorindirectlyaboutthefailureofaproces sPi,allotherprocessesrollbacktotheir
earliest checkpoint whose sequence number is greater than e qual to rec_line i. If any process does
nothavesuchacheckpoint,ittakesacheckpointandaddsitt otherec-lineandproceedsnormally.
Notethatnotall processesneed to perform arollbacktoits e arliestcheckpoint.
An Example
We illustrate the basic recovery using the example in Figure 13.15. Suppose process P 3fails at
the instant shown. When P 3recovers, it increments inc 3to 1, sets rec_line 3to sn 3(=5), rolls
back to its latest checkpoint C 3,5and sends a rollback(1,5) message to all other processes. Up on
receiving this message, P 2will rollback to checkpoint C 2,5since C 2,5is the earliest checkpoint
at P2with sequence number ≥5. However, since P 1does not have a checkpoint with sequence
numbergreaterthanorequalto5,ittakesalocalcheckpoint andassigns5asitssequencenumber.
Thus,{C 1,5,C2,5, C3,5} istherecoverylinecorrespondingthisfailure.
475
1P
P2
P3M3M1M2
M0 M4B
C2
1 23 4
3 4 0
00
55
3 46
***
*
failure
Figure13.15: An exampleillustratingManivannan-Singhal algorithm
Thus, the recovery is simple. The failed process (on recover ing from the failure) rolls back
to its latest checkpoint and requests other processes to rol lback to a consistent checkpoint which
theycaneasilydeterminesolelybasedonthelocalinformat ion. Thereisnodomino-effectandthe
recoveryis fast andefﬁcient.
In thisexample,weﬁndthatthesequencenumberofallcheckp ointsintherecoverylineisthe
same, butitneed notbethecasealways.
13.8.3 Comprehensive MessageHandling
Rollbacktoarecoverylinethatisconsistentmayresultinl ost,delayed,orphan,orevenduplicated
messages. Existenceofthesetypesofmessagemaylead thesy stemto an inconsistentstate. Next,
wediscussonhowto modifytheBRA tohandlethesemessages.
Handling thereplay ofmessages
Notallmessagesstoredinthestablestorageneedtoberepla yed. BRAhastobemodiﬁedsothatit
candecidewhichmessagesneedtobereplayed. InFigure13.1 6,ifweassumethatprocessP 1fails
at thepointmarked X andinitiatesarecovery withanew incar nation. After failureitrollsback to
its latest checkpoint, C 1,10, then increments the incarnation inc 1to 1 and sets the rec_line 1to 10,
and sends a rollback(1,10) message to all other processes. U pon receiving the rollback message
from P 1, process P 2rolls back to its checkpoint C 2,12. Consequently, all other process rolls back
to appropriate checkpoint following the BRA approach. Afte r all the processes have rolled back
to a set of consistent checkpoints, these checkpoints form a recovery line with number 10. The
messages sent to the left of the recovery line carry incarnat ion number 0 and messages sent to the
rightoftherecoverylinecarry incarnation1.
To avoid lost messages, when a process rolls back it must repl ay all messages from its log
whosereceivewasundoneandwhosesendwasnotundone. Inoth erwords,aprocessmustreplay
only those messages that originated from the left of the reco very line and delivered to the right of
476
1P
P2
P304 6 8 10 2
4 6 9 12 3
P40 23 54 6 8 10 7 11 910M1M7
M5M8M2
M4M3M6
B
C00
8 4
1inc =1
rec_line = 10
Message sent before the rollbackMessage sent after the rollbackfailure
Figure13.16: Handlingofmessagesduring therecovery.
therecoveryline. Intheexample,afterrollbackprocessP 2mustreplaymessagesM 1andM 2from
its log but must not replay M 3; because the send of M 1and M 2were not undone but the send of
M3was undone. It is easy to determine the origin of the send of a m essage M by looking at the
sequence number (M. sn) piggybacked. Therefore, we can state a rule for replaying m essages as
follows:
Messagereplayrule: AfteraprocessP jrollsbacktocheckpointC, itreplaysamessageMonlyif
itwas receivedafter Cand ifM. sn<recoverylinenumber.
Handling ofreceived messages
This section discusses how a process handles received messa ges. Suppose process P jreceives a
messageMfromprocessP i. Atthetimeofreceivingthemessage,ifP jisreplayingmessagesfrom
the message log, then P jwill buffer the message M and will process it only after it ﬁni shes with
the replaying of messages from the message log. If P jdoes not do this then the following three
cases may occur.
Case1: Mis a delayedmessage
A delayed message with respect to a recovery line carries an i ncarnation number less than the
incarnation number of the receiving process. The process P ithat sent such a message M was not
477
awareoftherecoveryprocessatthetimeofsendingofM.Ther efore, thepiggybackedincarnation
numberofP iislessthanthelatestincarnationnumberofP j,thereceivingprocess. Insuchasitua-
tion,ifM. sn<rec_line j,thenMisﬁrstloggedinthemessagelogandthenprocessed;o therwise,it
isdiscardedbecauseP iwilleventuallyrollbackandresendthemessage. Intheﬁgur e,M 4islogged
and then processed by P 2so that P 2might have to replay M 4due to a failure that may occur later,
whereas M 5is discarded by P 2. P2discards M 5because M. sn>rec_line 2(11>10) and M. inc(=0)
isless thaninc 2(=1). Therefore, wehavethefollowingruleforhandlingdel ayedmessages:
Rule for determining and handling delayed messages: A delayed message M received by process
Pjhas M. incless than inc j. Such a delayed message is processed by process P jonly if M. sn<
rec_line j; otherwise,itis discarded.
Case2: Mwas sentinthe current incarnation
Suppose P jreceives a message M such that inc j=M. inc. In this case, if M. sn<snj, then P j
must log M before processing it. This is done because P jmight need to replay M due to a future
failure. For example, in Figure 13.16, message M 7is sent by process P 1to process P 2after P 1’s
recovery and after P 2’s rollback during the same incarnation. In this case, M. inc= inc 2=1 and
(M.sn= 10)<(sn2=12)and M 7mustbelogged before beingprocessed because P 2mighthaveto
roll back to checkpoint C 2,12in case of a failure. In that case, P 2will need to replay message M 7.
Therefore, theruleformessagelogginginthiscase isstate das follows:
Message logging rule: A message received by process P jis logged into the message log if M. inc
<incjand M. sn<rec_line j)or(M. inc=inc jand M. sn<snj).
Case3: MessageM wassent ina future incarnation
Inthiscase,M. inc>incjandP jhandlesitasfollows: P jsetsrec_line jtoM. rec_lineandinc jto
M.inc, and then rolls back to the earliest checkpoint with sequenc e number≥rec_line j. After the
rollback, messageMishandled as inCase 2,because M. inc=inc j.
Features
Manivannan-Singhalquasi-synchronouscheckpointingalg orithmhas severalinterestingfeatures:
•Communication-induced checkpointing intelligently guid es the checkpointing activities to
eliminates“useless"checkpoints. Thus,everycheckpoint lies onconsistentcheckpoint.
•Thereisnoextramessageoverheadinvolvedincheckpointin g. Onlyascalarispiggybacked
onapplicationmessages.
•Ensures theexistenceof a recovery lineconsistentwith the latest checkpoint ofany process
allthetime. Thishelpsboundthedepthofrollbackduringa r ollbackrecovery.
478
•A failed process rolls back to its latest checkpoint and requ ests other processes to rollback
toaconsistentcheckpoint(no domino-effect).
•Helps in garbagecollection. After a process has establishe da recovery line, all checkpoints
preceding thelinecan bedeleted.
•Thealgorithmachievesthebestofthebothworlds:
–It has easeness and lowoverheadofuncoordinatedcheckpoin ting.
–It has recoverytimeadvantagesofcoordinated checkpointi ng.
13.9 Peterson-KearnsAlgorithmBasedonVectorTime
Peterson-Kearns checkpointing and recovery protocol is ba sed on the optimistic rollback. Vector
time is used to capture causality to identify events and mess ages which become orphans when a
failed processrollsback.
13.9.1 System Model
We assume that there are N processors in the system, which are logically conﬁgured as a ring.
Each processor knows its successor on the ring and this knowl edge is stored in its stable storage
sinceit is critical that it be recoverable after a failure. W e assumea singleprocess is executingon
eachprocessor. TheseNprocessesaredenotedasP 0,P1,P2....PN−1. WeassumethatP (i+1)modN
isthesuccessorofP ifor0≤i<N.
Each process P ihas a vectorclock V i[j], 0≤j≤N-1. V i(ei) denotes the clock valueof an event
eiwhichoccurredatP i. Theithcomponentofvectorisincrementedbeforeeacheventatproc essP i
and the current timestamp vector is sent on each message to up date the receiving process’s clock.
Vi(pi) denotes the current vector clock time process P iandeidenotes the most recent event in
Pi. ThusVi(pi) =Vi(ei). Each send and receive event increments the vector time. Th e processes
take periodic checkpoints of process state and also maintai n a message log on the stable storage.
The receipt of incoming messages is also logged periodicall y. The current vector clock value is
consideredapartoftheprocessstateandisloggedtothesta blestoragewhenacheckpointistaken.
Notations
Thefollowingnotationsareused toexplainthealgorithm:
•ei
j: Theitheventonpj. Weusee′ande′′torefer togenericeventsof Pj.
•s : A sendeventoftheunderlyingcomputation.
•σ(s): Theprocess wheresend event soccurs.
479
•ρ(s): Theprocess wherethereceiveeventmatched withsendevent soccurs.
•fi
j: TheithfailureonPj.
•cki
j: Theithstatecheckpointon Pj. Thecheckpointresides onthestablestorage.
•rsi
j: Theithrestart eventon Pj.
•rbi
j: Theithrollback eventon Pj.
•LastEvent (fi
j)=e′iffe′∝ma√sto→rsi
j
In a rollback protocol, every process must be contacted at le ast once to indicate that a failure
hasoccurredandtosendittheinformationnecessaryforrec overy. Thisprocessischaracterizedas
aseries ofoneormorepollingwaves whichare typiﬁed bythea rrivalofa pollingmessagewhich
transmits information necessary for rollback and a respons e by the polled process. We deﬁne two
neweventtypes:
Ci,k(m): the arrival of the ﬁnal polling wave message for rollbac k from failure
fimat process P k.
wi,k(m): theresponsetothisﬁnalpollingwaveby Pk. Ifnoresponseisrequired,
wi,k(m)= C i,k(m)
Theﬁnal pollingwaveforrecovery fromfailuref imisdeﬁned as:
PW i(m) =N−1/uniondisplay
k=0wi,k(m)∪N−1/uniondisplay
k=0Ci,k(m)
13.9.2 InformalDescription ofthe Algorithm
When a process P irestarts after failure f im, it retrieves its latest checkpoint, including its vector
clock value V i(Latest.ck (fm
i)), from the stable storage and rolls back to it. The message log is
replayed until it is exhausted. Since the vector time of each message is logged with the message,
when the messages are replayed, the clock value of the recove ring process is appropriately up-
dated. After the logged messages have been replayed, the rec overing process executes a restart
event,rsim,tobegintheglobalrollbackprotocol,originatesa tokenmessagecontainingthevector
timestamp of rsimand sends the token to its successor process. The token assoc iated with failure
fm
iand restart event rsimis denoted by tk(i,m). The timestamp of this token is denoted as tk(i,
m).ts.Process P ibuffers all incoming application messages until the return of the token. When
thisoccurs, P iresumes normalexecution.
Thetokeniscirculatedthroughalltheprocessesonthering . Whenthetokenarrivesatprocess
Pj, the timestamp in the token is used to determine whether the p rocess P jmust roll back. If tk(i,
m).ts<Vj(pj),then an orphan event has occurred at P jand P jmust roll back to an earlier state.
This is accomplished by restoring P jto the state of ck′
j,whereck′
jis the latest checkpoint at P j
480
for which V j(ck′
j) <tk(i, m).ts ,and then replaying logged messages as long as the timestamp o f
themessageisless than tk(i , m).ts.
ItispossiblethatanorphaneventinP jisthereceiptofamessageoriginatinginanon-orphaned
send event in process P i. Since the send event corresponding to such a receipt does no t causally
succeed any lost event in P i, the recovery of P iwill not result in the replay of such messages.
Therefore, these messages are lost unless some special acti ons are taken. To make sure that these
messages arenotlost,P jmustrequesttheirretransmissionduringtherollback.
During the rollback, P jmust also retransmit any message that it sent to P ithat was lost due
to failure. Process P jcan determine whether the messages it had sent have been rece ived by the
failed process P iby comparing the vector timestamps of the messages to the tim estamp in the
token. If Vj(s)[j] >Vi(rsm
i(j))where s is a message that was sent to P i,then it is possible that the
failed process has lost the message and it must be resent. It i s also possible that the message is
not lost, but is still in transit; thus P imust discard any duplicate messages. Because channels are
FIFO, P ican identifyanyduplicatemessagefrom itstimestamp.
After the logged messages have been replayed and retransmis sions of the required messages
aredone,P jinstigatesarollbackevent, rbkj,toindicatethatrollbackatitiscomplete. Vectortime
is not incremented for this event so V(jrbkj)= V j(e’j), where e’ jis the last event replayed. Any
loggedeventwhosevectortimeexceeds tk(i, m).ts is discarded.
Iftk(i,m).ts ≮Vj(pj)when the token arrives, the state of P jis not changed. However, for
consistency, a rollback event is instigated to indicate tha t rollback is complete at P jand to allow
thetokentobepropagated.
Note that after the rollback is complete, V j(pj)≯Vj(rsm
i, that is, every event in P jeither
happens before the restart event rsimor is concurrent to it. The property of vector time that e′
i→
e′′
jiffV i(e′
i)<V j(e′′
j)allowsus tomakethisclaim.
Thetokenispropagatedfromprocess pitoprocessp(i+1)modN. Asthetokenpropagates,itrolls
back orphan events at every process. When the token returns t o the originating process, the roll
back recoveryis complete.
Handling In-transit Orphan messages
It is possible for orphan messages to be in transit during the rollback process. If these messages
are received and processed duringor after therollbackproc edure, an inconsistentglobalstatewill
result. To identify these orphan messages and discard them o n arrival, it is necessary to include
an incarnationnumberwitheach messageand withthetoken. I ncidenotesthecurrent incarnation
numberoftheprocessP i.Inc(e i)denotestheincarnationnumberofanevente i. Thevaluereturned
foraneventequalsthecurrentincarnationnumberofthepro cessinwhichtheeventoccurred. The
incarnationnumberin thetoken isdenotedby tk(i,m).inc.
When P iinitiates the rollback process, it increments its current i ncarnation number by one
and attaches it to the token. A process receiving the token sa ves both the vector timestamp of the
token and the incarnation number in the stable storage. Beca use there is no bound on message
transmission time, the vector timestamps and associated in carnation numbers which have arrived
481
in the token must be accumulated in a set denoted as OrVect i. The set OrVect iis composed of
ordered pairs oftokentimestampsandincarnation numbersr eceivedby processP i.
When an application message is received by process P i,the vector timestamp of the message
is compared to the vector timestamps stored in OrVect i.If the vector timestamp of the message
is found to be greater than a timestamp in OrVect i, then the incarnation number of the message is
compared to the incarnation number corresponding to the tim estamp in OrVect i. If the message
incarnation number is smaller, then the message is discarde d. Clearly, this is an orphan message
that was in transit during the rollback process. In all other cases, the message is accepted and
processed. Uponthereceipt ofatoken, thereceiving proces ssets itsincarnationnumbertothatin
thetoken.
13.9.3 FormalDescription ofthe RollBack Protocol
The causal rollback protocol is described as set of six rules , CRB.1 to CRB.6. For each rule, we
ﬁrst present itsformaldescriptionand thengivea verbalex planationoftherule.
482
The Rollback Protocol
CRB.1 w i,i(m)occurs iffthereexistsf im,rsimsuchthatf im∝ma√sto→rsm
i→wi,i(m).
A formerly failed process creates and propagates a token, ev ent w i,i(m), only after
restoring the state from the latest checkpoint and executin g the message log from
thestablestorage.
CRB.2 Theoccurrence ofw i,i(m)impliesthat
tk.(i,m).ts=V i(rsim)∧
tk.(i,m).inc=Inc(Latest.ck(fm
i))+1∧
Inci=Inc(Latest.ck(fm
i))+1
The restart event increments the incarnation number at the r ecovering process, and
thetokencarriesthevectortimestampoftherestarteventa ndthenewlyincremented
incarnationnumber.
CRB.3 w i,j(m), i∝\⌉}atio\slash=j occurs iff
∃rbiksuch thatc i,j(m)→rbk
i→wi,j(m)∧
∀e′
jsuch thatV j(e′
j)> tk(i,m).ts,¬Recorded(e′
j)
A non-failedprocess willpropagatethetokenonlyafter ith as rolledback.
CRB.4 Theoccurrence ofw i,j(m)impliesthat
Inci=tk(i,m).inc∧(tk(i, m).ts,tk(i,m).inc) ∈OrVect j
Anon-failedprocesswillpropagatethetokenonlyafterith asincrementeditsincar-
nationnumberandhasstoredthevectortimestampofthetoke nandtheincarnation
numberofthetokenin itsOrVect set.
CRB.5 PollingwavePW i(m)iscompletewhenC i,j(m)occurs.
Whentheprocesswhichfailed,recovered,andinitiatedthe token,receivesitstoken
back, therollbackis complete.
CRB.6 Anymessagereceivedby event,n(s), isdiscarded iff ∃m∈OrVect (p(s))suchthat
Inc(s)< Inc(m)∧V(m)<V(s).
Messages whichwere intransitand which were orphanedby the failureand subse-
quent restartand recovery mustbediscarded.
13.9.4 An Example
Consider an example consisting of three processes shown in F igure 13.17. The processes have
takencheckpointsc10,c11,c12. Eacheventonaprocesstimelineistaggedwiththevectorti me(x,
483
0P
P1
P2C     (1)1,0
W    (1)1,2[1](3,0,0)
rb21
(1,4,4)W    (1)1,1
C     (1)1,2[1](3,0,0)rb11
(1,4,0)W    (1)1,0
C     (1)1,1[1](3,0,0)01rs(3,0,0) 01ffailure
1
0C(3,0,0)
1
1C
(1,2,0)
C1
2
(0,0,1)m2m4 m0
(1,1,0)(1,0,0)
[0](1,0,0)
m1 m3m5
m6(0,0,0)
(0,0,0)
(0,0,0)
(1,4,4)[0](2,0,0)(5,4,0) (2,0,0) (4,4,0)
[0](1,4,0)
(1,3,0)
(1,3,2)[0](1,3,0)(1,4,0)
(1,4,3)[0](1,4,0)[0](5,4,0)
[0](1,4,4)
Figure13.17: An ExampleofRollbackrecovery inPeterson-K earns Algorithm.
y, z) of its occurrence. Each message is tagged with [i](x, y, z), where i is the incarnation number
associated with the message send event, and (x, y, z) is the ve ctor time of the send event. Process
P0failsjustaftersendingmessage m5which incrementsitsvectorclock to(5,4,0).
Uponrestart ofP 0,thecheckpointc10is restored,and therestart event,rs1
0isperformed bythe
protocol. We assume that message m4was not looged into the stable storage at P0, henec it can
not be replayed during the recovery. A token, [1](4,0,0), is created and propagated to P 1. This is
shown in the Figure by a dotted vertical arrow. Upon the recei pt of the token, P 1rolls back to a
pointsuchthatitsvectortimeisnotgreaterthan(3,0,0),t hetimeinthetoken. HenceP 1rollsback
to its state at time (1,4,0). P 1then records the token in its OrVect set and sends the token to P2.
P2takes asimilaraction and rollsback to messagesend eventwi thtime(1,4,4). Thetoken isthen
returned toP 0and recoveryis complete.
Three messages are in transit while the polling wave is execu ting. The message m2from P 0
to P2with label [0](2,0,0) will be accepted when it arrives. Like wise, message m6from P 2will
be accepted by P 1when it arrives. However, application of rule CRB.6 will res ult in message m5
with label [0](5,4,0) being discarded when it arrives at P 1. The net effect of the recovery process
isthattheapplicationisrolledbacktoaconsistentglobal stateindicatedbythedottedline,andall
processeshavesufﬁcientinformationtodiscardmessagess entfromorphaneventsontheirarrival.
13.9.5 Correctness Proof
First weshowthat allorphaned eventsare detected and elimi nated[28].
Theorem 1: The completion of a wave in casual rollback protocol insures that every event or-
phaned byfailurefm
iiseliminatedbeforetheﬁnal pollingwave.
Proof:We prove that when the initiator process receives the token b ack, all the orphan events
484
have been detected and eliminated. That is, for an w i,j(m) event as it speciﬁed in causal rollback
protocol,
¬Orphan(w i,j(m), fm
i)
Firstweprovethatthetoken,asconstructedduringtherest orationofafailedprocess,contains
necessaryinformationtodetermineifanyeventisorphaned byafailure. Ifthereexistsanyorphan
evente’ iduetofailurefjm,thenthevectortimestampinthetokenwillbelessthanthev ectortime
of the event, i.e, tk(j,m).ts< V i(e’i).By the CRB.2, the vector timestamp in the token, tk(j,m).t s
must equal to V j(rsjm), and V j(rsjm) = V j(LastEvent(fmj)). In other words, timestamp in the
token must be equal to the vector time of the restart event rs jmat process P jdenoted as V j(rsjm)
and the vector time of the restart event at P jwill be one more than the vector time of the latest
event before failure fjm. Since rs jmoccupies the same position in causal partial order as e’ jand
LastEvent(fmj)∝ma√sto→e’j, the following must hold: V j(rsjm)≤Vj(e’j). If there exists an orphan e’ i,
thenthere existe’ jsuchthat LastEvent(fmj)→e’j→e’i.
Therefore, V j(e’j)< V i(e’i) andV j(rsjm)<V i(e’i)whichprovesthatwhen
tk(j,m).ts<V j(e’i) — (1)
thereexistsan orphanevente’ i.
Weusetheaboveresulttoprovethatthereexistsnoorphanev entattheendoftheﬁnalpolling
wave.
¬Orphan(w i,j(m), fm
i) — (2)
The proof is by contradiction. Let us assume that there exist a pollingevent w i,j(m)for which
orphan(w i,j(m),fm
i)istrue. Thenthereexistsanevente’ isuchthatLastEvent(fm
i)→e’i→wi,j(m).
Then there must exist e’ jsuch that e’ i→e’j→wi,j(m). This implies orphan(e’ j, fm
i). But
according to eq (1), tk(i,m).ts<V j(e’j), which contradicts the CRB 3: w i,j(m) occurs iff there
exists rb jksuch that c i,j(m)→rbjk→wi,j(m) and for every e’ jsuch that V j(e’j)>tk(i,m).ts,¬
recorded(e’ j).
Therefore, every event orphaned by a failure fm
iis eliminated before the ﬁnal polling wave is
completed. 2
Nowweshowthat onlyallorphaned messagesarediscarded [28 ].
Theorem 2: All orphaned messages are discarded and all non-orphaned me ssages are eventually
delivered.
Proof:Let us consider a send event s, which is not orphaned by the fai lure fm
i. In this case : n(s)
→wi,p(s)(m)∨wi,p(s)(m)→n(s).
485
Givenreliablechannels,themessagewilleventuallyarriv e. Thereceipt ofamessagecan only
disappear from the causal order if it is lost by a failed proce ss, rolled back by the protocol, or
discarded uponarrival.
TheﬁrstpossibilityisthatprocessP ilostthemessageduetoitsfailure. Inthiscasethereceiv-
ing process p(s) is i. During therollback at P σ(s)(the process where the send event occurred), this
message will be retransmitted as the occurrence of rbevent associated with w i,σ(s)(m) guarantees
this. Thereforew i,i→n(s).
Thesecondpossibilityis thatn(s) →wi,p(s)and n(s)has rolledback becausen(s)wasorphaned
by the failure fm
i. However if event s is not orphaned by fm
i, Pp(s)(the receiving process) will
request retransmissionbeforetheoccurrence oftherollba ckeventrb, and w i,p(s)→n(s).
Theﬁnalpossibilityisthatn(s)occurs afterthewavebutis discardeduponarrival. By CRB.6,
n(s) will be discarded if and only if V(s)>tk(i, m).ts and inc (s)<tk(i, m).inc. If s →wi,σ(s)and
Orphan(s,fi
m), then V(s) ≯tk(i, m).ts. If w i,σ(s)→s, then Inc(s) ≮tk(i,m).inc. Therefore, n(s) will
notbediscarded and w i,p(s)→n(s).
We nowprovetheconverse.
Ifn(s)→wi,p(s)(m)∨wi,p(s)→n(s)then¬Orphan(s,fm
i).
Assume n(s)→wi,p(s). From our eq (2), we know ¬Orphan(w i,p(s), fm
i). Therefore¬Orphan
(n(s), fm
i)and¬Orphan (s,fm
i).
Assume w i,p(s)→n(s) and orphan(s, fm
i). By eq (1), this implies tk(i ,m).ts < V σ(s). Rule CRB
2 of the protocol guarantees that if orphan(s,fm
i) is true, then Inc(s)<tk(i, m).inc. Rule CRB.4
requires that tk(i, m).ts and tk(i, m).inc are stored in OrVe ctjbefore w i,j(m) occurs. Therefore,
thereexistsz∈OrVect jsuchthatV(z)<V(s)andInc(z)>Inc(s). CRB 6requiressucha message
mustbediscarded,contradictingourassumptionthat w i,p(s)→n(s).2
13.10 Helary-Mostefaoui-Netzer-RaynalCommunication-i nduced
Protocol
Helary-Mostefaoui-Netzer-Raynal communication-induce d checkpointing protocol prevents use-
less checkpoints and does it efﬁciently. To prevent useless checkpoints, some coordination is
required in taking local checkpoints. Coordinated checkpo inting protocols use additional control
messages to synchronize their checkpointing activities, b ut these result in reduced process auton-
omy and degraded performance of the underlying application . Communication-induced check-
pointing protocols achieve this coordination by piggyback ing control information on application
messages. No control messages are needed and no synchroniza tion is added to the application.
More precisely, processes take local checkpoints independ ently, called basic checkpoints, and the
protocol directs them to take additional local checkpoints , called forced checkpoints. A process
takes a forced checkpoint when it receives a message and a pre dicate at it becomes true. This
predicate is based on local control variables of the receivi ng process and on the control values
carriedbythemessage. Thevaluesofthelocalcontrolvaria blesattheprocessarebasedoncausal
dependencies appearingin itspast.
486
m1
m2Pj
Pi
PkCj,y
Ck, zCi, x
(b)m1
m2Pj
Pi
PkCj,y
Ck, z
(a) 
Figure13.18: Tocheckpointornot tocheckpoint.
Helary-Mostefaoui-Netzer-Raynalcommunication-induce dcheckpointingprotocolensuresthat
no local checkpoint is useless and it takes as few forced chec kpoints as possible. It is based on Z-
pathandZ-cycletheoryintroducedbyNetzerandXu. Theprot ocolisbasedonZ-pathandZ-cycle
theory introducedby Netxerand Xu whoshowed thata uselessc heckpointexactly correspondsto
theexistenceofaZ-cycleinthedistributedcomputation. A tthemodellevel,theprotocolprevents
Z-cycles. At the operational level, each message is piggyba cked with an integer (Lamports clock
value), a vector of integers (checkpoint sequence number), and two Boolean vectors (the size of
each vector is n, the number of processes). An interesting fe ature of this protocol is that for any
checkpointC, it isveryeasy to determineaconsistentgloba lcheckpointtowhichC belongs.
13.10.1 DesignPrinciples
Witheach checkpointC, letusassociateatimestampdenoted byC.t. Theprotocoldependsonthe
followingresult:
“For any pair of checkpoints C j,yand C k,z, such that there is a Z-path from C j,yto C k,z, Cj,y.t
<Ck,z.t impliesthat thereisno Z-cycle."
Thus,ifwecanmanagethetimestampsandtakecheckpointsin suchawaythatthetimestamps
always increase along any Z-path, then no Z-cycles will form , and no checkpoints willbe useless.
Each process P ihas alogicalclock lc imanagedin thefollowingway:
•Before a process P itakes a (basic or forced) checkpoint, it increases its clock by 1 and
associatesthenewclock valuewiththecheckpoint.
•Everymessagemistimestampedwiththevalueofitssendercl ock(letm.tdenotethetimes-
tampassociatedwithmessagem).
•When aprocess P ireceivesamessagem,itupdates itslocalclock lc i=max (lc i, m.t).
It followsfrom this mechanismthat, ifthereis a causal Z-pa th from C j,yto C k,z, then wehave
Cj,y.t<C k,z.t
487
Tocheckpoint or not tocheckpoint
LetusconsiderthecomputationdepictedintheFigure13.18 whereC j,yisalocalcheckpointtaken
by P jbefore sending m 1and C k,zis the ﬁrst checkpoint of P ktaken after the delivery of m 2. As
the sending of m 2and the delivery of m 1belong to the same interval of P i, messages m 1and m 2
constituteaZ-path from C j,yto C k,z. When P ireceives m 1, two cases can occur:
•m1.t≤m2.t. Inthiscase,C j,y.t<m 1.t<m 2.t<C k,z.t. Hence,theZ-pathduetomessagesm 1
and m 2in Figure13.18(a)isinaccordance withtheaboveresult.
•m1.t >m 2.t. In thiscase, asafe strategyto preventZ-cycleformatio nisto direct P ito takea
forcedcheckpointC i,xbeforedeliveringm 1(asshowninFigure13.18(b). This“breaks”the
m1,m2Z-path, soit’snolongeraZ-pattern.
This strategy can be implemented in the following way. Each p rocess P imaintains a Boolean
arraysent_to i[1..n]todeterminewhetherthereceptionofamessagecreat esaZ-pattern. Thevalue
of sent_to i[k] is true iff P ihas sent a message to P ksince its last checkpoint. Each process P ialso
maintains an array of integer’s min_to i[1...n] where min_to i[k] keeps the timestamp of the ﬁrst
messageP isentto P ksinceitslastcheckpoint.
Theconditionm 1.t >m 2.tis thenexpressedas:
C≡(∃k: sent_to i[k]∧m1.t >min_to i[k])
Therefore, P itakes a forced checkpoint if C is true. The predicate C is true if there exists a
message from P ito Pksince its last checkpoint and the timestamp of m 1is greater than the ﬁrst
messageP isentto P ksinceitslast checkpoint.
Reducing the number of forcedcheckpoints
Each process P imaintains the local clock values of other processes. For eac h k (1≤k≤n), let
cli(k) denote the value of P k’s local clock as perceived by P i. If k = i, obviously cl i(i) = lc i.
However,ifk∝\⌉}atio\slash=i,theperceptionofP k’slocalclockbyP iisonlyanapproximationsuchthatcl i(k)
≤lck. Consideragain thesituationin Figure13.18. Ifthefollow ingpropertyholds
(m1.t <m 2.t)∨P, whereP≡(Cj,y.t≤m1.t≤cli(k)<C k,z.t)
then the Z-path due to messages m 1and m 2is in accordance with the above result. Let us
consider the property P in the case where m 1.t > m 2.t. Since m 1.t carries the value lc jwhen m 1is
sent, the ﬁrst relation C j,y.t≤m1.t necessarily holds when m 1is received. So, the property P can
beviolatedonlyif, whenm 1isreceived, m 1.t>cl i(k)orifcl i(k)≥Ck,z.t.
Therefore, to prevent the formation of Z-path due to message s m1and m 2that would violate
propertyP,theprotocolrequiresprocessP itotakeaforcedcheckpointbeforedeliveringm 1ifm1.t
>cli(k)orifcl i(k)≥Ck,z.t.
Now we have to determine which value of cl k, the approximation cl i(k) refers to. Let us
considerthefollowingtwopossiblecases:
488
m2Pj
Pi
PkCj,y
Ck, zm1
m’
(a) m2Pj
Pi
PkCj,y
Ck, zm1
m’’
(b)
Figure13.19: Valueofcl i(k)has been broughttoP iby acausal Z-path.
1. The value of cl i(k) has been brought to P iby a causal Z-path that started from P kand ended
before C k,z. This situation is illustrated in Figure 13.19. The value of cli(k) is brought to
Pibym’inFigure13.19(a)andbym”andm 1inFigure13.19(b). Inthiscase, wehavecl i(k)
<Ck,z.t and consequently,P ihas totakeaforced checkpointonlyifm 1.t >cl i(k).
2. The value of cl i(k) has been brought to P iby a causal Z-path that started from P kand ended
afterC k,z. Thissituationisillustratedin Figure13.20. Here therel evantcausal Z-path ism’
in Figure 13.20(a) and by m” and m 1in Figure 13.20(b). Both these ﬁgures can be redrawn
so that they corresponds to the pattern in Figure 13.21. In on e case, m’ brings thelast value
ofPk’s local clock to Piand in the other case, it is m”. m 1. In this case, we have cl i(k)≥
Ck,z.tandP ihastorecognizethispatternandtakeaforcedcheckpointif itoccurs. LetC 1be
apredicatedescribingthispatternoccurrence.
ThepreviousconditionCcan beredeﬁned as C’ asfollows:
C’≡(∃k: sent_to i[k]∧(m1.t >min_to i[k])∧(m1.t>cl i(k)∨C1))
The predicate C’ has two parts. The ﬁrst part is the previous c ondition C and the second part
is a predicate C 1. The second part will be true if the timestampof message m 1is greater than P k’s
local clockvalueas perceived byP iorifpredicateC 1istrue.
To evaluatethepredicate C 1, each processmaintainstwoadditionalarrays.
489
m’CC
m
C m
PPPj
i,x
i
k2 k,z1j,y
am"CC
C m
PPPj
i,x
i
k2 k,zj,y
bm1
Figure13.20: Valueofcl i(k)has been broughttoP iby acausal Z-path.
490
1. Array ckpt iis a vector that counts the number of checkpoints taken by eac h process. So,
ckpt i[k] denoted the number of checkpoints taken by P kto Pi’s knowledge. Let m.ckpt be
the value appended to m by its sender P iwhich is the value of the array ckpt iat the time of
sendingofmessagem.
2. ABoolean array taken iisused inconjunctionwithckpt itoevaluateC 1. Thevalueoftaken i
[k] is true iff there is a causal Z-path from the last checkpoi nt of P kknown by P ito the next
checkpointofP iand thiscausal Z-pathincludesacheckpoint.
Thearray taken iisupdatedin thefollowingway:
•When process a P itakes a checkpoint, it sets to true all entries of taken iexcept taken i[i],
whichalways remainsfalse. ∀k∝\⌉}atio\slash=i: taken i[k]=true
•When processP isendsamessage, P iappendsto itscurrent valueoftaken itothemessage.
•When processP ireceivesm,P iupdatestaken iinthefollowingway:
∀k∝\⌉}atio\slash=ido casem.ckpt[k]<ckpt i[k]→skip
m.ckpt[k]>ckpt i[k]→taken i[k]=m.taken[k]
m.ckpt[k]=ckpt i[k]→taken i[k]= (taken i[k]∨m.taken[k])
end docase
Withthesedatastructures,thepredicateC 1can beexpressedas follows:
C1≡(m1.ckpt[i]=ckpt i[i])∧m1.taken[i]
ConsidertheexampleshowninFigure13.21. Theﬁrstpartoft heconditionC 1statesthatthere
isacausalZ-pathstartingfromC i,xandarrivingatP ibeforeC i,x+1,whilethesecondpartindicates
thatsomeprocesshas taken acheckpointalongthiscausal Z- path.
13.10.2 The Checkpointing Protocol
Now we describe Helary-Mostefaoui-Netzer-Raynal communi cation induced checkpointing pro-
tocol which takes as few forced checkpoints as possible and a lso ensures that no local checkpoint
is useless. The protocol is executed by each process P i. S0, S1, S2 describe the initialization, the
statements executed by P iwhen it sends a message, and statements it executes when it re ceives
a message, respectively. The procedure take-checkpoint is called each time P itakes a checkpoint
(basicorforced).
The protocoluses thefollowingadditionaldatastructure: Every process Pimaintainsan array
clock i[1..n],where clock i[j]denotesthehighestvalueof lcjknowntoPi.clock i[1..n]isinitialized
to(0,0,...,0)and is updatedas follows:
491
m’
Ck,zm2C
PPi,x
i
k
Figure13.21: AnexampleofaZ-cycle.
492
•When aprocess P itakes a(basicorforced) checkpoint,itincreases clock i[i]clock by1.
•WhenPisendsamessagem,thecurrentvalueof clock iissentonthemessage. Letm.clock
thetimestampassociatedwithamessagem.
•When aprocess P ireceivesamessagemfrom Pj, itupdates itsclockas follows:
–clock i[i]= max(clock i[i], m.clock[j])
–∀k∝\⌉}atio\slash=i :clock i[k] =max(clock i[k], m.clock[k])
Notethatclock i[i]islci, sowedo notneed to keep lci.
Procedure take-checkpoint
∀kdo sent_to i[k]=falseend do;
∀kdo min_to i[k]= +∞end do;
∀k∝\⌉}atio\slash=i dotaken i[k]=trueend do;
clock i[i]=clock i[i]+ 1;
Savethecurrent local statewithacopy ofclock i[i];
/* letC i,xdenotethischeckpoint. WehaveC i,x.t=clock i[i]*/
ckpt i[i]=ckpt i[i]+1;
(S0) initialization
∀kdo clock i[k]=0;ckpt i[k]=0 end do;
taken i[i]=false;
take_checkpoint;
(S1) WhenP isends amessageto P k
if¬sent_to i[k] thensent_to i[k]=true; min_to i[k]=clock i[i]end if;
Send (m,clock i, ckpt i,taken i)to P k;
(S2) WhenP ireceives (m, clock ii, ckpt i, taken i)from P j
/* m.clock[j]istheLamport’stimestampofm (i.e.,m.t)*/
if (∃k : sent_to i[k]∧(m.clock[j]> min_to i[k])∧((m.clock[j]> max(clock i[k],
m.clock[k]))∨(m.ckpt[i]= ckpt i[i]∧m.taken[i]))
thentake_checkpoint/*forced checkpoint*/
end if;
clock i[i]=max(clock i[i], m.clock[j]);/*updateofthescalar clocklc i≡clock i[i]*/
∀k∝\⌉}atio\slash=i do
clock i[k]=max(clock i[k], m.clock[k]);
case
m.ckpt[k]<ckpt i[k]→skip
m.ckpt[k]>ckpt i[k]→ckpt i[k]=m.ckpt[k];taken i[k]=m.taken[k]
m.ckpt[k]<ckpt i[k]→taken i[k]= taken i[k]∨m.taken[k]
endcase
end do
deliver(m);
Helary-Raynal-Netzer-Mostefaoui [15] showed that given a local checkpoint Ci,xwith times-
tamp a, the checkpoint can be associated with theconsistent global checkpoint it belongs to using
493
thefollowingresult:
Theorem: LetabeaLamporttimestampand Cabeaglobalcheckpoint,{ C1,x1,C2,x2,...,Cn,xn,}.
If∀k,Ck,xkis the last checkpoint of Pksuch thatCk,xk.t≤a, thenCais a consistent global
checkpoint.
For a proof, the readers are referred to the original source [ 15]. This result implies that given
a local checkpoint at a process, it is easy to determine what l ocal checkpoints at other processes
form a consistent global checkpoint with it. This result has a strong implications on the recovery
from afailure.
13.11 BibliographicNotes
Checkpoiting and failure recovery is a well studied topic an d a large number of checkpoiting and
failurerecoveryalgorithmsexist. Aclassicalpaperonfau lttoleranceisbyRandell [32]. Classical
failure recovery algorithms are Leu and Bhargava algorithm [4], Sistla and Welch algorithm [34],
Kim [19], and Strom and Yemini algorithm [35]. Other checkpo inting and failure recovery
algorithmscanbefoundin[3],[12],[8],[30],[31],[24],[ 38],[39],[40],[14],[11],[37],and[15].
AnexcellentreviewpaperonthetopicisbyElnozahy,Alvisi ,WangandJohnson[13]. Richard
andSinghalgiveacomprehensiverecoveryprotocolusingve ctortimestamp[33]. Animpossibility
proof of min-process non-blocking in coordinated checkpoi nting is given in [7]. Cao and Singhal
introduced the concept of mutable checkpointing [8] to impr ove the performance. Alvisi and
Marzullo discuss various message logging techniques [1]. N etzer and Xu discuss necessary and
sufﬁcientconditionsforconsistentglobalsnapshotsindi stributedsystems[27]. Manivannanetal.
[26]andWang[40]discusshowtoconstructconsistentgloba lcheckpointsthatcontainagivenset
of local checkpoints. Prakash and Singhal discuss how to tak e maximal global snapshot with
concurrent initiators [29]. Other communication-induced checkpointing algorithms can be found
in paper by Baldoni et al. [2, 3, 17]. Tong et al. [36] present r ollback recovery using loosely
synchronizedclocks.
494
13.12 ExerciseProblems
1. Consider the followingsimplecheckpointingalgorithm: A process takes a local checkpoint
right after sending a message. Show that the last checkpoint at all processes will always be
consistent. What arethetrade-offs withthismethod?
2. Show by examplethat if Koo-Touegcheckpointingalgrithm , if processes do not block after
taking a tentative checkpoint, then global checkpoint take n by all processes may not be
consistent.
3. Showthat inManivannan-Singhalalgorithm,everycheckp ointtaken isuseful.
4. Designacheckpointingandrecoveryalgorithmthatusesv ectorclocks,anddoesnotassume
anyunderlyingtopology(likering ortree).
5. Give a rigorous proof of impossibility of a min-process, n on-blocking checkpointing algo-
rithm.
495
Bibliography
[1] Lorenzo Alvisi , Keith Marzullo, Message Logging: Pessi mistic, Optimistic, Causal, and
Optimal,IEEE Transactionson SoftwareEngineering,v.24n .2,p.149-159,February 1998
[2] Roberto Baldoni, Jean Michel Helary, Achour Mostefaoui and Michel Raynal, A
Communication-InducedCheckpointingProtocol thatEnsur esRollback-DependencyTrack-
ability,SymposiumonFault-TolerantComputing,1997, pp. 68-77.
[3] RobertoBaldoni,ACommunication-InducedCheckpointi ngProtocolthatEnsuresRollback-
Dependency Trackability, Proceedings of the 27th Internat ional Symposium on Fault-
TolerantComputing(FTCS ’97), p.68,June25-27,1997.
[4] B.BhargavaandP.Leu,ConcurrentRobustCheckpointing andRecoveryinDistributedSys-
tems,ProcoftheIEEE Int.Conf. on DataEng.,pages 154-163, February 1988.
[5] Daniele Briatico, Augusto Ciuffoletti, and Luca Simonc ini. A distributed domino-effect
free recovery algorithm. In Proc. of Symposium on Reliabili ty in Distributed Software and
DatabaseSystems,pages 207-215,SilverSpring(Maryland) , October1984.
[6] Guohong Cao, Mukesh Singhal Mutable Checkpoints: A New C heckpointing Ap-
proach for Mobile Computing Systems, IEEE Transactions on P arallel and Dis-
tributed Systems, Volume 12 , Issue 2 (February 2001), Pages : 157 - 172.
(http://www.cse.psu.edu/gcao/paper/gcao/TPDS01.pdf. )
[7] Guohong Cao and Mukesh Singhal, On the Impossibility of M in-Process Non-Blocking
Checkpointing and An Efﬁcient Checkpointing Algorithm for Mobile Computing Systems,
Proceedings of the 1998 International Conference on Parall el Processing table of contents
Pages: 37 -44,1998.
[8] Guohong Cao and Mukesh Singhal, Checkpointing with muta ble checkpoints, Theoretical
Computer Science, Volume 290, Issue 2 (January 2003), (Spec ial issue – Dependable com-
puting),Pages: 1127-1148,2003(http://www.cse.psu.edu /gcao/paper/gcao/TCS03.pdf).
[9] K. Mani Chandy and Leslie Lamport, Distributed snapshot s: determining global states of
distributedsystems,ACMTransactionsonComputerSystems (TOCS),v.3n.1,p.63-75,Feb.
1985.
496
[10] Chandy, M. and Ramamoorthy, C. V., Rollback and recover y strategies for computer pro-
grams.IEEE Trans.Comput.21,6, 546–556,1972.
[11] Om P. Damani , Yi-Min Wang , Vijay K. Garg, Distributed re covery with K-optimistic log-
ging, Journal of Parallel and Distributed Computing, v.63 n .12, p.1193-1218, December
2003.
[12] Elmootazbellah N. Elnozahy and Willy Zwaenepoel, Mane tho: Transparent RollBack-
Recovery with Low Overhead, Limited Rollback, and Fast Outp ut Commit,
http://www.cs.utexas.edu/users/mootaz/cs372/Project s/paper2.pdf.
[13] E. N. (Mootaz) Elnozahy, Lorenzo Alvisi, Yi-Min Wang an d David B. Johnson,
A Survey of Rollback-Recovery Protocols in Message-Passin g Systems, ACM Com-
puting Surveys, Volume 34 , Issue 3 (September 2002), Pages: 375 - 408.
(http://www.cs.utexas.edu/users/lorenzo/papers/Surv eyFinal.pdf)
[14] Elmootazbellah N. Elnozahy and James S. Plank, Checkpo inting for Peta-Scale Systems: A
LookintotheFutureofPractical Rollback-Recovery,IEEE T ransactionsonDependableand
Secure Computing,v.1n.2,p.97-108,April2004
[15] J. M. Helary , A. MosteFaul, R. H. Netzer and Raynal, Comm unication-Based Prevention
of Useless Checkpoints in Distributed Computations, In Pro c. of Sixteenth Symposium on
ReliableDistributedSystems,183-190.
[16] Jean-Michel Helary , Achour Mostefaoui , Michel Raynal , Preventing Useless Checkpoints
in Distributed Computations, Proceedings of the 16th Sympo sium on Reliable Distributed
Systems(SRDS’97), p.183,October22-24,1997.
[17] Jean-Michel Helary , Achour Mostefaoui , Michel Raynal , Communication-Induced Deter-
mination of Consistent Snapshots IEEE Transactions on Para llel and Distributed Systems,
Volume10, Issue9 (September1999),Pages: 865 -877.
[18] T. T-Y. Juang and S. Venkatesan, Crash Recovery with Lit tle Overhead, in Proc. of 11th
InternationalConf. onDistributedComput.Syst., pages 41 54-461,1991.
[19] K.H.Kim,Programmer-TransparentCoordinationofRec overingConcurrentProcesses: Phi-
losophyandRulesforEfﬁcientImplementation,IEEETransa ctionsonSoftwareEngineering,
Volume14, Issue6 (June1988),Pages: 810-821.
[20] K.H.Kim,"Approachtomechanizationoftheconversati onschemebasedonmonitor,"IEEE
Trans.SoftwareEng., vol.SE-8, no.3, pp.189-197,May 1982 .
[21] K.H.Kim,"Softwarefaulttolerance,"inHandbookofSo ftwareEngineering,C.R.Vickand
C. V. Ramamoorthy,Eds.New York: Van NostrandReinhold,198 4.
497
[22] Richard Koo , Sam Toueg, Checkpointing and rollback-re covery for distributed systems,
IEEETransactionsonSoftware Engineering,v 13,no 1,p. 23- 31,Jan. 1987.
[23] Leslie Lamport, Time, clocks, and the ordering of event s in a distributed system, Communi-
cationsoftheACM, v.21n.7,p.558-565,July1978.
[24] D.Manivannan,M.Singhal,Asynchronousrecoverywith outusingvectortimestamps,Jour-
nalofParallel and DistributedComputing,v.62n.12,p.169 5-1728,December 2002
[25] D. Manivannan and Mukesh Singhal, A Low Overhead Recove ry Technique Using Quasi-
SynchronousCheckpointing,ICDCS 1996,pg100-107.
[26] D. Manivannan , Robert H. B. Netzer , Mukesh Singhal, Fin ding Consistent Global Check-
pointsinaDistributedComputation,IEEETransactionsonP arallelandDistributedSystems,
v.8n.6,p.623-627,June1997.
[27] R. H.B. Netzerand J.Xu.,Necessary and Sufﬁcient Condi tionsforConsistentGlobalSnap-
shots,IEEE TransactionsonParallel and DistributedSyste ms,6(2):165-169,1995.
[28] S. L. Peterson and Phil Kearns, Rollback Based on Vector Time, in Proc. of the Symposium
onReliableDistributedSystems,1993: 68-77.
[29] R. Prakash, M. Singhal, Maximal global snapshot with co ncurrent initiators, Proc. 6th IEEE
Symp.on ParallelDistributedProcessing,Dallas,Texas, 1 994,pp.344-351.
[30] Ravi Prakash , Mukesh Singhal, Low-Cost Checkpointing and Failure Recovery in Mo-
bile Computing Systems, IEEE Transactions on Parallel and D istributed Systems, v 7 n 10,
p.1035-1048,October1996.
[31] Parameswaran Ramanathan , Kang G. Shin, Use of Common Ti me Base for Checkpointing
andRollbackRecoveryinaDistributedSystem,IEEETransac tionsonSoftwareEngineering,
v.19n.6,p.571-583,June1993
[32] B. Randell, System Structure for Software Fault Tolera nce, IEEE Trans. on Software Engi-
neering,Vol 1,No 2, 1975,pp.220-232.
[33] GoldenG.Richard III,MukeshSinghal,CompleteProces s Recovery: UsingVectorTimeto
HandleMultipleFailures inDistributedSystems,IEEE Para lleland DistributedTechnology:
Systemsand Technology,v.5n.2,p.50-59,April1997.
[34] A. P. Sistla and J. L. Welch, Efﬁcient distributed recov ery using message logging, Proceed-
ings of the eighth annual ACM Symposium on Principles of dist ributed computing table of
contents,Edmonton,Alberta,Canada, Pages: 223 -238,1989 .
[35] RobStromandShaulaYemini,Optimisticrecoveryindis tributedsystemsACMTransactions
onComputerSystems,Volume3, Issue3 (August1985), Pages: 204 -226.
498
[36] Z. Tong , R. Y. Kain , W. T. Tsai, Rollback Recovery in Dist ributed Systems Using Loosely
SynchronizedClocks,IEEETransactionsonParallelandDis tributedSystems,v.3n.2,p.246-
251,March 1992.
[37] S. Venkatesan , Tony Tong-Ying Juang , Sridhar Alagar, O ptimisticCrash Recovery without
ChangingApplicationMessages,IEEETransactionsonParal lelandDistributedSystems,v.8
n.3,p.263-271,March 1997.
[38] Yi-Min Wang and W. Kent Fuchs, Lazy Checkpoint Coordina tion for Bounding Rollback
Propagation,IEEESymposiumon ReliableDistributedSyste ms,1993.
[39] Yi-MinWang,Pi-YuChung,In-JenLin,W.KentFuchs,Che ckpointSpaceReclamationfor
Uncoordinated Checkpointing in Message-Passing Systems. , IEEE Transactions on Parallel
and DistributedSystems,v.6n.5,p.546-554,May1995
[40] Yi-MinWang,ConsistentGlobalCheckpointsthatConta inaGivenSetofLocalCheckpoints,
IEEETransactionsonComputers, v.46n.4, p.456-468,April 1997.
499
Chapter14
Consensus and AgreementAlgorithms
14.1 ProblemDeﬁnition
Agreement among the processes in a distributed system is a fu ndamental requirement for a wide
range of applications. Many forms of coordination require t he processes to exchange informa-
tion to negotiate with one another and eventually reach a com mon understanding or agreement,
before taking application-speciﬁc actions. A classical ex ample is that of the commitdecision in
database systems, wherein the processes collectively deci de whether to commitoraborta trans-
action that they participate in. In this chapter, we study th e feasibility of designing algorithms to
reach agreement under various system models and failure mod els, and where possible, examine
somerepresentativealgorithmstoreach agreement.
We ﬁrststatesomeassumptionsunderlyingourstudyofagree ment algorithms.
FailureModels: Among the nprocesses in the system, at most fprocesses can be faulty. A
faultyprocesscanbehaveinanymannerallowedbythefailur emodelassumed. Thevarious
failuremodels–fail-stop,sendomissionandreceiveomiss ion,andByzantinefailures–were
discussedinChapter2. Recall thatinthefail-stopmodel,a processmaycrash inthemiddle
ofastep,whichcould betheexecutionofalocal operationor processingofamessagefora
sendorreceiveevent. Inparticular,itmaysendamessageto onlyasubsetofthedestination
set before crashing. In the Byzantine failure model, a proce ss may behave arbitrarily. The
choiceofthefailuremodeldeterminesthefeasibilityand c omplexityofsolvingconsensus.
Synchronous/Asynchronous communication: If a failure-prone process chooses to send a mes-
sage to process Pibut fails, then Picannot detect thenon-arrivalof themessagein an asyn-
chronous system because this scenario is indistinguishabl e from the scenario in which the
message takes a very long time in transit. We will see this arg ument again when we con-
sidertheimpossibilityofreachingagreementinasynchron oussystemsinanyfailuremodel.
However, in a synchronous system, the scenario in which a mes sage has not been sent can
be recognized by the intended recipient, at the end of the rou nd. The intended recipient
can deal with the non-arrival of the expected message by assu ming the arrival of a message
containingsomedefaultdata, and thenproceeding withthen extround ofthealgorithm.
500
Network connectivity: Thesystemhas full logicalconnectivity,i.e.,each proces s can communi-
catewithanyotherby directmessagepassing.
Sender identiﬁcation: Aprocessthatreceivesamessagealwaysknowstheidentityo fthesender
process. Thisassumptionisimportant–becauseevenwithBy zantinebehaviour,eventhough
thepayloadof themessagecan containﬁctitiousdatasent by amalicioussender, theunder-
lyingnetworklayerprotocolscan revealthetrueidentityo fthesenderprocess.
When multiple messages are expected from the same sender in a single round, we implic-
itly assume a scheduling algorithm that sends these message s in sub-rounds, so that each
messagesent withintheroundcan beuniquelyidentiﬁed.
Channel reliability: The channels are reliable, and only the processes may fail (u nder one of
various failure models). This is a simplifyingassumption i n our study. As we will see even
withthissimplifyingassumption,theagreementproblemis eitherunsolvable,orsolvablein
acomplexmanner.
Authenticated vs. non-authenticated messages: Inourstudy,wewillbedealingonlywith unau-
thenticated messages. With unauthenticated messages, when a faulty pro cess relays a mes-
sage to other processes, (i) it can forge the message and clai m that it was received from
another process, and (ii) it can also tamper with the content s of a received message before
relaying it. When a process receives a message, it has no way t o verify its authenticity. An
unauthenticatedmessageisalso called an oralmessageoran unsigned message.
Usingauthenticationviatechniquessuchas digitalsignat ures,itiseasiertosolvetheagree-
ment problem because if some process forges a message or tamp ers with the contents of a
receivedmessagebefore relayingit,therecipientcan dete ct theforgery ortampering. Thus,
faultyprocesses can inﬂictless damage.
Agreement variable: The agreement variable may be boolean or multi-valued, and n eed not be
an integer. When studying some of the more complex algorithm s, we will use a boolean
variable. This simplifying assumption does not affect the r esults for other data types, but
helpsin theabstractionwhilepresentingthealgorithms.
Consider the difﬁculty of reaching agreement using the foll owing example, that is inspired by
thelongwars foughtby theByzantium EmpireintheMiddleAge s.1Fourcampsoftheattacking
army,each commandedbyageneral,arecampedaroundthefort ofByzantium. Theycan succeed
in attacking only if they attack simultaneously. Hence, the y need to reach agreement on the time
of attack. The only way they can communicate is to send messen gers among themselves. The
messengers model the messages. An asynchronous system is mo deled by messengers taking an
unbounded time to travel between two camps. A lost message is modeled by a messenger being
captured by the enemy. A Byzantine process is modeled by a gen eral being a traitor. The traitor
1Byzantium was the name of present-day Instanbul in the Middl e Ages; Byzantium itself was the new name of
ConstantinopleintheEarlyAges.
501
will attempt to subvert the agreement-reaching mechanism, by giving misleading information to
theothergenerals. Forexample,atraitormayinformonegen eraltoattackat10am,andinformthe
other generals to attack at noon. Or he may not send a message a t all to some general. Likewise,
hemaytamperwithmessageshegets fromothergenerals, befo rerelayingthosemessages.
G2
G3 G4011
1
0
01
00010G1
Figure14.1: Byzantinegenerals sendingconfusingmessage s.
AsimpleexampleofByzantinebehaviorisshowninFigure14. 1. Fourgeneralsareshown,and
aconsensus decision is to be reached about a boolean value. The various g enerals are conveying
potentially misleading values of the decision variable to t he other generals, which results in con-
fusion. In theface ofsuchByzantinebehavior, thechalleng eisto determinewhetheritispossible
to reach agreement, and if so under what conditions. If agree ment is reachable, then protocols to
reach itneed tobedevised.
14.1.1 The Byzantine Agreement and Other Problems
14.1.1.1 The Byzantine Agreement Problem
Before studying algorithms to solve the agreement problem, we ﬁrst deﬁne the problem formally.
TheByzantineagreement problemrequiresadesignatedprocess,calledthe sourceprocess thathas
aninitial value , to reach agreement with the other processes about its initi al value, subject to the
followingconditions.
Agreement: All non-faultyprocessesmustagree onthesamevalue.
Validity: If the source process is non-faulty, then the agreed upon val ue by all the non-faulty
processes mustbethesameas theinitialvalueofthesource.
Termination: Each non-faultyprocessmusteventuallydecideona value.
The validity condition rules out trivial solutions, such as one in which the agreed upon value
is a constant. It also ensures that the agreed upon value is co rrelated with the source value. If the
502
source process is faulty, then the correct processes can agr ee upon any value. It is irrelevant what
thefaultyprocesses agreeupon– orwhethertheyterminatea nd agreeupon anythingatall.
TherearetwootherpopularﬂavorsoftheByzantineagreemen tproblem–the Consensus prob-
lem,and the InteractiveConsistency problem.
14.1.1.2 The Consensus Problem
The Consensus problem differs from the Byzantine Agreement problem in that each process has
an initialvalueandall thecorrect processes mustagree ona singlevalue. Formally,
Agreement: All non-faultyprocessesmustagree onthesame(single)val ue.
Validity: Ifallthenon-faultyprocesseshavethesameinitialvalue, thentheagreeduponvalueby
allthenon-faultyprocesses mustbethat samevalue.
Termination: Each non-faultyprocessmusteventuallydecideona value.
14.1.1.3 The Interactive Consistency Problem
The Interactive Consistency problem differs from the Byzan tine agreement problem in that each
processhasaninitialvalue,andallthecorrectprocessesm ustagreeuponasetofvalues,onevalue
foreach process. Theformalspeciﬁcation isas follows.
Agreement: All non-faultyprocessesmustagree onthesamearray ofvalu esA[v1...v n].
Validity: Ifprocessiisnon-faultyanditsinitialvalueis vi,thenallnon-faultyprocessesagreeon
vias theith element of the array A. If process jis faulty, then the non-faulty processes can
agreeon anyvaluefor A[j].
Termination: Each non-faultyprocessmusteventuallydecideonthearray A.
14.1.2 Equivalence of the Problems andNotations
Thethreeproblemsdeﬁnedaboveareequivalentinthesenset hatasolutiontoanyoneofthemcan
be used as a solution to the other two problems. This equivale ncecan be shownusing a reduction
ofeach problem to theothertwo problems. If problemA isredu ced to problem B, then a solution
toproblemBcan beusedasasolutiontoproblemAinconjuncti onwiththereduction. Exercise1
asksthereader toshowthesereductions.
Formally, the difference between the agreement problem and theconsensus problem is that in
the agreement problem, a single process has the initial valu e, whereas in the consensus problem,
allprocesseshaveaninitialvalue. However,thetwotermsa re usedinterchangablyinmuchofthe
literatureandhence weshallalsousetheterms interchanga bly.
503
Failure Synchronous system Asynchronous system
mode (message-passing and shared memory) (message-passing and shared memory)
No agreement attainable; agreement attainable;
failure common knowledge also attainable concurrent common knowledge attainable
Crash agreement attainable agreement not attainable
failure f < nByzantine processes
Ω(f+ 1)rounds
Byzantine agreement attainable agreement not attainable
failure f≤⌊(n−1)/3⌋Byzantine processes
Ω(f+ 1)rounds
Table 14.1: Overview of results on agreement. fdenotes number of failure-prone processes. nis
thetotalnumberofprocesses.
Solvable Failure model and overhead Deﬁnition
Variants (MPand SM) MPand SM
Reliable crash failures Validity, Agreement, Integrity conditions
broadcast (Section 14.5.7)
k-set crash failures. f < k. size ofthe set ofvalues agreed
agreement upon mustbe less than k(Section 14.5.4)
ǫ-agreement crash failures values agreed upon are
within ǫofeach other (Section 14.5.5)
Renaming uptoffail-stop processes, n >2f+ 1 select aunique name from
aset ofnames (Section 14.5.6)
Table 14.2: Some solvable variants of the agreement problem in asynchronous system. The over-
head boundsareforthegivenalgorithms,and notnecessaril y tightboundsfortheproblem.
14.2 Overviewof Results
Table 14.1 gives an overview of the results and lower bounds o n solving the consensus problem
underdifferentassumptions.
Itisworthunderstandingtherelationbetweentheconsensu sproblemandtheproblemofattain-
ingcommonknowledgeoftheagreementvalue. Forthe“nofail ure”case, consensusisattainable.
Further, in a synchronous system, common knowledge of the co nsensus value is also attainable,
whereas in the asynchronous case, concurrent common knowle dge of the consensus value is at-
tainable.
Consensus is not solvable in asynchronous systems even if on e process can fail by crashing.
To circumvent this impossibility result, weaker variants o f the consensus problem are deﬁned in
Table14.2. Theoverheadsgivenin this Tableare forthe algo rithmsdescribed. Figure 14.2shows
further how asynchronous message-passing systems and shar ed memory systems deal with trying
tosolveconsensus.
504
Circumventing the impossibility results for consensus in asynchronous systems
kset consensus
epsilon− consensus
Renamingconsensusepsilon−Shared memory
Reliable broadcastusing atomic registers andkset consensus
RenamingConsensus 
atomic snapshot objects
constructed from atomic registersusing more powerful
objects than atomic registers.
universal objects and
universal constructions.Message−passing
This is the study of 
Figure14.2: Circumventingtheimpossibilityresultforco nsensusinasynchronoussystems.
14.3 AgreementinaFailure-FreeSystem(SynchronousorAsy n-
chronous)
In a failure-free system, consensus can be reached by collec ting information from the different
processes,arrivingata‘decision’,anddistributingthis decisioninthesystem. Adistributedmech-
anismwouldhaveeachprocessbroadcastitsvaluestoothers ,andeachprocesscomputesthesame
functiononthevaluesreceived. Thedecisioncanbereached byusinganapplication-speciﬁcfunc-
tion – some simpleexamples being the majority ,maxandminfunctions. Algorithmsto collect
the initial values and then distribute the decision may be ba sed on the token circulation on a logi-
cal ring, or thethree-phasetree-based broadcast-converg ecast-broadcast, ordirect communication
withall nodes.
•Inasynchronoussystem,thiscanbedonesimplyinaconstant numberofrounds(depending
on the speciﬁc logical topology and algorithm used). Furthe rmore, common knowledge of
thedecisionvaluecan beobtainedusingan additionalround (See Chapter 4).
•In an asynchronous system, consensus can similarly be reach ed in a constant number of
message hops. Further, concurrent common knowledge of the c onsensus value can also be
attained,usinganyofthealgorithmsinChapter 4.
Reaching agreement is straightforward in a failure-free sy stem. Hence, we focus on failure-prone
systems.
505
(global constants)
integer: f; //maximum number ofcrash failures tolerated
(local variables)
integer: x←−local value;
(1) Process Pi(1≤i≤n)executes the Consensus algorithm for up to fcrash failures:
(1a)forroundfrom1tof+ 1do
(1b) ifthe current value of xhas notbeen broadcast then
(1c) broadcast (x);
(1d) yj←−value (ifany) received from process jin this round;
(1e) x←−min(x,yj);
(1f)output xas the consensus value.
Figure 14.3: Consensus with up to ffail-stop processes in a system of nprocesses,n >f. Code
shownisforprocess Pi,1≤i≤n.
14.4 Agreementin(Message-Passing)SynchronousSystemsw ith
Failures
14.4.1 Consensus Algorithm forCrashFailures (Synchronou s System)
Figure 14.3 gives a consensus algorithm for nprocesses, where up to fprocesses, where f < n,
mayfail inthefail-stopmodel. Here, theconsensusvariabl exisinteger-valued. Each processhas
an initial value xi. If up toffailures (f < n) are to be tolerated, then the algorithm has f+ 1
rounds. In each round, a process isends the value of its variable xito all other processes if that
valuehas not been sent before. Of all the values received wit hin the round and its own value xiat
thestartoftheround,theprocesstakestheminimum,andupd atesxi. Afterf+1rounds,thelocal
valuexiisguaranteed tobetheconsensusvalue.
•Theagreement condition is satisﬁed because in the f+ 1rounds, there mustbe at least one
round in which no process failed. In this round, say round r, all the processes that have not
failed so far succeed in broadcasting theirvalues, and all t hese processes take theminimum
of the values broadcast and received in that round. Thus, the local values at the end of the
round are the same, say xr
ifor all non-failed processes. In further rounds, only this v alue
maybesent byeach processat mostonce, and noprocess iwillupdateitsvalue xr
i.
•Thevalidity condition is satisﬁed because processes do not send ﬁctitious values i n this
failuremodel. (Thus,aprocessthatcrasheshassentonlyco rrectvaluesuntilthecrash). For
alli, if the initial value is identical, then the only value sent b y any process is that identical
valuewhichis thevalueagreed uponas perthe agreement condition .
•Theterminationcondition isseen to beself-evidentlysatisﬁed.
506
Complexity: There aref+ 1rounds, where f < n. The number of messages is at most O(n2)
in each round, and each message has one integer. Hence the tot al number of messages is O((f+
1)·n2). The worst case scenario is as follows. Assume that the minim um value is with a single
process initially. In the ﬁrst round, theprocess manages to send its valueto just one otherprocess
before failing. In subsequent rounds, the single process ha ving this minimumvalue also manages
tosend thatvalueto justoneotherprocess beforefailing.
The algorithm in Figure 14.3 requires f+ 1rounds, independent of the actual number of
processes which fail. An early-stopping consensus algorithm terminates sooner; if there are f′
actual failures, where f′< f, then the early-stopping algorithm terminates in f′+ 1rounds.
Exercise 2 asks you to design an early-stopping algorithm fo r consensus under crash failures, and
toproveitscorrectness.
A Lower Bound on the Number of Rounds: At leastf+ 1rounds are required, where f < n.
The idea behind this lower bound is that in the worst-case sce nario, one process may fail in each
round; with f+ 1rounds, there is at least one round in which no process fails. In that guaranteed
failure-freeround,allmessagesbroadcastcanbedelivere dreliably,andallprocessesthathavenot
failed can computethecommonfunctionofthereceivedvalue storeach an agreement value.
14.4.2 Consensus Algorithms for Byzantine Failures (Synch ronous System)
PP
PP
P P a a b bc c
(a) (b)
malicious process01
1
0
second round messagefirst round messagecorrect process0commandercommander
0 0
1
Figure 14.4: Impossibility of achieving Byzantine agreeme nt whenn= 3processes and f= 1
maliciousprocess.
14.4.3 Upper Bound onByzantine Processes
In a system of nprocesses, the Byzantine agreement problem (as also the oth er variants of the
agreement problem) can be solved in a synchronous system onl y if the number of Byzantine pro-
507
cessesfis suchthatf≤⌊n−1
3⌋.
We informallyjustifythisresult usingtwosteps.
•Withn= 3processes, the Byzantine agreement problem cannot be solve d if the number
of Byzantine processes f= 1. The argument uses the illustration in Figure 14.4 which
shows a commander Pcand two lieutenant processes PaandPb. The malicious process is
the lieutenant Pbin the ﬁrst scenario and hence Pashould agree on the value of the loyal
commander Pc, which is 0. But note the second scenario in which Pareceives identical
valuesfrom PbandPc,butnowPcisthedisloyalcommanderwhereas Pbisaloyallieutenant.
In this case, Paneeds to agree with Pb. However, Pacannot distinguish between the two
scenariosandanyfurthermessageexchangedoesnothelpbec auseeachprocesshasalready
conveyedwhatitknowsfrom thethirdprocess.
Inbothscenarios, Pagetsdifferentvaluesfromtheothertwoprocesses. Intheﬁr stscenario,
itneedstoagreeona0,andifthatisthedefaultvalue,thede cisioniscorrect,butthenifitis
inthesecondindistinguishablescenario, itagrees onan in correctvalue. Asimilarargument
showsthatif1isthedefaultvalue,thenintheﬁrstscenario ,Pamakesanincorrectdecision.
Thisshowstheimpossibilityofagreement when n= 3andf= 1.
•Withnprocesses and f≥n/3processes, the Byzantine agreement problem cannot be
solved. The correctness argument of this result can be shown using reduction. Let Z(3,1)
denotetheByzantineagreementproblemforparameters n= 3andf= 1. LetZ(n≤3f,f)
denote the Byzantine agreement problem for parameters n(≤3f)andf. A reduction from
Z(3,1)toZ(n≤3f,f)needs to be shown, i.e., if Z(n≤3f,f)is solvable, then Z(3,1)
is also solvable. After showing this reduction, we can argue that asZ(3,1)is not solvable,
Z(n≤3f,f)isalso notsolvable.
The main idea of the reduction argument is as follows. In Z(n≤3f,f), partition the
nprocesses into three sets S1,S2,S3, each of size≤n/3. InZ(3,1), each of the three
processesP1,P2,P3simulates the actions of the corresponding set S1,S2,S3inZ(n≤
3f,f). If one process is faulty in Z(3,1), then at most f, wheref≤n/3, processes are
faulty inZ(n,f). In the simulation, a correct process in Z(3,1)simulates a group of up
ton/3correct processes in Z(n,f). It simulates the actions (send events, receive events,
intra-set communication, and inter-set communication) of each of the processes in the set
thatit issimulating.
Withthisreductioninplace,ifthereexistsanalgorithmto solveZ(n≤3f,f),i.e.,tosatisfy
the validity, agreement, and termination conditions, then there also exists an algorithm to
solveZ(3,1),whichhas been seento beunsolvable. Hence, therecannotex istan algorithm
tosolveZ(n≤3f,f).
508
00 01commander commanderd d
c c P P
(b) (a)b b a
1
correct process malicious processfirst round exchange second round exchange0010 00 0 11 0 0 0
0a P PP
PP
P
Figure14.5: AchievingByzantineagreement when n= 4processesand f= 1maliciousprocess.
14.4.4 Byzantine Agreement Tree Algorithm: Exponential (S ynchronous
System)
14.4.4.1 Recursive formulation
We begin with an informal description of how agreement can be achieved with n= 4andf= 1
processes, as depicted in Figure 14.5. In the ﬁrst round, the commander Pcsends its value to the
other three lieutenants, as shown by dotted arrows. In the se cond round, each lieutenant relays to
the other two lieutenants, the value it received from the com mander in the ﬁrst round. At the end
of the second round, a lieutenant takes the majority of the va lues it received (i) directly from the
commander in the ﬁrst round, and (ii) from the other two lieut enants in the second round. The
majority gives a correct estimate of the “commander’s” valu e. Consider Figure 14.5(a) where the
commander is a traitor. The values that get transmitted in th e two rounds are as shown. All three
lieutenants take the majority of (1, 0, 0) which is ‘0’, the ag reement value. In Figure 14.5(b),
lieutenantPdis malicious. Despite its behavior as shown, lieutenants PaandPbagree on ‘0’, the
valueofthecommander.
The ﬁrst algorithm for solving Byzantine agreement was prop osed by Lamport, Shostak, and
Pease. Wepresenttwo versionsofthealgorithm.
TherecursiveversionofthealgorithmisgiveninFigure14. 6. Eachmessagehasthefollowing
parameters: a consensus estimate value ( v), set of destinations ( Dests), list of nodes traversed by
the message, from most recent to least recent ( List), and the number of Byzantine processes that
the algorithm still needs to tolerate ( faulty). The listL=∝a\}⌊ra⌋k⌉tl⌉{tPi,Pk1...P kf+1−faulty∝a\}⌊ra⌋k⌉tri}htrepresents the
sequenceofprocesses(subscripts)intheknowledgeexpres sionKi(Kk1(Kk2...K kf+1−faulty(v0)...)).
Thisknowledgeiswhat Pkf+1−faultyconveyedto Pkf−faultyconveyedto ...P k1conveyedto Piwho
is conveying to the receiver of this message, the value of the Commander ( Pkf+1−faulty)’s initial
509
(variables)
boolean:v←−initial value;
integer:f←−maximum number ofmalicious processes, ≤⌊(n−1)/3⌋;
(message type)
Oral_Msg (v,Dests,List,faulty ), where
vis aboolean,
Destsisa setof destination process ids towhich the message issen t,
Listisalist ofprocess ids traversed by this message, ordered fr om most recent toearliest,
faultyisan integer indicating the number of malicious processes t o betolerated.
Oral_Msg( f), where f >0:
1. The algorithm is initiated by the Commander, who sends his source value vto all other processes
using aOM(v,N,∝a\}⌊ra⌋k⌉tl⌉{ti∝a\}⌊ra⌋k⌉tri}ht,f)message. Thecommander returns his ownvalue vand terminates.
2.[Recursionunfolding:] Foreachmessageoftheform OM(vj,Dests,List,f′)receivedinthisround
from someprocess j, theprocess iuses thevalue vjitreceives fromthesource, and using thatvalue,
acts as anewsource. (Ifno value is received, adefault value isassumed. )
Toactas anew source, the process iinitiatesOral_Msg( f′−1), wherein it sends
OM(vj,Dests−{i},concat (∝a\}⌊ra⌋k⌉tl⌉{ti∝a\}⌊ra⌋k⌉tri}ht,L),(f′−1))
to|N|−1−(f−f′+ 1)destinations not in concat (∝a\}⌊ra⌋k⌉tl⌉{ti∝a\}⌊ra⌋k⌉tri}ht,L)
in thenext round.
3.[Recursionfolding:] Foreachmessageoftheform OM(vj,Dests,List,f′)receivedinStep2,each
process iawaits the computed value vkfrom each of the|N|−2−(f−f′)processes (excluding
itself) not in Listin the folding phase of the recursion. If it receives no value in this round, it uses a
default value. Process ithen uses the value majority k/ne}ationslash∈List,k/ne}ationslash=i(vj,vk)as the agreement value and
returns it tothe next higher level inthe recursive invocati on.
Oral_Msg(0):
1.[Recursion unfolding:] Process acts asasource and sends its value to each other proc ess.
2.[Recursion folding:] Each process uses the value it receives from the other source s, and uses that
value as the agreement value. Ifno value isreceived, adefau lt value isassumed.
Figure 14.6: Byzantine generals algorithm – exponential nu mber of unsigned messages, n >3f.
Recursiveformulation.
value.
The commander invokes the algorithm with parameter faultyset tof, the maximum number
of malicious processes to be tolerated. The algorithm uses f+ 1synchronous rounds. Each
message(havingthisparameter faulty =k)receivedbyaprocessinvokesseveralotherinstances
ofthealgorithmwithparameter faulty =k−1. Theterminatingcaseoftherecursioniswhenthe
parameterfaultyis 0. As the recursion folds, each process progressively com putes the majority
function over the values it used as a source for that level of i nvocation in the unfolding, and the
values it has just computed as consensus values using the maj ority function for the lower level of
510
round amessage has aims totolerate and each message total number of
number already visited these manyfailures gets sent to messages in round
1 1 f n−1 n−1
2 2 f−1 n−2 (n−1)·(n−2)
... ... ... ... ...
x x (f+ 1)−x n−x (n−1)(n−2)...(n−x)
x+ 1 x+ 1 (f+ 1)−x−1 n−x−1 (n−1)(n−2)...(n−x−1)
f+ 1 f+ 1 0 n−f−1 (n−1)(n−2)...(n−f−1)
Table14.3: Relationshipsbetweenmessagesandroundsinth eOralMessagesalgorithmforByzan-
tineagreement.
invocations.
There are an exponential number of messages used by this algo rithm. Table 14.3 shows the
numberofmessagesusedineachroundofthealgorithm,andre latesthatnumbertothenumberof
processes already visitedby anymessageas wellas thenumbe rofdestinationsofthat message.
Asmultiplemessagesarereceivedinanyoneroundfromeach o ftheotherprocesses,theycan
bedistinguishedusingthe List, orby usinga schedulingalgorithmwithineach round. A deta iled
iterative version of the high-level recursive algorithm is given in Figure 14.7. Lines (2a)-(2e)
correspond to the unfolding actions of the recursive pseudo -code, and lines (2f)-(2h) correspond
to the folding of the recursive pesudo-code. Two operations are deﬁned in the list L:head(L)is
the ﬁrst member of the list L, whereastail(L)is the listLafter removing its ﬁrst member. Each
process maintainsatreeofboolean variables. Thetree data structureisused as follows.
•Therearef+ 1levelsfromlevel0throughlevel f.
•Level0has onerootnode, v/an}bracketle{t/an}bracketri}ht
0.
•Leveli,0< i≤fhas1·(n−2)·(n−3)...(n−i)·(n−(i+ 1))nodes. Each node at
level(i−1)has(n−(i+ 1))childnodes.
•NodevL
kdenotes the command received from the node head(L)by nodek. The command
was relayed to head(L)byhead(tail(L)), which received it from head(tail(tail(L))), and
soon. Theverylastelement of Listhecommander,denoted P0.
•In thef+ 1rounds of the algorithm (lines (2a)-(2e) of the iterative ve rsion), each level k,
0≤k≤f, of the tree is successively ﬁlled to remember the values rec eived at the end
of roundk+ 1, and with which the process sends the multiple instances of t heOral_Msg
message with the fourth parameter as f−(k+ 1)in roundk+ 2(other than the ﬁnal
terminatinground).
•For each message that arrives in a round (lines 2b-2c of the it erative version), a process
setsvtail(L)
head(L)(line 2d). It then removes itself from Dests, prepends itself to L, decrements
faulty,and forwardsthevalue vtotheupdated Dests(line2e).
511
(variables)
boolean:v←−initialvalue;
integer:f←−maximumnumberofmaliciousprocesses, ≤⌊n/3⌋;
treeofboolean :
•level0rootis vL
0,where L=∝a\}⌊ra⌋k⌉tl⌉{t∝a\}⌊ra⌋k⌉tri}ht;
•leveli(f≥i >0)nodes: foreach vL
jatlevel sizeof (L)(=i−1),itsn−2−sizeof (L)descendantsatlevel
i=sizeof (L) + 1arevconcat (/angbracketleftj/angbracketright,L)
k,∀ksuchthat k∝\⌉}atio\slash=j, iandkisnotamemberoflist L.
(messagetype)
OM(v, Dests, List, faulty ),wheretheparametersareasinthe recursiveformulation.
(1)Initiator(i.e.,Commander)initiatesOralByzantinea greement:
(1a)sendOral_Msg (v, N−{i},∝a\}⌊ra⌋k⌉tl⌉{tPi∝a\}⌊ra⌋k⌉tri}ht, f)toN−{i};
(1b)return(v).
(2)(Non-initiator,i.e.,Lieutenant)receivesOralMessa geOM:
(2a)forrnd=0tofdo
(2b)foreachmessageOMthat arrivesinthisround,thefollowingisp erformed:
(2c) receiveOral_Msg (v, Dests, L =∝a\}⌊ra⌋k⌉tl⌉{tPk1. . . P kf+1−faulty∝a\}⌊ra⌋k⌉tri}ht, faulty)from Pk1;
//faulty +round=f ;|Dests|+sizeof (L) =n
(2d) vtail(L)
head(L)←−v; //sizeof (L) +faulty =f+ 1. ﬁll in estimateofnodeat level sizeof (tail(L))
(2e) sendOral_Msg (v, Dests−{i},∝a\}⌊ra⌋k⌉tl⌉{tPi, Pk1. . .P kf+1−faulty∝a\}⌊ra⌋k⌉tri}ht, faulty−1)toDests−{i};
(2f)forlevel=f−1down to 0do
(2g)foreachofthe 1·(n−2)·. . .(n−(level+ 1))nodes vL
xinlevel level,thefollowingisperformed:
(2h) vL
x(x∝\⌉}atio\slash=i, x∝\⌉}atio\slash∈L) =majority y/negationslash∈concat (/angbracketleftx/angbracketright,L);y/negationslash=i(vL
x, vconcat (/angbracketleftx/angbracketright,L)
y );
Figure 14.7: Byzantine generals algorithm – exponential nu mber of unsigned messages, n >3f.
Iterativeformulation.
•Once the entire tree is ﬁlled from root to leaves, the actions in the folding of the recursion
are simulatedin lines (2f)-(2h) of theiterativeversion, p roceeding from theleaves up to the
root of the tree. These actions are crucial – they entail taki ng the majority of the values at
each level of the tree. The ﬁnal value of the root is the aagree ment value, which will be the
sameatall processes.
14.4.4.2 Example
Figure 14.8showsthetree at alieutenantnode P3, forn= 10processesP0throughP9andf= 3
processes. The commanderis P0. Only one branch of the tree is shown for simplicity. The read er
is urged to work through all the steps to ensure a thorough und erstanding. Some key steps from
P3’s perspectiveare outlinednext,withrespect to theiterat iveformulationofthealgorithm.
Round 1:P0sends its value to all other nodes. This corresponds to invok ingOral_Msg(3) in the
recursiveformulation. At theend oftheround, P3storesthereceivedvaluein v/an}bracketle{t/an}bracketri}ht
0
Round 2:P3acts as a source for this valueand sends this value to all node s except itselfand P0.
512
This corresponds to invoking Oral_Msg(2) in the recursive formulation. Thus, P3sends 8
messages. It will receive a similar message from all other no des exceptP0and itself; the
valuereceivedfrom Pkis storedinv/an}bracketle{t0/an}bracketri}ht
k.
Round 3: Foreachofthe8valuesreceivedinround2, P3actsasasourceandsendsthevaluesto
allnodesexcept(i)itself,(ii)nodesvisitedpreviouslyb ythecorrespondingvalue,asremem-
bered in the superscript list, and (iii) the direct sender of the received message, as indicated
by the subscript. This corresponds to invoking Oral_Msg(1) in the recursive formulation.
Thus,P3sends7 messages foreach of these8 values, givinga totalof 5 6 messages it sends
in this round. Likewise it receives 56 messages from other no des; the values are stored in
level2 ofthetree.
Round 4: For each of the 56 messages received in round 3, P3acts a source and sends the val-
ues to all nodes except (i) itself, (ii) nodes visited previo usly by the corresponding value,
as remembered in the superscript list, and (iii) the direct s ender of the received message,
as indicated by the subscript. This corresponds to invoking Oral_Msg(0) in the recursive
formulation. Thus, P3sends 6 messages for each of these 56 values, giving a total of 336
messagesitsendsinthisround. Likewise,itreceives336me ssages,andthevaluesarestored
atlevel3ofthetree. Asthisroundis Oral_Msg(0) ,thereceivedvaluesareusedasestimates
forcomputingthemajorityfunctionin thefoldingoftherec ursion.
An exampleofthemajoritycomputationisas follows.
•P3revisesitsestimateof v/an}bracketle{t5,0/an}bracketri}ht
7bytaking
majority (v/an}bracketle{t5,0/an}bracketri}ht
7,v/an}bracketle{t7,5,0/an}bracketri}ht
1,v/an}bracketle{t7,5,0/an}bracketri}ht
2,v/an}bracketle{t7,5,0/an}bracketri}ht
4,v/an}bracketle{t7,5,0/an}bracketri}ht
6,v/an}bracketle{t7,5,0/an}bracketri}ht
8,v/an}bracketle{t7,5,0/an}bracketri}ht
9). Similarlyfortheothernodes
at level2 ofthetree.
•P3revisesitsestimateof v/an}bracketle{t0/an}bracketri}ht
5by taking
majority (v/an}bracketle{t0/an}bracketri}ht
5,v/an}bracketle{t5,0/an}bracketri}ht
1,v/an}bracketle{t5,0/an}bracketri}ht
2,v/an}bracketle{t5,0/an}bracketri}ht
4,v/an}bracketle{t5,0/an}bracketri}ht
6,v/an}bracketle{t5,0/an}bracketri}ht
7,v/an}bracketle{t5,0/an}bracketri}ht
8,v/an}bracketle{t5,0/an}bracketri}ht
9). Similarly for the other nodes at
level1 ofthetree.
•P3revisesitsestimateof v/an}bracketle{t/an}bracketri}ht
0bytaking
majority (v/an}bracketle{t/an}bracketri}ht
0,v/an}bracketle{t0/an}bracketri}ht
1,v/an}bracketle{t0/an}bracketri}ht
2,v/an}bracketle{t0/an}bracketri}ht
4,v/an}bracketle{t0/an}bracketri}ht
5,v/an}bracketle{t0/an}bracketri}ht
6,v/an}bracketle{t0/an}bracketri}ht
7,v/an}bracketle{t0/an}bracketri}ht
8,v/an}bracketle{t0/an}bracketri}ht
9). Thisistheconsensusvalue.
14.4.4.3 Correctness
The correctness of the Byzantine agreement algorithm in Fig ure 14.7 can be observed from the
following two informal inductive arguments. Here we assume that theOral_Msg algorithm is
invoked with parameter x, and that there are a total of fmaliciousprocesses. There are two cases
depending on whether the commander is malicious. A maliciou s commander causes more chaos
thanan honestcommander. Thisisthesecond caseconsidered below.
513
<7,5,0> <7,5,0> <7,5,0> <7,5,0>v1 2 4 6 8 9245
<7,5,0>6 <0> <0><0><0>
<0>
v<5,0>
<5,0>
8
v v<5,0>
<7,5,0>8
v7enter afterround 1
v<5,0>
9round 2
round3
round4level 1level 0
level 2
level 3v9<0>
7<0> <0>
v6
4<5,0> <5,0> <5,0>v1v21vv
v v v<>
0v
v vvvvv
Figure 14.8: Local tree at P3for solving Byzantine agreement, for n= 10andf= 3. Only one
branch ofthetreeisshownforsimplicity.
Loyalcommander: Givenfandx, if the commanderprocess is loyal, then Oral_Msg (x)is cor-
rect ifthereare atleast 2f+xprocesses.
Thiscan easilybeseen by inductionon x.
•Forx= 0,Oral_Msg (0)is executed, and the processes simply use the (loyal) com-
mander’s valueas theconsensusvalue.
•Now assumetheaboveinductionhypothesisforany x.
•Then forOral_Msg (x+ 1), thereare 2f+x+ 1processesincludingtheCommander.
Each loyal process invokes Oral_Msg (x)to broadcast the (loyal) commander’s value
v0– here it acts as a commander for this invocation it makes. As t here are 2f+x
processes for each such invocation,by theinduction hypoth esis,there is agreement on
this value (at all the honest processes) – this would be at lev el 1 in the local tree in the
folding of the recursion. In the last step, each loyal proces s takes the majority of the
directorderreceivedfromthecommander(level0entryofth etree),anditsestimateof
the commander’s order conveyed to other processes as comput ed in the level 1 entries
of the tree. Among the 2f+xvalues taken in the majority calculation (this includes
the Commanders’s valuebut not its own), the majorityis loya l becausex>0. Hence,
takingthemajorityworks.
No assumptionaboutcommander: Givenf,Oral_Msg (x)is correct if x≥fand there are a
totalof 3x+ 1ormoreprocesses.
514
This case accounts for both possibilities – the commander be ing malicious or honest. An
inductiveargumentisagain useful.
•Forx= 0,Oral_Msg (0)is executed, and as there are no malicious processes ( 0≥f)
theprocessessimplyusethe(loyal)commander’svalueasth econsensusvalue. Hence
thealgorithmis correct.
•Now assumetheaboveinductionhypothesisforany x.
•ThenforOral_Msg (x+1),thereareatleast 3x+4processesincludingtheCommander
and at most x+ 1are malicious.
–(Loyal commander:) If the commander is loyal, then we can app ly the argument
used for the “loyal Commander” case above, because there wil l be more than
(2(f+ 1) + (x+ 1))totalprocesses.
–(Malicious commander:) There are now at most xother malicious processes and
3x+3totalprocesses(excludingthecommander). Fromtheinduct ionhypothesis,
eachloyalprocesscancomputetheconsensusvalueusingthe majorityfunctionin
theprotocol.
Oral_Msg(k)commandercommander? ?
1
0 0
(a) (b)malicious process correct processOral_Msg(k−1) Oral_Msg(k−1)
Oral_Msg(k)
Figure 14.9: The effects of a loyal or a disloyal commander in a system with n= 14andf= 4.
The subsystems that need to tolerate kandk−1traitors are shown for two cases. (a) Loyal
commander. (b)Noassumptionsaboutcommander.
Illustrationofarguments(Figure14.9): Inpart(a),thecommanderwhoinvokes Oral_Msg(x)
isloyal,soalltheloyalprocesseshavethesameestimate. A lthoughthesubsystemof 3xprocesses
hasxmalicious processes, all the loyal processes have the same v iew to begin with. Even if this
caserepeatsforeachnestedinvocationof Oral_Msg ,evenafterxrounds,amongtheprocesses,the
loyal processes are in a simple majority, so the majority fun ction works in having them maintain
515
thesamecommonviewoftheloyalcommander’svalue. (Ofcour se,hadweknownthecommander
was loyal, then we could have terminated after a single round , and neither would we be restricted
by then >3xbound.) In part (b), the commander who invokes Oral_Msg(x) may be malicious
and can send conﬂicting values to the loyal processes. The su bsystem of 3xprocesses has x−1
maliciousprocesses, butall theloyalprocesses do nothave thesameviewtobeginwith.
Complexity: Thealgorithmrequires f+ 1rounds,an exponentialamountoflocal memory,and
(n−1) + (n−1)(n−2) +...+ [(n−1)(n−2)...(n−f−1)]
messages.
14.4.4.4 Phase-King Algorithm forConsensus: Polynomial( Synchronous System)
The Lamport-Shostak-Pease algorithm requires f+ 1rounds and can tolerate up to f≤⌊n−1
3⌋
malicious processes, but requires an exponential number of messages. The phase-king algorithm
solves the consensus problem under the same model, requirin gf+ 1phases, and a polynomial
number of messages (which is a huge savings), but can tolerat e onlyf <⌈n/4⌉malicious pro-
cesses. The algorithm is so called because it operates in f+ 1phases, each with two rounds, and
auniqueprocess playsan asymmetricalroleasa leaderineac h round.
phase f+1 phase 2 phase 1f+1P
kP1
P0P
Figure14.10: Messagepatternforthephase-kingalgorithm .
ThephasekingalgorithmisgiveninFigure14.11,andassume sabinarydecisionvariable. The
messagepattern isillustratedinFigure14.10.
Round 1: Intheﬁrstround(lines(1b)-(1f))ofeachphase,eachproce ssbroadcastsitsestimateof
theconsensusvaluetoallotherprocesses,andlikewiseawa itsthevaluesbroadcastbyothers.
At the end of the round, it counts the number of ‘1’ votes and th e number of ‘0’ votes. If
eithernumberis greaterthan n/2, thenit setsits majority variabletothat consensusvalue,
and setsmultto the number of votes received for the majority value. If nei ther number is
greater than n/2, which may happen when the malicious processes do not respon d, and the
516
(variables)
boolean:v←−initial value;
integer:f←−maximum number ofmalicious processes, f <⌈n/4⌉;
tree ofboolean :
(1) Eachprocess executes the following f+ 1phases, where f < n/ 4:
(1a)forphase=1tof+ 1do
(1b) Execute the following Round 1actions: // actions inrou nd one of each phase
(1c) broadcast vto allprocesses;
(1d) awaitvaluevjfrom each process Pj;
(1e) majority←−the value among the vjthat occurs > n/2times(default value ifno majority);
(1f) mult←−number oftimes that majority occurs;
(1g) Execute the following Round 2actions: // actions inrou nd twoof each phase
(1h) ifi=phasethen// only the phase leader executes this send step
(1i) broadcast majority to allprocesses;
(1j) receive tiebreaker fromPphase(default value ifnothing isreceived);
(1k) ifmult > n/ 2 +fthen
(1l) v←−majority ;
(1m) elsev←−tiebreaker ;
(1n) ifphase =f+ 1then
(1o) output decision value v.
Figure14.11: Phase-king algorithm–polynomialnumberofu nsignedmessages, n>4f. Codeis
forprocessPi,1≤i≤n.
correct processes are split among themselves, then a defaul t value is used for the majority
variable.
Round 2: In thesecond round (lines (1g)-(1o)) of each phase, the phas eking initiates processing
–thephasekingforphase kistheprocesswithidentiﬁer Pk,wherek∈{1...n}. Thephase
king broadcasts its majority value majority , which serves the role of a tie-breaker vote for
thoseotherprocesseswhichhaveavalueof multoflessthann/2+f. Thus,whenaprocess
receives the tie-breaker from the phase king, it updates its estimate of the decision variable
vto the value sent by the phase king if its own multvariable< n/2 +f. The reason for
this is that among the votes for its own majority value,fvotes could be bogus and hence
it does not have a clear majority of votes (i.e., > n/2) from the non-malicious processes.
Hence, it adopts the valueof the phase king. However, if mult>n/ 2 +f(lines (1k)-(1l)),
then it has received a clear majority of votes from the non-ma licious processes, and hence
it updates its estimate of the consensus variable vto its own majority value, irrespective of
whattie-breaker valuethephasekinghas sent inthesecondr ound.
At the end of f+ 1phases, it is guaranteed that the estimate vof all the processes is the correct
consensusvalue.
Correctness: Thecorrectness reasoningis inthreesteps.
517
1. Amongthe f+ 1phases,thephasekingofsomephase kisnon-maliciousbecausethereare
at mostfmaliciousprocesses.
2. As the phase king of phase kis non-malicious, all non-malicious processes can be seen t o
have the same estimate value vat the end of phase k. Speciﬁcally, observe that any two
non-maliciousprocesses PiandPjcan settheirestimate vin threeways.
(a) BothPiandPjuses their own majority values. Assume Pi’smajority value isx,
which implies that Pi’smult > n/ 2 +f, and of these voters, at least n/2are non-
malicious. This implies Pjmust also have received at least n/2votes forx, implying
that itsmajorityvalue majority mustalsobe x.
(b) BothPiandPjuse the phase king’s tie-breaker value. As Pkis non-malicious it must
havesentthesametie-breakervalueto both PiandPj.
(c)Piuses its majority value as the new estimateand Pjuses the phase king’s tie-breaker
asthenewestimate. Assume Pi’smajority valueisx,whichimpliesthat Pi’smult>
n/2 +f, and of these voters, at least n/2are non-malicious. This implies phase king
Pkmust also have received at least n/2votes forx, implying that its majority value
majority thatit sendsas tie-breakermustalsobe x.
Forallthreepossibilities,anytwonon-maliciousprocess esPiandPjagreeontheconsensus
estimateat theend ofphase k, wherethephaseking Pkisnon-malicious.
3. All non-malicious processes have the same consensus esti matexat the start of phase k+ 1
and they continue to have the same estimate at the end of phase k+ 1. This is self-evident
because we have that n >4fand each non-malicious process receives at least n−f >
n/2+fvotesforxfromtheothernon-maliciousprocessesintheﬁrstroundofp hasek+1.
Hence, allthenon-maliciousprocesses retain theirestima tevoftheconsensus valueas xat
theendofphase k+ 1.
Thesamelogicholdsforall subsequentphases. Hence, theco nsensusvalueiscorrect.
Complexity: The algorithm requires f+ 1phases and two sub-rounds each, and (f+ 1)[(n−
1)(n+ 1)]messages.
14.5 AgreementinAsynchronousMessage-PassingSystemswi th
Failures
14.5.1 Impossibility Result for the Consensus Problem
Fischer, Lynch, and Paterson showed a fundamental result on the impossibilityof reaching agree-
ment in an asynchronous (message-passing) system, even if a single process is allowed to have a
crashfailure. Thisresult,popularlyknownastheFLPimpos sibilityresult,hasasigniﬁcantimpact
518
on the ﬁeld of designing distributed algorithms in a failure -susceptible system. The correctness
proofofthisresult alsointroducedtheimportantnotionof valencyofglobalstates.
For any global state GS, letv(GS)denote the set of possible values that can be agreed upon in
some global state reachable from GS.|v(GS)|is deﬁned as the valencyof global state GS. For a
boolean decision value, a global state can be bivalent, i.e., have a valency of two, or monovalent ,
i.e., having a valencyof one. A monovalentstate GSis1-valentifv(GS) ={1}and it is0-valent
ifv(GS) ={0}. Bivalency of a global state captures the idea of uncertaint y in the decision, as
eithera0-valentora1-valentstatemay bereachablefrom th isbivalentstate.
Inan(asynchronous)failure-freesystem,Section14.3sho wedhowtodesignprotocolsthatcan
reach consensus. Observethattheconsensusvaluecanbesol elydeterminedbytheinputs. Hence,
theinitialstateismonovalent!
In the face of failures, it can be shown that a consensus proto col necessarily has a bivalent
initial state (assuming each process can have an arbitrary i nitial value from{0,1}, to rule out
trivial solutions). This argument is by contradiction. Cle arly, the initial state where inputs are
all 0 is 0-valent and the initial state where inputs are all 1 is 1-valent. Transforming the input
assignments from the all-0 case to the all-1 case, observe th at there must exist input assignments
/vectorIaand/vectorIbthat are 0-valent and 1-valent, respectively,and that differ in the input value of only one
process, say Pi. Ifa 1-failuretolerant consensusprotocolexists,then:
•Starting from /vectorIa, ifPifails immediately, the other processes must agree on 0 due to the
terminationcondition.
•Starting from /vectorIb, ifPifails immediately, the other processes must agree on 1 due to the
terminationcondition.
However, execution (2) looks identical to execution (1), to all processes, and must end with a
consensusvalueof0, acontradiction. Hence, theremustexi stat leastonebivalentinitialstate.
Observethatreachingconsensusrequiressomeformofexcha ngeoftheintialvalues(eitherby
message-passing or shared memory, depending on the model). Hence, a running process cannot
makeaunilateraldecisionontheconsensusvalueThekeyide aoftheimpossibilityresultisthatin
thefaceofapotentialprocesscrash,itisnotpossibletodi stinguishbetweenacrashedprocessand
aprocessorlinkthatisextremelyslow. Hence, fromabivale ntstate,itisnotpossibletotransition
to a univalent state. More speciﬁcally, the argument runs as follows. For a protocol to transition
from a bivalent global state to a monovalent global state, an d using the global time interleaved
modelforreasoningintheproof,theremustexista criticalstep executionthatchangesthevalency
by makingadecisionon theconsensusvalue. Therearetwo pos sibilities.
•Thecriticalstep isaneventthatoccursatasingleprocess. However,otherpr ocessescannot
tell apart the two scenarios in which this process has crashe d, and in which this process is
extremelyslow. Inbothscenarios,theotherprocessescanc ontinuetowaitforeverandhence
theprocessesmay notreach a consensusvalue,remaininginb ivalentstate.
519
•Thecritical step occurs at two or moreindependent (i.e., not send-receivere lated) events at
different processes. However, as independent events at dif ferent processes can occur in any
permutation,the criticalstep isnotwell-deﬁnedandhencethispossibilityisnotadmissi ble.
Thus,startingfromabivalentstate,itisnotpossibletotr ansitiontoamonovalentstate. Thisisthe
keyto theimpossibilityresultforreaching consensusinas ynchronoussystems.
The impossibility result is signiﬁcant because it implies t hat all problems to which the agree-
ment problem can be reduced are also not solvable in any async hronous system in which crash
failures may occur. As all real systems are prone to crash fai lures, this result has practical sig-
niﬁcance. We can show that all the problems, such as the follo wing, requiring consensus are not
solvablein thefaceofevenasinglecrash failure.
•theleaderelectionproblem.
•thecomputationofa network-sideglobalfunctionusingbro adcast-convergecast ﬂows.
•terminatingreliablebroadcast.
•atomicbroadcast.
Thecommonstrategyistouseareductionmappingfromthecon sensusproblemtotheproblem X
underconsideration. Weneedtoshowthatusinganalgorithm tosolveX,wecansolveconsensus.
But as consensusisunsolvable,somustbeproblem X.
14.5.2 Terminating Reliable Broadcast
As an example, consider the Terminating Reliable Broadcast problem which states that a correct
processalwaysgetsamessageevenifthesendercrasheswhil esending. Ifthesendercrasheswhile
sending the message, the message may be a null message but it m ust be delivered to each correct
process. The formal speciﬁcation of Reliable Broadcast was studied in Chapter 3; here we have
theadditionalterminationconditionwhichstatesthateac h correct processmusteventuallydeliver
somemessage.
Validity: Ifthesenderofabroadcastmessage misnonfaulty,thenallcorrectprocesseseventually
deliverm.
Agreement: If acorrect process deliversamessage m, thenall correct processes deliver m.
Integrity: Each correct process delivers at most one message. Further, if it delivers a message
differentfrom thenullmessage, thenthesendermusthavebr oadcastm.
Termination: Everycorrect process eventuallydeliverssomemessage.
520
The reduction from consensus to TerminatingReliable Broad cast is as follows. A commander
process broadcasts its input value using the Terminating Re liable Broadcast. A process decides
on a ‘0’ or ‘1’ depending on whether it receives ‘0’ or ‘1’ in th e message from this process.
However, if it receives the null message, it decides on a defa ult value. As the broadcast is done
using the Terminating Reliable Broadcast, it can be seen tha t the conditions of the consensus
problem(Section14.1.1)aresatisﬁed. Butasconsensusisn otsolvable,analgorithmtoimplement
TerminatingReliableBroadcast cannotexist.
14.5.3 Distributed TransactionCommit
Database transactions require the Commitoperation to preserve the ACID properties (atomicity,
consistency,integrity,durability)oftransactionalsem antics. The commitoperationrequirespolling
allparticipantswhetherthetransactionshouldbecommitt edorrolledback. Evenasinglerollback
vote requires the transaction to be rolled back. Whatever th e decision, it is conveyed to all the
participantsinthetransaction. Clearly,thiscanbeseent obeaconsensusproblem. Exercise5asks
youto formallyprovethatdistributedcommitis notsolvabl eunderacrash failure.
Despitetheunsolvabilityofthedistributed commitproblemundercrash failure,the(blocking)
two-phasecommitandthenon-blockingthree-phasecommitp rotocolsdosolvetheproblem. This
is because the protocols use a somewhat different model in pr actice, than that used for our theo-
retical analysis of the consensus problem. The two-phase pr otocol waits indeﬁnitely for a reply,
and it is assumed that a crashed node eventually recovers and sends in its vote. Optimizations
such aspresumed abort andpresumedcommit are pessimisticandoptimisticsolutionsthatare not
guaranteed to be correct under all circumstances. Similarl y, the three-phase commitprotocol uses
timeouts to default to the ‘abort’ decision when the coordin ator does not get a reply from all the
participantswithinthetimeoutperiod.
14.5.4k-setconsensus
Although consensus is not solvable in an asynchronous syste m under crash failures, a weaker
version,knownasthe k-setconsensus problem,issolvableas longasthenumberofcrash failures
fis less than the parameter k. The parameter kindicates that the nonfaulty processes agree on
differentvalues,as longas thesizeoftheset ofvaluesagre ed uponisbounded by k.
Assumingthattheconsensusvalueisfromamulti-valueddom ain,theproblemspeciﬁcationis
as follows.
k-Agreement: All non-faulty processes must make a decision, and the set of values that the pro-
cesses decideoncan contain upto kvalues.
Validity: Ifanon-faultyprocess decideson somevalue,thenthat valu emusthavebeen proposed
bysomeprocess.
Termination: Each non-faultyprocessmusteventuallydecideona value.
521
(variables)
integer:v←−initialvalue;
(1)A process Pi,1≤i≤n, initiatesk-set consensus:
(1a)broadcastvtoall processes.
(1b)awaitvaluesfrom|N|−fprocesses and addthem toset V;
(1c)decideonmax(V).
Figure14.12: Protocol for k-setconsensus. Codeshownisforprocess Pi,1≤i≤n.
Thek-Agreement condition is new, the Validity condition is diff erent from that for regular con-
sensus,and theTerminationconditionis unchanged from tha tfor regularconsensus. Theprotocol
in Figure 14.12 can be seen to solve k-set consensus in a straightforward manner, as long as the
numberofcrash failures fislessthank.
14.5.5 Approximate Agreement
Another weaker version of consensus that is solvablein an as ynchronous system under crash fail-
ures is known as the approximate consensus problem. Like k-set consensus, approximate agree-
ment also assumes the consensus value is from a multi-valued domain. However, rather than
restrictingtheset ofconsensusvaluestoaset ofsize k,ǫ-approximateagreement requires thatthe
agreeduponvaluesbythenonfaultyprocessesbewithin ǫofeachother. Theproblemspeciﬁcation
isas follows.
ǫ-Agreement: Allnon-faultyprocessesmustmakeadecisionandthevalues decideduponbyany
twonon-faultyprocesses mustbewithin ǫrangeofeach other.
Validity: If a non-faulty process Pidecides on some value vi, then that value must be within the
rangeofvaluesinitiallyproposedby theprocesses.
Termination: Each non-faultyprocessmusteventuallydecideona value.
14.5.5.0.1 Algorithm Outline. The Dolev et al. algorithm to solve approximate agreement in
themessage-passingmodelisstudiednext. Thealgorithmfo rthemessage-passingmodelassumes
n≥5f+ 1,althoughtheproblemissolvablefor n>3f+ 1.
The asynchronous approximate agreement algorithm simulat es synchronous communication
by operating in rounds. The algorithm in given in Figure 14.1 3. Steps (1a)-(1c) perform the
initialization computation to decide the number of synchro nous rounds to be simulated. We will
examine this logic after examining the rest of the algorithm . The main loop, in lines (1d)-(1f),
performs an all-to-all message exchange asynchronously fo r the determined number of rounds.
In each round (simulated by Asynchronous_Exchange ), a process broadcasts its estimate of the
agreement value,andawaits n−fsuchmessages fromotherprocessesbeforemovingtothenext
522
(variables)
real:v←−input value; //initial value
multiset ofreal V;
integer r←−0; //number of rounds toexecute
(1) Execution atprocess Pi,1≤i≤n:
(1a)V←−Asynchronous _Exchange (v,0);
(1b)v←−anyelement in (reduce2f(V));
(1c)r←−⌈logc(diff(V))/ǫ⌉, where c=c(n−3f,2f).
(1d)forroundfrom1tordo
(1e) V←−Asynchronous _Exchange (v,round );
(1f) v←−new2f,f(V);
(1g)broadcast (∝a\}⌊ra⌋k⌉tl⌉{tv,halt∝a\}⌊ra⌋k⌉tri}ht,r+ 1);
(1h)output vasdecision value.
(2)Asynchronous_Exchange(v,h) returns V:
(2a)broadcast (v,h)toall processes;
(2b)await n−fresponses belonging to round h;
(2c) for each process Pkthat sent∝a\}⌊ra⌋k⌉tl⌉{tx,halt∝a\}⌊ra⌋k⌉tri}htasvalue, use xasits input henceforth;
(2d)returnthemultiset V.
Figure14.13: Asynchronousapproximationagreement algor ithm. Here, n≥5f+ 1.
round. After each round, each process revises its estimate o f the consensus value. The estimate
is revised in such a way that the choices of the different proc esses are guaranteed to converge at a
certain rate.
Consider any sorted collection U. The new estimate of a process is chosen by computing
new k,f(U), whichis parameterized by kandf, and deﬁned as mean(select k(reducef(U)))
reducef(U)removesthe flargestandfsmallestmembersof U.
select k(U)selects every kth member of U, beginning with the ﬁrst. If Uhasmmembers,
select k(U)hasc(m,k) =⌊(m−1)/k⌋+ 1members. This constant crepresents a con-
vergence factor towards the ﬁnal agreement value, i.e., if xis the range of possible values
held by correct processes before a round, then x/cis the possible range of estimate values
heldby thoseprocesses afterthat round.
Illustration of deﬁnitions: Figure 14.14 shows the select k(reducef(U))operation, with k= 5
andf= 4. Themean oftheselected membersis thenew estimate new5,4(U).
Thealgorithmuses m=n−3fandk= 2f. Soc(n−3f,2f)willrepresent the convergence
factortowardsreaching approximateagreement and new2f,fis the new estimateafter each round.
Thechoiceoftheseparameters willbejustiﬁed.
14.5.5.0.2 Notation. The algorithm uses multisets, which are sets with repeating elements in-
cluded. Union,intersection,andsetdifferenceoperation sonmultisetsarenaturalextensionsofthe
523
u u u u u15 50 10 25 20
select  (reduce  (U))54 shaded members belong to k=5f=4 reduce  (U)f
uU
Figure 14.14: Illustrating select k(reducef(U)), withk= 5andf= 4.reduce4(U)has 26
members,hence c(26,5) = 6membersare selected.
counterpartsforregularsets. mean(U)isthearithmeticmeanof U,calculatedbyconsideringeach
instance in the multiset. min(U)andmax(U)are deﬁned as for sets. range (U)is the interval
[min(U),max(U)].diff(U)ismax(U)−min(U).
Some essential combinatorial results are ﬁrst proved. Let |U|=m, and let the melements
u0...u m−1of multisetUbe in nondecreasing order. The following properties on none mpty mul-
tisetsU,V, andWcan easilybeseen.
Property 1. The number of the elements in multisets UandVis reduced by at most 1 when the
smallestelement isremovedfromboth. Similarlyforthelar gestelement.
Property 2. The number of elements commonto UandVbefore and after jreductions differby
atmost 2j. Thus,forj≥0and|V|,|W|≥2j,|V∩W|−|reducej(V)∩reducej(W)|≤2j.
Property 3. LetVcontainatmost jvaluesnotin U,i.e.,|V−U|≤j,andletsizeof Vbeatleast
2j. Thenbyremovingthe jlowandjhighelementsfrom V,itiseasytoseethatremaining
elementsin Vmustbelong totherangeof U, seeFigure14.15. Thus,
•each valuein reducej(V)isintherangeof U, i.e.,range (reducej(V))⊆range (U).
•new k,j(V)∈range (U).
14.5.5.0.3 Convergence Rate of Approximation. LetUbe the multiset of estimates, one es-
timate per correct process, at the start of a round. Let VandWbe the multisets received at two
arbitrary correct proceses in that round. The processes use the approximation function to choose
their values for the next round. The new estimates chosen by a ny two arbitrary correct processes,
using the approximation function new k,f, are guaranteed to be within range (U)/c(m,k)of each
other, when(i)|V|=|W|=m, (ii)|W−V|,|V−W|≤kand (iii)(|V−U|,|W−U|≤f.
524
Convergence Rate. Letk >0,f≥0, andm>2f. For the multisetsreceived, |V|=|W|=m.
Letthemultisetsreceiveddifferfrom Uinatmostfelements(|V−U|,|W−U|≤f),andlet
themultisetsreceiveddifferfromeachotherinatmost kelements(|W−V|,|V−W|≤k).
Then
|new k,f(V)−new k,f(W)|≤diff(U)/c(m−2f,k) (14.1)
Theproofofthisrelationshipisoutlinednext. Thereareex actlym−2fmembersineachof M=
reducef(V)andN=reducef(W). Hence,select k(M)={m0,m1...m c−1}andselect k(N)=
={n0,n1...n c−1}, whereselect k(M)andselect k(N)each havec=c(m−2f,k)members.
Observe that (i) at least ki+ 1members of Mare less than or equal to any mi(likewise for N).
Also,(ii)atmost kimembersof Marelessthan mi(likewisefor N). Thefollowingcanbeshown
usingtheearlier propertiesand deﬁnitions.
max(mi,ni)≤min(mi+1,ni+1),where 0≤i≤c−2. (14.2)
Thisdirectlyfollowsif mi≤ni+1andni≤mi+1can beshown.
V
U
W
range(reduce   (W))frange(U)
new    (V)k,fnew    (W)k,f
<=diff(U) / c(m−2f,k)range(reduce   (V))f
Figure 14.15: Illustrating Property 3 for the ǫ-agreement problem. |V|=|W|=m,|V−W|=
|W−V|=k, and|V−U|,|W−U|≤f. Note that the horizontal spacing in the ﬁgure shows
onlytherelativepositioningofelementsinthesortedmult isetsand need notbetoscale.
Assume to the contrary that mi>ni+1. From (i), at least k(i+ 1) + 1 elements of Nare less
thanorequalto ni+1,andhencelessthan mi. Butfrom(ii),atmost kielementsof Marelessthan
mi. Hence, atleast k+ 1elementsin Narenot inM, i.e.,|N−M|≥k+ 1.
Observe that|W−V|≤kand|W∩V|≥m−k. Using Property (2), This implies that
|N∩M|≥m−k−2fand hence|N−M|≤(m−2f)−(m−k−2f)≤k. Thiscontradicts
theconclusionoftheassumptionabout mi>ni+1. Hence,mi≤ni+1. Symmetrically, ni≤mi+1
525
can beshown. So Equation(14.2)holds.
|new k,f(V)−new k,f(W)|=1
c|c−1/summationdisplay
i=0(mi−ni)|≤1
cc−1/summationdisplay
i=0|mi−ni|=1
cc−1/summationdisplay
i=0(max(mi,ni)−min(mi,ni))
UsingEquation14.2intheR.H.S., expandingterms,and simp lifying:
|new k,f(V)−new k,f(W)|≤1
c(max(mc−1,nc−1)−min(m0,n0))
UsingProperty 3, max(mc−1,nc−1)−min(m0,n0)≤range (U)and Equation(14.1)follows.
14.5.5.0.4 Correctness. LetT, the set of correct processes, be such that |T|≥n−f. Let
UandU′be the multiset of estimates (one estimate from each process ) before and after some
roundh.|V|=|W|=n−f. Also,|V−U|,|W−U|≤fbecause at most fprocesses are
faulty.|V∩W|≥n−3fbecause both pandqwould have received the same values from the
correct processes from which both received messages. Hence , the difference between VandW
|V−W|=|W−V|=|V|−|V∩W|≤2f(the upper bound on this was denoted as kin
Equation14.1). Then, wehavethefollowing.
•ǫ-agreement.|new2f,f(V)−new2f,f(W)|≤diff(U)/c(n−3f,2f). This immediately
followsby observingthat themultisets U,V, andWsatisfy Equation14.1 when misset to
n−fandkis setto 2f,and hencec(m−2f,k)becomesc(n−3f,2f).
Thisinequalityimpliesthat therangeof themultisetofest imates chosen byall processes in
Treduces by afactorof c(n−3f,2f). This≥2asthealgorithmassumesthat n≥5f+ 1.
Hence, after a logarithmicnumberofiterations (determine d in lines(1a)-(1c) and described
below),thisrangereduces tobelow ǫ.
•Validity.range (U′)⊆range (U). As the multisets UandVsatisfy Property 14.5.5.0.2,
we havethat new2f,f(V)∈range (U). For each round, it can be seen that the valueofeach
correct process is within the range of the values of the corre ct processes at the start of the
ﬁrst round.
Initialization (lines 1a-1c): The upper bound on the number of iterations is determined in t he
initialization phase, in lines (1a)-(1c). Let the multiset s of estimates received by two arbitrary
correct processes PpandPqafter line (1a) be VpandVq.|Vp|,|Vq|>4fbecausen≥5f+ 1;
and|Vp−Vq|,|Vq−Vp|≤2f(shown above). We can apply Property 2 to both VpandWqwith
respect to each other(and by setting j= 2f)– toget that range (reduce2f(Vp))⊆range (Vq)and
range (reduce2f(Vq))⊆range (Vp).
It follows that vp∈range (Vq)andvq∈range (Vp)after line (1b). This guarantees that each
correct process Pqknows at the end of the initialization round that its range range (Vq)contains
allthe valuesvpof all correct processes Ppat the end of this initialization round. Knowing ǫand
the convergence rate c,epsilon≥[diff(V)/cround]and hence it is adequate to execute round=
526
⌈logc(diff(V)/ǫ)⌉rounds. Hence, thenumberofrounds computedin line(1c) is a n upperbound
on the number of iterations in which every two correct proces ses are guaranteed to converge to
withinǫ.
Termination(lines1g-1h): Observethateachprocessmaydetermineadifferentnumbero frounds
toexecuteatline(1c). Whenaprocessﬁnishestherequiredn umberofrounds,itexecutes(lines1g-
1h)whereinitsendsaspecialsymbol“ halt”andterminatesitself. Whensomeprocess Pqreceives
suchamessagefrom Pp,itshouldusethevalueof Pqforthisandallofitssubsequentroundsuntil
it ﬁnishes its own precomputed number of rounds. This detail is left out of the pseudo-code for
simplicity.
14.5.5.0.5 Complexity
Timecomplexity: ⌈logc(diff(V)/ǫ)⌉+ 1rounds.
Messagecomplexity: n×[⌈logc(diff(V)/ǫ)⌉+ 1]messages ofsize O(1)each.
14.5.6 Renaming Problem
Problem Deﬁnition
The consensus problem which was a problem about agreement re quired the processes to agree on
a single value, or a small set of values ( k-set consensus), or a set of values close to one another
(approximate agreement), or reach agreement with high prob ability (probabilistic or randomized
agreement). A different agreement problem introduced by At tiya et al. requires the processes
to agree on necessarily distinct values. This problem is ter med as the renaming problem. The
renaming problem assigns to each process Pi, a namemifrom a domain M, and is formally
speciﬁed as follows.
Agreement: Fornonfaultyprocesses PiandPj,mi∝\⌉}atio\slash=mj.
Termination: Each nonfaultyprocess is eventuallyassigned aname mi.
Validity: ThenamemibelongstoM.
Anonymity: Thecodeexecutedbyany processmustnotdepend onitsinitia lidentiﬁer.
The renaming problem is useful for name space transformatio n. A speciﬁc example where this
problemarises iswhen processes fromdifferent domainsnee d to collaborate,butmustﬁrst assign
themselvesdistinctnamesfromasmalldomain. Asecondexam pleoftheuseofrenamingiswhen
processes need to use their names as “tags” to simply mark the ir presence, as in a priority queue.
A third example is when the name space has to be condensed. Thi s can occur when, for a system
consistingofalargenumberofprocesses, k-mutualexclusionhastobeenforced. Ofthelargepool
of processes, only kcan be in the mutual exclusion at any time to use the kcopies of a replicated
resource. Each resource can be viewed as holding a permit, 1 t hroughk. For a process to gain
access to theresource, ithas togainapermit.
Theassumptionsabouttherenamingproblemareas follows.
527
•ThenprocessesP1...P nhave their identiﬁers in the old name space. Piknows only its
identiﬁer,andthetotalnumberofprocesses, n. Thenamesofotherprocessesarenotknown
toaprocess.
•Thenprocesses takeon newidentiﬁers m1...m n, respectively,from thenamespace M.
•Duetoasynchrony,each processthatchoosesitsnewnamemus tcontinuetocooperatewith
theothersuntiltheyhavechosen theirnewnames.
The above formulation of the renaming problem is called the one-time renaming problem.
If processes continually acquire and release names from a co mmon pool, then the formulation
becomesthe long-livedrenaming problem. Long-livedrenaming isaresourceacquisitionproblem.
name rank
< f+2pick new name
based on rank
as own nameV arrivesV not
same as
MRVcount=0
V=MRV
No
Yes
Yes YesNobroadcast own 
name as Most
Recent View (MRV)
decide MRV as name and help others to decideNoS
T
A
R
T
conflictcount++
> n−fcountMRVnew view
Figure14.16: Flow-chartoftheasynchronousrenamingalgo rithmin amessage-passingsystem.
Algorithm
Figure 14.17 gives Attiyaet al.’s algorithm for one-time re naming when n≥2f+ 1, and up tof
processes mayfail inafail-stopmanner. Thesizeofthetran sformednamespace Misn+f.
The high-level functioning of the algorithm is given in Figu re 14.16. Each process has a list
Viewin which it tracks the latest proposed name by each process, a s and when it learns of it. Its
own proposed name is tracked in View[1]. In more details, the view of a name has four compo-
nents, as described in the Viewdata structure in Figure 14.17. Viewis a list of up to nobjects of
typebid. Variousviewsareordered bythe ≤relation,deﬁned as follows.
•View≤View′if and only if for each process Pisuch thatView[k].P=Pi, we also have
thatforsome k′,View′[k′].P=PiandView[k].attempt≤View′[k′].attempt.
IfView′∝\⌉}atio\slash≤View(line1n),then Viewisupdated using View′(line1o)by:
1. including all process entries from View′that are missing in View(i.e.,View′[k′].Pis not
equal toView[k].P,forallk), sosuch entries View′[k′]are added to View.
528
2. replacing older entries for the same process with more rec ent ones, (i.e., if View′[k′].P=
Pi=View[k].PandView′[k′].attempt>View [k].attempt,replaceView[k]byView′[k′]).
Any new information learnt is broadcast to all processes (li nes 1c, 1v), and a process uses a
countercountto track the number of other processes that have broadcast th e exact same view as
thelatestviewofthisprocess(line1k). Iftheviewinarece ivedmessagecontainsinformationthat
isnotinthecurrentview(line1n),thecurrentviewisupdat ed(line1o). Notethatthisissimilarto
taking the pairwise maximum of vector clocks. However, a cru cial difference is that the ordering
ofthecomponentsisnotpredetermined,aseachprocessmayo rdertheotherprocessesdifferently.
Whencountreachesn−f(line 1l), no more messages may arrive because the other fprocesses
mayhavefailed. Such aviewforwhich n−fafﬁrmationswerereceived issaid bea stableview .
Once a process determines a view to be stable (lines 1m, 1q), t he process checks if there is a
conﬂict with its choice of a new name and the choices of other p rocesses (lines 1r, 1s). If there
is no conﬂict, it ﬁnalizes its choice of the new name (lines 1t , 1u) and goes to the loop (lines
1G-1K)wherein it helps otherprocesses to gain stableviews and ﬁnalize theirnew namechoices.
If there is a conﬂict (lines 1w-1F), a new name must be chosen o nce again and competed with
other processes. There are two cases here, depending on the rankof the process among all the
processes that have not yet ﬁnalized their new names (i.e., a mong all processes except those for
whichView[j].decide = 1). Letthesetofsuchprocessesbedenotedas UNDECIDED (View).
Clearly, as thenew names of such processes are not ﬁnalized, the rank is determined based on the
oldnames (line1x).
•If therankris less than f+ 2(line 1y), the process chooses the rth free name from
FREE (View), the “free” names from Mthat have not been ﬁnalized by the processes
(whichhavetheir decidecomponentsetto1in View). Theprocesshastorestartthebidding
process,by goingback tostep (1a), broadcastingitsupdate dview(line1c), and soon.
•If therankrexceedsf+ 1(lines 1C,ID), the process goes to line (1e) and then waits fo r
some other process to send its updated views. The logic here i s that at least one correct
processwillhavearankupto f+ 1amongUNDECIDED ,andwillpickandstabilizeits
newnamebeforeprocesses withrank greaterthan f+ 1beginto competeforanew name.
Somedeﬁnitionsand propertiesarenowgiven.
P1.An algorithmis locallyproper ifforeach runandeach process, thesequenceofthe Viewlist
istotallyorderedby ≤. ThealgorithminFigure14.17isseentobelocallyproper,f romlines
(1j)-(1o).
P2.A view is stable with respect to a process if the process has received n−f−1messages
containing identical information in the accompanying view . (Along with its own identical
view, there are n−fafﬁrmations.) A view is stable in a run if it is stable with respect to
someprocess.
529
(localvariables)
struct bid:
integer P; // oldnameofprocess
integer x; // newnamebeingbidbytheprocess
integer attempt; // the numberofbidsso far,includingthiscurrentbid
boolean decide; // whethernewname xisﬁnalized
list ofbid :V iew[1. . .n]←−∝a\}⌊ra⌋k⌉tl⌉{t∝a\}⌊ra⌋k⌉tl⌉{t i,0,0, false∝a\}⌊ra⌋k⌉tri}ht∝a\}⌊ra⌋k⌉tri}ht; // initialize list withanentryfor Pi
integer count; // numberofcopiesofthelatest localview,receivedfromo thers
boolean:restart,stable,no_choose; // loopcontrolvariables
(1)Aprocess Pi,1≤i≤n,participatesin renaming:
(1a)repeat
(1b) restart←−false;
(1c)broadcast message (V iew);
(1d) count←−1;
(1e)repeat
(1f) no_choose←−0;
(1g) repeat
(1h) await message (V iew′);
(1i) stable←−false;
(1j) ifV iew′=V iewthen
(1k) count←−count + 1;
(1l) ifcount≥n−fthen
(1m) stable←−true;
(1n) else if V iew′∝\⌉}atio\slash≤V iewthen
(1o) update V iewusingV iew′bytakinglatest informationforeachprocess;
(1p) restart←−true;
(1q) until(stable =trueorrestart =true); // n−fcopiesreceived,ornewviewobtained
(1r) ifrestart =falsethen//V iew[1]hasinformationabout Pi
(1s) ifV iew[1].x∝\⌉}atio\slash= 0andV iew[1].x∝\⌉}atio\slash=V iew[j].xforany jthen
(1t) decide V iew[1].x;
(1u) V iew[1].decide←−true;
(1v) broadcast message (V iew);
(1w) else
(1x) let rbethe rankof PiinUNDECIDED (V iew);
(1y) ifr≤f+ 1then
(1z) V iew[1].x←−FREE (V iew)(r), therth freenamein V iew;
(1A) V iew[1].attempt←−V iew[1].attempt + 1;
(1B) restart←−1;
(1C) else
(1D) no_choose←−1;
(1E)untilno_choose = 0;
(1F)untilrestart = 0;
(1G)repeat
(1H) onreceiving message (V iew′)
(1I) update V iewwithV iew′ifnecessary;
(1J) broadcast message (V iew);
(1K)untilfalse.
Figure 14.17: Asynchronous renaming in the message passing model. Code shown is for process
Pi,1≤i≤n.
530
P3.If an algorithmislocallyproper, then inanyrun, thesetofs tableviewsis totallyordered.
Thisisseen asfollows. Letviews ViewandView′bestablewithrespect toprocesses iand
j,respectively. Then n−fprocesses(say,set Ai)agreeonView,andn−fprocesses(say,
setAj)agree onView′.
IfViewandView′arenottotallyordered, Ai∩Aj=∅. Disjointnessimpliessizeof Ajisat
mostn−(n−f) =f. Thus,n−f≤f,implying,n≤2f. Thiscontradictstheassumption
thatn≥2f+ 1,hence, atleastoneprocessmusthavesentboth ViewandView′. SoView
andView′mustbetotallyordered.
P4.As thealgorithminFigure14.17is locallyproper, itssetof stableviewsis totallyordered.
Correctness
Safety:A process ﬁnalizes a new name once it has a stable view. PiandPjcannot ﬁnalize the
samenamebecausethestableviewsaretotallyordered. With outlossofgenerality,assumethat Pi
stableview≤Pj’s stableview when they respectivelyﬁnalize their names. T henPj’s stable view
mustincludethenameﬁnalized by Pi, andPjwillnotpickthesamename.
Liveness/Termination: Observe that when a process picks a new name (line 1z), there a re at
mostn−1names used by others, so f+ 1names are available. To show that all processes
eventually ﬁnalize a name, let FREE (View)be the set of free names from Mas perView. Let
DECIDED be the set of processes that ﬁnalize their new names (i.e., fo r whichbid.decide is
true). Then N−DECIDED isUNDECIDED , the set of processes which cannot ﬁnalize a
newname. Wenowargue usingcontradictionthat UNDECIDED is empty.
•Consider the execution after the time that all processes in DECIDED have decided their
new names, and at least one bid sent by every other correct pro cess has been received by
eachcorrectprocess,implyingthat |View|≥n−f. Asnocorrectprocessblocks,thispoint
intimewilloccur. Let View minbethesmalleststableviewafterthispointintime. By (P4),
all the views are totally ordered and hence View minis uniquely deﬁned. Let the set of free
names at this time be denoted as FREE (View min)and the set of undecided processes at
thistimebedenotedas UNDECIDED (View min).
•Among the processes in UNDECIDED (View min), consider the process Pminwith the
smallestrank, based on the old names. The rank is at most f+ 1, and hence the pro-
cess will select a new name (lines (1y, 1z, 1A)). As rankis unique, no other process in
UNDECIDED (View min)willnoworhenceforth choosethisnamechosenby Pmin.
•Pminupdates and broadcasts its view. When other processes recei ve this view, they update
theirlocal viewswiththisnewinformation,and willalsobr oadcast theirupdatedviews
–eitherin theloop(lines 1G-1K),or
–viaexecutionoflines(1C-1D), thenlines(1n-1o), and then (1b-1c).
531
(variables)
boolean:clean←−1; //variable ateach process
(1) Process P0initiates Reliable Broadcast:
(1a)broadcast message Mtoall processes.
(2) Aprocess Pi,1≤i≤n,receives message M:
(2a)ifcleanthenbroadcast Mtoall processes;
(2b)clean←−0.
Figure14.18: Protocolfor reliablebroadcast.
Pminand all other correct processes receive at least n−fconﬁrmations, making the view
containingPmin’schoiceofanewnameastableview. Hence, Pmincan decideanewname,
leadingtoa contradictionthat UNDECIDED (View min)isempty.
Complexity: Each time a process bids with a new name for itself, a broadcas t is sent (n−1
messages) and each recipient of the broadcast, seeing as new view, also does a broadcast ( n−1
messages). This leads to O(n2)messages per new name bid. Let the ﬁnal stable view be denoted
byView final. Thetotalnumberofmessagesis Σn
i=1View final.attempt i×n2. Exercise9asksyou
toanalyze theboundon thenumberofattemptsmadebytheproc esses.
14.5.7 Reliable Broadcast
Although Reliable Terminating Broadcast (RTB) is not solva ble under failures (recall that we
showed a reduction from consensus to that problem), a weaker version of RTB, namely Reliable
Broadcast, in which the Termination condition is dropped, i s solvable under crash failures. The
protocolisshowninFigure14.18. Thisprotocolusesup to O(n2)messagestobroadcastmessage
Mandworksinthefaceofanynumberoffailures. Thekeydiffer encebetweenRTBandReliable
Broadcast is that RTB requires eventual delivery of some mes sage – even if the sender fails just
when about to broadcast. In this case, a null message must get sent, whereas this null message
need not be sent under Reliable Broadcast. Thus, RTB require s the recognition of the failure (as
describedabove)asopposedtonomessagegettingsent. This reduces totheabilityofdistinguish-
ing between a slow process and a failed process, which was the crux in solving the consensus
problemundercrash failure.
532
14.6 Wait-freeSharedMemoryConsensusinAsynchronousSys -
tems
14.6.1 Impossibility Result
The impossibility of achieving consensus in asynchronous m essage-passing systems in a system
proneto crash failures (discussed in Section 14.5.1)also e xtends to asynchronousshared memory
systems. A shared memory system can be emulated by a message- passing system – if consensus
couldbereachedinasharedmemorysystem,itcouldalsobere achedinamessage-passingsystem,
leadingtoacontradiction. Thus,consensuscannotbereach ed inan asynchronousshared memory
system in the crash failure model. The intuitionbehind the i mpossibilityresult in shared memory
systemsissimilar–inthefaceofapotentialprocesscrash, itisnotpossibletodistinguishbetween
a crashed process and a process that is extremely slow in doin g itsReadorWriteoperation. The
FLPargumentusing0-valentand1-valentstatesandthe criticalstep usedearlierforasynchronous
message-passing systems can also be used here for asynchron ous shared memory systems. The
reasoningto showthatconsensuscannot beachievedevenifa singleprocess fails runsinformally
alongthefollowinglines.
i i ij
zX
i
0−val 0−val 1−val 1−valZY
Figure14.19: Executionpreﬁx usedto showimpossibilityof 1-failuretolerantconsensus.
Assume there exists a protocol in which consensus can be reac hed even if a single process
fails. Recall from Section 14.5.1 that there exists a bivale nt initial state. Due to the termination
requirementoftheproblem,theremustexistsomeprocess ithatmakesatransitionfromabivalent
statetoanunivalentstateeveniftherearenofailures. (Fo rawait-freeconsensus,thisisalsotrue.)
So there must be some execution preﬁx Xthat is bivalent, but from which a step by imakes it 0-
valent,whereasastepby iafteranextension YofXleadstoa 1-valentstate. (SeeFigure14.19.) If
therearemultipleeventsbetween XandY,thentheremustbeapreﬁx Zsuchthatastepby ileads
to0-valence but a step by another process j(j∝\⌉}atio\slash=ias processes are assumed to be deterministic)
followedbyastep by ileads to 1-valence.
Theargument nowuses asimplecase analysisbased on theacti onsofiandjafterZ, toshow
that theconﬁguration of Zas shown in Figure14.19 is impossible,showingtheimpossib ilityof a
1-failure consensusprotocol. Thenotation extend (Z,i◦j)denotes thestateafter processes iand
jtakestepsinthat order, afterexecution Z.
533
Processi’s event isa Read. (See Figure14.20(a).) Thenextend (Z,i◦j)andextend (Z,j◦i)
are identicaltoall processes except i. Ifidoes nottakeany stepafter extend (Z,i◦j),then
all process must eventually terminate with consensus on 0 wh ile executing a sufﬁx, say δ.
But if the same sufﬁx is executed after extend (Z,j◦i), they must reach a consensus on 1.
Asextend (Z,i◦j)andextend (Z,j◦i)are isomorphicto all processes except thestopped
processi, wehaveacontradiction.
Processj’s eventis aRead. Thestatesafter extend (Z,i)andextend (Z,j◦i)areidenticaltoall
processes except j. The same logic as for the previous case, this time letting jstop instead
ofi, leadsto asimilarcontradiciton.
Processesiandjexecute Writeondifferent variables. (See Figure14.20(b) ).Thesystemstate
afterextend (Z,i◦j)whichis0-valentisthesameasthesystemstateafter extend (Z,j◦i),
which is 1-valent. There now arises a contradiction, irresp ective of whether all processes
decideon0 oron1.
Processesiandjexecute Writeonthesamevariable. (See Figure14.20(c)). Thesystemstate
afterextend (Z,i)andextend (Z,j◦i)areidenticaltoallprocessesexcept j. Ifallprocesses
exceptjrun afterextend (Z,i), theconsensus valuemustbe 0. If all processes except jrun
afterextend (Z,j◦i), theconsensusvaluemustbe1. As extend (Z,j◦i)andextend (Z,i)
areisomorphictoall processesexcept thestoppedprocess j, wehaveacontradiction.
Hence, therecannot existany bivalentstatethatallowsany process togo aunivalentstate.
Read
Read
by ij
j0−val
0−val 0−valZ Z Z
0−val 0−valWrite
WriteWrite
WriteWrite Write
by
byi
iby
iby i by j
Write
by jby j by i
(a) i does a Read
different variables(c) i and j write to
the same variable(same logic if 
j does a Read)0−val
all processes
except i all processes1−val 1−val
except j
(b) i and j write to 
Figure 14.20: Various cases to show impossibility of 1-fail ure tolerant consensus in the asyn-
chronousmessage-passingmodel.
534
The key reason why this result for the 1-failure case is diffe rent from that for the failure-free
caseisthatthe1-failurecaseallowsforabivalentinitial state,whereastheinitialstateforafailure-
free executionisunivalent.
Between the time a process reads various registers and (deci ding on a consensus value) writes
its consensus value, the values of the other registers read c an get updated by other processes.
Herein lies the difﬁculty for shared memory systems – the rea ds and the writes are not together
guaranteed to be an atomic action – and hence taking action ab out deciding a consensus value,
independent of processes that are “suspected" to have faile d, can lead to an erroneous decision on
consensus. Hence, from a bivalent state, it is not possible t o transition to a univalent state. This
leads tothefollowingtworesults– thesecond onefollowstr iviallyfromtheﬁrst.
•Itisnotpossibletoreachconsensusinanasynchronousshar edmemorysystemusingRead/Write
atomicregisters,evenifasingleprocesscan failby crashi ng.
•Thereisnowait-freeconsensusalgorithmforreachingcons ensusinanasynchronousshared
memorysystemusingRead/Writeatomicregisters.
There aretwoways ofovercomingtheimpossibilityresult.
•Weakening the consensus problem, as was done for message-pa ssing systems. This area
covers the design of asynchronous algorithms for k-set consensus, approximate consensus,
andrenamingusingatomicregistersandatomicsnapshotobj ectswhicharebuiltfromatomic
registers,studiedin Chapter12. Thesealgorithmsarestud iedinSections 14.6.4-14.6.6.
•Usingmemory thatis strongerthan atomicRead/Write memory to designwait-free consen-
susalgorithms. Such amemorywouldhavecorrespondingacce ss primitives.
Recall that a wait-free algorithm in a system of nprocesses is a (n−1)-crash resilient
algorithm. Thus, any process should be able to perform its ex ecution, independent of any
otherprocesses. Theaboveresultslead tothequestion:
–are there objects (with supporting operations), using whic h there is a wait-free (i.e.,
(n−1)-crash resilient)algorithmforreaching consensusina n-process system?
In the remainder of this section, we assume only the crash fai lure model, and also require
thesolutionsto be wait-free.
As it turns out, the answer is Yes. Objects/primitives such a sTest-&-Set ,Swap,Compare-
&-Swap, andMemory Move , that were designed in the context of efﬁcient computer arch i-
tectures, do indeed allow consensus to be reached in a wait-f ree manner. Such objects are
stronger than the safe, regular, or atomic Read/Write regis ters. The notion of consensus
numberprovides a metric to measure the degree to which these variou s primitives allow
consensus to be reached. This study of these more complex obj ects also extends our study
oftheregistersimulationsofChapter6,whereinstrongerr egistertypesweresimulatedfrom
weakerregistertypes.
535
Object Consensusnumber
Read/Write objects 1
Test-&-Set, stack,FIFO queue, Fetch-&-Inc 2
Augmentedqueuewith peek-sizek k
Compare-&-Swap, Augmentedqueue, memory-memorymove ∞
memory-memoryswap,Fetch-&-Cons, store-conditional
Table 14.4: Consensus numbers of some object types. Some of t hese objects are described in
Figure14.22.
14.6.2 Consensus Numbers andConsensus Hierarchy
Deﬁnition 28. An object of type Xhas consensus number k, denoted as CN(X) =k, ifkis the
largestnumberforwhichtheobject Xcansolvewait-free k-processconsensusinanasynchronous
system subjectto k−1crashfailures,usingonlyobjectsof type Xand read/writeobjects.
Consensus numbers of some well-known objects are shown in Ta ble 14.4. Figure 14.22 gives
the deﬁnitions of some of these objects. As seen from Deﬁniti on 28, there is an inﬁnite hierarchy
- called the consensus hierarchy - that gets deﬁned, according to the power of the objects to so lve
wait-freeconsensusundercrash failures.
A natural consequenceofthedeﬁnitionof consensusnumber isthefollowingresult.
Theorem 14. ForobjectsXandYsuchthatCN(X)<CN (Y), thereis nowait-freesimulation
ofobjectYusingXandread/writeregisters(whoseconsensusnumberis1)inas ystemwithmore
thanCN(X)processes.
If such a simulation did exist, then by Deﬁnition 28, CN(X) =CN(Y), leading to a contra-
diction. Note that if there are up to CN(X)processes, it is possible (as shown in Section 14.6.3)
forXandread/writeregisterstowait-freesimulate Ybecausethefullpowerofreachingconsensus
amongmorethan CN(X)processes isneverrequired to beexercised.
A corollary of this result is that there is no wait-free simul ation of any object with consensus
numbermorethanone,usingonlyread/writeatomicregister s. Thiscorollaryisimportantbecause
it impliesthat objects with stronger properties than the re ad/writeatomicregisterare needed. The
abilitytoreadandwrite,perhapsconditionally,inanatom icmannerwasearlierfoundtobeuseful
indesigningsemaphoresinoperatingsystems,andcertainp rimitivesincomputerarchitectureand
design. Several of theobjects in Figure 14.22 were ﬁrst desi gned in hardware in thesespecialized
contexts. We will now see two examples of achieving wait-fre e consensus – one using the FIFO
queue, andanotherusingtheCompare-&-Swap instruction.
14.6.2.1 FIFOqueue
Figure 14.21 shows how 2-consensus is achieved using a FIFO q ueue. The queue operations
areenqueue anddequeue. The queue is initialized with a single value, 0. Both proces ses try to
536
(shared variables)
queue:Q←−∝a\}⌊ra⌋k⌉tl⌉{t0∝a\}⌊ra⌋k⌉tri}ht; // queueQinitialized
array ofinteger: Choice [1,2]←−[⊥,⊥] //preferred valueofeach process
(local variables)
integer:temp←−0;
integer:x←−initialchoice;
(1)ProcessPi,1≤i≤2, executesthisfor2-process consensususingaFIFO queue:
(1a)Choice [i]←−x;
(1b)temp←−dequeue (Q);
(1c)iftemp= 0then
(1d) output (x)
(1e)elseoutput (Choice [1−i]).
Figure 14.21: Protocol for 2-process wait-free consensus u sing a FIFO queue. Code for Pi,1≤
i≤2.
dequeuefromthequeue. However,duetotheatomicityofthe dequeue operation,accessisalways
serialized. Theﬁrstprocessthatdequeuesthe‘0’elementu sesitsowninitialvalue(local x)asthe
consensus value and outputs it. The other process, on comple ting itsdequeue operation, gets⊥,
andlearnsthattheﬁrstprocesshasdequeuedﬁrst,andthere foreborrowsthevaluesetasidebythe
ﬁrst process in Choice [1−i]. Thus, both processes agree on the same value and hence 2-pro cess
consensus is achieved. The operations of any process can be s een to be wait-free. The same logic
cannot be extended to three processes because of the followi ng informal reasoning. Some one
process will dequeue the ‘0’. When the other two processes de queue and get a⊥, they know that
one of the other two processes’ value is the consensus value, but do not know which of the other
two processes it is. This is because the queue object does not atomically allow the ﬁrst process
to leave behind (i.e., write) its identiﬁer as an imprint for the second and third processes to learn
aboutwhen theyissuetheir dequeue. Therefore, CN(queue ) = 2.
14.6.2.2 Compare&Swap
Figure 14.23 shows how wait-free consensus is achieved amon g any number of processes using
the Compare&Swap operation (see Figure 14.22) on a shared re gisterReg. TheCompare&Swap
performs all actions of an invocation atomically, thus seri alizing all concurrent accesses. Each
process executes Compare &Swap(Reg,⊥,x). The value of the object Regis read into local
variableval, and if this value valequals the key⊥, then the process’s preference xgets written
toRegatomically. Due to the serialization of the operations, som e process always gets serialized
ﬁrst, evenifaccesses are concurrent. There arethustwocas es.
•Considerthe process that gets serialized ﬁrst. Thevalueof Regread viaCompare &Swap-
(Reg,⊥,x)equals the key⊥, and the preference xof this process gets written to Reg. The
process returnsits xastheconsensusvalue.
537
(shared variablesamongtheprocesses accessingeach ofthe different objecttypes)
register:Reg←−initialvalue; // shared registerinitialized
(local variables)
integer:old←−initialvalue; // valuetobereturned
integer:key←−comparisonvalueforconditionalupdate;
(1)RMW(Reg, functionf)returnsvalue:
(1a)old←−Reg;
(1b)Reg←−f(Reg);
(1c)return(old).
(2)Compare &Swap(Reg,key,new)returnsvalue:
(2a)old←−Reg;
(2b)ifkey=oldthen
(2c)Reg←−new;
(2d)return(old).
(3)Fetch &Inc(Reg)returnsvalue:
(3a)old←−Reg;
(3b)Reg←−r+ 1;
(3c)return(old).
Figure14.22: Deﬁnitionsofsynchronizationoperations RMW,Compare &Swap,Fetch &Inc.
•Any other process executing Compare &Swap(Reg,⊥,x)will ﬁnd that the value of Reg
(which is the value xset by the ﬁrst process) does not match the key ⊥. Hence it leaves
Regunmodiﬁedandreturnsthevalueof Regastheconsensusvalue. Theimplicationisthat
another process has earlier found Reg=⊥and set its own preference as the value of Reg.
So thisprocess borrowsthevalueset bytheearlierprocess i nRegas theconsensusvalue.
Due to the atomicity of the Compare &Swapoperation and the fact that this logic works for any
number of processes, the code for consensus is wait-free and can tolerate up to n−1failures, for
alln. Hence,CN(Compare &Swap)is∞.
14.6.2.3 Read-Modify-Write abstraction
The Read-Modify-Write (abbreviated as RMW) abstracts several objects wherein a register can
be read and modiﬁed using an arbitrary function fatomically. Such objects include Fetch &Inc,
Swap, andTest&Set. TheRMWobject has a consensus number of at least 2 because the ﬁrst
process to read the object can atomically modify its value to leave an imprint that the object has
beenaccessedatleastonce(e.g.,asintheFIFO queue). Ifth eimprintcanalsoincludetheidentity
oftheﬁrst process to read, or ofthechoiceof theﬁrst proces s, processes that subsequentlyaccess
the object can by pointed to the choice made by the ﬁrst proces s, and the consensus number may
538
(shared variables)
integer:Reg←−⊥; //shared register Reginitialized
(local variables)
integer:temp←−0; //tempvariabletoread valueof Reg
integer:x←−initialchoice; //initialpreference ofprocess
(1)ProcessPi,(∀i≥1),executesthisforconsensususing Compare&Swap :
(1a)temp←−Compare &Swap(Reg,⊥,x);
(1b)iftemp=⊥then
(1c) output (x)
(1d)elseoutput (temp).
Figure 14.23: Protocol for wait-free consensus using Compare &Swap, for any number of pro-
cesses. Codefor Pi,1≤i≤∞.
thenbemorethan 2.
The various RMWobjects differ in their function f. A function is termed as interfering if
for all process pairs iandj, and for all legal values vof the register, (i) fi(fj(v)) =fj(fi(v)),
i.e., function is commutative,or (ii) the function is not wr ite-preserving, i.e., fi(fj(v)) =fi(v)or
vica-versawiththeroles of iandjinterchanged.
Examples: TheFetch &Inccommutes even though it is write-preserving. The Test&Setcom-
mutes and is not write-preserving. The Swapdoes not commute but it is not write-preserving.
Hence, all threeobjectsusesfunctionsthat are interfering .
Figure14.25showshowwait-freeconsensusisachievedamon gtwoprocessesusingthe RMW
operation(seeFigure14.22)onasharedregister Reg. TheRMWperformsallactionsofaninvoca-
tionatomically,thusserializingallconcurrentaccesses . Eachprocessexecutes RMW (Reg,f,x ),
wherexis the initial choice of the process. The shared data structu res are shown in Figure 14.24.
Reghas an initial distinguished value ⊥, known to all processes. The assumption here is that the
functionfisnon-trivial,meaning,itisnot theidentityfunction.
RMW register
Choice [0] [1]Reg 
Figure 14.24: Shared data structures for solving 2-process wait-free consensus using the RMW
operation.
Although any nontrivial RMW operation has a consensus numbe r of at least 2, it can be seen
that a nontrivial interfering RMW operation has a consensus number of exactly 2, i.e., ther e is no
539
(shared variables)
integer:Reg←−⊥; //shared register Reginitialized
(local variables)
integer:Choice [0,1]←−[⊥,⊥]; //data structure
integer:x←−initial choice; //initial preference of process
(1) Process Pi,(0≤i≤1), executes this for consensus using RMW:
(1a)Choice [i]←−x;
(1b)ifval=⊥then
(1c) output (Choice [i])
(1d)else output (1−i).
Figure 14.25: Protocol for wait-free consensus for two proc esses using RMW. Code is for Pi,
0≤i≤1.
algorithmtoreach consensuswiththreeprocesses. An infor malargumenttoseethisisas follows.
Consider the third process to access the object. If the RMW op eration is commutative, the third
process cannot tell which of the other two processes accesse d the object ﬁrst, and hence does not
knowwhatconsensusvaluetouse. IftheRMWoperationisnotw rite-preserving,thethirdprocess
cannot tell if it is the second or the third process to access t he object; and hence does not know
what consensus value to use. Operations such as Compare &Swapare noninterfering operations,
and hencehaveconsensusnumbershigherthan2.
14.6.3 Universality of Consensus Objects
InChapter6,westudiedthewait-freesimulationsofvariou stypesofregistersusingweakerforms
of registers. We now build on this notion of wait-free simula tionof one object type using another
object type, in the context of consensus under crash failure s. An object is deﬁned to be universal
if that object along with read/write registers can simulate any other object in a wait-free manner.
Themainresultofthissectionisthatinanysystemcontaini nguptokprocesses,anobject Xsuch
thatCN(X) =kisuniversal, i.e., it can simulate any other object. The condition on the number
ofprocessesinthesystemisessential;because Xdoesnotandcannotmanifestthegreaterpower
thatisrequired whenthenumberofobjectsexceeds CN(X). Iftheconditionwereremoved,then
an objectXwould truly wait-free simulate another object with a greate r consensus number in a
system with more than CN(X)processes, leading to a violation of the deﬁnition of consen sus
number.
For any system with up to kprocesses, the universality of objects Xwith consensus number
kis shown by giving a universal algorithm to wait-free simulate anyobject using only objects of
typeXand read/writeregisters. Thisisshownin twosteps.
1. Auniversal algorithmtowait-freesimulate anyobjectwhatsoeverusingread/writeregisters
and arbitrary k-processorconsensusobjects isgiven. Thisisthemainstep .
540
2. Then, the arbitrary k-process consensus objects are simulated with objects of ty peX, also
havingconsensusnumber k. Thistriviallyfollowsafter theﬁrst step.
Hence,anyobject Xwithconsensusnumber kisuniversalinasystemwith n≤kprocesses. Inthe
rest ofthissubsection,westudyauniversalalgorithmtowa it-free simulateanyobjectwhatsoever
usingread/write registersand arbitrary k-processorconsensus objects(step 1). Thefollowingtwo
conceptsare useful.
•An arbitrary consensus object Xallows a single operation, Decide (X,v in)and returns a
valuevout,whereboth vinandvouthavetoassumealegalvaluefromknowndomains Vinand
Vout,respectively. Forthecorrectnessofthissharedobjectve rsionoftheconsensusproblem,
allvoutvaluesreturned toeach invokingprocess mustequal the vinofsomeprocess.
•Anonblocking operation, in the context of shared memory operations, is an operation that
may not complete itself but is guaranteed to complete (i.e., provide a response indication
(see Chapter 6) to) at least one of the pending operations in a ﬁnite number of steps. This
operationisa weakerversionofawait-freeoperation.
Wewillﬁrststudyauniversalalgorithmthatdoesanonblock ingsimulationofanyobject,andthen
reﬁne thisalgorithmtoget await-free algorithm.
14.6.3.1 A Nonblocking UniversalAlgorithm
ThealgorithmshowninFigure14.26usesalinkedlist(witht heinitialrecordtermed anchor_record)
to store the linearized sequence of operations and resultin g states on an arbitrary object Z. The
datastructure opdeﬁnes theformatofonesuchelementinthislinkedlist. The linkedlistanddata
structure format are illustrated in Figure 14.27. Operatio ns to the arbitrary object Zare simulated
in a nonblocking way using only an arbitrary consensus objec t (namely, the ﬁeld op.nextin each
record)whichisaccessedviathe Decidecall. Wearenotconcernedwithhowtheconsensusobject
itselforDecideisimplemented.
When an operation Zbeing simulatedis invoked using invoc, a record called my_new_record
isallocatedandtherecord’s operation ﬁeld issettotheinvokedoperation(lines1a-1b). Themain
challengein simulating Zis to linearizeall theoperations being invokedon it concur rently by the
various processes – there is competition among the processe s to apply their own operation next,
i.e., to thread their own operation next to the tail of the lin ked list. This is where the consensus
objectcomesinuseful–withrespecttothecurrent mostrece ntoperationthathasbeenlinearized,
theconsensusobject“decides”on thenextoperationthat is to belinearized.
Before a process competes, it ﬁrst needs to identify the tail of the linked list which is dynam-
ically changing. Array Headstores pointers to the tail of the linked list; Head[i]isPi’s best
estimateofthepointerthatpointstothetailrecord. Inloo p(1c)-(1e),Piselectsthemostuptodate
estimate of the tail pointer. However, observe that this may still be hopelessly out of date due to
thenonatomicnatureofscanningthearray Head. Still,Head[i]isPi’sbestestimateoftherecord
that is at the tail of the linked list. In the main loop, lines ( 1f)-(1k),Picompetes on the consensus
objectHead[i].nexttothread itselfnexttothelist(line(1g)). Thefollowingp ossibilitiesarise.
541
(shared variables)
recordop
integer:seq←−0; //sequence number of serialized operation
integer:operation←−⊥; //operation, withassociated parameters
integer:state←−initial state ; //the state ofthe object after the operation
integer:result←−⊥; //the result ofthe operation, tobe returned to invoker
integer:next←−⊥; // pointer tothe next record
(local variables)
array ofinteger Head[1... k]←−∗(anchor_record );
(1) Process Pi,1≤i≤kperforms operation invocon an arbitrary consensus object:
(1a)my_new_record←−malloc (op);
(1b)my_new_rec.operation←−invoc;
(1c)forcount = 1tokdo
(1d) ifHead[i].seq < Head [count].seqthen
(1e) Head[i]←−Head[count];
(1f)repeat
(1g) winner←−Decide (Head[i].next, &my_new_record );
(1h) winner.seq←−Head[i].seq+ 1;
(1i) winner.state,winner.result ←−apply(winner.operation,Head [i].state);
(1j) Head[i]←−winner;
(1k)untilwinner =my_new_record;
(1l) enable the response to invoc, that is stored at winner.result .
Figure14.26: Nonblockinguniversalalgorithmtosimulate anarbitraryobjectusinganyconsensus
object. Codefor Pi,1≤i≤k.
1.Head[i]isindeedthecorrecttailofthelist. Theprocess PiinvokesDecideontheconsensus
objectwhich is the nextﬁeld oftherecord pointedto by Head[i]– to learn ifitsucceeds in
threadingitsoperationnext. Buttheremaybeconcurrentca llstoDecide. Thewinnerofthe
“race” is pointedto by winner. (We do not yet knowif Piwon.) Theﬁelds of winner– its
new state, new sequence number, new result – are computed and stored inwinnerin lines
(1h)-(1i).Head[i]isupdatedto pointto winner(line(1j)).
(a) Ifwinneris the same as my_new_record(line (1k)), then Piwon the race and suc-
ceeded in threading its operation after the Head[i]record before the current iteration
oftherepeatloop. Theprocessexitsafterreturningthevaluestoredint heresultﬁeld
(line(1l)).
(b) Ifwinneris notthesameas my_new_record, thenPilosttherace. Therecord ofthe
true winner of the race was returned in winnerby the consensus object. The record
of the true winner got ﬁlled in again by Piin (1h)-(1j). But now Head[i]is pointing
tothenextrecord, i.e.,therecord withsequencenumberone morethanintheprevious
iteration. Theprocesscompetesagainbygoingthroughthen extiterationofthe repeat
loop.
542
Announce[1..n] Head[1..n]
RecordAnchor_op
resultstateoperationseq
ten
x
Figure 14.27: Wait-free simulationof a universal consensu s object. For a nonblockingsimulation
oftheobject,thearray Announce is notused.
2.Head[i]is an old tail of the list. The process executes the repeatloop (see case (1b) that
repeats itself)until Head[i]pointstotherecord thatisthemostrecent tail. Itthen comp etes
tothread itsownoperation my_new_record as in step1.
We makesomenotes thatgivean insightintothedesignofthis algorithm.
•We cannot use a single consensus object because consensus ha s to be reached on-line with
respect to the current most recent operation, on the next ope ration to be linearized. A con-
sensus object always returns the same decision value. Thus t he algorithm uses as many
consensus objects (the nextﬁelds of the records) as there are records on whose order to
reach consensus.
•A single pointer in a read/write object cannot be used instea d of the array Headto point
to the latest operation record. This is because reading the p ointer to contend, and updating
it after contention is over and threaded to the list, cannot b e done atomically in a wait-free
manner.
•Thelinearizationoftheoperationsisgivenbythesequence numbers. Thesequencenumbers
increasemonotonicallyalongthelinkedlist.
•A process may never succeed in threading its own operation to the list. It continues the
repeatloopforever. Thismayhappenifitlosesthecontentionever ytimetoanotherprocess
tryingtothread concurrently. Thiscan beusedto observeth at thealgorithmisnotwait-free
butthealgorithmisnonblocking.
•The estimate of the tail of the list in lines (1c-1e) may be ver y out of date due to the way it
iscomputed. Thisisadrawbackastheprocesshastoiteratet hroughthe repeatloopatleast
as manytimesas thenumberofoperationsby whichtheestimat eisoutofdate.
543
(sharedvariables)
recordop
integer:seq←−0; //sequencenumberofserializedoperation
integer:operation←−⊥; // operation,withassociatedparameters
integer:state←−initial state ; // thestate ofthepbjectafterthe operation
integer:result←−⊥; // theresultoftheoperation,to bereturnedtoinvoker
integer:next←−⊥; // pointerto thenextrecord
(localvariables)
arrayofinteger Head[1. . .k], Announce [1. . .k]←−∗(anchor_record );
(1)Process Pi,1≤i≤kperformsoperation invoconanarbitraryconsensusobject:
(1a)Announce [i]←−malloc (op);
(1b)Announce [i].operation←−invoc;Announce [i].seq←−0;
(1c)forcount = 1tokdo
(1d) ifHead[i].seq < Head [count].seqthen
(1e) Head[i]←−Head[count];
(1f)while Announce [i].seq= 0do
(1g) turn←−(Head[i].seq+ 1)mod(k);
(1h) ifAnnounce [turn].seq= 0then
(1i) my_new_record←−Announce [turn];
(1j) elsemy_new_record←−Announce [i];
(1k) winner←−Decide (Head[i].next, &my_new_record );
(1l) winner.seq←−Head[i].seq+ 1;
(1m) winner.state, winner.result ←−apply(winner.operation, Head [i].state);
(1n) Head[i]←−winner;
(1o)enabletheresponseto invoc,thatisstoredat winner.result .
Figure 14.28: Wait-free universal algorithm to simulate an arbitrary object using any consensus
object. Codefor Pi,1≤i≤k.
Complexity: The worst-case time complexity to thread a speciﬁc operatio n isnot bounded due to
thenonblockingnatureofthealgorithm. Exercise14asksyo utoperformanaverage-caseanalysis.
14.6.3.2 A Wait-freeUniversal Algorithm
Thenonblockingalgorithmintheprevioussectionisenhanc edtomakeitwait-free. Toensurethat
aprocess does nothappen tocontinuallylosethecontention ,a round-robinapproach of“helping”
is used. If a process Pjdetermines that the next operation is to be assigned sequenc e numberx,
then it ﬁrst checks whether the process Pisuch thati=x(modn )is contending for threading its
operation. Ifso, then Pjtries tothread Pioperationinstead ofitsown.
The algorithm is shown in Figure 14.28. The implementation o f the round-robin “helping”
is done using the array Announce [1...n]. When a process Piwants to thread its operation, it
ﬁrst announces it by making Announce [i]point to the record where the operation is stored (lines
(1a)-(1b)). It then proceeds as before to estimate the lates t tail of the list, using the Headarray
(lines(1c)-(1e)). Eachprocessisrequiredtodeterminewh etheritshouldtrytothreadtherecordof
the rightful process (lines (1g)-(1h)), as determined by th e modulo function, or its own (line (1j)).
Only if the “rightful” process is not interested in threadin g its own operation does a process try to
544
(variables)
integer:v←−initialvalue;
array ofinteger local_array←−⊥;
(shared variables)
atomicsnapshotobject Obj[1...n]←−⊥;
(1)A process Pi,1≤i≤n, initiatesk-set consensus:
(1a)update i(Obj,x )withv;
(1b)repeat
(1c)local_array←−scan i(Obj);
(1d)untilthereare at least|N|−fnon-nullvaluesin Obj;
(1e)v←−minimumofthevaluesin local_array.
Figure 14.29: Asynchronous protocol for k-set consensus in the shared memory model using an
atomicsnapshotobject. Codeshownisforprocess Pi,1≤i≤n.
thread itsownoperation(line(1j)).
We argue using contradiction that within niterations of the whileloop, process Piwill have
succeeded in having its operation threaded to the linked lis t, and exit the loop. Assumeby way of
contradiction that Pi’s record is not threaded by Pi’s(n+ 1)th iteration of the whileloop. After
theAnnounce [i]havingbeensetinlines(1a-1b), notherrecordsinitiatedbyotherprocessesmust
have been threaded to the linked list. But of these nsequence numbers, one of them modulo n
musthaveequalled iandtheotherprocesseswouldhavethreaded Pi’srecord insteadoftheirown
(seelines(1g)-(1i)).
Complexity: Each process completes its operation within niterations of the main whileloop,
irrespectiveoftheotherprocesses.
14.6.4 Shared Memory k-setConsensus
The message-passing version of k-set consensus was presented in Section 14.5.4. Here, its co un-
terpartforthesharedmemorymodelassuminganatomicsnaps hotobjectisgiveninFigure14.29.
The algorithm can be easily derived from the message-passin g algorithm. A process writes its
initialvaluetoitscomponentwithinthesharedobject,and repeatedlyscansthesharedobjectuntil
n−fprocesseshavewrittentotheobject. It then takestheminim umofthevaluesscanned.
14.6.5 Shared MemoryRenaming
The renaming problem was introduced in Section 14.5.6 and an algorithm to solve renaming in
the message passing model was given. An asynchronous algori thm for wait-free renaming for the
shared memorymodelis givenin Figure14.30. Thealgorithma ssumes an atomicsnapshotobject
Obj, which has the nice property that it linearizes all asynchro nous operations to it. Each process
begins by bidding a new name of ‘1’ for itself (line 1a). The pr ocess then repeats the following
545
(variables)
integer:mi←−0;
integer:Pi←−name from old domain space;
array ofinteger tuples local_array←−∝a\}⌊ra⌋k⌉tl⌉{t⊥,⊥∝a\}⌊ra⌋k⌉tri}ht;
(shared variables)
atomic snapshot object Obj[1... n]←−∝a\}⌊ra⌋k⌉tl⌉{t⊥,⊥∝a\}⌊ra⌋k⌉tri}ht;
(1) Aprocess Pi,1≤i≤n,participates inwait-free renaming:
(1a)mi←−1;
(1b)repeat
(1c) update i(Obj,∝a\}⌊ra⌋k⌉tl⌉{tPi,mi∝a\}⌊ra⌋k⌉tri}ht); //update ith component withbid mi
(1d) local_array (∝a\}⌊ra⌋k⌉tl⌉{tP1,m1∝a\}⌊ra⌋k⌉tri}ht,...∝a\}⌊ra⌋k⌉tl⌉{tPn,mn∝a\}⌊ra⌋k⌉tri}ht)←−scan i(Obj);
(1e) ifmi=mjfor some j∝\⌉}atio\slash=ithen
(1f) Determine rank rank iofPiin{Pj|Pj∝\⌉}atio\slash=⊥∧j∈[1,n]};
(1g) mk←−rank ith smallest integer not in {mj|mj∝\⌉}atio\slash=⊥∧j∈[1,n]∧j∝\⌉}atio\slash=i};
(1h) else
(1i) decide(mk);exit;
(1j)untilfalse.
Figure 14.30: Asynchronous wait-free renaming using an ato mic snapshot object in the shared
memorymodel. Codeshownisforprocess Pi,1≤i≤n.
loop. Itwritesitslatestbidtoitscomponentof Obj(line1c);itreadstheentireobjectusinga scan
into its local array (line 1d). Piexamines the local array for a possible conﬂict with its prop osed
newname(line1e).
•IfPidetectsaconﬂictwithitsproposedname mi(line1e)itdeterminesitsrank rankamong
theoldnames (line 1f); and selects the rankthsmallest integer among the names that have
not been proposed in the view of the object just read (line 1g) . This will be used as Pi’s bid
foranewnamein thenextiteration.
•IfPidetects no conﬂict with its proposed name mi(line 1e), it selects this name and exits
(line1i).
We nowconsiderthefollowingproperties ofthisalgorithm.
Correctness: Iftwoprocessesweretochoosethesamenewname,thentheSca nsreturnedtothem
in theirﬁnal iterationmusthaveindicated thatthenamethe y bidwas unique. However,due
to thelinearizabilityproperty of theatomicsnapshotobje ctObj, theScan that was returned
to the “later” process could not have indicated that the name it bid was unique. Hence, no
twoprocesses can choosethesamenamewhentheyterminate.
Sizeofname space: At any time, there are at most n−1names that are bid by other processes,
and the rank of a process is at most n. Hence, a process will never bid a name greater than
2n−1. Thenamespaceisconﬁned to [1,2n−1].
546
Termination: Assumethereis asubset T⊆Nofprocesses that neverterminate. Let min(T)be
theprocessin Twiththelowestrankedprocessidentiﬁer(oldname). Let rank(min(T))be
therankofthisprocessamong alltheprocesses P1...P n. Onceeveryprocessin Thasdone
atleastone update, andoncealltheprocessesin Thaveterminated,wehavethefollowing.
•Theset ofnamesoftheterminatedprocesses,say MT, remains ﬁxed.
•The process min(T)willchoosea namenot in MT, that is ranked rank(min(T)). As
rank(min(T))isunique,no otherprocess in Twilleverchoosethisname.
•Hence,min(T)willnotdetect anyconﬂict with rank(min(T))andwillterminate.
Asmin(T)cannotexist,theset T=∅.
Wait-freedom: A process can choose its new name independent of the actions o f the other pro-
cesses.
Complexity: Exercise 17 asks you to perform a time complexity analysis of this algorithm, and
showthefollowinglowerbounds.
Lower bounds: LetMbe the new name space. For crash-failures, the following low er bounds
can beseen toexist.
•Forwait-freerenaming,wherein all other n−1processes mayfail, thenamespacemustbe
ofsize 2n−1.
•Totolerateup to ffailures,thenamespacemustbeofsize n+f.
14.6.6 Shared MemoryRenaming using Splitters
Moir and Anderson presented a very elegant wait-free renami ng algorithm using the splittercon-
currentobjectdeﬁned asfollows. When n(n≥1)processesinvokethe splitter,each isreturneda
valuefrom theset{stop,down,right}subjecttothefollowingconstraints.
•Atmostoneprocess isreturned stop.
•Atmostn−1processesare returned down.
•Atmostn−1processesare returned right.
Figure 14.31 shows a schematic deﬁnition of a splitter. Figu re 14.32 shows a wait-free imple-
mentationofasplitter.
•Theﬁrsttimethatsomeprocess PiﬁndsXequaltoitsownidentiﬁerinline(1d), Ymustbe
true, and hence all other processes must get the value right(unless they fail) while Pimust
get valuestop. Hence, at mostoneprocess isreturned stop.
547
at most   n−1processesn
processesn−1at most DOWNprocesses1 processat most STOP
RIGHT
Figure14.31: Thestructurefora splitter.
(shared variables)
MRMWatomic snapshot object X,Y←−false;
(1)splitter(), executed byprocess Pi,1≤i≤n:
(1a)X←−i;
(1b)ifYthen
(1c) return(right);
(1d)else
(1e) Y←−true;
(1f) if X=ithenreturn (stop)
(1g) else return (down).
Figure14.32: A wait-freeimplementationofasplitter. Cod eshownis forprocess Pi,1≤i≤n.
•LetPibethelastprocess toexecute(1a). Unless Picrashes,itwilleithergetvalue right(if
it is th ﬁrst process to execute line (1b)) or it will get the va luestop. Hence at most n−1
processes arereturned down.
•The ﬁrst process that reads Yin line (1b) cannot get value rightbecauseYis initialized to
false. Hence, notall processescan arereturned right.
The renaming algorithm is now constructed using n(n+ 1)/2splitters arranged as shown in
Figure14.33. Eachsplitterislabelledbycoordinates r,d. Observethateach processisguaranteed
togetastopvaluefromoneofthe n(n+1)/2splitters,andnotwoprocesseswillstopatthesame
splitter. So the coordinates of the splitter where a process stops can serve as the new label. The
codeisshowninFigure14.34.
Complexity: Thenewnamespaceis n(n+1)/2whenthenumberofprocessesis n. Eachprocess
takesO(n)stepstoselect itsnew name. Thealgorithmis clearly wait-f ree.
548
0,3 0,2 0,1 0,0
2,0
3,01,1 1,0 1,2
2,2dr
Figure14.33: TheMoir-Andersonwait-freerenamingalgori thmusingsplitters. Codeshownisfor
Pi,1≤i≤n.
(local variables)
next,r,d,new _name←−0;
(1) Process Pi,1≤i≤n,participates in wait-free renaming:
(1a)r,d←−0;
(1b)while next i∝\⌉}atio\slash=stopdo
(1c) next i←−splitter (r,d);
(1d) case
(1e) next=rightthenr←−r+ 1;
(1f) next=downthend←−d+ 1;
(1g) next=stopthen break()
(1h)return(new_name =n·d−d(d−1)/2 +r).
Figure14.34: Moirand Anderson’sasynchronouswait-freer enamingusingsplitters. Codeshown
isforprocess Pi,1≤i≤n.
14.7 ChapterSummary
Consensus problems are fundamental aspects of distributed computing because they require in-
herently distributed processes to reach agreement. This ch apter ﬁrst covers different forms of the
consensus problem, which are shown to be equivalent to one an other. Consensus is attainable in
fault-free systems. The chapter then gives an overview of wh at forms of consensus are solvable
underdifferentfailuremodelsand differentassumptionso nthesynchrony/asynchrony.
The chapter then covers agreement in the following categori es. (1) Synchronous message-
passingsystemswithfailures. Here,differentfaultmodel sareconsidered-thefail-stopmodeland
theByzantinemodel. Lowerboundsonthenumberoffailure-p roneprocessesaregiven. Also,rep-
resentative algorithms under different asumptions and fau lt models are given. (2) Asynchronous
message-passing systems with failures. The ﬁrst result her e is that it is impossible to reach con-
549
sensus in this model. Hence, several weaker versions of the c onsensus problem, such as k-set
consensus, approximate consensus, the renaming problem, a nd reliable broadcast are considered.
Algorithms to solve the weakened forms of consensus in these models are then given. (3) Wait-
free shared memory consensus in asynchronous systems. Here , the ﬁrst result is the impossibility
result, analogous to that for message-passing systems. The chapter then solves consensus using
registers (or objects) that are stronger than the atomic rea d/write registers. The consensus hierar-
chy that naturally emerges for stronger consensus objects i s then studied. Algorithms for shared
memoryrenamingand k-set consensusarealso covered.
14.8 ExerciseProblems
1. Foreach ofthesixordered pairs ofproblemsamong: the Byzantineagreement problem,the
Consensus problem, and the Interactiveconsistency problem, demonstratea reduction from
theformertothelatter.
2. Modify the algorithm in Figure 14.3 to design an early-stopping algorithm for consensus
under failstop failures, that terminates within f′+ 1rounds, where f′, the actual number of
stop-failures,islessthan f. Provethecorrectness ofyouralgorithm.
Hint:A process can be required to send a mesage in each round, even i f the valuewas sent
in the earlier round. Processes should also track the other p rocesses that failed, which is
detectablebyidentifyingtheprocesses fromwhich nomessa gewasreceived.
3. ModifytheiterativeByzantineAgreementalgorithmandt hetreedatastructurespeciﬁcation
given in Figure 14.7, as well as the example in Figure 14.8, to now solve the consensus
problem.
4. Examine the phase-king algorithm for consensus in the fac e of Byzantine failures, as given
in Figure 14.11. This algorithm works when n >4f. Presumably, the algorithm will fail
for4f≥n >3f, even though this condition is a sufﬁcient condition for the existence of a
solutiontotheconsensusprobleminasynchronousmessage- passingsystem.
(a) Why willthealgorithmfail for 4f≥n>3f?
(b) Eventhoughthealgorithmisnotcorrectfor 4f≥n>3f,undersomecircumstance(s),
the correct processors willend up with the samevalue. Chara cterize one such circum-
stance, independentofthebehaviorofthemaliciousproces ses.
(c) To deriveacorrect solutionfor 4f >n> 3f,changeline(1k)to read:
if mult>f
Will thissolutionwork?
(d) To derive another correct solution for 4f≥n >3f, run the algorithm for 4(f+ 1)
roundsinsteadoffor 2(f+1)roundsoftheoriginalalgorithm. Willthissolutionwork?
550
5. Provethat the distributedcommit problemisnot solvableunderacrash failure.
Hint:Showareductionfrom theconsensusproblemto thedistribut edcommitproblem.
6. Provethat the leader election problemisnot solvableunderacrash failure.
7. In theǫ-agreement problem, can a correct process halt if it receive sf+ 1halting tags from
other processes, even before it has completed its precomput ed number of rounds? Justify
youranswer.
8. Howcanthealgorithmfor ǫ-agreement,giveninFigure14.13,besimpliﬁedifasynchro nous
system is available? Identify all the changes to the various parameter values. Can a better
valuebeobtainedfortheconvergencerate?
9. Analyze the number of bids for a new name made by each proces s in the asynchronous
renamingalgorithmgiveninFigure14.17.
10. Howcan thealgorithmforasynchronousrenaming,giveni n Figure14.17,besimpliﬁedifa
synchronoussystemisavailable?
11. ExaminetheTest-&-SetinstructioninFigure14.22. Wha tistheconsensusnumber xofthis
registerobject? Givean algorithmtoachieveconsensusfor thisconsensusnumber.
12. (k-Writeinstruction).
(a) Considerthe 2-Writeinstructionthatcanwritetwolocationsatomically. Showh owthe
2-Writeinstruction can be used to implement a wait-free 2-consensu s protocol. (Hint:
structure the solution using a structure similar to that of t he protocols for RMWand
Swap.)
(b) Consider the k-Writeinstruction. Can this k-Writeinstruction be used to implement a
wait-free consensusprotocolfor kprocesses? Justifyyouranswer.
13. Examinethestandardstackobject,havingitsstandard pushandpopoperations. Whatisthe
consensus number xof the stack? Give the code for achieving 2-process consensu s using
thestack.
14. Perform an average-case time complexity analysis of the nonblocking universal algorithm
forconsensusobjectsgivenin Figure14.26.
15. Simplifythenonblockinguniversalalgorithmforconse nsusobjects(Figure14.28)byusing
thespeciﬁcCompare&Swap object,butalso eliminatingthe Headarray.
16. Adapt the message-passing asynchronous approximate ag reement algorithm given in Sec-
tion14.5.5forashared memorysystem.
551
17. Perform a time complexity analysis of the wait-free rena ming algorithm using the atomic
snapshot object in asynchronous systems, given in Figure 14 .30. Also prove the lower
boundsonthesizeofthenamespace, as indicatedinSection 1 4.5.6.
18. Show how the number of splitters used in the renaming algo rithm of Section 14.6.6 can be
reduced ton(n−1)/2.
14.9 BibliographicNotes
The Byzantine agreement and the consensus problems were deﬁ ned by Lamport, Shostak, and
Pease[24,20]. Theexponentialmessagesalgorithmforsolv ingconsensusinthefaceofBzyantine
failures and the 3f+ 1lower bound were given in these papers. A later proof of the ex ponential
algorithm was given by Bar-Noy, Dolev, Dwork, and Strong [3] , and a later proof of the 3f+ 1
lower bound was given by Fischer, Lynch, and Merritt [11]. Th e polynomial-messagephase-king
algorithmtosolveconsensusinthesameByzantinefailurem odelwasgivenbyBermanandGarey
[4]. Apolynomial-messagealgorithmrequiring t+ 1roundsandn>3tprocesses hasbeen given
byGaryandMoses[13]. Theresultontheimpossibilityofrea chingconsensusinanasynchronous
message-passing system was given by Fischer, Lynch, and Pat erson [12]. The same impossbility
resultforanasynchronoussharedmemorysystemwasgivenby LouiandAbu-Amara[21]. Fischer
and Lynch [10] and Dolev and Strong [9] proved the lower bound off+ 1rounds for reaching
consensusintheByzantinefailureand crash failuremodels ,respectively.
Thek-set consensusproblemwas deﬁned byChaudhuri [6]. Thiswor k alsopresented theﬁrst
algorithm for solving k-set consensus under ffaults, where f < k. The lower bound of f < k
crash-failureprocessesforsolvingthisproblemwasshown byBorowskiandGafni[5],Herlihyand
Shavit [15], and Saks and Zaharoglou [26]. The approximate a greement problem was proposed,
andsolvedforcrashfailureandByzantinefailuresintheme ssage-passingmodelbyDolov,Lynch,
Pinter, Stark, and Weihl [8]. The wait-free shared memory so lution to this problem was proposed
by Moran[23].
Wait-free synchronization was introduced by Lamport [18] a nd developed by Peteron [25].
The theory of wait-free synchronization, consensus hierar chy, and the universal constructions for
arbitraryconsensusobjectswasgivenbyHerlihy[14]. Thed iscussionofRMWoperationsandthe
analysisoftheconsensusnumberofRMWobjectswithinterfe ringoperationsisgivenbyKruskal,
Rudolph, and Snir [17]. The renamingproblem was proposed an d solved forthemessage-passing
modelbyAttiya,Bar-Noy,Dolev,Peleg,andReischuk[1]. Th eyalsoshowedthatatleast n+1new
names are needed if fcrash failures are to be tolerated. This lowerbound was tigh tened ton+f
by Herlihy and Shavit [15]. This lower bound, as well as the lo wer bound for k-set consensus are
derived from a theorem that characterizes the solvable prob lems by af-resilient algorithm using
only Read and Write operations, as shown by Herlihy and Shavi t [16]. The wait-free renaming
algorithm for the shared memory algorithm is adapted from [1 ] and Attiya and Welch [2]. The
wait-free shared memory renaming algorithmusing splitter swas proposed by Moirand Anderson
[22]. Theabstractionofwait-freesplitterswas proposeda nd implementedby Lamport[19].
552
Bibliography
[1] H.Attiya,A.Bar-Noy,D.Dolev,D.Peleg,R. Reischuk,Re naminginanasynchronousenvi-
ronment,JournaloftheACM, 41(1): 524-548,1990.
[2] H.Attiya,J.Welch,DistributedComputing: Fundamenta ls,Simulations,andAdvancedTop-
ics,WileyInterscience, 2nd edition,2004.
[3] A. Bar-Noy, D. Dolev, C. Dwork, H. R. Strong, Shifting gea rs: Changing algorithms on the
ﬂy toexpediteByzantineagreement, InformationandComput ation,92(2): 205-233,1992.
[4] P. Berman, J. Garay, Closure votes: n/4-resilient distributed consensus in (t+ 1)rounds,
MathematicalSystems Theory,26(1): 3-19,1993.
[5] E. Borowsky, E. Gafni, Generalized FLP impossibility re sult fort-resilient asynchronous
computations,Proceedings ofthe25thIEEE STOC, 91-100,19 93.
[6] S. Chaudhuri, More choices allow more faults: Set consen sus problems in totally asyn-
chronoussystems,Informationand Computation,105(1): 13 2-158,1993.
[7] S. Chaudhuri, M. Herlihy, N. Lynch, M. Tuttle, A tight low er bound for k-set agreement,
Proceedings IEEEFOCS, pp. 206-215,1993.
[8] D. Dolev, N. Lynch, S. Pinter, E. Stark, W. Weihl, Reachin g approximate agreements in the
presenceoffaults,JournaloftheACM, 33(3): 499-516,1986 .
[9] D. Dolev,H.R. Strong, AuthenticatedalgorithmsforByz antineagreement, SIAM Journal of
Computing,12(4): 656-666,1983.
[10] M.Fischer, N. Lynch,Alowerboundforthetimetoassure interactiveconsistency,Informa-
tionProcessingLetters, 14(4): 183-186,1982.
[11] M. Fischer, N. Lynch, M. Merritt, Easy impossibility pr oofs for distributed consensus prob-
lems,DistributedComputing,1(1): 26-39,1986.
[12] M. Fischer, N. Lynch, M. Paterson, Impossibility of dis tributed consensus with one faulty
processor,Journal oftheACM, 32(2): 374-382,1985.
553
[13] J. Garey, Y. Moses, Fully polynomial Byzantine agreeme nt forn >3tprocessors in t+ 1
rounds,SIAM JournalofComputing,27(1): 247-290,1998.
[14] M. Herlihy, Wait-free synchronization, ACM Transacti ons on Programming Languages and
Systems,11(1): 124-149,1991.
[15] M. Herlihy, N. Shavit, The asynchronous computability theorem for t-resilient tasks, Pro-
ceedingsofthe25thIEEE STOC, 111-120,1993.
[16] M. Herlihy, N. Shavit, The topological structure of asy nchronous computability, Journal of
theACM, 46(6): 858-923,1999.
[17] C. Kruskal, L. Rudolph, M. Snir, Efﬁcient synchronizat ion of multiprocessors with shared
memory,Proceedings ofACM PrinciplesofDistributedCompu ting,Aug.1986.
[18] L.Lamport,Concurrentreadingandwriting,Communica tionsoftheACM,20(11): 806-811,
1977.
[19] L. Lamport, A fast mutual exclusion algorithm, ACM Tran s. on Computer Systems, 5(1):
1-11,1987.
[20] L. Lamport, R. Shostak, M. Pease, The Byzantine general s problem, ACM Transactions on
ProgrammingLanguagesand Systems,4(3): 382-401,1982.
[21] M.C. Loui, H.H. Abu-Amara, Memory requirements for agr eement among unreliable asyn-
chronous processes, Advances in Computinng Research (Vol. 4): Parallel and Distributed
Computing,JAIPress, 1987.
[22] M. Moir, J. Anderson, Wait-free algorithms for fats lon g-lived renaming, Science of Com-
puterProgramming,25(1): 1-39,1995.
[23] S. Moran,Usingapproximateagreementtoobtaincomple tedisagreement: Theoutputstruc-
ture of input free asynchronous computations, Proc. 3rd Isr aeli Symposium on Theory of
Computingand Systems,251-257,1995.
[24] M. Pease, R. Shostak, L. Lamport, Reaching agreement in the presence of faults, Journal of
theACM, 27(2): 228-234,1980.
[25] G. Peterson, Concurrent reading while writing, ACM Tra nsactions on Programming Lan-
guagesand Systems,5(1): 46-55,1983.
[26] M. Saks, F. Zaharoglou, Wait-free k-set agreement is impossible: The topology of public
knowledge,Proc. 25thIEEESTOC, 101-110,1993.
554
Chapter15
Failure Detectors
15.1 Introduction
Thischapterdealswiththedesignoffault-tolerantdistri butedsystems. Itiswidelyknownthatthe
design and veriﬁcation of fault-tolerent distributed syst ems is a difﬁcult problem. Consensus and
atomic broadcast are two important paradigms in the design o f fault-tolerent distributed systems
andtheyﬁndwideapplications. Consensusallowsasetofpro cessestoreachacommondecisionor
valuethat depends upontheinitialvalues at theprocesses, regardlessoffailures. In atomicbroad-
cast, processes reliably broadcast messages such that they agree on the set of messages delivered
and theorder ofmessagedeliveries.
Thischapterfocusesonsolutionstoconsensusandatomicbr oadcastproblemsinasynchronous
distributed systems. In asynchronous distributed systems , there is no bound on the time it takes
for a process to execute a computation step or for a message to go from its sender to its receiver.
In an asynchronous distributed system, there is no upper bou nd on the relative processor speeds,
execution times, clock drifts, and delay during the transmi ssion of messages although they are
ﬁnite. This is mainly casued by unpredictable loads on the sy stem that causes asynchrony in the
systemandonecannotmakeanytimingassumptionsofanytype s. Ontheotherhand,synchronous
systemsarecharacterizedbystrictboundsontheexecution timesandmessagetransmissiondelays.
The asynchronous model of distributed system has simpler se mantics when compared to syn-
chronous model. Applicationsbased on theasynchronousmod elare easily portablebecause there
arenostricttimingassumptionstotakecareof. Theasynchr onousmodelofdistributedsystemsis
very popularand has attracted lot of attentiondue to theser easons. Inspiteof theattractivenessof
asynchronous distributed systems, it is well known that con sensus, atomic broadcast, and several
otherreliablebroadcastproblemscannotbesolveddetermi nisticallyevenforasingleprocessfail-
ureduetotheunboundedtimingcharacteristics. Themainca useofthisimpossibilityresultisthat
it is very difﬁcult to determine in asynchronous systems whe ther a process has failed or is simply
taking a long time for execution; so it is difﬁcult to deal wit h failures in these systems. On the
otherhand,insynchronoussystemsduetostricttimingcons traints,failurescaneasilybedetected.
The asynchronous model of distributed systems is widely use d, and such systems are prone
to failures. Thus, detection and/or prevention of failures in these systems is of vital importance.
555
Thedetectionofprocessfailuresisacrucialtaskinthedes ignoffaulttolerantdistributedsystems.
Detectionofcrashedprocessesisespeciallydifﬁcultinas ynchronoussystemsasitisimpossibleto
determine whether a process has really crashed or is very slo w (as there are no timing constraints
present).
In this chapter, we discuss the concept of unreliablefailur e detectors to deal with the impossi-
bilityresults in asynchronous distributed systemswith cr ash failures. Basically, the asynchronous
modelofcomputationisextendedwithafailuredetectionme chanismthatis pronetoerrors inthe
sense that a process can brand another process as crashed eve n though the process is running. We
study failure detectors in asynchronous distributed syste ms. We investigate two major problems
faced in asynchronous distributed environments, namely, c onsensus and atomic broadcast. We
studyseveralsolutionsfortheseproblems.
15.2 UnreliableFailureDetectors
Chandra and Toueg [3] introduced the concept of unreliable f ailure detectors and showed how
unreliable failure detectors can be used to solvetwo fundam ental paradigms of asynchronous dis-
tributedsystemswithcrash failures, namely,consensusan datomicbroadcast.
15.2.1 The SystemModel
Weconsiderasynchronousdistributedsystemsinwhichther eisnoboundonmessagedelay,clock
drift, or the time taken to execute a step. The system consist s of a ﬁnite set of nprocesses,Q=
p1,p2,...,p n. Each pairofprocessesisconnected byareliablecommunica tionchannel. Aprocess
can fail bycrashingonly,i.e.,by prematurelyhalting. A pr ocess behavescorrectly (i.e.,according
toitsspeciﬁcation)untilitcrashes.
A discrete global clock is assumed, and the range of the clock ’s ticks, Φ, is the set of natural
numbers. The global clock is used for the sake of simplicity o f presentation and reasoning and is
notaccessibletotheprocesses.
A processpiis said to crash at time t if pidoes not perform any action after time t. Process
failures are permanent; once a process crashes, it does not r ecover. A correctprocess is a process
thatdoes notcrash.
Informally, a run is an inﬁnite execution of the system. Give n any runσ, Crashed(t,σ) is the
set of processes that have crashed by time t and Up(t, σ) is the set of processes that are correct
(i.e., have not crashed) by time t, that is, Up(t, σ) =Q−Crashed (t,σ).Crashed(σ) is the set
of processes that have crashed in a run σand is equal to/uniontext
tCrashed(t,σ).Up(σ) is the set of
processesthatarecorrectinarun σandisequalto Q−Crashed(σ). Ifaprocessp∈Crashed(σ),
we say that p is a faulty process in σ. If a process p∈Up(σ), we say that p is a correct process in
σ. Weconsideronly executionrunswhere atleast oneprocessi s correct.
556
Failure Patternsand Environments
A failure pattern is a function F from Φto2Q, where F(t) denotes the set of processes that have
crashed through time t. An environment E is a set of failure pa tterns. Environments describe
the crashes that can occur in a system. In general, we conside r the environments that contain all
possiblefailurepatterns;i.e., thereisno boundonthenum berofprocesses thatcrash.
Each process pihas alocalfailuredetectormoduleofD, denotedby Di. Associatedwitheach
failuredetector D is a range RDofvalues outputby thefailuredetector. A failuredetector history
H with range R is a fuction H from ΩXΦto R. D(F) denotes the set of possible failure detector
histories permitted for the failure pattern F, i.e., each hi story represents a possiblebehaviour of D
forthefailurepatternF.ForanyfailuredetectorD,anyfai lurepatternFandanyhistoryHinD(F),
H(pi,t)istheset ofprocesses suspectedby process piattimet.
15.2.2 Failure Detectors
A failure detector Dis a distributed oracle that gives hints about failure patte rns. Each process
piin the distributed environment has its own local failure det ectorDi, which monitors all other
processesand maintainsalistofprocesses,currently pisuspectstohavecrashed. Thesuspicionis
based onrelativetimeoutsofotherprocessesat pi.
Thus, a failure detector Das the vector D=< D p1,Dp2,....D pn>, whereDiis the failure
detector module at process piwhich outputs the set of processes that it currently suspect s to have
crashed. Formally,afailuredetectorisafunction“fromti meandthesetofallruns"to 2Q.Dp(t,σ)
is the set of processes that are suspected to have crashed by p ’s failure detector module at time t
in runσ. If q∈Dp(t,σ), we say that p suspects q at time tin runσ. After a process crashes, it is
immaterial what its failure detector module indicates. We f ormalize this by assuming that if p ∈
Crashed (t,σ), thenDp(t,σ) =φ.
The failure detectors can make mistakes, i.e., a correct pro cess may be added to the list of
suspects and can later be removed if the failure detector rea lizes that it was a mistake. Thus, a
failuredetectormay continuallyadd and removeprocesses f rom itslistofsuspects. Processes can
be added and removed from the list of suspects by each failure detector module any number of
times. Atanytime,failuredetectormodulesat twoprocesse s mayhavedifferentlistsofsuspects.
Itshouldbenotedthatadditionofacorrectprocesstotheli stofsuspectsbyanyotherprocesses
or by all other processes should not prevent this process fro m behaving correctly, according to its
speciﬁcations.
15.2.3 Completeness and Accuracy Properties
Chandra and Toueg classiﬁed failure detectors in terms of th eir completeness and accuracy prop-
erties. Informally, completeness requires that a failure d etector eventually suspects all processes
that have crashed and accuracy resticts the mistakes a failu re detector can make (i.e., a correct
processsuspectanothercorrect process). Theydeﬁnetwoty pesofcompletenessandfourtypesof
accuracy properties, givingriseto eightclasses offailur edetectors.
557
ChandraandTouegintroducedtheconceptofreducibilityam ongfailuredetectors. Informally,
a failure detector D is reducible into another failure detector D’ if there exists a distribut ed al-
gorithm that can transform D into D’. In this case, any proble m that can be solved using D’ can
also be solved using D. If two failure detectors are reducibl e to each other, they are said to be
equivalent .
Chandra and Toueg put failure detectors into eight classes a nd ordered them into a hierarchy
according to the reducibility relationship. In this hierar chy, some failure detectors can solve the
consensus problem with any number of process failures, whil e others require a certain number of
correct processes to solve the consensus problem. This requ irement and the boundary where this
requirementbecomes necessary havebeen clearly speciﬁed.
We nowdeﬁnecompletenessandaccuracy propertiesofafailu redetector.
Completeness
Deﬁnition 29. Completeness: There is a time after which every process that has crashed is p er-
manentlysuspectedbya correct process.
Completenesscan beoftwo types:
1.Strong completeness: Eventually every process that crashes is permanently suspe cted by
everycorrect process. Notationally,
∀σ,∀p∈Crashed (σ),∀q∈Up(σ),∃tsuchthat∀t′≥t:p∈Dq(t′,σ)
2.Weakcompleteness: Eventuallyeveryprocessthatcrashesispermanentlysuspe ctedbysome
correct process. Notationally,
∀σ,∀p∈Crashed (σ),∃q∈Up(σ),∃tsuchthat∀t′≥t:p∈Dq(t′,σ)
Note that completeness by itself may not be of much use. For ex ample, a failure detector
may satisfy the strong completeness property by having ever y process permanently suspect all
other processes. Such a failure detector is useless because it provides no information about actual
failures. Thus, a failure detector must satisfy some accura cy property to be useful. We deﬁne this
propertynext.
Accuracy
Deﬁnition 30. Accuracy: There is a timeafter which a correct processis never suspect ed byany
correct process.
There aretwotypes ofaccuracy properties:
1.Strongaccuracy: Correct processes are neversuspectedby anycorrect proces s. Formally,
558
∀σ,∀t,∀p,q∈Up(t,σ) :p∝\⌉}atio\slash∈Dq(t,σ)
Since in any practical system it is extremely difﬁcult to ach ieve accuracy, we weaken it as
follows:
2.Weakaccuracy: Somecorrect process isneversuspectedby anycorrect proce ss. Formally,
∀σ,∃p∈Up(σ),∀t,∀q∈Up(t,σ) :p∝\⌉}atio\slash∈Dq(t,σ)
We collectively refer to strong accuracy and weak accuracy a s theperpetual accuracy proper-
tiesbecausethesepropertiesholdallthetime. Notethatev enweak accuracy isdifﬁculttoachieve
because a failure detector (even at a correct process) may su spect a correct process and then later
correctitsmistake. Theweakaccuracypropertydoesnotper mitthis. Thus,wefurtherweakenthe
accuracyrequirementandallowfailuredetectorsthatmays uspectacorrectprocessatsomepoints
intherun, butthey eventually satisfythestrongand weak accuracy properties.
EventualAccuracy
Deﬁnition31. EventualAccuracy: Weneednotrequireaccuracypropertytobesatisﬁedbyeach
processatallthetime. Instead,we requiretheaccuracypro pertytobeeventuallysatisﬁed.
There aretwotypes ofeventualaccuracies:
1.Eventual strong accuracy: There is a time after which correct processes are not suspect ed
byany correct process. Formally,
∀σ,∃t,∀t′≥t,∀p,q∈Up(t′,σ) :p∝\⌉}atio\slash∈Dq(t′,σ)
2.Eventual weak accuracy: There is a time after which some correct process is not suspec ted
byany correct process. Formally,
∀σ,∃t,∀t′≥t,∃p∈Up(σ),∀q∈Up(σ) :p∝\⌉}atio\slash∈Dq(t′,σ)
We collectively refer to eventual strong accuracy and event ual weak accuracy as the eventual
accuracy propertiesbecausethesepropertiesholdeventually.
559
15.2.4 Types of Failure Detectors
Based on types of accuracies and completeness deﬁned above, failure detectors can be classiﬁed
intothefollowingcategories:
1.Perfect FailureDetectors (P): Failure detectors that satisfy the strong completeness and the
strongaccuracy properties arecalled thePerfect FailureD etectors.
2.EventuallyPerfectFailureDetectors( ♦P):Failuredetectorsthatsatisfythestrongcomplete-
nessandtheeventualstrongaccuracypropertiesaretermed astheEventuallyPerfectFailure
Detectors.
3.Strong Failure Detectors (S): Failure detectors that satisfy the strong completeness and the
weak accuracy properties arecalled theStrongFailureDete ctors.
4.EventuallyStrongFailureDetectors( ♦S):Failuredetectorsthatsatisfythestrongcomplete-
ness and the eventual weak accuracy properties are called th e Eventually Strong Failure
Detectors.
5.Weak Failure Detectors (W): Failure detectors that satisfy the weak completeness and th e
weak accuracy properties arecalled theWeak FailureDetect ors.
6.Eventually Weak Failure Detectors ( ♦W):Failure detectors that satisfy the weak complete-
ness and the eventual weak accuracy properties are called th e Eventually Weak Failure De-
tectors.
7. Another class of failure detectors is the one that satisﬁe s weak completeness and strong
accuracy properties. Thisclass isdenoted by ϑ.
8. The last class is the set of failure detectors that satisfy weak completeness and eventually
strongaccuracy properties. Thisclass isdenoted by ♦ϑ.
15.2.5 Reducibility ofFailure Detectors
A failure detector D is reducible to another failure detecto r D’ if there is an algorithm that trans-
formsafailuredetectorDintoanotherfailuredetectorD’. Anaturalquestionis: whatdoesitmean
that an algorithm transforms D into D’? An algorithm T D→D′transforms a failure detector D
into another failure detector D’ if and only if for every run R of T D→D′under a failure pattern F
usingD,outputR∈D’(F), where outputRistheoutputofrunRusingfailuredetectorD andD’(F)
denotes the set of histories of failure detector D’ for failu re pattern F. That is, variable output pat
process p emulates the output of D’. Thus, T D→D′can emulate D’ using D. T D→D′need not
emulate all failure detector histories of D’; however, all f ailure detector histories it emulates must
behistoriesofD’. AlgorithmT D→D′iscalled the reductionalgorithm .
Given a reduction algorithm T D→E, any problem that can be solved using E, can also be
solved using D. We illustrate this with an example: suppose a given algorithm A requires failure
560
detector E, but only failure detector D is available. We can e xecute A using failure detector D as
follows. ConcurrentlywithA,processesrunT D→EtotransformDtoE.AlgorithmAismodiﬁed
at process pas follows: wheneverA requires thatp queries it sfailuredetectormodule,p reads the
current valueof output pwhichis concurrentlymaintainedbyT D→E.
SinceT D→EisabletouseDtoemulateE,Dmustprovideatleastasmuchinf ormationabout
processfailures asE does. Thus,ifthereisan algorithmT D→E, thattransformsDintoE,wesay
that E is weaker than D and denote it by D ⊑E. Note that⊑is a transitiverelation. If D ⊑E and
E⊑D, thenwesay thatD and E are equivalent and denoteitbyD ≡E.
IfDandεare two classes of failure detectors and there exists an algo rithm T D→Ethat can
transform every failure detector D ∈Dinto a failure detector E ∈ε, then we say that the class of
failure detectors Dis reducible to the class of failure detectors εand this is denoted by D⊑ε. In
this case,εis weaker than D. IfD⊑εandε⊑D, thenDandεare equivalentand this is denoted
byD≡ε.
From a trivial reduction algorithm where each process p peri odically writes the current output
of its failure detector module into output p, the following relations between the classes of failure
detectors areobvious:
Observation1: P⊑ϑ, S⊑W,♦P⊑♦ϑ,♦S⊑♦W.
15.2.6 Reducing WeakFailure Detector Wto aStrong Failure D etector S
InFigure15.1,wegiveareductionalgorithmT D→D′(duetoChandraandToueg) thattransforms
anygivenfailuredetectorDthatsatisﬁesweakcompletenes s,intoafailuredetectorD’thatsatisﬁes
strongcompleteness. D’satisﬁes thesameaccuracy propert ythat D satisﬁes. Thus,thisalgorithm
strenghtensthecompletenesswhilepreserving theaccurac y.
Informally, the conversion of any weak failure detector W to a strong failure detector S is as
follows: Initially, for every process p, output pis set to null. (Recall that output pis the vari-
able emulating the output of the failure detector module D′
p.) Every process p periodically sends
(p,suspects p) to every process, where suspects pdenotes the set of processes that p suspects ac-
cording to its failure detector module Dp. When a process p recieves a message (q, suspects q)
from a process q, process p adds the suspect list of process q, suspects q, to its output, output p,
and removestheprocess qfrom itsoutputas it isacorrect pro cess.
ACorrectness Argument
Thecorrectness proofofthealgorithminvolvesshowingthe followingthreeproperties:
1. It transformsweak completenessintostrongcompletenes s.
2. It preservestheperpetual accuracy.
561
Every processp executesthefollowing:
output p←φ
cobegin
||Task 1: repeat forever
suspects p←Dp{pqueries itslocal failuredetectormodule Dp}
send(p,suspects p)to allotherprocesses.
||Task 2: when recieve(q, suspects q)for aprocessq
output p←(output p∪suspects q)−{q} {output pemulatesEp}
coend
Figure15.1: Transformingweak completenesstostrongcomp leteness.
3. It preservingtheeventualaccuracy.
We showthesepropertiesin thefollowingthreelemmas.
Lemma 1: Let p be any process that crashes. If eventually some correct process permanently
suspects p in HD, then eventually all correct processes permanently suspec t p inoutputR, where
HDisthehistoryoffailuredetectorDand outputRistheoutputofanarbitraryrunRusingfailure
detectorD.
Since process p crashes, there is a time t’ after which no proc ess recieves a message from p.
Suppose there is a correct process q that permanently suspec ts p inHDafter time t. Consider the
executionofTask1byprocessqaftertime tp=max(t,t’). Processqsendsamessage(q, suspects q)
such that p∈suspects qto all processes. Eventually, every correct process reciev es (q,suspects q)
andaddsp tooutput(inTask2). Sincenocorrect processreci evesanymessagesfrom paftertime
t’ andtp≥t’, no correct process removes p from its output after tp. Thus, there is a time after
whichevery correct process permanentlysuspectspin outputR.
Lemma 2: Let p be any process. If no process suspects p in HDbefore time t, then no process
suspectsp in outputRbeforetimet.
Suppose there is a timet before which no process suspects pro cess p inHD. Thus, no process
sends a messageoftype(-,suspects)such that p ∈suspects before timet. Thus, no process q adds
p tooutput qbefore timet.
Lemma 3: Let p be a correct process. If there is a time after which no cor rect process suspects p
inHD, then thereisatimeafter whichnocorrect process suspects pinoutput R.
562
Suppose there is a time t after which no correct process suspe cts p inHD. Thus, all processes
that suspect p after time t eventually crash. Thus, there is t ime after which no process will send
messagesoftype(-,suspects)suchthatp ∈suspects. Thus,thereisatimet’afterwhichnocorrect
process recieves amessageoftype(-, suspects)such that p ∈suspects. Let q bea correct process.
We need to show that there is a time after which q does not suspe ct p inoutputR. Consider the
execution of Task 1 by process p after time t’. Process p sends the message (p, suspects p) to q.
When q receivesthismessage, itremovespfrom output qifp is presentin output q(Task 2). Note
that q does not recieve any messages of type (-, suspects) suc h that p∈suspects after time t’,
therefore, q does not add p to output qafter time t’. Thus, there is a time after which q does not
suspectp in outputR.
Theorem 1: ϑ⊑P,W⊑S,♦ϑ⊑♦P and♦W⊑♦S.
Proof:LetDbeanyfailuredetectorin ϑ, W,♦ϑor♦W.WeshowthatT D→EtransformsDinto
a failure detector E in P, S, ♦P, or♦S. Since D satisﬁes weak completeness, E satisﬁes strong
completeness(from Lemma1). We now argue that D and E havethe sameaccuracy properties. If
D is inϑor W, then D and E have the same accuracy property (from Lemma 2 ). If D is in♦ϑor
♦W, then Dand E havethesameaccuracy property (fromLemma3).
Thuswe have,
ϑ⊑P,W⊑S,♦ϑ⊑♦P and♦W⊑♦S
2
From Theorem 1and Observation1,wehavethefollowingresul t:
P≡ϑ, S≡W,♦P≡♦ϑ, and♦S≡♦W.
A signiﬁcance of this result is that if we solve a problem for t he four failure detectors with
strongcompleteness,theproblemis automaticallysolvedf ortheremainingfourfailuredetectors.
15.2.7 ReducinganEventuallyWeakFailureDetector ♦WtoanEventually
Strong Failure Detector ♦S
Figure15.2givesanalgorithmthatconvertsanyeventually weakfailuredetectorD ∈♦W intoan
eventuallystrongfailuredetectorE ∈♦S. Q istheset ofallprocesses.
Atprocessp,variablesuspected p(r,q)denoteshowmanytimesprocessqhassuspectedprocess
randvariablerefuted p(r,q)denoteshowmanytimesprocessrhasrefutedprocessq. Bothvariables
are initializedtozero. S pdenotesthesuspect listofprocess p.
An Explanationof the Algorithm
Thealgorithmconsistsoffourtasks.
563
Process p runs thefollowing:
forall q,r∈Q
{Numberoftimesq suspectedraccording top}
suspected p(r, q)←0
{Numberoftimesrrefuted q according top}
refuted p(r, q)←0
cobegin
||Task 1: repeat forever
if(r∈Dpand refuted p(r, p)≤suspected p(r, p))then
prbcasts (p, suspects,r, refuted p(r, p)+1)
||Task 2: when p rbdelivers(q, suspects,r, k)
suspected p(r, q)←k
ifp =rthen p rbcasts(p, refutes, q,k)
||Task 3: when p redelivers(r, refutes, q,k)
refuted p(r, q)←k
||Task 4: repeat forever
forallprocesses r
if∃q : suspected p(r, q)>refuted p(r, q)
thenS p←Sp/uniontext{r}
elseS p←Sp-{r}
coend
Figure 15.2: An algorithm to reduce an eventually weak failu re detector into an eventually strong
failuredetector.
In Task 1, a process p continuously performs the following fo r every process r that it suspects
according to its failure detector module Dp: if the number of times process r is suspected by p
is greater than the number of times r has refuted p, then p broa dcasts a suspect message which
containstheincrementedrefuted value.
In Task 2, when process p recieves a suspect message (q, suspe cts, r, k) from a process q, it
updates suspected p(r, q) to k. If process p discovers that it was erroneously sus pected by process
q, pbroadcasts an appropriaterefutation,refuting thesus picionofprocessq.
In Task 3, when process p receives a refutation message (r, re futes, q, k) from process r, it
updatesrefuted p(r, q)to k.
In Task 4, the followingis repeatedly donefor every process r: if there exists a process q such
that the number of times q suspects process r is greater than t he number of times the process r
refutes q according to p, then process r is added to the suspec t list of process p. Otherwise, r is
removedfromthesuspectlistofprocessp.
564
Correctness Argument
Acorrectnessargumentofthealgorithmisasfollows. Whena processqrecievesasuspectmessage
accusing process p, process q may add p to its list of suspects Sq. However, upon receiving p’s
refutation,process qwillremovep fromitslistofsuspects Sq. However,p can besuspectedagain
and added to Sqa second time. However, a further refutation from p will caus e p to be again
removed from Sq. Thus, a possibly inﬁnite sequence of suspicions followed b y corresponding
refutations may occur, resulting in p being repeatedly adde d to and removed from Sq. However,
fromtheeventualweakaccuracypropertyofD,thereisatime afterwhichsomecorrect processis
not suspected. That is, there is a process p such that there is a timeafter which no correct process
receives a message of type (*, suspects, p, k), suspecting p. Thus, after a time no correct process
addsprocessptoitssuspectlist. Togetherwiththerefutat ionmechanism,thisensurestheeventual
weak accuracy property oftheconstructed E.
Now let us see why E satisﬁes the strong completeness propert y. Since D satisﬁes the weak
completeness property, eventually every process that cras hes is permanently suspected by some
correct process, say p. Thus, eventually process p will repe atedly broadcast (p, suspects, *, k)
messages for these crashed processes and since these proces sed have crashed, no one will send
refute messages for them. Thus all crashed processes will ev entually belong to the suspect list
of all correct processes. Thus, due to the broadcast of suspe ct messages and weak completeness
property of D, E satisﬁes the strong completeness property. Thus E satisﬁes strong completeness
and weak accuracy.
15.3 TheConsensusProblem
In the consensus problem, each correct process proposes a va lue and all processes must reach a
unanimous and irrevocable decision on a value that is relate d to the proposed values [9]. The
consensusproblemisdeﬁned in termsofthefollowingproper ties:
1.Termination: Every correct process eventuallydecides somevalue.
2.UniformIntegrity: Everyprocess decidesat mostonce.
3.Agreement: Notwo correct processes decidedifferently.
4.UniformValidity: Ifaprocess decides avaluev,then someprocess proposedv.
It is widely known that the Consensus can not be solved in asyn chronous systems in the pres-
ence of even a single crash failure. This is primarily becaus e one can not distinguish between
a process that has crashed and a process that is responding ve ry slow (may be due to the slow
network).
565
15.3.1 Solutions to the Consensus Problem
ChandraandTouegshowedhowtosolvetheconsensusproblem u singunreliablefailuredetectors
for each of the eight classes of failure detectors. From the f ollowing property, the classes of
failure detectors P, S, ♦P,♦Sare, respectively, equivalent to failure detectors ϑ,W,♦ϑ,♦W.
Notationally,
P≡ϑ, S≡W,♦P≡♦ϑ, and♦S≡♦W
So the problem of solving the consensus problem using unreli able failure detectors reduces to
solvingitforfourclassesoffailuredetectorsthatsatisf ystrongcompleteness(i.e.,P,S, ♦Pand♦
S), instead of solving it for all eight classes. Since P is red ucible to S and♦P is reducible to♦S
(i.e., P⊑S and♦P⊑♦S), the algorithms for solving consensus using S also solves the consensus
usingPand thealgorithmsforsolvingconsensususing ♦Salso solvestheconsensususing ♦P.
Next, we present algorithms that solve consensus using S and ♦S. The consensus algorithm
using S can tolerateany numberof process failures. However , the consensus algorithmusing ♦S
requires amajorityoftheprocesses tobeup.
15.3.2 A Solution Using Strong Failure Detector S
The algorithm in Figure 15.3 solves the consensus problem in an asynchronous system using a
failuredetectorDthatsatisﬁesstrongcompletenessandwe akaccuracy(i.e.,D ∈S).Thisalgorithm
toleratesany numberofprocess failures(upton-1 faultypr ocesses amongatotalofn processes).
Notations:
•ipisthevalueproposedby processp.
•⊥is nullvalue.
•Vp[q]is theprocess p’sestimateofprocess q’sproposedvalue.
•Vpis processp’s estimateoftheproposedvaluesby allotherpr ocesses.
•△ pcontainsallthevaluesof Vp.
•rpis thecurrent round numberofprocess p.
•msgs p(rp)is the set of messages that p recieves from other processes ab out the proposed
valuesinround rp.
•lastmsgs pcontainstherecieved Vqforall processes qby theprocessp.
566
Every processp executesthefollowing:
procedurepropose( ip)
Vp←<⊥,⊥,...,⊥>{p’sestimateoftheproposedvalues}
Vp[p]←ip;
△p←Vp
Phase1:{Executeround rp, 1≤rp≤n-1}
forrp←l ton-1
psends (rp,△p, p)toall otherprocesses
waituntil [∀q:received(rp,△q,q)orq∈Dp]{query thefailuredetector}
msgs p[rp]←{(rp,△q,q)|received(rp,△q,q)}
△p←<⊥,⊥,...,⊥>
fork←1 ton
if(Vp[k] =⊥and∃(rp,△q,q)∈msgs p(rp)with△q[k]∝\⌉}atio\slash=⊥)
thenVp[k]←△ q[k]
△p[k]←△ q[k]
Phase2: p sendsVptoallprocesses
wait until [∀q:receivedVqorq∈Dp]{querythefailuredetector}
lastmsgs p←{Vq|receivedVq}
fork←1to n
if∃Vq∈lastmsgs pwithV q[k] =⊥
thenVp[k]←⊥
Phase3: decideon theﬁrst non- ⊥elementofVp
Figure15.3: AnAlgorithmtoSolvetheconsensusproblemUsi ngaStrongFailureDetectorD ∈S
.
An Explanationof the Algorithm
Thisalgorithmhas3phases. Initially, Vpissettonulland Vp[p]containsthevalue, ip,proposedby
process p.
In the ﬁrst phase, each process executes n-1 asynchronous ro unds. In each round, processes
broadcast and relay their proposed values. Then, each proce ss p waits until it receives a round r
messagefromeveryprocessthatisnotin Dp,beforeproceedingtoroundr+1. Whilepiswaiting
for a message from a process q in round r, it is possible that q i s added toDp. If this is the case,
p does not wait for q’s message before it proceeds to round r + 1 . All messages recieved by p in
roundrpare stored in msgs p(rp). If p’s estimateof someprocess k’s proposed valueis nullan d it
hasrecievedamessageoftheform (rp,△q,q)suchthatq’sestimateofprocessk’sproposedvalue
isnotnull,thenpupdatesitsestimateofk’sproposedvalue toq’sestimateofprocessk’sproposed
value.
Inthesecondphase,aprocesspbroadcastsitsestimateofth eproposedvaluesoftheprocesses
567
and waits until it receives the estimate from every process t hat is not in Dp. While p is waiting
for an estimate from q, it is possible that q is added to Dp. If this occurs, p stops waiting for
q’s estimate. By the end of the second phase, correct process es agree on a vector based on the
proposedvalues ofall processes. Theith elementofthisvec toreithercontainstheproposed value
of processpior⊥. If any of the correct processes does not agree with the propo sed value of a
process, say pi, then the ith element in the vector is set to null and consensu s is not reached on
the proposed value. It has been shown that this vector contai ns the proposed value of at least one
process.
In thethirdphase, allcorrect processesdecidetheﬁrst non -trivialcomponentofthisvector.
This solution for the consensus problem using strong failur e detectors, even one having weak
accuracy property, has an excellent fault tolerance capaci ty; the solution tolerates any number of
process failures.
Also, since a weak failure detector W is reducible to a strong failure detector S using the
algorithmgivenabove,thisalgorithmalsosolvestheconse nsususingaweak failuredetectorW.
15.3.3 A Solution Using Eventually Strong Failure Detector ♦S
The previoussolutionto theConsensus problem used failure detectors with weak accuracy : some
correct process is never suspected. We now present a solutio n to the consensus problem using a
failure detector that satisﬁes the eventual weak accuracy : all processes may be erroneously added
to the lists of suspects at one time or another, but there is a t ime after which a correct process p
is permanently removed from the list of suspects. However, a t any given time t, processes cannot
determine if a particular process is correct, or whether a co rrect process will never be suspected
aftertimet.
Figure 15.4 presents a solution to the consensus using an eve ntually strong failure detector
D∈♦S. Such failure detectors satisfy strong completeness and e ventual weak accuracy. The al-
gorithm requires that a majority of the processes are always up. If f is the maximum number of
processes that may crash at any time, this algorithm require s that f<⌈n/2⌉, that is, at least (n +
1)/2processes are correct at alltimes.
An Explanationof the Algorithm
Thisalgorithmproceedsinasynchronousroundsandmakesus eoftherotatingcoordinator paradigm
untiladecisionis reached. Allprocesses knowthat duringr oundr, thecoordinatoris processc=(r
mod n) + 1. All messages are either to or from the "current" coo rdinator. The "current" coordi-
nator tries to determinea consistentdecision value. If the current coordinatoris correct and is not
suspectedby anysurvivingprocess,then itsucceeds and bro adcaststhedecisionvalue.
The algorithm goes through three asynchronous stages where each stage can contain several
asynchronous rounds. In the ﬁrst stage, several decision va lues are proposed. In second stage, a
value gets locked: no other decision value is possible. In th e third and ﬁnal stage, the processes
decideonthelocked valueand consensusis reached.
568
Every process pexecutes the following:
estimate p←ip{p’s estimate ofthe decision value }
statep←undecided
rp←0{rpdenotes the current round number }
tsp←0{the round inwhich estimate pwas last updated, initially 0 }
cobegin
||Task 1:{Rotate through coordinators until adecision is reached }
while state p=undecided
rp←rp+l
cp←(rpmod n)+1{cpisthe current coordinator }
Phase 1:{All processes psend estimate pto thecurrent coordinator }
psends (p, r p, estimate p, tsp)to c p
Phase 2:{The current coordinator gathers ⌈(n+ 1)/2⌉estimates and proposes anew estimate }
if p=c pthen
waituntil [for⌈(n+ 1)/2⌉processes q: received(q,r p,estimate q,tsq)from q ]
msgs p[rp]←{(q,rp,estimate q,tsq)|preceived(q,r p,estimate q,tsq)from q}
t←largest ts qsuch that (q,r p,estimate q,tsq)∈msgs p[rp]
estimate p←select one estimate qsuch that (q,r p,estimate q,t)∈msgs p[rp]
psends (p, r p,estimate p)toall processes
Phase 3:{Allprocesses wait forthe new estimate proposed by
the current coordinator }
wait until [received(c p,rp,estimatec p)from c porcp∈Dp]{Query thefailure detector }
if[received(c p,rp,estimate cp)from c p]then{preceived estimate cpfromcp}
estimate p←estimate cp
tsp←rp
psends (p, r p, ack) toc p
else
psends(p, r p,nack) toc p{p suspects that c pcrashed}
Phase 4:{The current coordinator waits for ⌈(n+ 1)/2⌉replies.
If these replies indicate that ⌈(n+ 1)/2⌉processes adopted
its estimate, the coordinator broadcatss a request todecid e.}
if p=c pthen
wait until [for⌈(n+1)/2⌉processes q: received (q, r p, ack) or(q, r p, nack) ]
if[for⌈(n+1)/2⌉processes q: received (q, r p,ack)]
then pR-broadcasts (p, r p,estimate p,decide)
||Task 2:{When preceives adecide message, it decides }
when pR-delivers (q,r q,estimate q,decide) forsome q
ifstate p=undecided then
decide on estimate q
statep←decided
coend
Figure 15.4: An algorithm to solve the consensus problem usi ng an eventually strong failure de-
tectorD∈♦S.
569
Initially, the state of a process p is "undecided" and its est imate of the decision value is ip.
A timestamp tspis associated with every process p which contains the round n umber when its
estimatewas lastupdated.
Each round ofTask1 consistsoffourasynchronousphases.
In phase 1, every process p sends its current estimate of the d ecision value to the current
coordinator cp. Italso sendstheroundnumber( tsp)in whichit adoptedthisestimate.
In phase2, thecoordinatorc gathers ⌈(n+ 1)/2⌉such estimatesand proposesanew estimate.
The current coordinator waits until it receives estimates f rom⌈(n+ 1)/2⌉processes. It stores all
these estimates in the array msgs p[rp], selects one with the largest timestamp, and sends it to all
theprocessesas thenewestimate, estimate p.
In phase 3, all processes wait for the new estimate proposed b y the current coordinator. For
each process p, therearetwo possibilities:
1. Process p recieves estimatec pfromthecoordinator cp: inthiscase, pupdates itstimestamp
tothecurrent roundnumberand sendsan ack to cpto indicatethat itadopted estimatec pas
itsownestimate.
2. Process p does not recieve an estimatec pfrom the coordinator cpand upon consulting its
failure detector module Dp, p suspects that the coordinator cphas crashed: in this case, p
sendsanack to cp.
In phase 4, the coordinator cpwaits for⌈(n+ 1)/2⌉replies (acks or nacks). If all replies are
acks, thencpknows that a majority of processes changed their estimates t oestimatec pand thus
estimate pis lockedand cpbroadcasts arequest todecidevalue estimate p.
In Task 2, at any time, if a process receives such a request, it decides accordingly, i.e., when
a process p recieves a message of the form (q, rq,estimate q, decide) from a process q, then p
decidesontheestimateofqprovidedithasnotalreadydecid ed. Inthiscase, processpchangesits
stateto"decided".
For correctness of the algorithm, we have to show that the alg orithm satisﬁes termination,
uniform validity, agreement, and uniform integrity proper ties. The readers are referred to the
originalsourceforacorrectness proof.
This algorithm requires that f <⌈n/2⌉, i.e., at least⌈n/2⌉processes are correct and assumes
thatprocesses haveaprioriknowledgeofthelistofpotenti alcoordinators.
15.4 AtomicBroadcast
Atomic broadcast is one of the fundamental problems in fault -tolerant distributed computing. It
is a powerful paradigm in the design of fault-tolerant distr ibuted computing systems. Chandra
and Toueg showed that the results of consensus can be applied to solve the problem of atomic
broadcast. Informally, atomic broadcast requires that all correct processes deliver the same set of
570
messagesinthesameorder(i.e.,deliverthesamesequenceo fmessages). Formally, atomicbroad-
castcan bedeﬁned asa reliablebroadcast withthetotalorderpro perty.
TheTotalOrderproperty: Iftwocorrectprocessespandqdelivertwomessagesmandm′,then
p deliversmbefore m′ifand onlyifq deliversmbefore m′.
The total order and agreement properties of atomic broadcas t ensure that all correct processes
deliverthesamesequenceofmessages.
In asyncronous sytemswith crash failures, consensus and at omicbroadcast are equivalentand
this can be shown by reducing one to the another. Consensus ca n be reduced to atomic broadcast
as follows: In the consensus problem, to propose a value, a pr ocess atomically broadcasts it. To
decide a value, a process picks the value of the ﬁrst message t hat it atomically delivers. The total
orderpropertyofatomicbroadcastensuresthatallcorrect processesdeliverthesameﬁrstmessage.
Hence,allcorrectprocesseschoosethesamevalueandtheag reementpropertyoftheconsensusis
satisﬁed. In thenextsection,weshowhowtoreduce atomicbr oadcastto consensus.
A consequence of this equivalence is that a solution for one c an be used to solve the other. In
addition,it impliesthefollowingfor solvingatomicbroad cast inasynchronoussystems:
1. Since consensus has no deterministic solution in aynchro nous systems, even if we assume
thatatmostoneprocessmayfailbycrashing,atomicbroadca stcannotbesolvedbyadeter-
ministicalgorithmevenifat mostoneprocess mayfail by cra shing.
2. Asconsensusissolvableusingrandomizationorunreliab lefailuredetectorsinasynchronous
systems,atomicbroadcast can besolvedusingthesetechniq ues.
15.5 ASolutiontoAtomicBroadcast
Figure 15.5 presents a solution (due to Chandra and Toueg) to atomic broadcast problem using
the consensus in asynchronous systems. This algorithm show s how to transform any consensus
algorithm into an atomic broadcast algorithm in asynchrono us systems. This atomic broadcast
algorithmtolerates as manyfaulty processesas theconsens usalgorithmdoes.
This atomic broadcast algorithm uses repeated executions o f consensus. The kth execution of
consensus is used to decide on the kth batch of messages to be a tomically delivered. Processes
distinguish between these executions by tagging all the mes sages pertaining to the kth execution
ofconsensuswiththecounterk.
The atomic broadcast algorithm uses R_broadcast(m) and R_d eliver(m) primitives of reliable
broadcast. To avoid any confusion, note that the primitives A_broadcast(m) and A_deliver(m)re-
spectivelyrefertoabroadcastandadeliveryinatomicbroa dcast,whileprimitivesR_broadcast(m)
and R_deliver(m) respectively refer to a broadcast and a del ivery associated with reliable broad-
cast. propose(k,−) and decide(k,−) are the propose and decide primitives corresponding to the
kthexecutionofconsensus.
571
Every processp executesthefollowing:
Initialization:
R_delivered←∅
A_delivered←∅
k←0
To executeA-broadcast(m): {Task 1}
R-broadcast(m)
A_deliver(-)occurs as follows:
when R_deliver(m) {Task 2}
R_delivered←R_delivered/uniontext{m}
when R_delivered-A_delivered ∝\⌉}atio\slash=∅ { Task 3}
k←k +1
A_undelivered←R_delivered-A_delivered
propose(k,A_undelivered)
waituntildecide(k, msgSetk)
A_deliverk←msgSetk-A_delivered
atomicallydeliverallmessages inA_deliverkinsomedeterminisicorder
A_delivered←A_delivered/uniontextA_deliverk
Figure15.5: A SolutiontoAtomicBroadcast UsingConsensus .
An Explanationof the Algorithm
Thealgorithmconsistsofthreetaskssuchthat: (1)ataskth atisenablediseventuallyexecutedand
(2)atask ican executeconcurrentlywithanotherTaskj prov idedi∝\⌉}atio\slash=j.
In Task 1, when a process p wants to A-broadcast a message m, it R_broadcasts m. In Task 2,
amessagemisadded to set R_delivered pwhenprocess p R_deliversit.
InTask3,whenaprocesspA_deliversamessagem,itaddsmtos etA_delivered p.A_undelivered p
(deﬁned as R_delivered p−A_delivered p) is the set of messages that p has R_delivered but
has not A_delivered yet. Process p periodically checks whet herA_undelivered pcontains mes-
sages. IfA_undelivered pcontains messages, p enters its next execution of consensus , say the
kth one, and proposes A_undelivered pas the next batch of messages to be A_delivered. Process
p then waits for the kth consensus decision, which is denoted bymsgSetk.msgSetkcontains
messages which are R_delivered but they are yet to be A_deliv ered. Finally, p A_delivers all
the messages in msgSetkexcept those already A_delivered by it (i.e, all the message s in the set
A_deliverk
p=msgSetk−A_delivered p) in some deterministic order that was agreed a prioriby
all processes.
Foracorrectness proofofthealgorithm,thereaders should referto theoriginalsource.
572
15.6 TheWeakestFailureDetectorstoSolveFundamentalAgr ee-
mentProblems
Delporte-Gallet et al. [5] showed that if exclude unrealist ic failure detectors1, then in an environ-
mentwherewedonotboundthenumberoffaultyprocesses,the classofPerfectfailuredetectorsP
istheweakesttosolvefundamentalagreementproblemslike unifromconsensus,atomicbroadcast
and terminatingreliablebroadcast(also called theByzant ineGenerals).
Delporte-Gallet et al. [5] collapsed the Chandra-Toueg fai lure detector hierarchy in this en-
vironment, and showed that P is the only useful class to solve these agreement problems. This
explains why most reliable distributed systems, we know of, rely on a group membership service
that precisely aims at emulating a Perfect failure detector P, that is, when a process is suspected
duetoatime-out,itisexcludedfrom thegroup. Thus,everys uspicionis taken asbeing accurate.
Uniform Consensus
In consensus, the agreement property allows the bad process es to decide differently from good
processes. This fact can be sometimes undesirable as it does not prevent a bad process from
propagating a different decision in the system before crash ing. In the unifrom consensus, the
uniform-agreement property allows no two processes (good o r bad) to decide differently, which
enforces thesamedecisiononanyprocess thatdecides.
Terminating Reliable Broadcast
Solving the consensus problem is equivalent to solving the a tomic broadcast problem, in any sys-
tem with reliable channels (i.e., where only a ﬁnite number o f messages can be lost). Atomic
broadcastentailsdeliveringmessagestoprocessesinarel iableandtotallyorderedmanner. Termi-
natingreliablebroadcastisastrongerformofatomicbroad cast. Interminatingreliablebroadcast ,
the processes deliver messages in the same sequence as atomi c broadcast does, but, in addition,
processes shoulddelivera speciﬁc nil valuefor every messa ge that was broadcast by a faulty pro-
cess but was not delivered by any correct process. This probl em is a rephrasing of the famous
ByzantineGenerals probleminthefail-stopmodel.
Delporte-Gallet et al. [5] showed that in environments wher e the number of faulty processes
is not bounded, uniform consensus is strictly harder than co nsensus, and uniform consensus and
atomicbroadcast arestrictlyweakerthan terminatingreli ablebroadcast.
In environments where the number of faulty processes is not b ounded, the exact information
aboutfailuresneeded tosolveconsensus(henceatomicbroa dcast)and terminatingreliablebroad-
cast, is captured by P. Thus,in thefailuredetectorhierarc hy, Pis theonlyuseful class tosolvethe
agreement problems.
1Unrealistic failuredetectorsarefailure detectorsthat c anguessthe futureandthus, cannot be implementedeven
ina perfectlysynchronoussystems.
573
15.6.1 Realistic Failure Detectors
Notethatafailuredetectorhasbeendeﬁnedas anyfunctionofthefailurepatternandthisfunction
may be able to provide information about the future failures . Such a failure detector does not
factor out synchrony assumptions of the system and can not be implemented even in a perfectly
synchronoussystem.
Delporte-Gallet et al. [5] restricted the scope of failure d etectors as functions of the "past"
failurepatternsanddeﬁnedtheclassofrealisticfailured etectorsR,whichcannotguessthefuture.
A failure detector is realistic if it cannot guess the future , i.e., there is no time t and no failure
pattern F at which the failure detector can provide exact inf ormation about crashes that will hold
aftert inF.
Formally,theclassofrealisticfailuredetector RisthesetoffailuredetectorsDthatsatisfythe
followingproperty:
∀(F, F′)∈E,∀t∈φsuchthat∀t1≤t;F(t 1)=F′(t1),
wehave:
∀H∈D(F),∃H′∈D(F′)suchthat∀t1≤t;∀pi∈Ω: H(p i;t1)=H′(pi;t1)
Thatis,afailuredetectorDisrealisticifforanypairoffa ilurepatternsFandF′thataresimilar
up to a given time t, whenever D outputs some information at a t ime t-k in F, D could output the
very same information at t-k in F′. Thus, a realistic failure detector cannot distinguishtwo failure
patternsaccordingtowhatwillhappeninthefuture. Inothe rwords,theoutputofarealisticfailure
detectordependsonlyuponthepast. Forarealisticfailure detectorD,foranyfailurepatternF,the
outputofD at timet isafunctionofFup totimet.
Two Examples
Wenowpresenttwofailuredetectorexamplestoillustratet heconcept. Theﬁrstfailuredetectoris
realisticand thesecondis non-realistic.
1.Scribe(C): Ascribe,’C’,isafailuredetectorwhichseeswhathappensa tallprocessesinreal
time and outputs a list of processes based on what it sees. For any failure pattern F, failure
detector C outputs, at any time t, the list of values of F up to t ime t, denoted by F[t]. For
each failure pattern F, C(F) is the singleton set that contai ns the failure detector history H
suchthat:
∀t∈φ,∀pi∈Ω,H(pi,t)=F[t]
Cis an exampleofa realisticfailuredetector.
574
2.The Marabout (M): Failure detector M (Marabout) outputs a list of processes. F or any
failurepattern F and at any process p i, the outputofthefailure detectorM is constantand it
is the listof faulty processes in F. Thus, M outputsthelist o f processes that havecrashed or
willcrash inF. Thisisan exampleofan unrealisticfailured etector.
To betterunderstand why M is an unrealisticfailure detecto r, considerthe failure patterns F
and F′such that (i) all processes are correct in F except p1which crashes at time 10, (ii) all
processes arecorrect inF′,and (iii)Fand F′are sameup totimet=9.
Consideranyhistory HofM(F)and anyhistory H′ofM(F′). By thedeﬁnitionofM,
•theoutputat anyprocessand at anytimeofH′isφand
•for any history H∈M(F), for any process pi, and any time t∈Φ, the output, H( pi,t), is
{p1}.
However, if M was realistic, its failure detector histories H in M(F) and H’ in M(F’) should
be such that H′and H are dentical up to time 9. Thus, M is unrealistic because itis accurate
aboutthefuture.
15.6.2 The weakestfailure detector forconsensus
Recallthatintheconsensusproblem,everyprocesspropose saninitialvalueandallprocessesmust
agreeononeofthesevaluessuchthattermination,agreemen t,andvaliditypropertiesaresatisﬁed.
Delporte-Gallet et al. [5] showed that if the number of fault y processes is not restricted, then P is
the weakest “realistic" failure detector class to solve con sensus. Prcisely, they showed that if the
numberoffaultyprocessesisnotrestricted,anyrealistic failuredetectorthatsolvesconsensuscan
betranformedintoafailuredetectorofclassP.Wenextgive anintuitiveproofofthislowerbound,
whichincludesthefollowingtwoparts.
1. First,weshowthat"anyconsensusalgorithmistotal",th atis,thecausalchainofanydecision
eventcontainsamessagefromeveryprocessthathasnotcras hedatthetimeofthedecision.
We argue that a consensus decision cannot be reached by any pr ocess without having con-
sulted every other correct process. If this is not true, a sit uation is possible where, after the
decision, all the consulted processes crash except the one w hich is not consulted and this
processlaterdecides differently. Ifalltheprocessesare consultedbeforeeverydecision,we
call suchan algorithmtotal.
2. Second part of the proof entails showing that "if a realist ic failure detector D implements a
totalconsensusalgorithm,then Dcan betransformed intoap erfect failuredetectorP."
This proof uses the fact that D is realistic and the algorithm is total. Therefore, for accurate
tracking of process failures, no decision is taken without c onsulting every correct process.
Aprocessissuspectedtohavecrashedinasequenceofconsen susinstances,ifandonlyifa
decisionisreached and theprocess was notconsultedinthed ecision.
575
15.6.3 The WeakestFailure Detector for Terminating Reliab le Broadcast
Terminating reliable broadcast is a strong form of reliable broadcast in which processes must de-
liver a speciﬁc value nilif the sender process has crashed, else, the processes must d eliver the
messagem, broadcastby sender(m).
A general variant of the problem is considered where every pr ocess is a potential initiator of
thebroadcast. Thekthinstanceofthebroadcastinitiatedb yprocesspiisdenotedby(i,k). Instance
(i,*)isdeﬁned by thefollowingproperties:
1. Validity: Ifacorrect process pibroadcastsamessagem,then pieventuallydeliversm.
2. Agreement: Ifaprocess deliversamessagem,then everyco rrect processdeliversm.
3. Integrity: Ifaprocess deliversa messagemand piis correct, thensender(m)= pi.
If we do not bound the number of processes that can crash, then among realistic failure de-
tectors, the weakest class to solve terminating reliable br oadcast is P. A sketch of the proof is as
follows.
Sufﬁcient condition: Terminating reliable broadcast problem can be solved by any perfect fail-
ure detector, including realistic failure detectors. When instance (k, k′) of the terminating reliable
broadcastisexecuted,eachprocesswaitsuntilitreceives thevaluefromp koritsuspectsp k. Inthe
former case, it proposes the received value to consensus, an d in the latter case, it proposes value
nil. Thevaluedeliveredistheconsensusvalue.
Necessary condition: Suppose A is any terminating reliable broadcast algorithm u sing a fail-
ure detector D. We can emulate the output of D, a failure detec tor of class P, using terminating
reliable broadcast algorithm A in a distributed variable ou tput(P) in the following way: whenever
a process p jdelivers nil for an instnace (i, *) of the algorithm, p jadds p ito output(P) j. Any pro-
cessthatcrasheswilleventuallybepermanentlyaddedtoou tput(P)ateverycorrectprocess. Thus,
strong completeness will be ensured. A process p iis added to output(P) jat some timet only if p i
isfaulty. SinceD is assumedtoberealistic,p imusthavecrashed by timet.
15.7 AnImplementationofa FailureDetector
Now we present an algorithm to implement a dailure fetector. The algorithm is a timeout based
implementation of eventually perfect failure detector D ∈♦Pin partially synchronous models.
The concept of partial synchrony in a distributed system lie s between the cases of a synchronous
systemandanasynchronoussystem. Inpartialsynchrony,th esystemisasynchronousinitiallybut
after an unknowntimet, the systembecomes synchronous. Thi s assumptioncaptures the fact that
thesystemdoesnotbehavealwaysassynchronous. Generally distributedsystemsaresynchronous
576
Every processp executesthefollowing:
Output p←∅ {Initializesoutputset toempty}
forall q∈/producttext
∆p(q)←defaulttime-outinterval {Set thetimeoutinterval}
Cobegin
Task1:repeat periodically
send“p-is-alive”toall
Task2:repeat periodically
forallq∈/producttext
ifq∝\⌉}atio\slash=Output pand
p didnotreceive“q-is-alive”duringthelast ∆p(q)ticksofp’sclock
Output p←Output p∪{q} {ptimes-outonq and startssuspectingthat qhas crashed }
Task3: when receive“q-is-alive”forsomeq
Ifq∈Output p {pknowsthatitprematurely timed-outon q}
Output p←Output p−(q) {prepents on q}
∆p(q)←∆p(q)+1 {pincreases its time-outperiod forq}
Coend
Figure15.6: A time-outbased implementationofD ∈♦P inthepartialsynchronymodel.
most of the time and then they experience bounded asynchrony periods. We expect from partial
synchronya periodofsynchronylongenough toterminatethe distributedalgorithm.
Each process p maintains a default timeout interval for ever y other process in the system. A
process sets a timeout based on worst case round trip of a mess age exchange. To measure the
elapsed time, each process p maintains a local clock, say, by counting the number of steps that it
takes.
Variables usedin thealgorithm:
•Output p(calledthesuspectlistofp)isasettoholdallthesuspecte dprocessesbyprocessp.
Thisset isinitiallyempty. Thisset islocal toprocess p whi chisexecutingthealgorithm.
•q istheloopvariableusedto identifyeach process inthesys tem.
•Πisaset ofallprocesses in thesystem.
•∆p(q)isthedurationofp’stimeoutintervalforq.
Thealgorithmis presented inFigure15.6.
Explanationof the Algorithm
Task1: Eachprocesspperiodicallysendsa“p-is-alive”mes sagetoallotherprocesses. Thisislike
aheart-beat messagethatinformsotherprocessesthat proc essp isalive.
577
Task 2: If a process p does not receive a “q-is-alive”message from a process q within ∆p(q) time
unitsonitsclock, thenp adds qto itssetofsuspectsifq isno talready in thesuspect listofp.
Task 3: When a process delivers a message from a suspected pro cess, it corrects its error about
thesuspected process and increases its time-outfor that pr ocess. If process p receives “q-is-alive”
messagefromaprocessqthatitcurrentlysuspects,pknowst hatitsprevioustime-outonqwaspre-
mature–premovesqfromitssetofsuspectsandincreasesits time-outperiodforprocessq, ∆p(q).
Correctness ofthe Algorithm
The algorithm insures the properties of an Eventually Perfe ct Failure Detector as discussed
below:
•Strong completeness: If a process p crashes, it will stop sen ding “p-is-alive” messages.
Eventually every process that crashes is permanently detec ted by every correct process.
Therefore, a crashed process will be suspected by any correc t process and no process will
revisethejudgement.
•Eventualstrongaccuracy: Aftertimet, thesystembecomes s ynchronous,i.e., aftertimet, a
messagesent by acorrect process p to anotherprocess q will b edeliveredwithina bounded
time. If p was wrongly suspected by q, then q will revise its su spicious. Eventually, no
correct process iseversuspected.
15.8 AnAdaptiveFailureDetectionProtocol
In this section, we discuss an adaptive failure detection pr otocol that allows a process to moni-
tor other processes and eventually detects its crash. The pr otocol relies as much as possible on
application messages to do this monitoring and uses control messages only when no application
message is sent by the monitoring process to the observed pro cess. More precisely, the proposed
protocolallowsaprocesstomonitoranotherprocessusingt heapplicationmessagesitisexchang-
ing to communicate with the other process, saving failure de tection messages. A failure detector
(thus, failure detection messages) are used when the proces ses are not communicating. The cost
associated with the implementation of a failure detector in curs only when the failure detector is
used (hence, it is called a lazy failure detector). When the u nderlying system satisﬁes the partial
synchrony assumption, the protocol implements an eventual ly perfect failure detector D ∈♦P. Re-
callthataneventuallyperfectfailuredetectormakesnomi stake(i.e,thelistofsuspectsataprocess
includesallcrashed processes,butno correct process)aft er aﬁnite, butunknowntime.
For any failure detector in ♦P, after it becomes perfect, if the average observed transmi ssion
delay is ﬁnite and the upper layer application terminates wi thin a bounded number of steps, then
it terminates correctly when run with the proposed protocol . These properties make the protocol
attractive: it isinexpensive,implementable,and powerfu l.
Thebasicfailuredetectionprotocol(denotedby FDL)ensuresthatifaprocessqueriesanother
process that has crashed, then it will deﬁnitely suspect it. Thus, completeness of the detection is
578
satisﬁed. The failure detection protocol is plugged into tw o particular contexts. The ﬁrst context
is deﬁned by the properties to be satisﬁed by the lower layer, namely, partial synchrony. When
the failure detection protocol is plugged in such a system, t he protocol provides a failure detector
of the class♦P. The second context is deﬁned by a property assumed to be sat isﬁed by the upper
layer, i.e., the application and some weaker properties to b e satisﬁed by the lower level. The ﬁrst
contextisdeﬁned by partialsynchrony.
Thesecond contextdeﬁnes aproperty(called ♦P−terminating)that theapplicationhas tosat-
isfy. Afailuredetector-basedapplication(thefailurede tectoritusesbelongsto ♦P)is♦P−terminating
if it terminates correctly within at most some l steps after t he failure detector becomes perfect.
Whenrunwitha♦P−terminatingapplication,theprotocolprovidestheapplic ationwiththesame
properties as♦P if the average observed transmissiondelay is ﬁnite. Inter estingly, unlikethe ﬁrst
context, the second context does not require an upper bound o n message transfer delays. These
twocontextsshowthatthisfailuredetectionprotocolisin expensive,implementable,andpowerful.
15.8.1 Lazy Failure Detection Protocol( FDL)
Assumptions
The basic system consists of a ﬁnite set of processes P = { p1,p2,...p n}. Each process pihas a
local hardware clock hcithat strictly monotonically increases. The local clocks ar e not required
to be synchronized, and there is no assumptionon theirpossi bledrift. The behaviour of a process
can be modeled by a ﬁnite state automaton. Each step of a proce ss is triggered by a message. An
event is the execution of communication statement by a proce ss. The history hiof a process piis
thesequenceofcommunicationeventsitproduces.
Every pair of processes is connected by a channel and they com municate by sending and re-
ceivingmessagesthroughchannels. Channelsarenotrequir edtobeFIFO.Theyareonlyassumed
to be reliable in the following sense: they do not create, dup licate, alter or loose messages, i.e., if
aprocesspjis correct, messagesent byaprocess pitopjiseventuallyreceived by pj.
PrimitivesProvided
Theprotocolprovidesthefollowingprimitivestoeach uppe rlayerapplicationprocess p i:
1. SEND Mto p j: usedby p itosend an applicationmessageMto p j.
2. RECEIVE M: usedby p itoreceivean applicationmessageM.
3. QUERY(j): usedto knowwhetherp jissuspectedtohavecrashed. Thisprimitivereturnsan
answer, namely,thevaluesuspect orno_suspect.
At operational level, the protocol uses three types of messa ges: "appl", "ack" and "ping".
To send an application message M to pj, a process piinvokes "sendappl(m) to pj" where the
protocol message m includes M plus some control information . When it receives such a message,
579
pjsystematicallyacknowledgesit by sendingback ack(m). Whe n it receives ack(m), picomputes
the round trip delay of the pair appl(m)+ack(m). For each des tination process pj,piaditionally
computesmaximumroundtripdelay forthemessagesthathave been acknowledgedby pj.
The answer provided by QUERY(j) when it is invoked by the uppe r layer depends on the
existence of a "pending" message,i.e., a message m such that appl(m) has been sent to pjbut the
corresponding ack(m) has not yet been received by pi:(1) If there is no such message, the answer
isnosuspect, butpisends a ping message to pjinorder to verify its answer. (2) If there are such
"pending"messages,theanswerdependson themaximumround tripdelay already experienced.
The Protocol FDL
Theprotocolmanagestwoarraysoflocalvariablesforeachp rocesspi: 1)pending_msg_st i[j]:
thisset is initiallyempty and itcontains thesendingtimes ofthemessages sent by pitopj, whose
acknowledgementshavenotyetbeenreceivedby pi. 2)max_rtd i[j]: containsthebiggestroundtrip
timeofthemessagesthat pisenttopjandthathavebeenacknowledged. Initially,thisvariableh as
the value zero. If the valueof max_rtd i[j] from the previous execution is known, then max_rtd i[j]
can beinitializedtothisvalue.
A call to SEND M is interpreted as a message reception from the upper layer. Similarly, RE-
CEIVE M is interpreted as a message sent to the upper layer. A p rotocol message m has a type
(appl/ack/ping). In additionto a content (m.content),a me ssage m also carries thelocal send time
(m.st). Moreprecisely,appl(m)andping(m)carrytheirloc alsendtimeandack(m)carriesthesend
timeoftheappl(m)orping(m)messageitis associatedwith.
Theprotocolforprocess piisdeﬁned as follows:
The protocol works as follows: When SEND M to pjis invoked by pi, m.content is ini-
tialized to the application message M and m.st is initialize d to the local hardware clock time.
Since the acknowledgement of this message is not yet receive d bypi, m.st is added to the set
pending_msg_st i[j]. Now,pisendstheapplicationmessageappl(m)to pj.
Whenpireceives a message from pj, it acts as follows: If the message received by process
piis of type ’appl’, then the message content(m.content) is tr ansmitted to the upper layer and an
acknowledgement message, ack(m)is sent to pj. If the message is an acknowledgement, ’ack’,
then themaximumroundtrip delay timeofthemessages sentto pjby processpiis updated tothe
maximum of the previous and current round trip delay times. S ince this is an acknowledgement
message, its sending time is deleted from the pending time se t. When the message of type ping is
receivedby pi, itsendsan acknowledgementmessageack(m)to pj.
When QUERY(j) is invoked by the process pi, the following two conditions arise: (1) If
pending_msg_st i[j] is empty, then a control message m is created and is used to ping process
pj. A control message is used as there is no communication betwe en the processes. The ping
messagesendtimeisaddedtothependingtimesetandavalue’ no_suspect’isreturned. (2)When
pending_msg_st i[j]isnon-empty,ifthetimetakentoreceiveanacknowledge mentfromprocess pj
580
when SEND Mto p jisinvoked:
m.content←M; m.st←hci;
pending_msg_st i[j]←pending_msg_st i[j]/uniontext{m.st}
send appl(m)top j
when type(m)is recievedfrom p j:
casetype=appl thentransmitM=m.contenttoupperlayer,
{*RECIEVE M*} sendack(m)to p j{* m.stkeeps itsvalue*}
type=ack thenrt←hci;
max_rtd i[j]←max(max_rtd i[j], rt-m.st);
pending_msg_st i[j]←pending_msg_st i[j]-{m.st}
type=pingthensend ack(m)top j{* m.stkeepsitsvalue*}
endcase
when QUERY(j)isinvoked:
ifpending_msg_st i[j]=∅then createacontrol messagem;
m.content←null;m.st←hci
send ping(m)top j;
pending_msg_st i[j]←{m.st};
return(no_suspect)
else
rt←hci;
ifrt-min(pending_msg_st i[j])>max_rtd i[j]
thenreturn (suspect)
elsereturn (no_suspect)
endif
endif
Figure15.7: Lazy FailureDetectionProtocol forprocess pi.
isgreater thanthemax_rtd i[j], thentheprocess pjis suspectedtobecrashed and avalue’suspect’
isreturned else’no_suspect’isreturned.
Properties of FDL
If from some time t, a process piobtains the answer suspect each time it invokes QUERY(j), we
say thatfrom thattimeit"permanentlysuspects pj" fromt.
Completeness Property: Let us assume that p iis correct, while p jis faulty (i.e., it has crashed).
Then, FDL ensuresthat eventuallyp ipermanentlysuspectsp jtohavecrashed.
The Protocol in Partially Synchronous Systems2:If the underlying system is partially syn-
chronous, there is a time t after which FDL ensures that no cor rect process is suspected by a
2This means that there is a time after which there are upper bou nds on messages transfer delays and associated
processingtimes
581
correct process.
♦P Terminating Protocol: If theupperlayerprotocol is ♦P-Terminating, then it terminateswith
probability1 when,instead ofusingafailuredetectorof ♦P, itusesFDL.
Message Cost: Each appl() or ping() message generates atmost one ack() mes sage. Both appl()
andping()areduetotheapplicationlayer. appl()whenitse ndsan applicationmessageand ping()
when itinvokesQUERY().
The cost of invocation of QUERY(j) by a process piafterpjhas crashed: According to the
current state of pending_msg_st i[j],pican be forced to send ping(m) message to pj. But from
now, the condition pending_msg_st i[j]∝\⌉}atio\slash= Φremains permanently true. Consequently, the next
invocationsofQUERY(j)donot sendmessages,and theircomm unicationcost iszero.
15.9 BibliographicNotes
The area of failure detectors was initiated by Chandra and To ueg [3] and a large number of re-
searchers followed it. An excellent short review paper on th e topic is by Raynal [22]. Delporte-
Gallet et al. [5] present a realistic failure detector. An ad aptive failure detector can be found in
Fetzer et al. [8].
Implementations of failure detectors can be found in [17, 18 , 19, 20]. Garg and Mitchell [11]
describe implementable failure detectors. Gupta et al. [14 ] discuss scalable failure detectors.
Hurﬁn et al. [15, 16] present a family of consensus protocols based on failure detectors. Schiper
[23] discusses early consensus using weak failure detector s. Chandra et al. [4] discuss the weak-
est failure detector to solve the consensus. Guerraoui [12] present non-blocking atomic commit
using failure detectors. Delporte-Gallet et al. [6] discus s how to achieve mutual exclusion in
asynchronousdistributedsystemswithfailuredetectors.
15.10 ExerciseProblems
1. It is well known fact that consensus and atomicbroadcast p roblems cannot be solved deter-
ministicallyinasynchronousdistributedsystemsevenfor asingleprocessfailure. Thenhow
failuredetectorssolvetheseproblems?
582
Bibliography
[1] Marcos Aguilera Wei Chen Sam Toueg, Heartbeat: A Timeout -Free Failure Detector for
QuiescentReliableCommunication,Proc. ofDISC, 1997.
[2] Marcos Aguilera, Wei Chen, Sam Toueg, Using the heartbea t failure detector for quiescent
reliable communicationand consensus in partitionablenet works, Theoretical Computer Sci-
ence, Volume220,Issue1, June1999,Pages: 3- 30.
[3] Chandra T.D. and Toueg S., Unreliable Failure Detectors for Reliable Distributed Systems.
Journal ofthe ACM, 43(2):225-267, 1996. (First version pub lishedin theproceedings ofthe
10thACM SymposiumonPrinciples ofDistributedComputing, 1991.)
[4] Tushar Deepak Chandra, Vassos Hadzilacos and Sam Toueg, The Weakest Failure Detector
forSolvingConsensus,JournaloftheACM,43:4,July1996,6 85-722.
[5] Delporte-Gallet C., Fauconnier H. and Guerraoui R., A Re alistic Look at Failure Detectors.
Proc. IEEE Inter. Conference on Dependable Systems and Netw orks (DSN’02), IEEE Com-
puterSociety Press, pp. 345352,WashingtonD.C., 2002.
[6] Delporte-GalletCarole, FauconnierHugues,Guerraoui Rachid,KouznetsovPetr,Mutualex-
clusion in asynchronous systems with failure detectors, Jo urnal of parallel and distributed
computing,2005,vol.65,no4, pp.492-505.
[7] Delporte-Gallet C., Fauconnier H. and Guerraoui R., Fai lure Detection Lower Bounds on
Registers and Consensus. Proc. 16th Symposium on Distribut ed Computing (DISC’02),
SpringerVerlag LNCS#2508,pp. 237251,2002.
[8] Fetzer C., Raynal M. and Tronel F., An AdaptiveFailure De tectionProtocol. Proc. 8th IEEE
PaciﬁcRimInt.SymposiumonDependableComputing(PRDC’01 ),IEEEComputerSociety
Press, pp.146153,Seoul (Korea), 2001.
[9] M.J.Fischer,N.A.Lynch,and M.S.Paterson.Impossibil ity of distributed consensus with one
faultyprocess.JournaloftheACM,32(3):374.382,April19 85.
[10] FriedmanR.,MostefaouiA.andRaynalM.,AWeakestFail ureDetectorBasedAsynchronous
ConsensusProtocolforf<n,InformationProcessingLetter s,Volume90,Issue1,April2004,
Pages: 39 -46.
583
[11] VijayK.GargandJ.RogerMitchell,ImplementableFail ureDetectorsinAsynchronousSys-
tems, Lecture Notes in Computer Science, Springer Berlin/H eidelberg, Volume 1530/2004,
Foundations of Software Technology and Theoretical Comput er Science Pages 158-170,
1998.
[12] GuerraouiR.,NonBlockingAtomicCommitinAsynchrono usDistributedSystemswithFail-
ureDetectors.DistributedComputing,15:17-25,2002.
[13] Guerraoui R., Indulgent Algorithms. Proc. 19th ACM Sym posium on Principles of Dis-
tributedComputing,(PODC’00), ACM Press, pp. 289298,Port land(OR), 2000.
[14] Indranil Gupta, Tushar D. Chandra, German S. Goldszmid t, On scalable and efﬁcient dis-
tributed failure detectors, Proc. of the twentieth annual A CM symposium on Principles of
distributedcomputing,p.170-179,August2001,Newport,R hodeIsland.
[15] M. Hurﬁn , A. Mostefaoui, M. Raynal, A Versatile Familyo f Consensus Protocols Based on
Chandra-Toueg’s Unreliable Failure Detectors, IEEE Trans actions on Computers, v.51 n.4,
p.395-408,April 2002.
[16] MichelHurﬁn, MichelRaynal,A simpleandfast asynchro nousconsensusprotocolbasedon
aweak failuredetector, DistributedComputing,v.12n.4,p .209-223,September1999.
[17] Mikel Larrea, Sergio Arevalo, AntonioFernandez, Efﬁc ient Algorithmsto Implement Unre-
liable Failure Detectors in Partially Synchronous Systems , Proceedings of the 13th Interna-
tionalSymposiumonDistributedComputing,p.34-48,Septe mber27-29,1999.
[18] Mikel Larrea, Antonio Fernandez, Sergio Arevalo, Opti mal Implementation of the Weak-
est Failure Detector for Solving Consensus, Proceedings of the 19th IEEE Symposium on
ReliableDistributedSystems(SRDS’00), p.52,October16- 18,2000.
[19] GerardLeLannandUlrichSchmid,HowtoImplementaTime -FreePerfect FailureDetector
in Partially Synchronous Systems, Technical University of Vienna, Institute for Technische
Informatik,Research Report, Number28/2005,2005.
[20] Mostefaoui A., Mourgaya E., and Raynal M., Asynchronou s Implementation of Failure De-
tectors. Proc. Int. IEEE Conference on Dependable Systems a nd Networks (DSN’03), IEEE
ComputerSociety Press, pp. 351360,San Francisco (CA), 200 3.
[21] Achour Mostefaoui, Eric Mourgaya, Michel Raynal, An in troduction to oracles for asyn-
chronous distributed systems, Future Generation Computer Systems, v.18 n.6, p.757-767,
May2002.
[22] RaynalM.,AShortIntroductiontoFailureDetectorsfo rAsynchronousDistributedSystems,
ACM SIGACT News,Volume36,Issue1,March 2005,Pages: 53-70 .
584
[23] Andre Schiper, Early consensus in an asynchronous syst em with a weak failure detector,
DistributedComputing,v.10n.3,p.149-157,April1997.
[24] LyndaTemal,DenisConan,Failure,connectivityanddi sconnectiondetectors,Proceedingsof
the 1st French-speaking conference on Mobility and ubiquit y computing, June 01-03, 2004,
Nice, France.
585
Chapter16
Authenticationin DistributedSystem
16.1 Introduction
Afundamentalconcerninbuildingasecuredistributedsyst emisauthenticationoflocalandremote
entitiesinthesystem[41]. Inadistributedsystem,thehos tscommunicatebysendingandreceiving
messages overthe network. Various resources (like ﬁles and printers)distributedamong the hosts
aresharedacrossthenetworkintheformofnetworkservices providedbyservers. Theentitiesina
distributedsystemlikeusers,clients,servers,processe sarecollectivelyreferredtoasprincipals. A
distributed system is susceptible to a variety of threats mo unted by intruders as well as legitimate
users ofthesystem.
In an environment where a principal can impersonate other pr incipal, principals must adopt a
mutuallysuspiciousattitudetowardoneanotherandauthen ticationbecomesanimportantrequire-
ment. Authentication is a process by which one principal ver iﬁes the identity of other principal.
For example, in a client-server system, the server may need t o authenticate the client. Likewise,
theclientmaywanttoauthenticatetheserversothatitisas suredthatitistalkingtotherightentity.
Authenticationis needed for both authorization and accoun ting functions. In one-way authentica-
tion,onlyoneprincipalveriﬁestheidentityoftheotherpr incipalandinmutualauthentication,both
communicatingprincipals verify each other’s identity. A u ser gains access to a distributedsystem
byloggingtoahostinthesystem. Inanopenaccessenvironme ntwherehostsarescatteredacross
unrestricted areas, a host can be arbitrarily compromised, necessitating mutual authentication be-
tween the user and host. In a distributed system, authentica tion is carried out using a protocol
involvingmessageexchanges andtheseprotocolsaretermed authenticationprotocols [41].
16.2 BackgroundandDeﬁnitions
In simple terms, authentication is identiﬁcation plus veri ﬁcation.Identiﬁcation [41] is the proce-
dure whereby an entity claims a certain identity, while veriﬁcation is the procedure whereby that
claimischecked. Authenticationisaprocessofverifyingt hattheprincipal’sidentityisasclaimed.
Thecorrectness ofauthenticationreliesheavilyon theveriﬁcationproced ureemployed.
586
A successful identityauthenticationresultsin abeliefhe ld by theauthenticatingprincipal(the
veriﬁer) that the authenticated principal (the claimant) possesses the claimed identity. The other
typesofauthenticationincludemessageoriginauthentica tionand messagecontentauthentication.
In thischapter, werestrictourattentiontotheidentityau thenticationonly.
Authentication in distributed systems is carried out with p rotocols. A protocol is a precisely
deﬁned sequence ofcommunicationand computationsteps. A c ommunicationstep transfers mes-
sagesfromoneprincipal(thesender)toanother(thereceiv er),whileacomputationstepupdatesa
principal’sinternalstate. Twodistinctstatescanbeiden tiﬁedupontheterminationoftheprotocol:
onesignifyingsuccessfulauthenticationandtheotherfai lure.
Althoughthegoalofanyauthenticationistoverifytheclai medidentityofaprincipal,speciﬁc
success and failure states are highly protocol dependent. F or example, the success of an authenti-
cationduringtheconnectionestablishmentphaseofacommu nicationprotocolisusuallyindicated
by the distribution of a fresh session key between two mutual ly authenticated peer processes. On
the other hand, in a user login authentication, success usua lly results in the creation of a login
process onbehalfoftheuser.
16.2.1 Basisof Authentication
Authenticationisbasedonthepossessionofsomesecretinf ormation,likepassword,knownonlyto
theentitiesparticipatingintheauthentication. Whenane ntitywantstoauthenticateanotherentity,
theformerwillverifyifthelatterpossessestheknowledge ofthesecret. Iftheentitydemonstrates
theknowledgeoftherightsecretinformation,theauthenti cationsucceeds,elseauthenticationfails.
Examplesofsecretinformationforthepurposeofauthentic ationincludethefollowing: something
known(e.g.,asharedkey),somethingpossessed(e.g.,smar tcard),orsomethinginherent(e.g.,bio-
metrics). However,theveriﬁcation processshouldnotallo wan attackertoreuse an authentication
exchangeto impersonatean entity. The veriﬁcation process mustprovidetheveriﬁer with enough
conﬁdencethat an attackerisnot tryingtoimpersonatean en tity.
16.2.2 Types of Principals
In a distributed system, the entities that require identiﬁc ation are hosts, users and processes [26].
Theythusare theprincipalsinvolvedin an authentication.
Hosts.These are addressable entities at the network level. A host i s usually identiﬁed by its
name (for example, a fully qualiﬁed domain name) or its netwo rk address (for example, an IP
address).
Users.Theseentitiesare ultimatelyresponsibleforall systemac tivities. Users initiateand are
accountable for all system activities. Most access control and accounting functions are based on
users. Typical users include humans, as well as accounts mai ntained in the user database. Users
are consideredtobeoutsidethesystemboundary.
Processes. The system creates processes within the system boundary to r epresent users. A
process requestsand consumesresources onthebehalfofits user.
587
Processes fall into two classes: client and server. Client p rocesses are consumers who obtain
services from server processes, who are service providers. A particular process can act as both a
clientand aserver.
16.2.3 A Simple ClassiﬁcationofAuthentication Protocols
Authentication protocols can be categorized based on the fo llowing criteria [28]: type of cryp-
tography (symmetric vs. asymmetric), reciprocity of authe ntication (mutual vs. one-way), key
exchange, real-time involvement of a third party (on-line v s. off-line), nature of trust required
from athirdparty,natureofsecurityguarantees, and stora geofsecrets.
In this chapter, we classify authentication protocols [41] primarily based on the cryptographic
techniqueused. There are twobasictypes ofcryptographict echniques: symmetric("privatekey")
and asymmetric("publickey"). Symmetriccryptography use s a singleprivatekey to both encrypt
and decrypt data. Any party that has the key can use it to encry pt and decrypt data. Symmetric
cryptography algorithms are typically fast and are suitabl e for processing large streams of data.
Asymmetric cryptography, also called Public-key cryptogr aphy, uses a secret key that must be
kept from unauthorized users and a public key that is made pub lic. Both the public key and the
private key are mathematically linked: data encrypted with the public key can be decrypted only
bythecorrespondingprivatekey,anddatasignedwiththepr ivatekeycanonlybeveriﬁedwiththe
correspondingpublickey. Bothkeysare uniquetoacommunic ationsession.
16.2.4 Notations
We specify authentication protocols [39] with precise synt ax and semantics and deﬁne a system
model that characterizes protocol executions. We assume a g iven set of constant symbols which
denotethenamesofprincipals,nonces,andkeys. Insymmetr ickeycryptography,let {X}kdenote
the encryption of X using a symmetric key k and {Y}k−1denote the decryption of Y using a
symmetrickeyk. In asymmetrickeycryptography,foraprinc ipalx, K xand K−1
xdenoteitspublic
and privatekeys,respectively.
Wepresentauthenticationprotocolsusingthefollowingfo rmat. Acommunicationstepwhereby
PsendsamessageMtoQisrepresentedasP →Q:M,whereasacomputationstepofPiswritten
as P: ...,where“...” is aspeciﬁcationofthecomputationst ep.
For example, a typical login protocol between a host H and a us er U is given in Table 16.1 (f
denotes a one-wayfunction, that is, given y, it is computationally infeasibl e to ﬁnd an x such that
f(x)=y).
Since authentication protocols for distributed systems di rectly use cryptosystems, their basic
design principles also follow the type of cryptosystem used . Speciﬁcally, we identify two basic
categories of authentication: one based on symmetric crypt osystems and other on asymmetric
cryptosystems. Protocolspresentedinthischapterareint endedtoillustratebasicdesignprinciples
and arealisticprotocolis certainlyareﬁnement oftheseba sicprotocols.
588
U→H : U
H→U : "Pleaseenterpassword"
U→H : p
H : computey =f(p)
: Retrieveuserrecord (U,f (password)U)from thedatabase
: Ify =f(password)U,then accept; otherwisereject
Table16.1: A loginprotocol
16.2.5 Design Principles for Cryptographic Protocols
Abadi and Needham set out a set of principles [2, 36] to denote prudent engineering practices
for cryptographic protocols design [2, 4]. They are not mean t to apply to every protocol in every
instance, but they do provide rules of thumb that should be co nsidered when designing a crypto-
graphicprotocol.
We nextpresenttheseprinciplesandbrieﬂy commenton them[ 2, 4].
•Principle 1. Every message should say what it means: The inte rpretation of the message
should depend only on its content. It should be possible to wr ite down a straightforward
English sentence describing the content—though if there is a suitable formalism available,
whichis good,too.
•Principle 2. The conditions for a message to be acted upon sho uld be clearly set out so that
someonereviewingthedesignmaysee whethertheyare accept ableornot.
•Principle3. Iftheidentityofaprincipalisessentialtoth emeaningofamessage,itisprudent
tomentiontheprincipal’snameexplicitlyin themessage.
•Principle 4. Be clear as to why encryption is being done. Encr yption is not wholly cheap,
and not asking precisely why it is being done can lead to redun dancy. Encryption is not
synonymouswithsecurity,and itsimproperusecan lead toer rors.
•Principle5. Whenaprincipalsignsmaterialthathasalread ybeenencrypted,itshouldnotbe
inferred that the principal knows the content of the message . On the other hand, it is proper
to infer that the principal that signs a message and then encr ypts it for privacy knows the
contentofthemessage.
•Principle6. Beclearaboutwhatpropertiesyouareassuming aboutnonces. Whatmaydofor
ensuringtemporalsuccessionmaynotdoforensuringassoci ation—andperhapsassociation
isbest establishedby othermeans.
•Principle 7. The use of a predictable quantity (such as the va lue of a counter) can serve in
guaranteeingnewness,throughachallenge-responseexcha nge. Butifapredictablequantity
is to be effective, it should be protected so that an intruder cannot simulate a challenge and
laterreplay aresponse.
589
•Principle 8. If timestamps are used as freshness guarantees by reference to absolute time,
then the difference between local clocks at various machine s must be much less than the
allowableage of a messagedeemed to be valid. Furthermore, t he timemaintenance mecha-
nismeverywherebecomes partofthetrustedcomputingbase.
•Principle 9. A key may have been used recently, for example, t o encrypt a nonce, yet be
quiteold,andpossiblycompromised. Recentusedoesnotmak ethekeylookanybetterthan
itwouldotherwise.
•Principle 10. If an encoding is used to present the meaning of a message, then it should be
possible to tell which encoding is being used. In the common c ase where the encoding is
protocoldependent,itshouldbepossibletodeducethatthe messagebelongstothisprotocol,
and infact to aparticularrunoftheprotocol,andto knowits numberintheprotocol.
•Principle 11. The protocol designer should know which trust relations his protocol depends
on, and why the dependence is necessary. The reasons for part icular trust relations being
acceptable should be explicit though they will be founded on judgment and policy rather
thanon logic.
16.3 ProtocolsBasedonSymmetricCryptosystems
Inasymmetriccryptosystem,knowingthesharedkeyletsapr incipalencryptanddecryptarbitrary
messages [41]. Without such knowledge, a principal cannot c reate the encrypted version of a
message,ordecryptanencryptedmessage. Hence,authentic ationprotocolscanbedesignedusing
tothefollowingprinciple,
“Ifaprincipalcancorrectlyencryptamessageusingakeyth attheveriﬁerbelievesisknown
onlytoaprincipalwiththeclaimedidentity(outsideofthe veriﬁer),thisactconstitutessufﬁcient
proofofidentity.”
Thus the principle embodies the fact that a principal’s know ledge is indirectly demonstrated
throughitsabilityto encrypt ordecrypt.
16.3.1 Basic Protocol
Using the aboveprinciple, we immediatelyobtain the basic p rotocol (shown in Table 16.2) where
principal P is authenticating itself to principal Q. ‘k’ den otes a secret key that is shared between
onlyPand Q [41].
Inthisprotocol,theprincipalPpreparesamessagemandenc ryptsthemessageandidentityof
QusingthesymmetrickeykandsendstoQboththeplaintextme ssageandtheencryptedmessage.
Principal Q on receiving the message encrypts the plaintext message and its identity to get the
encrypted message. If it is equal to the encrypted message se nt by P, then Q has authenticated P,
else, theauthenticationfails.
590
P: Create amessagem="Iam P."
: Computem′={m, Q} k
P→Q : m, m′
Q : verify {m,Q} k=m′
: ifequal thenaccept; otherwisetheauthenticationfails
Table16.2: Basic Protocol
Weaknesses
Clearly, this method is sound only if the underlying cryptos ystem is strong (one cannot create
the encrypted version of a message without knowing the key) a nd the key is secret (it is shared
only between the real principal and the veriﬁer). Note that t his protocol performs only one-way
authentication,mutualauthenticationcan beachievedby r eversingtheroles ofPand Q.
Onemajorweaknessoftheprotocolisitsvulnerabilitytore plays. Moreprecisely,anadversary
could masqueradeas Pby recording themessagem, m’and later replayingit to Q. Asmentioned,
replay attacks can be countered by using nonces or timestamp s. Since both plaintext message
m and its encrypted version m’ are sent together by P to Q, this method is vulnerable to known
plaintextattacks. Thusthecryptosystemmustbeabletowit hstandknownplaintextattacks.
16.3.2 Modiﬁed Protocolwith Nonce
To prevent replay attacks, we modify the protocol by adding a challenge-and-response step using
nonce (shown in Table 16.3). A nonce is a large random or pseud o-random number that is drawn
from a large space so that it is difﬁcult to guess by an intrude r. This property of a nonce helps
ensurethatold communicationscannot bereused in replay at tacks.
P→Q : "Iam P."
Q : generate noncen
Q→P: n
P: computem′={P, Q, n} k
P→Q : m′
Q : verify {P, Q,n} k=m′
: ifequal thenaccept; otherwisetheauthenticationfails
Table16.3: Challenge-and-responseprotocolusinganonce
In the modiﬁed version of the protocol [41], the principal P w ants to authenticate itself to Q.
Q generates a nonce and sends this nonce to P. P then encrypts Q , the nonce and its own identity
with the secret key and sends this encrypted message to Q. Q ve riﬁes this encrypted message by
encrypting its identity, P’s identity and the nonce with the key k. Q authenticates P if encrypted
informationequals thatsent byP, elsetheauthenticationf ails.
591
Replay isfoiledbythefreshnessofnoncenandbecausenisdr awnfromalargespace. There-
fore, it is highly unlikely that the nonce n generated by Q in t he current session is the same as
one used in a previous session. Thus an attacker cannot use a m essage of type m′from a previous
session to mount a replay attack. In addition, even if an eave sdropper has monitored all previous
authenticationconversationsbetween P and Q, it is impossi bleto produce themessagem because
itdoesnotknowthesecretkeyk. Thechallenge-and-respons estepcanberepeatedanynumberof
timesuntilthedesired levelofconﬁdence isreached byQ.
Weaknesses
This protocol has scalability problems because each princi pal must store the secret key for every
other principal it would ever want to authenticate [41]. Thi s presents major initialization (the
predistribution of secret keys) and storage problems. More over, the compromise of one principal
can potentiallycompromisethe entire system. Note that thi s protocol is also vulnerable to known
plaintextattacks.
16.3.3 Wide-Mouth FrogProtocol
The aboveraised problemscan besigniﬁcantly reduced by pos tulatinga centralized server S. The
wide-mouth frog protocol [28] uses a similar approach where a principal A authenticates itself to
principalBusingaServer S. Theprotocolworksas follows:
A→S: A, {T A,KAB, B}KAS
S→B : {T S,KAB, A} KBS
A decides that it wants to set up communicationwith B. A sends to S its identityand a packet
encrypted with the key, K AS, it shares with S. The packet contains the current timestamp , A’s
desired communication partner, and a randomly generated ke y KAB, for communication between
A and B. S decrypts the packet to obtain K ABand then forwards this key to B in an encrypted
packet that also contains the current timestampand A’s iden tity. B decrypts this message with the
key it shares with S and retrieves the identity of the other pa rty and the key, K AB. Any principal
receivingamessagewithanout-of-datetimestampduringth isprotocoldiscardsittopreventreplay
attacks. This protocol achieve two objectives: First, it se curely establishes a secret key between
two principals A and B. Second, A authenticates itself to B wi th the help of the server S. This is
because, only the server S could have constructed the messag e {T S, KAB, A} KBSin Step (2) only
afterreceiving amessagefrom A instep1.
A weakness of the protocol is that a global clock is required a nd the protocol will fail if the
serverSiscompromised.
592
16.3.4 A ProtocolBasedOn anAuthentication Server
Anotherapproachtosolvetheproblemisbyusingacentraliz edauthenticationserverSthat shares
a secret key K XSwith every principal X in the system [41]. The basic authenti cation protocol is
showninTable16.4.
P→Q : "IamP."
Q : generatenoncen
Q→P: n
P : computex ={P, Q, n} KPS
P→Q : x
Q : computey ={P, Q, x} KQS
Q→A : y
A : recoverP, Q, xfrom y bydecryptingy with KQS
: recoverP,Q, nfrom y bydecryptingx with KPS
: computem= {P, Q,n} KQS
A→Q : m
Q : independentlycompute{P, Q, n} KQSand verify{P, Q, n} KQS=m
: ifequal,then accept; otherwise,theauthenticationfail s
Table16.4: A protocolusinganauthenticationserver
Intheprotocolusinganauthenticationserver,theprincip alPsendsitsidentitytoQ.Qgenerates
anonceandsendsthisnoncetoP.PthenencryptsP,Q,nwithth ekeyKPSandsendsthisencrypted
valuex to Q. Q then encrypts P, Q, x with KQSand sends thisencrypted valuey to authentication
server S. Since S knows both the secret keys, it decrypts y wit hKQS, recovers x , decrypts x with
KPSand recovers P, Q, n. Server S then encrypts P, Q, n with key KQSand sends the encrypted
value m to Q. Q then computes P, Q, n KQSand veriﬁes if this value is equal to the value received
from S. Ifbothvaluesare equal,then authenticationsuccee ds, elseitfails.
Thus Q’s veriﬁcation step is preceded by a key-translation step by S. Since P and Q do not
share a secret key, the authentication server S does the key t ranslation because it shares a secret
key with both principals P and Q. Q sends themessage (encrypt ed withKPSthat it received from
P)toS.Sdoesthekeytranslationbydecryptingitwith KPS,encryptingP,Q,nwith KQS,sending
themessageencrypted with KQStoQ. Thisis termedas thekey-translationstep[41].
The basisof thisprotocolis a challengefor Q to P ifP can encr ypt the noncen with thesecret
key that it shares with server S. The protocol correctness re sts on S’s trustworthiness—thatS will
properlydecryptusingP’skeyandreencryptusingQ’skey. T heinitializationandstorageproblems
are greatly alleviated because each principal needs to keep only one key. The risk of compromise
is mostly shifted to S, whose security can be guaranteed by va rious measures, such as encrypting
storedkeysusingamasterkeyand puttingSin aphysicallyse cureroom.
593
16.3.5 One-Time PasswordScheme
In theOne-TimePassword scheme [24], apassword can onlybe u sed once. A one-timepassword
systemgeneratesalistofpasswordsandsecretlycommunica testhislisttotheclientandtheserver.
The client uses the passwords in the list to log on to a server. Once a password has been used, it
cannot be used again. To log on again, the client must use the n ext password in the list. The
serveralwaysexpectsthenextpasswordinthelistatthenex tlogon. Therefore,evenifapassword
is disclosed, the possibility of replay attacks is eliminat ed because the system expects the next
password in the subsequent logon. This protocol is best suit ed for distributed systems where an
authenticationmainlytakes placebetween clientand these rver.
ProtocolDescription
Protocol consistoftwostages:
1. Registrationstage: wheretheclientregisterswiththes erverand getsa listofpasswords.
2. Loginand authenticationstage: where theserverauthent icatestheclient.
(1)RegistrationStage
1. Every client shares a pre-shared secret key, represented as SEED with the server. It is a large
randomnumbersecretlycommunicatedbytheservertothecli ent.
2. Theservergeneratesasessionkey(SK)withthehelpofara ndomnumberDandatimestampT,
i.e.,SK=D||T.TheservercomputesandsendsSEED ⊕SKtotheclient. Whentheclientreceives
SEED⊕SK, itcomputesthevalueofSK asfollows:
SK =SEED⊕(SEED⊕SK)
Theclientthengenerates an initialkeyIK withthehelpofar andomlygenerated secret keyK,
IK =K⊕SEED
The client then decides the number of times (N) it wants to log in to the server and sends the
generated initial key (IK) to the server. To do this, the clie nt performs IK⊕SK and N⊕SK and
sendsthesevaluestotheserver.
3. When the server receives IK ⊕SK and N⊕SK, it retrieves IK and N from thereceived values
and computes
p0=HN(IK)fortheuserwhereH isa HashFunction
and performs p 0= p0⊕SK and stores p 0and N in its database and sends p 0⊕SK back to the
clientas aresponse. Italso computesp 1and p 2as follows:
594
p1=HN−1(IK)and
p2=HN−2(IK)
Theserverthensends p 0⊕SK, p 1⊕SK and p 2⊕SK totheclient
4. On receiving p 0⊕SK, p 1⊕SK and p 2⊕SK from the server, the client performs the XOR
operationonSKandp 0⊕SK,p 1⊕SKandp 2⊕SKseparately,toobtainp 0,p1andp 2,respectively.
The client hashes IK for N times and then compares it with p 0. If both values are equal, the client
issureoftheauthenticityoftheserverand that itisnotcom municatingwithan intruder.
It then saves the values of p 0, p1, p2and N for future communication with the server. This
markstheend oftheregistrationstage.
Theabovestepsare describedin Table16.5.
Server→Client : SEED
Server→Client : SEED⊕SK
Client→Server : IK⊕SK andN⊕SK
Server→Client : p 0⊕SK, p 1⊕SK, p 2⊕SK
Table16.5: TheRegistrationStage
IfNis50,theusercanlogintotheserver50timesandp 0=H50(IK).After50logins,theuser
mustrepeat thestepsintheregistration.
(2)Loginand Authentication Stage
Once the client is registered, every time it needs to access a service provided by the server, the
clientneeds toget authenticated. Authenticationrequire s thefollowingsteps:
1. Iftheclientisloggingin forthetthtime,theservergenerates anew sessionkey (SK)
SK =D||T whereT isthetimestampand D isarandomnumber.
Theserveralso computesp t−1=HC+1(IK)where C=N-t. It then performs p t−1⊕SK and SK
⊕SEED (SEED isstoredin thedatabase)and sendsthesevaluest otheclient.
2. Onthereceipt ofthevaluesfrom theserver,theclientcom putesSK as follows:
SK =p t−1⊕(pt−1⊕SK)
Then the Client checks the timestamp T of the session key SK. I f the timestamp is valid, the
clientcomputesSEED=SK ⊕(SK⊕SEED)andchecksthevalueofSEEDwiththeonesavedto
makesureoftheserver’sidentity. Iftheymatch, theserver ’s authenticityisveriﬁed.
3. Now the client proves its identity to the server as follows : It sends SK⊕ptto the server. The
clientuses thep tsavedinthepreviousloginin thisEX-ORoperation.
Server calculatesp tfromSK⊕ptreceived fromtheclientas follows:
595
pt=SK⊕(SK⊕pt)
Fromthereceivedp tvalue,itcalculatesp t−1=H(p t)andcomparesitwithp t−1obtainedinthe
Step 1. Ifbothmatch,theidentityoftheclientisveriﬁed.
Finally,theserverupdates N withC, where C=N-t and compute spt+1usingp 0and sendsp t+1
⊕SK totheclient.
4. Theclient computesvalueofp t+1as pt+1=SK⊕(SK⊕pt+1)and storesitfor itsnextlogin.
Forexample,ift=10 and N=100,then p t−1=H91(IK), p t=H90(IK)and p t+1= H89(IK).
Theabovestepsare describedin Table16.6.
Server→Client : p t−1⊕SK, SEED⊕SK
Client→Server: p t⊕SK
Server→Client : p t+1⊕SK
Table16.6: TheLoginand Authentication
In this protocol, the client and the server communicate with each other by passing parameters
which are encrypted, i.e., exclusive ORed with either SK or S EED. SK is the session key of a
particular session and SEED is the pre-shared secret key. Si nce these two values are known only
to the client and server, eavesdropping of the connection do es not have any effect. Since SK is
obtained by usingthetimestamp,replay ofprevioussession does not work and thus thescheme is
robustagainstreplayattacks. Theuseofhash functionmake stheDictionaryattacks impossible.
Weaknesses
One-time passwords that are not time-synchronized are vuln erable to phishing. Phishing usually
occurswhenafraudstersendsanemailthatcontainsalinkto afraudulentwebsitewheretheusers
are asked to provide personal account information. The emai l and website are usually disguised
to appear to recipients as though they are from a bank or anoth erwell-known brand. In late 2005,
customersofaSwedishbank were trickedintogivingup their one-timepasswords.
16.3.6 Otway-Rees Protocol
The Otway-Rees protocol [28] is a server-based protocol tha t provides authenticated key trans-
port only in four messages without requiring timestamps. It provides key authentication and key
freshness assurances. It does not,however,provideentity authenticationorkeyconﬁrmation.
Thenotationsusedintheprotocolareasfollows: K ABisasessionkeythattheseverSgenerates
for users A and B to share. N Aand N Bare nonces chosen by A and B, respectively, to allow
veriﬁcation of key freshness (thereby, detecting replay at tacks). M is another nonce chosen by
A which serves as a transaction identiﬁer. S shares symmetri c keys K ASand K BSwith A, B,
respectively. ThisprotocolisshowninTable16.7.
596
(1)A→B: M, A,B, (N A, M,A, B) KAS
(2)B→S: M, A,B, (N A, M,A, B) KAS,(NB, M,A, B) KBS
(3)S→B: (N A, KAB)KAS, (NB,KAB)KBS
(4)B→A: M, (N A, KAB)KAS
Table16.7: Otway Rees Protocol
In the step (1), user A encrypts two nonces, N Aand M, and the identities of itself and the
identity of the party B to whom it wishes to communicate, with the key K ASand sends this to B
along with M, A, B in plaintext. On the receipt of this message , user B creates its own nonce N B
and an analogousencrypted message, (N B, M, A, B) KBS, in step (2)and sends thisalong with A’s
messagetoserverS.WhentheserverSreceivesthismessage, itusesthecleartextidentiﬁersinthe
message to retrieve K ASand K BS, then veriﬁes if the clear text (M, A, B) matches that recover ed
upon decrypting both parts of the message in step (2). Verify ing M in particular conﬁrms the
encrypted parts are linked. If so, S decides on a new key K ABfor communication between A
and B, prepares two distinct messages (N A, M, A, B) KASand (N B, M, A, B) KBSfor A and B,
respectively,andsendsbothtoBinstep(3). WhenBreceives thismessage,itdecryptsthesecond
part of the message received in step (3) and checks if N Bmatches that sent in step (2). If so, it
sendstheﬁrstparttoAinstep(4). WhenAreceivesthismessa ge,itdecryptsmessagereceivedin
step(4)and checks ifN Amatchesthat sentinstep (1).
If all checks pass, A and B are assured that K ABis fresh (due to their respective nonces), and
trust that (N A, KAB)KASand (N B, KAB)KBShave been constructed by the server S. A knows that
B is active as veriﬁcation of step (4) implies that B sent mess age in step (2) recently; B however
has no assurance that A is active until subsequent use of K ABby A, since B cannot determine if
messagein step(1)is fresh.
Weaknesses
Oneproblemwiththisprotocolisthatamaliciousintruderc anarrangeforAandBtoendupwith
different keys as follows: A and B execute the ﬁrst three mess ages; at this point, B has received
thekeyK AB. Theintruderinterceptsthefourthmessage. He/Shereplay sstep(2),whichresultsin
S generating a new key K′
ABand sending it to B in step (3). The intruder intercepts this m essage,
too,butsendstoAthepartofitthatBwouldhavesenttoA.SoA hasﬁnallyreceivedtheexpected
fourthmessage, butwithK′
ABinsteadofK AB. Anotherproblemis thatalthoughtheservertellsB
thatA used anonce, Bdoesn’tknowifthiswas areplay ofan old message.
16.3.7 Kerberos Authentication Service
Kerberos[20,30]primarilyaddressesclient-serverauthe nticationusingasymmetriccryptosystem.
Kerberos is an authentication system designed for MIT’s Pro ject Athena [1]. The goal of Project
Athenawas tocreate an educationalcomputingenvironmentb ased on high-performanceworksta-
597
Request a ticket
for the server
Provide server
authenticatorServer (TGS)Ticket GrantingAuthentication
System (AS)
Ticket and session key
Ticket and session key
Request serviceticket graoting ticketRequest for
User/ Work station
ServerData
baseKerberos
Figure16.1: Steps inAuthenticationin Kerberos.
tions, high-speed networking, and servers of various types . Researchers envisioned a large-scale
(10,000 workstations to 1,000 servers) open network comput ing environment in which individual
workstations can be privately owned and operated. Therefor e, a workstation cannot be trusted
to identify its users correctly to network services. Kerber os is not a complete authentication ser-
vice required for secure distributed computing in general; it only addresses issues of client-server
interactions.
Inthissection,wedescribetheKerberosauthenticationpr otocol. Kerberos’designisbasedon
the use of a symmetric cryptosystem together with trusted th ird-party authentication servers. The
basic components include authentication servers ( Kerberos servers ) andticket-granting servers
(TGSs).
InitialRegistration
Every Client/user registers with the Kerberos server by pro viding its user id, U and a password,
password u. TheKerberosservercomputesakeyk u=f(password u)usingaone-wayfunctionfand
stores this key in a database. Note that k uis a secret key that depends on the password of the user
and isshared by clientU andKerberos serveronly.
598
The Authentication Protocol
AuthenticationinKerberos proceeds inthreesteps:
1. InitialAuthenticationatLogin: KerberosServerauthen ticatesuserloginatahostandinstalls
aticketfortheticketgrantingserver, TGS, at theloginhos t.
2. Obtain a ticket for the server: Using the ticket for the tic ket granting server, the client re-
queststheticket grantingserver,TGS, for aticketforthes erver.
3. RequestingServicefromtheserver: Theclientusesthese rverticketobtainedfromtheTGS
torequest services fromtheserver.
Thesestepsare shownin Figure16.1. Next,weexplaintheses teps indetail.
(i) InitialAuthentication atLogin
Initial Authentication at Login uses Kerberos server and is shown in Table 16.8. Let U be a user
whois attemptingtolog inahostH.
1)U→H : U
2)H→Kerberos: U, TGS
3)Kerberos: retrievek Uand k TGSfrom database
: generate newsessionkeyk
: create aticket-grantingticket
: tick TGS= {U,TGS, k, T,L} KTGS
4)Kerberos→H: {TGS, k, T,L, tick TGS}kU
5)H→U : “Password?”
6)U→H : password
7)H : computek′
U=f(password)
: recoverk, tick TGSbydecrypting
TGS, k,T,L, tick TGS k Uwithk’ U: ifdecryptionfails, abortlogin,otherwise,retain
tickTGSand k. : erase passwordfrom thememory
Table16.8: InitialAuthenticationat Login
In step (1), user U initiates login by entering his/her user n ame. In step (2), the login host
H forwards the login request and the id of TGS to a Kerberos ser ver. In step (3), the Kerberos
serverretrievesk Uandk TGSfromthedatabase,generatesanewsessionkeykandcreatesa ticket-
grantingtickettick TGS={U,TGS,k,T,L} KTGSwhereUistheidentityoftheuserwhowishesto
communicatewiththeserver,TGSistheidentityoftheticke tgrantingserver, kisthesessionkey,
T is a timestamp, L is the ticket’s lifetime and k TGSis the key shared between TGS and Kerberos
Server. InStep4,Kerberosserverencryptsthetickettick TGS,theidentityoftheTGS,thesession
key,timestampand lifetimewithk Uand sendsitto hostH.
599
In step (5), on receiving this message from the Kerberos serv er, host H prompts the user for
his/her password, which the user supplies in step (6). In ste p (7), host H computes the key, K′
U,
correspondingtothepasswordusingtheone-wayfunctionf. Thehostrecoversthesessionkeykby
decrypting{TGS,k,T,L,tick TGS}kUwithk′
U. Ifthepasswordsuppliedbytheuserisnotthevalid
password of U, k′
Uwould not be identical to k U, and the authentication will fail. Thus, the user is
authenticated if the host is able to decrypt the message for t he Kerberos server. Upon successful
authentication, the host saves the new session key k and the t icket-granting ticket, tick TGS, for
further use and erases the user password from the memory. The ticket-granting ticket is used
to request server tickets from a TGS. Note that tick TGSis encrypted with k TGS, the key shared
between TGSand Kerberos.
(ii) Obtain aticket for the server
TheclientexecutesstepsshowninTable16.9torequestatic ketfortheserverfromTGS.Basically
the client sends the ticket tick TGSto TGS, requesting it a ticket for the server S. (T 1and T 2are
timestamps).
Because a ticket is susceptible to interception and replay, it does not by itself constitute suf-
ﬁcient proof of identity. For authentication, a principal p resenting a ticket must also demonstrate
the knowledgeof the session key k named in theticket. An authenticator {C, T} k, where C is the
client identity,T is thetimestampand k isthesession key,p rovidesthedemonstration. Unlikethe
ticketwhich is reusable, an authenticatorcan beused onlyo nce and hasa veryshort lifetime. The
ticket proves the client’s identity and also distributes th e key; however, it is susceptible to replay
attacks. Theauthenticatorisusedtocounterthisattack. B ecauseanauthenticatorcanbeusedonly
once and has a very short lifetime, the threat of an opponent s tealing the ticket for a replay attack
iscountered.
1)C→TGS: S, tick TGS, {C, T 1}k
2)TGS: recoverk fromtick TGSby decryptingwithk TGS,
recoverT 1from {C, T 1}kbydecryptingwithk
check timelinesofT 1withrespect tolocal clock
generate newsessionkeyk.
Create servertickettick S={C, S, k, T,L} kS
3)TGS→C: {S, k, T,L, tick S}k
4)C: recoverk, tick Sbydecryptingthemessagewithk
Table16.9: Obtaina ticketfortheserver
In step (1), to request a ticket for server S, client C present s its ticket-granting ticket tick TGS
along with the authenticator to TGS. C’s knowledge of k is dem onstrated using the authenticator
{C,T 1}k. Instep(2),TGSdecryptstick TGSwithk TGStorecoverk,veriﬁestheauthenticityofthe
authenticator by decrypting C, T 1}kwith k, and checks the timeliness of T 1in the authenticator
and T in the tick TGS. If both decryptions in step (2) timeliness of T 1of the authenticator and T
600
in the tick TGS. If both decryptionsin step(2)are successful and T 1is timely,TGS is convinced of
the authenticity of the ticket, creates a ticket tick S= {C, S, k, T, L kSfor server S, where C is the
identity of the client, S is the server identity, k is the new s ession key, T is the timestamp of the
TGS, L is the lifetimeof the ticket, k Sis the key shared between TGS and server S. This ticket is
returnedtoCinstep(3). Instep(4),Crecoverskandtick Sfrom{S,k,T,L,tick S}kbydecrypting
itwithk.
(iii) Requesting Service fromthe server
ClientCsendstheticketandtheauthenticatortoserver. Th eserverdecryptsthetick Sandrecovers
k. It then uses k to decrypt the authenticator {C, T 2}k′and checks if the timestamp is current and
the client identiﬁer matches with that in the tick Sbefore granting service to the client. If mutual
authenticationis required, theserverreturns anauthenti cator.
1)C→S: tick S, {C, T 2}k′
2)S: recoverk from tick Sbydecryptingit withk S
recoverT 2from{C, T 2}kbydecryptingwith k
check timelinessofT 2withrespect to thelocal clock
3)S→C: {T 2+1} k
Table16.10: RequestingService from theserver
Instep(1),CpresentsSwithtick Sandanewauthenticator. Instep(2),Srecoverskfromtick S
by decrypting it with k Sand uses k obtained to decrypt C,T 2k.If both decryptions are successful
and T 2is timely, then S is assured of the authenticity of the Client . Finally, step (3) assures C of
theserver’sidentity.
Weaknesses
Kerberos [21] makes no provisions for host security; it assu mes that it is running on trusted hosts
withanuntrustednetwork. Ifhostsecurityiscompromised, thenKerberosiscompromisedaswell.
Kerberos uses a principal’s password (encryption key) as th e fundamental proof of identity. If a
user’sKerberos passwordisstolenby an attacker, thenthea ttackercan impersonatethatuserwith
impunity. SincetheKerberos’passworddatabaseholdsallt hepasswordsforalloftheprincipalsin
arealm,ifthehostsecurityonthedatabaseiscompromised, thentheentirerealmiscompromised.
InKerberosversion4,authenticatorsarevalidforapartic ulartime. Ifanattackersniffsthenetwork
for authenticators, they have a small time window in which th ey can re-use it and gain access to
the same service. Kerberos version 5 introduced a replay cac he which prevents any authenticator
frombeingusedmorethanonce. SinceanybodycanrequestaTi cketGrantingTicketforanyuser,
andthatticketisencrypted withtheuser’ssecret key(pass word),itissimpletoperform anofﬂine
attack on this ticket by trying to decrypt it, say using the di ctionary attack. Kerberos version 5
introducedpre-authenticationtosolvethisproblem.
601
16.4 ProtocolsBasedonAsymmetricCryptosystems
In anasymmetriccryptosystem[41], each principalPpublis heshispublickeyk pandkeeps secret
his privatekey k−1
p. Thus only P can generate {m}k−1
pfor any message m by signing it using k−1
p.
Thesignedmessage{m}k−1
pcanbeveriﬁedbyanyprincipalwiththeknowledgeofk p(assuminga
commutativeasymmetriccryptosystem). Asymmetricauthen ticationprotocols can be constructed
usingadesignprinciplecalled ASYM whichisas follows:
“Ifaprincipalcancorrectlysignamessageusingtheprivat ekeyoftheclaimedidentity,this
act constitutesa sufﬁcient proofofidentity.”
This ASYM principle follows the proof-by-knowledge princi ple for authentication, in that a
principal’sknowledgeisindirectlydemonstratedthrough itssigningcapability.
16.4.1 The BasicProtocol
UsingASYM, weobtainabasicprotocolas follows[41]:
P→Q : “IamP.”
Q : generatenoncen
Q→P: n
P: computem={P, Q, n}k−1
p
P→Q : m
Q : verify(P, Q, n)={m} kp
: ifequal, thenaccept; otherwise, theauthenticationfail s
Table16.11: Basicprotocol
In this protocol, Q sends a random number n to P and challenges it to encrypt with its private
key. Pencrypts(P,Q,n)withitsprivatekeyk−1
pandsendsittoQ.Qveriﬁesthereceivedmessage
by decryptingitwithP’s publickey k pand checking withtheidentityofP, Q and n. Thisprotocol
depends on the guarantee that {P, Q, n}k−1
pcannot be produced withoutthe knowledgeof k−1
pand
thecorrectness ofk pas publishedby Pand keptby Q.
16.4.2 A Modiﬁed Protocolwith a Certiﬁcation Authority
The basic protocol requires that Q has the knowledge of P’s pu blic key. A problem arises if Q
does not know P’s public key. This problem is alleviated by po stulatinga centralized certiﬁcation
authority CA thatmaintainsadatabaseofallpublishedpublickeys[41 ]. IfauserAdoesnothave
thepublickeyofanotheruserB, Acan requestB’s publickeyf rom theCA.
Thebasicprotocolcan bemodiﬁedas shownin Table16.12toad dress thisissue.
This protocol is similar to the basic protocol described abo ve but a certiﬁcation authority CA
is involved. When Q receives a message encrypted with P’s pri vate key from P, it requests the
authentication server for P’s public key. CA retrieves publ ic key of P from the key database and
602
P→Q : “Iam P.”
Q : generatenoncen
Q→P: n
P : computem= {P,Q, n}k−1
p
P→Q : m
Q→CA : “Ineed P’s publickey.”
CA : retrievepublickeyk PofPfrom keyDatabase
Create certiﬁcate c={P, k P}k−1
CA
CA→Q : P, c
Q : recoverP, k Pfrom cbydecryptingwithk CA
verify(P, Q,n)={m} kP
: ifequal,then accept; otherwise,theauthenticationfail s
Table16.12: A ModiﬁedProtocol withacertiﬁcation authori tyCA
providesQwithacertiﬁcateforP’spublickey. Thecertiﬁca te,{P,k P}k−1
CAcontainsP’sidentityand
its public key, encrypted with the private key of the certiﬁc ation authority. Q retrieves the public
key of P by decrypting the certiﬁcate with the public key of CA . Then it decrypts the message m,
itreceivedfromPusingthepublickeyk Pandchecksif{m} kPequals{P,Q,n}. Ifbothareequal,
authenticationsucceeds, elseitfails.
Notethatc,calleda publickeycertiﬁcate ,representsacertiﬁedstatementbyCAthatP’spublic
key is k p. Other information such as an expiration date and the classi ﬁcation of principal P can
alsobeincludedinthecertiﬁcate. However,eachprincipal inthesystemmustknowthepublickey
kCAofCA.
In this protocol, CA is an example of an on-linecertiﬁcation authority. It supports interactive
queries and is actively involved in authentication exchang es. A certiﬁcation authority can also
operateoff-line. Inthiscase,apublickeycertiﬁcateisissuedtoaprincipa lwhenitﬁrstregistered.
The certiﬁcate is kept by the principal and is forwarded duri ng an authentication exchange, thus
eliminatingtheneedto makeaseparatequerytoaCA. Forgery isimpossible,sinceacertiﬁcate is
signedby thecertiﬁcation authority.
16.4.3 Needham and Schroeder Protocol
The Needham-Schroeder public key protocol [29] uses a trust ed key server that issues certiﬁcates
containing the public key of a user. The protocol is describe d in Table 16.13. In this protocol,
the initiator A seeks to establish a session with responder B with the help of trusted key server S.
(Recall thatforaprincipalx, K xandK−1
xdenoteitspublicand privatekeys,respectively.)
Instep1,AsendsamessagetotheserverS,requestingB’spub lickey. Srespondsbyreturning
B’s publickey K balong with B’s identity(to preventattacks based upon diver tingkey deliveries),
encrypted using S’s secret key (to assure A that this message originated from S). A then seeks
to establish a connection with B by selecting a nonce N a, and sending it along with its identity
to B (message 3) encrypted using B’s public key. When B receiv es this message, it decrypts the
603
1. A→S: A,B
2. S→A: {K b, B}K−1
s
3. A→B: {N a, A} Kb
4. B→S: B, A
5. S→B: {K a, A}K−1
s
6. B→A: {N a, Nb}Ka
7. A→B: {N b}Kb
Table16.13: Needham-SchroederProtocol
message to obtain the nonce N aand to learn that user A is trying to communicate with it. It th en
requests the publickey of A from server S (message 4) which th e server sends to B in message 5.
BthenreturnsnonceN a,alongwithanewnonceN b,toA,encryptedwithA’spublickey(message
6). WhenAreceivesthismessage,itdecryptsitwithitspriv atekeyandisassuredthatitistalking
to B, since only B could have decrypted message in step 3 to obt ain N a. A then returns nonce N b
to B, encrypted with B’s key. When B receives this message, it is assured that it is talking to A,
sinceonlyAcouldhavedecryptedmessageinstep6toobtainN b. Thus,afterstep7,AandBhave
mutuallyauthenticatedthemselves.
This protocol can be considered as the interleaving of two lo gically disjoint protocols: mes-
sages 1, 2, 4 and 5 are concerned with obtaining public keys, w hereas messages 3, 6 and 7 are
concerned withtheauthenticationofA and B.
Weaknesses
This protocol provides no guarantee that the public keys obt ained are current and not replays of
old, possibly compromised keys. This problem can be overcom e in various ways. For example,
one way is that the server S includes timestamps in messages 2 and 5; however, this requires
synchronized clocks at processes. Another method is that A s ends a nonce in message 1 and S
returns thesamenonceinmessage2.
An Impersonationattackonthe protocol
Wenowshowhowanintrudercanmountanimpersonationattack onthisprotocol[25]. Weassume
that the intruder I is a user of the computer network, and so is able to set up standard sessions
with other users, and other users may try to set up sessions wi th I. We assume that the intruder
can intercept any messages in the system and introduce new me ssages. However, we make some
assumptionsabout what sort ofmessages theintrudermay int roduce. We assumethat the intruder
cannot guess the value of nonces being passed in encrypted me ssages, unless those messages are
encryptedwithhisownkey. Thustheintrudercanonlyproduc enewmessagesusingnoncesthatit
inventeditself,orthatithaspreviouslyseenandundersto od. Itcanalsoreplaycompleteencrypted
messages,evenifitis unabletounderstand thecontents.
Theattack shownin Table16.14,startswithauserA tryingto establishasessionwithI.
604
TheattackontheprotocolallowsanintruderItoimpersonat etheuserAtosetupafalsesession
withauserB. Theattackinvolvestwosimultaneousrunsofth eprotocol: In run1, Aestablishesa
valid session with I; in run 2, I impersonates A to establish a fake session with B. In Table 16.14,
1.3represents message3in run 1and I(A)represents theintr uderIimpersonatingA.
1.3 A→I: {N a, A} Ki
2.3 I(A)→B: {N a, A} Kb
2.6 B→I(A): {N a, Nb}Ka
1.6 I→A : {N a, Nb}Ka
1.7 A→I: {N b}Ki
2.7 I(A)→B: {N b}Kb
Table16.14: An Impersonationattack on Needham-Schroeder Protocol
Instep1.3,AstartstoestablishasessionwithI,sendingit anonceN a. Instep2.3,theintruder
impersonates A to try to establish a false session with B send ing it the nonce N aobtained in the
previousmessagefromA.Brespondsinstep2.6byselectinga newnonceN bandreturningit,along
with N ato A. The intruder intercepts this message, but cannot decry pt it because it is encrypted
with A’s public key. The intruder uses A as an oracle, by forwa rding the message to A in step
1.6; note that this message is of the form expected by A in run 1 of the protocol. A decrypts the
message to obtain N band returns this to I in step 1.7. I decrypts this message to ob tain N band
returns it to B in step 2.7, thus completing run 2 of the protoc ol. After B receives the message in
step2.7, Bisled to believethat Ahas correctly established asessionwithit.
ASolution to the Attack
The main cause of this attack is that step 6 does not contain th e identity of the responder. If we
includetheresponder’sidentityin step6 oftheprotocol:
6. B→A : {B, N a,Nb}ka
then step2.6 oftheattack wouldbecome
2.6. B→I(A): {B, N a,Nb}ka
andtheintruderIcannotsuccessfullyreplaythismessagei nstep1.6becauseAisexpectinga
messagecontainingI’sidentity.
16.4.4 SSL Protocol
SSL stands for Secure Sockets Layer protocol [37] developed by Netscape and is the standard
Internet protocolforsecurecommunications. Thesecurehy pertexttransferprotocol(HTTPS) isa
communicationsprotocol designed to transfer encrypted in formation between computers over the
605
WorldWideWeb. HTTPSishttpusingaSecureSocketLayer(SSL ).SSLresidesbetweenTCP/IP
and upper layer applications, requiring no changes to the ap plication layer. SSL is used typically
between server and client to secure the connection. One adva ntage of SSL is that it is application
protocolindependent. A higherlevelprotocolcan layeront op oftheSSL Protocoltransparently.
SSL protocol allows client/server applications to communi cate in a way so that eavesdrop-
ping, tampering, and message_forgery are prevented. The SS L protocol, in general, provides the
followingfeatures:
•Endpointauthentication: The server is the “real” party tha t a client wants to talk to,
notsomeonefakingtheidentity.
•Messageintegrity: If the data exchanged with the server has been modiﬁed
alongtheway,itcan beeasily detected.
•Conﬁdentiality: Data is encrypted. A hacker cannot read you r information
bysimplylookingat thepackets on thenetwork.
SSL recordprotocol
The record protocol takes an application message to be trans mitted, fragments the data into man-
ageableblocks,optionallycompressesthedata,appliesMA C,encryptsaddsaheaderandtransmits
the resulting unit into a TCP segment. Received data are decr ypted, veriﬁed, decompressed and
reassembledand then deliveredintohighlevelusers.
SSL handshake protocol
The SSL Handshake Protocol [37] allows the server and client to authenticate each other and to
negotiateanencryptionalgorithmandcryptographickeysb eforetheapplicationprotocoltransmits
orreceivesitsﬁrst byteofdata.
Thefollowingsteps,showninFigure16.2,are involvedinth eSSL handshake:
1. TheSSLclientsendsa"clienthello"messagethatlistscr yptographicinformationsuchasthe
SSLversionand,intheclient’sorderofpreference,theCip herSuitessupportedbytheclient.
Themessagealso containsa randombytestringthat isusedin subsequentcomputations.
2. TheSSLserverrespondswitha"serverhello"messagethat containstheCipherSuitechosen
by the server from the list provided by the SSL client, the ses sion ID and another random
byte string. The SSL server also sends its digital certiﬁcat e. If the server requires a digital
certiﬁcate for client authentication, the server sends a "c lient certiﬁcate request" that in-
cludesalistofthetypesofcertiﬁcatessupportedandtheDi stinguishedNamesofacceptable
Certiﬁcation Authorities(CAs).
3. TheSSLclientveriﬁesthedigitalsignatureontheSSLser ver’sdigitalcertiﬁcateandchecks
thattheCipherSuitechosenby theserveris acceptable.
606
4. The SSL client, usind all data generated in the handshake s o far, creates a premaster secret
for the session that enables both the client and the server to compute the secret key to be
used for encrypting subsequent message data. The premaster secret itself is encrypted with
theserver’spublickey.
5. IftheSSLserversenta"clientcertiﬁcaterequest",theS SLclientsendsanothersignedpiece
ofdatawhichisuniquetothishandshakeandknownonlytothe clientandserver,alongwith
the encrypted premaster secret and the client’s digital cer tiﬁcate, or a "no digital certiﬁcate
alert". This alert is only a warning, but with some implement ations the handshake fails if
clientauthenticationismandatory.
6. TheSSL serververiﬁes thesignatureontheclientcertiﬁc ate.
7. TheSSLclientsendstheSSLservera"ﬁnished"message,wh ichisencryptedwiththesecret
key,indicatingthattheclientpart ofthehandshakeiscomp lete.
8. TheSSLserversendstheSSLclienta"ﬁnished"message,wh ichisencryptedwiththesecret
key,indicatingthattheserverpart ofthehandshakeiscomp lete.
9. For the duration of the SSL session, the SSL server and SSL c lient can now exchange mes-
sages thatareencrypted withtheshared symmetricsecret ke y.
HowSSL provides authentication
Duringbothclientand serverauthentication,thereisaste p thatrequires datato beencrypted with
oneofthekeysin an asymmetrickey pairandis decryptedwith theotherkeyofthepair[37].
Forserverauthentication,theclientusestheserver’spub lickeytoencryptthedatathatisused
to compute the secret key. The server can generate the secret key only if it can decrypt that data
withthecorrect privatekey.
For client authentication, the server uses the public key in the client certiﬁcate to decrypt the
data the client sends during step 5 of the handshake. The exch ange of ﬁnished messages that
are encrypted with the secret key (steps 7 and 8 in the overvie w) conﬁrms that authentication is
complete.
If anyoftheauthenticationstepsfails,thehandshakefail s and thesessionterminates.
The exchange of digital certiﬁcates during the SSL handshak e is a part of the authentication
process. The certiﬁcates required are as follows, where CA X issues the certiﬁcate to the SSL
client,and CA Y issuesthecertiﬁcateto theSSL server:
Forserverauthenticationonly,theSSL serverneeds:
•Thepersonalcertiﬁcate issuedtotheserverbyCA Y
•Theserver’sprivatekey
607
SSL Client SSL Server
1. "client hello"
Cryptograhpic information
2. "server hello"
CipherSuite
"client certificate request" (optional)Server certificate
4. Client key exchange
Send secret key information
(encrypted with server public key)
7. Client "finished"5. Send client certificate
9. Exchange messages8. Server "finished"
(encrypted with the shared secret key)3. Verify server
certificate.
Check
cryptograohic
paremeters.
6. Verify client
(if required).certificate.
Figure16.2: SSL HandshakeProtocol andDataExchange
and theSSL client needs:
•TheCA certiﬁcate forCA Y orthepersonal certiﬁcate issuedt otheserverby CA Y
IftheSSLserverrequiresclientauthentication,theserve rveriﬁestheclient’sidentitybyverify-
ingtheclient’sdigitalcertiﬁcate withthepublickeyfort heCA thatissuedthepersonalcertiﬁcate
totheclient,in thiscaseCA X. Forbothserverandclient aut hentication,theSSL serverneeds:
•Thepersonalcertiﬁcate issuedtotheserverbyCA Y
•Theserver’sprivatekey
•TheCA certiﬁcate forCA X orthepersonal certiﬁcate issuedt otheclientbyCA X
and theSSL client needs:
•Thepersonalcertiﬁcate issuedtotheclientby CA X
608
•Theclient’sprivatekey
•TheCA certiﬁcate forCA Y orthepersonal certiﬁcate issuedt otheserverby CA Y
Both the SSL server and the SSL client might need other CA cert iﬁcates to form a certiﬁcate
chain totherootCA certiﬁcate.
16.5 Password-basedAuthentication
The use of passwords is a highly popular technique to achieve authentication because of low cost
and convenience. Thissection isconcerned withauthentica tiontechniquesthat arebased on pass-
words.
A problem with passwords is that people tend to pick a passwor d that is convenient, i.e., short
andeasytoremember. Suchpasswordsarevulnerabletoapass word-guessingattackwhichworks
asfollows: anadversarybuildsadatabaseofpossiblepassw ords,calledadictionary. Theadversary
picks a password from the dictionary and checks if it works. T his may amount to generating a
responsetoachallengeordecryptingamessageusingthepas swordorafunctionofthepassword.
Aftereveryfailedattempt,theadversarypicksadifferent passwordfromthedictionaryandrepeats
theprocess. Thisnon-interactiveform ofattack isknownas theoff-linedictionaryattack .
Preventing Off-line Dictionary Attacks
Thus, a major problem is that users tend to choose weak passwo rds which are chosen from a
samplespacesmallenoughtobeenumeratedbyanadversary. H ence,protocolswhicharestronger
than simplechallenge-response protocols are needed which can use these cryptographically weak
passwords to securely authenticate entities. A password-b ased authentication protocol aims at
preventing off-line dictionary attacks by producing a cryp tographically strong shared secret key,
called thesession key,after asuccessful run of theprotoco l. This sessionkey can be used by both
entitiestoencrypt subsequestmessages foraseceret sessi on.
Inthissection,wefocusonprotocolsdesignedtopreventof f-linedictionaryattacksonpassword-
based authentication. Next,wepresent twopassword-based authenticationprotocols.
16.5.1 Encrypted Key Exchange (EKE)Protocol
The ﬁrst attempt to protect a password protocol against off- line dictionary attacks was made by
Bellovin and Merritt [6] who developed a password-based enc rypted key exchange (EKE) pro-
tocol using a combination of symmetric and asymmetric crypt ography. Figure 16.3 describes the
EKEprotocolthatworksasfollows: supposeusers AandBareparticipatinginarunoftheproto-
col. (Recall that{X}kdenotes the encryption of X using a symmetric key k and {Y}k−1denotes
thedecryptionofYusingasymmetrickeyk.)
In Step 1, user Agenerates a public/private key pair (EA,DA)and also derives a secret key
Kpwdfrom his password pwd. In Step 2, Aencrypts his public key EAwithKpwdand sends it
609
toB. In Steps 3 and 4, Bdecrypts the message and uses EAtogether with Kpwdto encrypt a
session key KABand sends it to A. In Steps 5 and 6, Auses this session key to encrypt a unique
challengeCAandsendstheencryptedchallengeto B. InStep7,Bdecryptsthemessagetoobtain
the challenge and generates a unique challenge CB. In Step 8, Bthen encrypts { CA,CB} with
the session key KABand sends it to A. In Step 9, Adecrypts this message to obtain CAandCB
and compares theformerwith thechallengeit hadsent to B. Iftheymatch, thecorrectness of B’s
response is veriﬁed (i.e., Bis authenticated). In Step 10, AencryptsB’s challenge CBwith the
session key KABand sends it to B. WhenBreceives this message, it decrypts the message to
obtainCBand uses it verify the correctness of A’s response and to authenticate A. Note that the
protocol results in a session key (strongerthan the shared p assword)which the users can later use
toencrypt sensitivedata.
1.A: (EA,DA),Kpwd=f(pwd). {* fisafunction. *}
2.A→B:A,{Kpwd}EA.
3.B:ComputeEA={{EA}Kpwd}K−1
pwdand generatea randomsecret key KAB.
4.B→A:{{KAB}EA}{Kpwd}.
5.A:KAB={{{{KAB}EA}{Kpwd}}K−1
pwd}DA. Generate auniquechallenge CA.
6.A→B:{CA}KAB.
7.B:ComputeCA={{CA}KAB}K−1
ABand generateauniquechallenge CB.
8.B→A:{CA,CB}KAB.
9.A:Decrypt message sent by Bto obtainCAandCB. Compare the former with his own
challenge. Iftheymatch,go tothenextstep,elseabort.
10.A→B:{CB}KAB.
Figure16.3: EncryptedKeyExchangeProtocol
The EKE protocol suffers from the plain-text equivalence, w hich means the user and the host
haveaccess tothesamesecret passwordorhashofthepasswor d.
16.5.2 Secure Remote Password(SRP) Protocol
Wu [44] combined the technique of zero-knowledge proof with asymmetric key exchange pro-
tocols to develop a veriﬁer-based protocol, called secure r emote password (SRP) protocol. SRP
protocoleliminatesplain-textequivalence.
610
All computationsin SRP are carried out on the ﬁnite ﬁeld Fn, wherenis a large prime. Let g
beageneratorof Fn. LetAbeauserand Bbeaserver. Before initiatingtheSRP protocol, Aand
Bdo thefollowing:
1.AandBagreeon theunderlyingﬁeld.
2.Apicks a password pwd, a random salt sand computes the veriﬁer v=gx, wherex=
H(s,pwd )isthelong-termprivate-keyand Hisa cryptographichashfunction.
3.Bstorestheveriﬁer vandthesalt s.
Now,AandBcan engage in the SRP protocol (shown in Figure 16.4). The SRP protocol
works as follows: In Step 1, Asends its username “A” to server B. In Step 2, Blooks-upA’s
veriﬁervand saltsand sendsAhis salt. In Steps 3 and 4, Acomputes its long-term private-key
x=H(s,pwd ), generates an ephemeral public-key KA=gawhereais randomly chosen from
the interval 1< a < n and sendsKAtoB. In Steps 5 and 6, Bcomputes ephemeral public-key
KB=v+gbwherebis randomly chosen from the interval 1< a < n and sendsKBand a
random number rtoA. In Step 7, AcomputesS= (KB−gx)a+rx=gab+brxandBcomputes
S= (KAvr)b=gab+brx. The values of Scomputed by AandBwill match if the password A
entered in Step 3 matches the one that Aused to calculate the veriﬁer vwhich is stored at B.
In Step 8, both AandBuse a cryptographically strong hash function to compute a se ssion key
KAB=H(S). In Step 9, AcomputesCA=H(KA,KB,KAB)and sends it to Bas an evidence
that it has the session key. CAalso serves as a challenge. In Step 10, BcomputesCAitself and
matches it with A’s message. Balso computes CB=H(KA,CA,KAB). In Step 11, BsendsCB
toAas an evidencethat it has thesamesessionkey as A. In Step 12, AveriﬁesCB, accepts ifthe
veriﬁcationpasses andaborts otherwise.
NotethatunlikeEKE,noneoftheprotocolaremessagesencry ptedintheSRPprotocol. Since
neither the user nor the server has access to the same secret p assword or hash of the password,
SRPeliminatesplain-textequivalence. SRPwasuniqueinit sswapped-secretapproachinbuilding
averiﬁer-based, zero-knowledgeprotocol,resistingoff- linedictionaryattacks.
16.6 AuthenticationProtocolFailures
Despite the apparent simplicity of the basic design princip les, realistic authentication protocols
[11, 29]are notoriouslydifﬁculttodesign[39]. Thereare s everalreasonsforit.
•First, most realistic cryptosystems satisfy algebraic add itional identities. These extra prop-
erties maygenerateundesirableeffectswhen combinedwith aprotocollogic.
•Second, even assumingthat the underlyingcryptosystemis p erfect, unexpected interactions
amongtheprotocolstepscan lead tosubtlelogicalﬂaws.
611
1.A→B:A.
2.B→A:s.
3.A:x=H(s,pwd );KA=ga.
4.A→B:KA.
5.B:KB=v+gb.
6.B→A:KB,r.
7.A:S= (KB−gx)a+rxandB:S= (KAvr)b.
8.A,B:KAB=H(S).
9.A→B:CA=H(KA,KB,KAB).
10.BveriﬁesCAandcomputes CB=H(KA,CA,KAB).
11.B→A:CB.
12.AveriﬁesCB. Accept ifveriﬁcationpasses;abort otherwise.
Figure16.4: Secure RemotePassword(SRP) Protocol
•Third, assumptions regarding the environment and the capab ilities of an adversary are not
explicitlyspeciﬁed, makingitextremelydifﬁculttodeter minewhenaprotocolisapplicable
and whatﬁnal states areachieved.
Weillustratethedifﬁcultybyshowinganauthenticationpr otocolproposed,withasubtleweak-
ness. considerthefollowingauthenticationprotocol: (k pandk qaresymmetrickeyssharedbetween
Pand A, and Qand A, respectively,whereA isan authenticatio nserver. kis asessionkey.)
1)P→A : P, Q, n p
2)A→P: {n p, Q,k , {k,P} kQ}kp
3)P→Q : {k,P} kQ
4)Q→P: {n Q}K
5)P→Q : {n Q+1}K
Themessage{k,P} kQinstep(3)canonlybedecryptedbyQandhencecanonlybeunde rstood
by Q. Step (4) reﬂects Q’s knowledgeof k, whilestep (5) assur es Q of P’s knowledgeof k; hence
theauthenticationhandshakeis based entirelyontheknowl edgeofk.
The subtleweakness in theprotocolarises from thefact that themessage{k, P} kQsent in step
(3) contains no information for Q to verify its freshness. Th is is the ﬁrst message sent to Q about
612
P’s intentionto establish a secure connection. An adversar y who has compromised an old session
keyk′canimpersonatePbyreplayingtherecordedmessage{k′,P}kQinstep(3)andsubsequently
executingthesteps(4)and (5)usingk′.
To avoid protocol failures, formal methods may be employed i n the design and veriﬁcation of
authenticationprotocols. A formal designmethodshouldem bodythebasicdesign principles. For
example, informal reasoning such as “If you believe that onl y you and Bob know k , then you
should believe any message you receive encrypted with k was o riginally sent by Bob.” should be
formalizedby averiﬁcationmethod.
16.7 BibliographicNotes
Authentication in distributed systems is a well studied top ic and a large number of authentication
protocols exist. An excellent survey on the topic is by Woo am d Lam [39]. Burrows, Abadi and
Needhamdiscussthelogicofauthentication[7]. Aclassica lpaperonthetopicisbyNeedhamand
Schroeder [29].
AreviewpaperonpasswordbasedauthenticationisbyChakra bartiandSinghal[8]. Biometric
authenticationhasbeenverypopularrecently. Informatio nonthistopiccanbefoundin[16,17,34,
15,31]. KingandDosSantos[22]discussAIbasedmethodsfor humanauthentication. Kaminsky
etal. [18]discussuserauthenticationinaglobalﬁlesyste m. Alistofpapersonauthenticationcan
befoundat: http://www.passwordresearch.com/papers/pu bindex.html.
16.8 ExerciseProblems
1. Listthreeattacks/threatsthatare associatedwithuser authenticationon theInternet.
2. What isanonce? What securityproblemdoes itsolve?
3. Consider the following simple method to handle attacks on the password based authenti-
cation: If a user fails to login in three successive attempts , the system locks his account
suspectingan attack/intrusion. What majorproblemdo yous eewiththismethod?
4. Choosetwo principlesgivenby Needham and Abadi fordesig ningcryptographicprotocols.
Foreach, giveanexamplewheretheirprincipleappliesandr esultsinanimprovedprotocol.
5. ConsiderthefollowingprotocolforAuthentication/Key Distribution: (XandYaretwoprin-
cipals,AisaCertiﬁcateAuthorityoraKeyDistributionCen ter,RXisarandonnumber,and
EXmeans encrypted withthesecret key ofX.)
1. X→A:X,Y,R X
2. A→X:EX(RX,Y,K,E Y(K,X))
3. X→Y:EY(K,X)
4. Y→X:EK(RY)
613
5. X→Y:EK(RY−1)
(a) What does thepresence of RXin message2 assure?
(b) What problem will be created if an attacker were to break a n oldK(and the attacker
has also copiedmessagesforthat session)? Explainyourans wer.
(c) Suggest amethodtosolvethisproblem?
6. Discusstwobiometricbasedmethodsforauthentication. Whatareprosandconsofbiomet-
ricbased methodsforauthentication?
614
Bibliography
[1] Arfman,J. M.;Roden,Peter. Project Athena: Supporting distributedcomputingatMIT IBM
SystemsJournalVolume31,Number3, 1992.
[2] Martin Abadi and Roger Needham. Prudent engineering pra ctices for cryptographic proto-
cols.InProceedingsoftheIEEEComputerSociety Symposium onResearch inSecurityand
Privacy,pages 122–136.IEEE CS Press, May1994.
[3] M.Abadi,M.Burrows,C.Kaufman,andB.W.Lampson.Authe nticationanddelegationwith
smart-cards. Scienceof ComputerProgramming ,21(2):93–113,October1993.
[4] Ross Anderson and Roger Needham. Robustness principles for public key protocols. In D.
Coppersmith, editor, Advances in Cryptology — CRYPTO’95, p ages 236–247. Springer-
Verlag, LNCS963,August1995.
[5] S.M.BellovinandM.Merritt.LimitationsoftheKerbero sauthenticationsystem.In Proceed-
ingsofUSENIX WinterConference , pages 253–267,Dallas, TX,January 1991.
[6] S.M. Bellovin and M. Merritt, Encrypted Key Exchange: Pa ssword-based Protocol Secure
AgainstDictionaryAttacks,inProc.oftheIEEESymposiumo nSecurityandPrivacy,Wash-
ington,DC, 1992.
[7] M.Burrows,M.Abadi,andR.M.Needham.Alogicofauthent ication.ACMTransactionson
ComputerSystems ,8(1):18–36,February 1990.
[8] S.ChakrabartiandM.Singhal,Password-basedAuthenti cation,toappearinIEEEComputer.
[9] CCITT Recommendation X.509 The Directory—Authenticat ion framework, 1988. See also
ISO/IEC9594-8,1989.
[10] Art Conklin, Glenn Dietrich, Diane Walz, Password-Bas ed Authentication: A System Per-
spective,Proceedings ofthe 37th Hawaii InternationalCon ference on System Sciences, Jan-
uary 2004.
[11] D.E.Denning. CryptographyandDataSecurity .Addison-Wesley,1982.
[12] D.DolevandA.C.Yao.Onthesecurityofpublickeyproto cols.IEEETransactionsonInfor-
mationTheory , IT-29(2):198–208,March1983.
615
[13] M. Gasser, A. Goldstein, C. Kaufman, and B.W. Lampson. T he Digital distributed system
security architecture. In Proceedings of 12th National Computer Security Conference , pages
305–319,Baltimore, Maryland,October1989.
[14] M.GasserandE.McDermott.Anarchitectureforpractic aldelegationinadistributedsystem.
InProceedingsof 11th IEEE Symposiumon Research in Securitya nd Privacy , pages 20–30,
Oakland,California, May7–9 1990.
[15] L. O’Gorman, Practical Systems for Personal Fingerpri nt Authentication, IEEE Computer,
33,No. 2,58.60(2000).
[16] A. Jain, L. Hong, and S. Pankanti, Biometrics Identiﬁca tion, Communications of the ACM,
43,No. 2,91.98(2000).
[17] M. Indovina, U. Uludag, R. Snelick, A. Mink and A. Jain, " Multimodal Biometric Authen-
tication Methods: A COTS Approach", Proc. MMUA 2003, Worksh op on Multimodal User
Authentication,pp.99-106,Santa Barbara, CA, December11 -12,2003.
[18] M. Kaminsky, G. Saviddes, D. Mazieres and M. F. Kaashoek , Decentralized User Authenti-
cationin aGlobalFileSystem,Symp.on Oper.Sys. Principle s,2003.
[19] C.Kaufman, DASSDistributedAuthenticationSecurityService ,September1993.RFC1507.
[20] J.T. Kohl, B.C. Neuman, and T.Y. Ts’o. The evolution of t he Kerberos authentication sys-
tem. In F. Brazier and D. Johansen, editors, Distributed Open Systems , pages 78–94. IEEE
ComputerSociety Press, 1994.
[21] Kerberos Frequently Asked Questions, URL: http://www.nrl.navy.mil/CCS/
people/kenh/kerberos-faq.html .
[22] JeffreyKingandAndredosSantos,"AUser-FriendlyApp roachtoHumanAuthenticationof
Messages", in Financial Cryptography and Data Security, LN CS 3570, pp 225-239. Febru-
ary/March 2005.
[23] Lampson, B., Abadi, M. and Burrows, M, Authentication i n Distributed Systems: Theory
and Practice, ACM TransactionsonComputerSystems,1992.
[24] Min-HuiLinandChin-ChenChang,Asecureone-timepass wordauthenticationschemewith
low-computation for mobile communications, ACM SIGOPS Ope rating Systems Review,
Volume38,Issue2, April2004,Pages: 76 -84.
[25] Gavin Lowe, An Attack on the Needham-Schroeder Public- Key Authentication Protocol,
InformationProcessingLetters, Aug22, 1995,pages131-13 3.
616
[26] J.Linn.Practicalauthenticationfordistributedcom puting.In Proceedingsof11thIEEESym-
posium on Research in Security and Privacy , pages 31–40, Oakland, California, May 7–9
1990.
[27] Cheng-Chi Lee, Min-Shiang Hwang, Li-Hua Li, A New Key Au thentication Scheme Based
onDiscreteLogarithms,AppliedMathematicsandComputati on,Volume139,Issue2-3,July
2003.
[28] A. Menezes, P. van Oorschot, and S. Vanstone, Handbook o f Applied Crytography, Chapter
12-KeyEstablishmentProtocols,CRC Press, October1996.
[29] R.M. Needham and M.D. Schroeder. Using encryption for a uthentication in large networks
ofcomputers. CommunicationsoftheACM , 21(12):993–999,December1978.
[30] B.C. Neuman and T.Y. Ts’o. An authentication service fo r computer networks. IEEE Com-
municationsMagazine ,32(9):33–38,September1994.
[31] N. K. Ratha, J. H. Connell, and R. M. Bolle Enhancing secu rity and privacy in biometrics-
based authenticationsystems,IBM SystemsJournal,issue4 0-3,End-to-EndSecurity,2001.
[32] J.G. Steiner, C. Neuman, and J.I. Schiller. Kerberos: An authentication service for open
network systems. In Proceedings of USENIX Winter Conference , pages 191–202, Dallas,
TX,February 1988.
[33] B. Schneier, AppliedCryptography,JohnWiley&Sons, I nc., NewYork (1996).
[34] B. Schneier, The Uses and Abuses of Biometrics, Communi cations of the ACM, 42, No. 8,
136(1999).
[35] William Stallings, Cryptography and Network Security : Principles and Practice, Prentice-
Hall,4thedition.
[36] Paul Syverson and Iliano Cervesato, The Logic of Authen tication Protocols, Lecture Notes
inComputerScience", Vol2171,2001.
[37] The Secure Socket Layer, URL: http://publib.boulder.ibm.com/
infocenter/wmqv6/v6r0/index.jsp?topic=/com.ibm.mq.c sqzas.
doc/cssauthentication.htm .
[38] J.J. Tardo and K. Alagappan. SPX: Global authenticatio n using public key certiﬁcates. In
Proceedings of 12thIEEE Symposium on Research in Security and Privacy , pages 232–244,
Oakland,California, May20–221991
[39] T.Y.C. Woo and S.S. Lam. Authentication for distribute d systems. Computer , 25(1):39–52,
January1992. Seealso “Authentication”revisited. Computer ,25(3):10,March 1992.
617
[40] T.Y.C. Woo and S.S. Lam. A lesson on authentication prot ocol design. ACM Operating Sys-
temsReview , 28(3):24–37,July1994.
[41] Thomas Y.C. Woo, Simon Lam , Authentication for Distrib uted Systems, revised version
of a paper with the same title published in Computer, Volume 2 5, Number 1, pages 39–52,
January1992.
[42] T.Y.C.Woo and S.S. Lam. Design, veriﬁcation, and imple mentation of an au-
thentication protocol. In Proceedings of International Conference on Network
Protocols , Boston, Massachusetts, October 25–28 1994. (Also availab le from
http://www.cs.utexas.edu/users/lam/NRL/.)
[43] T.Y.C. Woo, R. Bindignavle, S. Su, and S.S. Lam. SNP: An i nterface for secure network
programming. In Proceedings of USENIX Summer Technical Conference , Boston, Mas-
sachusetts,June6–101994.(Alsoavailablefromhttp://ww w.cs.utexas.edu/users/lam/NRL/.)
[44] T.D. Wu, The Secure Remote Password Protocol, in Proc. o f the Network and Distributed
SystemsSecurity,NDSS 1998,San Diego,CA, 1998.
618
Chapter17
Self-Stabilization
17.1 Introduction
Theideaofself-stabilizationindistributedcomputing[3 6]wasﬁrst proposedby Dijkstrain1974.
The concept of self-stabilization is that regardless of its initial state, the system is guaranteed to
converge to a legitimatestate in a bounded amount of timeby i tselfwithout any outside interven-
tion. A non self-stabilizing system may neverreach a legiti matestate or it may reach a legitimate
state only temporarily. The main complication in designing a self-stabilizing distributed system
is that nodes do not have a global memory that they can access i nstantaneoulsy. Each node must
make decisionsbased on thelocal knowledgeavailableto it a nd actions of all nodes must achieve
aglobalojective.
The deﬁnition of legitimateand illegitimatestates depend s on the particularapplication. Gen-
erally, all illegitimatestates are deﬁned to be those state s which are not legitimatestates. Dijkstra
alsogaveanexampleoftheconceptofself-stabilizationus ingaself-stabilizingtokenringsystem.
For any given token ring when there are multiple tokens or the re is no token, then such global
statesareknownas illegitimatestates. Whenweconsiderad istributedsystemwherealargenum-
ber of systems are widely distributed and communicate with e ach other using message passing or
shared memory approach , there is a possibility for these sys tems to go into an illegitimate state,
for example, if a message is lost. The concept of self-stabil ization can help us recover from such
situationsindistributedsystem.
Letusexplaintheconceptofself-stabilizationusinganex ample. Letustakeagroupofchildren
andaskthemtostandintheformofacircle. Afterfewminutes ,youwillgetalmostaperfectcircle
withouthavingtotakeanyfurtheraction. Inaddition,youw illdiscoverthattheshapeofthiscircle
is stable, at least until you ask the children to disperse. If you force one of the children out of
the position, the others will move accordingly, moving the e ntire circle in another position, but
keepingitsshapeunchanged.
In this example, the group of children build a self-stabiliz ing circle: if some thing goes wrong
withthecircle,theyareabletorebuildthecirclebythemse lves,withoutanyexternalintervention.
The time required for stabilization varies from experiment to experiment, depending on the (ran-
dom)initialposition. However,iftheﬁeldsizeislimited, thistimewillbebounded. Thealgorithm
619
does not deﬁne the position of the circle in the ﬁeld and so it w ill not always be the same. The
positionofeach childrelativeto each otherwillalsovary.
The self-stabilization principle applies to any system bui lt on a signiﬁcant number of compo-
nentswhichareevolvingindependentlyfromoneanother,bu twhicharecooperatingorcompeting
to achieve common goals. This applies, in particular, to lar ge distributed systems which tend to
result from the integration of many subsystems and componen ts developed separately at earlier
timesorbydifferent people.
Inthischapter,weﬁrstpresentthesystemmodelofadistrib utedsystemandpresentdeﬁnitions
ofself-stabilization. Next,wediscussDijkstra’ssemina lworkanduseittomotivatethetopic. We
discussthe issuesarising from theDijkstra’soriginalpre sentation as well as severalrelated issues
in the design of self-stabilizing algorithms and systems. A fter that, we discuss three important
themes that have recently emerged. In particular, we discus s the methods that have been used
to design complex self-stabilizing systems, we discuss the role of compilers in designing self-
stabilization, and we enumerate factors that have been foun d to interfere with self-stabilization.
We also discuss self-stabilizing protocols for constructi on of spanning trees and present a self-
stabilizing algorithm for 1-maximal independent set. We co nclude the chapter with limitationsof
self-stabilization.
17.2 SystemModel
The term distributed system is used to describe set of comput ers that communicate over network.
Variants of distributed systems have similar fundamental c oordination requirements among the
communicating entries, whether they are computers, proces sors or processes. Thus an abstract
model that ignores the speciﬁc settings and captures the imp ortant characteristics of a distributed
systemisusuallyused.
In a distributed system, each computer runs a program compos ed of executable statements.
Each execution changes the content of the computer’s logica l memory. An abstract way to model
acomputerthatexecutesaprogramistousethestatemachine model. A distributedsystemmodel
comprises of a set of n state machines called processors that communicate with each other. We
usuallydenotethe ithprocessorinthesystemby Pi. Neighborsofprocessorareprocessorsthatare
directly connected to it. A processor can directly communic ate with its neighbors. A distributed
system can be conveniently represented by a graph in which ea ch processor is represented by a
nodeandevery pairofneighboringnodesare connectedby ali nk.
Thecommunicationbetweenneighboringprocessorscanbeca rriedouteitherbymessagepass-
ingorsharedmemory. Communicationbywritinginandreadin gfromthesharedmemoryusually
ﬁts systems with processors that are geographically close t ogether, such as multiprocessor com-
puter. Amessage-passingdistributedmodelﬁtsbothproces sorsthatarelocatedclosetoeachother
as wellas that arewidelydistributedoveranetwork.
In the message-passing model, neighbors communicate by sen ding and receiving messages.
In asynchronous distributed systems, the speed of processo rs and message transmission can vary.
620
First-in ﬁrst-out (FIFO) queues are used to model asynchron ous deliveryof messages. A commu-
nication link is either unidirectional or bidirectional. A unidirectional communication link from
processorP itoPjtransfersmessagesonlyfromP itoPj. Theabstractionusedforsuchaunidirec-
tionallinkis aﬁrst-in ﬁrst-out (FIFO) queueQ i,jthat containsallmessages sentby a processorP i
toitsneighborP jthathavenotyet beenreceived. WheneverP isendsamessagemto P j, themes-
sage is en-queued (added to the tail of the queue). The bidire ctional communication link between
processors P iand P jis modeled by two FIFO queues, one from P ito Pjand the other from P jto
Pi.
It is convenient to identify the state of a computer or a distr ibuted system at a given time, so
that no additional information about the past of the computa tion is needed in order to predict the
future behavior (state transitions) of the computer or the d istributed system. A full description of
a message passing distributed system at a particular time co nsists of the state of every processor
and thecontentofevery queue(messagestravelinginthecom municationlinks). Thetermsystem
conﬁguration(orconﬁguration)isusedforsuchadescripti on. Aconﬁgurationisdenotedbyc=(s 1,
s2...sn,q1,2,q1,3,...q i,j.......q n,n−1),wheres i,1≤i≤nisthestateofP iandq i,j,i∝\⌉}atio\slash=jisthestate
of queue Q i,j, that is, messages sent by P ito Pjbut not yet received. The behavior of a system
consistsofasetofstates,atransitionrelationbetweenth osestates,andasetoffairnesscriteriaon
thetransitionrelation[81].
Thesystemisusuallymodeledasagraphofprocessingelemen ts(modeledasstatemachines),
where edges between these elements model unidirectional or bidirectional communication links.
Let N be an upper bound on n (the number of nodes in the system). Communication network is
usually restricted to the neighbors of a particular node. Le tδdenote the diameter of the network
(i.e., the length of the longest unique path between two node s) and let ∆denote the upper bound
onδ. A network is static if the communication topology remains ﬁ xed. It is dynamic if links and
networknodescangodownandrecoverlater. Inthecontextof dynamicsystems,self-stabilization
refers to the time after the “ﬁnal” link or node failure. The t erm “ﬁnal failure” is typical in the
literature on self-stabilization. Since stabilization is only guaranteed eventually, the assumption
that faults eventually stop to occur implies that there are n o faults in the system for “sufﬁciently
long period” for the system to stabilize. In any case, it is as sumed that the topology remains
connected, i.e.,thereexistsapathbetween anytwo nodes.
In the shared memory model, processors communicate using sh ared communication registers
(hereafter,calledregisters). Processorsmaywriteinase tofregistersandmayreadfromapossibly
differentsetofregisters. Twoneighboringnodeshaveacce ss toacommondatastructure, variable
or register which can store a certain amount of information. These variables can be distinguished
between input and output variables (depending on which proc ess can modify them). When exe-
cuting a step, a process may read all its input variables, per form a state transition and write all its
outputvariablesinasingleatomicoperation. Thisiscalle d compositeatomicity. Aweakernotion
of a step (called read/write atomicity) also exists where a p rocess can only either read or write its
communicationvariablesinoneatomicstep.
The conﬁguration ofa systemwith n processors and m communic ationregistersis denoted by
621
c= ( s 1, s2, s3.....s n, r1, r2..., r m), where s i, 1≤i≤n, is the state of P iand r j, 1≤j≤m, is the
contentsofacommunicationregister.
Algorithms are modeled as state machines performing a seque nce of steps. A step consists of
reading input and the local state, then performing a state tr ansition and writing output. Commu-
nication can be by exchanging messages overthe communicati onchannels. An algorithmmay be
randomized, i.e., have access to a sourceof randomness(a ra ndom numbergenerator or a random
coin ﬂip). If an algorithm is not randomized, we will call it d eterministic. A related characteris-
tic of a system model is its execution semantics. In self-sta bilization, this has been encapsulated
within the notion of a scheduler or daemon (also demon). Unde r a central daemon, at most one
processingelementis allowedtotakeastepat thesametime.
17.3 Deﬁnitionof Self-Stabilization
We have seen an informal deﬁnition of self-stabilization at the beginning. Formally, we deﬁne
self-stabilization for a system S with respect to a predicat e P over its set of global states, where P
isintendedtoidentifyitscorrectexecution[81]. Statess atisfyingParecalledlegitimatestatesand
thosenotsatisfyingParecalled illegitimatestates. Weus ethetermssafeandunsafeinterchange-
ablywith legitimateand illegitimate,respectively.
A system S is self-stabilizing with respect to predicate P if it satisﬁes the following two prop-
erties:
1.Closure—PisclosedundertheexecutionofS.Thatis,oncePisestabl ishedinS,itcannot
befalsiﬁed.
2.Convergence — Starting from an arbitrary global state, S is guaranteed to reach a global
statesatisfyingPwithinaﬁnitenumberofstatetransition s.
Arora and Gouda [13] introduced a more generalized deﬁnitio n of self-stabilization, called
stabilization , which is deﬁned as follows. We deﬁne stabilization for a sys tem S with respect to
twopredicatesPandQ,overitssetofglobalstates. Predica teQdenotesarestrictedstartcondition.
Ssatisﬁes Q→P(read as Q stabilizesto P)ifitsatisﬁes thefollowingtwo p roperties:
1.Closure—PisclosedundertheexecutionofS.Thatis,oncePisestabl ishedinS,itcannot
befalsiﬁed.
2.Convergence — If S starts from any global state that satisﬁes Q, then S is gu aranteed to
reach a globalstatesatisfyingP withinaﬁnitenumberofsta tetransitions.
Notethatself-stabilizationisaspecial caseofstabiliza tionwhereQ isalways true,thatis,ifS
isself-stabilizingwithrespect toP, then thismay beresta ted asTRUE→Pin S.
Next,wedeﬁne twotermsthat relevanttothediscussionofse lf-stabilization.
622
Reachable Set: Often when a programmerwrites aprogram, hedoes not havea pa rticulardeﬁni-
tionofsafeandunsafestatesinmindbutdevelopstheprogra mtofunctionfromaparticularsetof
startstates. Insuchsiruations,itisreasonabletodeﬁnea ssafethosestatesthatarereachableunder
normalprogramexecutionfromthesetoflegitimatestartst ates. Thesestatesarereferred toasthe
reachableset . So, when wesay that a program is self-stabilizingwithoutm entioninga predicate,
wemeanwithrespecttothereachableset. Bydeﬁnition,ther eachablesetisclosedunderprogram
execution,and itcorresponds toapredicateoverthesetofs tates[81].
We usetransientfailuremodelin thediscussion.
Transientfailure: Atransientfailureistemporary(shortlived)anditdoesno tpersist. Atransient
failure may be caused by corruption of local state of process es or by corruption of chennels or
shared memory. A transientfailuremay changethestateofth esystem,butnotitsbehavior.
Randomized and Probabilistic Self-Stabilization
Randomized methodsfor self-stabilizationare useful in ac hieving self-stabilizationunder process
symmetry (i.e., all processes are identical). Depending on the stabilization time, self-stabilization
can beclassiﬁed as randomizedand probabilisticself-stab ilization.
RandomizedSelf-Stabilization: A systemissaidtobe randomizedself-stabilizingsystem ,ifand
onlyifitisself-stabilizingandtheexpectednumberofrou ndsneededtoreachacorrectstate(legal
state)isboundedby someconstantk.
Probabilistic Self-Stabilization: A system S is said to be probabilistically self stabilizing with
respect toa predicatePifitsatisﬁesthefollowingtwoprop erties:
1.Closure: P is closed under the execution of S. That is, once P is establi shed in S, it cannot
befalsiﬁed.
2.Convergence: There exists a function f from natural numbers to [0,1] satis fying lim k→∞
f(k) = 0, such that the probability of reaching a state satisf ying P, starting from an arbitrary
globalstatewithink statetransitions,is1-f(k).
Pseudo-stabilizingsystem is one, which if started in an arbitrary state is guaranteed t o reach a
state after which it does not deviate from its intended speciﬁcation. A stabilizing system is one,
which if started at an arbitrary state is guaranteed to reach a state after which it cannotdeviate
from its intended speciﬁcation. Thus, the difference betwe en the two notions comes down to
the difference between cannot and does not - a difference tha t hardly matters in many practical
situations. Thestrongerrequirementofself-stabilizati onisadvantageousoverpseudo-stabilization
inﬁnite-statesystems,sinceself-stabilizationpropert yimpliesaboundedconvergencespan while
thepseudostabilizationdoesnot. Algorithmshavebeenpro posedforprobabilisticorientationofan
623
asynchronous bi-directional ring, as well as for a synchron ous ring with odd number of processes
and onetoken.
In thenextsection,wediscusstheissuesin thedesignofsel f-stabilizationalgorithms.
17.4 Issuesin thedesignof self-stabilizationalgorithms
A distributed system comprises of many individual units and many issues arise in the design of
self-stabilizationalgorithmsin distributedsystem. Som eofthemainissuesareas follows:
1. Numberofstatesin each oftheindividualunitsina distri butedsystem
2. Uniformand Non-uniformAlgorithmsin distributedsyste ms
3. Central and DistributedDemon
4. Reducing thenumberofstates inatoken ring
5. Shared memorymodels
6. Mutualexclusion.
7. Costsofself-stabilization
Dijkstra’sSelf-Stabilizing TokenRing System
We explain theabovestated issues with thehelp of Dijkstra’ slandmark self-stabilizingtoken ring
system [36]. His system consisted of a set of n ﬁnite state mac hines connected in the form a
ring. He deﬁnes a privilege of a machine to be the ability to ch ange its current state. This ability
is based on a Boolean predicate that consists of its current s tate and the states of its neighbors.
When a machine has a privilege, it is able to change its curren t state, which is referred to as a
move. Furthermore, when multiplemachines enjoy a privileg eat the same time, the choice of the
machine that is entitled to make a move is made by a central dem on, which arbitrarily decides
whichprivilegedmachinewillmakethenextmove.
A legitimatestatemustsatisfythefollowingconstraints:
1. Theremustbeat leastoneprivilegeinthesystem(livenes sornodeadlock).
2. Everymovefrom alegalstatemustagainputthesysteminto alegalstate(closure).
3. During an inﬁnite execution, each machine should enjoy a p rivilege an inﬁnite number of
times(nostarvation).
4. Givenany twolegalstates, there is aseries ofmovesthat c hange onelegalstateto theother
(reachability).
624
Dijkstra[36]consideredalegitimate(orlegal)stateason einwhichexactlyonemachineenjoys
the privilege. This corresponds to a form of mutual exclusio n, because the privileged process is
the only process that is allowed in its critical section. Onc e the process leaves the critical section,
itpasses theprivilegeto oneofitsneighbors.
With this background, let us see how the above stated issues e ffect the design of a self-
stabilizationalgorithm.
17.4.1 The Number of Statesin Eachofthe Individual Units
Aninterestingissueinself-stabilizingsystemsisthenum berofstatesthateachmachineisrequired
to have. Dijkstra offered three solutions for a directed rin g with n machines, 0, 1, ........., n-1,
each having K states, (i) K ≥n, (ii) K=4, (iii) K=3. It was later proven that a minimum of th ree
states is required in a self-stabilizing ring. In all three a lgorithms, Dijkstra assumed the existence
ofat leastoneexceptionalmachinethatbehaved differentl yfromtheothers.
Theﬁrst solution(K ≥n)is describedbelow.
First Solution
For any machine, we use the symbols S, L, and R to denote its own state, the state of the left
neighborand thestateoftherightneighboronthering,resp ectively.
The exceptional machine
IfL =Sthen
S: =(S+ 1)modK
EndIf;
The other machines
IfL∝\⌉}atio\slash=Sthen
S: =L
EndIf;
In this algorithm, except the exceptional machine (machine 0), all other machines follow the
same algorithm. In the ring topology, each machine compares its state with the state of the anti-
clockwise neighbor and if they are not same, it updates its st ate to be the same as that of its
anti-clockwiseneighbor.
So, if there are n machines and each of them is initially at a ra ndom state r dK, then all the
machines(excepttheexceptionalmachine,machine0)whose statesare notthesameas theiranti-
clockwise neighbor are said to be privileged and there is a ce ntral demon which decides which of
theseprivilegedmachineswillmakethemove.
Suppose machine 6 (assume n ≫6) makes the ﬁrst move. It is obvious that it’s state is not
the same as that of machine 5 and hence it had the privilege to m ake the move and ﬁnally sets
its state to be the same as that of machine 5. Now machine 6 lose s its privilege as its state is
625
same as that of its anti-clockwise neighbor (machine 5). Nex t, suppose machine 7, whose state
is different from the state of machine 6, is given the privile ge. It results in making the state of
machine 7 sameas that of machine 6. Now machines 5, 6 and 7 are i n the samestate. Eventually,
allthemachineswillbeinthesamestateinthesimilarmanne r. Atthispoint,onlytheexceptional
machine (machine 0) will be privileged as its condition L = S i s satisﬁed, i.e., it’s state is same as
that of its anti-clockwise neighbor. Now there exists only o ne privilegeor token in the system (at
machine0). Machine0makesamoveandchangesitsstatefromS to(S+1)modK.Thiswillmake
the next machine, machine 1, privileged as its state is not th e same as its anti-clockwiseneighbor,
i.e., machine 0. Thus, it can be interpreted as the token is cu rrently with machine 1. Machine 1,
as per the algorithm, changes its state to the same state as th at of machine 0. This will move the
token to machine 2 as its state is now not same as that of machin e 1. Likewise, the token keeps
circulatingaround thering andthesystemisstable.
This is asimplealgorithm,but it requires a numberof states , which dependson the sizeofthe
ring,which maybeawkward forsomeapplications.
Second Solution
Thesecondsolutionusesonly3-statemachinesandispresen tedbelow. Thestateofeachmachine
isin {0,1, 2}.
Intheﬁrstalgorithm,thereisonlyoneexceptionalmachine ,machine0. Inthesecondsolution,
there are two such machines, machine 0, referred to as the bot tom machine and machine n-1,
referred to asthetopmachine.
Algorithm
The bottom machine, machine0
If(S+ 1)mod3=R then
S: =(S -1)mod3
The top machine, machine n-1
IfL =Rand (L +1)mod3 ∝\⌉}atio\slash=Sthen
S: =(L+1)mod 3
The other machines
If(S +1)mod3=L then
S: =L
If(S +1)mod3=R then
S: =R
In thisalgorithm,thebottommachine, machine0 behaves,as follows:
If (S+1)mod3 =R then
626
S:=(S -1)mod 3
Thus, the state of the bottom machine depends upon its curren t state and the state of its right
neighbor.
The condition(s+1) mod3 covers thethreepossiblestates; f ors=0, 1, 2, wehave(s+1) mod3
=1, 2,0. Theseresultinthefollowingthreepossibilities:
1. ifs=0and r=1, then thestateofsis changedto 2
2. ifs=1and r=2, then thestateofsis changedto 0
3. ifs=2and r=0 then, thestateofsis changedto 1
Thetopmachine, machinen -1, behavesas follows:
If L=R and(L +1)mod3 ∝\⌉}atio\slash=Sthen
S:=(L+1) mod3
The state of the top machine depends upon both its left and rig ht neighbors (the bottom ma-
chine). The condition speciﬁes that the left neighbor (L) an d the right neighbor (R) should be in
thesamestateand(L+1)mod3shouldnotbeequaltoS.(Noteth at(L+1)mod3is1,2,0whenL
is0, 1, 2,respectively)Thus,thestateofthetop machineis asfollows:
1. 1, whenitsleft neighboris0
2. 2, whenitsleft neighboris1
3. 0 whenitsleft neighboris2
All othermachinesbehaveas follows:
If (S+ 1)mod3 =Lthen
S:=L
If (S+ 1)mod3 =R then
S:=R
Whileﬁndingoutthestateoftheothermachines(machine1,2 intheexamplebelow),weﬁrst
comparethestateofamachinewithitsleftneighbor:
1. Ifs=0 and L=1,then s=0
2. Ifs=1 and L=2,then s=2
3. Ifs=2 and L=0,then s=1
627
If the above conditions are not satisﬁed, then the machine co mpares its state with its right
neighbor.
628
Stateof
machine0Stateof
machine1Stateof
machine2Stateof
machine3Privileged
machinesMachine to
makemove
0 1 0 2 0,2,3 0
2 1 0 2 1,2 1
2 2 0 2 1 1
2 0 0 2 0 0
1 0 0 2 1 1
1 1 0 2 2 2
1 1 1 2 2 2
1 1 2 2 1 1
1 2 2 2 0 0
0 2 2 2 1 1
0 0 2 2 2 2
0 0 0 2 3 3
0 0 0 1 2 2
Table17.1: AnExampleofDijkstra’sThree-StateAlgorithm
A sampleexecutionofDijkstra’sthree-state algorithmis s hownin Table17.1. The exampleis
foraring offourprocesses(0, 1, 2, 3). Machine0 isthebotto mmachineandmachine3 isthetop
machine. The last column in the table gives the number of the m achine chosen to make the next
move. Initially,threeprivilegesexistinthesystem. Then umberofprivilegesdecreases untilthere
isonlyoneprivilegein thesystem.
We makethefollowingobservations:
1. Thereare nodeadlocksin anystate(at leastoneprivilege ispresent).
2. Theclosureproperty issatisﬁed (thesystemmovesfrom al egalstatetoalegalstate).
3. No starvation(each machinehas achanceofmakingmoretha n1 move).
4. Reachability(there arealways aseries ofmovestoreach f romonelegalstatetoother).
All four properties given in the beginning of this section ar e satisﬁed. So the system is stabi-
lized.
Special Networks
In the above two algorithms, each processor needs K states an d 3 states, respectively. There are
special networks,wherethenumberofstatesrequired byeac h processoris two.
A network organized liketheone in Figure 17.1 needs only two states permachine. Thealgo-
rithm uses information from all of its neighbors. The follow ing algorithm uses s[i] to denote the
state of machine i and there are two possible states for each m achine, 0 and 1. In the algorithm,
629
1
23
45
67
82n−3
2n−202n−1
Figure17.1: A Special Network NeedingOnlyBinary StateMac hines
bisusedtodenoteanarbitrarystate(0or1)andb ∼isusedtodenotethecomplementarystateofb.
Formachine0:
If(s[0], s[1])=(b∼, b)then s[0]:=b
Formachine2n-1:
If(s[2n-1], s[2n-2])=(b,b)then s[2n-1]:=b ∼
Forevennumberedmachines:
If(s[2i-2], s[2i-1], s[2i],s[2i+1 ])=(b, b, b ∼, b)then s[2i]:=b
Foroddnumberedmachines:
If(s [2i-2], s[2i-1], s [2i],s [2i+1]) =(b, b,b, b ∼)then s[2i-1]:=b∼
In this algorithm, each machine must examine the states of al l its neighbors. Thus, a large
atomicityis assumedbecauseeach machinemustbeableto exa minethestates ofall itsneighbors
inoneatomicstep. Thealgorithmalsorequiresanevennumbe rofmachines(atleast6). However,
the algorithm shows that self-stabilizing algorithms requ iring a small number of states can be
designed.
Dolevetal.’sSolution
For a system with odd number of machines in a ring, a solution f or self-stabilization by Dolev et
al. [42] is as follows: Each node has two states, 0 and 1. Given a global state, the nodes make
movesaccording tothefollowingrules:
1. If the local stateis different from its left neighbor’s st ate, then the stateis changed to be the
sameasitsleft neighbor.
2. If the local state is the same as its left neighbor’s state, the state is chosen randomly from 0
and 1.
Ateachstep,thenodesmaketheirmovesinsynchronization. Anodehasaprivilegeifitsstate
is the same as its left neighbor’s state. It is shown, using pr obability theory, that eventually only
630
one privilege exists in the system. This algorithm requires that the nodes operate synchronously,
but itshowsthat thenumberof statesrequired for each nodem aybe reduced usinga probabilistic
algorithm.
17.4.2 Uniform Vs. Non-uniform Networks
Whether processes are uniform or nor is an important aspect o f self-stabilization. In a distributed,
it is desirable to have each machine use the same algorithm. I n self-stabiliziing systems, it is
desirable to have non-uniformity among machines. In the pre ceding section, at least one of the
machines had a privilege and a move that was different from th e rest of the machines. These
machinesare knownas exceptionalmachines,and thealgorit hmsarenon-uniform.
The individual processes can be anonymous, meaning they are indistinguishable and all run
thesamealgorithm. Often,anonymousnetworksarecalledun iformnetworks. Anetwork issemi-
uniform if there is one process (the root) which executes a di fferent algorithm. While there is no
way to distinguish nodes, in uniform or semi-uniform algori thms nodes usually have a means of
distinguishingtheirneighborsbyorderingtheincomingco mmunicationlinks. Inthemostgeneral
caseit isassumedthatprocesses havegloballyuniqueident iﬁers.
Self-stabilization algorithms for distributed systems sh ould be uniform, but this is not always
possible. As asimpleexample,considertheringoffourproc essorsshowninFigure17.2.
0 2 3 1
Figure17.2: A Ring ofFourProcessors
Assume there is a uniform self-stabilizing algorithm for th is ring. In a distributed system, the
state of a machine/process is changed depending on the state of its neighbors. In this example, if
all processors have the same state when started, all must hav e privileges because there must be at
least oneprivilegein thesystem(property 1ofalegalstate ).
Note that 0 and 2 make a move(because if one makes a move, it doe s not affect the neighbors
of the other), and change their states. In this example, 0 and 2 make an independent set. After the
transition,0 and 2are inthesamestateand soare 1 and3.
The system is partitioned into two sets: {0,2} and {1,3}. At l east two machines must have
a privilege because 0 and 2 have the same states and also their neighbors 1 and 3 have the same
states. Thus once again, machines 0 and 2 can make moves and le ave the network in a similar
situation. The scenario with 1 and 3 is also the same, they bot h are in the same state and their
neighbors 0 and 2 are in the same state. So, if 1 has privilege, then 3 will also have privilege and
631
both machines can make moves and leave the network in a simila r situation. So, in either case,
therewillbetwoprivilegedmachinesat anytimeinthenetwo rk.
Even though uniformity is a desirable property, most algori thms that have been developed to
use at least one exceptional machine. However, uniformity i s sometimes attainable. A uniform
self-stabilizingalgorithmforaringofnprocessors,wher enisprime,wasdevelopedbyBurnsand
Pachl [22] and it was observed that fora ring ofcompositesiz e, thealgorithmfailed only because
it could deadlock. Thus, if deadlock can be tolerated or can b e corrected easily from outside the
system, then the algorithm may be useful. These examples sho w that uniformitymay be achieved
ifwearewillingtosacriﬁce apropertyofself-stabilizati on.
17.4.3 Central and Distributed Demons
Dijkstra original assumption was that there is a central dem on that decides which machine with a
privilege will make the next move. However, the presence of a central demon is an undesirable
constraint. A distributed demon is more desirable where eac h privileged machine makes its own
decision on whether to make a move. In a self-stabilizing sys tem without a central demon, each
machinemakesadecisionlocally. Eventhoughthedecisions aremadelocally,thesedecisionswill
eventually take the system towards a global goal. Once this g lobal goal is achieved, the system is
self-stabilized.
Interestingly, many early algorithms (e.g., Dijkstra’s th ree, four, and K-state algorithms)were
developed assuming the presence of a central demon and they d id not deal with the possibility of
havingadistributeddemon,yet thesealgorithmsalsowork w ithdistributeddemons.
Even though a central demon is not desirable, it is usually ea sier to verify a weak correctness
criterion on an algorithmusingthis assumption. For this re ason, self-stabilizingsystemsare often
developed assuming the presence of a central demon. After th e weak correctness is veriﬁed, the
system is examined to see if it is still self-stabilizing whe n the assumption of a central demon is
removed. If itisnot,thealgorithmis extendedsothat acent ral demonisnotnecessary.
Burns et al. [23, 25] examine the extensibility of some algor ithms. They showed that letting
all machines operate simultaneously will not affect the cor rectness of some algorithms. Such in-
terleavingassumptionis veryuseful intheveriﬁcationofs elf-stabilizingsystems. As an example,
Burnsetal. [25]veriﬁedthatDijkstra’salgorithmsarecor recteveninthepresenceofadistributed
demon. Originally, Dijkstra’s algorithms were only proven to be correct in the presence of a cen-
tral demon. However,theyshowedthatthecentral demonassu mptionis unnecessary forboth,the
three and four state algorithms. The K-state solution is sho wn to be valid for a distributed demon
only if K > n (n is the numberofmachines), because there is a cy cle of illegalglobal states if K =
n.
Burns et al. also developed results, which can be used to show an algorithm that is correct in
the presence of a central demon, is also correct when the cent ral demon assumption is removed.
This is useful in the veriﬁcation process because once the al gorithm is veriﬁed in the presence of
a central demon, the algorithm may be correct even when the ce ntral demon assumption is lifted
without any modiﬁcation to the algorithm. This of course may not be the case for all algorithms,
632
buttheseresultscan behelpfulin theprocess ofveriﬁcatio n.
17.4.4 Reducing the number ofstatesin a tokenring
A natural question is: what is the number of states of a machin e to achieve self-stabilization in
variousconﬁgurations. Clearly, theobjectiveis to minimi zethenumberofstates ofa machinefor
efﬁcient implementation.
Ithasbeenshownthatifself-stabilizationisnotarequire ment,thenthereexistsanasymmetric
token ring with two states per machine. In a self-stabilizin g token ring with a central demon and
deterministicexecution,Ghosh[51]showedthataminimumo fthreestatespermachineisrequired.
However,for a non-ring topology,the numberofstates can be reduced to two per machine. There
exists a non-trivial self-stabilizing system with two stat es per machine [49]. It requires a high
degreeofatomicityineachaction. Eachnon-exceptionalpr ocessreadsfromthreeofitsneighbors.
Thus,obviously,thetopologyisnon-ring.
Herman [61] presented a unidirectional and symmetric solut ion, that has only two states, for
a "probabilistically" self-stabilizing synchronous toke n ring with randomized actions. a solution
requiring two states per machine exists. Flatebo and Datta [ 43] developed a two-state, unidirec-
tionalandasymmetricsolutionfora"probabilistically"s elf-stabilizingtokenringwithrandomized
actionsundertheassumptionofarandomizedcentraldemon. Witharandomizedcentraldemon,a
demonischosenrandomlyamongprivilegedmachinesanditmi nimizestheproblemofmalicious
schedulingonthepart ofthedemon.
Thus, it appears that to obtain self-stabilizing systems wi th two states per machine, we must
either relax the objective to "probabilistic self-stabili zation" using randomized actions, or use a
non-ringtopologywithhigheratomicityintheactions.
17.4.5 Shared memoryModels
Distributedsystemshavingsharedmemorybetweenmachines whereprocessescommunicatewith
each other by reading and writing to registers have also been used as self-stabilizing systems. In
this type of model, no processor has direct access to the stat e of its neighbors, and the only way
todetermineitis bypassinginformationthroughshared reg isters. Iftwoprocessors,P iand P jare
neighbors, then there are two registers, i and j between the t wo nodes. To communicate, P iwrites
to i and reads from j and P jwrites to j and reads from i. It is convenient to represent a di stributed
systembyagraphinwhicheachprocessorisrepresentedbyan odeandtheneighboringnodesare
connected byalinkwhich showsthecommunicationbetween an odeand itsneighbors.
The self-stabilization algorithms work for an arbitrarily connected graph. They also work if
the graph is changed during execution (due to a node failure, etc.). So, there is no problem even
ifthesystemisdynamic. In aself-stabilizationalgorithm ,eventuallyonlyoneprocesscan change
a register at any instance, and this is when the system is stab ilized. The only assumption made is
thatallread/writeoperationsperformedontheregistersa reatomic. Laterinthischapter,westudy
adynamicself-stabilizingalgorithm.
633
Dolev et al. [42] present a dynamic self-stabilizing algori thm for mutual exclusion. The al-
gorithm only requires that all nodes be connected (that is, t he network should not be partitioned).
Node failures may cause an illegal global state, but the prot ocol is dynamic and self-stabilizing.
This means that even with a node failing, the system will agai n converge to a legal state. If a
nodeis restarted, anillegalglobalstatemayagainoccur, b utthesystemwillautomaticallycorrect
itself. The size of the registers are on the order of log (n), w here n is the number of processors.
Theonlyassumptionmadeis thattheread/writeoperationso n theregistersare atomic. Thisweak
assumptionmakestheimplementationofthealgorithmfeasi ble.
17.4.6 Mutual Exclusion
In previous sections, we discussed self-stabilizing syste ms where there is only one action being
done after a ﬁnite amount of time. The action could be changin g a state or the contents of a
register. In a mutualexclusionalgorithm,each process has acritical section ofcode, and onlyone
process can enter its critical section at any time, and every process that wants to enter its critical
section, will be allowedto enter itscritical section withi na ﬁnite amountof time. If a process has
a privilege, it can enter its critical section, and once it is ﬁnished (execuing the critical section),
it passes the privilege to the neighbor. If the process does n ot want to enter its critical section, it
simplypassestheprivilegetoits neighbor. Since theself- stabilizingalgorithmsmentionedadhere
to the four properties discussed previously, mutual exclus ion is also satisﬁed. Since eventually,
there is only one privilegein the system and each process enj oys a privilegean inﬁnitenumber of
times,aprocess isguaranteed toenteritscritical section ina ﬁniteamountoftime.
Aself-stabilizingmutualexclusionsystemcanalsobedesc ribedintermsofatokensystem. A
tokensystemhastheprocessescirculatingtokens. Ifaproc esshasoneofthesetokens,itisallowed
toenteritscriticalsection. Brown,Gouda,andWu[21]used thissystemtodevelopself-stabilizing
mutual exclusion systems. At ﬁrst, there may be more than one token in the system, but after a
ﬁniteamountoftime,onlyonetokenexistsinthesystemwhic hiscirculatedamongtheprocesses.
Suchsystemsareeasiertoimplementincircuits,andBrowne tal. showedhowtheimplementation
is done usingﬂip-fops. All of themodels, token systems, pri vileges,shared memory,are forms of
mutualexclusion,and thealgorithmsalsotoleratenodefai lures andrestarts orabadinitialization.
So thesealgorithmsaremoretolerantoferrors than othermu tualexclusionalgorithms.
17.4.7 Costsof self-stabilization
The deﬁnition of self-stabilization does not put any upper b ound on the number of transitions
required by the system to reach a safe state starting from an u nsafe one. Thus, the system might
remain in an unsafe state for a considerable amount of time be fore reaching a safe state. A study
and assessmentofthesecostfactor isveryimportantinanyp ractical implementation.
Gouda and Evangelist [55] introduced the following two conc epts related to the cost of self-
stabilization:
634
•Convergence span: It is the maximum number of transitions that can be executed i n a
system,startingfrom an arbitrary state,beforeit reaches asafe state.
•Response span: It is the maximum number of transitions that can be executed i n a system
to reach a speciﬁed target state, starting from some initial state. The choice of initial state
and target statedependsupon theapplication.
Clearly, the aim of the designer of a self-stabilizing algor ithm is to reduce the convergence
span andresponsespan.
Time-complexity measure for self-stabilizing algorithms is the number of rounds. In syn-
chronousmodels,algorithmsexecuteinrounds,i.e.,proce ssorsexecutestepsatthesametimeand
at a constant rate. Rounds can be deﬁned in asynchronous mode ls too, where the ﬁrst round ends
in a computation when every processor has executed at least o ne step. In general, the ithround
ends, when every processor has executed at least i steps. Gen erally, communication between any
twoprocessors ina particularsystemtakes at least(d)roun ds. This isbecauseit normallytakes at
least oneround topropagateinformationbetweentwo adjace nt processors.
17.5 Methodologiesfordesigningself-stabilizingsystem s
Having seen the issues in the design of self-stabilizing sys tem, let us now discuss the methodolo-
giesfordesigningself-stabilizingsystems.
Self-stabilizationischaracterizedintermsofa"malicio usadversary"whoseobjectiveistodis-
rupt thenormaloperation ofthesystem. Thisadversary (e.g ., a virusor ahardware problem)may
destroysomeportionsofthesystem,ordisrupttheoperatio nofoneormoreportions. Furthermore,
it mightnotbe possiblefora systemto detect that it has been "attacked", as soon as theattack ap-
pears. To becalled self-stabilizing,a systemmust havethe capabilityto recover normal operation
when exposedto suchattacks. Ifthesystem(orpartsofit)is destroyedcompletely,so thatitisno
longerpossibleforthesystemto operate, thenno self-stab ilizingsystemcan work. Theadversary
succeedsinachievinghisgoals. However,ifenoughcompone ntsareleftforthesystemtooperate,
then a self-stabilizing system will slowly resume normal op eration after the attack. It is up to the
designer to decide under what conditions the system may be te rmed "completely destroyed" or
"stillcapableofoperating".
Layering andModularization
The mostcommonlyused techniques for buildingself-stabil izingsystemsare layering and modu-
larization. The basic idea is to divide the system into small er component, make each component
self-stabilizingindependently,and thenintegratethemt o composethesystem.
Self-stabilizationisamenabletolayeringbecausethesel f-stabilizationrelationistransitive,i.e.
ifP→Q (P StabilizesQ) and Q →R, then P→R. Thus,different layers ofself-stabilizingprograms
(each byitselfselfstabilizing)can becomposed. First ste pis tobuildaself-stabilizing"platform"
635
and any program written on that platform automatically beco mes self-stabilizing. The basic idea
behind a self-stabilizing platform is to provide primitive s using which, other programs can be
written.
To develop self-stabilizing systems using the technique of layering, we require primitives to
provide structures on which algorithms may be built. There a re two basic structuring mechanism
primitives: commonclock primitives,and topologybased pr imitives.
(1)CommonClockPrimitives
Unison is the process of maintaining time through the use of l ocal clocks in shared memory sys-
tems. The properties required here are the safety property a nd the progress property. For a syn-
chronousshared memorysystem,safetyand progress propert iesforunisonareas follows:
•Safety: Allclocks havethesamevalue.
•Progress: Ateach step,each clock isincremented bythesame amount.
For asynchronous systems with shared memory, safety and pro gress properties for unison are
as follows:
•Safety: Clocks oftwoneighboringnodes can differbyat most 1.
•Progress: A clock is incremented to i +1 when clocks at all nei ghboring nodes have value i
ori+l.
(2)TopologyBasedPrimitives
Leader election is perhaps the mostbasic primitivewith res pect to an arbitrary dynamictopology.
Oncealeaderhasbeenfound,aspanningtreemightbeconstru cted. Algorithmsformutualexclu-
sion and reset can be easily developed on the top of self-stab ilizing spanning tree algorithms for
arbitrarilyconnected graphs.
We now discuss two examples of self-stabilizing programs, n amely, mutual exclusion and re-
set,developedusingtheconcept oflayering.
Example1: A two-layered self-stabilizingalgorithmformutualexclu sion[42].
The ﬁrst layer creates a spanning tree from an arbitrarily co nnected graph, whose topology
might change dynamically with the exception of a distinguis hed process (the root). The self-
stabilizing spanning tree protocol is based on breadth ﬁrst search of the graph, rooted at the dis-
tinguishednode. The distinguishednodeisneeded tobreak s ymmetryand allothernodes execute
identicalprogram.
The second layer achieves mutual exclusionon a dynamictree structured system. It is a token
based system. When a node receives the token/privilege,it e xecutes its critical section (if it wants
636
to)andthenitpassestothetokentoitschildreninleft-to- rightorder. Thus,thetokentraversesthe
treein depthﬁrst manner.
Finally,thetwoprotocolsaresuperposedtoobtainasingle self-stabilizingprotocolformutual
exclusionan arbitrarily connectedgraph.
Example2: Self-stabilizingreset algorithmforasynchronousshared memorysystem[13].
AroraandGouda[13]usedlayeringtechniquetodevelop asel f-stabilizingresetalgorithmfor
asynchronous shared-memory systems. The algorithms allow s dynamic topology as long as the
underlying graph remains connected. There is no distinguis hed process, hoever, each process has
auniqueidentiﬁer.
The algorithm consists of three layers. In the ﬁrst layer, a r oot is elected forming a spanning
tree. In the second layer, the root initiates a diffusing com putation in which reset requests are
propagated to the leaf nodes and are refelected back to the ro ot node. The reset request passes
through every node, detecting any anomaly in the global stat e. When the reset returns to the root,
thereset iscomplete.
A self-stabilizing "platform" resets the system upon encou ntering an illegitimate state. Plat-
formwritesto variablesoforiginalprogramonlyifan illeg itimatestateisdetected. Platformdoes
notaffect theoriginalprogramundernormalexecution.
17.6 CommunicationProtocols
A communication protocol is a collection of processes that e xchange messages over communica-
tionlinksinanetwork. A protocolmay beadverselyaffected forseveralreasons:
(1) Initializationtoan illegalstate.
(2) A change in the mode of operation. Not all processes get th e request for the change at the
sametime,so an illegalglobalstatemay occur.
(3) Transmissionerrors because ofmessagelossorcorrupti on.
(4) Process failureand recovery.
(5) A localmemorycrash which changes thelocal stateofapro cess.
Previously, these ﬁve types of errors have been treated sepa rately. However, if a protocol is
self-stabilizing, they will all be corrected in a ﬁnite numb er of steps, regardless of the reason for
thelossofcoordination.
A communication protocol is stabilizing if and only if start ing from any unsafe state (i.e., one
thatviolatestheintendedinvariantoftheprotocol),thep rotocolisguaranteedtoconvergetoasafe
state within a ﬁnite numberof state transitions. Stabiliza tion allows the processes in a protocol to
reestablishcoordinationbetweenoneanotherwhenevercoo rdinationislostdueto somefailure.
637
GoudaandMultari[57]showedthatacommunicationprotocol mustsatisfythefollowingthree
propertiesto beself-stabilizing:
1. It mustbenon-terminating.
2. Thereare an inﬁnitenumberofsafestates.
3. Thereare timeoutactionsin anon-emptysubsetofprocess es.
Self-stabilizing systems can automatically recover from a rbitrary state perturbations in ﬁnite
time. They are therefore well-suited for dynamic, failure p rone environments. Spanning-tree con-
struction in distributed systems is a fundamental operatio n that forms the basis for many other
network algorithms (like token circulation or routing). Ne xt, we discuss some self-stabilizing al-
gorithmsthat constructaspanningtree withinanetwork ofp rocessingentities.
Let us consider an arbitrary distributed algorithm, e.g., f or termination detection, and start it
in a state where one of its variables has been set to a random va lue from its domain. Usually, the
behaviorisnotpredictable: eitherthealgorithmwilloutp utgarbage(e.g.,declareacomputationas
ﬁnished although it is still running), or (most probably) it will deadlock (e.g., it will fail to output
anythingat all). It may be argued that changingthe valueofa variableis unfair: no algorithmcan
tolerate such manipulations since algorithms have to rely o n proper initialization. This argument,
however,is nottrue.
Self-stabilizing algorithms are guaranteed to recover fro m an arbitrary perturbation of their
local state in a ﬁnite number of execution steps. This means t hat the variables of such algorithms
donotneedtobeinitializedproperly. Ifweassigneachvari ableanarbitraryvaluefromitsdomain,
stillthealgorithmwilleventuallystarttobehaveasexpec ted. Arbitrarystateperturbationscanalso
happen without curious users playing around with their algo rithm: Cosmic rays in spacecraft for
example can arbitrarily change the contents of memory cells in random access memory. Self-
stabilizingalgorithmshavethedesirablepropertyto reco verfrom suchfaults automatically.
17.7 Self-StabilizingDistributedSpanningTrees
In distributed systems, a spanning tree is the basis for many complex distributed protocols. To
deﬁneaspanningtree,thenetworkismodeledasagraphG=(V, E)whereVisthesetofnetwork
nodes(vertices)andEisthesetofcommunicationlinks(edg es)betweennetworknodes(formally
it is a subset of E×E). A spanning tree T = (V, E′) of G is a graph consisting of the same set of
nodesV, butonlyasubsetE′ofedges E suchthatthereexistsexactlyonepathbetween eve rypair
ofnetworknodes. Basically,thismeans thatthegraph iscon nected and itdoesnot containcycles.
Abasictheoremsofspanningtreesstatesthatinanetworkof nnodes,thetreecontainsexactlyn-1
communicationlinks. A spanning tree ofa graph is in general not unique(even if theroot node is
ﬁxed).
Figure 17.3 shows an example of a network of ﬁve nodes and a spa nning tree of the network
[45].
638
P1 P2 P3
P5 P4P1 P2 P3
P5 P4
Figure17.3: A network anditsspanningtree
A spanning tree in a network is often a prerequisite for more i nvolved network protocols like
routing or token circulation. It generally increases the ef ﬁciency of network protocols. For exam-
ple, consider the problem of broadcasting messages in the ne twork. There are algorithms which
ﬂood the network, i.e., the broadcast message is recursivel y sent to all neighbors. Consequently,
the message crosses all communication links before the prot ocol terminates. However, if a span-
ning tree of the network is available, the message only needs to be sent along all the edges of the
spanning tree. Instead of crossing all E links, the message j ust crosses n-1 links. Since |E| is usu-
allysigniﬁcantlylarger thann-1, a spanningtree can consi derablyreduce themessagecomplexity
ofthebroadcastalgorithm.
Twokindsofspanningtrees maybedistinguished: breadth-ﬁ rstsearch (BFS) treesresultfrom
a breadth-ﬁrst traversal of the underlying network topolog y. Similarly, depth-ﬁrst search (DFS)
trees are obtained from a depth-ﬁrst traversal. A notion und erlying DFS and BFS trees is that of
a rooted tree. A rooted spanning tree is a spanning tree of the network where the tree edges are
consistentlydirectedwithrespecttoaparticularnode(th eroot). Edgescanbedirectedtowardsthe
rootor“awayfrom”theroot. Rootedspanningtrees haveanot ionof“parent”and naturallyresult
from the execution of semi-uniform algorithms. In fact, sin ce almost all algorithms use a single
pointer(to aneighbor, theparent) to storethestructureso f thetree, all thesealgorithmsimplicitly
constructarooted spanningtree.
In spanning-tree construction, it is impossibleto determi nisticallyconstruct a spanning tree in
uniform networks. Intuitively, this is caused by problems o f symmetry, and so at least a semi-
uniformsetting(e.g.,adistinguishedrootprocessor)ora sourceofrandomizationis needed.
Time-complexity of self-stabilizing algorithms is often m easured by the number of rounds.
In self-stabilizing spanning-tree construction, an arbit rary initial state may make it necessary to
propagateinformationthroughtheentirenetwork. Therefo re, a general lowerboundof(d)rounds
can be assumed for self-stabilizing spanning-tree algorit hms. By combining the algorithm with a
hierarchical structureandsacriﬁcing truedistribution, thisboundcan belowered.
Space complexitymeasures thetheamountofstatenecessary to performself-stabilizingspan-
ning tree construction. Dolev, Gouda, and Schneider [40] de rived the following result on lower
bounds regarding the space complexity: self-stabilizing s panning tree construction needs at least
(logn)bitsperprocessorifthealgorithmissilent(i.e.,i fthecontentsofthecommunicationregis-
terseventuallystopchanging). Ifthealgorithmisnotrequ iredtobesilent,Johnen[68]showedthat
639
it is possible to construct an algorithm using only O(1) bits per edge in a uniform rooted network
withacentral daemon.
17.8 Self-Stabilizing Algorithms for Spanning-tree Const ruc-
tion
Inthissection,wediscussasetofrepresentativeself-sta bilizingalgorithmsforconstructingspanning-
trees [45].
17.8.1 Dolev, Israeli,and MoranAlgorithm
Dolev, Israeli and Moran [42] developed a self-stabilizing BFS spanning-tree construction algo-
rithmforsemi-uniformsystemswithacentraldaemonunderr ead/writeatomicity. Inthealgorithm,
every node maintains two variables: (1) a pointer to one if it s incoming edges (this information
is kept in a bit associated with each communication register ), and (2) an integer measuring the
distancein hopstotherootofthetree. Thedistinguishedno deinthenetworkacts as theroot.
Thealgorithmworksasfollows: Thenetworknodesperiodica llyexchangetheirdistancevalue
(current distance from the root node) with each other. After reading the distance values of all
neighbors, a network node chooses the neighbor with minimum distancedistas its new parent. It
thenwritesitsowndistanceintoitsoutputregisters,whic hisdist+1. Thedistinguishedrootnode
does notread thedistancevaluesofitsneighborsand always sendsa valueof0.
The algorithm stabilizes starting from the root process. Af ter sufﬁcient activationsof the root,
it has written 0 values into all of its output variables. Thes e values will not change anymore.
Notethatwithoutadistinguishedrootprocessthedistance valuesinallnodeswouldgrowwithout
bound. More speciﬁcally, after reading all neighbors value s for k times, the distance value of a
process is at least k + 1. This means, that after the root has wr itten its output registers, the direct
neighbors of the root- after inspecting their input variabl es - will see that the root node has the
minimum distance of all other nodes (the other nodes have dis tance at least 1). Hence, all direct
neighbors of the root will select the root as their parent and update their distance correctly to 1.
Thislineofreasoningcanbecontinuedincrementallyforal lotherdistancesfromtheroot. Thatis,
afterallnodesatdistancedfromtheroothavecomputedthei rdistancefromtherootcorrectlyand
writtenitintheirregisters,theirregistersnolongercha ngeandnodesatdistanced+1fromrootare
ready to compute their distance from the root. After O( δ) update cycles, the entire tree will have
stabilized.
Dolev et al.’s self-stabilizing algorithm for constructin g spanning trees is shown in Algorithm
2. Two neighbors P iand P jcommunicate with each other by reading from and writing to tw o
shared registers, rijandrji. To communicate, P iwrites torijand reads from rjiand P jwrites to
rjiand reads from rij.
The root node repeatedly writes values <0,0> in the register s of all of its neighbors. All other
processors repeatedly perform the following steps: in each iteration, the processor reads the reg-
640
isters of all of its neighbors and computes the a value for var iabledistas follows: it chooses the
minimum distance of their neighbors, sets it distvariable to the minimum distance plus 1, and
updates the registers of its neighbors. The internal vriabl e corresponding to register rijis denoted
bylrij. It storesthelastvalueof rjithatisread byP i.
A snapshot of the system state in Dolev et al.’s self-stabili zing algorithm is given in Figure
17.4.
Variables:
no_neighbors=Numberofprocessor’sneighbors
i=thewritingprocessor
m=forwhomthedataiswritten
lrji(local register rji)thelastvalueofr jiread byPi
RootNode:
{doforever}
whileTRUEdo
form := 1to no_neighbors do
writelrim:=<0, 0>
endend
OtherNodes:
{doforever}
whileTRUEdo
form := 1to no_neighbors do
lrmi:=read(lrmi)
FirstFound :=false
dist:=1+min(lr mi.dist)∀m: 1≤m≤no_neighbors
form :=1 tono_neighbors do
ifnotFirstFound andlrmi.dis=dist-1
writerim:=<1,dist>
FirstFound :=true
elsewrite rim:=<0,dist>
endendend
Algorithm2 : Dolevetal.’s Spanning-treeConstructionAlgorithmfor Pi
Dolev et al.’s self-stabilizing algorithm has been used as t he basis for a topology update al-
gorithm in dynamic networks. Based on the similar idea, Coll in and Dolev [32] present a semi-
uniform spanning-tree algorithm under a central daemon and read/write atomicity that constructs
a DFS tree (instead of a BFS tree). A similar algorithm which a lso constructs a DFS tree but
usescompositeatomicitywasdevelopedbyHerman. Inthisal gorithm,theoutgoinglinksatevery
process are ordered, and the DFS tree is deﬁned as the tree res ulting from a DFS graph traversal
always selecting the smallest outgoing edge. Instead of wri ting its current level into the output
641
The distributed system − computation step
P1 P212rm1: 
P1 P212rm1: 
P2reads
m1 m1P1writes
P1 P212r : x
1
2
7
6
34
85r21
parent = 1
dist = 1:
r73
parent = 2
dist = 3:r58
parent = 8
dist = 3:Spanning−tree, system and code
Figure17.4: AnexampleofDolevet al.’salgorithm
registers,itwritesarepresentationofitscurrentestima teofthepath(thesequenceofoutgoinglink
identiﬁers)totheroot. Theroot repeatedly writesthe“emp typath”(⊥) to itsoutputregisters. If a
node has k neighbors, there are k alternative paths to choose from. From these, the node chooses
thepathwhichisminimalaccordingtoalexicographicorder whichpreferssmallerlinkidentiﬁers.
For example, (⊥) < (⊥, 1) < (⊥, 1, 1) < (⊥, 2) < (1). Thus, a node does not choose the shortest
pathto therootbutapath alongthesmallestlinkidentiﬁers .
The memory requirement for the DFS algorithm is O(n logK) bit s where K is an upper bound
on themaximumdegreeofanode. Thetimecomplexityis O( δnK)rounds.
17.8.2 Afek, Kutten, andYung Algorithm for Spanning-tree C onstruction
The algorithm by Afek, Kutten and Yung [3] constructs a BFS sp anning-tree in the read/write
atomicity model. However, this algorithm does not make the a ssumption of a distinguished root
process. Instead, it assumes that all nodes have globally un ique identiﬁers which can be totally
ordered. Thenodewiththelargest identiﬁerwilleventuall ybecometherootofthetree.
The idea of the algorithm is as follows: Every node maintains a parent pointer and a distance
variable like in the Dolev, Israeli, and Moran algorithm. In addition, it stores the identiﬁer of the
root of the tree in which it thinks it is present. Periodicall y, nodes exchange this information. If
642
a node notices that it has the maximum identiﬁer in its neighb orhood, it makes itself the root of
its own tree. If a node learns that there is a tree with a larger root identiﬁer nearby, it joins this
tree by sending a“join request” to theroot of that tree and re ceiving a “grant”back from the root.
Local consistency checks ensure that cycles and fake root id entiﬁers are eventually detected and
removed.
The algorithm stabilizes in O(n2) asynchronous rounds and needs O(log n) space per edge to
storetheprocessidentiﬁer. Afeketal. arguedthisisoptim alsincemessagecommunicationbuffers
need tocommunicate“at least”theidentiﬁer.
17.8.3 Arora and Gouda Algorithm for Spanning-tree Constru ction
Aroraand Gouda[13]developedaself-stabilizingBFS spann ing-treealgorithmforthecomposite
atomicitymodelundertheassumptionofacentraldaemon. Li keAfek,KuttenandYung,theyalso
assume unique identiﬁers and the node with maximum identiﬁe r eventually becomes the root of
the system. However, the algorithm needs a bound N on the numb er n of nodes in the network
to work correctly. The bound on the number of nodes is necessa ry because the algorithm uses a
differenttechniquetodetect and removecycles.
Everynodemaintainsvariablesfordistance,parentandroo tidentiﬁer. Periodically,everynode
compares its own distance and root identiﬁer values with the values stores in the node pointed to
by the parent variable. In the ﬁnal spanning tree, the root id entiﬁers should be identical and the
distance should be the distance of the parent plus one. If thi s is not the case, the root identiﬁer
is copied from the parent and the distance is set to the parent ’s distance plus one. A node also
continuously monitors the root identiﬁer and distance sett ings of its neighbors. If a neighbor has
a larger root identiﬁer or the same identiﬁer with smaller di stance, the node adjusts its values
accordingly.
Cycles are detected in the following manner: If there is a cyc le in the tree (or the graph to be
precise), say, due to improper initialization, the distanc e values are incremented along this cycle
withoutbound. Hence,acycleisdetectedwhenthedistancev alueexceedestheboundN.Theﬁrst
nodetodetect thismakesitselftherootofanew tree.
A bound on the number of nodes in the network, N, allows the Aro ra and Gouda algorithm to
be simpler than the one by Afek, Kutten and Yung. However, the stabilization time in Arora and
Gouda algorithm is O(N2), which can be much larger than that of Afek, Kutten and Yung, O(n2).
In dynamic networks where network nodes may go down, a stabil ization time in the order of the
actual numberofnodesis preferable.
17.8.4 Huang et al. Algorithmsfor Spanning-tree Construct ion
Chen, Yu and Huang [30] developed a self-stabilizing spanni ng tree algorithm for semi-uniform
systemswithcompositeatomicity. It is based on thesameide aofcyclebreaking (bumpingup the
distancecounter). Thefactthatthereisadistinguishedro otmakesthealgorithmevensimplerthan
the one by Arora and Gouda [13]. However, the algorithm does n ot necessarily stabilizeto a BFS
643
tree since the choice of a new parent after a cycle is broken is non-deterministic and is governed
by thescheduler.
This algorithm was later improved by Huang and Chen [65] to yi eld an algorithm which con-
structsaBFS tree usingknowledgeofthesizen ofthenetwork .
17.8.5 Afek and BremlerAlgorithm for Spanning-tree Constr uction
Afek andBremler[6]gaveaself-stabilizingalgorithmforc onstructingspanningtrees forsystems
with unidirectional, bounded capacity communication link s. They assumed node have unique
identiﬁers and adopted the algorithm for the synchronous an d the asynchronous networks. The
networknodewiththesmallestidentiﬁereventuallybecome stherootofthespanningtree.
Thealgorithmisbasedonanewideacalled“powersupply”. Th epowersupplymethodexploits
thefact that self-stabilizingalgorithmsmustcontinuous lycheck theirown state. Nodes which are
part of a spanning tree expect to receive “power” from the roo t of the tree. Power, like electric
current, means a continuous ﬂow of certain messages, one per round. The basic idea is that only
legal roots may be the source of power and nodes attached to fa ke roots eventually fail to receive
powerand subsequentlymakethemselvestherootofanew tree .
Whenever a node receives power from a neighbor with a smaller identiﬁer, it attaches itself
to its tree. In the asynchronous case, the power supply idea i s implemented using different types
of messages: weak messages are exchanged periodically betw een the nodes to synchronize their
states,whilestrongmessages carry power.
The idea of called power supply imparts the algorithm severa l interesting features. For exam-
ple, the algorithm stabilizes in O(n) rounds without proces ses to have the knowledge of n. Afek
and Bremler gavea generic powersupply algorithm which can b e instantiated to a leader election
algorithm,oran algorithmto constructDFS orBFS spanningt rees.
The spanning-tree algorithms discussed in this section hav e been applied in many different
settings in practice. For example, a variant of the algorith m by Dolev, Israeli and Moran [42] was
used to implement a reliable data storage subsystem for the s elf-stabilizing ﬁle system developed
at theBen GurionUniversity[70].
As another example [45], consider the protocol to eliminate redundant paths in switched Eth-
ernets [31]. If a network segment becomes unreachable or net work parameters are changed, the
protocol automatically reconﬁgures the spanning-tree top ology by activating a standby path. The
protocolcanbebrieﬂydescribedasfollows: Initially,swi tchesbelievetheyaretherootofthespan-
ning tree but they do not forward any packets. Based by a timer , they regularly exchange status
information. The status information contains (1) the ident iﬁer of the transmitting switch (usually
aMACaddress),(2)theidentiﬁeroftheswitchwhichisbelie vedtobetherootofthetree,and(3)
the “cost” of the path towards the root. A switch uses this inf ormation to choose the shortest path
towards theroot. If there are multiplepossibleroots, it se lects the root with the smallestidentiﬁer
(lowest MAC address). Links that are not included in the span ning tree are placed in blocking
modeand theydo notforward packets, butstilltransportsta tusinformation.
644
17.9 An anonymous self-stabilizing algorithm for 1-maxima l
independentsetintrees
In a distributed system, an independent set is deﬁned as a lar ge subset of nodes that are pair-
wise nonadjacent. Maximal independent set is a set of nodes such that every node not in the set
is adjacent to a node in the set. Maximal independent sets are important in several distributed
network applications and several parallel or distributed a lgorithms have been developed for this
task[75].
This algorithm for ﬁnding a 1-maximal independent set in a tr ee uses constant space at each
node. Also this algorithm is somewhat unusual in that it stab ilizes on all graphs, but is only
guaranteed tobecorrect onsomegraphs.
A distributedsystem is modeled as a connected, undirected g raphGwith nodeset Vand edge
setE. Two nodes joined by an edge are said to be neighbors and N(i) is used to denote the set
of neighbors of node i. A self-stabilizing algorithm is presented as a set of rules , each with a
Boolean predicate and an action. A node is said to be privileged if the predicate is true. If a node
becomes privileged, it may execute the corresponding actio n called a move. The assumption is
that there exists a central daemon , which at each time-step selects one of the privileged nodes to
move (and thus two nodes never move at the same time). When no f urther move is possible, the
system is said to be in a stable conﬁguration . While the deﬁnition of self-stabilizing is normally
moregeneral,sincethisisagraphalgorithmwesaythatanal gorithmisself-stabilizingiffromany
initial conﬁguration it always terminates in a legitimate s table conﬁguration after a ﬁnite number
ofmovesnomattertheselectionsofthedaemon.
Description ofalgorithm
In the algorithm citeShi04 for 1-maximal independent set, e ach node is in one of a ﬁnite number
of distinct states. Those nodes in the state called 0 will end up being in the desired set: let us
call this set M. A node with no neighbor in state 0 will change to state 0 and a n ode in state 0
with a neighbor in state 0 will change to something else. This idea readily produces a maximal
independentset.
To achieve 1-maximality, however, a node must be able to leav e setMwhen that would allow
two of its neighbors to enter M. Available neighbors are those which have no other neighbor in
state0: thesewillbeinthestatecalled1. Inordertoallowt hisinterchange ,weimplementahand-
shaking process: the node offers to leave Mby changing to state 0′, the relevant neighbors agree
to enterMby changing to state 1′, the node leaves by changing to state 2′, and then the relevant
neighborsgoin bychangingto state0.
Speciﬁcally, the set of states is 0 ,0′,1,1′,2,2′. The states with a prime are transition states,
used in thehand-shaking process described above. Thesetra nsitionstates willbe absent when the
algorithmterminatesifthenetworksatisﬁes certain prope rties.
For the purpose of the algorithm, the nodes with state 0′are also considered to be in M. The
states 0, 1 and 2 are used to indicate that a node has zero, one, or at least two neighbors in M,
645
respectively.
Actionsofanodeinthealgorithmcan besummarizedas follow s:
•If not involvedin a transitionprocess, then set stateto the numberof neighborsin state 0 or
state0′. (Thevalue2 is usedto indicatetwoormoresuchneighbors.)
•Ifin state0 and adjacentto at leasttwo 1s,changestateto 0′.
•Ifin state1 and adjacentto a0′, changestateto 1′.
•Ifin state0′and adjacent toat leasttwo 1′s,change stateto2′.
•Ifin state1′and adjacent tono 0′, changestateto 0.
•Ifin state2′and adjacent tono 1′, changestateto 2.
The complexity of the actual algorithm arises from invalid i nitial states and from two inter-
changes affectingoneanother.
For a state y, we use the notation S(y)to represent theset of nodes in state y. Furthermore, we
usethenotation S (y1/y2/y3/···)todenote S(y1)∪S (y2)∪S (y3)···.
For example, the notation S (0)denotes the nodes in state 0. The state of a node is stored in
a local variable denoted by x. The states with a prime are transition states. We will also i dentify
the primewith a virtual ﬂag—we willsay theﬂag is set when the node is in a transition state, and
clearing theﬂag willmeanchanging fromstate i′tostatei.
To deﬁne therules of thealgorithm,wedeﬁne thefollowingfu nctionf. Letibea nodeand ta
state. Then wedeﬁne fi(t)=min{2,|N(i)∩S(t)|}.
Thefunction figivesthenumberofneighborsofnode iinaspeciﬁedstate. Wefurtherusethe
notation: fi(x/y/z/···)=min{2,fi(x)+fi(y)+fi(z)+···}Whenthenode iisclearfromthecontext,
wewilldrop thesubscriptfrom fi. Wealso utilizetheconceptof bad edge, whichis deﬁned next.
The rules will be such that a bad edge can only occur as a result of faulty initialization. A bad
edgeisanedgeconnectingtwonodesinthefollowinglistofp airsofstates: 0–0,0–0′,0′–0′,0′–2′,
1′–1′, and 2′–2′.
Thecompletealgorithmforﬁndinga1-maximalindependents etisgiveninAlgorithm3.
The algorithm converges in O(mn) time, where m is the number o f edges and n is the number
ofnodesinthenetwork. Thealgorithmstabilizestoa1-maxi malindependentsetinO(n2)stepsin
an arbitrary tree.
Having seen two regular self-stabilizing algorithms, let u s now discuss a probabilistic self-
stabilizingalgorithm.
17.10 AProbabilisticSelf-StabilizingLeaderElectionAl gorithm
We now discuss a probabilisticself-stabilizingleader ele ction algorithmby Dolevet al. [37]. The
distributedsystemconsist ofn stations(sites)and they ne ed to choosea leader among themselves
646
{*All movesaretried inthelistedorder*}
V1:ifﬂag isset andnodeisincidenton badedge
andafterclearing ﬂag nodewouldnotbeincidenton anybad edge
thenclear ﬂag
V2:ifﬂag isclear andx′=f (0/0′)and(f (0/0′)≥1orf (1′/2′)=0)
thensetx=f (0/0′)
C1:ifx=0andf (1)=2andf (0/0′/2′)=0
thensetx=0′
C2:ifx=0′and(f (1/1′)≤1orf (0/0′)≥1)
thensetx=f (0/0′)
C3:ifx=0′andf(1′)=2andf(0′/2′)= 0
thensetx=2′
C4:ifx=2′andf(1′)= 0
thensetx=f (0/0′)
C5:ifx=1andf(0′)=1andf (0/1′/2′)=0
thensetx=1′
C6:ifx= 1′and(f (0′)∝\⌉}atio\slash=1orf(0/1′/2′)≥1)
thensetx=f (0/0′)
Algorithm3 : Analgorithmforﬁndinga1-maximalindependentset
by using a leader election algorithm. The following three po ssibilities arise: During a time unit,
stationscan detecteithersilence, successorcollision.
Silence in the system implies that no station tried to transm it a message. Success implies that
onlyonestationusedthechanneltotransmitamessage,andﬁ nally,acollisionimpliesthatatleast
twostationsattemptedtotransmitmessages.
Leader electionalgorithmis shownin Algorithm4.
{TerminationCondition. }
Ifn =1 thenStop.
{RandomizedSelection Process }
Ifn≥2 then randomlydividen into(n 1, n- n 1).
Ifn1∝\⌉}atio\slash=0 thenApply d(n1).
ElseApplyd(n).
Algorithm 4 : Dolevet al.’sLeader ElectionAlgorithm d(n)
If the number of stations is greater than or equal to two, then in the ﬁrst time unit, all the
stations send their messages via the channel and as a result, a collision occurs. First time unit is
nothingbut theﬁrst instanceofa timeunit.
If weconsiderastationSintoconsideration,inthenexttim eunit,therearetwo possibilities:
•Case-1) Striesto sendthemessageagain or
647
•Case-2) Sdoesnot tryto sendthemessageagain.
There are two possibilities for the ﬁrst case (S tries to send the message again ): success or
collision. Ifresultisasuccess,thenSistheleader,else( acollisionoccurs)Sﬂipsacoin(send/not
send.
For the second case (S does not participate), there are three possibilities: Silence, Success,
or Collision. If Silence occurs, then the station S ﬂips the c oin (send/not send) again, if Success
occurs, thenstationSdetects theleader, andifacollision occurs, S iseliminated.
Thus,thealgorithmcan bewrittenas:
n Stations,n≥2
—Firsttimeunit : Allstationssend theirmessages viathechannel;Collisio n.
→Each stationﬂips acoin(send ornotsend)again.
—Nexttimeunit:
Case1−StationS triesagain
Success: S istheleader
Collision: S ﬂipsacoin again
Case2−StationS isn’tparticipating
Silence: Sﬂips againthecoin
Success: S detectstheleader
Collision: S iseliminated
An Example
WenowillustratethealgorithmusingtheexampleshowninFi gure17.5.
Collision
Collision
SucessΦ
B AABABCD
AB CD
Silence
Figure17.5: An example.
648
In Figure 17.5 initially (in the ﬁrst time unit), ABCD try to s end messages and a collision
occurs. In the next time unit, A and B send message again, whil e C and D do not participate.
Since both A and B try to send their messages, there is a collis ion again. As a result, C and D
are eliminated. Now in the next time unit, both A and B do not pa rticipate and the result is a
Silence. So both of them ﬂip a coin and B decides to send a messa ge again and A decides not to
participate. Since B is the only one sending a message, the re sult is Success and B is the Leader
and thealgorithmterminates.
17.11 Therole ofcompilersin self-stabilization
A compiler converts a program written in a language into an eq uivalent program in another lan-
guage. Typically, the latter is an object program that is to b e run on a particular architecture.
Formally,acompilerisa homomorphismf: A →B whereA andB aretwoclasses ofarchitecture
or systems. Then, for each m dA, f (M) mimics the actions of M in some well-deﬁned fashion
[81].
Whenasourceprogramisself-stabilizing,weexpectthecom pilertoproduceanobjectprogram
that is self-stabilizing on the target architecture. It wou ld be highly desirable to have a "self-
stabilizing compiler" that will convert a non-self-stabil izing source program into self-stabilizing
objectcode.
It is very important for the compiler to preserve the propert ies of the source program that are
importantto thedesigners.
•In a sequential paradigm under termination it’s important t hat both the programs compute
thesameresults(quantitative).
•In a distributed or parallel paradigm, preservation of qual itative properties due to the need
forcontroland coordinationamongtheprocesses isimporta nt.
Dijkstra[36],inhisseminalwork,impliedthattheredoesn ’texistacompilerfromasymmetric
ringstosymmetricringsthatforcesorpreservesself-stab ilization. However,ifself-stabilizationis
notrequired, wecan compilean asymmetricringintoasymmet ricring[81].
Gouda et al. [55] showed that self-stabilization across arc hitectures is in principle unstable.
They also demonstrated that the ability to force or preserve self stabilization is very much de-
pendent on how certain properties, like termination, fairn ess and concurrency, are required to be
preserved whencompilingfrom onesystemto other.
Next we discuss compilers that force self stabilization in s equesntial programs, asynchronous
distributedsystems,and shared memorysystems[81].
17.11.1 Compilers for sequential programs
The main focus of research on self-stabilization has been in the domains of concurrent and dis-
tributed systems, where the goals of algorithms are both qua litative and quantitative. Achieving
649
self stabilization in sequential programs becomes much mor e difﬁcult due to the termination re-
quirement.
Browne et al. [20] and Schneider [79] suggested a rule-based program model. A rule based
programconsistsofaninitializationsectionandaﬁnitese tofrules. A ruleisamultipleassignment
statementwithanenablingcondition,calleda guard,whichisapredicateoverthevariablesofthe
program. Iftheguardofaruleistrueforastate,thentherul eissaidtobe enabled. Acomputation
is a sequence of rule ﬁrings, where at each step an enabled rul e is non-deterministically selected
forexecution. Aprogramissaidtohave terminated whenaﬁxedpoint isreached. A ﬁxedpoint is
a state in which the values of the variables can no longer chan ge. Apartial ﬁxed point is deﬁned
as astatefromwhich thevaluesofasubsetofvariablesdo not change.
For a terminating program to be self stabilizing, the relati on it computes should be veriﬁable
in one step, else it might terminate in an unsafe state. Brown e et al. [20] showed that a class
of programs exists for which there is a compiler that forces s elf-stabilization while preserving
termination. Objectprogramshaveruntimeandsizewithina constantfactorofthesourceprogram.
However, it is assumed that inputs are incorruptible. These programs must satisfy the following
properties[81]:
•Datadependencygraphs oftheseprogramsare acyclic.
•Each ruleintheprogramassignsonlyonevariable.
•For any pair of enabled rules with the same target variable, b oth rules will assign the same
valuetothevariable.
For arbitrary programs, one cannot obtain the same result as for acyclic programs. Consider
the class of programs restricted to Boolean variables. Schn eider [79] showed that if there exists a
compiler that forces self-stabilization onto Boolean prog rams, while preserving termination, then
PSPACE =NP, whichisnotaverylikelyresult. Further, ifwer equirethatthesourceandtargetto
havethesamesetofvariables,then PSPACE =P, which isevenl esslikelyresult.
However, if we waive the requirement that the object program reach a ﬁxed point (i.e., the
conditionoftermination),lifebecomessimpler. Schneide r[78,79]introducedthenotionofpartial
ﬁxed-points(where terminationnotrequired)and showedth atonecan produce, inquadratictime,
an equivalent self-stabilizing program with time complexi ty and size within a constant factor of
theoriginal.
17.11.2 Compilers for asynchronous messagepassing system s
Such a compilershould convert a non self-stabilizingprogr am into a self-stabilizingversion in an
asynchronous message passing system [71]. This is accompli shed through a self-stabilizing plat-
form,whichwhennterleavedwithanonself-stabilizingpro gram,yieldsaself-stabilizingprogram.
Theresultingprogram iscalled an extensionoftheoriginal program.
Thealgorithmconsistsofthreecomponents[ ?]:
650
•Self-stabilizingversionofChandy-Lamport’sglobalsnap shotalgorithm[29].
•Self-stabilizingreset algorithmthatsi superposedonit.
•A non self-stabilizing program on which the former two are su perposed to obtain a self-
stabilizingprogram.
The algorithm works as follows: A distinguished initiator r epeatedly takes global snapshots.
Afterthedistinguishedinitiatorhas obtainedasnapshot, itevaluatesapredicate1. on thecollected
state. Ifan illegitimateglobalstateisdetected, thenthe initiatorinitiatestheexecutionofthereset
algorithm which resets the global state of the source progra m to an initial state. In this methodol-
ogy, the compiler takes the program and the predicate (speci fying the set of safe states) as input
and producesaself-stabilizingversionoftheprogram.
An Extension: Informally, a program Q is an extension of program P if the sub set of Q corre-
sponding to P behaves exactly like P, except that the same sta te may repeat. If P terminates, its
extension Q needs to repeat the ﬁnal state of P forever, chang ing only the variables not present in
P,inordertoachieveself-stabilization. IfQterminates, itcannotbeaself-stabilizingextensionof
Pbecause itcouldterminatein an illegalstate.
The Katz and Perry methodology [71] has the following two dra wbacks: First, it might not
be always possible to ﬁnd a predicate that can distinguish be tween legitimate and illegitimate
states. Legitimatestatescouldbedeﬁnedintermsoftherea chablestates. However,computingthe
reachablesetmightbecomeintractable. Second,aglobalsn apshotalgorithmdoesnotproducethe
current state. It captures a possiblesuccessorto the state it was inititedin. If the originalprogram
stabilizesbyitself,wemightend updoingareset from alegi timatestate.
17.11.3 Compilers for asynchronous sharedmemorysystems
In shared-memory systems, we can write the snapshot and rese t algorithms in a way very similar
tomessagepassingsystems. Aself-stabilizingsynchronou ssharedmemorysystemmightbecom-
piled into an asynchronous self-stabilizing shared memory system as follows [81]: Assume that a
process can read and write in one atomic action and that each s hared variable is written by only
oneprocess (called theownerof thevariable). Thesteps oft hesynchronoussystemare simulated
using self-stabilizing asynchronous unison algorithm. On e step of the synchronous algorithm is
executedeach timetheclockisincremented. Foreach shared variable,twocopiesare maintained:
one to store the current valueand another to storethe previo us value. This allows a process to ac-
cess the previous value of a shared variable even if it has bee n updated by another process. When
thelocalclockofaprocessticksfromitoi+1,itconcurrent lyexecutesonestepofthesynchronous
systemandupdates current and previousvaluesofallvariab lesthat itowns.
1It isassumedthatthereexistsa decidablepredicatethatca ndetectwhethera globalstate islegitimate
651
17.12 Selfstabilizationas aSolutiontoFaultTolerance
Self-Stabilization is the property of a system, component, process or object to correct itself no
matter how severely it’s state variables, including memory , message buffers, and registers, are
corrupted. Self-stabilization is most interesting for dis tributed and concurrent systems because
local detectionofafaultyconditionis difﬁcult.
Self stabilization has risen beyond the theory and has serve d as a guiding principle in many
network protocols (in fact, a number of Internet and LAN prot ocols are self-stabilizing or very
close to it). Recent applied research has succeeded in demon strated self-stabilizing ﬁle systems
and in implementing protocols for routing, reprogramming, and synchronizing nodes in sensor
networks. These examples show that the principles of self-s tabilization can be used to implement
lightweightsolutionstotheproblemsoffault tolerancein real-lifesystems.
Fault Tolerance
Fault tolerance is deﬁned as tolerance to transient failure s, in which the state of a component
changes spontaneously,butthecomponentremainscorrect.
Fault-tolerance or graceful degradation is the property th at enables a system to continue oper-
ating properly in the event ofthe failure of someof its compo nents. The qualityof operation may
decrease in proportion to the severity of the failure, while in a naively-designed system, even a
smallfailurecan causethetotalsystembreakdown.
In a system, fault tolerance is generally achieved by antici pating exceptional conditions and
designing the system to cope with them. The concept of self-s tabilization has emerged as a com-
plementary paradigm to fault tolerance in distributed comp uting. A system is said to be self-
stabilizing, if starting from any state, it automatically r ecovers to a speciﬁed set of legal states in
ﬁnitetime. Thearbitrarystatefromwhichthesystemstarts maybeafaultystateduetoatransient
failure within the system. Such a fault could be the corrupti on of local memory, loss of a mes-
sage,orreceptionofacorruptedmessage. Duringtherecove ryprocess,theusermayexperiencea
partial loss of services and performance, but guarantee is g iven that correct system operation will
eventuallyresume.
Self-stabilizingsystemsmeetastrongernotionofcorrect nessunderfailures. Ifatransienterror
pushes the system into an inconsistent or incorrect state, t hen regardless of the origin and type of
the failure, the system eventually coverges to a correct sta te without any outside assistance. The
fact that the type of fault is not speciﬁed further contains t he striking power of the paradigm: The
ability to mask the effect of faults is traded for the ability to tolerate any kind and any number
of faults. Thus, self-stabilizing systems offer a degree of fault tolerance that goes beyond the
shortcomingsoftraditionalapproaches fordesigningfaul t-tolerantsystems.
Robustness is one of the most important requirements of mode rn distributed systems and a
practical distributed system should be able to recover from transient faults of the processors and
communication links. Ideally, the recovery process should automatically start as soon as a fault
is detected and must not rely on the assumption that it is poss ible to start the system from a well
652
deﬁnedstate. Itisnotreasonabletoassumethatthecodeexe cutedbyeveryprocessorisnotaltered
bytransientfaults. Thiscodemaybestoredinaread-onlyme moryormaybereloadedfromanon-
volatile memory after a transient fault. A distributed self -stabilizing system is a system that can
startfrom anypossibleinitialstateand reach alegitimate stateinﬁnitetime.
Self-stabilizationisadifferentwayoflookingatdistrib utedsystemfaulttolerance;itprovidesa
“built-in-safeguard"against“transientfailures"thatm ightcorruptthedatainadistributedsystem;
self-stabilization enables systems to recover from failur es automatically without any intervention
by any external agency. Stabilizing algorithms are optimis tic in the sense that the distributed
systemmaytemporarilybehaveinconsistentlybutareturnt ocorrectsystembehaviorisguaranteed
inﬁnitetimewhiletraditionalrobustdistributedalgorit hmsfollowapessimisticapproachinthatit
protects against the worst possiblescenario which demands an assumption of the upper bound on
thenumberoffaults.
Self-stabilization provides a uniﬁed approach to transien t failures by formally incorporating
them into the design model. The following transient faults c an be handled by a self-stabilizing
system[81]:
1.Inconsistent initialization : Different processes in the program may be initialized to lo cal
statesthatare inconsistentwithoneanother.
2.Mode of change : There can be different modes of execution of a system. In cha nging the
mode of operation, it is impossible for all of the processes t o effect the change at the same
time. The program is bound to reach a global state in which som e processes have changed
whileothers havenot.
3.Transmission errors : These errors include loss, corruption, or reordering of me ssages and
can causeinconsistencybetween thestatesofthesenderand receiver.
4.Processfailureandrecovery : Ifaprocessgoesdownand recoverslater, itslocalstatema y
beinconsistentwiththerest ofthesystem/program.
5.Memory crash : A memory crash may cause the loss of local state, making it in consistent
withtherestofthesystem/program.
Traditional approaches to fault tolerance have addressed e ach of these issues separately. Self-
stabilization provides a uniﬁed approach to fault toleranc e by handling all these issues single-
handedly.
Global initializationisnot necessary; each componentcan bestarted separately in an arbitrary
state. Self-stabilization does not rely on particular init ial state as other distributed algorithms do.
Thereisnoneedforproperandconsistentinitialization. A self-stabilizingdistributedsystemeven-
tually reaches a legitimate system state, regardless of its initial state. Because of this property, a
self-stabilizingdistributedsystemisextremelyrobusta gainstfailures;ittoleratesanyﬁnitenumber
oftransientfailures.
653
Self-stabilization can be applied to topology preservatio n/control. After a topological change
the system converges to a new feasible conﬁguration. The sel f-stabilization principle applies to
anysystembuiltonsigniﬁcantnumberofcomponentswhichar eevolvingindependentlyfromone
another, but which are cooperating or competing to achieves ome common goals. This applies, in
particulartolargedistributedsystemswhichtendtoresul tfromtheintegrationofmanysubsystems
and componentsdevelopedseparatelyearlier bydifferent p eople.
The investigation and use of self stabilization as an approa ch to fault-tolerance has been un-
dergoing a renaissance. Dijkstra’s notion of self stabiliz ation, which originally had a very narrow
scope of application, is proving to encompass a formal and un iﬁed approach to fault tolerance
under a model of transient failures for distributed systems . Self-stabilization has most obvious
applicationto thenetwork protocolsarea sincecommunicat ionprotocolsshould beespecially tol-
erant totemporary faults.
17.13 FactorsPreventingSelf-Stabilization
Inthissection,wediscusssomeofthefactorsthatprevents elf-stabilization. Thefactorspreventing
self-stabilizationincludethefollowing:
1. Symmetry
2. Termination
3. Isolationand
4. Look-alikeconﬁguration.
Symmetry
Self-Stabilization requires that all processes should not be identical/symmetric because a self-
stabilization solution generally relies on a distiguished process. Asymmetry must be maintained
in systems where processes may synchronize with one another such as mutual exclusion, dining
philosophers,drinkingphilosophers,andresource alloca tionsystemsunderdeterministicrules.
A system can be asymmetric by state or asymmetric by identity . A system is asymmetric by
state when all processes are identical, however, they start from different initial local states. A
system is asymmetric by identity when not all of the processe s are identical. In general, a system
asymmetriconly by state cannot be self stabilizing,whilea systemasymmetricby identity can be
selfstabilizing.
Termination
Self stabilization is generally incompatible with termina tion. If any unsafe global state is a ﬁnal
state,thenasystemwillnotbeabletostabilize. Thoughsel f-stabilizationisgenerallyincompatible
654
with termination, there is one exceptional case where self- stabilization can be achieved in the
presence of termination. That is, in the case of ﬁnite-state sequential programs since the number
ofstatesis ﬁnite,acompilercan removeall theunsafestate s [81].
While the property of termination is very natural when deali ng with algorithms whose goal
is to compute a function (i.e., quantitative), it is unnatur al in the domain of distributed systems,
wherecomputationsarenon-terminatingbydesignandhaveq ualitativegoalssuchascoordination
and control.
Oneform ofterminationthat occurswithindistributedsyst emsisdeadlock whereoneormore
processes wait for an event that will never occur [71]. In a di stributed message passing system,
processes will be waiting for messages to come from other pro cesses. A process sends a message
and then waits for a response. By way of a malicious adversary , control of a local process could
beplacedatapointjustafterasendinstructionwithoutame ssageactuallyhavingbeensent. Thus
at anylocal processstatethatfollowsthesendingofamessa ge,itis impossiblefor thatprocessto
knowwhetheramessagehas infact been sent.
This situation can lead to deadlock where one or more process es wait for messages that will
never come. The problem of deadlock is not seen in a shared mem ory system. Because a process
can test the value of shared memory when required, there is no waiting for messages and thus no
deadlock.
Isolation
Isolationoccurswithinasystemwhenthelocalstateandcom putationofeachprocessisconsistent
with some safe global state and computation, however, the re sulting global state and computation
is not safe. In such a situation,the system is unable to stabi lizedue to inadequate communication
and coordinationbetween itsprocesses [55,81].
Look-alike conﬁgurations
Look-alike conﬁgurations result when the same computation (sequence of actions) is enabled in
two different states with no way to differentiate between th em [55, 81]. If one of the two states is
unsafe, thenthesystemcannotguaranteeconvergencefrom t heunsafestate.
17.14 LimitationsofSelf-Stabilization
Theprobleminself-stabilizingsystemsisthetimeittakes forasystemtocorrectitselfwhenstarted
in an illegalstateor there is an error causing it to go in an il legalstate. If a system cannot tolerate
this initial unknown period, then self-stabilization does not help. Even if the initial unknown can
betoleratedforabriefperiodoftime,thesystemmaynotcon vergetoalegalstatequicklyenough.
655
Need foranexceptional machine
Almost all self-stabilization algorithms rely on the fact t hat is at least one exceptional machine in
thesystem. Thismaybedifﬁculttoachieveinsomesystems,b utitisnotamajordrawbackinmost
distributedsystems.
Convergence -Response Tradeoffs
Convergence span denotes the maximum number of critical tra nsitions made before the system
reaches a legal state and response span denotes the maximum n umber of transitions to get from
some starting state to some goal state. Critical transition s are similar to errors occurring in the
system due to a move. For example, in a mutual exclusion syste m, if one process is in its critical
section and another process makes a move and enters its criti cal section, an error has occurred
becausemorethanoneprocess hasbeen allowedto enteritscr iticalsection.
Severalself-stabilizingterminationdetectionalgorith ms,eachhavingdifferentproperties,have
beendeveloped. Foraringofnprocesses,ifonehascomparat iveconvergenceandresponsespans,
one has a fast convergent span and a slow response span, and on e shows the relationship between
the two spans. If theconvergence span is decreased by a facto r of k (1≤k≤n), the responsespan
is increased by thesamefactor. So, theconvergencespan iso f theorder ofn/k whiletheresponse
span isn*k. Thisrelationshipexistsinall theotherclasse s ofself-stabilizingsystems.
This relationship is reasonable because the more checks tha t are made, the longer it will take
to converge, while there will be a fewer number of errors made . This relationship is very useful
in the design ofself-stabilizingsystemsbecause the syste mcan be modiﬁed according to thegoal
of the system. Depending on the requirements of the system, o ne can have fast convergence with
manyerrors orslowerconvergencewithfewererrors orsomet hingin between.
Pseudo stabilization
It is sometimes expensive to design self-stabilizing syste ms. Lessening the requirements of the
system can reduce some of thecost. A system is said to stabili zeif and only if every computation
has some state in it such that any computation starting from t his state will be in the set of legal
computations. On the other hand, in order for a system to pseu do stabilize, every computation
only needs to have some state such that the sufﬁx of the comput ation beginning at this state is in
the set of legal computations [24]. The property of pseudo-s tabilization is obviously weaker than
therequirementofstabilization,however,itis lessexpen sivetoimplement.
Veriﬁcation ofSelf-Stabilizing Systems
When designing self-stabilizing systems, verifying the co rrectness of these algorithms may be
difﬁcult,buttherehasbeensomeworkinthisarea. Aconverg encestairmethodhasbeendeveloped
where the legal states are built up step by step. Proof that th e algorithm stabilizes in each step,
veriﬁes the correctness of the entire algorithm. The interl eaving assumptions can be relaxed to
656
make it easier to verify the correctness of the algorithm. Al gorithms that are pseudo-stabilizing
[24]areusuallygoodenoughformanysystems,andthesearee asiertoimplement,easiertoverify,
and moreefﬁcient to run.
17.15 ChapterSummary
Self-stabilizationhasbeenusedinmanyareasandtheareas ofstudycontinuetogrow. Algorithms
havebeendevelopedusingcentralordistributeddaemonsan duniformandnon-uniformnetworks.
Thealgorithmsthatassumeacentraldaemoncanusuallybeea silyextendedtosupportdistributed
daemon,so thesealgorithmsare stilluseful when appliedto distributedsystems.
Extensionsofcommunicationprotocolsthatareself-stabi lizinghavealsobeendevelopedsuch
as the sliding window protocol, the two-way handshake, and t he alternating-bit protocol [2]. The
major drawback of self-stabilizing systems is the initial i llegal conﬁgurations. The system must
converge quickly in order to make the illegal conﬁgurations less serious. Veriﬁcation of the sys-
tems can be difﬁcult, but there are ways to make it easier. Rel axing interleaving assumptions and
usage of a convergence stairare two of theways. Some of theas sumptionsmade while designing
the systems make it nearly impossible to implement the syste ms. For example, self-stabilizing
protocols require a timeout action that needs to examine the contents of the communication link
and alsoneeds toknowthevaluesofsomenon-localvariables . Globaltimeoutactions areusually
avoidedwhich makesthesealgorithmsnoteasy to implement.
These requirements may not be necessary in some cases. The al ternating-bit protocol [2], for
example, does not need unbounded sequence numbers, nor does it need expensive global timeout
actions. Therefore, this protocol can be implemented relat ively easily, and even though the algo-
rithm is pseudo stabilizing and not exactly stabilizing, th is does not affect the usefulness of the
algorithmin mostsituations.
17.16 BibliographicNotes
Theideaofself-stabilizationwasﬁrst proposedbyDijkstr ainaseminalpaper[36]in1974. Since
then considerable volume of work has been done on this topic. The most extensive work in self-
stabilization has been done in the area of mutual exclusion [ 66, 69, 76, 26]. The reason for this is
mainlyduetoDijkstra’soriginalself-stabilizingmodelt herealegalstateisdeﬁned tobeastatein
whichonlyoneprivilegeexistsinthesystem.
An excellent survey on the topic is due to by Schneider [81]. G artner [45] presents a survey
of algorithms for construction of self-stabilizing spanni ng-trees. Aggarwal [7] presents a time
optimal self-stabilizing algorithms for spanning trees. M ore details on distributed reset can be
found in [13]. Chang et al. [28] discuss the cost of self-stab ilization. Self-stabilization has been
used todesignmorerobustdistributedmechanismslikesync hronization[14].
657
17.17 ExerciseProblems
1. When self-stabilization claims to solve so many problems in fault tolerance in a uniﬁed
manner,whyarepeoplestillstudyingandinvestigatingeac hofthoseproblemsindividually?
2. Describeself-stabilizingalternating-bitprotocol.
3. Give a psuedo-stabilization algorithm. Discuss how it re duces the cost compared to stabi-
lization.
4. What is“superstabilization"? Whattypeofguarantees do superstabilizationprovide?
5. What arethetrade-offsin aself-stabilizingsystem/alg orithm?
6. Fault containment is a problem with self-stablizing algo rithms. What are fault-containing
self-stablizingalgorithms[50]? Describehowtheysolvet heproblem.
7. Describeaself-stabilizingmutualexclusionalgorithm .
8. One weakness of self-stabilization is that it is a global p roperty. A failure that is local to a
machine may spread and lead to corrective actions across the entire system. Discuss how
thisproblemcan beaddressed bylocal detectionand correct ionoffailures [4, 16].
658
Bibliography
[1] Abadir, M.S., and Gouda, M. G. 1992. The stabilizing comp uter. In Proc. of the 1992 Inter-
nationalConference onParallel and DistributedSystems,( Dec.).
[2] Y. Afek, and G. Brown, Self-stabilization of the alterna ting-bit protocol. In Proceedings of
the8th SymposiumonReliableDistributedSystems,80-83, 1 989.
[3] Y. Afek, S. Kutten and M. Yung, Memory efﬁcient self-stab ilizing protocolsfor general net-
works,Proc. ofthe4thInternationalWorkshopon DistributedAlgorithms,1991, 1 5-28.
[4] Y.Afek, S. KuttenandM.Yung,TheLocalDetectionParadi gmanditsApplicationstoSelf-
stabilization,TheoreticalComputerScience, 186(1-2), 1 99-229,1997.
[5] Y. Afek, S. Kutten, and M. Yung, Memory-efﬁcient self-st abilization on general networks.
In Proc. of the 4th International Workshop on Distributed Al gorithms (Bari, Italy, Sept.). In
LectureNotesin ComputerScience, vol.486.Springer-Ver- lag, New York, 15-28,1990.
[6] YehudaAfekandAnatBremler,Self-stabilizingunidire ctionalnetworkalgorithmsbypower
supply,Chicago JournalofTheoreticalComputerScience, 1 998(3),December1998.
[7] S. Aggarwal, Timeoptimalself-stabilizingspanning tr ee algorithms,Technical Report MIT-
LCS/ MIT/ LCS/ TR-632, Massachusetts Institute of Technolo gy, Laboratory for Computer
Science, August1994.
[8] S.AggarwalandS.Kutten,Timeoptimalself–stabilizin gspanningtreealgorithms,InRudra-
patna K. Shyamasundar, editor, Proceedings of Foundations of Software Technology and
Theoretical Computer Science, volume 761 of Lecture Notes i n Computer Science, pages
400–410,Berlin, Germany,December1993.Springer-Ver-la g.
[9] Gheorghe Antonoiu and Pradip K. Srimani, A self-stabili zing distributed algorithm to con-
struct an arbitrary spanning tree of a connected graph, Comp uters and Mathematics with
Applications,30:1–7,1995.
[10] Gheorghe Antonoiu and Pradip K. Srimani, Distributed s elf-stabilizing algorithm for mini-
mum spanning tree construction, In Euro-Par ’97 Parallel Pr ocessing, Proceedings, number
1300inLectureNotes inComputerScience, pages 480–487.Sp ringer-Verlag, 1997.
659
[11] Gheorghe Antonoiu and Pradip K. Srimani, A self-stabil izing distributed algorithm for min-
imal spanning tree problem in a symmetric graph, Computers a nd Mathematics with Appli-
cations,35(10):15–23,1998.
[12] A. Arora And M. G. Gouda, Closure and convergence: A foun dation for fault-tolerant com-
puting,In Proc. ofthe22ndInternationalConference onFau lt-TolerantComputingSystems,
1992.
[13] Anish Arora and Mohamed G, Gouda. Distributed reset, IE EE Transactions on Computers,
43(9):1026–1038,September1994.
[14] Baruch Awerbuch, Shay Kutten, Yishay Mansour, Boaz Pat t-Shamir and George Varghese,
Time optimal self-stabilizing synchronization, In ACM, ed itor, Proc. of the twenty-ﬁfth an-
nual ACM Symposium on the Theory of Computing, San Diego, Cal ifornia, May 16–18,
1993,pages 652–661,New York,NY, USA, 1993.ACM Press.
[15] BaruchAwerbuchandRafailOstrovsky,Memory-efﬁcien tandself-stabilizingnetworkreset,
In Symposium on Principles of Distributed Computing (PODC ’ 94), pages 254–263, New
York,USA, August1994,ACM Press.
[16] BaruchAwerbuch,BoazPatt-Shamir,andGeorgeVarghes e,Self-stabilizationbylocalcheck-
ing and correction, In FOCS91 Proceedings of the 31st Annual IEEE Symposium on Foun-
dationsofComputerScience, pages 268–277,1991.
[17] B. Awerbuch and G Varghese, Distributed program checki ng: A paradigm for building self-
stabilizing distributed protocols, In Proc. of the 32nd IEE E Symposium on Foundations of
ComputerScience (Oct.), 1991
[18] Awerbuch,Patt,andG.Varghese,Self-stabilizationb ylocalcheckingandcorrection,InProc.
ofthe32ndIEEE Symposiumon FoundationsofComputerScienc e(Oct.), 1991.
[19] Bastani, Yen, and Y. Zhao, On self stabilization, non-d eterminism, and inherent fault toler-
ance, In Proc. of the MCC Workshop on Self-Stabilizing Syste ms. MCC Tech. Rep. STP-
379-89,1989
[20] J. C Browne, A. Emerson, M. Gouda, D. Miranker, A. Mok and L. Rosier, Bounded time
fault-tolerantrule-based systems,TelematicsInformat. 7, 3/4,441–454,1990.
[21] Geoffrey M. Brown, Mohamed G. Gouda and Chuan-Lin Wu, To ken Systems That Self Sta-
bilize,IEEE Transactionson Computers,Vol.38, No.6, pp84 5-852,June1989.
[22] J.E.BurnsandJanK.Pachl,Uniformself-stabilizingr ings,ACMTransactionsonProgram-
mingLanguages and Systems(TOPLAS),v.11n.2,p.330-344,A pril 1989.
[23] J.E.Burns,Self-stabilizingringswithoutdemons,Te chnicalReportGITICS-87/36, Georgia
InstituteofTechnology,1987.
660
[24] J.E.Burns,M.G.GoudaAndR.EMiller,Stabilizationan dpseudo-stabilization,Distributed
ComputingarchiveVolume7, Issue1,November1993.(Specia l issue: Self-stabilization)
[25] J.E Burns, M.G GoudaAnd R. E.Miller,Onrelaxing interl eavingassumptions,Inproc. of
theMCC WorkshoponSelf-Stabilizing SystemsMCC, Tech. Rep . STP-379-89, 1989.
[26] R. W. Buskens and R. P. Bianchini, Jr., Self-Stabilizin g Mutual Exclusionin the Presence of
FaultyNodes, 25thInternationalSymposiumon FaultTolera nt ComputingDigest ofPapers,
144–153,1995.
[27] Franck Butelle, Christian Lavault, and Marc Bui, A unif orm self-stabilizing minimum di-
ameter tree algorithm (extended abstract), In Jean-Michel H´elary and Michel Raynal, edi-
tors,DistributedAlgorithms,9thInternationalworkshop ,WDAG’95,volume972ofLecture
NotesinComputerScience,pages25–272,LeMont-Saint-Mic hel,France,13–15September
1995.Springer-Verlag.
[28] Ernest J. H. Chang, Gaston H. Gonnet and Doron Rotem, On t he costs of self-stabilization,
InformationProcessingLetters, Vol.24,No. 5, pp311-316, 16 March 1987.
[29] K. M. Chandy and L. Lamport, Distributed snapshots: Det ermining global states of dis-
tributedsystems,ACM Trans.Comput.Syst.(63-75), 1985.
[30] Nian-Shing Chen, Hwey-Pyng Yu, and Shing-Tsaan Huang, A self-stabilizing algorithm for
constructingspanningtrees, InformationProcessingLett ers, 39:147–151,1991.
[31] Cisco Systems Inc, Using Vlan Director system document ation, Internet:
http://www.cisco.com/univercd/cc/td/doc/product/rtr mgmt/swntman/cwsimain/cwsi2/cwsiug2/vlan2/index.htm
1998.
[32] Zeev Collin and Shlomi Dolev, Self-stabilizing depth ﬁ rst search, Information Processing
Letters,49:297–301,1994.
[33] Couvreur, N. Francez and M. G. Gouda, Asynchronous unis on, In Proc. of the 12th Interna-
tionalConference onDistributedComputingSystems,Yokoh ama,Japan,June1992.
[34] E.W. Dijkstra,A belatedproofofself-stabilization, Distrib.Comput.,1, 5-6, 1986.
[35] E.W.Dijkstra,Self-stabilizationinspiteofdistrib utedcontrol,InSelectedWritingsonCom-
puting: A Personal Perspective. Springer-Verlag, Berlin, 1982, 41–46. Originally published
in1973.
[36] Edsger W. Dijkstra, Self stabilizing systems in spite o f distributed control, Communications
oftheACM, 17(11):643–644,1974.
[37] S. Dolev, A. Israeli, and S. Moran, Uniform dynamic self -stabilizing leader election, IEEE
Transactionson Parallel andDistributedSystems,8(4):42 4–440,1997.
661
[38] Shlomi Dolev, Optimal time self stabilization in dynam ic systems (preliminary version), In
Andr´e Schiper, editor, Proce. of the 7th International Wor kshop on Distributed Algorithms
(WDAG93), volume 725 of Lecture Notes in Computer Science, p ages 160–173, Lausanne,
Switzerland,27–29September1993. Springer-Verlag
[39] ShlomiDolev,Self-Stabilization,MIT Press, 2000.
[40] Shlomi Dolev, Mohamed G. Gouda, and Marco Schneider, Me mory requirements for silent
stabilization,ActaInformatica,36(6):447–462,1999.
[41] ShlomiDolev,A. IsraeliandS. Moran,Selfstabilizati onofdynamicsystems,In Proc. ofthe
MCCWorkshoponSelf-StabilizingSystems,MCCTechnicalRe portNo.STP-379-89,1989.
[42] Shlomo Dolev, Amos Israeli and Shlomo Moran, Self-stab ilization of dynamic systems as-
sumingonlyread/writeatomicity,InProc.oftheninthannu alACMsymposiumonPrinciples
of distributed computing, Quebec City, Quebec, Canada, Aug ust 22-24, 1990, pp 103-117.
(AlsoinDistributedComputing7(1993),3-16.)
[43] M. Flatebo and A. Datta, Two-state self-stabilizing al gorithms, In Proc. of the 6th Interna-
tionalParallelProcessing Symposium,BeverlyHills.Cali f. Mar1992,198-203.
[44] M.FlateboandS.Ghosh,Self-stabilizationindistrib utedsystems,IEEEComput,1991.(Also
in Readings in Distr. Comp. Systems. T. L. Casavant and M. Sin ghal Eds. New York: IEEE
ComputerSociety Press, 1994,p.100-114.)
[45] Felix C. Gartner, A Survey of Self-Stabilizing Spannin g-
Tree Construction Algorithms, EPFL Technical Report, 2003 .
(icwww.epﬂ.ch/publications/documents/IC_TECH_REPORT _200338.pdf)
[46] Felix C. Gartner and Henning Pagnia, Time-efﬁcient sel f-stabilizing algorithms through hi-
erarchical structures, In Proc. of the 6th Symposium on Self -Stabilizing Systems, Lecture
NotesinComputerScience, San Francisco, June2003.Spring er-Verlag.
[47] C. Genolini and S. Tixeuil, A lower bound on dynamic k-st abilization in asynchronous sys-
tems, In SRDS 2002 21st Symposiumon Reliable DistributedSy stems, IEEE Computer So-
cietyPress, pages 211–221,2002.
[48] SukumarGhosh,Binaryself-stabilizationindistribu tedsystems,InformationProcessingLet-
ters,v.40n.3, p.153-159,Nov.1991
[49] S. Ghosh, Self-stabilizing distributed systems with b inary machines, In Proc. of the 28th
AnnualAllertonConference, 1988-997,1990.
[50] S. Ghosh, A. Gupta, T. Herman and S. V. Pemmaraju, Fault- Containing Self-Stabilizing Al-
gorithms,InProc. oftheﬁfteenthannual ACMsymposiumon Pr inciplesofdistributedcom-
puting,Philadelphia,1996.
662
[51] S. Ghosh, Understanding self-stabilization in distr, systems. Tech. Rep. TR-90-02, Dept. of
ComputerScience, Univ.ofIowa,1990.
[52] S. Ghosh, A. Gupta, and S. Pemmaraju, A fault-containin g self-stabilizing algorithm for
spanningtrees, Journal ofComputingandInformation2(199 6), 322-338.
[53] S. Ghosh, A. Gupta, M. Karaata, S. Pemmaraju, Self-stab ilizing dynamic programming al-
gorithms on trees, in: Proc. of the Second Workshop on Self-S tabilizing Systems, 1995, pp.
11.1-11.15.
[54] M.G.Gouda,ThestabilizingPhilosopher: Asymmetryby MemoryandbyAction,Technical
Report TR-87-12, Dept.ofComputerSciences, Universityof Texas atAustin,1987.
[55] M. G. Gouda and M. Evangelist, Convergence/response tr adeoffs in concurrent systems, In
Proc. ofthe2ndIEEE SymposiumonParallel and DistributedP rocessing, Dec1990.
[56] M. G. Gouda and T. Herman, Stabilizing unison. Inf. Proc ess. Lett. 35 (1990), 171–175.,
1990.
[57] M.G.GoudaandN.Multari,Stabilizingcommunicationp rotocols,IEEETrans.Comput.40,
4(Apr.), 448–458,1991.
[58] M. G. Gouda, R. R. Howell and L. E. Rosier, The instabilit y of self-stabilization, Acts Inf.
27,(1990), 697-724,1990.
[59] F. F. Haddix, Stabilization of bounded token rings, Tec h. Rep. ARL-TR-91-31, Applied Re-
search Lab., Univ.ofTexasat Austin,1991.
[60] S. M. Hedetniemi, S.T. Hedetniemi, D. P. Jacobs, P. K. Sr imani, Self-stabilizing algorithms
for minimal dominating sets and maximal independent sets, C omput. Math. Appl. 46 (5-6)
(2003)805-811.
[61] T.Herman,Probabilisticself-stabilization,Inform ationProcessingLetters,v.35n.2,p.63-67,
June1990.
[62] T. Herman, Self-stabilization: Randomness to reduce s pace, Distributed Computing, vol. 6,
p.95-98,1992.
[63] Lisa Higham and Zhiying Liang, Self-stabilizing minim um spanning tree construction on
message-passing networks, In Proc. of the 15th Internation al Symposium on Distributed
Computing (DISC), number 2180 in Lecture Notes in Computer S cience, Lisbon, Portugal,
and October2001.Springer-Verlag.
[64] Su-Chu Hsu and Shing-Tsaan Huang, A self-stabilizing a lgorithm for maximal matching,
InformationProcessingLetters, Volume43,Issue2,pp 77-8 1,August1992.
663
[65] S. Huang and N. Chen, A self-stabilizing algorithm for c onstructing breadth-ﬁrst trees, In-
form.Process. Lett. 41(1992),109-117.
[66] Amos Israeli and Marc Jaﬂon, Token management schemes a nd random walks yield self-
stabilizingmutualexclusion,Proceedingsoftheninthann ualACMsymposiumonPrinciples
ofdistributedcomputing,p.119-131,August22-24,1990,Q uebec City,Quebec, Canada.
[67] G. Itkis and L. Levin, Fast and lean self-stabilizing as ynchronous protocols, In Shaﬁ Gold-
wasser,editor,Proc.: 35thAnnualSymposiumonFoundation sofComputerScience,Novem-
ber 20–22, 1994, Santa Fe, New Mexico, pages 226–239, 1109 Sp ring Street, Suite 300,
SilverSpring, MD20910,USA, 1994.IEEE ComputerSociety Pr ess.
[68] ColetteJohnen,Memoryefﬁcient,self-stabilizingal gorithmtoconstructBFSspanningtrees,
In Proc. of the 16th Annual ACM Symposium on Principles of Dis tributed Computing
(PODC ’97),pages 288–288,August1997.
[69] Hirotsugu Kakugawa, Masafumi Yamashita, A Universal S elf-Stabilizing Mutual Exclusion
Algorithm, Dagstuhl Seminor 00431: SelfStabilization, Da gstuhl, Germany, 2000. (url =
"citeseer.ist.psu.edu/yamashita00universal.html")
[70] Ronen Kat, Self-stabilizing replication ﬁle system, I nternet: http://www.cs.bgu.ac.il/ srfs/,
September2002.
[71] S. Katz and K. J. Perry, Self-stabilizing extensions fo r message -passing systems, In Proc.
of the 9th Annual ACM Symposium on Principles of Distributed Computing, Quebec City,
Canada, Aug 1990.
[72] H.S.M.Kruijer,Self-stabilization(inspiteofdistr ibutedcontrol)intree-structuredsystems,
Inf. Process. Lett.,8, 2,2– 79,1979.
[73] D. Lehman and M. Rabin, On the advantages of free choice: A symmetric and fully dis-
tributedsolutionofthediningphilosopher’sproblem,In P roc. ofthe8thAnnualACM Sym-
posiumon PrinciplesofProgrammingLanguages,1981.
[74] X. Lin and S. Ghosh, Self-stabilizing maxima ﬁnding. In Proceedings of the 28thAnnual
AllertonConf., pp.662-671,1991.
[75] Michael Luby, A simpleparallel algorithm for the maxim al independent set problem, SIAM
JournalonComputing,Volume15, Issue4,pp 1036-1055,Nove mber,1986.
[76] Masaaki Mizuno and Mikhail Nesterenko and Hirotsugu Ka kugawa, Lock Based Self-
Stabilizing Distributed Mutual Exclusion Algorithms, Int ernational Conference on Dis-
tributedComputingSystems,708-716,1996.
664
[77] Reuay-Ching Pan, Jone-Zen Wang, and Louis R. Chow. A sel f-stabilizing distributed span-
ningtreeconstructionalgorithmwithadistributeddemon. TamsuiOxfordJournalofMathe-
maticalSciences, 15:23–32,1999.
[78] M. Schneider, Self-Stabilization – A Uniﬁed Approach t o Fault Tolerance in the Face Tran-
sient Errors, TechReport TR-91-18, Dept. of Computer Scien ce, University of Texas at
Austin,Austin,TX,1991.
[79] M. Schneider, Compiling Self-Stabilization into Sequ ential Programs, Dept. of Computer
Science, UniversityofTexasat Austin,Austin,TX, 1992.
[80] M.Schneider,LecturenotesonSelf-Stabilization,Th eUniversityofTexasatAustin, http:
//www.cs.utexas.edu/users/plaxton/c/395t/slides/Sch neider.pdf
[81] M.Schneider, Self Stabilization,ACM ComputingSurve ys,Vol. 25,No. 1,March 1993.
[82] S. Shukla, D. Rosenkrantz, S. Ravi, Observations on sel f-stabilizing graph algorithms for
anonymous networks, in: Proc. of the Second Workshop on Self -Stabilizing Systems, 1995,
p.7.17.15.
[83] ZhengnanShi,WayneGoddardandStephenT.Hedetniemi, AnAnonymousSelf-Stabilizing
Algorithmfor 1-MaximalIndependent Set in Trees, Informat ion Processing Letters, Volume
91, Issue2,pp 77-83,July2004.
[84] S. Sur and P. K. Srimani. A self-stabilizing distribute d algorithm to construct BFS spanning
trees ofasymmetricgraph. Parallel ProcessingLetters, 2( 2-3):171–179,September1992.
[85] Ming-Shin Tsai and Shing-Tsaan Huang. A self-stabiliz ing algorithm for the shortest paths
problemwithafullydistributeddemon.ParallelProcessin gLetters,4(1-2):65–72,June1994.
665
Chapter18
Peer-to-PeerComputing and Overlay
Graphs
18.1 Introduction
Peer-to-peer (P2P) network systems use an application-lev el organization of the network overlay
for ﬂexibly sharing resources (e.g., ﬁles and multimedia do cuments) stored across network-wide
computers. In contrast to the client-server model, any node in a P2P network can act as a server
to others and at thesametime, itcan act as aclient. Communic ationand exchangeof information
isperformed directlybetween theparticipatingpeers and t herelationshipsamongthenodesinthe
network are equal. Thus, P2P networks differ from other Inte rnet applications in that they tend
to share data from a large number of end users rather than from the more central machines and
Web servers. Several well known P2P networks that allow P2P ﬁ le-sharing include Napster [22],
Gnutella[14, 15], Freenet [9], Pastry[27], Chord [29]. and CAN [24].
Traditional distributed systems used DNS (Domain Name serv ice) to provide a lookup from
host names (logical names) to IP addresses. Special DNS serv ers are required, and manual con-
ﬁguration of the routing information is necessary to allow r equesting client nodes to navigate the
DNShierarchy. Further,DNSisconﬁnedtolocatinghostsors ervices(notdataobjectsthathaveto
beaprioriassociatedwithspeciﬁccomputers),andhostnam esneedtobestructuredasperadmin-
istrative boundary regulations. P2P networks overcome the se drawbacks, and more importantly,
allowthelocationofarbitrary dataobjects.
AnimportantcharacteristicofP2Pnetworksistheirabilit ytoprovidealargecombinedstorage,
CPU power, and other resources while imposing a low cost for s calability, and for entry into and
existfrom thenetwork. Theongoingentry and exitof various nodes,as well as dynamicinsertion
anddeletionofobjectsistermedas churn. Theimpactofchurnshouldbeastransparentaspossible.
P2Pnetworksexhibitahighlevelofself-organizationanda reabletooperateefﬁcientlydespitethe
lack of any prior infrastructure or authority. The philosop hy of this model requires that if a node
wants to enjoy the services which other nodes provide, that n ode should provide service to other
nodes. Somedesirablefeatures ofP2Psystemsaresummarize dinTable18.1.
666
Features Performance
self-organizing large combined storage, CPUpower, and resources
distributed control fast search for machines and data objects
role symmetry fornodes scalable
anonymity efﬁcient management ofchurn
naming mechanism selection of geographically close servers
security, authentication, trust redundancy instorage and paths
Table18.1: Desirablecharacteristics andperformance fea tures ofP2Psystems.
18.1.1 Napster
OneoftheearliestpopularP2Psystems,Napster,usedaserv er-mediatedcentralindexarchitecture
that is organized around clusters of servers that store dire ct indices of the ﬁles in the system. The
central server maintains a table with the following informa tion of each registered client: (i) the
client’s address (IP) and port, and offered bandwidth, and ( ii) information about the ﬁles that the
client can allow to share. The basic steps of operation to sea rch for content and to determine a
nodefromwhich todownloadthecontentare thefollowing.
1. Aclientconnectstoameta-serverthatassignsalightly- loadedserverfromoneoftheclose-
byclusters ofserversto processtheclient’squery.
2. Theclientconnectstotheassignedserverandforwardsit squeryalongwithitsownidentity.
3. The server responds to the client with information about t he users connected to it and the
ﬁles theyaresharing.
4. On receiving the response from the server, the client choo ses one of the users from whom
todownloadadesiredﬁle. Theaddress toenabletheP2Pconne ctionbetween theclientand
theselecteduseris providedby theserverto theclient.
Users are generally anonymousto each other. Thedirectory s erves to providethe mappingfrom a
particularhostthatcontainstherequiredcontent, totheI Paddress needed todownloadfromit.
18.1.2 Application LayerOverlays
A core mechanism in P2P networks is searching for data, and th is mechanism depends on how
(i) the data, and (ii) the network, are organized. Search alg orithms for P2P networks tend to be
data-centric, as opposed to the host-centric algorithms fo r traditional networks. P2P search uses
theP2P overlay , which is a logical graph among the peers, that is used for the object search and
object storage and management algorithms. Note that above t he P2P overlay is the application
layer overlay, where communication between peers is point- to-pont (representing a logical all-to-
all connectivity,)onceaconnectionis established.
The P2P overlay can be structured (e.g., hypercubes, meshes, butterﬂy networks, de Bruijn
graphs) or unstructured , i.e., no particular graph structure is used. Structured ov erlays use some
667
rigid organizational principles based on the properties of the P2P overlay graph structure, for the
object storage algorithms and the object search algorithms . Unstructured overlays use very loose
guidelines for object storage. As there is no deﬁnite struct ure to the overlay graph, the search
mechanismsaremore“ad-hoc”,andtypicalyusesomeformsof ﬂoodingorrandomwalk strategies.
Thus, object storage and search strategies are intricately linked to the overlay structure as well as
tothedataorganizationmechanisms.
18.2 DataIndexingandOverlays
The data in a P2P network is identiﬁed by using indexing. Data indexingallows the physical data
independence from the applications. Indexing mechanisms c an be classiﬁed as being centralized ,
local,ordistributed .
Centralized indexing entailstheuseofoneorafewcentralserverstostorerefere nces(indexes)to
thedataonmanypeers. TheDNSlookupaswellasthelookupbys omeearlyP2Pnetworks
suchas Napsterused acentral directorylookup.
Distributed indexing involves the indexes to the objects at various peers being sc attered across
other peers throughout the P2P network. In order to access th e indexes, a structure is used
in the P2P overlay to access the indexes. Distributed indexi ng is the most challenging of
the indexing schemes, and many novel mechanisms have been pr oposed, most notably the
distributed hash table (DHT) . Various DHT schemes differ in the hash mapping, search
algorithms,diameterforloookup,search diameter, fault- tolerance,and resiliencetochurn.
A typical DHT uses a ﬂat key space to associate the mapping bet ween network nodes and
data objects/ﬁles/values. Speciﬁcally, the node address i s mapped to a logical identiﬁer in
the key space using a consistent hash function. The data obje ct/ﬁle/value is also mapped to
thesamekeyspace usinghashing. Thesemappingsare illustr atedin Figure18.1.
Local indexing requireseach peertoindexonlythelocaldataobjectsandre moteobjectsneedto
besearchedfor. Thisformofindexingistypicallyusedinun structuredoverlaysinconjunc-
tionwithﬂoodingsearch orrandomwalk search. Gnutellause s localindexing.
An alternate way to classify indexing mechanisms is as being asemantic index mechanism or
asemantic-free index mechanism. A semantic index is human readable, for exa mple, a document
name, a keyword, or a database key. A semantic-free index is n ot human readable and typically
correspondstotheindexobtainedbyahashmechanism,e.g., theDHTschemes. Asemanticindex
mechanism supports keyword searches, range searches, and a pproximate searches, whereas these
searches are notsupportedbysemantic-free indexmechanis ms.
668
(address) space value spaceObject/ file Native node identifier
spaceCommon key (identifier)
Figure 18.1: The mappings from node address space and object space in a typical DHT scheme,
e.g., Chord, CAN, Tapestry.
18.2.1 Distributed Indexing
Structured overlays. The P2P network topology has a deﬁnite structure, and the pla cement of
ﬁles or data in this network is highly deterministic as per so me algorithmic mapping. (The
placement of ﬁles can sometimes be “loose”, as in some earlie r P2P systems like Freenet,
where “hints” are used.) The objective of such a determinist ic mapping is to allow a very
fast and deterministic lookup to satisfy queries for the dat a. These systems are termed as
lookup systems and typically use a hash table interface for the mapping. The hash function,
whichefﬁcientlymaps keystovalues,inconjunctionwiththeregularstructureoftheoverlay,
allowsfast search forthelocationoftheﬁle.
An implicit characteristic of such a deterministic mapping of a ﬁle to a location is that the
mapping can be based on a single characteristic of the ﬁle (su ch as its name, its length,
or more generally some predetermined function computed on the ﬁle). A disadvantage of
such a mapping is that arbitrary queries, such as range queri es, attribute queries and exact
keywordqueries cannotbehandleddirectly.
Another implicit effect of the tight coupling of the regular overlay structure and the rigid
mapping function to enable fast access is that ﬁle insertion s and deletions incur some over-
head whichmay benontrivialunderchurn.
Unstructured overlays. TheP2Pnetworktopologydoesnothaveanyparticularcontro lledstruc-
ture,noristhereanycontroloverwhereﬁles/dataisplaced . Eachpeertypicallyindexesonly
itslocaldataobjects,hence, localindexing isused. Nodejoinsand departuresare easy-the
local overlay is simply adjusted. File placement is not gove rned by the topology. Search
for a ﬁle may entail high messageoverhead and highdelays. Ho wever, complexqueries are
supportedbecausethesearch criteriacan bearbitrary.
AlthoughtheP2Pnetworktopologydoesnothaveanycontroll edstructure,sometopologies
naturallyemerge. Thefollowingtopologiesarecommonandw illbestudiedinlatersections.
669
1. Power Law Random Graph (PLRG): This is a random graph where the node degrees
follow the power law. Here, if the nodes are ranked in terms of their degree, then the
ithnodehasc/iαneighbors,where cisaconstant.
2. NormalRandomGraph: Thisisanormalrandomgraphwhereth enodestypicallyhave
a uniformdegree.
Westudysearch in unstructuredoverlaynetworksin thenext section.
18.3 UnstructuredOverlays
18.3.1 Unstructured Overlays: Properties
Unstructuredoverlayshavetheseriousdisadvantagethatq ueriesmaytakealongtimetoﬁndaﬁle
or may even be unsuccessful even if the queried object exists . The message overhead of a query
search may alsobehigh.
Advantages: Thefollowingarethemainadvantagesofunstructuredoverl ayssuchastheoneused
by Gnutella.
1. Exactkeywordqueries,rangequeries,attribute-basedq ueriesandothercomplexqueriescan
be supported because the search query can capture the semant ics of the data being sought;
and theindexingoftheﬁles and dataisnotboundto anynon-se manticstructure.
2. Unstructured overlays can accommodate high churn, i.e., the rapid joining and departure of
manynodeswithoutaffecting performance.
Thefollowingareadvantagesofunstructuredoverlaysifce rtain conditionsare satisﬁed.
1. Unstructured overlays are efﬁcient when there is some deg ree of data replication in the net-
work.
2. Users aresatisﬁed withabest-effortsearch.
3. Thenetworkisnot solargeas to lead toscalabilityproble msduringthesearch process.
18.3.2 Gnutella
Gnutella uses a fully decentralized architecture. In Gnute lla logical overlays, nodes index only
theirlocalcontent. Theacutaloverlaytopologycanbearbi traryasnodesjoinandleaverandomly.
A node joins the Gnutella network by forming a connection to s ome nodes found in standard
Gnutella directory-like databases. (Note that the functio n of joining the network cannot be said
to be fully decentralized.) Users communicatewith each oth er, performing therole of both server
and client,termed as servent. Thefollowingarethemainmessagetypes usedby Gnutella.
•Pingmessagesare usedto discoverhosts,and allowanew hosttoan nounceitself.
670
•Pongmessages are the responses to Pings. ThePongmessages indicate the port and (IP)
address of the responder, and some information about the amo unt of data (the number and
sizeofﬁles)thatnodecan makeavailable.
•Querymessages. The search strategy used is ﬂooding. Querymessages contain a search
stringandtheminimumdownloadspeedrequiredofthepotent ialresponder,andareﬂooded
inthenetwork.
•QueryHit messages are sent as responses if a node receiving a Querydetects a local match
in responseto a query. A QueryHit containsthe port and address (IP), speed, thenumberof
ﬁles found, and related information. Thepathtraced by a Queryisrecorded in themessage,
sotheQueryHit followsthesamepathin reverse.
18.3.3 Search in Gnutella andUnstructured Overlays
Consider a system with nnodes andmobjects. Let qibe the popularity of object i, as measured
by the fraction of all queries that are queries for object i. All objects may be equally popular, or
morerealistically,aZipf-likepowerlaw distributionofp opularityexists. Thus,
m/summationdisplay
i=1qi= 1 (18.1)
Uniform:qi= 1/m; Zipf-like:qi∝i−α(18.2)
Letribethenumberofreplicasofobject i,andletpibethefractionofallobjectsthatarereplicas
ofi. Threestaticreplicationstrategiesare: uniform,propor tional,and squareroot. Thus,
m/summationdisplay
i=1ri=R; pi=ri/R (18.3)
Uniform:ri=R/m; Proportional: ri∝qi; Square-root: ri∝√qi(18.4)
Underuniformreplication,allobjectshaveanequalnumber ofreplicasandhencetheperformance
forallqueryrates isthesame. Withauniformquery rate,pro portionaland sqaure-rootreplication
schemesreduce totheuniformreplicationscheme.
Foran objectsearch, someofthemorepopularmetrics ofefﬁc iency are:
•probabilityofsuccess ofﬁndingthequeried object.
•delay orthenumberofhopsin ﬁndingan object.
•thenumberofmessagesprocessed byeach nodein asearch.
•nodecoverage, thefraction of(distinct)nodesvisited
•messageduplication ,whichis (#messages-#nodesvisited)/#messages
671
•maximumnumberofmessagesat anode
•recall, the number of objects found satisfying the desired search c riteria. This metric is
usefulforkeyword,inexact,and rangequeries.
•messageefﬁciency , whichistherecall permessageused
Guided versus Unguided Search. In unguided or blind search, there is no history of earlier
searches, andf hence, each search is inherently independen t. In guided search, nodes store some
history of past searches to aid future searches. Various mec hanisms for caching hints to guide
and narrow down future searches are used. In this chapter, we focus on unguided searches in the
contextofunstructuredoverlays.
Search strategies: Flooding
•In order to curtail the high message overhead that ﬂooding in troduces, the initial strategy
wastouse checking. Here,anodechecksbackwiththequeryoriginatorbeforefo rwardinga
query. Unfortunately,thiscauseheavyloadontheoriginat or,inadditiontoexcessivedelays,
and henceisnotpractical.
•Thenextapproach istousethe timetolive (TTL)ﬁeld orthehopcount. However,thisdoes
notguaranteethatamatchcanbefoundforthequeryevenifth eobjectexistsinthenetwork,
and requiresa highvalueofTTLto haveahighdegreeofsucces s.
•A reﬁnement that allows more control is the expanding ring strategy. A node ﬁrst ﬂoods
with a small TTL. If the search is not successful, it starts an other ﬂood with a larger TTL,
and soon. Thisstrategyis moresuccessful whenobjects arer eplicated.
The expanding ring approach is signiﬁcantly more successfu l than the TTL approach, for
all replication strategies, and all query distributions, a nd the cost is only a relatively small
increasein delay.
Although expanding ring is superior to TTL, both are ﬂooding -based strategies and suffer from
messageduplication.
Search strategies: Random walk. Another strategy to use is that of random walking . Here, a
query is randomly forwarded by a node when it is received. Ran dom walk greatly reduces the
message overhead but it increases the search latency. Hence ,krandom walkers can be used. To
terminate the krandom walkers, a “checking-cum-TTL” strategy is effectiv e. Here, each walker
periodically(afteracertainnumberofhops)checkswithth equeryoriginatorwhethertoterminate;
theTTLis usedtopreventlooping,and is usuallyset toalarg e value.
Search strategies: Performance. Theperformanceofsearches inunstructuredoverlayshas be en
studiedviasimulationsandbyexperiments. Thefollowinga resomeoftherelationshipsofinterest,
forbothﬂoodingandfor k-randomwalk(forvariousvaluesof k)forvariousgraphtopologiessuch
as therandomgraph andthePLRG.
•Thesuccessrate as afunctionofthenumberofmessagehops,o rTTL.
672
nnumber ofnodes inthe system
mnumber ofobjects in the system
qinormalized query rate, where/summationtextm
i=1qi= 1
rinumber ofreplicas of object i
ρcapacity (measured as number ofobjects) per node
Rnρ=/summationtextm
i=1ri, thetotal capacity in the system
piri/R, the population fraction ofobject ireplicas
Table18.2: Parameters to studyreplication.
•Thenumberofmessagesas afunctionofthenumberofmessageh ops,orTTL.
•Theabovemetricsas thereplicationratio and thereplicati onstrategychanges.
•The node coverage, recall, and message efﬁciency, as a funct ion of the number of hops, or
TTL;and ofvariousreplicationratios and replicationstra tegies.
Search strategies: Guidelines
•Adaptivelydeterminingtheterminationconditionisimpor tant. Checkingisadaptivewhereas
TTLis not.
•Messageduplicationmustbeminimized,forit representswa sted resources.
•At each step in the search, the numberof messages (or numbero f nodes visited) should not
increaseby alargeammount.
Overall,k-random walk performs much better than ﬂooding and is more sc alable, for various
replicationand query distributions,andvariousgraph top ologies.
18.3.4 Replication Strategies
Scott and Shenker [11] studied the degree of replication for blind orunguided search in random
overlay graphs. The various parameters used to study replic ation are deﬁned in Table 18.2. Ran-
dom search is modeled by the following process. A node is repe atedly drawn at random from a
bin, examined for a match with the copy of the object, and repl aced in ther bin, until the object
is found. The metric then is the number of nodes drawn (or equi valently, the number of hops of
a random walker) until success. The probability that the obj ect is found on the kth drawing is:
Pri(k) =ri
n(1−ri
n)k−1. Theaveragesearch sizefor i, denoted as Ai, is:
Ai=Eover all k (Pri(k)) =n/summationdisplay
k=1[kri
n(1−ri
n)k−1]∼n
ri,forlargen (18.5)
Across thesystem,theaveragesearch size Ais:
Averagesearch size A=m/summationdisplay
i=1qiAi=n/summationdisplay
iqi
ri(18.6)
673
SettingritonmaximizesA, but requires full replication. As resources are constrain ed, assume
that average number of replicas per node is ρ=R/n < m . (It is easy to see that R≥m≥ρ.)
Substitutingfor nwithR/ρintheequationabove,wehave
Averagesearch size A=R
ρ/summationdisplay
iqi
ri=1
ρ/summationdisplay
iqi
pi(18.7)
Theutilizationrate uiofareplicaofobject iistheaveragerateofrequestsservicedbyareplica
ofi. Withrandom search, ui=qi
pi=Rqi
ri. Overall all replicas ofobject i, the utilizationis simply
=Rqi. The average utilization rate over (all copies of) all objec ts isu=/summationtextm
i=1riui
R=/summationtextm
i=1piqi
pi
= 1. This average is a constant, and independent of the replicat ion scheme. It is desirable to have
alowmaximumutilizationratein ordertodistributetheloa d moreuniformly.
The replication problem is formulated as the optimization s olution for Equation 18.7. We
assume that all objects are of uniform size. To simplify anal ysis, we also assume that each object
thatisqueriedexistsinthesystemandasearchcontinuesun tiltheobjectisfound,i.e.,allsearches
are eventually successful. (In practice, there is a paramet erL– such as TTL – that control the
maximumsearchsize. Searchoninsolublequeriescontinues untilthisparameterisexceeded. The
costofsuch queriesis fsA+ (1−fs)L, wherefsis thefraction ofqueries thatare soluble.)
Two naturalreplicationstrategiesare UniformandProportional .
Uniform:ri=R
mwhich implies pi=ri
R=1
m.
Average search size for object iisAi=n
ri. This equalsR
ρri=R
ρR/m i=m
ρ. This is the same
forallobjects.
From Equation(18.7), averagesearch size Auniform =1
ρ/summationtext
iqi
pi=1
ρ/summationtext
imqi=m
ρ.
Utilization of a replica of iisui=qi
piwhich is proportional to the query rate as piis same
forallobjects.
Maximum utilization of a replica of iismax iui=max iqi
pi=Rqi
ri, which can vary signiﬁ-
cantly.
Proportional: ri=Rqiwhichimplies pi=qi.
Average search size for object iisAi=n
ri=n
Rpi=n
Rqi=1
ρqi, which is inversely propor-
tionaltothequery rate.
From Equation(18.7), averagesearch size Aproportional =1
ρ/summationtext
iqi
pi=1
ρ/summationtextm
i=11 =m
ρ.
Utilizationofareplicaof iisui=qi
pi= 1, aconstantforall replicasofall objects.
Maximumutilizationofareplicaof iismax iui=max iqi
pi=max iqi
qi= 1foralli.
BothUniformandProportionalreplicationhavethesameave ragesearchsizewhichisindependent
of the query distribution. However, objects whose query rat es are below the average have lower
overheadwithuniformreplication,whilethosewithqueryr ateslargerthantheaveragehavelower
overheadwithproportionalreplication.
Square root: Theoptimalreplicationstrategythatminimizestheaverag esearchsizeistheSquare-
Root replication, which is deﬁned as having pi=ri
R∝√qi//summationtext
j√qj, assumingthat 1/R≤√qi//summationtext
j√qj≤n/Rforalli.
674
ri A Ai=n/riui=Rqi/ri
Uniform constant, R/m m/ρ m/ρ qim
Proportional qiR m/ρ 1/(ρqi) 1
Square-root R√qi//summationtext
j√qj(/summationtext
i√qi)2/ρP
j√qj/√qi
ρ√qi/summationtext
j√qj
Table18.3: ComparisonofUniform,Proportional,and Squar e-root replication.
The optimalityof square-root replication can be seen as fol lows. Substituting 1−/summationtextm−1
i=1pi
forpmin thecost functionofEquation18.7, wehave
search sizeAsq−rt=1
ρ/summationdisplay
iqi/pi=1
ρ[m−1/summationdisplay
i=1qi/pi+qm/(1−m−1/summationdisplay
i=1pi)]
By solvingds/dp i= 0,thevalueof pithat minimizes Asq−rtis seen tobe pm/radicalbig
qi/qm.
Analogous to Uniform and Proportional replications, the va lues ofA,Ai, anduifor Square-
root replication can be dervied. Exercise 1 asks you to show t he derivations. The results are
summarizedinTable18.3. It can beseen thatto minimize A,ri=R√qi//summationtext
j√qj.
TheSquare-root replicationrate( ∝√qi)ismorethanthatofUniform( ∝1), butlessthan that
ofProportional(∝qi). Ithas been shownthat
1. any allocation rate “in between” that of Uniform and of Pro portional has a lower average
search sizeAthan thatofUniformand Proportional,and
2. anyallocationrateeitherlessthanthatofUniform,orgr eaterthanthatofProportionalhasa
higheraveragesearch size AthanthatofUniformand Proportional.
18.3.5 Implementing Replication Strategies.
Proportional and Uniform can be trivally implemented. For P roportional, each query creates a
copy;forUniform,aﬁxed numberofcopies aremadewhen an obj ectiscreated.
The simple “path replication” scheme, wherein the number of copies made is proportional to
the length of the (successful) search path, implements Squa re-root replication. Here object iis
replicatedcn
ritimesperquery,where cissomeconstant. Then rican becaptured bythefollowing
equation:dri
dt=qicn
ri.
Leta=ln(ri
rj). Thenda
dt=cn(qj
r2
j−qi
r2
i)=1
rjdrj
dt−1
ridri
dt.
Square-root replication, wherein ri=RP√qi√qi, is a ﬁxed point solution of this equation.
Therefore, pathreplicationimplementsSquare-root repli cation.
The analysis implicitly assumes that replicas also get dele ted, in a way that is independent of
their object identity or query rate, and the lifetime of a rep lica is a non-decreasing function of its
age. (Policies such as random and FIFO satisfy this conditio n, but LRU and LFU do not.) Then,
duringsteadystate, thecreationrate can equalthedeletio nrate.
675
An alternate way of analyzing replication schemes is as foll ows. LetCbe the number of
replicas created on asuccessfulquery; Cisitsaverage. Then insteady state,
pi
pj=qiCi
qjCj. (18.8)
To implement distributed algorithms for various replicati on policies, it is necessary to deter-
mineCilocallywithoutknowing piorqi.
•ForProportional, Cis thesameforall objects.
•ForSquare-root, if Ci∝1/√qithenpi/pj=/radicalbig
qi/qj, bysubstitutingin Equation(18.8).
AsAi∝nR
piandpi∝qiCi, thereforeAi∝1
qiCi.
Withpathreplication ,Ci∝Ai,henceCi∝Ai∝1
qiCi.
In steady state, AiandCiare equal. Solving Ci∝1
qiCifor the ﬁxed point, Ci∝1√qi. As
pi∝qiCiwhenCiis steady, this gives pi∝√qi. In a practical implementation,it needs to
beensured thatconvergenceoccurs oncesteadystatesetsin .
18.4 ChordDistributedHashTable
18.4.1 Overview
The Chord protocol, proposed by Stoica et al. [29], uses a ﬂat key space to associate the map-
ping between network nodes and data objects/ﬁles/values. T he node address as well as the data
object/ﬁle/valueis mappedto alogicalidentiﬁerinthecom monkey spaceusingaconsistenthash
function. These mappings are illustrated in Figure 18.1. Bo th these mappings should ensure that
thekeysaredistributedroughlyequallyamongthenodes. Th isalsoinsuresthatwithhighprobabil-
ity,theoverheadofkeymanagementwhennodesjoinorleavet heP2Pnetworkislow. Speciﬁcally,
whenanodejoinsorleavesthenetworkhaving nnodes,only O(1/n)keysneedtobemovedfrom
onelocationtoanother.
The Chord key space is ﬂat, thus giving applications ﬂexibil ity in mapping their ﬁles/ data to
keys. Chord supports a single operation, lookup (x), that maps a given key xto a network node.
Speciﬁcally, Chord stores a ﬁle/object/valueat thenode to which theﬁle/object/value’skey maps.
Two stepsareinvolved.
1. Maptheobject/ﬁle/valueto itskeyin thecommonaddress s pace.
2. Map the key to the node in its native address space using lookup. The design of lookupis
themainchallenge.
InChord,anode’sIPaddressishashedtoa m-bitidentiﬁerwhichserversasthenodeidentiﬁer
inthecommonkey(identiﬁer)space. Similarly,theﬁle/dat akeyishashedtoa m-bitidentiﬁerthat
676
K87N5
N18
N23
N28 K28K8 K15K121
N99N104N115N119
N73
K53N63lookup(K8)
Figure 18.2: An example Chord ring with m= 7, showing mappings to the Chord address space,
and aquery lookupusingasimplescheme.
serves as the key identiﬁer. mis sufﬁciently large so that the probability of collisions d uring the
hashisnegligible. TheChordoverlayusesalogicalringofs ize2m. Theidentiﬁerspaceisordered
onthelogicalringmodulo 2m. Henceforthinthissection,wewillassumemodulo marithmetic. A
keykgetsassignedtotheﬁrstnodesuchthatitsnodeidentiﬁereq ualsorfollowsthekeyidentiﬁer
ofkin the common identiﬁer space. The node is the successor of k, denotedsucc(k). A Chord
ring form= 7is depicted in Figure 18.2. Nodes N5, N18, N23, N28, N63, N73, N99, N104,
N115 and N119 are shown. Six keys: K8, K15, K28, K53, K87, K121 are stored among these
nodes as follows. succ(8) = 18,succ(15) = 18 ,succ(28) = 28 ,succ(53) = 63 ,succ(87) = 99 ,
andsucc(121) = 5 .
18.4.2 Simple lookup
A simple key lookup algorithm that requires each node to stor e only 1 entry in its routing table
works as follows. Each node tracks its successor on the ring, in the variable succ; a query for
keyxis forwarded to the successors of nodes until it reaches the ﬁ rst node such that that node’s
identiﬁeryis greater than the key x, modulo 2m. The result, which includes the IP address of the
node with key y, is returned to the querying node along the reverse of the pat h that was followed
by thequery. Thismechanismrequires O(1)local spacebut O(n)hops,where nis thenumberof
nodes in the P2P network. The pseudo-code for this simple loo kup is given in Figure 18.3. The
following convention is assumed. Notation (x,y]represents the left-open right-closed segment of
the Chord logical ring modulo m. Notationx.Proc (·)is a RPC to execute Procon nodexwhile
x.varisa RPC toread thevariable varat processx.
Example: Thestepsforthequery: lookup(K8) initiatedat node 28 ,areshowninFigure18.2
usingarrows.
677
(variables)
integer:successor←−initial value;
(1)i.Locate_Successor (key), where key∝\⌉}atio\slash=i:
(1a)ifkey∈(i,successor ]then
(1b) return(successor )
(1c)else return successor.Locate _Successor (key).
Figure18.3: A simpleobject locationalgorithminChord at n odei.
18.4.3 Scalable Lookup
A scalable lookup algorithm that uses O(logn)message hops at the cost of O(logn)space in the
local routing tables, uses the following idea. Each node imaintains a routing table, called the
ﬁnger table , withO(logn)entries, such that the xth entry ( 1≤x≤m) is the node identiﬁer of
the nodesucc(i+ 2x−1). This is denoted by i.finger [x] =succ(i+ 2x−1). This is the ﬁrst node
whose key is greater than the key of node iby at least 2x−1modm. Note that each ﬁnger table
entry would have to contain the IP address and port number in a ddition to the node identiﬁer, in
order thatican communicatewith i.finger [x]; henceforth we will assumethis implicitlywithout
showingtheseentries.
The size of the ﬁnger table is bounded by mentries. Due to the logarithmic structure, the
ﬁnger table has more information about nodes closer ahead of it in the Chord overlay, than about
nodes further away. Given any key whose node is to be located, the highly scalable logarithmic
search shown in Figure 18.4 is used. For a query on key keyat nodei, ifkeylies between iand
its successor, the keywouldreside at the successorand the successor’saddress is returned. If key
lies beyond the successor, then node isearches throughthe mentries in its ﬁnger table to identify
the nodejsuch thatjmost immediately precedes key, among all the entries in the ﬁnger table.
Asjistheclosestknownnodethatprecedes key,jismostlikelytohavethemostinformationon
locatingkey,i.e., locatingtheimmediatesuccessornodetowhich keyhas been mapped.
Example: The use of the ﬁnger tables in answering the query lookup(K8) at node N28 is
illustratedin Figure18.5. TheﬁngertablesofN28, N99,and N5 thatareused areshown.
18.4.4 Managing Churn
Thecodetomanagedynamicnodejoins,departures, and failu resis giveninFigure18.6.
Node Joins. To create a new ring, a node iexecutesCreate_New_Ringwhich creates a ring
with the singleton node. To join a ring that contains some nod ej, nodeiinvokesJoin_Ring(j).
Nodejlocatesi’s successor on the logical ring and informs iof its successor. Before ican par-
ticipate in the P2P exchanges, several actions need to happe n:i’s successor needs to update its
predecessor entry to i,i’s predecessor needs to revise its successor ﬁeld to i,ineeds to identify
its predecessor, the ﬁnger table at ineeds to be built, and the ﬁnger tables of all nodes need to be
678
(variables)
integer:successor←−initial value;
integer:predecessor←−initial value;
array ofinteger finger [1... log n ];
(1)i.Locate_Successor (key), where key∝\⌉}atio\slash=i:
(1a)ifkey∈(i,successor ]then
(1b) return(successor )
(1c)else
(1d) j←−Closest_Preceding _Node(key);
(1e)return j.Locate_Successor (key).
(2)i.Closest _Preceding _Node(key), where key∝\⌉}atio\slash=i:
(2a)forcount =mdownto1do
(2b) iffinger [count]∈(i,key]then
(2c) break();
(2d)return(finger [count]).
Figure18.4: A scalableobjectlocationalgorithminChord a t nodei.
updated to account for i’s presence. This is achieved by procedures Stabilize (),Fix_Fingers (),
andCheck_Predecessor ()thatareperiodicallyinvokedby each node.
Figure 18.7 illustrates the main steps of the joining proces s. A recent joiner node ithat has
executedJoin_Ring(·)getsintegratedintothering bythefollowingsequence.
(a).Theconﬁgurationafterarecent joinernode ihas executed Join_Ring(·).
(b).NodeiexecutesStabilize (),whichallowsitssuccessor jtoadjustj’svariablepredecessor to
i. Speciﬁcally, when node iinvokesStabilize (), it identiﬁes the successor’s predecessor k.
Ifk∈(i,successor ),theniupdatesitssuccessor tok. Ineithercase, inotiﬁesitssuccessor
of itself via successor.Notify (i), so the successor has a chance to adjust its predecessor
variabletoi.
(c).The earlier predecessor kofj(i.e., the predecessor in Step (a)) executes Stabilize ()and
adjustsitssuccessor pointerfrom jtoi.
(d).NodeiexecutesFix_Fingers ()to build its ﬁnger table, and other nodes also execute the
proceduretoupdatetheirﬁngertablesifnecessary.
Onceallthesuccessorvariablesandﬁngertableshavestabi lized,acallbyanynodeto Locate_Successor (·)
will reﬂect the new joiner i. Until then, a call by to Locate_Successor (·)may result in the
Locate_Successor (·)callperformingaconservativescan. Theloopin Closest_Preceding _Node
that scans theﬁnger table will result in a search traversal u sing smaller hops rather than truly log-
arithmic hops, resulting in some inefﬁciency. Still, the no deiwill be located although via more
hops.
679
5+1
N104
N104
N104
N115
N115
N599+1
99+2
99+4
99+8
99+16
99+32N99N63N63N63N635+2finger table for N5
for N28for N99finger table
finger tableN73N63N23N18N18N18N18
5+645+325+165+85+4
N63N18N5
N23
N63
28+6428+3228+1628+828+428+228+1lookup(K8)
N6399+64 N63N73N119
N115
N104
N99K8
N28
Figure 18.5: An example showing a query lookup using the loga rithmically-structured ﬁnger ta-
bles.
Showing the correctness of the Chord protocol in the face of c oncurrent join operations and
stablize operations in which pointers are being rewired is n ontrivial. It can be shown that for any
set of concurrent join operations, at some point after the la st join operation completes, all the
pointers and ﬁnger tables will be correct. However, in the tr ansient period before the Chord ring
stabilizes,an objectsearch can result inthreeoutcomes.
•Theﬁngertablesusedinasearchareuptodateandthecorrect successorofthekeyissought
inO(logn)hops.
•The ﬁnger tables are not up to date but the successor pointers are correct. The sought key
will be located but may take more steps as the full advantage o f a logarithmicsearch space
pruningcannotbeused.
•If the successor pointers are incorrect, or the key transfer to the new joiners in procedure
Notifyhas not completed, the search may fail. This is during a trans ient duration, and the
sourcehas thechoiceofreissuingthequery.
Node Failures and Departures. When a node jfails abruptly, its successor ion the ring will
discover the failure when the successor iexecutesCheck_Predecessor ()periodically. Process i
getsachancetoupdateits predecessor ﬁeld whenanothernode kcausesitoexecuteNotify (k).
But that can happen onlyif k’ssuccessor variableisi. This requires thepredecessor of thefailed
node to recognize that its successor has failed, and get a new functioning successor! In fact, the
successor pointers are required for object search; the pred ecessor variables are required only to
accommodate new joiners. Note from Figure 18.4 that knowing that the successor is functional,
and thatthenodespointedtoby theﬁnger pointersarefuncti onal,isessential.
Example: In Figure 18.5, assume that node N63 fails. The closest succe ssor that node N28 can
680
(variables)
integer:successor←−initial value;
integer:predecessor←−initial value;
array ofinteger finger [1... log m ];
integer:next_finger←−1;
(1)i.Create_New_Ring():
(1a)predecessor←−⊥;
(1b)successor←−i.
(2)i.Join_Ring(j), where jis anynode onthe ring to bejoined:
(2a)predecessor←−⊥;
(2b)successor←−j.Locate_Successor (i).
(3)i.Stabilize ()://executed periodically to verify and inform successor
(3a)x←−successor.predecessor ;
(3b)ifx∈(i,successor )then
(3c) successor←−x;
(3d)successor.Notify (i).
(4)i.Notify (j)://jbelieves itispredecessor of i
(4a)ifpredecessor =⊥orj∈(predecessor,i ))then
(4b) transfer keys in the range [j,i)toj;
(4c) predecessor←−j.
(5)i.Fix_Fingers ()://executed periodically to update the ﬁngertable
(5a)next_finger←−next_finger + 1;
(5b)ifnext_finger > m then
(5c) next_finger←−1;
(5d)finger [next_finger ]←−Locate_Successor (i+ 2next_finger−1).
(6)i.Check_Predecessor ()://executed periodically toverify whether predecessor sti ll exists
(6a)ifpredecessor has failed then
(6b) predecessor←−⊥.
Figure18.6: Managingchurn in Chord. Code shownis fornode i.
ﬁndviatheﬁngertableisN99. N73cannotbedetected,andkey sK64throughK73willeffectively
belost.
Asolutionsuchasintroducinga Check_Successor ()procedureanalogousto Check_Predecessor
procedure will not solvetheproblem because it does not help to identify the functional successor.
The Chord protocol proposes that rather than maintain a sing le successor, each node maintains a
listofαsuccessors,whicharethenode’sﬁrst αsuccessors. Iftheﬁrstsuccessordoesnotrespond,
the node can try the next successor from the list, and so on. On ly the simultaneous failure of all
theαsuccessorscan thencausetheprotocoltofail. Maintaining alistofsuccessorsrequiressome
681
successor=j
predecessor=i predecessor=ipredecessor=i
j
i
j
i ijj
i
successor=i successor=ik
predecessor=ksuccessor=j
predecessorsuccessor
(c) after k executes Stabilize(), that  (a) after i executes Join_Ring(.)
(d) after i executes Notify(k)
triggers step (d)j executes Notify(i)(b) after i executes Stabilize() and 
TT
T
predecessor=k successor=j successor=jsuccessor=j successor=j
ksuccessor=predecessor= successor=
predecessor=kpredecessor=
k
predecessor=
Figure18.7: Steps intheintegrationofnode iinthering,where j >i>k .
changes to thecode in Figure 18.6. Exercise2 asks youto adap t thiscode to thechanges required
formaintainingsuccessorlists.
Theprovisionforasuccessorlistateachnodeprovidesanat uralmechanismfortheapplication
to manage replicated objects. The replicas get placed at the node corresponding to the object key,
as well as at the nodes in the successor list of that node. As Ch ord is able to update its successor
list as the successor list changes, Chord can also interface with the application to let it track the
locationsofthereplicas.
A voluntary departure from the ring can be treated as a failur e. However, a failed node causes
all the data (keys) stored at that node to be lost until correc tive action is taken. When a node
departs voluntarily, it should ﬁrst transfer all the keys it is responsible for to its successor. The
departing node should also inform its successor and predece ssor. This will enable the successor
to update its predecessor to the predecessor of the departin g node. The predecessor will also be
abletoupdateitssuccessorlistbydeletingthedepartingn odeand addingthelastsuccessorofthe
departingnode’ssuccessorlisttoitsownsuccessorlist.
18.4.5 Complexity
The followingresults on thecomplexityhavea nontrivialco rrectness proof and interested readers
shouldconsulttheChord papers fortheproofs.
1. For a Chord network with nnodes, each node is responsible for at most (1 +ǫ)K/nkeys,
with“highprobability”,where Kisthetotalnumberofkeys.
Usingconsistenthashing, ǫcanbeshowntobeboundedby O(logn). The“highprobability”
clauseisrequired becausethevalidityoftheresultdepend s ontherandomnessandconﬂict-
free mappingsofthehash functionused.
682
2. The search for a successor in Locate_Successor in a Chord network with nnodes requires
timecomplexity O(logn)withhighprobability.
Thisresultisbasedontheobservationthatassumingcomple telyrandomdistributionsofthe
key mappings and node mappings, after 2lognhops, the distance between the key being
searched forand thepresentnodethatthequery hasreached i sat most 1/n.
3. Thesizeoftheﬁngertableis log(n)≤m.
4. Theaveragelookuptimeis 1/2log(n).
Exercises2and3,basedontheChordpapers,askyoutoprovef urtherresultsaboutthecomplexity
underchurn conditions.
18.5 ContentAddressibleNetworks: CAN
18.5.1 Overview
A content-addressible network (CAN) is essentially an inde xing mechanism that maps objects to
theirlocationsinthenetwork. TheCANprojectoriginatedf romtheobservationthatthebottleneck
todesigningascalableP2Pnetworkisthisindexingmechani sm. AnefﬁcientandscalableCANis
useful not only for object location in P2P networks, but also for large-scale storage management
systems and wide-area name resolution services that decoup le name resolution and the naming
scheme. Alltheseapplicationsinherentlyrequireefﬁcien t and scalableadditionofand locationof
objectsusingarbitrary location-independentnamesorkey sfortheobjects.
A CAN supports three basic operations: insertion, search, a nd deletion of (key, value) tuples.
(A“value”isanobjectinthecontextofaCAN.)AgoodCANdesi gnisdistributed,fault-tolerant,
scalable, independent of the naming structure, implementa ble at the application layer, and auto-
nomic,i.e.,self-organizingandself-healing. AlthoughCANisa genericphrase,italsospeciﬁcally
denotes the particular design of a CAN proposed by Ratnasamy et al. [24]. We now study this
particularCAN design.
CAN is a logicald-dimensional Cartesian coordinate space organized as a d-torus logical
topology, i.e., a virtual overlay d-dimensional mesh with wrap-around. A two-dimensional tor us
was shown in Figure ??, Chapter 1. The entire space is partitioned dynamically among all the
nodes present, so that each node iis assigned a disjoint region r(i)of the space. As nodes arrive,
depart,orfail,thesetofparticipatingnodes,aswellasth eassignmentofregionstonodes,change.
For any object v, its keyk(v)is mapped using a deterministic hash function to a point /vector pin
the Cartesian coordinate space. The (k,v)pair is stored at the node that is presently assigned the
region that contains the point /vector p. In other words, the (k,v)pair is stored at node iif presently the
point/vector pcorrespondingto (k,v)liesinregion r(i). Analogously,toretrieveobject v,thesamehash
function is used to map its key kto the same point /vector p. The node that is presently assigned the
region that contains /vector pis accessed (using a CAN routing algorithm) to retrieve v. The three core
componentsofaCAN designarethefollowing.
683
1. Setting up the CAN virtual coordinate space, and partitio ning it among the nodes as they
jointheCAN.
2. Routinginthevirtualcoordinatespacetolocatethenode thatisassignedtheregioncontain-
ing/vector p.
3. MaintainingtheCAN dueto nodedepartures and failures.
18.5.2 CAN Initialization
1. Each CAN is assumed to have a unique DNS name that maps to the IP address of one or
a few bootstrap nodes of that CAN. A bootstrap node is respons ible for tracking a partial
listofthenodesthatitbelievesarecurrentlyparticipati ngintheCAN. Thesearereasonable
assumptions,and perhaps themost“non-distributed”porti onsoftheCAN design.
2. To join a CAN, the joiner node queries a bootstrap node via a DNS lookup, and the boot-
strap node replies with the IP addresses of some randomly cho sen nodes that it believes are
participatingin theCAN.
3. The joiner chooses a random point /vector pin the coordinate space. The joiner sends a request to
one of the nodes in the CAN, of which it learnt in Step 2, asking to be assigned a region
containing/vector p. The recipient of the request routes the request to the owner old_owner (/vector p)of
theregioncontaining /vector p, usingtheCAN routingalgorithm.
4. Theold_owner (/vector p)node splits its region in half and assigns one half to the join er. The
region splitting is done using an a priori ordering of all the dimensions, so as to decide
whichdimensiontosplitalong. Thisalsohelpstomethodica llymergeregions,ifnecessary.
The(k,v)tuples for which the key know maps to the zone to be transferred to the joiner,
arealso transferred to thejoiner.
5. The joiner learns the IP addresses of its neighbours from old_owner (/vector p). The neighbors are
old_owner (/vector p)anda subsetoftheneighboursof old_owner (/vector p).old_owner (/vector p)also updates
itssetofneighbours. Thenewjoineraswellas old_owner (/vector p)informtheirneighboursofthe
changes tothespaceallocation,sothat thattheyhavecorre ct informationabouttheirneigh-
bourhood and can route correctly. In fact, each node has to se nd an immediateupdate of its
assignedregion,followedbyperiodicHEARTBEAT refreshme ssages,toallitsneighbours.
When a node joins a CAN, only the neighbouring nodes in the coo rdinate space are required to
participate in the joining process. The overhead is thus of t he order of the number of neighbours,
whichisO(d)and independentof n, thenumberofnodesin theCAN.
684
18.5.3 CAN Routing
CAN routing uses the straight-line path from the source to th e destination in the logical Eu-
clidean space. This routing is realized as follows. Each nod e maintains a routing table that
tracks its neighbour nodes in the logical coordinate space. Ind-dimensional space, nodes x
andyare neighbours if the coordinate ranges of their regions ove rlap ind−1dimensions, and
abut in one dimension. All the regions are convexand can be characterized as follows. Let
region (x) = [[x1
min,x1
max],...[xd
min,xd
max]]. Letregion (y) = [[y1
min,y1
max],...[yd
min,yd
max]].
Nodesxandyare neighbours if there is some dimension jsuch thatxj
max=yj
minand for all
other dimensions i,[xi
min,xi
max]and[yi
min,yi
max]overlap. An example of neighbouring nodes in
2-dimensionalspaceisshowninFigure18.8.
4 5
[[75,100],
[25,50]]
6
[[75,100],
[0,25]]
7[[50,75],
[0,50]]
[[0,0],[50,50]][[0,25],
[50,100]][[25,50],
[50,100]]
3(100,100) (0,100)
(0,0) (100,0)[[50,50],[100,100]]
1 2
Figure18.8: Two-dimensionalCANspace. Sevenregionsares hown. Thedashedarrowsshowthe
routingfromnode2 tothecoordinate /vector pshownby theshadedcircle.
The routing table at each node tracks the IP address and the vi rtual coordinate region of each
neighbour. Tolocatevalue v,itskeyk(v)ismappedtoapoint /vector pwhosecoordinatesareusedinthe
message header. Knowing the neighbours’ region coordinate s, each node follows simple greedy
routing by forwarding the message to that neighbour having c oordinates that are closest to the
destination’s coordinates. To implement greedy routing to a destination node x, the present node
routesa messagetothat neighbouramongtheneighbours k∈Neighbours , givenby
argmin k∈Neighbours [min|/vector x−/vectork|]
Here,/vector xand/vectorkare thecoordinatesofnodes xandk.
Assuming equal-sized zones in d-dimensional space, the average number of neighbours for a
node isO(d). The average path length isd
4·n1/d. The implication on scaling is that each node
has about the same number of neighbours and needs to maintain about the same amount of state
information, irrespective of the total number of nodes part icipating in the CAN. In this respect,
685
the CAN structure is superior to that of Chord. Also note that unlike in Chord, there are typically
many paths for any given source-destination pair. This grea tly helps for fault-tolerance. Average
pathlengthin CAN scales as O(n1/d)as opposedto lognforChord.
18.5.4 CAN Maintainence
When a node voluntarily departs from CAN, it hands over its re gion and the associated database
of(key,value )tuples to one of its neighbours. The neighbour is chosen as fo llows. If the node’s
region can be merged with that of one of its neighbours to form a valid convex region, then such
a neighbouris chosen. Otherwise the node’s region is handed over to the neighbourwhose region
hasthesmallestvolumeorload–theregionsarenotmergedan dtheneighbourhandlesbothzones
temporarily until a periodic background region reassignme nt process runs to integrate the regions
and preventfurtherfragmentation.
CAN requires each node to periodically send a HEARTBEAT upda te message to each neigh-
bour, giving its assigned region coordinates, the list of it s neighbours, and their assigned region
coordinates. When anodedies, theneighbourssuspectitsde ath and initiateaTAKEOVERproto-
coltodecidewhowilltakeoverthecrashednode’sregion. De spitethisTAKEOVERprotocol,the
(key,value )tuples in the crashed node’s database remain lost until the p rimary sources of those
tuples refresh the tuples. Requiring the primary sources to periodically issue such refreshes also
servesthedualpurposeofupdatingstale(dirty)objectsin theCAN.
The TAKEOVER protocol is as follows. When a node suspects tha t a neighbour has died, it
starts a timer in proportion to its region’s volume. On timeo ut, it sends a TAKEOVER message,
with its region volume piggybacked on the message, to all the neighbours of the suspected failed
node. When a TAKEOVER message is received, a node cancels its bid to take over the failed
node’s region if the received TAKEOVER message contains a sm aller region volume than that
of the recipient’s region. This protocol thus helps in load b alancing by choosing the neighbour
whose region volume is the smallest, to take over the failed n ode’s region. As all nodes initiate
the TAKEOVER protocol, the node taking over also discovers i ts neighbours and vica versa. In
the case of multipleconcurrent node failures in one vicinit yof the Cartesian space (this is rare), a
morecomplexprotocolusingaexpandingringsearch fortheT AKEOVERmessages can beused.
Agracefuldepartureaswellasafailurecanresultinaneigh bourholdingmorethanoneregion
if its region cannot be merged with that of the departed or fai led node. To prevent the resulting
fragmentationandrestorethe 1→1nodetoregionassignment,thereisabackgroundreassignme nt
algorithm that is run periodically. Conceptually, conside r a binary tree whose root represents the
entire space. An internal node represents a region that exis ted earlier but is now split into regions
representedbyitschildrennodes. Aleafrepresentsacurre ntlyexistingregion,and(tooverloading
thesemanticsand thenotation),also thenodethatrepresen ts that region.
When aleaf node xfails ordeparts,thereare twocases.
1. If its sibling node yis also a leaf, then the regions of xandyare merged and assigned to y.
The region corresponding to the parent of xandybecomes a leaf and it is assigned to node
686
y.
2. If the sibling node yis not a leaf, run a depth-ﬁrst search in the subtree rooted at yuntil a
pairofsiblingleaves(say, z1andz2)isfound. Mergetheregionsof z1andz2,makingtheir
parentzaleaf node, assignthe merged region to node z2, and the regionof xis assignedto
nodez1.
Figure18.9 illustratesthisreassignment. Ifnode2 fails, itsregionis assignedto node3. Ifnode7
fails, regions 5 and 6 get merged and assigned to node 5 wherea s node 6 is assigned the region of
thefailednode7.
1
25
34
6
71
2 3 4
67
5(entire coordinate space) root
Figure18.9: Exampleshowingregionreassignmentin aCAN.
A distributed version of the above depth-ﬁrst centralized t ree traversal can be performed by
the neighbours of a departed node. The distributed traversa l leverages the fact that when a region
is split, it is done in accordance to a particular ordering on the dimensions. Node iperforms its
part of thedepth-ﬁrst traversal (initiatedby thenodeto wh ich theregion ofthedeparted node xis
assignedintheTAKEOVERprotocol)as follows.
1. Identifythehighestordereddimension dim athathastheshortestcoordinaterange [idima
min,idimamax].
Nodei’sregionwas lasthalvedalong dimension dim a.
2. Identify neighbour jsuch thatjis assigned the region that was split off from i’s region in
the last partition along dimension dim a. Nodej’s region abuts i’s region along dimension
dim a.
3. Ifj’sregionvolumeequals i’sregionvolume,thetwonodesaresiblingsandtheregionsc an
be combined. This is the terminating case of the depth-ﬁrst t ree search for siblings. Node
jis assigned the combined region, and node itakes over the region of the departed node x.
This takeover by node iis done by returning the recursive search request to the orig inator
node,and communicating i’s identityonthereplies.
4. Otherwise, j’s region volume must be smaller than i’s region volume. Node iforwards a
recursivedepth-ﬁrstsearch requestto j.
687
18.5.5 CAN Optimizations
The followingdesign techniques aim to improveone or more of the performance factors: the per-
hop latency, the path length, fault tolerance, availabilit y, and load balancing. These techniques
typicallydemonstratea trade-off.
1.Multipledimensions. Asthepathlengthis O(d·n1/d),increasingthenumberofdimensions
decreases the path length and increases routing fault toler ance at the expense of larger state
spacepernode.
2.Multiple realities. A coordinate space is termed as a reality. The use of multiple indepen-
dent realities assigns to each node a different region in eac h different reality. This implies
that in each reality, the same node will store different (k,v)tuples belonging to the region
assigned to it in that reality, and will also have a different neighbour set. The data contents
(k,v)getreplicatedineachreality,leadingtohigherdataavail ability. Furthermore,themul-
tiplecopies of each (k,v)tuple, onein each reality, offer a choice – the closest copy c an be
accessed. Routingfaulttolerancealsoimprovesbecauseea ch realityoffers asetofdifferent
paths to the same (k,v)tuple. All these advantages come at the cost of more storage – for
state information for the neighbours in each reality, as wel l as for the (k,v)tuples mapped
totheregionallocatedto anodeineach reality.
3.Delay latency. Rather than using just the Cartesian distance as a metric to m ake routing
decisions, the delay latency (measured using round-trip ti meRTT) on each of the candidate
logicallinkscan alsobeused inmakingtheroutingdecision .
4.Overloadingcoordinateregions. Eachregioncanbesharedbymultiplenodes,uptosome
upper limit. This offers several advantages. First, the pat h length and path latency get
reduced because overloading is equivalent to having fewer n odes in the CAN. Second, the
faulttoleranceimprovesbecausearegionbecomesemptyonl yifallthenodesassignedtoit
depart or fail concurrently. Third, the per-hop latency dec reases because a node can select
theclosestnodefromtheneighbouringregiontoforwardame ssagetowardsthedestination.
The cost of gaining these advantages is that many of the aspec ts of the basic CAN protocol
needtobereengineeredtoaccommodateoverloadingofcoord inateregions(SeeExercise5).
5.Multiple hash functions. The use of multiple hash functions maps each key to different
points in the coordinate space. This replicates each (k,v)pair for each hash function used.
Theeffect issimilartothat ofusingmultiplerealities.
6.Topologicallysensitiveoverlay. TheCANoverlaydescribedsofarhasnocorrelationtothe
physicalproximityortotheIPaddressesofdomains. Logica lneighboursintheoverlaymay
begeographicallyfarapart,andlogicallydistantnodesma ybephysicalneighbours. Bycon-
structingan overlaythat accounts for physicalproximityi n determininglogicalneighbours,
theaveragequerylatency can besigniﬁcantlyreduced.
688
18.5.6 CAN Complexity
The time overhead for a new joiner is O(d)for updating the new neighbours in the CAN, and
O(d/4·log(n))for routing to the appropriate location in the coordinate sp ace. This is also the
overhead in terms of the number of messages. The time overhea d and the overhead in terms of
the number of messages for a node departure is O(d2), because the TAKEOVER protocol uses a
message exchange between each pair of neighbours of the depa rted node. Exercise 4 asks you to
computethecomplexityofthedistributedregionreassignm entprotocol.
18.6 Tapestry
18.6.1 Overview
The Tapestry P2P overlay network provides efﬁcient scalabl e location-independent routing to lo-
cate objects distributed across the Tapestry nodes. Much of the design is adapted from an earlier
design of Plaxton trees. The notable enhancements of Tapest ry include dealing with node churn
as well as dynamicaddition and deletion of objects. As in Cho rd, nodes as well as objects are as-
signedidentiﬁersobtainedbymappingfromtheirnativenam espacestoacommonlargeidentiﬁer
space usinga uniformlydistributedhash function such as SH A-1. Thehashed nodeidentiﬁers are
termed VIDs and the hashed object identiﬁers are termed as GU IDs (acronym for globallyunique
ids). For brevity, a speciﬁc node v’s identiﬁer is denoted vidand a speciﬁc object O’s GUID is
denotedOG.
18.6.2 Overlay andRouting
18.6.2.0.1 RootandSurrogateRoot. Tapestryusesacommonidentiﬁerspacespeciﬁedusing
mbit values. This identiﬁer is typically expressed in hexade cimal notation, i.e., base b= 16and
presently Tapestry recommends m= 160. Each identiﬁer OGin this common overlay space is
mapped to a set of uniquenodes that exists in the network, termed as the identiﬁer’ s r oot set
denotedOGR. Typically,|OGR|is a small constant, and the main purpose of having |OGR|>1is
to increase fault-tolerance. In our discussion, we assume |OGR|= 1, and refer to a root node of
OGasOGR.
If there existsa node vsuch thatvid=OGR, thenvis the root of identiﬁer OG. If such a node
does not exist, then a globally known deterministic rule is u sed to identify another unique node
sharingthelargestcommonpreﬁxwith OG,thatactsasthe surrogate root. Toaccessobject O,the
goalistoreachtheroot OGR(whetherrealorsurrogate). Routingto OGRisdoneusingdistributed
routing tables that are constructed using preﬁx routing information. Preﬁx routing in Tapestry
is somewhat analogous to preﬁx routing within the telephone network, or to address allocation
in the Internet using Classless InterDomain Routing (CIDR) . Unlike the telephone numbers or
CIDR-assignedIPaddresses,Tapestry’sVIDsareinavirtua lspacewithoutcorrelationtotopology,
however,topologicalinformationcan beused toselect node sthatare “close”as persomemetric.
689
7C27
7C217C2B
44
1122
23
33140672
9833AA21
71147DD0
7C4A
7C137CFF7B28
7C25
Figure 18.10: Some example links of the Tapestry routing mes h at node with identiﬁer “7C25”.
Threelinksfromeach level1through4 arelabeled bytheleve l.
18.6.2.0.2 PreﬁxRouting. Preﬁxroutingatanynodetoselectthenexthopisdonebyincr eas-
ing the preﬁx match of the next hop’s VID with the destination OGR. Thus, a message destined
forOGR= 62C35could be routed along nodes with VIDs 6****, then 62***, then 62C**, then
62C3*, andthen to62C35. Let M= 2m. Theroutingtableat node vidcontainsb·logbMentries,
organized in logbMlevelsi= 1...log bM. Each entry is of the form ∝a\}⌊ra⌋k⌉tl⌉{twid,IPaddress∝a\}⌊ra⌋k⌉tri}ht. In level
i, therearebentries withthefollowingproperty.
•Each entry denotes some “neighbour” node VIDs with a (i−1)-digit preﬁx match with vid
– thus, the entry’s widmatchesvidin the (i−1)-digit preﬁx. Further, in level i, for each
digitjin the chosen base (e.g., 0,1,...E,F whenb= 16), there is an entry for which the
ithdigit position is j. Speciﬁcally, the jthentry (counting from 0) in level ihas valuejfor
digit position i. Let anidigit preﬁx of vidbe denoted as prefix (vid,i). Then thejthentry
(countingfrom0)inlevel ibeginswithan i-digitpreﬁx prefix (vid,i−1)◦j. Forexample,
theﬁfth entryin level2 at node9F248 willbe94***,thushavi nga2-digitpreﬁx “94”.
18.6.2.0.3 RouterTable. Thenodesintheroutertableat vidaretheneighbours intheoverlay,
and these are exactly the nodes with which vidcommunicates. A part of the routing mesh at one
node is shown in Figure 18.10. For each forward pointer from nodevtov′, there is a backward
pointerfromv′tov. Observethefollowingregardingtheroutertableconstruc tion.
•Thereisachoiceofwhichentrytoaddintheroutertable. For example,the jthentryinlevel
ican be the VID of any node whose i-digit preﬁx is determined; the (m−i)-digit sufﬁx
can vary. The ﬂexibilityis useful to select a node that is “cl ose”, as deﬁned by somemetric
space (e.g., round-trip time). In fact, this choice also all ows a more fault-tolerant strategy
for routing. Multiple VIDs can be stored in the routing table , as follows. For each preﬁx
βof a nodev’s identiﬁer and for each digit j∈{0...b−1}in the alphabet, deﬁne the
neighbour setNv
β,jas the set of all nodes whose identiﬁers share preﬁx β◦j. The nodes in
thisneighboursetarealsoreferredtoas (β,j)neighboursof v. Thebsets,oneforeachvalue
690
(variables)
array ofarray of integer Table[1... log b2m,1... b]; //routing table
(1)NEXT_HOP(i,OG=d1◦d2...◦dlogbM)executed at node vidto route to OG:
//iis (1+length oflongest common preﬁx), also level of thetable
(1a)while Table[i,di] =⊥do//djisith digit of destination
(1b) di←−(di+ 1)modb;
(1c)ifTable[i,di] =vthen //node valso acts asnext hop (special case)
(1d) return NEXT_HOP(i+ 1,OG)//locally examine next digit ofdestination
(1e)else return (Table[i,di]). //node Table[i,di]is nexthop
Figure 18.11: Routing in Tapestry. The logic for determinin g the next hop at a node with node
identiﬁerv,1≤v≤n, based on the ithdigit ofOG, i.e., based on the digit in the ithmost
signiﬁcantpositionin OG.
ofj, form the routing table of level |β|+ 1.|Nv
β,j|grows exponentially as |β|decreases, so
the size of this set can be limited by a predetermined paramet erc. The closest node in each
setis theprimary neighbour. Thusthesizeoftheroutingtab leis:c·b·logβM.
Theroutefrom v0
id(source)todestination j1◦j2...◦jlog m,isvianodes v1,v2...vlog m,where
v1∈Nv0
⊥,j1(ﬁrst hop),v2∈Nv1
j1,j2(second hop), v1∈Nv2
j1◦j2,j3(third hop), and so on. The
primary neighbour is chosen at each hop. Observe that this pr ovideslocation-independent
routing,i.e.,irrespectiveofthesource, thesameuniquer oot nodeis reached.
•Thejthentry in level imay not exist because no node meets the criterion. This is a holein
theroutingtable. Statedmoregenerally, |Nv
β,j|maybe0,signifyingaholefordigit jatlevel
|β|+ 1.
Surrogate routing can be used to route around holes. If the jthentry in level ishould be
chosen but is missing, route to the next non-empty entry in le veli, using wraparound if
needed. All the levels from 1 to logb2mneed to be considered in routing, thus requiring
logb2mhops. The code for determining the next hop using NEXT_HOP (i,OG)is shown
inFigure18.11. Thisisinvokedas NEXT_HOP (1,OG)at thesourcenode. To determine
hopiof the route, the node vthat executes the function has a preﬁx at least i−1digits in
commonwith OG.
Example: An exampleofroutingisshownin Figure18.12.
P1.Surrogateroutingleadsto auniqueroot.
If the routing were to lead to different nodes AandB, let the most signiﬁcant position in
which the digits of AandBdiffer bei. This implies level irouting caused the routing
at some nodes XandYalong different digits. However, the ﬁrst idigits do not change
henceforth, and assuming synchronized routing tables, the holes would be consistent in the
tables atXandY. Hence both should route to the same ith digit, which is a contradiction.
It can nowbeseen that:
691
62C3A
64000 FAB1162C3A
6C1446240962C1162C35
62C2444 4
5
5
5
4
3432
4
3
12265011 62006
62CAB62C79 62CFF
62C0162C31
62655
Figure18.12: AnexampleofroutingfromFAB11to62C35. Then umbersonthearrowsshowthe
leveloftheroutingtableused. Thedashedarrows showsomeu nusedlinks.
P2.The routing algorithm identiﬁes for each identiﬁer vid, a uniquespanning tree rooted at
vid.
18.6.3 Object Publication and Object Search
Theuniquespanningtreeused torouteto vidisused topublishand locatean object whoseunique
root identiﬁer OGRisvid. A server S that stores object Ohaving GUID OGand rootOGRperiod-
ically publishes the object by routing a publishmessage from StowardsOGR. At each hop and
including the root node OGR, thepublishmessage creates a pointer to the object. Ideally, “each
node between OandOGRmust maintain a pointer to Odespite churn”. (Note that the publishing
is done by each server at which a replica of the object resides , as well as for each GUID of the
object. Recall that an object can be assigned multiple GUIDs , each mapping to a different root
node, and giving rise to the set of root nodes OGR.) If a node lies on the path from two or more
servers storing replicas, that nodewill storea pointerto e ach replica, sorted in terms of a distance
metric(suchaslatencyfromitself). Thisisthedirectoryi nformationforobjects,andismaintained
asasoft-state,i.e.,itrequiresperiodicupdatesfromtheserver,todeal withchangesandtoprovide
fault-tolerance.
Example: An example showing publishing of an object with OG= 72EA1 by two replicas, at
1F329 andC2B40 isshownin Figure18.13.
To search for an object Owith GUID OG, a client sends a query destined for the root OGR.
Along thelogb2mhops, if a node ﬁnds a pointer to the object residing on server S, the node
redirects the query directly to S. Otherwise, it forwards the query towards the root OGRwhich is
guaranteed to have the pointer for the location mapping. A qu ery gets redirected directly to the
objectassoonasthequerypathoverlapsthepublishpathtow ardsthesameroot. Eachhoptowards
theroot reduces thechoiceoftheselectionofitsnextnodeb yafactorof b; hence, themorelikely
by a factor of bthat a query path and a publish path will meet. Furthermore, a s the next hop is
chosen based on the network distance metric whenever there i s a choice, we also observe that the
692
72EA872EA1
object pointer72F1172E347826C
1F329 25011
routing pointer publish pathBCF35
server server094ED
C2B40 1720275BB1 7D4FF729CC 720B472E33
706667FAB1
Figure 18.13: An example showing publishing of object with i dentiﬁer 72EA1 at two replicas
1F329 andC2B40.
closer the client is to the server in terms of the distance met ric, the more likely that their paths to
theobjectrootwillmeet sooner,and thefasterthequerywil lberedirected to theobject.
Example: Consider the object OGwhich has identiﬁer 72EA1 and two replicas at 1F329 and
C2B40, as shownin Figure 18.13. A query for the object from 09 4ED will ﬁnd the object pointer
at 7FAB1. A query from 7826C will ﬁnd the object pointer at 72F 11. A query from BCF35 will
ﬁnd theobjectpointerat 729CC.
18.6.4 Node Insertion
Whennodesjointhenetwork,theresultshouldbethesameast houghthenetworkandtherouting
tables had been initialized with the nodes as part of the netw ork. The procedure for the insertion
ofnodeXshouldmaintainthefollowingpropertyofTapestry:
P3. Foranynode Yon thepathbetween apublisherofobject Oandtheroot GOR, nodeYshould
haveapointerto O.
Moregenerally,theinsertionshouldsatisfythefollowing properties.
•Nodes which have a hole in their routing table should be notiﬁ ed if the insertion of node X
can ﬁll thathole.
•IfXbecomes the new root of existing objects, references to thos e objects should now lead
toX.
•Theroutingtablefornode Xmustbeconstructed.
•Thenodesnear Xshouldinclude Xintheirroutingtablestoperformmoreefﬁcientrouting.
Themainstepsin nodeinsertionareoutlinedhere.
693
•NodeXusessomegatewaynodeintotheTapestrynetworktorouteame ssagetoitself. This
leads to its “surrogate”, i.e., the root node with identiﬁer closest to that of itself (which is
Xid). The surrogate Zidentiﬁes the length αof the longest common preﬁx that Zidshares
withXid.
•NodeZinitiatesaMULTICAST-CONVERGECAST onbehalfof Xbyessentiallycreating
alogicalspanningtreeasfollows. Actingasaroot, Zcontactsallthe (α,j)nodes,forall j∈
{0,1...b−1}(treelevel1). Thesearethenodeswithpreﬁx αfollowedbydigit j. Eachsuch
(level1)node Z1contactsallthe (prefix (Z1,|α|+ 1),j)nodes,forall j∈{0,1...b−1}
(treelevel2). Thiscontinuesup tolevel logb2m−|α|and completestheMULTICAST.The
nodes at this level are the leaves of the tree, and initiateth e CONVERGECAST, which also
helpsto detecttheterminationofthisphase.
All the nodes contacted ﬁll in any holes in their routing tabl e and, if necessary, transfer
any references of pointers that are rooted locally. All thes e nodes also contact Xwith their
information, so that Xcan build its routing table from level |α|+ 1up tologb2m. All these
nodesthat contact Xhavea commonpreﬁx of α.
To construct the rest of its routing table from levels 1 throu gh|α|, nodeXprocures similar
listsforsuccessivelysmallerpreﬁxesuntilitgetscloses tbnodesmatchingtheemptypreﬁx.
NodeXbegins with the list of nodes for level α, corresponding to the level lof its routing
table which is already ﬁlled. To construct the level l−1list, nodeXcontacts all the nodes
in the level llist to ﬁnd out all the level l−1nodes they know about by asking for both
forwardpointersandbackwardpointers. Level l−1oftheroutingtableisﬁlledinusingthe
Kclosest nodes from the level l−1list, for each of the digits 0...b−1. In this manner,
Xcompletes its routing table, and all the nodes contacted in t he process can optimize their
routingtablesbyusing Xifithelps.
Theinsertionprotocolsare fairlycomplexand deal withcon currentinsertions.
18.6.5 Node Deletion
When anode AleavestheTapestryoverlay,thefollowingactionsareperf ormed.
•NodeAinforms the nodes to which it has (routing) backpointers. It also provides them
with replacement entries for each level from its routing tab le. This is to prevent holes in
their routing tables. (The notiﬁed neighbours can periodic ally run the nearest neighbour
algorithmto ﬁne-tunetheirtables.)
•Theserverstowhich Ahasobjectpointersarealsonotiﬁed. Thenotiﬁedserversse ndobject
republishmessages.
•Duringtheabovesteps,node Aroutesmessagestoobjectsrootedatitselftotheirnewroot s.
On completion of the above steps, node Ainforms the nodes reachable via its backpointers
and forward pointersthatitis leaving,and thenleaves.
694
Nodes failures are handled by using the redundancy that is bu ilt in to the routing tables and
object location pointers. For example, each routing table e ntry has up to cneighbours in the
neighbour setNv
β,j. A nodeXdetects a failure of another node Aby using soft-state beacons or
whenanodesendsareplybutdoesnotgetaresponse. Node Xupdatesitsroutingtableentryfor A
withasuitablesubstitutenode,runningthenearestneighb ouralgorithmifnecessary. If A’sfailure
leaves a hole in the routing table of X, thenXcontacts the suggorate of Ain an effort to identify
a nodeto ﬁll the hole. Thedetails of theprotocol can be found in the Tapestry papers. In addition
torepairing theroutingmesh,theobjectlocationpointers alsohaveto beadjusted. Objectsrooted
at the failed node may be inaccessible until the object is rep ublished. The protocols for doing
so essentially have to (i) maintain path availability, and ( ii) optionally collect garbage/dangling
pointerswhichwouldotherwisepersistuntilthenextsoft- staterefresh and timeout.
Overall,experimentshaveshownthatTapestrycontinuesto performwellwithhighprobability
despitedynamicnodeinsertionsand failures.
Complexity:
•A search for an object is expected to take (logb2m)hops. However, the routing tables are
optimizedtoidentifynearest neighbourhops(asperthespa cemetric). Thus,thelatencyfor
each hop isexpectedto besmall,comparedto thatforCAN and C hord protocols.
•Thesize ofthe routingtableat each nodeis c·b·logb2m, wherecis theconstant that limits
thesizeoftheneighboursetthat ismaintainedforfault-to lerance.
The larger the Tapestry network, the more efﬁcient is the per formance. Hence, it is better that
differentapplicationssharethesameoverlay.
18.7 SomeOtherChallengesinP2PSystemDesign
18.7.1 Fairness: AGame Theory Application
P2P systems depend on all the nodes cooperating to store obje cts and allowing other nodes to
download from them. However, nodes tend to be selﬁsh in natur e; thus there is a tendancy to
download ﬁles without reciprocating by allowing others to d ownload the locally available ﬁles.
This behavior, termed as leachingorfree-riding , leads to a degradation of the overall P2P system
performance. Hence, penalties and incentives should be bui lt in the system to encourage sharing
and maximizethebeneﬁt to allnodes.
We now examineat the classical problem, termed the Prisoners’Dilemma , from gametheory,
that has some useful lessons on how selﬁsh agents might coope rate. This problem is an example
ofanon-zero-sum-game.
“Twosuspects,AandB, arearrestedbythepolice. Thereisno tenoughevidenceforaconvic-
tion. Thepoliceseparatethetwoprisoners,andseparately ,offereachthesamedeal: iftheprisoner
testiﬁesagainst(betrays)theotherprisonerand theother prsionerremainssilent,thebetrayer gets
freed and the silent accomplice get a 10 year sentence. If bot h testify against the other (betray),
695
they each receive a 2 year sentence. If both remain silent, th e police can only sentence both to a
small6-monthterm ona minoroffence.”
Rational selﬁsh behavior dictates that both A and B would bet ray the other. This is a not a
Paretooptimalsolution,whereaPareto-optimalsolutioni soneinwhichtheoverallgoodofallthe
participants is maximized. In the above example, both A and B staying silent results in a Pareto
optimalsolution. Thedilemmaisthatthisis notconsidered therationalbehaviourofchoice.
In the IterativePrisoners’ Dilemma, the game is played mult ipletimes, until an “equilibrium”
isreached. Eachplayerretainsemmoryofthelastmoveofbot hplayers(Inmoregeneralversions,
thememoryextendstoseveralpastmoves.) Aftertryingoutv ariousstrategies,bothplayersshould
convergetotheidealoptimalsolutionofstayingsilent. Th isisPareto-optimal.
The commonly accepted view is that the tit-for-tat strategy, described next, is the best for
winning such a game. In the ﬁrst step, a prisoner cooperates, and in each subsequent step, he
reciprocates theactiontaken bytheotherpartyin theimmed iatelypreceding step.
The BitTorrent P2P system has adopted the tit-for-tat strat egy in deciding whether to allow a
download of a ﬁle in solving the leaching problem. Here, coop eration is analogous to allowing
others to upload local ﬁles, and betrayal is analogous to not allowing others to upload. The term
chocking refers to the refusal to allow uploads. As the interactions i n a P2P system are long-
lived, as opposed to a one-timedecision to cooperate or not, optimisticunchocking is periodically
done to unchoke peers that have been chocked. This optimisti caction roughly corresponds to the
re-initiationofthegamewiththepreviouslychocked peera ftersometimeepoch haselapsed.
18.7.2 Trust or Reputation Management
Variousincentive-basedeconomicmechanismstoensuremax imumcooperationamongtheselﬁsh
peers inherently depend on thenotion oftrust. In a P2P envir onment where thepeer populationis
highly transient, there is also a need to have trust in the qua lity of data being downloaded. This
requirementshaveleadtotheareaoftrustandtrustmanagem entinP2Psystems. Asnonodehasa
completeviewoftheotherdownloadsintheP2Psystem,itmay havetocontactothernodestoeval-
uatethetrustinparticularofferersfromwhichitcoulddow nloadsomeﬁle. Thesecommunication
protocol messages for trust management may be susceptible t o various forms of malicious attack
(such as man-in-the-middle attacks and Sybil attacks), the reby requiring strong security guaran-
tees. The many challenges to tracking trust in a distributed setting include: quantifying trust and
using different metrics for trust, how to maintain trust abo ut other peers in the face of collusion,
howtominimizethecost ofthetrustmanagementprotocols.
18.8 TradeoffsbetweenTableStorageandRouteLengths
18.8.1 Unifying DHT Protocols
Chord, CAN, and Tapestry are three well-knownrepresentati veprotocolsformanaging structured
P2P overlays. Despitetheir seeming differences, Xu, Kumar , and Yu [32] showed that therouting
696
functiontheyperformcanbeexpressedinauniformwaybygen eralizingthefunctionofClassless
Interdomain Domain Routing (CIDR) used by the IP protocol. W e assume that all identiﬁers are
in the common address space. We also assume modulo arithmeti c (modulonfor Chord, modulo
n−dfor CAN, modulo bforTapestry).
Routing Rule: The next-hop routing to node with identiﬁer destfrom the current node with
identiﬁeridisas follows.
Let thekentries in a routing table at a node with identiﬁer idbe the tuples∝a\}⌊ra⌋k⌉tl⌉{tSid,i,Jid,i∝a\}⌊ra⌋k⌉tri}ht, for
1≤i≤k. If|dest−id|∈the rangeSid,ithen route to R(id+Jid,i), whereR(x)is the node
responsibleforkey R(x).
Clearly, we must have that for distinct iandj,Sid,i∩Sid,j=∅andJid,i∝\⌉}atio\slash=Jid,j. Further,
∪1≤i≤sSid,icontainsall thekeysnot stored by node id. WhenSid,iandJid,iare independent of id,
as isthecaseforCAN, CHord, and Tapestry,thesubscript idcan bedeleted.
Chord:ifdest−id∈Si= [2i−1,2i)then nodeidroutesto node id+Ji,whereJi= 2i−1.
Thiscorrespondstolookingupthe ithentryintheﬁngertable,asdescribedinSection18.4.3.
CAN:ThegreedyroutingfunctionforCANwasgiveninSection18.5 .3. Hereweassumeasimple
uniform distributionofnodes in theaddress space, xd=n, and that nodes are numbered by
anintegerinbase x,wherexisthenumberofnodesineach dimension. Routingisassumed
tobedonedimensionby dimension(ratherthan usinggreedy r outing). Wraparound routing
is assumed in each dimension. Then, for each dimension i, the followingholds: If destand
iddifferin dimension i, routetoi’s neighbourinthatdimension. Formally,
Ifdest−id∈(Si=)[xi−1,xi)then route to id+JiwhereJi+idis a neighbour node in
dimensionin i−1andJi=kxi−1forsomek≤x.
Tapestry: Letx=logbn,lvl= 1...xandj∈0...b−1. After deleting the longest common
preﬁx between idanddest,prefix (dest,lvl−1), fromdest, we havesuffix (dest,x−
lvl+ 1). Theroutingfunctionwas described inSection 18.6.2.
Ifsuffix (dest,x−lvl+ 1)∈S(lvl−1)·b+j= [j·bx−lvl+1,(j+ 1)·bx−lvl+1)then nodeid
routes to node prefix (id,lvl−1)◦suffix (J(lvl−1)·b+j,x−lvl+ 1), whereJ(lvl−1)·b+j∈
[j·bx−lvl+1,(j+ 1)·bx−lvl+1).
Theseroutingrelationshipsaresummarizedin Table18.4.
18.8.2 Bounds onDHT Storageand Routing Distance
BasedonTable18.4,theroutertablesizeandnetworkdiamet erarerepresentedinFigure18.14. A
fundamental question is whether the asymptotic bounds on (r outing table size, network diameter
asdeterminedbythemaximumnumberofhops)are (log2n,Ω(log2n))asforChordandTapestry,
and(d,Ω(n−d))as forCAN. Xu etal. [32]uased thefollowingdeﬁnitionstoan swerthis.
697
Protocol Chord CAN Tapestry
Routing table size k=O(log2n)k=O(d)k=O(logbn)
Worst case distance O(log2n) O(n1/d)O((b−1)·logbn)
n,common name space 2kxdbx
Si [2i−1,2i) [xi−1,xi)[j·bx−lvl+1,(j+ 1)·bx−lvl+1)
Ji 2i−1kxi−1suffix (J(lvl−1)·b+j,x−lvl+ 1)
Table 18.4: Comparison of representativeP2P overlays. dis thenumberof dimensionsin CAN. b
isthebaseinTapestry.
maintain full state
asymptotic tradeoff curve
Chord, Tapestry
maintain no stateCAN
O(n     )−dO(log  n)n
log  n
<= d
0
O(1) O(n)Routing table size
distanceWorst
case
Figure18.14: Fundamental asymptotictradeoffsbetween ro utertablesizeand networkdiameter.
•Aroutingalgorithmis weaklyuniform ifforanynodes idandid′,thejumpsizes Jid,i=Jid′,i.
Thus, a weakly uniform algorithm requires the correspondin g “jump sizes” for any index i
tobethesameforallnodes,irrespectiveofthenodeidentiﬁ er.
•A routing algorithm is strongly uniform if it is weakly uniform and if for any nodes idand
id′,Sid,i=Sid′,i. A strongly uniform algorithm requires all routing tables t o also have the
samecorrespondingsizes oftheindexranges.
•Anetworkisnode-congestion-free(resp.,edge-congestio nfree)ifallnodes(resp.,edges)are
handlingthesameaverage trafﬁc. A network iscongestion-f reeit itisnode-congestion-free
and edge-congestion-free. Chord, CAN, and Tapestry are all congestion-free algorithms. A
stronglyuniformalgorithmisnode-congestion-free.
Thefollowingresulthas been shownbyXu, Kumar,andYu.
•Whentheroutingalgorithmsareweaklyuniform, Ω(log2n)andΩ(n−d)arethelowerbounds
on the diameter in networks with routing tables of sizes O(logn)andd, respectively. As
698
Chord, CAN, and Tapestry are strongly uniform, they achieve the asymptotic lower bounds
inthetradeoff.
18.9 GraphStructuresofComplexNetworks
P2P overlay graphs can have different structures. An intrig uing question is to characterize the
structure of overlay graphs. This question is a small part of a much wider challenge of how to
characterize large networks that grow in a distributed mann er without any coordination. Such
networksexistin:
•computer science: the WWW graph (WWW), the Internet graph th at models individual
routers and interconnecting links (INTNET), the Autonomou s Systems (AS) graph in the
Internet;
•insocialnetworks(SOC),phonecallgraph(PHON),movieact orcollaborationgraph(ACT),
authorcollaborationgraph (AUTH)citationnetworks(CITE );
•inlinguistics: wordco-occurrencegraph(WORDOCC),thewo rdsynonymgraph(WORDSYN);
•thepowerdistributiongrid (POWER);
•in nature: protein folding (PROT) where nodes are proteins a nd an edge represents that the
two proteins bindtogether, substrategraph for variousbac teria and micro-organisms(SUB-
STRATE), where nodes are substrates and edges are chemical r eactions in which substrates
participate.
Itiswidelyintuitedthatsuchcomplexgraphsmustdisplays omeorganizationalprinciplesthatare
encoded intheirtopologyinsomesubtleways. Thishas drive nresearch on auniﬁcationtheoryto
determineasuitablemodelin whichall suchuncontrolledgr aphsare instantiations.
Theﬁrstlogicalattempttomodellargenetworkswithoutany knowndesignprinciplesistouse
random graphs. The random graph model, also known as the Erdo s-Renyi (ER) model, assumes
nnodes and a link between each pair of nodes with probability p, leading to n(n−1)p/2edges.
Manyinterestingmathematicalpropertieshavebeenshownf orrandomgraphs(seeSection18.11)
for examples. However, the complex networks encountered in practice are not entirely random,
and showsome, somewhatintangible,organizationalprinci ples.
Three ideashavereceivedmuchinvestigativeattentioninr ecent times.
Smallworldnetworks: Even in very large networks, the path length between any pair of nodes
isrelativelysmall. Thisprincipleofa“smallworld”waspo pularizedby sociologistStanley
Milgramby the“sixdegrees ofseparation”uncoveredbetwee n anytwo people[21].
As the average distance between any pair of nodes in the ER mod el grows logarithmically
withn, theERgraphsare smallworlds.
699
Clustering: Socialnetworksarecharacterizedbycliques. Thedegreeof cliquesinagraphcanbe
measuredbyvariousclusteringcoefﬁcients,suchasthefol lowing. Consideranode ihaving
kiout-edges. Let libe the actual number of edges among the kinearest neighbours of i. If
thesekinearest neighbours were in a clique, they would have ki.(ki−1)/2edges among
them. The clustering coefﬁcient for node iisCi= 2li/(ki(ki−1)). The network-wide
clusteringcoefﬁcient istheaverageofall Cis, forallnodes iinthenetwork.
The random graph model has a clustering coefﬁcient of exactl yp. As most real networks
havea muchlargerclusteringcoefﬁcient, thisrandomgraph model(ER)is unsatisfactory.
Degree distributions: LetP(k)be the probability that a randomly selected node has kincident
edges. In many networks – such as INTER, AS, WWW, SUBST – P(k)∼k−γ, i.e.,P(k)
is distributed with a power-law tail. Such networks that are free of any characteristic scale,
i.e.,whosedegreecharacterization isindependentof n, are called scale-free networks .
In a random graph, the degree distribution is Poisson-distr ibuted with a peak of P(∝a\}⌊ra⌋k⌉tl⌉{tk∝a\}⌊ra⌋k⌉tri}ht),
where∝a\}⌊ra⌋k⌉tl⌉{tk∝a\}⌊ra⌋k⌉tri}ht,whichisafunctionof n,istheaveragedegreeinthegraph. Thus,randomgraphs
are not scale-free. While some real networks have an exponen tial tail, the actual form of
P(k)is stillverydifferent fromthat foraPoissondistribution .
Current empirical measurements show the following propert ies of some commonly occuring
graphs.
WWW: In-degree and out-degree distributionsboth follow power l aws; WWW is a small world;
directed graph,but doesshowahighclusteringcoefﬁcient.
INTNET: Degreedistributionsfollowpowerlaw;INTNETis asmallwor ld;showsclustering.
AS:Degreedistributionsfollowpowerlaw;INTNET isasmallwor ld;showsclustering.
ACT:Degree distributions follow power law tail; ACT is a small wo rld (similar path length as
ER); showshighclustering.
AUTH:Degreedistributionsfollowpowerlaw;AUTHisasmallworld ;showshighclustering.
SUBSTRATE: In-degreeandout-degreedistributionsbothfollowpowerl aws;smallworld;large
clusteringcoefﬁcient.
PROT:Degreedistributionhasa powerlawwithexponentialcutoff .
PHON:In-degreeand out-degreedistributionsbothfollowpowerl aws.
CITE:In-degreefollowspowerlaw,out-degreehas an exponential tail.
WORDOCC: Two-regime power-law degree distribution; small world; hi gh clustering coefﬁ-
cient.
700
WORDSYN: power-lawdegreedistribution;smallworld;highclusteri ngcoefﬁcient.
POWER: Degreedistributionisexponential.
Efforts on developing models focus on: random graphs to mode l random phenomena, small
worldstointerpolatebetweenrandomgraphsandstructured clusteredlattices,scale-freegraphsto
studynetworkdynamicsand networkevolutions.
18.10 Internetgraphs
18.10.1 BasicLaws andtheir Deﬁnitions
Inthissection,weconsidersomepropertiesoftheInternet ,thatdemonstrateapower-lawbehavior
as measured empirically. Power law informally implies that large occurrences are very rare, and
the frequency of the occurrence increases as the size decrea ses. Examples pertaining to the web
are: the number of links to a page, the number of pages within a web locaiton, and the number of
accessestoawebpage. Webeginbytakingtheexampleofthepo pularityofwebsitestoillustrate
thedeﬁnitionsof3 related observedlaws: theZipfLaw,theP areto Law,and thePowerLaw.
LOG
rank of site # visitorsslope a slope b = a−1 slope c = 1/b
(b) Power Law (c) Pareto law (a) Power law
     (linear scale)       (log−log scale)      (log−log scale)       (log−log scale)(d) Zipf’s Law> x visitors)P(site hasPDF PDF CDF PDF
(i.t.o. > y visitors)LOG# sites # sites
LOG
# visitors # visitors# visitors
LOG LOG LOG
Figure 18.15: The popularity of web sites. (a) Power law show ing the PDF using a linear scale.
(b) Power Law showing the PDF using a log-log scale. (c) Paret o Law showing the CDF using a
log-logscale. (d)Zipf’sLaw usinga log-logscale.
PowerLaw: P[X=x]∼x−a
This law is stated as a Probability Distribution Function (P DF). It says that the number of
occurrences of events that equal xis an inverse power of x. Figures 18.15(a) and (b) show
the typical Power Law PDF plots on a nomral scale and on a log-l og scale, respectively. In
thelog-logplot,theslopeis a.
In ourexample,thiscorrespondsto thenumberofsiteswhich haveexactly xvisitors.
Pareto Law: P[X≥x]∼x−b=x−(a−1)
701
Thislawisstatedas aCumulativeDistributionFunction(CD F). Thenumberofoccurrences
larger thanxis an inverse power of x. The CDF can be obtained by integrating the PDF.
Theexponents aandbofthePareto(CDF) and PowerLaws(PDF) arerelated as b+ 1 =a.
Figure 18.15(c) shows the Pareto Law CDF plot on a log-log sca le. In the log-log plot, the
slopeisb=a−1.
In ourexample,thiscorrespondsto thenumberofsiteswhich haveatleast xvisitors.
Zipf’s Law: n∼r−c.
Thislawstatesthecount n(i.e.,thenumber)oftheoccurrences ofan event,asafuncti onof
the event’srank r. It says that the count of the rth largest occurrence is an inversepower of
the rankr. Figure 18.15(d) shows the Zipf plot on a log-log scale. In th e log-log plot, the
slopeisc, which weseebelowis1
b=1
a−1.
The context initally used by Zipf was the frequency of occurr ence of words in English,
where the most frequently occurring word had rank 1. Zipf’s l aw is widely occurring, e.g.,
magnitude of earthquakes, and populations of cities follow this law. In our example, this
correspondsto thenumberofvisitstothe rthmostpopularsite.
Clearly, that the Pareto Law (CDF) and Power law (PDF) are rel ated. The Zipf Law n∼r−c,
stating “the r-ranked object has n=rcoccurrences, can be equivalently expressed as: “ robjects
(X-axis)have n=r−c(Y-axis)ofmoreoccurrences”. Thisbecomesthesameas theP areto Law’s
CDF after transposing the X and Y axes, i.e., by restating as: “the number of occurrences larger
thann=r−c(Y-axis)isr(X-axis)”.
FromZipf’sLaw, n=r−c,hence,r=n−1
c. Hence,theParetoexponent bis1
c. Asb= (a−1),
whereais thePower Lawexponent,we seethat a= 1 +1
c. Hence, theZipfLaw distributionalso
satisﬁesa PowerLawPDF.
18.10.2 Properties of the Internet
The Internet is a prime example of a complex entity that exhib its power-law behaviour. Based on
extensiveempiricalmeasurements,Siganosatel. [28]show edthefollowingresults.
Rankexponent/ Zipf’s law: The nodes in the Internet graph are ranked in decreasing orde r of
theirdegree. Whenthedegree diisplottedasafunctionoftherank rionalog-logscale,the
graph is likeFigure18.15(d). The slopeis termed therank ex ponentR, anddi∝rR
i. If the
minimumdegree dn=mis known,then m=dn=CnR, implyingthat theproportionality
constantCism/nR. Exercise 6 asks you to estimate the number of edges as a funct ion of
therankexponentand thenumberofnodes.
Degree exponent/ PDFand CDF: Let the CDF fdof the node degree dbe the fraction of nodes
with degree greater than d. Thenfd∝dD, whereDis the degree exponent that is the slope
ofthelog-logplotof fdas afunctionof d.
702
Analogously,let the PDF be gd. Thengd∝dD′, whereD′is the degree exponent that is the
slopeofthelog-logplotof gdas afunctionof d.
Empirically, D′∼D+ 1, as theoretically predicted. Further, Rsim1
D, also as theoretically
predicted. Theimperfectmatchisattributedtoimperfectm easurementsandapproximations
incurve-ﬁtting. Inpractice,theCDFispreferredasitcanb eestimatedwithgreateraccuracy.
EigenexponentE:For the adjacency matrix Aof a graph, its eigenvalue λis the solution to
AX=λX, whereXis a vectorof real numbers. The eigenvalues are related to th e graph’s
numberofedges,numberofconnectedcomponents,thenumber ofspanningtrees,thediam-
eter,andotherimportanttopologicalproperties. Letthev ariouseigenvaluesbe λi,whereiis
theorderandbetween1and n. Thenthegraphof λiasafunctionof iisastraightline,witha
slopeofE, theeigen-exponent. Thus, λi∝iE. Moreintriguingly,when theeigenvaluesand
thedegreeare sortedin descendingorder, itis foundthat λi=√di, implyingthatE=D
2.
The following additional hypotheses have not been very vigo rously tested and veriﬁed. Nev-
ertheless, they offer very insightful looks into the preval ance and use of power laws in complex
uncontrolledentitiessuch as theInternet. Twodeﬁnitions are usefulat thisstage.
•PN(h)is the number of pairs of nodes within hhops, counting self-pairs, and counting all
otherpairstwiceduetothedualedgeincidence.
•NH(h), theneighbourhood,is theexpected numberofnodeswithin hhops.
Hop-plotexponent, H:Experimentalmeasurementshaveshownthat PN(h)followsapowerlaw
regimemore closely, rather than the exponentialregimeas p reviouslyestimated. Thus, PN(h)∝
hH, whereHis the slope of the log-log plot of PN(h)as a function of hforh≪dia. From the
deﬁnitionof PN(h), observethat PN(1) =n+ 2l. Hence,
PN(h) =/braceleftbigg
(n+ 2l)hH,ifh≪dia
n2, ifh≥dia(18.9)
Thehop-plotexponentisusefultoestimatetheeffectivedi ameterdiaeffofthenetwork. Infor-
mally,anytwonodesinthenetworkarewithin diaeffhopsofeach other,with“highprobability”.
When some destination node whose location is unknown needs t o be reached, the use of hop-
constrained broadcast is the standard solution. A large hop count takes too long, whereas a small
hop count may not reach the entire network. If the hop count, i s set todiaeff, then with high
probability,thedestinationcanbereachedwithjusttheri ghtamountofoverhead. Using n,H,and
thenumberofedges l(seeExercise6), theeffectivediameteris deﬁned as:
diaeff= (n2
n+ 2l)1/H
This effective diameter is estimated as the abscissa of the i ntersection of the log-log hop-plot
withslopeHand then2coveragethatisexpected withindiameterhops.
703
Observe that the average size of the neighbourhood NN(h) =PN(h)
n−1. HenceNN(h) =
(n+2l)hH
n−1. TheNN(h)is seen to be a more accurate estimate of the neighbourhood th an the
average-degree estimate, NN d(h) =d(d−1)h−1TheNN d(h)estimate assumes that the degree
distributionis mor uniform, and that each hop adds d−1new nodes per node at the boundary of
theexaminednetwork. As thedegreedistributionishighlys kewed,thetraditional NN′(h)metric
isnot accurate.
Forallthecasesabove,thepowerlawregimehassofarbeenmp iricallyvaliated. Theexponent
itself has been observed to change gradually over time as the networks evolve. The power law
regimeprovidesagoodhandleonpredictingthefuturegrowt hoftheInternet,andbuildingaccurate
graphs forsimulations.
18.10.2.0.4 Classiﬁcation of Scale-free Networks. Scale-free networks of different types –
WWW,INTNET,AS,ACT,AUTH,SUBSTRAE,PROT,PHON,in-degree forCITE,WORDSYN
-havedifferentdegreeexponents,typicallyrangingfrom2 to3. Thequesttoseekamoreuniversal
and commonfactorresulted intheanalysisofanothermetric , called the“betweenness centrality”.
For any graph, let its geodesics, i.e., set of shortest paths , between any pair of nodes iandjbe
denotedS(i,j). LetSk(i,j)be a subset of S(i,j)such that all the geodesics in Sk(i,j)pass
through node k. The betweenness centrality BC of node k,bk, is/summationtext
i/ne}ationslash=jgk(i,j) =/summationtext
i/ne}ationslash=j|Sk(i,j)|
|S(i,j)|.
Thebkdenotestheimportanceofnode kinshortest-pathconnectionsbetweenallpairsofnodesin
thenetwork.
ThemetricBC followsthepowerlaw PBC(g)∼g−β,whereβistheBC-exponent. Unlikethe
degree exponent which varies across different network type s, the BC-exponent has been empiri-
cally found totake onvalues ofonly2 or 2.2for thesevariedn etwork types. This veryinteresting
observationis underfurtherstudy.
18.10.3 Error andAttackTolerance ofComplex Networks
Based on the node degree distribution P(k), two broad classes of small world networks are the
exponentialnetworksandthescale-freenetworks. Inexpon entialnetworks,suchastheERrandom
graphmodelandtheWattsStrogatzsmallworldmodel, P(k)reachesamaximumata kvalueand
thenP(k)decreasesexponentiallyperaPoissondistributionas kincreases. Inscale-freenetworks,
such astheweb and theInternet, P(k)decreases as perapowerlaw, P(k)∼k−γ.
Thefollowingaretwokeydifferencesthatleadstodifferen tbehaviourofexponentialnetworks
and of scale-free networks, under errors and attakcs. (1) No des with a very high degree are statis-
ticallysigniﬁcantin scale-free networks, whereas theyar e closetoan impossibilityin exponential
networks. (2) In an exponential network, all nodes have abou t the same number of links, whereas
in a scale-free network, some nodes have many links and the ma jority of the nodes have a small
numberoflinks.
Errors are simulated by removing nodes at random. Attacks ar e simulated by removing the
nodes with highest degree. Their impact is measured on netwo rk diameter and network partition-
ing.
704
network
diameter
exponential (attack & errors)
0.1 0.05
f, the fraction of nodes removed0(under attack) scale−free
scale−free (under errors)
Figure18.16: Impactofattacksandfailuresonthediameter ofexponentialnetworksandscale-free
networks,from Albert,Jeong,and Barabasi.
18.10.3.0.5 Impact on network diameter. Figure??is used to descibe the impact on the di-
ameter. The graph shows only the relativetrends, as empiric ally veriﬁed by simulationsfor many
large networks, including the Web and Internet. Any numbers simply in the graph convey an ap-
proximate order of magnitude for the particular networks st udied by Albert, Jeong, and Barabasi
[5].
Errors.As all nodes have about the same degree, the removal of any nod e has approximately
the same amount of small impact in terms of decreases connect ivity. The network diameter
increases gradually. The diameterofscale-free networks r emains almostsameunder errors,
asnodesthatareremovedhavesmalldegreewithveryhighpro babilityandareveryunlikely
toalterthelengthsofthepathsamongothernodes.
Attacks. As nodes in an exponential network have about the same degree , the network behaves
similarly under attack as under errors. Under attack, the di ameter of scale-free networks
increases dramatically, as the few nodes with highest conne ctivity are removed, thereby
greatlyreducing theconnectivityoftheentirenetwork.
18.10.3.0.6 Impactonnetworkpartitioning. Theimpactofremovalofnodesonpartitioning
is measured usingtwo metrics: Smax, theratio of thesizeofthepargest clusterto thesystemsiz e,
andSothers, theaveragesizeofallclustersexcept thelargest.
Exponential networks. See Figure 18.17. Asf,thefractionofnodesremovedisincreased, Sothers
increasesfrom1toaround2forsomethresholdfraction fthreshold. Thisimpliesthatforvery
smallf, whereSothers∼1, single nodes break off. As fincreases, several small but larger
partitions set in, leading to a peak of Sothersatfthreshold. Forf > f threshold,Sothersreduces
back to 1, as the isolated clusters (fragments) in the networ k further disintegrate. In terms
ofSmax, asfis varied from 0 to fthreshold,Smaxdecreases from 1 to a low value as small
(mostly single-node) partitions break off. As fthresholdis approached, the main cluster dis-
integrates, leading to Smaxtending to 0. As fis increased beyond fthreshold,Smaxremains
near0.
705
0 0.5others maxS        and S2
1S
f > f partitions at
thresholdfpartitions at
very low fpartitions at
f. the fraction of nodes removedthresholdfunder errors
under errorsunder attack andunder attack and
maxSothers
Figure 18.17: Impact on cluster size of exponential network s, from Albert, Jeong, and Barabasi.
(a) Graphical trend. (b) Pictoral cluster sizes for low f, i.e.,f≪fthreshold. (c) Pictoral cluster
sizes forf∼fthreshold. (d) Pictoral clustersizes for f >f threshold. Thepictoral trend in (b)-(d) is
alsoexhibitedbyscale-free networksunderattack, butfor alowervalueof fthreshold.
The impact of attacks on network partitioning is the same as t he impact of errors, for the
samereasoninggivenfortheanalysisonthediameter.
Scale-free networks. See Figure18.18. Whennodesarerandomlyremoved, Smaxdecreasesfrom
1 very gradually. Also, Sothersremains steady at 1, indicating that singleton nodes get re-
movedfromthemainnetwork. Thereisnothreshold fthresholdobserved,evenforhighvalues
off,such as 0.5error rate.
However,underattack,whenthemostconnectednodesarerem oved,thebehaviourissimilar
to (but more acute than) that of the exponential network. Thu s, the threshold fthresholdsets
in at alowervalue. This is because the impactof removingthe highlyconnected nodes ﬁrst
causes disintegrationto setin quickly.
maxS
under attackmaxS
0.4
f. the fraction of nodes removedthresholdf0others maxS        and S2
1under errors
(higher f) (moderate f)under errors under errors under errors
(very low f)partitions partitions partitions Sothersunder attack
under errorsSothers
Figure18.18: Impactonclustersizeofscale-freenetworks ,fromAlbert,Jeong,andBarabasi. The
pictoralimpactofattacks onclustersizesare similartoth oseinFigure18.17. (a)Graphicaltrend.
(b) Pictoral cluster sizes for low funder failure. (c) Pictoral cluster sizes for moderate funder
failure. (d)Pictoral clustersizes forhigh funderfailure.
706
18.11 RandomGraphs
Someinterestingfeatures ofrandom graphsare as follows.
18.11.1 Graph Model
The probability of obtaining a particular random graph G= (V,L), where|V|=nand|L|=l,
isP(G) =pl(1−p)n(n−1)/2−l. Alternately, Gcan be viewed as a random graph obtained from a
space ofCl
n(n−1)/2equiprobable graphs. Gpis used to denote that the probability of a conneciton
between anypairofedges in Gisp.
18.11.1.1 GraphProperties
A graph has a property Qiflimit n→∞p(Q) = 1. A main focus of random graph theory is to
determine the connection probability pat which a particular property Q, such as the occurence of
aspeciﬁcsubgraphliketreeorring,can mostlikelyarise. A signiﬁcantresultby ErdosandRenyi
is that many properties in random networks appear or disappe ar “suddenly”, at a particular value
ofprobability pc(n), calledthe criticalprobability .
Theconnectionprobabilityisitselfmodeledasafunctiono fn. Ifp(n)growsfasterthan pc(n),
thenalmostanygraphwillexhibittheproperty Q. Butifp(n)growsslowerthan pc(n),thenalmost
no graphwillexhibittheproperty Q.
limit n→∞p(Q) =/braceleftBigg
0ifp(n)
pc(n)→0
1ifp(n)
pc(n)→∞(18.10)
Aninterestingpropertyofrandomgraphsistheappearanceo fsubgraphs. Forexample,isthere
a critical probability at which arbitrary subgraphs consis ting ofknodes andledges appear in the
graph? Givena graph Gp, thenumberofsuchsubgraphs FwasshownbyBollobas [8]tobe:
E(G′) =Ck
nk!
apl∼nkpl
a(18.11)
Here,aisthenumberofnumberofsubgraphsthatareisomorphictoon eanother. If p(n) =cn−k/l,
themeannumberofsubgraphs Fisλ=cl/a. Usingthedistributionofsubgraphnumbers Pp(X=
r),Bollobas showedthat
limit n→∞Pp(X=r) =e−λλr
r!(18.12)
Theprobabilitythat Gcontainsat leastonesubgraph Fis:
∞/summationdisplay
i=1Pp(X=r) = 1−e−λ(18.13)
This probability converges to 1 with increasing c. Hence the critical probability for which each
graph containsasubgraph F(k,l)ispc(n) =cn−k/l. Instantiatingthis,
707
1. foratreeof knodes,pc(n) =cn−k/(k−1)
2. foracompletesubgraphof knodes,pc(n) =cn−2/(k−1)
3. foracycleofsize k,pc(n) =cn−1
18.11.2 Graph Degree Distribution
Thedegreedistribution kiofnodeiisabinomialdistribution,givenbyBollobas [7]as:
P(ki=k) =Ck
n−1pk(1−p)n−k−1(18.14)
Fortheentiregraph Gp,theexpectednumberofnodeswithdegree kissimplynP(ki=k),which
wedenoteas λ. Thedegreedistributionofthegraphgives Xk,thenumberofnodeswithdegree k,
whichthen becomesthePoissondistributionwithmean λk:
P(Xk=r) =e−λλr
k
k!(18.15)
Forlargen,
P(k) =e−pn(pn)k
k!=e−k(k)k
k!(18.16)
Much work studied the existence and uniqueness of the maximu m and minimum degrees of a
random graph. Among the many interesting results is the resu lt that for a sufﬁciently high p, if
pn/ln (n)→∞, then the average degree and the maximum degree of almost all random graphs
is of the same order of magnitude. A typical random graph has t he same number of edges for the
majorityofthenodes.
18.11.3 Graph Diameter
Further, the diameterof a random graph is typically small. W ith a high probability,the numberof
nodeslhops awayis closeto kl. Askl∼Coverage ,thenl=ln(Coverage )
ln(k). Thisgives:
d=n
pn=ln(n)
k(18.17)
In particular,if k≥ln(n), thediameterofallgraph withthesame nandkisvery closetoln(n)
k.
18.11.4 Graph Clustering Coefﬁcient
In a random graph, the probability that two of the neighbours of any node are connected is the
clustering coefﬁcient, which is simply:k
n. However, real networks have a clustering coefﬁcient
thatis independentof noranotherparameter.
708
18.11.5 Generalized Random Graph Networks
Random graphs cannot capture the scale-free nature of real n etworks, which states that the node
degree distribution follows a power law. The generalized random graph model uses the degree
distribution as an input, but is random in all other respects . Thus, the constraint that the degree
distribution must obey a power law is superimposed on an othe rwise random selection of nodes
to be connected by edges. These semi-random graphs can be ana lyzed for various properties of
interest. Although a simple formal model for the clustering coefﬁcient is not known, it has been
observed that generalized random graphs have a random distr ibution of edges similar to the ER
model,and hencetheclusteringcoefﬁcient willlikelytend tozero asNincreases.
18.12 Small-worldNetworks
Real-world networks are small worlds, having small diamete r, like random graphs, but they have
relativelylargeclusteringcoefﬁcients thattend tobeind ependentofthenetworksize.
Ordered lattices tend to satisfy this property that cluster ing coefﬁcients are independent of the
networksize. Figure18.19(a)showsaone-dimensionallatt iceinwhich each nodeis connectedto
k= 4closestnodes. Theclusteringcoefﬁcient C=3(k−2)
4(k−1).
(a) (c) (b)/0/1/0/1
/0/1 /0/1 /0/0/0/0/1/1/1/1
/0/1
/0/1/0/1
/0/1
/0/1
/0/1
/0/1 /0/1/0/1/0/1/0/1
/0/1 /0/1
/0/1/0/1
/0/1
/0/0/0/0/1/1/1/1/0/1
/0/1
/0/1
/0/1 /0/1/0/1/0/1 /0/1
/0/1
/0/1
/0/1 /0/1/0/1/0/1
Figure 18.19: The Watts-Strogatz random rewiring procedur e. (a) Regular. (b) Small-world. (c)
Random. Therewiringshownmaintainsthedegreeofeach node .
The ﬁrst model for smallworld graphs with high clusteringco efﬁcients and low path length is
theWattsStrogatz(WS) model.
1. Deﬁnearinglatticewith nnodesandeachnodeconnectedto Kclosestneighbours( k/2on
eitherside). Let n≫k≫ln(n)≫1.
2. Rewire each edge randomly with probability p. Whenp= 0, there is a perfect structure, as
inFigure18.19(b). When p= 1, completerandomness,as inFigure18.19(c).
A characteristic of small-world graphs is the small average path length. When pis small,len
scaleslinearlywith nbutwhenpislarge,lenscaleslogarithmically. Throughanalyticalarguments
709
and simulations,itis nowbelievedthatthecharacteristic path lengthvariesas:
len(n,p)∼n1/d
kf(pkn) (18.18)
wherethefunction fbehavesas follows.
f(u) =/braceleftbiggconstant ifu≪1
ln(u)
uifu≫1(18.19)
The variable u∝pkndhas the intuitive interpretation that it depends on the aver age number of
random links that provide “jumps” across the graph, and f(u)is the average factor by which the
distancebetween apairofnodesgets reduced by the“jumps”.
18.13 Scale-freeNetworks
Manyrealnetworksarescale-free,andevenforthosethatar enotscale-free,thedegreedistribution
followsanexponentialtailthatissigniﬁcantlydifferent fromthatofthePoissondistribution. Semi-
randomgraphsthatareconstrainedtoobeyapowerlawforthe degreedistributionsandconstrained
to have large clustering coefﬁcients yield scale-free netw orks, but do not shed any insightinto the
mechanisms that givebirth to scale-free networks. Rather t han modeling the network topology, it
isbetterto modelthenetwork assemblyand evolutionproces s. Speciﬁcally,
•Rather than begin with a constant number of nodes nthat are then randomly connected or
rewired, real networks (e.g., WWW, INTERNET) exhibit growthby the addition of nodes
and edges.
•Rather than assume that the probability of adding (or rewiri ng) an edge between two nodes
is a constant, real networks exhibit the property of preferential attachment , where the prob-
abilityofconnectingto anodedependsonthenodedegree.
The simple Barabasi-Albert model which captures growth and preferential attachment is de-
scribedinFigure18.20. Numerically,itisveriﬁedthatthe degreedistributionfollowsapowerlaw
withdegree=3, thatis independentoftheparameter m.
Twotechniquestoanalyzethedegreedistributionofmodels arenowexempliﬁedinthecontext
oftheBAmodel.
18.13.1 Master-equationapproach
Letp(k,ti,t)denotethe probabilitythat at time t, a nodeithat was added at time tihas degreek.
When a new node with medges is added to the graph, the degree of node iincreases by one with
probabilitym·/producttext(k) =k/2t. Hence, wehave:
p(k,ti,t+ 1) =k−1
2t·p(k−1,ti,t)−[1−k
2t]·p(k,ti,t) (18.21)
710
Initially, there are m0isolated nodes. Ateach sequential step, perform one of thef ollowing operations.
With probability p,addm, where m≤m0, newedges. For each new edge, one end is randomly se-
lected, theother end withprobability
/productdisplay
(ki) =ki+ 1/summationtext
j(kj+ 1)(18.20)
With probability q,rewire medges.To rewire an edge, randomly select node i, delete some edge (i,w),
add edge (i,x)tonode xthat is chosen withprobability/producttext(kx)as per Equation (18.20).
With probability 1−p−q, inserta newnode. Addmnew edges tothe new node, such that withproba-
bility/producttext(ki),an edge connects to anode ialready present before this step.
Figure18.20: ThesimpleBarabasi-Albert model.
The ﬁrst term is the probabilitythat a node with k−1degree gets a new edge; the second term is
the probability that a node with degree kdoes not get a new edge. Based on this formulation, the
degreedistributioncan beexpressed as
P(k) =limit t→∞/summationdisplay
tip(k,ti,t)/t (18.22)
From Equation(18.21), itcan beshownthat
P(k) =/braceleftbiggk−1
k+2P(k−1)ifk≥m+ 1
2
m+2ifk=m(18.23)
Thissolvesas:
P(k) =2m(m+ 1)
k(k+ 1)(k+ 2)(18.24)
18.13.2 Rate-equation approach
LetNk(t)be the average number of nodes having kedges at time t. When a new node is added,
Nk(t)changes as follows. New edges are added to some nodes with deg reek−1, new edges are
added to some nodes with degree k, and new nodes with medges are added. These three changes
affectNk(t)inthefollowingmanner.
dNk
dt=m·[(k−1)·Nk−1(t)/summationtext
kkNk(t)−k·Nk(t)/summationtext
kkNk(t)] +δk,m (18.25)
By taking the asymptotic limit, Nk(t) =t·P(k), and/summationtext
kkNk(t) = 2mt. This yields the same
recursiveEquation( ??)obtainedusingtheMaster-equationapproach.
711
18.14 EvolvingNetworks
The BA algorithmin Figure 18.20 represents a basic modeltha t cannot fully capture real network
properties. For example, the BA model has a ﬁxed exponent of 3 for the power law, independent
oftheparameter m. Real networkshavean exponentthat varies,typicallybetw een 1and 3. Some
real networks sometimes have exponential cutoffs that are n ot within the power law regime. The
study of more general and ﬂexible models that can accurately capture real networks has lead to
severalnotabledirectionsofinvestigation.
Preferential attachment: TheBAmodelassumedthattheprobability/producttext(k)thatanodeconnects
toanodeof iisproportionaltothedegree ki. Thisimpliedthat/producttext(k)islinearlyproportional
tok.
It has been shown analytically that for sublinear preferential attachment as well as for su-
perlinearpreferentialattachment ,thescale-free natureofthenetworkcannot bepreserved.
In real networks, there is a ﬁnite probability that a node att aches to a isolated node, i.e.,/producttext(0)∝\⌉}atio\slash= 0and/producttext(k) =C+kα.
Here,Cdenotes the intial attractiveness . It can be seen that initial attractiveness changes
thedegreeexponentbutpreserves thescale-free natureoft hedegreedistribution.
Growth: TheBAmodelassumedthattherateofadditionofnodesandedg eswasuniform. Many
real networks like INTNET, AS, WEB, SUBSTRATE, WORDOCC, hav e the property that
the number of edges increases faster than the number of nodes , implying an increase in
the average degree as the number of nodes increases. It has be en analytically shown that
accelerated growth does not affect the power law nature alth ough the exponent degree is
altered.
Local events: Real networks undergo local (microscopic) changes to the to pology, such as node
additionand nodedeletion, edge additionand edge deletion . A popularmodel that explores
the properties of such local events is the extended Barabasi -Albert model, shown in Fig-
ure18.21.
Growthconstraints: Real networks often have bounded capacity for the number of e dges (e.g.,
connectionsatarouter)oraﬁnitelifetimeforthenodes(as insocialnetworks). Intheelectri-
calpowerdistributionnetworkwhichexhibitsanexponenti aldistribution,therearepractical
reasons why the node degree is bounded. In the actors network which exhibits a power law
with an exponentialcutoff for large k, ageing limitsthe accrual of new edges. Thus, ageing
and ﬁnitecapacity need to explicitlycaptured in agoodmode lforsuch networks.
Competition: Real-world networks exhibit competition, wherein some nod es can attract more
edges (e.g., via advertising) at the cost of other nodes. Thi s feature can be modeled by a
ﬁtness parameter. Similarly,a new node may inherit edges be longingto someother nodeor
nodes(e.g., modifyingareplicaofaweb page). Thisneeds to beexplicitlymodeled.
712
Initially, there are m0isolated nodes. Ateach sequential step, perform one of thef ollowing operations.
With probability p,addm, where m≤m0, newedges. For each new edge, one end is randomly se-
lected, theother end withprobability
/productdisplay
(ki) =ki+ 1/summationtext
j(kj+ 1)(18.26)
With probability q,rewire medges.To rewire an edge, randomly select node i, delete some edge (i,w),
add edge (i,x)tonode xthat is chosen withprobability/producttext(kx)as per Equation 18.26.
With probability 1−p−q, inserta newnode. Addmnew edges tothe new node, such that withproba-
bility/producttext(ki),an edge connects to anode ialready present before this step.
Figure18.21: TheextendedBarabasi-Albert model.
Preferential attachment: Various local-level mechanisms such as: copying mechanism (copy
edges of another node as in web pages), and tracing selected w alks (as in recursively fol-
lowingthecitationtrail inacitationnetwork), need tobem odeled.
18.14.1 Extended Barabasi-Albert Model
TheextendedBA modelisan examplemodelforevolvingnetwor ks.
Continuumtheoryanalysis: Incontinuumtheory,itisassumedthat kichangescontinuouslyand/producttext(ki)thenrepresentstherateatwhich kichanges. Eachofthethreepossibleeventsinasequential
stepcan affect therate atwhich kichangesas follows.
1. With probability p,mnew links are added. For each link, one end is randomly chosen ,
leading to a change in kiofpm/N. For each link, the second end attaches preferentially,
leadingtoa changein kiofpm·(ki+1)P
j(kj+1). Hence,
dki
dt=pm1
N+pmki+ 1/summationtext
j(kj+ 1)(18.27)
2. With probability p,mexisting links are rewired. For each rewired link, a randoml y chosen
nodeloses oneincidentedgewhich thenattaches preferenti ally. Thus,theimpacton kiis:
dki
dt=−qm1
N+qmki+ 1/summationtext
j(kj+ 1)(18.28)
3. Withprobability (1−p−q),anewnodeisaddedwith mlinks. Eachofthe mlinksconnects
preferentially,thus:
dki
dt= (1−p−q)Cki+ 1/summationtext
j(kj+ 1)(18.29)
713
Summingthethreeeffects, wehave:
dki
dt= (p−q)m1
N+mki+ 1/summationtext
j(kj+ 1)(18.30)
As thesystemsizeand topologyvarieswithtime,wehave:
N(t) =m0+ (1−p−q)t;/summationdisplay
jkj= 2mt(1−q)−m (18.31)
Astincreases, the constants mandm0can be deleted. Further, for a node added at ti, we
have thatk(ti) =m(the initialization step). Exercise 9 asks you to show that t he solution to
Equation(18.30)has theform
ki(t) = [A(p,q,m ) +m+ 1](t
ti)1/B(p,q,m), (18.32)
A(p,q,m ) = (p−q)(2m(1−q)
1−p−q+ 1), B (p,q,m ) =2m(1−q) + 1−p−q
m(18.33)
Based onfurtheralgebraicderivations,Albertand Barabas i showedthat
P(k)α[k+κ(p,q,m )]−γ(p,q,m),whereκ(p,q,m ) =A(p,q,m )+1andγ(p,q,m ) =B(p,q,m )+1
(18.34)
Equation(18.34)isvalidif, foraﬁxed pandm,
q<q max= min(1−p,(1−p+m)/(1 + 2m))
Thereare nowtwocases.
q<q max:Equation(18.34)isvalidand thedegreedistributionisapo werlaw.
q<q max:Equation (18.34) is invalid, and P(k)can be shown to behave like an exponential dis-
tribution. ThemodelnowbehavesliketheERand WSmodels.
This is similar to the behaviour seen in real networks – some n etworks show a power law
while others show an exponential tail – and a single model can capture both behaviors by tuning
the parameter q. The scale-free regime and the exponential regime are marke d in the graph in
Figure 18.22. The boundary between the two regimes depends o n the value of mand has slope
−m/(1 + 2m). Theareaenclosedbythicklinesshowsthescale-freeregim e;thedashedlineisits
boundarywhen m→∞andthedottedlineis itsboundarywhen m→0.
18.15 ChapterSummary
Peer-to-peer (P2P) networksallowequal participationand resourcesharingamongtheusers. This
chapter ﬁrst analyzed the different types of P2P networks. U nstructured P2P networks are like
714
SFq
0
p 0 1.01.0
E
Figure 18.22: Phase diagram for the Extended Barabasi-Albe rt model. SFdenotes the scale-free
regime, which is enclosed by the thick border. Edenotes the exponential regime which exists in
the remainder of the lower diagonal region of the graph. The p lain line shows the boundary for
m= 1,havingaY-axis interceptat 0.67.
GnutellaandBitTorrent. Westudieddifferentsearchmecha nisms-ﬂooding,constrainedﬂooding,
andblindsearch -forsuchunstructurednetworks. Wealsoex aminedsomedatareplicationstrate-
gies, and their impact on the search performance. The chapte r then studied 3 classical structured
P2Pnetworks-Chord,CAN,Tapestry-allofwhichusethedist ributedhashtableconceptintheir
implementations. Although all the three mechanisms differ , they are similarin that they represent
different trade-offs in search efﬁciency, i.e., path lengt h, and the amount of local storage for im-
plementingthehash tables. Thespectrum ofP2P networksfro m unstructuredto structured offera
wide range of trade-offs for user requirements. The chapter also examined issues such as fairness
and trust management. These issues are importantbecause in the P2P environment where there is
no controlauthority,thesystemmustbeabletoautonomousl yalllowforfairness.
The internet, AS-AS level internets, and the web (WWW) overl ays exhibit some interesting
properties about how they grow and evolve. Many network over lays outside of computer science
also exhibit the same properties. The chapter studied sever al properties of the Internet and the
web graphs. Then, in a more general setting, the chapter exam ined random networks, small-
world networks,nodedegree distributions,scale-free net works,and theimpact oferror and attack
tolerance for such networks. Networks grow in an uncontroll ed fashion, yet, there seems to be
someunderlyingbasisforsuchgrowth. Oftheseveralpropos alstomodelthegrowthofnetworks,
we study the Barabasi-Albert model which appears to be promi sing in its applicability to not just
thecomputersciencenetworks,butalso tonetworksin other disciplinesand natural phenomena.
are beingwidelyused as the
715
18.16 ExerciseProblems
1. (Replication.) Derive the values of average search size A ,Ai, and utilization uifor Square-
rootreplication. Thederivedanswersshouldmatchtheentr ies inTable18.3.
2. (Fault-tolerance in Chord.) Adapt the code in Figure 18.6 so that the nodes manage a suc-
cessorlistor αsuccessors,rather thanasinglesuccessor.
3. (Chord.) IntheChordprotocol,assumethatthesuccessor listateachnodehas α= Ω(logn)
nodes. Showthefollowing.
(a) If a Chord ring is initially stable, and if the probabilit y of subsequent failure of each
node is 0.5, then Locate_Successor returns the closest functional successor node to
thekeybeing searched withhighprobability.
(b) If a Chord ring is initially stable, and if the probabilit y of subsequent failure of each
nodeis0.5, ittakes O(logn)average-case timefor Locate_Successor to complete.
4. (CAN.) Compute the time and message complexity of the dist ributed region reassignment
protocolthatis runperiodicallyby theCAN protocol.
5. (CAN.)Identifyall thechanges tothebaseCAN protocolto accommodatetheoptimization
ofoverloadingcoordinateregions,discussedin Section 18 .5.5.
6. (Power Law in the Internet. [28]) Show that the number of ed ges in the Internet graph that
obeys the power law for the rank exponent is given as follows. Let the graph have nnodes
and rank exponent R. Then:l∼1
2(R+1)(1−1
nR+1)n
7. Show that Equation (18.23) using the Master-equation app roach for the degree distribution
intheextendedBA modelcan besolvedas Equation(18.24).
8. Show that the Master-equation approach used to solve for t he degree distribution in the
extendedBA modelinSection 18.13.2givesthesolutionexpr essedbyEquation( ??).
9. Show that the solution to Equation (18.30) for the degree d istribution in the Extended BA
modelusingcontinuumtheoryanalysisisgivenbyEquation( 18.33).
18.17 BibliographicNotes
The introduction is based on the survey by Risson and Moors [2 6] and Androutsellis-Theotokis
and Spinellis [6]. The discussion on replication and search in unstructured networks is based
on Cohen and Shenker [11], and on Lv, Cao, Cohen, Li, Shenker [ 20], respectively. Gnutella
[14, 15], Napster [22], and Freenet [9] are widely implement ed commercial P2P protocols. The
Chord protocol was proposed by Stoica et al. [29]. The Conten t Addressible Network (CAN)
was proposed by Ratnasamy et al. [24]. The design of Tapestry [18, 19, 33, 34] and the related
716
Pastry [27] overlay was based on the ideas of Plaxton trees pr oposed by Plaxton, Rajaraman, and
Richa[23]. TapestrybuiltonthePlaxtontreesbyproviding betterfault-toleranceandresiliencein
the face of node joins and departures. The discussion on fund amental tradeoffs between routing
table size and network diameter is based on Xu, Kumar, and Yu [ 32] and Ratnasamy, Stoica, and
Shenker[25]. TheBitTorrentsystemwasinitiallyproposed byBrahmCohen[10]. Thediscussion
oftrustmanagementisbased on Guptaet al. [16].
The discussion on the graph structures of complex networks i s structured and based on the
excellentsurveybyAlbertandBarabasi [4]. Thediscussion onpowerlawsandZipf’slawistaken
from the tutorial by Adamic [2]. The power laws for the Intern et were discovered by Siganos
and theFaloutsosbrothers [28]. The discussionon thebetwe enness centrality metricfor graphs is
based on the work by Goh et al. [13]. The random graphs model wa s proposed and analyzed by
Erdos and Renyi [12]. Furtherresults on theproperties on ra ndom graphs were givenby Bollobas
[7,8]. ThesmallworldsmodelwasproposedbyWattsandStrog atz[30]. TheExtendedBarabasi-
Albert model for graph evolutionwas given by Barabasi and Al bert [3]. The analysis of error and
attacktoleranceonexponentialnetworksandon scale-free networksinbased wasdoneby Albert,
Jeong,and Barabasi [5].
717
Bibliography
[1] K.AbererandZ.Despotovic,ManagingTrustinaPeer-To- PeerInformationSystem, InPro-
ceedings of the 10th InternationalConference on Informati onand Knowledge Management ,
Atlanta,Georgia, USA, November2001,pp. 310-317.
[2] L. Adamic, Zipf, Power-Laws, and Pareto - A Ranking Tutor ial,
http://www.hpl.hp.com/research/idl/papers/ranking/r anking.html
[3] R. Albert, A.-L. Barabasi, Topology of Evolving Network s: Local Events and Universality,
PhysicalReviewLetters, Volume85(24): 5234-5237,Decemb er 2000.
[4] R. Albert, A.-L. Barabasi, Statistical Mechanics of Com plex Networks, Review of Modern
Physics,Volume74(1): 47-97,January 2002.
[5] R. Albert, H. Jeong,A. Barabasi, Errorand AttackTolera nce ofComplexNetworks,Nature,
Vol.406,378-381,July2000.
[6] S. Androutsellis-Theotokis, D. Spinellis, A Survey of P eer-to-Peer Content Distribution
Technologies,ACM ComputingSurveys,Vol. 36(4): 335-371, December2004.
[7] B. Bollobas,DiscreteMath,Vol.33, pp.1-, 1981.
[8] B. Bollobas,Random Graphs,AcademicPress, London,198 5.
[9] I. Clarke, O. Sandberg, B. Wiley, T. W. Hong, Freenet: A Di stributed Anonymous Informa-
tion Storage and Retrieval System. In Workshop on Design Issues in Anonymity and Unob-
servability ,Berkeley, California,USA, July2000,pp.46-66.
[10] B. Cohen, Incentives Build Robustness in BitTorrent,
http://www.bittorrent.com/bittorrentecon.pdf
[11] E. Cohen, S. Shenker, Replication Strategies in Unstru ctured Peer-to-Peer Networks, ACM
SIGCOMM, 177-190,2002.
[12] P. Erdos,A. Renyi,Random Graphs.Publ. math.(Debrece n), Vol6, p.290-, 1959
[13] K.Goh,E.Oh,H.Jeong,B.Kahng,D.Kim,Classiﬁcationo fScale-FreeNetworks,Proceed-
ingsoftheNationalAcademy ofSciences, 2002.
718
[14] Gnutella, http://www.gnutella.com/ .
[15] TheGnutellaprotocolspeciﬁcation,
http://www9.limewire.com/
developer/gnutella_protocol_0.4.pdf .
[16] M. Gupta, P. Judge and M. Ammar, A Reputation System for P eer-to-Peer Networks. In
Proceedingsofthe13thInternationalWorkshoponNetworka ndOperatingSystemsSupport
for Digital Audio and Video, (ACM Press) , Monterey, California, USA, June 2003, pp. 144-
152.
[17] M. Gupta, M. H. Ammar, M. Ahamad: Trade-offs between Rel iability and Overheads in
Peer-to-peer ReputationTracking,ComputerNetworks50(4 ): 501-522(2006)
[18] K. Hildrum, J. Kubiatowicz, S. Rao, B. Y. Zhao, Distribu ted Object Location in a Dynamic
Network,ACM SPAA 2002: 41-52
[19] K.Hildrum,J.Kubiatowicz,S.RaoandB.Y.Zhao,Distri butedObjectLocationinaDynamic
Network,TheoryofComputingSystems,March2004,No.37,Pg s.405-440,Springer-Verlag
[20] Q. Lv, P. Cao, E. Cohen, K. Li, S. Shenker, Search and Repl ication in Unstructured Peer-to-
peerNetworks,InternationalConference on Supercomputin g,2002: 84-95
[21] S. Milgram,TheSmall WorldProblem. PsychologyToday, 2, page60-67,1967.
[22] Napster, http://www.napster.com/ .
[23] C. G. Plaxton, R. Rajaraman, A. W. Richa, Accessing Near by Copies of Replicated Objects
inaDistributedEnvironment.ACMSPAA 1997: 311-320
[24] S.Ratnasamy,P.Francis,M.Handley,R.M.Karp,S.Shen ker: Ascalablecontent-addressable
network.SIGCOMM 2001: 161-172.
[25] S. Ratnasamy, I. Stoica, S. Shenker: Routing Algorithm s for DHTs: Some Open Questions.
IPTPS 2002: 45-52
[26] J. Risson, T. Moors, Survey of research towardsrobust p eer-to-peer networks: Search Meth-
ods.Computernetworks,2006 (toappear).
[27] A. Rowstron and P. Druschel, Pastry: Scalable, Distrib uted Object Location and Routing
for Large-Scale Peer-to-Peer Systems, In Proceedings of the IFIP/ACM Middleware 2001 ,
Heidelberg,Germany,November2001,pp. 329-350.
[28] G. Siganos, M. Faloutsos, P. Faloutsos, C. Faloutsos, P ower Laws and the AS-level Internet
Topology,IEEE/ACMTransactionson Networking,11(4): 514 -524,2003.
719
[29] I.Stoica,R.Morris,D.Liben-Nowell,D.Karger,M.F.K aashoek,F.Dabek,H.Balakrishnan,
Chord: AScalablePeer-to-peerLookupServiceforInternet Applications,IEEETransactions
onNetworking11(1): 17-31, February 2003.
[30] D.J.Watts,S.H. Strogatz. Nature, 393,page440,1998.
[31] O. Wolfson, S. Jajodia, Y. Huang, An AdaptiveData Repli cation Algorithm, ACM Transac-
tionson DatabaseSystems,22(2): 255-314,1997.
[32] J. Xu, A. Kumar, X. Yu, On the Fundamental Tradeoffs betw een Routing Table Size and
Network Diameter in Peer-to-Peer Networks, IEEE Journal on Selected Areas in Communi-
cations,22(1): 151-163,Jan 2004.
[33] B. Y.Zhao, L.Huang,J.Stribling,S. Rhea, A.Joseph,J. Kubiatowicz,Tapestry: A Resilient
Global-Scale Overlay for Service Deployment, IEEE Journal on Selected Areas inCommu-
nications,22(1): 41-53,Jan 2004.
[34] B. Y. Zhao, J. D. Kubiatowicz and A. D. Joseph, Tapestry: An Infrastructure for Fault-
Resilient Wide-Area Location and Routing, Technical Report UC Berkeley, CSD-01-1141,
U.C. Berkeley , Berkeley,California, USA, April2001.
720
Index
Compare &Swap,536
Fetch &Increment , 536
Swap,421
Test&Set, 421
Deﬁnitely ,373
Possibly,373
Read-Modify-Write ,539
Abadi,M, 589,613
accuracy properties, 558
Acharya, 99
adaptivealgorithms,122
Afek, Y, 642,644
Agarwal,D, 320
Agrawala, AK,300
agreement
failure-free system,505
Alagar,100
Alvisi,L, 494
anonymousalgorithms,121
antimessages,68
Arora, A, 622,637,643
asynchronousexecution,18
asynchronoussystem,124
atomicbroadcast, 570
atomicregisters,424
authentication,586
authenticationprotocolfailures, 611
authenticationprotocols
withasymmetriccryptosystem,602
withsymmetriccryptosystem,590
authenticationserver, 593
Badrinath, 99Baldoni, R, 494
Barabasi-Albert model
extendedBarabasi-Albert model,713
Bellovin,SM, 609
Bhargava, B, 494
Bremler, A,644
Briatico, D, 458
broadcast, 137
Burrows, M,613
Byzantineagreement, 502
exponentialtreealgorithm,509
upperbound,507
Cao, G,456
causal delivery,98
causal order, 196
optimalalgorithm,198
Raynal-Sciper-Toueg algorithm,197
causal ordering, 40
causal path, 104
causal precedence relation,39
Chakrabarti, S, 613
Chandra, TD,556, 557,561,566,570, 571
Chandrasekaran, S, 242
Chandy, 87,352,353
Chandy, KM,365
channel staterecording,99
checkpoint,102, 447
global,448
local, 447
checkpointing
communication-induced,456
coordinated,454
721
uncoordinated,452
checkpointingalgorithm
Helary-Mostefaoui-Netzer-Raynal proto-
col, 486
Juangand Venkatesan algorithm,466
Koo-Toueg,463
Manivannan-Singhalalgorithm,470
Peterson-Kearns algorithm,479
Chord, 676
churn, 678
clock inaccuracies, 73
clock offset,73
clock skew,73
clocks
matrix,63
physical,72
scalar, 49
vector,51
closure, 622
clustering,700
commonclockprimitives,636
commonknowledge,280
concurrent commonknowledge,281
Epsiloncommonknowledge,280
eventualcommonknowledge,280
protocolsforconcurrentcommonknowl-
edge, 282
timestampedcommonknowledge,280
communication
asynchronous,44
synchronous,44
communicationprimitives,14
asynchronous,14
blocking,14
nonblocking,14
synchronous,14
Compare&Swap, 537
completenessproperties,558
complexnetworks
Barabasi-Albert model,710error and attacktolerance, 704
graph structures,699
Internet, 702
Internet graph, 701
complexitymetrics,127
concurrency,12
concurrency measure, 47
conistentcut,86
conjunctivepredicatedetection
interval-basedpiggybackingalgorithm,390
intervalbased algorithm,379
interval-basedtokenalgorithm,386
state-based tokenalgorithm,384
conjunctivepredicatedetetion
state-based algorithm,381
consensus,503
k-set consensus,521
approximateagreement, 522
impossibilityinsharedmemoryasynchronous
systems,533
impossibilityresultforasynchronoussys-
tems,518
phasekingalgorithm,516
reliablebroadcast, 532
renaming problem,527
transactioncommit,521
wait-free renamingusingsplitters,547
wait-free shared memoryrenaming,545
consensushierarchy,536
consensusproblem,565
solutionusingeventuallystrongFD, 568
solutionusingstrongFD, 566
consensusundercrash failures, 507
Consistentclobalgnapshots,105
consistentglobalsnapshots
necessary and bufﬁcient conditions,102
consistentglobalstate,85
consistentglobalstates,41
consnesus
shared memory k-set consensus,545
722
terminatingreliablebroadcast, 520
content-addressiblenetworks(CAN), 683
convergecast, 137
convergence, 622
crown,186
cryptographicprotocols
designprinciples,589
cut, 86
cut inaditributedcomputation,42
dataindexing,668
deadlock
avoidance, 343
Chandy-Misra-Haas algorithm,352,353
detection,344
Kshemkalyani-Singhalalgorithm,355
Mitchell-Merrittalgorithm,349
phantom,344
prevention,343
resolution,344
deadlock detection,344
deadlocks,318
diffusingcomputationsbasedalgorithms,
348
edge-chasing algorithm,348
global state detection based algorithms,
349
path-pushingalgorithms,348
degreedistributions,700
delayed messages,450
Delporte-Gallet,C, 573
deterministicexecution,122
dictionaryattack, 609
diffusioncomputation,348
Dijkstra,E,619, 624,649
distributeddeadlock, 342
distributeddiscreteeventsimulations,71
DistributedProgram, 37
distributedreset, 637
distributedsystems
characteristics, 1designissues,21
Dolev,S, 646
Dolve,S, 640
duplicatemessages, 450
dynamicterminationdetection,249
El Abbadi,A, 320
Elnozahy,EN, 494
emulations,20
message-passing,13
shared memory,13
synchronoussystem,19
EncryptedKeyExchange(EKE)protocol,609
enumeratingconsistentsnapshots,109
eventcounting,51
eventualaccuracy properties,559
evolvingnetworks,712
executions realizable with synchronous com-
munication,185
timestamps,188
failuredetector
adaptive,578
implementation,576
realistic, 574
weakest, 575,576
failuredetectors, 557
reducibility,560
types,560
failurepattern, 557
failurerecovery,450
Fowler,58
free-riding, 695
Fuchs, WK, 457
futureconeofan event,43
Garg, V, 582
Gartner, F, 640
generalized deadlocks, 355
generalized random graphnetworks,709
Gligor,V, 365
globalstate, 40,86
723
consistent,85
globalvirtualtime,70
Gnutella,670
Gouda,M, 622,637,638, 643,649
graph algorithms,129
maximalindependentset(MIS), 158
all sourcesshortestpaths,142
compactroutingtables,161
connected dominatingset(CDS), 160
constrainedﬂooding,145
delay boundedSteinertrees, 221
distancevectorrouitng,141
leaderelection, 163
minimumweightspanningtree,146,152
reversepathforwarding, 219
singlesourceshortestpath,140,141
spanningtree, 130,131,134, 137
Steinertrees, 220
groupcommunication,195
fault-tolerant,216
multicast,209
Guerraoui, R, 582
Haas, L, 352,353
Helary,93
Helary,JM, 486
Herman, T,365
Huang,ST, 643
illegitimatestate, 622
impersonationattack, 604
incarnationnumber,473
incrementalsnapshot,92
inhibition,123
interactiveconsistency,503
interconnectionnetworks,6,667
Israeli, A, 640
Jard, 60
Johnson,D, 494
Jourdan,60
Juang,466Kaminsky,M,613
Kasami,325
Katz, S, 651
Kearns, 91,100
Kearns, P, 479
Kerberos
authenticationservice, 597
authenticator,600
Kerberos authenticationservice, 597,599
Kim,KH, 494
Knapp, 348
Knapp, E,365
knowledge
agreement, 279
asynchronoussystem,278
logic,272
multi-dimensionalclocks,287
operators, 272
properties, 277
transfer, 283
Koo,R, 463
Kripkestructures,274
Kshemkalyani,56,309,355
Kshemkalyani,AD,365
Kutten,S, 642
Lai, 95
Lam, S, 613
Lamport,87, 297
Lamport’shappensbeforerelation, 39
layering, 635
lazy failuredetectionprotocol,579
legitimatestate, 622
Lodha, 309
log-based rollbackrecovery,458
logging
causal, 462
optimistic,461
pessimistic,459
logicalclocks, 48
lostmessages,450
724
Maekawa, M,317
Manivannan,109,470
Marzullo,K, 494
matrixclocks,63
matrixtime,63
Mattern,97
Mattern,F, 251
memoryconsistency,402
atomicconsistency,403
causal consistency,409
hierarchy,413
linearizability,403
pipelinedRAM (PRAM), 411
processorconsistency,411
sequentialconsistency,406
slowmemory,412
Menasce, D, 365
Merritt,349
Merritt,M,609
messageordering, 180
asynchronousexecutions,180
hierarchy,188
synchronousexecutions,184
messageordering paradigms
causal order, 181
FIFO executions,180
Misra,352,353
Mitchell,349
modularization,635
monitoringglobalgtate,100
Moran,S, 640
Mostefaoui,486
muddychildrenpuzzle, 271
multicast,209
core-based trees, 222
destinationagreement based, 216
ﬁxed sequencerbased, 216
historybased,214
movingsequencerbased, 215
privilegebased, 215propagationtrees, 210
Muntz,R, 365
mutualexclusion
Agarwal-ElAbbadi algorithm,320
fast mutualexclusion,418
hardware-assisted, 421
Lamport’salgorithm,297
Lamport’sbakery algorithm,416
Lodha-Kshemkalyanialgorithm,309
Maekawa’salgorithm,317
quorum-basedalgorithms,316
Raymond’salgorithm,327
Ricart-Agrawala algorithm,300
Singhal’sdynamicalgorithm,303
Suzuki-Kasami algorithm,325
token-based algorithms,324
Napster, 667
Needham and Schroeder protocol,603
Needham, R, 589,603, 613
Network TimeProtocol(NTP), 74
Netzer, 105,109
Netzer, R, 486
nonblockinguniversalalgorithm,541
nonce, 591
nondeterministicexecution,122
object replication,165
one-timepassword,594
orphan messages,450
Otway-Rees protocol,596
overlays,118,668
structured, 669
unstrucuted,669
parallel system,5
coupling,10
Flynn’staxonomy,10
interconnectionnetworks,6
multiprocessor,5
paralelism,11
Pareto law,701
725
partialsynchrony,576
partiallysynchronousmodels,576
pastconeofan event,43
path
causal, 104
zigzag, 103
peer-to-peer
ﬂooding,672
proportionalreplication,674
randomwalk, 672
replication,674
square-root replication,674
uniformreplication,674
Peterson, SL, 479
physicalclock cynchronization,72
physicalclocks, 72
powerlaw,701
Prakah, R, 494
predicates, 371
conjunctive,378
disjunctive,393
modalities,373
observer-independent,393
relational,374
stable,371
unstable,372
Prisoners’dilemma,695
probabilisticself-stabilization,623
probemessage,353
programstructure, 128
progress,344
pseudostabilization,656
pseudo-stabilizingsystem,623
publickeycertiﬁcate, 603
R-graph, 110
Ramamoorthy,CV, 365
randomgraphs, 707
randomizedself-stabilization,623
Raymond,K, 327
Raynal, M,486, 582Reducing Weak FD toaStrong FD, 561
registerhierarchy, 423
regularregisters,424
relationalpredicate detection,374
rendezvous, 191
reputationmanagement,696
Ricart, 300
Richard, G,494
safe registers,423
safety, 344
scalar time,49
scale-free networks,704, 706,710
Schiper, A, 582
Schneider, M,650
Schroeder, MD,603
SecureRemotePassword(SRP)protocol,610
secure socketslayer, 605
self-stabilization,622
cost, 634
forfault folerance, 652
roleofcompilers,649
self-stabilizing algorithm for 1-maximal in-
dependent set,645
self-stabilizingdistributedspanningtrees,638
self-stabilizingtoken ring,624
shared memory,399
shared memorymutualexclusion,416
simultaneousregions,100
Singhal, 56,109,303, 355,365,456,470
Sistla, P, 494
small-worldnetworks,699,709
snapshots,262
solutionto atomicbroadcast,571
spanningtree, 236
Spezialetti, 91,100
splitters,547
SSL Protocol,605
stableproperty,90
stablestorage,445–447
starvation,334
726
statelattice,374
staticterminationdetection, 247
Strom,494
surface ofthefuturecone, 44
surface ofthepastcone, 44
Suzuki, 325
symmetry,654
synchronizers,153
αsynchronizer,155
βsynchronizer,156
gammasynchronizer, 156
simplesynchronizer,154
synchronousexecution,19
synchronousorder, 192
synchronoussystem,124
Tapestry,689
terminationdetection,231, 358
atomiccomputationmodel,251
channel countingmethod,258
distributedsnapshots,232
faultydistributedsystem,260
fourcountermethod,253
message-optimal,242
spanning-sreetbased,236
vectorcounters method,256
verygeneral model,245
weightthrowing,234
time
matrix,63
physical,72
scalar, 49
vector,51
virtual,64
timewarp mechanism,67
time-spacediagram, 38
topologybased primitives,636
totalorder, 205
centralized algorithm,205
three-phasedistributedalgorithm,206
totalorderproperty,571totalordering, 50
Toueg,S, 463, 556,557,561,566, 570,571
transientfailure, 623
tree-structured quorum,320
Tseng, 260
uniformalgorithms,122
uniformconsensus,573
universalityofconsensusobjects,540
uselesscheckpoints,453,457
vectorclocks,51
efﬁcient implementations,56
size, 54
vectorclockssize, 54
vectortime,51,479
Venkatesan, 92
Venkatesan, S, 242,466
Venkatesan, S., 100
virtualtime,64
wait-for-graph (WFG), 343
wait-free algorithms,126
wait-free atomicsnapshot,435
wait-free consensus
Compare&Swap, 538
wait-free register simulations, 426–429, 432,
433
wait-free simulations,423
wait-free universalalgorithm,544
wait-freedom, 422
Wang, Y-M,106
Watts Strogatzmodel,709
weight-throwingscheme,260
Welch, J, 494
wide-mouthfrog protocol,592
Woo, T,613
Wu, TD, 610
Xu, 105
Yang, 95
Yemini,494
727
Yung,M, 642
zigzag cycle,104
zigzag path,103
Zipf’slaw,702
Zwaenepoel, 58
728

Learning Kernel Classiﬁers
Adaptive Computation and Machine Learning
Thomas G. Dietterich, Editor
Christopher Bishop, David Heckerman, Michael Jordan, and Michael Kearns, Associate Editors
Bioinformatics: The Machine Learning Approach, Pierre Baldi and Søren Brunak
Reinforcement Learning: An Introduction, Richard S. Sutton and Andrew G. Barto
Graphical Models for Machine Learning and Digital Communication , Brendan
J. Frey
Learning in Graphical Models , Michael I. Jordan
Causation, Prediction, and Search, second edition ,Peter Spirtes, Clark Glymour,
and Richard Scheines
Principles of Data Mining, David Hand, Heikki Mannilla, and Padhraic Smyth
Bioinformatics: The Machine Learning Approach, second edition, Pierre Baldi and
Søren Brunak
Learning Kernel Classiﬁers: Theory and Algorithms , Ralf Herbrich
Learning with Kernels: Support V ector Machines, Regularization, Optimization,
and Beyond, Bernhard Schölkopf and Alexander J. Smola
Learning Kernel Classiﬁers
Theory and Algorithms
Ralf Herbrich
The MIT Press
Cambridge, MassachusettsLondon, England
c/circlecopyrt2002 Massachusetts Institute of Technology
All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means
(including photocopying, recording, or information storage and retrieval) without permission in writing from the
publisher.
This book was set in Times Roman by the author using the L ATEX document preparation system and was printed
and bound in the United States of America.
Library of Congress Cataloging-in-Publication Data
Herbrich, Ralf.
Learning kernel classiﬁers : theory and algorithms / Ralf Herbrich.
p. cm. — (Adaptive computation and machine learning)
Includes bibliographical references and index.
ISBN 0-262-08306-X (hc. : alk. paper)
1. Machine learning. 2. Algorithms. I. Title. II. Series.
Q325.5 .H48 2001
006.3/prime1—dc21
2001044445
To my wife, Jeannette
There are many branches of learning theory that have not yet been analyzed and that are important
both for understanding the phenomenon of learning and for practical applications. They are waiting
for their researchers.
—Vladimir V apnik
Geometry is illuminating; probability theory is powerful.
—Pál Ruján
Contents
Series Foreword xv
Preface xvii
1 Introduction 1
1.1 The Learning Problem and (Statistical) Inference 1
1 . 1 . 1 S u p e r v i s e d L e a r n i n g ............... 3
1 . 1 . 2 U n s u p e r v i s e d L e a r n i n g.............. 6
1 . 1 . 3 R e i n f o r c e m e n t L e a r n i n g ............. 7
1.2 Learning Kernel Classiﬁers 8
1.3 The Purposes of Learning Theory 11
I LEARNING ALGORITHMS2 Kernel Classiﬁers from a Machine Learning Perspective 17
2.1 The Basic Setting 17
2.2 Learning by Risk Minimization 24
2.2.1 The (Primal) Perceptron Algorithm ....... 2 6
2 . 2 . 2 R e g u l a r i z e d R i s k F u n c t i o n a l s .......... 2 7
2.3 Kernels and Linear Classiﬁers 30
2 . 3 . 1 T h e K e r n e l T e c h n i q u e .............. 3 32.3.2 Kernel Families .................. 3 6
2.3.3 The Representer Theorem . . . ......... 4 7
2.4 Support V ector Classiﬁcation Learning 49
2 . 4 . 1 M a x i m i z i n g t h e M a r g i n ............. 4 9
2.4.2 Soft Margins—Learning with Training Error . . 53
2.4.3 Geometrical Viewpoints on Margin Maximization 56
2.4.4 The ν– T r i c k a n d O t h e r V a r i a n t s ......... 5 8
x Contents
2.5 Adaptive Margin Machines 61
2.5.1 Assessment of Learning Algorithms ....... 6 1
2 . 5 . 2 L e a v e - O n e - O u t M a c h i n e s ............ 6 32.5.3 Pitfalls of Minimizing a Leave-One-Out Bound . 642 . 5 . 4 A d a p t i v e M a r g i n M a c h i n e s ............ 6 6
2.6 Bibliographical Remarks 68
3 Kernel Classiﬁers from a Bayesian Perspective 73
3.1 The Bayesian Framework 73
3 . 1 . 1 T h e P o w e r o f C o n d i t i o n i n g o n D a t a ....... 7 9
3.2 Gaussian Processes 81
3.2.1 Bayesian Linear Regression . . . ........ 8 2
3.2.2 From Regression to Classiﬁcation ........ 8 7
3.3 The Relevance V ector Machine 92
3.4 Bayes Point Machines 97
3 . 4 . 1 E s t i m a t i n g t h e B a y e s P o i n t ............ 1 0 0
3.5 Fisher Discriminants 103
3.6 Bibliographical Remarks 110
II LEARNING THEORY
4 Mathematical Models of Learning 115
4.1 Generative vs. Discriminative Models 1164.2 PAC and VC Frameworks 121
4.2.1 Classical PAC and VC Analysis . ........ 1 2 3
4 . 2 . 2 G r o w t h F u n c t i o n a n d V C D i m e n s i o n ...... 1 2 74 . 2 . 3 S t r u c t u r a l R i s k M i n i m i z a t i o n ........... 1 3 1
4.3 The Luckiness Framework 134
4.4 PAC and VC Frameworks for Real-V alued Classiﬁers 140
4.4.1 VC Dimensions for Real-V alued Function Classes 1464.4.2 The PAC Margin Bound ............. 1 5 0
4.4.3 Robust Margin Bounds ............. 1 5 1
4.5 Bibliographical Remarks 158
xi Contents
5 Bounds for Speciﬁc Algorithms 163
5.1 The PAC-Bayesian Framework 164
5.1.1 PAC-Bayesian Bounds for Bayesian Algorithms 164
5.1.2 A PAC-Bayesian Margin Bound ......... 1 7 2
5.2 Compression Bounds 175
5.2.1 Compression Schemes and Generalization Error 1765.2.2 On-line Learning and Compression Schemes . . 182
5.3 Algorithmic Stability Bounds 185
5.3.1 Algorithmic Stability for Regression . . . . . . 1855.3.2 Algorithmic Stability for Classiﬁcation . . . . . 190
5.4 Bibliographical Remarks 193
III APPENDICES
A Theoretical Background and Basic Inequalities 199
A.1 Notation 199
A.2 Probability Theory 200
A.2.1 Some Results for Random V ariables ....... 2 0 3
A.2.2 Families of Probability Measures ........ 2 0 7
A.3 Functional Analysis and Linear Algebra 215
A.3.1 Covering, Packing and Entropy Numbers . . . . 220A.3.2 Matrix Algebra .................. 2 2 2
A.4 Ill-Posed Problems 239
A.5 Basic Inequalities 240
A.5.1 General (In)equalities . .............. 2 4 0
A.5.2 Large Deviation Bounds ............. 2 4 3
B Proofs and Derivations—Part I 253
B.1 Functions of Kernels 253
B.2 Efﬁcient Computation of String Kernels 254
B.2.1 Efﬁcient Computation of the Substring Kernel . . 255B.2.2 Efﬁcient Computation of the Subsequence Kernel 255
B.3 Representer Theorem 257
B.4 Convergence of the Perceptron 258
xii Contents
B.5 Convex Optimization Problems of Support V ector Machines 259
B . 5 . 1 H a r d M a r g i n S V M ................ 2 6 0
B . 5 . 2 L i n e a r S o f t M a r g i n L o s s S V M.......... 2 6 0
B . 5 . 3 Q u a d r a t i c S o f t M a r g i n L o s s S V M ........ 2 6 1B.5.4ν– L i n e a r M a r g i n L o s s S V M ........... 2 6 2
B.6 Leave-One-Out Bound for Kernel Classiﬁers 263
B.7 Laplace Approximation for Gaussian Processes 265
B.7.1 Maximization of f
Tm+1|X=x,Zm=z......... 2 6 6
B.7.2 Computation of /Sigma1 ................ 2 6 8
B.7.3 Stabilized Gaussian Process Classiﬁcation . . . . 269
B.8 Relevance V ector Machines 271
B.8.1 Derivative of the Evidence w.r.t. θ........ 2 7 1
B.8.2 Derivative of the Evidence w.r.t. σ2
t....... 2 7 3
B.8.3 Update Algorithms for Maximizing the Evidence 274
B . 8 . 4 C o m p u t i n g t h e L o g - E v i d e n c e .......... 2 7 5B.8.5 Maximization of f
W|Zm=z............. 2 7 6
B.9 A Derivation of the Operation ⊕µ 277
B.10 Fisher Linear Discriminant 278
C Proofs and Derivations—Part II 281
C.1 VC and PAC Generalization Error Bounds 281
C . 1 . 1 B a s i c L e m m a s .................. 2 8 1
C . 1 . 2 P r o o f o f T h e o r e m 4 . 7 ............... 2 8 4
C.2 Bound on the Growth Function 287
C.3 Luckiness Bound 289
C.4 Empirical VC Dimension Luckiness 292C.5 Bound on the Fat Shattering Dimension 296
C.6 Margin Distribution Bound 298
C.7 The Quantiﬁer Reversal Lemma 300
C.8 A PAC-Bayesian Marin Bound 302
C . 8 . 1 B a l l s i n V e r s i o n S p a c e .............. 3 0 3C . 8 . 2 V o l u m e R a t i o T h e o r e m .............. 3 0 6
C.8.3 A V olume Ratio Bound . ............. 3 0 8
xiii Contents
C . 8 . 4 B o l l m a n n ’ s L e m m a ................ 3 1 1
C.9 Algorithmic Stability Bounds 314
C.9.1 Uniform Stability of Functions Minimizing a Regularized
R i s k........................ 3 1 5
C.9.2 Algorithmic Stability Bounds . ......... 3 1 6
D Pseudocodes 321
D.1 Perceptron Algorithm 321
D.2 Support V ector and Adaptive Margin Machines 323
D.2.1 Standard Support V ector Machines ........ 3 2 3
D.2.2ν–Support V ector Machines . . ......... 3 2 4
D . 2 . 3 A d a p t i v e M a r g i n M a c h i n e s ............ 3 2 4
D.3 Gaussian Processes 325
D.4 Relevance V ector Machines 325
D.5 Fisher Discriminants 329
D.6 Bayes Point Machines 330
List of Symbols 331
References 339Index 357
Series Foreword
One of the most exciting recent developments in machine learning is the discovery
and elaboration of kernel methods for classiﬁcation and regression. These algo-rithms combine three important ideas into a very successful whole. From mathe-matical programming, they exploit quadratic programming algorithms for convexoptimization; from mathematical analysis, they borrow the idea of kernel repre-sentations; and from machine learning theory, they adopt the objective of ﬁndingthe maximum-margin classiﬁer. After the initial development of support vectormachines, there has been an explosion of kernel-based methods. Ralf Herbrich’s
Learning Kernel Classiﬁers is an authoritative treatment of support vector ma-
chines and related kernel classiﬁcation and regression methods. The book examinesthese methods both from an algorithmic perspective and from the point of view oflearning theory. The book’s extensive appendices provide pseudo-code for all of thealgorithms and proofs for all of the theoretical results. The outcome is a volumethat will be a valuable classroom textbook as well as a reference for researchers inthis exciting area.
The goal of building systems that can adapt to their environment and learn from
their experience has attracted researchers from many ﬁelds, including computerscience, engineering, mathematics, physics, neuroscience, and cognitive science.Out of this research has come a wide variety of learning techniques that have thepotential to transform many scientiﬁc and industrial ﬁelds. Recently, several re-search communities have begun to converge on a common set of issues surround-ing supervised, unsupervised, and reinforcement learning problems. The MIT Press
series on Adaptive Computation and Machine Learning seeks to unify the many di-
verse strands of machine learning research and to foster high quality research andinnovative applications.
Thomas Dietterich
Preface
Machine learning has witnessed a resurgence of interest over the last few years,
which is a consequence of the rapid development of the information industry.Data is no longer a scarce resource—it is abundant. Methods for “intelligent”data analysis to extract relevant information are needed. The goal of this bookis to give a self-contained overview of machine learning, particularly of kernelclassiﬁers—both from an algorithmic and a theoretical perspective. Although there
exist many excellent textbooks on learning algorithms (see Duda and Hart (1973),
Bishop (1995), V apnik (1995), Mitchell (1997) and Cristianini and Shawe-Taylor(2000)) and on learning theory (see V apnik (1982), Kearns and V azirani (1994),Wolpert (1995), Vidyasagar (1997) and Anthony and Bartlett (1999)), there is nosingle book which presents both aspects together in reasonable depth. Instead,these monographs often cover much larger areas of function classes, e.g., neuralnetworks, decision trees or rule sets, or learning tasks (for example regressionestimation or unsupervised learning). My motivation in writing this book is tosummarize the enormous amount of work that has been done in the speciﬁc ﬁeldof kernel classiﬁcation over the last years. It is my aim to show how all the workis related to each other. To some extent, I also try to demystify some of the recentdevelopments, particularly in learning theory, and to make them accessible to alarger audience. In the course of reading it will become apparent that many alreadyknown results are proven again, and in detail, instead of simply referring to them.
The motivation for doing this is to have all these different results together in one
place—in particular to see their similarities and (conceptual) differences.
The book is structured into a general introduction (Chapter 1) and two parts,
which can be read independently. The material is emphasized through many ex-amples and remarks. The book ﬁnishes with a comprehensive appendix containingmathematical background and proofs of the main theorems. It is my hope that thelevel of detail chosen makes this book a useful reference for many researchersworking in this ﬁeld. Since the book uses a very rigorous notation systems, it isperhaps advisable to have a quick look at the background material and list of sym-bols on page 331.
xviii Preface
The ﬁrst part of the book is devoted to the study of algorithms for learning
kernel classiﬁers. This part starts with a chapter introducing the basic concepts oflearning from a machine learning point of view. The chapter will elucidate the ba-sic concepts involved in learning kernel classiﬁers—in particular the kernel tech-nique. It introduces the support vector machine learning algorithm as one of themost prominent examples of a learning algorithm for kernel classiﬁers. The secondchapter presents the Bayesian view of learning. In particular, it covers Gaussianprocesses, the relevance vector machine algorithm and the classical Fisher discrim-inant. The ﬁrst part is complemented by Appendix D, which gives all the pseudo
code for the presented algorithms. In order to enhance the understandability of the
algorithms presented, all algorithms are implemented in R—a statistical language
similar to S-PLUS . The source code is publicly available at
http://www.kernel-
machines.org/ . At this web site the interested reader will also ﬁnd additional
software packages and many related publications.
The second part of the book is devoted to the theoretical study of learning algo-
rithms, with a focus on kernel classiﬁers. This part can be read rather independentlyof the ﬁrst part, although I refer back to speciﬁc algorithms at some stages. The ﬁrstchapter of this part introduces many seemingly different models of learning. It wasmy objective to give easy-to-follow “proving arguments” for their main results,sometimes presented in a “vanilla” version. In order to unburden the main body,all technical details are relegated to Appendix B and C. The classical PAC andVC frameworks are introduced as the most prominent examples of mathematicalmodels for the learning task. It turns out that, despite their unquestionable gener-
ality, they only justify training error minimization and thus do not fully use the
training sample to get better estimates for the generalization error. The followingsection introduces a very general framework for learning—the luckiness frame-
work .This chapter concludes with a PAC-style analysis for the particular class of
real-valued (linear) functions, which qualitatively justiﬁes the support vector ma-chine learning algorithm. Whereas the ﬁrst chapter was concerned with boundswhich hold uniformly for all classiﬁers, the methods presented in the second chap-ter provide bounds for speciﬁc learning algorithms. I start with the PAC-Bayesianframework for learning, which studies the generalization error of Bayesian learn-ing algorithms. Subsequently, I demonstrate that for all learning algorithms thatcan be expressed as compression schemes, we can upper bound the generalizationerror by the fraction of training examples used—a quantity which can be viewedas a compression coefﬁcient. The last section of this chapter contains a very re-cent development known as algorithmic stability bounds. These results apply to all
algorithms for which an additional training example has only limited inﬂuence.
xix Preface
As with every book, this monograph has (almost surely) typing errors as well
as other mistakes. Therefore, whenever you ﬁnd a mistake in this book, I would bevery grateful to receive an email at
herbrich@kernel-machines.org .The list of
errata will be publicly available at http://www.kernel-machines.org .
This book is the result of two years’ work of a computer scientist with a
strong interest in mathematics who stumbled onto the secrets of statistics ratherinnocently. Being originally fascinated by the the ﬁeld of artiﬁcial intelligence, Istarted programming different learning algorithms, ﬁnally ending up with a giantlearning system that was completely unable to generalize. At this stage my interest
in learning theory was born—highly motivated by the seminal book by V apnik
(1995). In recent times, my focus has shifted toward theoretical aspects. Takingthat into account, this book might at some stages look mathematically overloaded
(from a practitioner’s point of view) or too focused on algorithmical aspects (froma theoretician’s point of view). As it presents a snapshot of the state-of-the-art, thebook may be difﬁcult to access for people from a completely different ﬁeld. Ascomplementary texts, I highly recommend the books by Cristianini and Shawe-Taylor (2000) and V apnik (1995).
This book is partly based on my doctoral thesis (Herbrich 2000), which I wrote
at the Technical University of Berlin. I would like to thank the whole statisticsgroup at the Technical University of Berlin with whom I had the pleasure ofcarrying out research in an excellent environment. In particular, the discussionswith Peter Bollmann-Sdorra, Matthias Burger, Jörg Betzin and Jürgen Schweigerwere very inspiring. I am particularly grateful to my supervisor, Professor Ulrich
Kockelkorn, whose help was invaluable. Discussions with him were always very
delightful, and I would like to thank him particularly for the inspiring environmenthe provided. I am also indebted to my second supervisor, Professor John Shawe-Taylor, who made my short visit at the Royal Holloway College a total success.His support went far beyond the short period at the college, and during the manydiscussions we had, I easily understood most of the recent developments in learningtheory. His “anytime availability” was of uncountable value while writing thisbook. Thank you very much! Furthermore, I had the opportunity to visit theDepartment of Engineering at the Australian National University in Canberra. Iwould like to thank Bob Williamson for this opportunity, for his great hospitalityand for the many fruitful discussions. This book would not be as it is without themany suggestions he had. Finally, I would like to thank Chris Bishop for giving allthe support I needed to complete the book during my ﬁrst few months at MicrosoftResearch Cambridge.
xx Preface
During the last three years I have had the good fortune to receive help from
many people all over the world. Their views and comments on my work werevery inﬂuential in leading to the current publication. Some of the many people Iam particularly indebted to are David McAllester, Peter Bartlett, Jonathan Bax-ter, Shai Ben-David, Colin Campbell, Nello Cristianini, Denver Dash, ThomasHofmann, Neil Lawrence, Jens Matthias, Manfred Opper, Patrick Pérez, GunnarRätsch, Craig Saunders, Bernhard Schölkopf, Matthias Seeger, Alex Smola, Pe-ter Sollich, Mike Tipping, Jaco V ermaak, Jason Weston and Hugo Zaragoza. Inthe course of writing the book I highly appreciated the help of many people who
proofread previous manuscripts. David McAllester, Jörg Betzin, Peter Bollmann-
Sdorra, Matthias Burger, Thore Graepel, Ulrich Kockelkorn, John Krumm, GaryLee, Craig Saunders, Bernhard Schölkopf, Jürgen Schweiger, John Shawe-Taylor,Jason Weston, Bob Williamson and Hugo Zaragoza gave helpful comments on thebook and found many errors. I am greatly indebted to Simon Hill, whose help inproofreading the ﬁnal manuscript was invaluable. Thanks to all of you for yourenormous help!
Special thanks goes to one person—Thore Graepel. We became very good
friends far beyond the level of scientiﬁc cooperation. I will never forget the manyenlightening discussions we had in several pubs in Berlin and the few excellentconference and research trips we made together, in particular our trip to Australia.Our collaboration and friendship was—and still is—of uncountable value for me.Finally, I would like to thank my wife, Jeannette, and my parents for their patienceand moral support during the whole time. I could not have done this work without
my wife’s enduring love and support. I am very grateful for her patience and
reassurance at all times.
Finally, I would like to thank Mel Goldsipe, Bob Prior, Katherine Innis and
Sharon Deacon Warne at The MIT Press for their continuing support and helpduring the completion of the book.
1 Introduction
This chapter introduces the general problem of machine learning and how it re-
lates to statistical inference. It gives a short, example-based overview about super-
vised, unsupervised and reinforcement learning. The discussion of how to design alearning system for the problem of handwritten digit recognition shows that kernelclassiﬁers offer some great advantages for practical machine learning. Not only arethey fast and simple to implement, but they are also closely related to one of themost simple but effective classiﬁcation algorithms—the nearest neighbor classi-ﬁer. Finally, the chapter discusses which theoretical questions are of particular, andpractical, importance.
1.1 The Learning Problem and (Statistical) Inference
It was only a few years after the introduction of the ﬁrst computer that oneof man’s greatest dreams seemed to be realizable—artiﬁcial intelligence. It wasenvisaged that machines would perform intelligent tasks such as vision, recognitionand automatic data analysis. One of the ﬁrst steps toward intelligent machines ismachine learning.
The learning problem can be described as ﬁnding a general rule that explains
data given only a sample of limited size. The difﬁculty of this task is best comparedto the problem of children learning to speak and see from the continuous ﬂow ofsounds and pictures emerging in everyday life. Bearing in mind that in the earlydays the most powerful computers had much less computational power than a cellphone today, it comes as no surprise that much theoretical research on the potentialof machines’ capabilities to learn took place at this time. One of the most inﬂuentialworks was the textbook by Minsky and Papert (1969) in which they investigatewhether or not it is realistic to expect machines to learn complex tasks. Theyfound that simple, biologically motivated learning systems called perceptrons were
2 Chapter 1
incapable of learning an arbitrarily complex problem. This negative result virtually
stopped active research in the ﬁeld for the next ten years. Almost twenty years later,the work by Rumelhart et al. (1986) reignited interest in the problem of machinelearning. The paper presented an efﬁcient, locally optimal learning algorithm forthe class of neural networks, a direct generalization of perceptrons. Since then,an enormous number of papers and books have been published about extensionsand empirically successful applications of neural networks. Among them, the mostnotable modiﬁcation is the so-called support vector machine—a learning algorithmfor perceptrons that is motivated by theoretical results from statistical learning
theory. The introduction of this algorithm by V apnik and coworkers (see V apnik
(1995) and Cortes (1995)) led many researchers to focus on learning theory and itspotential for the design of new learning algorithms.
The learning problem can be stated as follows: Given a sample of limited
size, ﬁnd a concise description of the data. If the data is a sample of input-output patterns, a concise description of the data is a function that can producethe output, given the input. This problem is also known as the supervised learningproblem because the objects under considerations are already associated with targetvalues (classes, real-values). Examples of this learning task include classiﬁcation ofhandwritten letters and digits, prediction of the stock market share values, weatherforecasting, and the classiﬁcation of news in a news agency.
If the data is only a sample of objects without associated target values, the
problem is known as unsupervised learning. A concise description of the datacould be a set of clusters or a probability density stating how likely it is to
observe a certain object in the future. Typical examples of unsupervised learning
tasks include the problem of image and text segmentation and the task of noveltydetection in process control.
Finally, one branch of learning does not fully ﬁt into the above deﬁnitions:
reinforcement learning. This problem, having its roots in control theory, considersthe scenario of a dynamic environment that results in state-action-reward triplesas the data. The difference between reinforcement and supervised learning is thatin reinforcement learning no optimal action exists in a given state, but the learningalgorithm must identify an action so as to maximize the expected reward over time.The concise description of the data is in the form of a strategy that maximizes thereward. Subsequent subsections discuss these three different learning problems.
Viewed from a statistical perspective, the problem of machine learning is far
from new. In fact, it can be related to the general problem of inference, i.e., go-ing from particular observations to general descriptions. The only difference be-
tween the machine learning and the statistical approach is that the latter considers
3 Introduction
description of the data in terms of a probability measure rather than a determin-
istic function (e.g., prediction functions, cluster assignments). Thus, the tasks tobe solved are virtually equivalent. In this ﬁeld, learning methods are known as es-timation methods. Researchers long have recognized that the general philosophyof machine learning is closely related to nonparametric estimation. The statisticalapproach to estimation differs from the learning framework insofar as the latterdoes not require a probabilistic model of the data. Instead, it assumes that the onlyinterest is in further prediction on new instances—a less ambitious task, whichhopefully requires many fewer examples to achieve a certain performance.
The past few years have shown that these two conceptually different approaches
converge. Expressing machine learning methods in a probabilistic framework isoften possible (and vice versa), and the theoretical study of the performances ofthe methods is based on similar assumptions and is studied in terms of probabilitytheory. One of the aims of this book is to elucidate the similarities (and differences)between algorithms resulting from these seemingly different approaches.
1.1.1 Supervised Learning
In the problem of supervised learning we are given a sample of input-output pairs(also called the training sample ), and the task is to ﬁnd a deterministic function
that maps any input to an output such that disagreement with future input-output
observations is minimized. Clearly, whenever asked for the target value of an objectpresent in the training sample, it is possible to return the value that appearedthe highest number of times together with this object in the training sample.However, generalizing to new objects not present in the training sample is difﬁcult.
Depending on the type of the outputs, classiﬁcation learning, preference learning
and function learning are distinguished.
Classiﬁcation Learning
If the output space has no structure except whether two elements of the outputspace are equal or not, this is called the problem of classiﬁcation learning . Each
element of the output space is called a class . This problem emerges in virtually
any pattern recognition task. For example, the classiﬁcation of images to theclasses “image depicts the digit x”w h e r e xranges from “zero” to “nine” or the
classiﬁcation of image elements (pixels) into the classes “pixel is a part of a cancertissue” are standard benchmark problems for classiﬁcation learning algorithms (see
4 Chapter 1
Figure 1.1 Classiﬁcation learning of handwritten digits. Given a sample of images from
the four different classes “zero”, “two”, “seven” and “nine” the task is to ﬁnd a function
which maps images to their corresponding class (indicated by different colors of the
border). Note that there is no ordering between the four different classes.
also Figure 1.1). Of particular importance is the problem of binary classiﬁcation,
i.e., the output space contains only two elements, one of which is understoodas the positive class and the other as the negative class. Although conceptuallyvery simple, the binary setting can be extended to multiclass classiﬁcation by
considering a series of binary classiﬁcations.
Preference Learning
If the output space is an order space—that is, we can compare whether two
elements are equal or, if not, which one is to be preferred—then the problem ofsupervised learning is also called the problem of preference learning . The elements
of the output space are called ranks . As an example, consider the problem of
learning to arrange Web pages such that the most relevant pages (according to a
query) are ranked highest (see also Figure 1.2). Although it is impossible to observethe relevance of Web pages directly, the user would always be able to rank any pairof documents. The mappings to be learned can either be functions from the objects(Web pages) to the ranks, or functions that classify two documents into one of threeclasses: “ﬁrst object is more relevant than second object”, “objects are equivalent”and “second object is more relevant than ﬁrst object”. One is tempted to think thatwe could use any classiﬁcation of pairs, but the nature of ranks shows that therepresented relation on objects has to be asymmetric and transitive. That means, if“object bis more relevant than object a” and “object cis more relevant than object
5 Introduction
Figure 1.2 Preference learning of W eb pages. Given a sample of pages with different
relevances (indicated by dif ferent background colors), the task is to ﬁnd an ordering of the
pages such that the most relevant pages are mapped to the highest rank.
b”, then it must follow that “object cis more relevant than object a”. Bearing this
requirement in mind, relating classiﬁcation and preference learning is possible.
Function Learning
If the output space is a metric space such as the real numbers then the learningtask is known as the problem of function learning (see Figure 1.3). One of the
greatest advantages of function learning is that by the metric on the output spaceit is possible to use gradient descent techniques whenever the functions value
f(x)is a differentiable function of the object xitself. This idea underlies the
back-propagation algorithm (Rumelhart et al. 1986), which guarantees the ﬁnding
of a local optimum. An interesting relationship exists between function learningand classiﬁcation learning when a probabilistic perspective is taken. Consideringa binary classiﬁcation problem, it sufﬁces to consider only the probability that agiven object belongs to the positive class. Thus, whenever we are able to learnthe function from objects to [0,1](representing the probability that the object is
from the positive class), we have learned implicitly a classiﬁcation function by
thresholding the real-valued output at
1
2. Such an approach is known as logistic
regression in the ﬁeld of statistics, and it underlies the support vector machine
classiﬁcation learning algorithm. In fact, it is common practice to use the real-valued output before thresholding as a measure of conﬁdence even when there isno probabilistic model used in the learning process.
6 Chapter 1
−0.5 0.0 0.5 1.01.0 1.5 2.0 2.5 3.0 3.5
xy
−0.5 0.0 0.5 1.01.0 1.5 2.0 2.5 3.0 3.5
xy
−0.5 0.0 0.5 1.01.0 1.5 2.0 2.5 3.0 3.5
xy
linear function cubic function 10th degree polynomial
Figure 1.3 Function learning in action. Given is a sample of points together with asso-
ciated real-valued target values (crosses). S hown are the best ﬁts to the set of points using
a linear function (left), a cubic function (middle) and a 10th degree polynomial (right).
Intuitively, the cubic function class seems to be most appropriate; using linear functions
the points are under-ﬁtted whereas the 10th degree polynomial over-ﬁts the given sample.
1.1.2 Unsupervised Learning
In addition to supervised learning there exists the task of unsupervised learning. In
unsupervised learning we are given a training sample of objects, for example im-ages or pixels, with the aim of extracting some “structure” from them—e.g., iden-tifying indoor or outdoor images, or differentiating between face and backgroundpixels. This is a very vague statement of the problem that should be rephrased bet-ter as learning a concise representation of the data. This is justiﬁed by the followingreasoning: If some structure exists in the training objects, it is possible to take ad-vantage of this redundancy and ﬁnd a short description of the data. One of the mostgeneral ways to represent data is to specify a similarity between any pairs of ob-jects. If two objects share much structure, it should be possible to reproduce thedata from the same “prototype”. This idea underlies clustering algorithms :G i v e na
ﬁxed number of clusters, we aim to ﬁnd a grouping of the objects such that similar
objects belong to the same cluster. We view all objects within one cluster as being
similar to each other. If it is possible to ﬁnd a clustering such that the similarities ofthe objects in one cluster are much greater than the similarities among objects fromdifferent clusters, we have extracted structure from the training sample insofar asthat the whole cluster can be represented by one representative. From a statisticalpoint of view, the idea of ﬁnding a concise representation of the data is closely re-lated to the idea of mixture models, where the overlap of high-density regions of the
individual mixture components is as small as possible (see Figure 1.4). Since wedo not observe the mixture component that generated a particular training object,we have to treat the assignment of training examples to the mixture components as
7 Introduction
first feature
second featuredensity
Figure 1.4 (Left) Clustering of 150 training points (black dots) into three clusters (white
crosses). Each color depicts a region of points belonging to one cluster. (Right) Probability
density of the estimated mixture model.
hidden variables—a fact that makes estimation of the unknown probability mea-
sure quite intricate. Most of the estimation procedures used in practice fall into therealm of expectation-maximization (EM) algorithms (Dempster et al. 1977).
1.1.3 Reinforcement Learning
The problem of reinforcement learning is to learn what to do—how to map situa-
tions to actions—so as to maximize a given reward. In contrast to the supervisedlearning task, the learning algorithm is not told which actions to take in a given sit-uation. Instead, the learner is assumed to gain information about the actions taken
by some reward not necessarily arriving immediately after the action is taken. One
example of such a problem is learning to play chess. Each board conﬁguration, i.e.,the position of all ﬁgures on the 8 ×8 board, is a given state; the actions are the
possible moves in a given position. The reward for a given action (chess move) iswinning the game, losing it or achieving a draw. Note that this reward is delayedwhich is very typical for reinforcement learning. Since a given state has no “op-timal” action, one of the biggest challenges of a reinforcement learning algorithmis to ﬁnd a trade-off between exploration and exploitation. In order to maximizereward a learning algorithm must choose actions which have been tried out in thepast and found to be effective in producing reward—it must exploit its current
8 Chapter 1
featuresimage index
1 100 200 300 400 500 600 700 7844 1 11 5 2 12 52 9 3 43 84 2 4 9
Figure 1.5 (Left) The ﬁrst 49 digits (28 ×28 pixels) of the MNIST dataset. (Right)
The 49 images in a data matrix obtained by concatenation of the 28 rows thus resulting in28·28=784–dimensional data vectors. Note that w e sorted the images such that the four
images of “zero” are the ﬁrst, then the 7 images of “one” and so on.
knowledge. On the other hand, to discover those actions the learning algorithm has
to choose actions not tried in the past and thus explore the state space. There is nogeneral solution to this dilemma, but that neither of the two options can lead ex-clusively to an optimal strategy is clear. As this learning problem is only of partialrelevance to this book, the interested reader should refer Sutton and Barto (1998)for an excellent introduction to this problem.
1.2 Learning Kernel Classiﬁers
Here is a typical classiﬁcation learning problem. Suppose we want to design asystem that is able to recognize handwritten zip codes on mail envelopes. Initially,we use a scanning device to obtain images of the single digits in digital form.In the design of the underlying software system we have to decide whether we“hardwire” the recognition function into our program or allow the program tolearn its recognition function. Besides being the more ﬂexible approach, the idea oflearning the recognition function offers the additional advantage that any changeinvolving the scanning can be incorporated automatically; in the “hardwired”approach we would have to reprogram the recognition function whenever wechange the scanning device. This ﬂexibility requires that we provide the learning
9 Introduction
Figure 1.6 Classiﬁcation of three new images (leftmost column) by ﬁnding the ﬁve
images from Figure 1.5 which are closest to it using the Euclidean distance.
algorithm with some example classiﬁcations of typical digits. In this particular case
it is relatively easy to acquire at least 100–1000 images and label them manually(see Figure 1.5 (left)).
Our next decision involves the representation of the images in the computer.
Since the scanning device supplies us with an image matrix of intensity values atﬁxed positions, it seems natural to use this representation directly, i.e., concatenatethe rows of the image matrix to obtain a long data vector for each image. As aconsequence, the data can be represented by a matrix Xwith as many rows as
number of training samples and as many columns are there are pixels per image(see Figure 1.5 (right)). Each row x
iof the data matrix Xrepresents one image of
a digit by the intensity values at the ﬁxed pixel positions.
Now consider a very simple learning algorithm where we just store the training
examples. In order to classify a new test image, we assign it to the class of thetraining image closest to it. This surprisingly easy learning algorithm is also knownas the nearest-neighbor classiﬁer and has almost optimal performance in the limit
of a large number of training images. In our example we see that nearest neighborclassiﬁcation seems to perform very well (see Figure 1.6). However, this simpleand intuitive algorithm suffers two major problems:
1. It requires a distance measure which must be small between images depicting
the same digit and large between images showing different digits. In the exampleshown in Figure 1.6 we use the Euclidean distance
vextenddoublevextenddoublex−˜xvextenddoublevextenddouble
def=radicaltpradicalvertexradicalvertexradicalbt
Nsummationdisplay
j=1parenleftbig
xj−˜xjparenrightbig2,
10 Chapter 1
where N=784 is the number of different pixels. From Figure 1.6 we already
see that not all of the closest images seem to be related to the correct class, whichindicates that we should look for a better representation.
2. It requires storage of the whole training sample and the computation of the
distance to all the training samples for each classiﬁcation of a new image. This be-
comes a computational problem as soon as the dataset gets larger than a few hun-dred examples. Although the method of nearest neighbor classiﬁcation performsbetter for training samples of increasing size, it becomes less realizable in practice.
In order to address the second problem, we introduce ten parameterized functions
f
0,..., f9that map image vectors to real numbers. A positive number fi(x)indi-
cates belief that the image vector is showing the digit i; its magnitude should be
related to the degree with which the image is believed to depict the digit i.T h e
interesting question is: Which functions should we consider? Clearly, as compu-tational time is the only reason to deviate from nearest-neighbor classiﬁcation, weshould only consider functions whose value can quickly be evaluated. On the otherhand, the functions should be powerful enough to approximate the classiﬁcation ascarried out by the nearest neighbor classiﬁer. Consider a linear function, i.e.,
f
i(x)=Nsummationdisplay
j=1wj·xj, (1.1)
which is simple and quickly computable. We summarize all the images showing
the same digit in the training sample into one parameter vector wfor the function
fi. Further, by the Cauchy-Schwarz inequality, we know that the difference of
this function evaluated at two image vectors xand˜xis bounded from above by
/bardblw/bardbl·vextenddoublevextenddoublex−˜xvextenddoublevextenddouble. Hence, if we only consider parameter vectors wwith a constant norm
/bardblw/bardbl, it follows that whenever two points are close to each other , any linear function
would assign similar real-values to them as well. These two properties make linearfunctions perfect candidates for designing the handwritten digit recognizer.
In order to address the ﬁrst problem, we consider a generalized notion of a
distance measure as given by
vextenddoublevextenddoublex−˜xvextenddoublevextenddouble=radicaltpradicalvertexradicalvertexradicalbt
 nsummationdisplay
j=1parenleftbig
φj(x)−φjparenleftbig˜xparenrightbigparenrightbig2. (1.2)
Here, φ=(φ1,...,φ n)is known as the feature mapping and allows us to
change the representation of the digitized images. For example, we could con-
11 Introduction
sider all products of intensity values at two different positions, i.e. φ(x)=
(x1x1,..., x1xN,x2x1,..., xNxN), which allows us to exploit correlations in
the image. The advantage of choosing a distance measure as given in equation(1.2) becomes apparent when considering that for all parameter vectors wthat
can be represented as a linear combination of the mapped training examplesφ(x
1),...,φ(xm),
w=msummationdisplay
i=1αiφ(xi),
the resulting linear function in equation (1.1) can be written purely in terms of a
linear combination of inner product functions in feature space, i.e.,
f(x)=msummationdisplay
i=1αinsummationdisplay
j=1φj(xi)·φj(x)
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
k(xi,x)=msummationdisplay
i=1αik(xi,x).
In contrast to standard linear models, we need never explicitly construct the param-
eter vector w. Specifying the inner product function k, which is called the kernel ,i s
sufﬁcient. The linear function involving a kernel is known as kernel classiﬁer and
is parameterized by the vector α∈ /CAmof expansion coefﬁcients. What has not yet
been addressed is the question of which parameter vector worαto choose when
given a training sample. This is the topic of the ﬁrst part of this book.
1.3 The Purposes of Learning Theory
The ﬁrst part of this book may lead the reader to wonder—after learning so manydifferent learning algorithms—which one to use for a particular problem. This
legitimate question is one that the results from learning theory try to answer.
Learning theory is concerned with the study of learning algorithms’ performance.By casting the learning problem into the powerful framework of probability theory,we aim to answer the following questions:
1. How many training examples do we need to ensure a certain performance?
2. Given a ﬁxed training sample, e.g., the forty-nine images in Figure 1.5, what
performance of the function learned can be guaranteed?
12 Chapter 1
3. Given two different learning algorithms, which one should we choose for a
given training sample so as to maximize the performance of the resulting learningalgorithm?
I should point out that all these questions must be followed by the additional phrase
“with high probability over the random draw of the training sample”. This require-ment is unavoidable and reﬂects the fact that we model the training sample as arandom sample. Thus, in any of the statements about the performance of learningalgorithms we have the inherent duality between precision and conﬁdence: Themore precise the statement on the algorithm’s performance is, e.g., the prediction
error is not larger than 5%, the less conﬁdent it is. In the extreme case, we can say
that the prediction error is exactly 5%, but we have absolutely no (mathematical)conﬁdence in this statement. The performance measure is most easily deﬁned whenconsidering supervised learning tasks. Since we are given a target value for eachobject, we need only to measure by how much the learned function deviates fromthe target value at all objects—in particular for the unseen objects. This quantity ismodeled by the expected loss of a function over the random draw of object-targetpairs. As a consequence our ultimate interest is in (probabilistic) upper bounds onthe expected loss of the function learned from the random training sample, i.e.,
P(training samples s .t.the expected loss of the function learned ≤ε(δ))≥1−δ.
The function εis called a bound on the generalization error because it quantiﬁes
how much we are mislead in choosing the optimal function when using a learningalgorithm, i.e., when generalizing from a given training sample to a general pre-diction function. Having such a bound at our disposal allows us to answer the three
questions directly:
1. Since the function εis dependent on the size of the training sample
1,w eﬁ xε
and solve for the training sample size.
2. This is exactly the question answered by the generalization error bound. Note
that the ultimate interest is in bounds that depend on the particular training sampleobserved; a bound independent of the training sample would give a guarantee ex-ante which therefore cannot take advantage of some “simplicity” in the training
sample.
3. If we evaluate the two generalization errors for the two different learning
algorithms, we should choose the algorithm with the smaller generalization error
1 In fact, it will be inversely related because with increasing size of the training sample the expected loss will be
non-increasing due to results from large deviation theory (see Appendix A.5.2).
13 Introduction
bound. Note that the resulting bound would no longer hold for the selection
algorithm. Nonetheless, Part II of this book shows that this can be achieved with aslight modiﬁcation.
It comes as no surprise that learning theory needs assumptions to hold. In contrast
to parametric statistics, which assumes that the training data is generated from adistribution out of a given set, the main interest in learning theory is in boundsthat hold for all possible data distributions. The only way this can be achieved is toconstrain the class of functions used. In this book, this is done by considering linearfunctions only. A practical advantage of having results that are valid for all possibleprobability measures is that we are able to check whether the assumptions imposedby the theory are valid in practice. The price we have to pay for this generality is
that most results of learning theory are more an indication than a good estimate
of the real generalization error. Although recent efforts in this ﬁeld aim to tightengeneralization error bound as much as possible, it will always be the case that anydistribution-dependent generalization error bound is superior in terms of precision.
Apart from enhancing our understanding of the learning phenomenon, learn-
ing theory is supposed to serve another purpose as well—to suggest new algo-rithms. Depending on the assumption we make about the learning algorithms, wewill arrive at generalization error bounds involving different measures of (data-dependent) complexity terms. Although these complexity terms give only upperbounds on the generalization error, they provide us with ideas as to which quanti-ties should be optimized. This is the topic of the second part of the book.
I Learning Algorithms

2 Kernel Classiﬁers from a Machine Learning
Perspective
This chapter presents the machine learning approach to learning kernel classiﬁers.
After a short introduction to the problem of learning a linear classiﬁer, it showshow learning can be viewed as an optimization task. As an example, the classicalperceptron algorithm is presented. This algorithm is an implementation of a moregeneral principle known as empirical risk minimization. The chapter also presents
a descendant of this principle, known as regularized (structural) risk minimization .
Both these principles can be applied in the primal or dual space of variables. It isshown that the latter is computationally less demanding if the method is extendedto nonlinear classiﬁers in input space. Here, the kernel technique is the essential
method used to invoke the nonlinearity in input space. The chapter presents severalfamilies of kernels that allow linear classiﬁcation methods to be applicable evenif no vectorial representation is given, e.g., strings. Following this, the support
vector method for classiﬁcation learning is introduced. This method elegantly
combines the kernel technique and the principle of structural risk minimization.The chapter ﬁnishes with a presentation of a more recent kernel algorithm calledadaptive margin machines . In contrast to the support vector method, the latter aims
at minimizing a leave-one-out error bound rather than a structural risk.
2.1 The Basic Setting
The task of classiﬁcation learning is the problem of ﬁnding a good strategy toassign classes to objects based on past observations of object-class pairs. We shallonly assume that all objects xare contained in the set/CG, often referred to as the
input space .L e t /CHbe a ﬁnite set of classes called the output space . If not otherwise
stated, we will only consider the two-element output space {−1,+1}, in which case
18 Chapter 2
the learning problem is called a binary classiﬁcation learning task. Suppose we are
given a sample of mtraining objects ,
x=(x1,..., xm)∈ /CGm,
together with a sample of corresponding classes,
y=(y1,..., ym)∈ /CHm.
We will often consider the labeled training sample,1
z=(x,y)=((x1,y1),...,(xm,ym))∈(
/CG× /CH)m= /CIm,
and assume that zis a sample drawn identically and independently distributed (iid)
according to some unknown probability measure PZ.
Deﬁnition 2.1 (Learning problem) The learning problem is to ﬁnd the unknown
(functional) relationship h ∈ /CH
/CGbetween objects x ∈ /CGand targets y ∈ /CH
based solely on a sample z=(x,y)=((x1,y1),...,(xm,ym))∈(
/CG× /CH)m
of size m∈ /C6drawn iid from an unknown distribution PXY. If the output space/CHcontains a ﬁnite number |/CH|of elements then the task is called a classiﬁcation
learning problem .
Of course, having knowledge of PXY= PZis sufﬁcient for identifying this
relationship as for all objects x,
PY|X=x(y)=PZ((x,y))
PX(x)=PZ((x,y))
summationtext
˜y∈ /CHPZ((x,˜y)). (2.1)
Thus, for a given object x∈ /CGwe could evaluate the distribution PY|X=xover
classes and decide on the class ˆy∈ /CHwith the largest probability PY|X=xparenleftbig
ˆyparenrightbig
.
Estimating PZbased on the given sample z, however, poses a nontrivial problem.
In the (unconstrained) class of all probability measures, the empirical measure
vz((x,y))=|{i∈{1,..., m}|zi=(x,y)}|
m(2.2)
1 Though mathematically the training sample is a sequence of iid drawn object-class pairs (x,y)we sometimes
take the liberty of calling the training sample a training set . The notation z∈zthen refers to the fact that there
exists an element ziin the sequence zsuch that zi=z.
19 Kernel Classiﬁers from a Machine Learning Perspective
is among the “most plausible” ones, because
vz({z1,..., zm})=msummationdisplay
i=1vz(zi)=1.
However, the corresponding “identiﬁed” relationship hvz∈ /CH
/CGis unsatisfactory
because
hvz(x)=summationdisplay
xi∈xyi·Ix=xi
assigns zero probability to all unseen objects-class pairs and thus cannot be used
for predicting further classes given a new object x∈ /CG. In order to resolve this
difﬁculty, we need to constrain the set /CH
/CGof possible mappings from objects
x∈ /CGto classes y∈ /CH. Often, such a restriction is imposed by assuming a given
hypothesis space /C0⊆ /CH
/CGof functions2h: /CG→ /CH. Intuitively, similar objects xi
should be mapped to the same class yi. This is a very reasonable assumption if we
wish to infer classes on unseen objects x based on a given training sample zonly.
A convenient way to model similarity between objects is through an inner
product function /angbracketleft·,·/angbracketrightwhich has the appealing property that its value is maximal
whenever its arguments are equal. In order to employ inner products to measuresimilarity between objects we need to represent them in an inner product spacewhich we assume to be /lscript
n
2(see Deﬁnition A.39).
Deﬁnition 2.2 (Features and feature space) A function φi: /CG→ /CAthat maps
each object x ∈ /CGto a real value φi(x)is called a feature . Combining n features
φ1,...,φ nresults in a feature mapping φ: /CG→ /C3⊆/lscriptn
2and the space /C3is called
afeature space .
In order to avoid an unnecessarily complicated notation we will abbreviate φ(x)
byxfor the rest of the book. The vector x∈ /C3is also called the representation of
x∈ /CG. This should not be confused with the training sequence xwhich results in
anm×nmatrix X=parenleftbig
x/prime
1;...;x/prime
mparenrightbig
when applying φto it.
Example 2.3 (Handwritten digit recognition) The important task of classifying
handwritten digits is one of the most prominent examples of the application of
learning algorithms. Suppose we want to automatically construct a procedure
2 Since each his a hypothetical mapping to classes, we synonymously use classiﬁer , hypothesis and function to
refer to h.
20 Chapter 2
which can assign digital images to the classes “image is a picture of 1” and “image
is not a picture of 1”. Typically, each feature φi: /CG→ /CAis the intensity of
ink at a ﬁxed picture element, or pixel, of the image. Hence, after digitalization
at N×N pixel positions, we can represent each image as a high dimensional
vector x(to be precise, N2–dimensional). Obviously, only a small subset of the
N2–dimensional space is occupied by handwritten digits3, and, due to noise in the
digitization, we might have the same picture x mapped to different vectors xi,xj.
This is assumed encapsulated in the probability measure PX. Moreover , for small
N , similar pictures x i≈xjare mapped to the same data vector xbecause the
single pixel positions are too coarse a representation of a single image. Thus, it
seems reasonable to assume that one could hardly ﬁnd a deterministic mappingfrom N
2–dimensional vectors to the class “picture of 1”. This gives rise to a
probability measure PY|X=x. Both these uncertainties—which in fact constitute the
basis of the learning problem—are expressed via the unknown probability measureP
Z(see equation (2.1)).
In this book, we will be concerned with linear functions or classiﬁers only .Let us
formally deﬁne what we mean when speaking about linear classiﬁers.
Deﬁnition 2.4 (Linear function and linear classiﬁer) Given a feature mapping
φ: /CG→ /C3⊆/lscriptn
2, the function f : /CG→ /CAof the form4
fw(x)=/angbracketleftφ(x),w/angbracketright=/angbracketleftx,w/angbracketright
is called a linear function and the n–dimensional vector w∈ /C3is called a weight
vector .A linear classiﬁer is obtained by thresholding a linear function,
hw(x)=sign(/angbracketleftx,w/angbracketright). (2.3)
Clearly, the intuition that similar objects are mapped to similar classes is satisﬁed
by such a model because, by the Cauchy-Schwarz inequality (see Theorem A.106),we know that
vextendsinglevextendsingle/angbracketleftw,x
i/angbracketright−angbracketleftbig
w,xjangbracketrightbigvextendsinglevextendsingle=vextendsinglevextendsingleangbracketleftbig
w,xi−xjangbracketrightbigvextendsinglevextendsingle≤/bardblw/bardbl·vextenddoublevextenddoublexi−xjvextenddoublevextenddouble;
3 To see this, imagine that we generate an image by tossing a coin N2times and mark a black dot in a N×N
array, if the coin shows head. Then, it is very unlikely that we will obtain an image of a digit. This outcome is
expected as digits presumably have a pictorial structure in common.
4 In order to highlight the dependence of fonw,w eu s e fwwhen necessary.
21 Kernel Classiﬁers from a Machine Learning Perspective
that is, whenever two data points are close in feature space (smallvextenddoublevextenddoublexi−xjvextenddoublevextenddouble), their
difference in the real-valued output of a hypothesis with weight vector w∈ /C3is
also small. It is important to note that the classiﬁcation hw(x)remains unaffected
if we rescale the weight wby some positive constant,
∀λ> 0:∀x∈ /CG: sign(/angbracketleftx,λw/angbracketright)=sign(λ/angbracketleftx,w/angbracketright)=sign(/angbracketleftx,w/angbracketright). (2.4)
Thus, if not stated otherwise, we assume the weight vector wto be of unit length,/BY={x/mapsto→/angbracketleftx,w/angbracketright|w∈ /CF}⊆ /CA
/CG, (2.5)/CF={w∈ /C3|/bardbl w/bardbl=1}⊂ /C3, (2.6)/C0=braceleftBig
hwdef=sign(fw)|fw∈ /BYbracerightBig
⊆ /CH
/CG. (2.7)
Ergo, the set /BY, also referred to as the hypothesis space , is isomorphic to the unit
hypersphere /CFin /CAn(see Figure 2.1).
The task of learning reduces to ﬁnding the “best” classiﬁer f∗in the hypothesis
space /BY. The most difﬁcult question at this point is: “How can we measure the
goodness of a classiﬁer f? We would like the goodness of a classiﬁer to be
strongly dependent on the unknown measure PZ; otherwise, we would not have
a learning problem because f∗could be determined without knowledge of the
underlying relationship between objects and classes expressed via PZ.
pointwise w.r.t. the object-class pairs (x,y)due to the independence assumption
made for z.
a positive, real-valued function, making the maximization task computationally
easier.
All these requirements can be encapsulated in a ﬁxed loss function l : /CA× /CH→ /CA.
Here l(f(x),y)measures how costly it is when the prediction at the data point
xisf(x)but the true class is y. It is natural to assume that l(+∞,+1)=
l(−∞,−1)=0, that is, the greater y·f(x)the better the prediction of f(x)
was. Based on the loss lit is assumed that the goodness of fis the expected loss
EXYbracketleftbig
l(f(X),Y)bracketrightbig
, sometimes referred to as the expected risk. In summary, the
ultimate goal of learning can be described as:
Based on the training sample z∈ /CIm, a hypothesis space /BY⊆ /CA
/CGand a
loss function l: /CA× /CH→ /CAﬁnd the function
f∗=argmin
f∈ /BYEXYbracketleftbig
l(f(X),Y)bracketrightbig
.

22 Chapter 2
Assuming an unknown, but ﬁxed, measure PZover the object-class space /CIwe
can view the expectation value EXYbracketleftbig
l(f(X),Y)bracketrightbig
o ft h el o s sa sa n expected risk
functional over /BY.
Deﬁnition 2.5 (Expected risk) G i v e nal o s sl : /CA× /CH→ /CAand a measure PXY,
the functional
R[f]def=EXYbracketleftbig
l(f(X),Y)bracketrightbig
, (2.8)
is called expected risk orexpected loss of a function f ∈ /BY⊆ /CA
/CG, respectively.
If the loss function l : /CH× /CH→ /CAmaps from the predicted and true classes to the
reals, the expected risk is also deﬁned by (2.8) but this time w.r .t. h ∈ /C0⊆ /CH
/CG.
Example 2.6 (Classiﬁcation loss) In the case of classiﬁcation learning, a natural
measure of goodness of a classiﬁer h ∈ /C0is the probability of assigning a new
object to the wrong class, i.e., PXY(h(X)/negationslash=Y). In order to cast this into a loss-
based framework we exploit the basic fact that P(A)=Ebracketleftbig
IAbracketrightbig
for some A. As a
consequence, using the zero-one loss l0−1: /CA× /CH→ /CAfor real-valued functions
l0−1(f(x),y)def=Iyf(x)≤0, (2.9)
renders the task of ﬁnding the classiﬁer with minimal misclassiﬁcation probability
as a risk minimization task. Note that, due to the fact that y ∈{−1,+1},t h e
zero-one loss in equation (2.9) is a special case of the more general loss function
l0−1: /CH× /CH→ /CA
l0−1(h(x),y)def=Ih(x)/negationslash=y. (2.10)
Example 2.7 (Cost matrices) Returning to Example 2.3 we see that the loss given
by equation (2.9) is inappropriate for the task at hand. This is due to the fact thatthere are approximately ten times more “no pictures of 1” than “pictures of 1”.
Therefore, a classiﬁer assigning each image to the class “no picture of 1” (this
classiﬁer is also known as the default classiﬁer f) would have an expected risk of
about 10%. In contrast, a classiﬁer assigning each image to the class “picture of1” would have an expected risk of about 90%. To correct this imbalance of prior
probabilities P
Y(+1)and PY(−1)one could deﬁne a 2×2cost matrix
C=parenleftbigg
0 c12
c21 0parenrightbigg
.
23 Kernel Classiﬁers from a Machine Learning Perspective
Hypothesis space Feature space
Figure 2.1 (Left) The hypothesis space /CFfor linear classiﬁers in /CA3. Each single point
xdeﬁnes a plane in /CA3and thus incurs a grand circle {w∈ /CF|/angbracketleftx,w/angbracketright=0}in hypothesis
space (black lines). The three data points in the right picture induce the t hree planes in the
left picture. (Right) Considering a ﬁxed classiﬁer w(single dot on the left) the decision
planebraceleftbig
x∈ /CA3|/angbracketleftx,w/angbracketright=0bracerightbig
is shown.
Let 1yand 1sign(f(x))denote the 2×1indicator vectors of the true class and the
classiﬁcation made by f ∈ /BYat x∈ /CG. Then we have a cost matrix classiﬁcation
loss lCby
lC(f(x),y)def=1/prime
yC1 sign(f(x))=

c12 y=+ 1and f(x)<0
c21 y=− 1and f(x)>0
0 otherwise .
Obviously, setting c 12=PY(−1)and c 21=PY(+1)leads to equal risks for both
default classiﬁers and thus allows the incorporation of prior knowledge on theprobabilities P
Y(+1)and PY(−1).
Remark 2.8 (Geometrical picture) Linear classiﬁers, parameterized by a weight
vector w, are hyperplanes passing through the origin in feature space /C3.E a c hc l a s -
siﬁer divides the feature space into two open half spaces, X +1(w)⊂ /C3,X−1(w)⊂
24 Chapter 2/C3by the hyperplane5X0(w)⊂ /C3using the following rule,
Xy(w)={x∈ /C3|sign(/angbracketleftx,w/angbracketright)=y}.
Considering the images of X 0(w)in object space /CG
tildewideX0(w)={x∈ /CG|/angbracketleftx,w/angbracketright=0},
this set is sometimes called the decision surface . Our hypothesis space /CF for
weight vectors wis the unit hypersphere in /CAn(see equation (2.6)). Hence, having
ﬁxed x, the unit hypersphere /CF is subdivided into three disjoint sets W +1(x)⊂/CF,W−1(x)⊂ /CFand W 0(x)⊂ /CFby exactly the same rule, i.e.,
Wy(x)={w∈ /CF|sign(/angbracketleftx,w/angbracketright)=y}.
As can be seen in Figure 2.1 (left), for a ﬁnite sample x=(x1,..., xm)of training
objects and any vector y=(y1,..., ym)∈{−1,+1}mof labelings the resulting
equivalence classes
Wz=mintersectiondisplay
i=1Wyi(xi)
are (open) convex polyhedra. Clearly, the labeling of the x idetermines the training
error of each equivalence class
Wz={w∈ /CF|∀i∈{1,..., m}:sign(/angbracketleftxi,w/angbracketright)=yi}.
2.2 Learning by Risk Minimization
Apart from algorithmical problems, as soon as we have a ﬁxed object space /CG,a
ﬁxed set (or space) /BYof hypotheses and a ﬁxed loss function l, learning reduces to
a pure optimization task on the functional R[f].
Deﬁnition 2.9 (Learning algorithm) Given an object space /CG, an output space/CHand a ﬁxed set /BY⊆ /CA
/CGof functions mapping /CGto /CA,a learning algorithm /BT
5 With a slight abuse of notation, we use sign (0)=0.
25 Kernel Classiﬁers from a Machine Learning Perspective
for the hypothesis space /BYis a mapping6/BT:∞uniondisplay
m=1(
/CG× /CH)m→ /BY.
The biggest difﬁculty so far is that we have no knowledge of the function to be
optimized, i.e., we are only given an iid sample zinstead of the full measure
PZ. Thus, it is impossible to solve the learning problem exactly. Nevertheless, for
any learning method we shall require its performance to improve with increasingtraining sample size, i.e., the probability of drawing a training sample zsuch
that the generalization error is large will decrease with increasing m. Here, the
generalization error is deﬁned as follows.
Deﬁnition 2.10 (Generalization error) Given a learning algorithm/BTand a loss
l: /CA× /CH→ /CAthe generalization error of /BTis deﬁned as
R[
/BT,z]def=R[
/BT(z)]−inf
f∈ /BYR[f].
In other words, the generalization error measures the deviation of the expected risk
of the function learned from the minimum expected risk.
The most well known learning principle is the empirical risk minimization (ERM)
principle. Here, we replace PZbyvz, which contains all knowledge that can be
drawn from the training sample z. As a consequence the expected risk becomes an
empirically computable quantity known as the empirical risk.
Deﬁnition 2.11 (Empirical risk) Given a training sample z∈(
/CG× /CH)mthe
functional
Remp [f,z]def=1
mmsummationdisplay
i=1l(f(xi),yi), (2.11)
is called the empirical risk functional over f∈ /BY⊆ /CA
/CGortraining error of f ,
respectively.
6 The deﬁnition for the case of hypotheses h∈ /C0⊆ /CH
/CGis equivalent.
26 Chapter 2
By construction, Remp can be minimized solely on the basis of the training sample
z. We can write any ERM algorithm in the form,/BTERM(z)def=argmin
f∈ /BYRemp [f,z]. (2.12)
In order to be a consistent learning principle, the expected risk R[
/BTERM(z)]must
converge to the minimum expected risk R[f∗], i.e.,
∀ε> 0: lim
m→∞PZmparenleftbig
Rbracketleftbig/BTERM(Z)bracketrightbig
−Rbracketleftbig
f∗bracketrightbig
>εparenrightbig
=0, (2.13)
where the randomness is due to the random choice of the training sample z.
It is known that the empirical risk Remp [f,z]of a ﬁxed function fconverges
toward R[f]at an exponential rate w.r.t. mfor any probability measure PZ(see
Subsection A.5.2). Nonetheless, it is not clear whether this holds when we con-sider the empirical risk minimizer/BTERM(z)given by equation (2.12) because this
function changes over the random choice of training samples z. We shall see in
Chapter 4 that the ﬁniteness of the number nof feature space dimensions com-
pletely determines the consistency of the ERM principle.
2.2.1 The (Primal) Perceptron Algorithm
The ﬁrst iterative procedure for learning linear classiﬁers presented is the percep-
tron learning algorithm proposed by F. Rosenblatt. The learning algorithm is given
on page 321 and operates as follows:
1. At the start the weight vector wis set to 0.
2. For each training example (xi,yi)it is checked whether the current hypothesis
correctly classiﬁes or not. This can be achieved by evaluating the sign of yi/angbracketleftxi,w/angbracketright.
If the ith training sample is not correctly classiﬁed then the misclassiﬁed pattern xi
is added to or subtracted from the current weight vector depending on the correct
class yi. In summary, the weight vector wis updated to w+yixi.
3. If no mistakes occur during an iteration through the training sample zthe
algorithm stops and outputs w.
The optimization algorithm is a mistake-driven procedure, and it assumes the
existence of a version space V(z)⊆ /CF, i.e., it assumes that there exists at least
one classiﬁer fsuch that Remp [f,z]=0.
27 Kernel Classiﬁers from a Machine Learning Perspective
Deﬁnition 2.12 (Version space) Given the training sample z=(x,y)∈(
/CG× /CH)m
and a hypothesis space /C0⊆ /CH
/CG,w ec a l l
V/C0(z)def={h∈ /C0|∀i∈{1,..., m}:h(xi)=yi}⊆ /C0
the version space , i.e., the set of all classiﬁers consistent with the training sample.
In particular , for linear classiﬁers given by (2.5)–(2.7) we synonymously call theset of consistent weight vectors
V(z)def={w∈ /CF|∀i∈{1,..., m}:yi/angbracketleftxi,w/angbracketright>0}⊆ /CF
the version space .
Since our classiﬁers are linear in feature space, such training samples are called
linearly separable. In order that the perceptron learning algorithm works for any
training sample it must be ensured that the unknown probability measure PZsatis-
ﬁes R[f∗]=0. Viewed differently, this means that PY|X=x(y)=Iy=h∗(x),h∗∈ /C0,
where h∗is sometimes known as the teacher perceptron . It should be noticed that
the number of parameters learned by the perceptron algorithm is n, i.e., the dimen-
sionality of the feature space /C3. We shall call this space of parameters the primal
space, and the corresponding algorithm the primal perceptron learning algorithm.
As depicted in Figure 2.2, perceptron learning is best viewed as starting from anarbitrary
7point w0on the hypersphere /CF, and each time we observe a misclas-
siﬁcation with a training example (xi,yi), we update wttoward the misclassiﬁed
training object yixi(see also Figure 2.1 (left)). Thus, geometrically, the perceptron
learning algorithm performs a walk through the primal parameter space with eachstep made in the direction of decreasing training error. Note, however, that in theformulation of the algorithm given on page 321 we do not normalize the weightvector wafter each update.
2.2.2 Regularized Risk Functionals
One possible method of overcoming the lack of knowledge about PZis to replace
it by its empirical estimate vz. This principle, discussed in the previous section,
justiﬁes the perceptron learning algorithm. However, minimizing the empiricalrisk, as done by the perceptron learning algorithm, has several drawbacks:
7 Although in algorithm 1 on page 321 we start at w0=0it is not necessary to do so.
28 Chapter 2Ꜷ/BD
/B4 /DC/CX
/BN /B7/BD/B5/CU /DC /CY /CW /DC /BN /DB/D8
/CX /BP /BC /CV
Ꜷ/BE/DB/D8
/CU /DC /CY /CW /DC /BN /DB/D8 /B7/BD
/CX /BP /BC /CV
/DC/CX/DB/D8 /B7/BD
Figure 2.2 A geometrical picture of the update ste p in the perceptron learning algorithm
in /CA2. Evidently, xi∈ /CA2is misclassiﬁed by the linear classiﬁer (dashed line) having
normal wt(solid line with arrow). Then, the update step amounts to changing wtinto
wt+1=wt+yixiand thus yixi“attracts” the hyperplane. After t his step, the misclassiﬁed
point xiis correctly classiﬁed.
1. Many examples are required to ensure a small generalization error R[
/BTERM,z]
with high probability taken over the random choice of z.
2. There is no unique minimum, i.e., each weight vector w∈V(z)in version
space parameterizes a classiﬁer fwthat has Remp [fw,z]=0.
3. Without any further assumptions on PZthe number of steps until convergence
of the perceptron learning algorithm is not bounded.
A training sample z∈ /CImthat is linearly separable in feature space is required.
The second point in particular shows that ERM learning makes the learning task
anill-posed one (see Appendix A.4): A slight variation ˜zin the training sample z
might lead to a large deviation between the expected risks of the classiﬁers learnedusing the ERM principle,vextendsinglevextendsingleR[/BTERM(z)]−Rbracketleftbig/BTERMparenleftbig
˜zparenrightbigbracketrightbigvextendsinglevextendsingle. As will be seen in Part
II of this book, a very inﬂuential factor in this deviation is the possibility of thehypothesis space/BYadopting different labelings yfor randomly drawn objects x.
The more diverse the set of functions a hypothesis space contains, the more easily
29 Kernel Classiﬁers from a Machine Learning Perspective
it can produce a given labeling yregardless of how bad the subsequent prediction
might be on new, as yet unseen, data points z=(x,y). This effect is also known
asoverﬁtting , i.e., the empirical risk as given by equation (2.11) is much smaller
than the expected risk (2.8) we originally aimed at minimizing.
One way to overcome this problem is the method of regularization . In our
example this amounts to introducing a regularizer a-priori, that is, a functional/Omega1:/BY→ /CA+, and deﬁning the solution to the learning problem to be/BT/Omega1(z)def=argmin
f∈ /BYRemp [f,z]+λ/Omega1 [f]bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
Rreg[f,z]. (2.14)
The idea of regularization is to restrict the space of solutions to compact subsets
of the (originally overly large) space /BY. This can be achieved by requiring the set
Fε={f|/Omega1[f]≤ε}⊆ /BYto be compact for each positive number ε> 0. This,
in fact, is the essential requirement for any regularizer /Omega1. Then, if we decrease
λfor increasing training sample sizes in the right way, it can be shown that the
regularization method leads to f∗asm→∞ (see equation (2.13)). Clearly,
0≤λ<∞controls the amount of regularization. Setting λ=0 is equivalent
to minimizing only the empirical risk. In the other extreme, considering λ→∞
amounts to discounting the sample and returning the classiﬁer which minimizes/Omega1alone. The regularizer /Omega1can be thought of as a penalization term for the
“complexity” of particular classiﬁers.
Another view of the regularization method can be obtained from the statistical
study of learning algorithms. This will be discussed in greater detail in Part II ofthis book but we shall put forward the main idea here. We shall see that thereexist several measures of “complexity” of hypothesis spaces, the VC dimensionbeing the most prominent thereof. V . V apnik suggested a learning principle whichhe called structural risk minimization (SRM). The idea behind SRM is to, a-priori,
deﬁne a structuring of the hypothesis space/BYinto nested subsets /BY0⊂ /BY1⊂···⊆/BYof increasing complexity. Then, in each of the hypothesis spaces /BYiempirical
risk minimization is performed. Based on results from statistical learning theory,an SRM algorithm returns the classiﬁer with the smallest guaranteed risk
8.This
can be related to the algorithm (2.14), if /Omega1[f]is the complexity value of fgiven
by the used bound for the guaranteed risk.
From a Bayesian perspective, however, the method of regularization is closely
related to maximum-a-posteriori (MAP) estimation. To see this, it sufﬁces to
8 This is a misnomer as it refers to the value of an upper bound at a ﬁxed conﬁdence level and can in no way be
guaranteed.
30 Chapter 2
express the empirical risk as the negative log-probability of the training sample
z, given a classiﬁer f. In general, this can be achieved by
PZm|F=f(z)=mproductdisplay
i=1PY|X=xi,F=f(yi)PX|F=f(xi),
PY|X=x,F=f(y)=exp(−l(f(x),y))
summationtext
˜y∈ /CHexp(−l(f(x),˜y))
=1
C(x)exp(−l(f(x),y)).
Assuming a prior density fF(f)=exp(−λm/Omega1[f]), by Bayes’ theorem we have
the posterior density
fF|Zm=z(f)∝ expparenleftBigg
−msummationdisplay
i=1l(f(xi),yi)parenrightBigg
exp(−λm/Omega1[f])
∝ expparenleftbig
−Remp [f,z]−λ/Omega1 [f]parenrightbig
.
The MAP estimate is that classiﬁer fMAP which maximizes the last expression, i.e.,
the mode of the posterior density. Taking the logarithm we see that the choice ofa regularizer is comparable to the choice of the prior probability in the Bayesianframework and therefore reﬂects prior knowledge.
2.3 Kernels and Linear Classiﬁers
In practice we are often given a vectorial representation x=/vectorxof the objects. Using
the identity feature mapping, i.e., x=φ(x)=/vectorx, results in classiﬁers linear in
input space. Theoretically, however, any mapping into a high-dimensional featurespace is conceivable. Hence, we call a classiﬁer nonlinear in input space whenever
a feature mapping different from the identity map is used.
Example 2.13 (Nonlinear classiﬁers) Let/CG= /CA2and let the mapping φ: /CG→/C3be given by
φ(/vectorx)=parenleftBig
(/vectorx)1,(/vectorx)2
2,(/vectorx)1(/vectorx)2parenrightBig/prime
. (2.15)
In Figure 2.3 (left) the mapping is applied to the unit square [0,1]2and the
resulting manifold in /CA3is shown. Note that in this case the decision surface tildewideX0(w)
31 Kernel Classiﬁers from a Machine Learning Perspective
feature 10.0
0.2
0.4
0.6
0.8
1.0feature 2
0.00.20.40.60.81.0feature 3
−0.50.00.51.0
−1.0 −0.5 0.0 0.5 1.0− 2 − 1 012
x1x2
Figure 2.3 (Left) Mapping of the unit square [0 ,1]2⊂ /CA2to the feature space /C3⊆/lscript3
2
by equation (2.15). The mapped unit square forms a two-dimensional sub-manifold in /CA3
though dim (
/C3)=3.(Right) Nine different decision surfaces obtained by varying w1and
w3in equation (2.16). The solid, dashed and dot-dashed lines result from varying w3for
different values of w1=− 1,0a n d+1, respectively.
in input space is given by
tildewideX0(w)=braceleftBig
/vectorx∈ /CA2vextendsinglevextendsinglevextendsinglew1(/vectorx)1+w2(/vectorx)2
2+w3(/vectorx)1(/vectorx)2=0bracerightBig
, (2.16)
whose solution is given by
(/vectorx)2=−w3
2w2·(/vectorx)1±radicalBig
(/vectorx)1parenleftbig
w2
3(/vectorx)1−4w1w2parenrightbig
2w2.
In Figure 2.3 (right) we have depicted the resulting decision surfaces for various
choices of w1andw3. Clearly, the decision surfaces are nonlinear functions
although in feature space we are still dealing with linear functions.
32 Chapter 2
As we assume φto be given we will call this the explicit way to non-linearize a
linear classiﬁcation model. We already mentioned in Section 2.2 that the number ofdimensions, n, of the feature space has a great impact on the generalization ability
of empirical risk minimization algorithms. Thus, one conceivable criterion fordeﬁning features φ
iis to seek a small set of basis functions φiwhich allow perfect
discrimination between the classes in /CG. This task is called feature selection .
Let us return to the primal perceptron learning algorithm mentioned in the last
subsection. As we start at w0=0and add training examples only when a mistake is
committed by the current hypothesis, it follows that the each solution has to admit
a representation of the form,
wt=msummationdisplay
i=1αiφ(xi)=msummationdisplay
i=1αixi. (2.17)
Hence, instead of formulating the perceptron algorithm in terms of the nvariables
(w1,...,w n)/prime=wwe could learn the mvariables (α1,...,α m)/prime=αwhich
we call the dual space of variables. In the case of perceptron learning we start
withα0=0and then employ the representation of equation (2.17) to update αt
whenever a mistake occurs. To this end, we need to evaluate
yjangbracketleftbig
xj,wtangbracketrightbig
=yjangbracketleftBigg
xj,msummationdisplay
i=1αixiangbracketrightBigg
=yjmsummationdisplay
i=1αiangbracketleftbig
xj,xiangbracketrightbig
which requires only knowledge of the inner product function /angbracketleft·,·/angbracketrightbetween the
mapped training objects x. Further, for the classiﬁcation of a novel test object x
it sufﬁces to know the solution vector αtas well as the inner product function,
because
/angbracketleftx,wt/angbracketright=angbracketleftBigg
x,msummationdisplay
i=1αixiangbracketrightBigg
=msummationdisplay
i=1αi/angbracketleftx,xi/angbracketright.
Deﬁnition 2.14 (Kernel) Suppose we are given a feature mapping φ: /CG→ /C3⊆
/lscriptn
2.T h e kernel is the inner product function k : /CG× /CG→ /CAin /C3, i.e., for all
xi,xj∈ /CG,
kparenleftbig
xi,xjparenrightbigdef=angbracketleftbig
φ(xi),φparenleftbig
xjparenrightbigangbracketrightbig
=angbracketleftbig
xi,xjangbracketrightbig
.
Using the notion of a kernel kwe can therefore formulate the kernel perceptron
ordual perceptron algorithm as presented on page 322. Note that we can beneﬁt
33 Kernel Classiﬁers from a Machine Learning Perspective
from the fact that, in each update step, we only increase the jth component of
the expansion vector α(assuming that the mistake occurred at the jth training
point). This can change the real-valued output /angbracketleftxi,wt/angbracketrightat each mapped training
object xiby only one summand yjangbracketleftbig
xj,xiangbracketrightbig
which requires just one evaluation of the
kernel function with all training objects. Hence, by caching the real-valued outputso∈/CAmat all training objects we see that the kernel perceptron algorithm requires
exactly 2 mmemory units (for the storage of the vectors αand o) and is thus suited
for large scale problems, i.e., m/greatermuch1000.
Deﬁnition 2.15 (Gram matrix) Given a kernel k : /CG× /CG→ /CAand a set
x=(x1,..., xm)∈ /CGmof m objects in /CGwe call the m ×mm a t r i x Gwith
Gijdef=kparenleftbig
xi,xjparenrightbig
=angbracketleftbig
xi,xjangbracketrightbig
(2.18)
the Gram matrix of k at x.
By the above reasoning we see that the Gram matrix (2.18) and the m–dimensional
vector of kernel evaluations between the training objects xiand a new test object
x∈ /C3sufﬁce for learning and classiﬁcation, respectively. It is worth also mention-
ing that the Gram matrix and feature space are called the kernel matrix and kernel
space , respectively, as well.
2.3.1 The Kernel Technique
The key idea of the kernel technique is to invert the chain of arguments, i.e., choose
ak e r n e l krather than a mapping before applying a learning algorithm. Of course,
not any symmetric function kcan serve as a kernel. The necessary and sufﬁcient
conditions of k: /CG× /CG→ /CAto be a kernel are given by Mercer’s theorem.
Before we rephrase the original theorem we give a more intuitive characterizationof Mercer kernels.
Example 2.16 (Mercer’s theorem) Suppose our input space/CGhas a ﬁnite num-
ber of elements, i.e., /CG={x1,..., xr}. Then, the r ×r kernel matrix Kwith
Kij=kparenleftbig
xi,xjparenrightbig
is by deﬁnition a symmetric matrix. Consider the eigenvalue de-
composition of K=U/Lambda1U/prime,w h e r e U=parenleftbig
u/prime
1;...;u/prime
rparenrightbig
is an r×n matrix such that
U/primeU=In,/Lambda1=diag(λ1,...,λ n),λ 1≥λ2≥···≥ λn>0and n≤rb e i n g
known as the rank of the matrix K(see also Theorem A.83 and Deﬁnition A.62).
34 Chapter 2
Now the mapping φ: /CG→ /C3⊆/lscriptn
2,
φ(xi)=/Lambda11
2ui,
leads to a Gram matrix Ggiven by
Gij=angbracketleftbig
φ(xi),φparenleftbig
xjparenrightbigangbracketrightbig/C3=parenleftBig
/Lambda11
2uiparenrightBig/primeparenleftBig
/Lambda11
2ujparenrightBig
=u/prime
i/Lambda1uj=Kij.
We have constructed a feature space /C3and a mapping /Lambda1into it purely from the
kernel k. Note that λn>0is equivalent to assuming that Kis positive semideﬁnite
denoted by K≥0(see Deﬁnition A.40). In order to show that K≥0is also
necessary for k to be a kernel, we assume that λn<0. Then, the squared length of
the nth mapped object x nis
/bardblφ(xn)/bardbl2=u/prime
n/Lambda1un=λn<0,
which contradicts the geometry in an inner product space.
Mercer’s theorem is an extension of this property, mainly achieved by studying the
eigenvalue problem for integral equations of the form
integraldisplay/CGk(x,˜x)f(˜x)d˜x=λf(x),
where kis a bounded, symmetric and positive semideﬁnite function.
Theorem 2.17 (Mercer’s theorem) Suppose k∈L∞(
/CG× /CG)is a symmetric
function, i.e., k (x,˜x)=k(˜x,x), such that the integral operator T k:L2(
/CG)→
L2(
/CG)given by
(Tkf)(·)=integraldisplay/CGk(·,x)f(x)dx
is positive semideﬁnite, that is,
integraldisplay/CGintegraldisplay/CGk(˜x,x)f(x)f(˜x)dxd˜x≥0, (2.19)
for all f∈L2(
/CG).L e tψi∈L2(
/CG)be the eigenfunction of T kassociated with the
eigenvalue λi≥0and normalized such that /bardblψi/bardbl2=integraltext/CGψ2
i(x)dx=1, i.e.,
∀x∈ /CG:integraldisplay/CGk(x,˜x)ψi(˜x)d˜x=λiψi(x).
35 Kernel Classiﬁers from a Machine Learning Perspective
Then
1.(λi)i∈ /C6∈/lscript1,
2.ψi∈L∞(
/CG),
3.kcan be expanded in a uniformly convergent series, i.e.,
k(x,˜x)=∞summationdisplay
i=1λiψi(x)ψi(˜x) (2.20)
holds for all x,˜x∈ /CG.
The positivity condition (2.19) is equivalent to the positive semideﬁniteness of K
in Example 2.16. This has been made more precise in the following proposition.
Proposition 2.18 (Mercer Kernels) The function k : /CG× /CG→ /CAis a Mercer
kernel if, and only if, for each r ∈ /C6and x=(x1,..., xr)∈ /CGr,t h er×rm a t r i x
K=parenleftbig
kparenleftbig
xi,xjparenrightbigparenrightbigr
i,j=1is positive semideﬁnite.
Remarkably, Mercer’s theorem not only gives necessary and sufﬁcient conditions
for kto be a kernel, but also suggests a constructive way of obtaining features φi
from a given kernel k. To see this, consider the mapping φfrom /CGinto/lscript2
φ(x)=parenleftBigradicalbig
λ1ψ1(x),radicalbig
λ2ψ2(x),...parenrightBig/prime
. (2.21)
By equation (2.20) we have for each x,˜x∈ /CG
k(x,˜x)=∞summationdisplay
i=1λiψi(x)ψi(˜x)=∞summationdisplay
i=1φi(x)φi(˜x)=/angbracketleftφ(x),φ(˜x)/angbracketright.
The features ψiare called Mercer features; the mapping
ψ(x)=(ψ1(x),ψ 2(x),...)/prime
is known as the Mercer map ;t h ei m a g e /C5 ofψis termed Mercer space .
Remark 2.19 (Mahalanobis metric) Consider kernels k such that dim(
/C3)=
dim(
/C5)<∞. In order to have equal inner products in feature space /C3and
Mercer space /C5, we need to redeﬁne the inner product in /C5, i.e.,
/angbracketlefta,b/angbracketright/C5=a/prime/Lambda1b,
36 Chapter 2
where /Lambda1=diag(λ1,...,λ n). This metric appears in the study of covariances
of multidimensional Gaussians and is also known as the Mahalanobis metric .I n
fact, there is a very close connection between covariance functions for Gaussianprocesses and kernels which we will discuss in more depth in Chapter 3.
2.3.2 Kernel Families
So far we have seen that there are two ways of making linear classiﬁers nonlinearin input space:
1. Choose a mapping φwhich explicitly gives us a (Mercer) kernel k,o r
2. Choose a Mercer kernel kwhich implicitly corresponds to a ﬁxed mapping φ.
Though mathematically equivalent, kernels are often much easier to deﬁne and
have the intuitive meaning of serving as a similarity measure between objects
x,˜x∈/CG. Moreover, there exist simple rules for designing kernels on the basis
of given kernel functions.
Theorem 2.20 (Functions of kernels) Let k 1: /CG× /CG→ /CAand k 2: /CG× /CG→ /CA
be any two Mercer kernels. Then, the functions k : /CG× /CG→ /CAgiven by
1.k(x,˜x)=k1(x,˜x)+k2(x,˜x),
2.k(x,˜x)=c·k1(x,˜x), for all c∈ /CA+,
3.k(x,˜x)=k1(x,˜x)+c, for all c∈ /CA+,
4.k(x,˜x)=k1(x,˜x)·k2(x,˜x),
5.k(x,˜x)=f(x)·f(˜x), for any function f : /CG→ /CA
are also Mercer kernels.
The proofs can be found in Appendix B.1. The real impact of these design rules
becomes apparent when we consider the following corollary (for a proof seeAppendix B.1).
Corollary 2.21 (Functions of kernels) Let k
1: /CG× /CG→ /CAbe any Mercer
kernel. Then, the functions k : /CG× /CG→ /CAgiven by
1.k(x,˜x)=(k1(x,˜x)+θ1)θ2, for allθ1∈ /CA+andθ2∈ /C6,
2.k(x,˜x)=expparenleftBig
k1(x,˜x)
σ2parenrightBig
, for allσ∈ /CA+,
37 Kernel Classiﬁers from a Machine Learning Perspective
3.k(x,˜x)=expparenleftBig
−k1(x,x)−2k1(x,˜x)+k1(˜x,˜x)
2σ2parenrightBig
, for allσ∈ /CA+
4.k(x,˜x)=k1(x,˜x)
√
k1(x,x)·k1(˜x,˜x)
are also Mercer kernels.
It is worth mentioning that, by virtue of the fourth proposition of this corollary,
it is possible to normalize data in feature space without performing the explicitmapping because, for the inner product after normalization, it holds that
k
norm(x,˜x)def=k(x,˜x)
radicalbig
k(x,x)·k(˜x,˜x)=1
radicalBig
/bardblx/bardbl2·vextenddoublevextenddouble˜xvextenddoublevextenddouble2angbracketleftbig
x,˜xangbracketrightbig
=angbracketleftBigg
x
/bardblx/bardbl,˜x
vextenddoublevextenddouble˜xvextenddoublevextenddoubleangbracketrightBigg
.(2.22)
Kernels on Inner Product Spaces—Polynomial and RBF Kernels
If the input space /CGis already an N–dimensional inner product space /lscriptN
2we can
use Corollary 2.21 to construct new kernels because, according to Example A.41at page 219, the inner product function /angbracketleft·,·/angbracketright/CGin /CGis already a Mercer kernel. In
Table 2.1 some commonly used families of kernels on /lscriptN
2are presented. The last
column gives the number of linearly independent features φiin the induced feature
space /C3.
The radial basis function (RBF) kernel has the appealing property that each
linear combination of kernel functions of the training objects9x=(/vectorx1,...,/vectorxm)
f(/vectorx)=msummationdisplay
i=1αik(/vectorx,/vectorxi)=msummationdisplay
i=1αiexpparenleftBigg
−/bardbl/vectorx−/vectorxi/bardbl2/CG
2σ2parenrightBigg
, (2.23)
can also be viewed as a density estimator in input space /CGbecause it effectively
puts a Gaussian on each /vectorxiand weights its contribution to the ﬁnal density by αi.
Interestingly, by the third proposition of Corollary 2.21, the weighting coefﬁcients
αicorrespond directly to the expansion coefﬁcients for a weight vector win a
classical linear model f(/vectorx)=/angbracketleftφ(/vectorx),w/angbracketright. The parameter σcontrols the amount
of smoothing, i.e., big values of σlead to very ﬂat and smooth functions f—
hence it deﬁnes the unit on which distances /bardbl/vectorx−/vectorxi/bardblare measured (see Figure
2.4). The Mahalanobis kernel differs from the standard RBF kernel insofar as
9 In this subsection we use /vectorxto denote the N–dimensional vectors in input space. Note that x:=φ(/vectorx)denotes
a mapped input object (vector) /vectorxin feature space /C3.
38 Chapter 2
Name
 Kernel function
 dim(
/C3)
pth degree polynomial
 k(/vectoru,/vectorv)=(/angbracketleft/vectoru,/vectorv/angbracketright/CG)p
parenleftbigN+p−1
pparenrightbig
p∈ /C6+
complete polynomial
 k(/vectoru,/vectorv)=(/angbracketleft/vectoru,/vectorv/angbracketright/CG+c)p
parenleftbigN+p
pparenrightbig
c∈ /CA+,p∈ /C6+
RBF kernel
 k(/vectoru,/vectorv)=expparenleftbigg
−/bardbl/vectoru−/vectorv/bardbl2/CG
2σ2parenrightbigg
∞
σ∈ /CA+
Mahalanobis kernel
 k(/vectoru,/vectorv)=expparenleftbig−(/vectoru−/vectorv)/prime/Sigma1(/vectoru−/vectorv)parenrightbig
∞
/Sigma1=diagparenleftBig
σ−2
1,...,σ−2
NparenrightBig
,
σ1,...,σ N∈ /CA+
Ta b l e 2 . 1 List of kernel functions over /lscriptN
2. The dimensionality of the input space is N.
each axis of the input space /CG⊆/lscriptN
2has a separate smoothing parameter, i.e., a
separate scale onto which differences on this axis are viewed. By setting σi→∞
we are able to eliminate the inﬂuence of the ith feature in input space. We shall
see in Section 3.2 that inference over these parameters is made in the contextofautomatic relevance determination (ARD) of the features in input space (see
also Example 3.12). It is worth mentioning that RBF kernels map the input spaceonto the surface of an inﬁnite dimensional hypersphere because by construction
/bardblφ(/vectorx)/bardbl=radicalbig
k(/vectorx,/vectorx)=1f o ra l l/vectorx∈ /CG. Finally, by using RBF kernels we have
automatically chosen a classiﬁcation model which is shift invariant, i.e., translatingthe whole input space/CGby some ﬁxed vector /vectoradoes not change anything because
∀/vectora∈ /CG:/bardbl(/vectorx+/vectora)−(/vectorxi+/vectora)/bardbl2=/bardbl/vectorx+/vectora−/vectorxi−/vectora/bardbl2=/bardbl/vectorx−/vectorxi/bardbl2.
The most remarkable advantage in using these kernels is the saving in compu-
tational effort, e.g., to calculate the inner product for pth degree complete polyno-
mial kernels we need /C7(N+p)operations whereas an explicit mapping would
require calculations of order /C7(exp(pln(N/p))). Further, for radial basis function
kernels, it is very difﬁcult to perform the explicit mapping.
39 Kernel Classiﬁers from a Machine Learning Perspective
Figure 2.4 The real-valued function f(/vectorx)for m=20 training points /vectorx∈ /CA2withα=1
(see equation (2.23)) for varying values of σ(from upper left to lower right σ=0.5,
σ=0.7,σ=1.0a n dσ=2.0). From the contour plot it can be seen that by increasing σ
the contribution of single points to the ﬁnal density vanishes. Further, for bigger values of
σthe resulting surface is smoother. For visualization purposes the surface {/vectorx|f(/vectorx)=0}
is made transparent.
Example 2.22 (Polynomial kernel) Consider the pth degree polynomial kernel as
given in Table 2.1. In order to obtain explicit features φ: /CG→ /CAlet us expand
the kernel function as follows10
(/angbracketleft/vectoru,/vectorv/angbracketright/CG)p=parenleftBiggNsummationdisplay
i=1uiviparenrightBiggp
=parenleftBiggNsummationdisplay
i1=1ui1vi1parenrightBigg
···
Nsummationdisplay
ip=1uipvip

10 For notational brevity, in this example we denote the i–th component of the vector /vectoru∈ /CGand/vectorv∈ /CGbyui
andvi, respectively.
40 Chapter 2
=Nsummationdisplay
i1=1···Nsummationdisplay
ip=1parenleftbig
ui1···uipparenrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
φi(/vectoru)·parenleftbig
vi1···vipparenrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
φi(/vectorv)=/angbracketleftφ(/vectoru),φ(/vectorv)/angbracketright.
Although it seems that there are Npdifferent features we see that two index vectors
i1and i2lead to the same feature φi1=φi2if they contain the same distinct
indices the same number of times but at different positions, e.g., i1=(1,1,3)
and i2=(1,3,1)both lead to φ(/vectoru)=u1u1u3=u2
1u3. One method of computing
the number of different featuresφis to index them by an N –dimensional exponent
vector r=(r1,..., rN)∈{0,..., p}N, i.e.,φr(/vectoru)=ur1
1····· urN
N. Since there are
exactly p summands we know that each admissible exponent vector rmust obey
r1+···+ rN=p. The number of different exponent vectors ris thus exactly given
by11
parenleftbiggN+p−1
pparenrightbigg
,
and for each admissible exponent vector rthere are exactly12
p!
r1!····· rN!
different index vectors i∈{1,..., N}pleading to r. Hence the rth feature is given
by
φr(/vectoru)=radicalBigg
p!
r1!····· rN!·ur1
1····· urN
N.
Finally note that the complete polynomial kernel in Table 2.1 is a pth degree
polynomial kernel in an N +1–dimensional input space by the following identity
(/angbracketleft/vectoru,/vectorv/angbracketright+c)p=parenleftbigangbracketleftbigparenleftbig
/vectoru,√
cparenrightbig
,parenleftbig
/vectorv,√
cparenrightbigangbracketrightbigparenrightbig p,
11 This problem is known as the occupancy problem :G i v e n pballs and Ncells, how many different conﬁgura-
tions of occupancy numbers r1,..., rNwhose sum is exactly pexist? (see Feller (1950) for results).
12 To see this note that we have ﬁrst to select r1indices j1,..., jr1and set ij1=···= ijr1=1. From the
remaining p−r1indices select r2indices and set them all to 2, etc. Thus, the total number of different index
vectors ileading to the same exponent vector requals
parenleftbiggp
r1parenrightbiggparenleftbiggp−r1
r2parenrightbigg
·····parenleftbiggp−r1−···− rN−2
rN−1parenrightbigg
=p!
r1!····· rN!,
which is valid because r1+···+ rN=p(taken from (Feller 1950)).
41 Kernel Classiﬁers from a Machine Learning Perspective
w h e r ew eu s et h ef a c tt h a tc ≥0. This justiﬁes the number of dimensions of feature
space given in the third column of Table 2.1.
Kernels on Strings
One of the greatest advantages of kernels is that they are not limited to vectorialobjects/vectorx∈/CGbut that they are applicable to virtually any kind of object repre-
sentation. In this subsection we will demonstrate that it is possible to efﬁcientlyformulate computable kernels on strings. An application of string kernels is in theanalysis of DNA sequences which are given as strings composed of the symbols
13
A,T,G,C.Another interesting use of kernels on strings is in the ﬁeld of text cate-
gorization and classiﬁcation. Here we treat each document as a sequence or stringof letters. Let us start by formalizing the notion of a string.
Deﬁnition 2.23 (Strings and alphabets) An alphabet /Sigma1is a ﬁnite collection of
symbols called characters. A string is a ﬁnite sequence u=(u
1,..., ur)of
characters from an alphabet /Sigma1. The symbol /Sigma1∗denotes the set of all strings of
any length, i.e., /Sigma1∗def=∪∞
i=0/Sigma1i. The number |u|of symbols in a string u∈/Sigma1∗is
called the length of the string. Given two strings u∈/Sigma1∗andv∈/Sigma1∗, the symbol
uvdef=parenleftbig
u1,..., u|u|,v 1,...,v|v|parenrightbig
denotes the concatenation of the two strings.
Deﬁnition 2.24 (Subsequences and substrings) Given a string u∈/Sigma1∗and an
index vector i=(i1,..., ir)such that 1≤i1<···<ir≤|u|, we denote by
u[i]the subsequenceparenleftbig
ui1,..., uirparenrightbig
. The index vector (1,..., r)is abbreviated by
1:r . Given two strings v∈/Sigma1∗and u∈/Sigma1∗where|u|≥|v|we deﬁne the
index set I v,udef={i:(i+|v|−1)|i∈{1,...,|u|−|v|+1}}, i.e., the set of all
consecutive sequences of length |v|in|u|. Then the string vis said to be a substring
ofuif there exists an index vector i∈Iv,usuch that v=u[i].T h e length l(i)of
an index vector is deﬁned by i |v|−i1+1, i.e., the total extent of the subsequence
(substring) vin the string u.
In order to derive kernels on strings, it is advantageous to start with the explicit
mapping φ:/Sigma1∗→ /C3and then make sure that the resulting inner product function
/angbracketleftφ(·),φ(·)/angbracketrightis easy to compute. By the ﬁniteness of the alphabet /Sigma1, the set/Sigma1∗is
countable and we can therefore use it to index the features φ.
13 These letters correspond to the four bases Adenine, Thymine, Guanine and Cytosine .
42 Chapter 2
The most trivial feature set and corresponding kernel are obtained if we con-
sider binary features φuthat indicate whether the given string matches uor not,
φu(v)=Iu=v⇔ k(u,v)=braceleftbigg
1i f u=v
0 otherwise,
Though easy to compute, this kernel is unable to measure the similarity to any
object (string) not in the training sample and hence would not be useful forlearning.
A more commonly used feature set is obtained if we assume that we are given
alexicon B={b
1,..., bn}⊂/Sigma1∗of possible substrings which we will call words .
We compute the number of times the ith substring biappears within a given string
(document). Hence, the so-called bag-of-words kernel is given by
φb(v)=βb·summationdisplay
i∈Ib,vIb=v[i]⇔ kB(u,v)=summationdisplay
b∈Bβ2
bsummationdisplay
i∈Ib,usummationdisplay
j∈Ib,vIb=u[i]=v[j], (2.24)
which can be efﬁciently computed if we assume that the data is preprocessed
such that only the indices of the words occurring in a given string are stored.The coefﬁcients β
ballow the weighting of the importance of words b∈Bto
differ. A commonly used heuristic for the determination of the βbis the use
of the inverse-document-frequency (IDF) which is given by the logarithm of the
inverse probability that the substring (word) bappears in a randomly chosen string
(document).
The kernel given in equation (2.24) has the disadvantage of requiring a ﬁxed
lexicon B⊂/Sigma1∗which is often difﬁcult to deﬁne a-priori . This is particularly
true when dealing with strings not originating from natural languages. If we ﬁx
the maximum length, r, of substrings considered and weight the feature φbbyλ|b|,
i.e., forλ∈(0,1)we emphasize short substrings whereas for λ> 1 the weight of
longer substrings increases, we obtain
φb(v)=λ|b|summationdisplay
i∈Ib,vIb=v[i]⇔ kr(u,v)=rsummationdisplay
s=1λ2ssummationdisplay
b∈/Sigma1ssummationdisplay
i∈Ib,usummationdisplay
j∈Ib,vIb=u[i]=v[j],(2.25)
which can be computed using the following recursion (see Appendix B.2)
kr(u1u,v)=braceleftbigg0i f |u1u|=0
kr(u,v)+summationtext|v|
j=1λ2·k/prime
r(u1u,v) otherwise, (2.26)
43 Kernel Classiﬁers from a Machine Learning Perspective
k/prime
r(u1u,v 1v)=

0i f r=0
0i f |u1u|=0o r|v1v|=0
0i f u1/negationslash=v1 parenleftbig
1+λ2·k/prime
r−1(u,v)parenrightbig
otherwise.(2.27)
Since the recursion over krinvokes at most |v|times the recursion over k/prime
r(which
terminates after at most rsteps) and is invoked itself exactly |u|times, the compu-
tational complexity of this string kernel is /C7(r·|u|·|v|).
One of the disadvantages of the kernels given in equations (2.24) and (2.25)
is that each feature requires a perfect match of the substring bin the given string
v∈/Sigma1∗. In general, strings can suffer from deletion and insertion of symbols, e.g.,
for DNA sequences it can happen that a few bases are inserted somewhere in agiven substring b. Hence, rather than requiring bto be a substring we assume that
φ
b(v)only measures how often bis a subsequence of vand penalizes the non-
contiguity of binvby using the length l(i)of the corresponding index vector i,
i.e.,
φb(v)=summationdisplay
{i|b=v[i]}λl(i)⇔ kr(u,v)=summationdisplay
b∈/Sigma1rsummationdisplay
{i|b=u[i]}summationdisplay
{j|b=v[j]}λl(i)+l(j)(2.28)
This kernel can efﬁciently be computed by applying the the following recursion
formula (see Appendix B.2)
kr(uus,v)=braceleftbigg0i f m i n (|uus|,|v|)<r
kr(u,v)+λ2summationtext
{t|vt=us}k/prime
r−1(u,v[1:(t−1)])(2.29)
k/prime
r(uus,v)=

0i f m i n (|uus|,|v|)<r
1i f r=0
λ·k/prime
r(u,v)+λ2summationtext
{t|vt=us}λ|v|−jk/prime
r−1(u,v[1:(t−1)])(2.30)
Clearly, the recursion for kris invoked exactly |u|times by itself and each time
invokes at most |v|times the recursive evaluation of k/prime
r. The recursion over k/prime
r
is invoked at most rtimes itself and invokes at most |v|times the recursion
over k/prime
r−1. As a consequence the computational complexity of this algorithm is/C7parenleftbig
r·|u|·|v|2parenrightbig
. It can be shown, however, that with simple caching it is possible
to reduce the complexity further to /C7(r·|u|·|v|).
Remark 2.25 (Ridge Problem) The kernels (2.25) and (2.28) lead to the so-called
ridge problem when applied to natural language documents, i.e., different docu-
ments u∈/Sigma1∗andv∈/Sigma1∗map to almost orthogonal features φ(u)andφ(v).
Thus, the Gram matrix has a dominant diagonal (see Figure 2.5) which is prob-
44 Chapter 2
5 1 01 52 02 53 05 1 01 52 02 53 0
row indexcolumn index
5 1 01 52 02 53 05 1 01 52 02 53 0
row indexcolumn index
5 1 01 52 02 53 05 1 01 52 02 53 0
row indexcolumn index
Figure 2.5 Intensity plots of the normalized Gram matrices when applying the string
kernels (2.24), (2.25) and (2.28) (from left to right) to 32 sentences taken from this chapter
with n=5a n dλ=0.5. 11, 8, 4 and 9 sentences were taken from Section 2.2, Subsection
2.2.2, Section 2.3 and Subsection 2.3.1, respectively. For the sake of clarity, white lines areinserted to indicate the change from one section to another section.
lematic because each new test document x is likely to have a kernel value k (x,xi)
close to zero. In order to explain this we notice that a document u∈/Sigma1∗has at
least|u|−r+1matches of contiguous substrings with itself, i.e., all substrings
u[i:(i+r−1)]for all i∈{1,...,|u|−r+1}. However , even if two documents
u∈/Sigma1∗andv∈/Sigma1∗share all words b∈/Sigma1rof length r (on average) but in differ-
ent orders, we have approximately|u|
rmatches (assuming |u|≈|v|). Therefore the
differenceparenleftbig
(|u|−r)−|u|
rparenrightbig
·λrbetween diagonal and off-diagonal elements of the
Gram matrix becomes systematically larger with increasing subsequence length r .
Kernels from Probabilistic Models of the Data
A major disadvantage of the two kernel families presented so far is that they are
limited to a ﬁxed representation of objects, x, i.e., vectorial data or strings. In order
to overcome this limitation, Jaakkola and Haussler introduced the so-called Fisherkernel .The idea of the Fisher kernel is to use a probabilistic model of the input
data, x, to derive a similarity measure between two data items. In order to achieve
this, let us assume that the object generating probability measure P
Xcan be written
as a mixture, i.e., there exists a vector θ=(θ1;...;θr;π)such that14
PX(x)=Pθ
X(x)=rsummationdisplay
i=1Pθi
X|M=i(x)·PM(i)bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
πi=rsummationdisplay
i=1πi·Pθi
X|M=i(x), (2.31)
14 With a slight abuse of notation, we always use PXeven if Xis a continuous random variable possessing a
density fX. In this case we have to replace PXbyfXand PX|M=ibyfX|M=ibut the argument would not change.
45 Kernel Classiﬁers from a Machine Learning Perspective
where the measure Pθi
X|M=iis parameterized by θionly. In the search for the most
plausible mixture components θML(given a set x∈ /CGmofmtraining objects) the
Fisher score and the Fisher information matrix play a major role.
Deﬁnition 2.26 (Fisher score and Fisher information matrix) Given a parame-
terized family /C8/C9of probability measures Pθ
Xover the space /CGand a parameter
vector ˜θ∈ /C9the function
f˜θ(x)def=∂lnparenleftBig
Pθ
X(x)parenrightBig
∂θvextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextendsingle
θ=˜θ
is called the Fisher score of x at ˜θ. Further , the matrix
I˜θdef=EXbracketleftBig
f˜θ(X)parenleftbig
f˜θ(X)parenrightbig/primebracketrightBig
(2.32)
is called Fisher information matrix at ˜θ. Note that the expectation in equation
(2.32) is w.r .t. P˜θ
X.
Now, given an estimate ˆθ∈ /C9of the parameter vector θ—probably obtained by
using unlabeled data {x1,..., xM},w h e r e M/greatermuch m—let us consider the Fisher
score mapping in the|θ|–dimensional feature space /C3, i.e.,
φˆθ(x)=fˆθ(x). (2.33)
Interestingly, we see that the features φassociated with πimeasure the amount
by which the ith mixture component PX|M=icontributes to the generation of the
pattern x, i.e.,
∂lnparenleftBig
Pθ
X(x)parenrightBig
∂π j=∂lnparenleftbiggrsummationtext
i=1πiPθi
X|M=i(x)parenrightbigg
∂π j=Pθj
X|M=j(x)
rsummationtext
i=1πiPθi
X|M=i(x)=Pθj
X|M=j(x)
Pθ
X(x).
As a consequence, these features allow a good separation of all regions of the input
space /CGin which the mixture measure (2.31) is high for exactly one component
only. Hence, using the Fisher score fθ(x)as a vectorial representation of xprovides
a principled way of obtaining kernels from a generative probabilistic model of thedata.
46 Chapter 2
Deﬁnition 2.27 (Fisher kernel ) Given a parameterized family /C8of probability
measures Pθ
Xover the input space /CGand a parameter vector θ∈ /C9the function
k(x,˜x)=(fθ(x))/primeI−1
θfθ(˜x)
is called the Fisher kernel .T h e naive Fisher kernel is the simpliﬁed function
k(x,˜x)=(fθ(x))/primefθ(˜x).
This assumes that the Fisher information matrix Iθis the identity matrix I.
The naive Fisher kernel is practically more relevant because the computation of
the Fisher information matrix is very time consuming and sometimes not evenanalytically possible. Note, however, that not only do we need a probability modelP
θ
Xof the data but also the model /C8⊃Pθ
Xof probability measures.
Example 2.28 (Fisher kernel) Let us assume that the measures PX|M=ibelong to
the exponential family, i.e., their density can be written as
fθi
X|M=i(x)=ai(θi)·ci(x)·expparenleftbig
θ/prime
iτi(x)parenrightbig
,
where c i: /CG→ /CAis a ﬁxed function, τi: /CG→ /CAniis known as a sufﬁcient
statistic of x and a i: /CAni→ /CAis a normalization constant. Then the value of the
features φθjassociated with the j th parameter vector θjare given by
∂lnparenleftBig
fθ
X(x)parenrightBig
∂θj=1
fθ
X(x)·∂parenleftbiggrsummationtext
i=1PM(i)·ai(θi)·ci(x)·expparenleftbig
θ/prime
iτi(x)parenrightbigparenrightbigg
∂θj
=fθj
X|M=j(x)PM(j)
fθ
X(x)
∂aj(θj)
∂θj
ajparenleftbig
θjparenrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
independent of x+τj(x)
.
Let us consider the contribution of the features φθjat objects x ,˜x∈ /CGfor which15
fθj
X|M=j(x)
fθ
X(x)≈fθj
X|M=j(˜x)
fθ
X(˜x)
15 If this relation does not hold then the features associated with πjalready allow good discrimination.
47 Kernel Classiﬁers from a Machine Learning Perspective
and, additionally, assume that PMis the uniform measure. We see that
angbracketleftBig
φθj(x),φθj(˜x)angbracketrightBig
∝parenleftbig
τj(x)parenrightbig/primeτj(˜x),
that is, we effectively consider the sufﬁcient statistic τj(x)of the j th mixture
component measure as a vectorial representation of our data.
2.3.3 The Representer Theorem
We have seen that kernels are a powerful tool that enrich the applicability of linearclassiﬁers by a large extent. Nonetheless, apart from the solution of the perceptronlearning algorithm it is not yet clear when this method can successfully be applied,i.e., for which learning algorithms/BT:∪∞
m=1
/CIm→ /BYthe solution /BT(z)admits a
representation of the form
(
/BT(z))(·)=msummationdisplay
i=1αik(xi,·). (2.34)
Before identifying this class of learning algorithms we introduce a purely func-
tional analytic point of view on kernels. We will show that each Mercer kernelautomatically deﬁnes a reproducing kernel Hilbert space (RKHS) of functions as
given by equation (2.34). Finally, we identify the class of cost functions whosesolution has the form (2.34).
Reproducing Kernel Hilbert Spaces
Suppose we are given a Mercer kernel k: /CG× /CG→ /CA.T h e nl e t /BY0be the linear
space of real-valued functions on /CGgenerated by the functions {k(x,·)|x∈ /CG}.
Consider any two functions f(·)=summationtextr
i=1αik(xi,·)and g(·)=summationtexts
j=1βjkparenleftbig
˜xj,·parenrightbig
in /BY0where α∈ /CAr,β∈ /CAsand xi,˜xj∈ /CG. Deﬁne the inner product /angbracketleftf,g/angbracketright
between fand gin /BY0as
/angbracketleftf,g/angbracketrightdef=rsummationdisplay
i=1ssummationdisplay
j=1αiβjkparenleftbig
xi,˜xjparenrightbig
=ssummationdisplay
j=1βjfparenleftbig
˜xjparenrightbig
=rsummationdisplay
i=1αig(xi), (2.35)
where the last equality follows from the symmetry of the kernel k. Note that this
inner product /angbracketleft·,·/angbracketrightis independent of the representation of the function fand g
because changing the representation of f, i.e., changing r,αand{x1,..., xr},
would not changesummationtexts
j=1βjfparenleftbig
˜xjparenrightbig
(similarly for g). Moreover, we see that
48 Chapter 2
1./angbracketleftf,g/angbracketright=/angbracketleftg,f/angbracketrightfor all functions f,g∈ /BY0,
2./angbracketleftcf+dg,h/angbracketright= c/angbracketleftf,h/angbracketright+d/angbracketleftg,h/angbracketrightfor all functions f,g,h∈ /BY0and all
c,d∈ /CA,
3./angbracketleftf,f/angbracketright=summationtextr
i=1summationtextr
j=1αiαjkparenleftbig
xi,xjparenrightbig
≥0 for all functions f∈ /BY0because kis
a Mercer kernel.
It still remains to established that /angbracketleftf,f/angbracketright=0 implies that f=0. To show this we
need ﬁrst the following important reproducing property : For all functions f∈ /BY0
and all x∈ /CG
/angbracketleftf,k(x,·)/angbracketright=f(x), (2.36)
which follows directly from choosing s=1,β1=1a n d˜x1=xin (2.35)—hence
g(·)=k(x,·). Now using the Cauchy-Schwarz inequality (see Theorem A.106
and preceding comments) we know that
0≤(f(x))2=(/angbracketleftf,k(x,·)/angbracketright)2≤/angbracketleftf,f/angbracketright/angbracketleftk(x,·),k(x,·)/angbracketrightbracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
k(x,x), (2.37)
which shows that /angbracketleftf,f/angbracketright=0 only if f(x)=0f o ra l l x∈ /CG, i.e., f=0.
Finally, let us consider any Cauchy sequence (fr)r∈ /C6of functions in /BY0. Then,
by virtue of equation (2.37), we know that, for all r,s∈ /C6,(fr(x)−fs(x))2≤
/bardblfr−fs/bardbl2k(x,x)and hence (fr)r∈ /C6converges toward some real-valued function
fon /CG. It is possible to complete /BY0by adding the limits of all Cauchy sequences
to it, extending it and its inner product to a slightly larger class /BY⊆ /CA
/CG. Thus,
we have shown that each kernel k: /CG× /CG→ /CAdeﬁnes a Hilbert space /BYof
real-valued functions over /CGwhich has the reproducing property (2.36), i.e., the
value of the function fatxis “reproduced” by the inner product of fwith k(x,·).
The full power of this consideration is expressed in the following theorem.
Theorem 2.29 (Representer theorem) Let k be a Mercer kernel on /CG,z∈
(
/CG× /CH)mbe a training sample and g emp:(
/CG× /CH× /CA)m→ /CA∪{∞}be any
arbitrary but ﬁxed function. Let g reg: /CA→ [0,∞)be any strictly monotoni-
cally increasing function. Deﬁne /BYas the RKHS induced by k. Then any f ∈ /BY
minimizing the regularized risk
Rreg[f,z]=gempparenleftbig
((xi,yi,f(xi)))i∈{1,..., m}parenrightbig
+greg(/bardblf/bardbl), (2.38)
49 Kernel Classiﬁers from a Machine Learning Perspective
admits a representation of the form
f(·)=msummationdisplay
i=1αik(xi,·) α∈ /CAm. (2.39)
The proof is given in Appendix B.3. It elucidates once more the advantage of
kernels: Apart from limiting the computational effort in application, they allowfor a quite general class of learning algorithms (characterized by the minimizationof a functional of the form (2.38)) to be applied in dual variables α∈/CAm.
2.4 Support V ector Classiﬁcation Learning
The methods presented in the last two sections, namely the idea of regularization,
and the kernel technique, are elegantly combined in a learning algorithm known assupport vector learning (SV learning).
16In the study of SV learning the notion of
margins is of particular importance. We shall see that the support vector machine
(SVM) is an implementation of a more general regularization principle knownas the large margin principle. The greatest drawback of SVMs, that is, the need
for zero training error, is resolved by the introduction of soft margins. We will
demonstrate how both large margin and soft margin algorithms can be viewed inthe geometrical picture given in Figure 2.1 on page 23. Finally, we discuss severalextensions of the classical SVM algorithm achieved by reparameterization.
2.4.1 Maximizing the Margin
Let us begin by deﬁning what we mean by the margin of a classiﬁer. In Figure
2.6 a training sample zin /CA2together with a classiﬁer (illustrated by the incurred
decision surface) is shown. The classiﬁer fwin Figure 2.6 (a) has a “dead zone”
(gray area) separating the two sets of points which is larger than the classiﬁer f˜w
chosen in Figure 2.6 (b). In both pictures the “dead zone” is the tube around the
(linear) decision surface which does not contains any training example (xi,yi)∈z.
To measure the extent of such a tube we can use the norm of the weight vector w
parameterizing the classiﬁer fw. In fact, the size of this tube must be inversely
proportional to the minimum real-valued output yi/angbracketleftxi,w/angbracketrightof a classiﬁer won a
16 V apnik also introduced the term support vector machines (SVMs) for learning algorithms of the “support
vector” type.
50 Chapter 2/CU
/DC
/BE
/CA
/BE
/CY
/CW
/DB
/BN
/DC
/CX
/BP
/B7
/BD
/CV/AD
/DE
/B4
/DB
/B5/DB/CU
/DC
/BE
/CA
/BE
/CY
/CW
/DB
/BN
/DC
/CX
/BP
/BC
/CV/CU
/DC
/BE
/CA
/BE
/CY
/CW
/DB
/BN
/DC
/CX
/BP
/A0
/BD
/CV
/CU
/DC
/BE
/CA
/BE/CY/CW
/DI/DB
/BN
/DC
/CX
/BP
/B7
/BD
/CV/AD/DE
/B4
/DI/DB
/B5/DI/DB/CU
/DC
/BE
/CA
/BE/CY/CW
/DI/DB
/BN
/DC
/CX
/BP
/BC
/CV/CU
/DC
/BE
/CA
/BE/CY
/CW
/DI/DB
/BN
/DC
/CX
/BP
/A0
/BD
/CV
Figure 2.6 Geometrical margins of a plane (thick solid line) in /CA2. The crosses ( yi=
+1) and dots ( yi=− 1) represent labeled examples xi.(Left) The classiﬁer fwwith the
largest geometrical margin γz(w). Note that this quantity is invariant under rescaling of
the weight vector. (Right) A classiﬁer f˜wwith a smaller geometrical margin γzparenleftbig˜wparenrightbig
.S i n c e
min(xi,yi)∈zyiangbracketleftbig
xi,˜wangbracketrightbig
=1,vextenddoublevextenddouble˜wvextenddoublevextenddoublecan be used to measure the extent of the gray zone tube by
γzparenleftbig˜wparenrightbig
=1/vextenddoublevextenddouble˜wvextenddoublevextenddouble.
given training sample z. This quantity is also known as the functional margin on
the training sample zand needs to be normalized to be useful for comparison
across different weight vectors wnot necessarily of unit length. More precisely,
when normalizing the real-valued outputs by the norm of the weight vector w
(which is equivalent to considering the real-valued outputs of normalized weightvectors w//bardblw/bardblonly) we obtain a conﬁdence measure comparable across different
hyperplanes. The following deﬁnition introduces the different notions of marginsmore formally.
Deﬁnition 2.30 (Margins) Suppose we are given a training sample z=(x,y)∈/CIm, a mapping φ: /CG→ /C3⊆/lscriptn
2and a vector w∈ /C3. F or the hyperplane having
normal wwe deﬁne the
functional margin ˜γi(w)on an example (xi,yi)∈zto be˜γi(w)def=yi/angbracketleftxi,w/angbracketright,
51 Kernel Classiﬁers from a Machine Learning Perspective
functional margin ˜γz(w)on a training sample zto be˜γz(w)def=min(xi,yi)∈z˜γi(w),
geometrical margin γi(w)on an example (xi,yi)∈zto beγi(w)def=˜γi(w)//bardblw/bardbl,
geometrical margin γz(w)on a training sample zto beγz(w)def=˜γz(w)//bardblw/bardbl.
Note that˜γi(w)>0implies correct classiﬁcation of (xi,yi)∈z. Furthermore, for
w∈ /CFthe functional and geometrical margin coincide.
In 1962 Novikoff proved a theorem for perceptrons which was, in 1964, extended to
linear classiﬁers in kernel space. The theorem shows that the number of correctionsin the perceptron learning algorithm is provably decreasing for training sampleswhich admit a large margin.
Theorem 2.31 (Perceptron convergence theorem) Let z=(x,y)∈/CImbe a
training sample, let φ: /CG→ /C3⊆/lscriptn
2be a ﬁxed feature map, and let ς=
max xi∈x/bardblφ(xi)/bardblbe the smallest radius of a sphere enclosing all the mapped
training objects x. Suppose that there exists a vector w∗∈ /CFsuch that˜γz(w∗)=
γz(w∗)> 0. Then the number of mistakes made by the perceptron learning
algorithm on zis at most
parenleftbiggς
γz(w∗)parenrightbigg2
.
The proof is given in Appendix B.4. This theorem answers one of the questions
associated with perceptron learning, that is, the number of steps until convergence.The theorem was one of the ﬁrst theoretical justiﬁcations of the idea that largemargins yield better classiﬁers; here in terms of mistakes during learning. We shallsee in Part II that large margins indeed yield better classiﬁers in terms of expectedrisk.
Let/BYand /C3be the RKHS and feature space connected with the Mercer kernel
k, respectively. The classiﬁer wwith the largest margin γz(w)on a given training
sample can be written as
wSVMdef=argmax
w∈ /CFγz(w)=argmax
w∈ /C31
/bardblw/bardbl˜γz(w). (2.40)
Two methods of casting the problem of ﬁnding this classiﬁer into a regularization
framework are conceivable. One method is to reﬁne the (coarse) l0−1loss function
given in equation (2.9) by exploiting the minimum real-valued output γz(w)of
52 Chapter 2
each classiﬁer w∈ /CF. A second option is to ﬁx the minimum real-valued output
˜γz(w)of the classiﬁer w∈ /C3and to use the norm /bardblw/bardblof each classiﬁer to measure
its complexity. Though the latter is better known in the SV community we shallpresent both formulations.
1. Fix the norm of the classiﬁers to unity (as done in Novikoff’s theorem), then we
must maximize the geometrical margin. More formally, in terms of equation (2.38)we have
w
SVM=argmin
w∈ /CFlmargin(γz(w)), (2.41)
where
lmargin(t)def=− t. (2.42)
A more convenient notation of this minimization problem is
maximize min (fw(x1),..., fw(xm))=γz(w)
subject to /bardblfw/bardbl2=/bardblw/bardbl2=1.
This optimization problem has several difﬁculties associated with it. First, the ob-
jective function is neither linear nor quadratic. Further, the constraints are nonlin-ear. Hence, from an algorithmic viewpoint this optimization problem is difﬁcultto solve. Nonetheless, due to the independence of the hypothesis space from thetraining sample it is very useful in the study of the generalization error.
2. Fix the functional margin to unity and minimize the norm /bardblw/bardblof the weight
vector. More formally, the set of all classiﬁers considered for learning is/CF(z)def={w∈ /C3|˜γz(w)=1}, (2.43)
which are known as canonical hyperplanes. Clearly, this deﬁnition of the hypothe-
sis space is data dependent which makes a theoretical analysis quite intricate17.T h e
advantage of this formulation becomes apparent if we consider the correspondingrisk functional:
w
SVM∝argmin
w∈ /CF(z)/bardblfw/bardbl2=argmin
w∈ /CF(z)/bardblw/bardbl2. (2.44)
17 In general, the hypothesis space must be independent of the training sample. The training sample dependence
on the hypothesis space for Mercer kernels is resolved in Theorem 2.29. Note, however, that this theorem doesnot apply to canonical hyperplanes.
53 Kernel Classiﬁers from a Machine Learning Perspective
The risk functional seems to imply that we minimize a complexity or structural
risk, but this is wrong. In fact, the lack of any empirical term in the risk functionalis merely due to the formulation which uses a data dependent hypothesis space(2.43). If we cast the minimization of this risk functional in a convex programmingframework we obtain
minimize /bardblw/bardbl
2=/bardblfw/bardbl2
subject to yi/angbracketleftxi,w/angbracketright≥ 1 i=1,..., m.(2.45)
This optimization problem is much more computationally amenable. Here, the
objective function is quadratic and the constraints are linear. As a consequence, the
solution must be expressible in its dual form. Introducing mLagrangian multipliers
αifor the linear constraints (which turn out to be the expansion coefﬁcients of the
weight vector win terms of the mapped training objects), taking the derivative
w.r.t. wand back-inserting into the Lagrangian, we obtain the following Wolfe dual
(for details see Section B.5)
W(α)=α/prime1−1
2α/primeYGYα, (2.46)
which needs to be maximized in the positive quadrant 0≤α,
ˆα=argmax
0≤αW(α).
Here, Gis the m×mGram matrix deﬁned by equation (2.18) and Ydef=
diag(y1,..., ym). Note, however, that the solution
wSVM=msummationdisplay
i=1ˆαiyixi
is equivalent to the solution of optimization problem (2.41) up to a scaling factor.
Using decomposition techniques to solve the problem, the computational effort isroughly of order/C7parenleftbig
m2parenrightbig
.
2.4.2 Soft Margins—Learning with Training Error
The algorithm presented in the last subsection is clearly restricted to training
samples which are linearly separable. One way to deal with this insufﬁciency isto use “powerful” kernels (like an RBF kernel with very small σ)w h i c hm a k e s
each training sample separable in feature space. Although this would not causeany computational difﬁculties, the “large expressive” power of the classiﬁers in
54 Chapter 2
feature space may lead to overﬁtting, that is, a large discrepancy between empirical
risk (which was previously zero) and true risk of a classiﬁer. Moreover, the abovealgorithm is “nonrobust” in the sense that one outlier (a training point (x
i,yi)∈z
whose removal would lead to a large increase in margin) can cause the learningalgorithm to converge very slowly or, even worse, make it impossible to apply atall (ifγ
i(w)<0f o ra l l w∈ /CF).
In order to overcome this insufﬁciency we introduce a heuristic which has
become known as the soft margin SVM . The idea exploited is to upper bound the
zero-one loss l0−1as given in equation (2.9) by a linear or quadratic function (see
Figure 2.7),
l0−1(f(x),y)=I−yf(x)>0≤ max{1−yf(x),0}=llin(f(x),y), (2.47)
l0−1(f(x),y)=I−yf(x)>0≤ max{1−yf(x),0}2=lquad(f(x),y).
It is worth mentioning that, due to the cut off at a real-valued output of one (on the
correct side of the decision surface), the norm /bardblf/bardblcan still serve as a regularizer.
Viewed this way, the idea is in the spirit of the second parameterization of theoptimization problem of large margins (see equation (2.40)).
Linear Approximation
Let us consider the case of a linear approximation. Given a tradeoff parameterλ> 0, the regularization functional becomes
R
reg[fw,z]=1
mmsummationdisplay
i=1llin(fw(xi),yi)+λ/bardblfw/bardbl2,
or equivalently
minimizemsummationdisplay
i=1ξi+λm/bardblw/bardbl2
subject to yi/angbracketleftxi,w/angbracketright≥1−ξi i=1,..., m, (2.48)
ξ≥0.
Transforming this into an optimization problem involving the corresponding Wolfe
dual we must maximize an equation of the form (2.46), but this time in the “box”0≤α≤
1
2λm1(see Section B.5). In the limit λ→ 0 we obtain the “hard
margin” SVM because there is no upper bound on α. Another explanation of
this equivalence is given by the fact that the objective function is proportional to
55 Kernel Classiﬁers from a Machine Learning Perspective
−2.0 −1.5 −1.0 −0.5 0.0 0.5 1.001234
−yf(x)loss
Iyf(x)≤0hinge lossquadratic loss
Figure 2.7 Approximation to the Heaviside step function Iyf(x)≤0(solid line) by the
so-called “hinge loss” (dashed line) and a quadratic margin loss (dotted line). The x–
axis contains the negat ive real-valued output −yf(x)which is positive in the case of
misclassiﬁcation of xby f.
1
λmsummationtextm
i=1ξi+/bardblw/bardbl2. Thus, in the limit of λ→ 0, any wfor which ξ/negationslash=0incurs
an inﬁnitely large value of the objective function and therefore in the optimumsummationtextm
i=1ξi=0. Note that by virtue of this formulation the “box” is decreased with
increasing training sample size.
Quadratic Approximation
Though not as popular in the SV community, the quadratic approximation has
proven to be successful in real world applications. Formally, the regularization
functional becomes
Rreg[fw,z]=1
mmsummationdisplay
i=1lquad(fw(xi),yi)+λ/bardblfw/bardbl2,
which in its equivalent form is
minimizemsummationdisplay
i=1ξ2
i+λm/bardblw/bardbl2
56 Chapter 2
subject to yi/angbracketleftxi,w/angbracketright≥1−ξi i=1,..., m, (2.49)
ξ≥0.
The corresponding Wolfe dual (derived in Section B.5) is given by
W(α)=α/prime1−1
2α/primeYGYα−λm
2α/primeα,
and must be maximized in the positive quadrant 0≤α. This can equivalently be
expressed by a change of the Gram matrix, i.e.,
W(α)=α/prime1−1
2α/primeYtildewideGYα,tildewideG=G+λmI. (2.50)
Remark 2.32 (Data independent hypothesis spaces) The two algorithms pre-
sented in this subsection use the idea of ﬁxing the functional margin to unity.
This allows the geometrical margin to be controlled by the norm /bardblw/bardblof the weight
vector w. As we have seen in the previous subsection there also exists a “data inde-
pendent” formulation. In the case of a quadratic soft margin loss the formulationis apparent from the change of the Gram matrix: The quadratic soft margin SVMis equivalent to a hard margin SVM if we change the Gram matrix GtoG+λmI.
Furthermore, in the hard margin case, we could alternatively have the hypothesisspace being the unit hypersphere in feature space. As a consequence thereof, allwe need to consider is the change in the feature space, if we penalize the diagonal
of the Gram matrix byλm.
Remark 2.33 (Cost matrices) In Example 2.7 we showed how different a-priori
class probabilities P
Y(−1)and PY(+1)can be incorporated through the use of a
cost matrix loss function. In the case of soft margin loss this can be approximatelyachieved by using different values λ
+∈ /CA+andλ−∈ /CA+at the constraints for
the training points of class +1and−1, respectively. As the (general) regularizer
is inversely related to the allowed violation of constraints it follows that theunderrepresented class having smaller prior probability should have the largerλvalue.
2.4.3 Geometrical Viewpoints on Margin Maximization
In the previous two subsections the SV learning algorithms were introduced purely
from a margin maximization perspective. In order to associate these algorithmswith the geometrical picture given in Figure 2.1 on page 23 we note that, for a
57 Kernel Classiﬁers from a Machine Learning Perspective
Figure 2.8 Finding the center of the largest inscribable ball in version space. (Left) In
this example four training points were given which incur the depicted four planes. Let us
assume that the labeling of the training sample was such that the polyhedra on top of thesphere is the version space. Then, the SV learning algorithm ﬁnds the (weight) vector won
top of the sphere as the center of the largest inscribable ball/BUτ(w)(transparent cap). Here,
we assumed /bardblyixi/bardbl=/bardblxi/bardblto be constant. The distance of the wfrom the hyperplanes
(dark line) is proportional to the margin γz(w)(see text). (Right) Viewed from top we see
that the version space V(z)is a bended convex body into which we can fully inscribe a
circle of radius proportional to γz(w).
ﬁxed point (xi,yi)∈z, the geometrical margin γiparenleftbig˜wparenrightbig
can be read as the distance
of the linear classiﬁer having normal ˜wto the hyperplane {w∈ /C3|yi/angbracketleftxi,w/angbracketright=0}.
In fact, the Euclidean distance of the point ˜wfrom the hyperplane having normal
yixiisyiangbracketleftbig
xi,˜wangbracketrightbig
//bardblyixi/bardbl=γiparenleftbig˜wparenrightbig
//bardblxi/bardbl. For the moment let us assume that /bardblxi/bardblis
constant for all xiin the training objects x∈ /CGm. Then, if a classiﬁer f˜wachieves
am a r g i no f γzparenleftbig˜wparenrightbig
on the training sample zwe know that the ball,/BUτparenleftbig˜wparenrightbig
=braceleftBigg
w∈ /CFvextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextenddoublevextenddoublew−˜wvextenddoublevextenddouble<γzparenleftbig˜wparenrightbig
/bardblxi/bardblbracerightBigg
⊂V(z)
58 Chapter 2
of radius τ=γzparenleftbig˜wparenrightbig
//bardblxi/bardblis totally inscribable in version space V(z). Hence-
forth, maximizing γzparenleftbig
˜wparenrightbig
is equivalent to ﬁnding the center of the largest inscrib-
able ball in version space (see Figure 2.8).
The situation changes if we drop the assumption that /bardblxi/bardblis constant. In this
case, training objects for which /bardblxi/bardblis very large effectively minimize the radius
τof the largest inscribable ball. If we consider the center of the largest inscribable
ball as an approximation to the center of mass of version space V(z)(see also
Section 3.4) we see that normalizing the xi’s to unit length is crucial to ﬁnding a
good approximation for this point.
The geometrical intuition still holds if we consider the quadratic approximation
presented in Subsection 2.4.2. The effect of the diagonal penalization is to add anew basis axis for each training point (x
i,yi)∈z. Hence, in this new space the
quadratic SVM tries to ﬁnd the center of the largest inscribable ball. Needless tosay that we again assume the x
i’s to be of constant length /bardblxi/bardbl. We shall see in
Section 5.1 that the margin γzparenleftbig˜wparenrightbig
is too coarse a measure to be used for bounds on
the expected risk if /bardblxi/bardbl/negationslash=const.—especially if we apply the kernel technique.
2.4.4 The ν–Trick and Other Variants
The SV algorithms presented so far constitute the basis of the standard SV tool
box. There exist, however, several (heuristic) extensions for the case of multipleclasses (2 <|/CH|<∞), regression estimation ( /CH= /CA) and reparameterizations in
terms of the assumed noise level EXbracketleftbig
1−max y∈ /CHparenleftbig
PY|X=x(y)parenrightbigbracketrightbig
which we present
here.
Multiclass Support V ector Machines
In order to extend the SV learning algorithm to K=|/CH|>2 classes two different
strategies have been suggested.
1. The ﬁrst method is to learn KSV classiﬁers fjby labeling all training points
having yi=jwith+1a n d yi/negationslash=jwith−1 during the training of the jth classiﬁer.
In the test stage, the ﬁnal decision is obtained by
fmultiple(x)=argmax
y∈ /CHfy(x).
Clearly, this method learns one classiﬁer for each of the Kclasses against all the
other classes and is hence known as the one-versus-rest (o-v-r) method. It can be
59 Kernel Classiﬁers from a Machine Learning Perspective
shown that it is possible to solve the Koptimization problems at once. Note that
the computational effort is of order /C7parenleftbig
Km2parenrightbig
.
2. The second method is to learn K(K−1)/2 SV classiﬁers. If 1 ≤i<j≤K
the classiﬁers fi,jis learned using only the training samples from the class iand
j, labeling them +1a n d−1, respectively. This method has become known as the
one-versus-one (o-v-o) method. Given a new test object x∈ /CG, the frequency ni
of “wins” for class iis computed by applying fi,jfor all j. This results in a vector
n=(n1;...;nK)of frequencies of “wins” of each class. The ﬁnal decision is
made for the most frequent class, i.e.,
fmultiple(x)=argmax
y∈ /CHny.
Using a probabilistic model for the frequencies n, different prior probabilities of the
classes y∈ /CHcan be incorporated, resulting in better generalization ability. Instead
of solving K(K−1)/2 separate optimization problems, it is again possible to
combine them in a single optimization problem. If the prior probabilities PY(j)
for the Kclasses are roughly1
K, the method scales as /C7parenleftbig
m2parenrightbig
and is independent
of the number of classes.
Recently, a different method for combining the single pairwise decisions has been
suggested. By specifying a directed acyclic graph (DAG) of consecutive pairwise
classiﬁcations, it is possible to introduce a class hierarchy. The leaves of such aDAG contain the ﬁnal decisions which are obtained by exclusion rather than byvoting. This method compares favorably with the o-v-o and o-v-r methods.
Support V ector Regression Estimation
In the regression estimation problem we are given a sample of mreal target values
t=(t1,..., tm)∈ /CAm, rather than mclasses y=(y1,..., ym)∈ /CHm. In order to
extend the SV learning algorithm to this task, we note that an “inversion” of thelinear loss l
linsufﬁces in order to use the SV machinery for real-valued outputs ti.
In classiﬁcation the linear loss llin(f(x),·)adds to the total cost, if the real-valued
output of|f(x)|is smaller than 1. For regression estimation it is desirable to have
the opposite true, i.e., incurred costs result if |t−f(x)|is very large instead of
small. This requirement is formally captured by the ε–insensitive loss
lε(f(x),t)=braceleftbigg
0i f |t−f(x)|≤ε
|t−f(x)|−ε if|t−f(x)|>ε. (2.51)
60 Chapter 2
Then, one obtains a quadratic programming problem similar to (2.46), this time in
2mdual variables αiand˜αi—two corresponding to each training point constraint.
This is simply due to the fact that fcan fail to attain a deviation less than εon both
sides of the given real-valued output ti, i.e., ti−εand ti+ε. An appealing feature
of this loss is that it leads to sparse solutions, i.e., only a few of the αi(or˜αi)a r e
non-zero. For further references that cover the regression estimation problem theinterested reader is referred to Section 2.6.
ν–Support V ector Machines for Classiﬁcation
A major drawback of the soft margin SV learning algorithm given in the form
(2.48) is the lack of control over how many training points will be considered
as margin errors or “outliers”, that is, how many have ˜γi(wSVM)<1. This is
essentially due to the fact that we ﬁxed the functional margin to one. By a simplereparameterization it is possible to make the functional margin itself a variableof the optimization problem. One can show that the solution of the followingoptimization problem has the property that the new parameter νbounds the fraction
ofmargin errors
1
m|{(xi,yi)∈z|˜γi(wSVM)<ρ}|from above:
minimize1
mmsummationdisplay
i=1ξi−νρ+1
2/bardblw/bardbl2
subject to yi/angbracketleftxi,w/angbracketright≥ρ−ξi i=1,..., m, (2.52)
ξ≥0,ρ≥0.
It can be shown that, for each value of ν∈[0,1], there exists a value of λ∈ /CA+
such that the solution wνand wλfound by solving (2.52) and (2.48) have the same
geometrical margins γz(wν)=γz(wλ). Thus we could try different values of λ
in the standard linear soft margin SVM to obtain a required fraction of marginerrors. The appealing property of the problem (2.52) is that this adjustment is donewithin the one optimization problem (see Section B.5). Another property whichcan be proved is that, for all probability models where neither P
X({X,1})nor
PX({X,−1})contains any discrete component, νasymptotically equals the fraction
of margin errors. Hence, we can incorporate prior knowledge of the noise levelE
Xbracketleftbig
1−max y∈ /CHparenleftbig
PY|X=x(y)parenrightbigbracketrightbig
viaν. Excluding all training points for which the
real-valued output is less than ρin absolute value, the geometrical margin of the
solution on the remaining training points is ρ//bardblw/bardbl.
61 Kernel Classiﬁers from a Machine Learning Perspective
2.5 Adaptive Margin Machines
In this last section we will introduce an algorithm which is based on a conceptually
different principle. Our new approach is motivated by a recently derived leave-one-out bound on the generalization error of kernel classiﬁers. Let us start byintroducing the concept of the leave-one-out error.
2.5.1 Assessment of Learning Algorithms
Whilst the mathematical model of learning to be introduced in Part II of this bookgives some motivation for the algorithms introduced so far, the derived boundsare often too loose to be useful in practical applications. A completely differentapproach can be taken if we study the expected risk of a learning algorithm/BT
rather than any hypothesis.
Deﬁnition 2.34 (Expected risk of a learning algorithm) Given an algorithm /BT:
∪∞
m=1
/CIm→ /BY, a loss function l : /CA× /CH→ /CAand a training sample size m ∈ /C6,
the expected risk R[
/BT,m]of the learning algorithm /BTis deﬁned by
R[
/BT,m]def=EZmbracketleftbig
Rbracketleftbig/BT(Z)bracketrightbigbracketrightbig
.
Note that this quantity does not bound the expected risk of the one classiﬁer
learned from a training sample zbut the average expected risk performance of
the algorithm /BT. For any training sample z, an almost unbiased estimator of this
quantity is given by the leave-one-out error R loo[
/BT,z]of /BT.
Deﬁnition 2.35 (Leave-one-out error) Given an algorithm /BT:∪∞
m=1
/CIm→ /BY,a
loss function l : /CA× /CH→ /CAand a training sample z∈ /CIm,t h e leave-one-out
error is deﬁned by
Rloo[
/BT,z]def=1
mmsummationdisplay
i=1l(
/BT((z1,..., zi−1,zi+1,..., zm))(xi),yi).
This measure counts the fraction of examples that are misclassiﬁed if we leave them
out for learning when using the algorithm /BT. The unbiasedness of the estimator is
made more precise in the following proposition.
62 Chapter 2
Theorem 2.36 (Unbiasedness of the leave-one-out error) Given a ﬁxed measure
PZ, a ﬁxed hypothesis space /BY, a ﬁxed loss l and a ﬁxed learning algorithm/BT:uniontext∞
m=1
/CIm→ /BY, the leave-one-out error is almost unbiased, that is,
EZmbracketleftbig
Rloobracketleftbig/BT,Zbracketrightbigbracketrightbig
=R[
/BT,m−1].
Proof In order to prove the result we note that
EZmbracketleftbig
Rloobracketleftbig/BT,Zbracketrightbigbracketrightbig
= EZmbracketleftBigg
1
mmsummationdisplay
i=1l(
/BT((Z1,..., Zi−1,Zi+1,..., Zm))(Xi),Yi)bracketrightBigg
=1
mmsummationdisplay
i=1EZmbracketleftbig
l(
/BT((Z1,..., Zi−1,Zi+1,..., Zm))(Xi),Yi)bracketrightbig
=1
mmsummationdisplay
i=1EZm−1bracketleftbig
EXY|Zm−1=zbracketleftbig
l(
/BT(z)(X),Y)bracketrightbigbracketrightbig
= EZm−1bracketleftbig
Rbracketleftbig/BT(Z)bracketrightbigbracketrightbig
=R[
/BT,m−1].
The theorem is proved.
Despite the fact that this result allows us to obtain a precise estimate of the expected
risk of the learning algorithm, its computation is very time consuming as thelearning algorithm must be invoked mtimes. Therefore, it is desirable to have a
bound on this quantity which can be computed solely on the basis of the trainingsample zand the learned hypothesis/BT(z). As demonstrated in Section 2.4, a rather
powerful class of learning algorithms is given by
ˆα= argmax
0≤α≤uW(α)
W(α)=−1
2α/primeYGYα+msummationdisplay
i=1J(αi), (2.53)
where J: /CA→ /CAis a ﬁxed function, uis an m×1 vector of positive real numbers,
Ydef=diag(y1,..., ym)and Gis the m×mGram matrix given by equation (2.18).
Based on the vector ˆα∈ /CAm, the linear classiﬁer fis then given by
f(x)=angbracketleftbigˆw,xangbracketrightbig
=msummationdisplay
i=1ˆαiyik(xi,x)⇔ˆw=msummationdisplay
i=1ˆαiyixi. (2.54)
We can give the following bound on the leave-one-out error Rloo[
/BTW,z].
63 Kernel Classiﬁers from a Machine Learning Perspective
Theorem 2.37 (Leave-One-Out Bound) Suppose we are given a training sample
z∈ /CImand a Mercer kernel k. Let ˆαbe the maximizing coefﬁcients of (2.53). Then
an upper bound on the leave-one-out error of /BTWis given by
Rloo[
/BTW,z]≤1
mmsummationdisplay
i=1/Theta1
−yimsummationdisplay
j=1
j/negationslash=iˆαjyjkparenleftbig
xi,xjparenrightbig
, (2.55)
where/Theta1(t)=It≥0is the Heaviside step function.
The proof is given in Appendix B.6. For support vector machines V . V apnik has
shown that the leave-one-out error is bounded by the ratio of the number of non-
zero coefﬁcients ˆαito the number mof training examples. The bound given in
Theorem 2.37 is slightly tighter than V apnik’s leave-one-out bound. This is easy tosee because all training points that have ˆα
i=0 cannot be leave-one-out errors in
either bound. V apnik’s bound assumes all support vectors (all training points with
ˆαi>0) are leave-one-out errors, whereas they only contribute as errors in equation
(2.55) if yisummationtextm
j=1
j/negationslash=iˆαjyjkparenleftbig
xi,xjparenrightbig
≤0. In practice this means that the bound (2.55)
is tighter for less sparse solutions.
2.5.2 Leave-One-Out Machines
Theorem 2.37 suggests an algorithm which directly minimizes the expression in
the bound. The difﬁculty is that the resulting objective function will contain thestep function I
t≥0. The idea we exploit is similar to the idea of soft margins in
SVMs, where the step function is upper bounded by a piecewise linear function,also known as the hinge loss (see Figure 2.7). Hence, introducing slack variables,gives the following optimization problem:
minimize
msummationdisplay
i=1ξi
subject to yimsummationdisplay
j=1
j/negationslash=iαjyjkparenleftbig
xi,xjparenrightbig
≥1−ξi i=1,..., m, (2.56)
α≥0,ξ≥0.
64 Chapter 2
For further classiﬁcation of new test objects we use the decision rule given in
equation (2.54). Let us study the resulting method which we call a leave-one-out
machine (LOOM).
First, the technique appears to have no free regularization parameter. This
should be compared with support vector machines, which control the amount ofregularization through the free parameter λ. For SVMs, in the case of λ→ 0
one obtains a hard margin classiﬁer with no training errors. In the case of linearlyinseparable datasets in feature space (through noise, outliers or class overlap) onemust admit some training errors (by constructing soft margins). To ﬁnd the best
choice of training error/margin tradeoff one must choose the appropriate value
ofλ. In leave-one-out machines a soft margin is automatically constructed. This
happens because the algorithm does not attempt to minimize the number of trainingerrors—it minimizes the number of training points that are classiﬁed incorrectlyeven when they are removed from the linear combination which forms the decisionrule. However, if one can classify a training point correctly when it is removedfrom the linear combination, then it will always be classiﬁed correctly when it isplaced back into the rule. This can be seen as α
iyik(xi,xi)always has the same
sign as yi; any training point is pushed further from the decision boundary by its
own component of the linear combination. Note also that summing for all j/negationslash=i
in the constraint (2.56) is equivalent to setting the diagonal of the Gram matrixGto zero and instead summing for all j. Thus, the regularization employed by
leave-one-out machines disregards the values k(x
i,xi)for all i.
Second, as for support vector machines, the solutions ˆα∈ /CAmcan be sparse
in terms of the expansion vector; that is, only some of the coefﬁcients ˆαiare non-
zero. As the coefﬁcient of a training point does not contribute to its leave-one-outerror in constraint (2.56), the algorithm does not assign a non-zero value to thecoefﬁcient of a training point in order to correctly classify it. A training point hasto be classiﬁed correctly by the training points of the same label that are close to it,but the point itself makes no contribution to its own classiﬁcation in training.
2.5.3 Pitfalls of Minimizi ng a Leave-One-Out Bound
The core idea of the presented algorithm is to directly minimize the leave-one-out
bound. Thus, it seems that we are able to control the generalization ability of an
algorithm disregarding quantities like the margin. This is not true in general18and
18 Part II, Section 4.3, shows that there are models of learning which allow an algorithm to directly minimize a
bound on its generalization error. This should not be confused with the possibility of controlling the generalization
error of the algorithm itself.
65 Kernel Classiﬁers from a Machine Learning Perspective
in particular the presented algorithm is not able to achieve this goal. There are some
pitfalls associated with minimizing a leave-one-out bound:
1. In order to get a bound on the leave-one-out error we must specify the algorithm/BTbeforehand. This is often done by specifying the form of the objective function
which is to be maximized (or minimized) during learning. In our particular casewe see that Theorem 2.37 only considers algorithms deﬁned by the maximizationofW(α)with the “box” constraint 0≤α≤u. By changing the learning algorithm
to minimize the bound itself we may well develop an optimization algorithmwhich is no longer compatible with the assumptions of the theorem. This is true inparticular for leave-one-out machines which are no longer in the class of algorithmsconsidered by Theorem 2.37—whose bound they are aimed at minimizing. Further,instead of minimizing the bound directly we are using the hinge loss as an upperbound on the Heaviside step function.
2. The leave-one-out bound does not provide any guarantee about the generaliza-
tion error R[/BT,z](see Deﬁnition 2.10). Nonetheless, if the leave-one-out error is
small then we know that, for most training samples z∈ /CIm, the resulting classi-
ﬁer has to have an expected risk close to that given by the bound. This is due toHoeffding’s bound which says that for bounded loss (the expected risk of a hypoth-esis fis bounded to the interval [0,1]) the expected risk R[/BT(z)]of the learned
classiﬁer /BT(z)is close to the expectation of the expected risk (bounded by the
leave-one-out bound) with high probability over the random choice of the trainingsample.
19Note, however, that the leave-one-out estimate does not provide any in-
formation about the variance of the expected risk. Such information would allowthe application of tighter bounds, for example, Chebyshev’s bound.
3. The original motivation behind the use of the leave-one-out error was to measure
the goodness of the hypothesis space/BYand of the learning algorithm /BTfor the
learning problem given by the unknown probability measure PZ. Commonly, the
leave-one-out error is used to select among different models /BY1, /BY2,... for a given
learning algorithm /BT. In this sense, minimizing the leave-one-out error is more a
model selection strategy than a learning paradigm within a ﬁxed model.
Deﬁnition 2.38 (Model selection) Suppose we are given r ∈ /C6ﬁxed learning
algorithms /BTi:∪∞
m=1
/CIm→ /CH
/CGwhich map training samples zto classiﬁers
h∈ /CH
/CG. Then, given a training sample z∈ /CIm, the problem of model selection
is to identify the learning algorithm /BTiw h i c hw o u l dl e a dt oac l a s s i ﬁ e r /BTi(z)
19 We shall exploit this idea further in Part II, Section 5.3.
66 Chapter 2
possessing the smallest expected risk, i.e., ﬁnd the algorithm /BTzsuch that/BTz=argmin/BTiR[
/BTi(z)].
If we have a ﬁxed learning procedure /BTχ:∪∞
m=1
/CIm→ /CH
/CGwhich is param-
eterized by χthen the model selection problem reduces to ﬁnding the the best
parameter χ(z)for a given training sample z∈ /CIm.
A typical model selection task which arises in the case of kernel classiﬁers is the
selection of parameters of the kernel function used, for example, choosing theoptimal value of σfor RBF kernels (see Table 2.1).
2.5.4 Adaptive Margin Machines
In order to generalize leave-one-out machines we see that the mconstraints in
equation (2.56) can be rewritten as
yimsummationdisplay
j=1
j/negationslash=iαjyjkparenleftbig
xi,xjparenrightbig
+αik(xi,xi)≥ 1−ξi+αik(xi,xi) i=1,..., m,
yif(xi)≥ 1−ξi+αik(xi,xi) i=1,..., m.
Now, it is easy to see that a training point (xi,yi)∈zis linearly penalized for
failing to obtain a functional margin of ˜γi(w)≥1+αik(xi,xi). In other words,
the larger the contribution the training point makes to the decision rule (the largerthe value of α
i), the larger its functional margin must be. Thus, the algorithm
controls the margin for each training point adaptively . From this formulation one
can generalize the algorithm to control regularization through the margin loss.To make the margin at each training point a controlling variable we propose thefollowing learning algorithm:
minimize
msummationdisplay
i=1ξi (2.57)
subject to yimsummationdisplay
j=1αjyjkparenleftbig
xi,xjparenrightbig
≥1−ξi+λα ik(xi,xi), i=1,..., m.
α≥0,ξ≥0. (2.58)
67 Kernel Classiﬁers from a Machine Learning Perspective
This algorithm—which we call adaptive margin machines —can also be viewed in
the following way: If an object xo∈xis an outlier (the kernel values w.r.t. points in
its class are small and w.r.t. points in the other class are large), αoin equation (2.58)
must be large in order to classify xocorrectly. Whilst support vector machines use
the same functional margin of one for such an outlier, they attempt to classify
xocorrectly. In adaptive margin machines the functional margin is automatically
increased to 1 +λα ok(xo,xo)for xoand thus less effort is made to change the
decision function because each increase in αowould lead to an even larger increase
inξoand can therefore not be optimal.
Remark 2.39 (Clustering in feature space) In adaptive margin machines the ob-
jects x r∈x, which are representatives of clusters (centers) in feature space /C3, i.e.,
those which have large kernel values w.r .t. objects from its class and small kernelvalues w.r .t. objects from the other class, will have non-zero α
r. In order to see this
we consider two objects, x r∈xand x s∈x, of the same class. Let us assume that
xrwithξr>0is the center of a cluster (w.r .t. the metric in feature space /C3induced
by the kernel k) and s with ξs>0lies at the boundary of the cluster . Hence we
subdivide the set of all objects into
xi∈C+:ξi=0,yi=yr,i/negationslash=r,i/negationslash=s,
xi∈C−:ξi=0,yi/negationslash=yr,
xi∈I+:ξi>0,yi=yr,i/negationslash=r,i/negationslash=s,
xi∈I−:ξi>0,yi/negationslash=yr.
We consider the change in ξif we increase αrby/Delta1> 0(giving ξ/prime) and simul-
taneously decrease αsby/Delta1(giving ξ/prime/prime). From equations (2.57)–(2.58) we know
that
xi∈C+:ξ/prime
i=ξi,ξ/prime/prime
i≤/Delta1k(xi,xs),
xi∈C−:ξ/prime
i≤/Delta1k(xi,xr),ξ/prime/prime
i=ξi,
xi∈I+:ξ/prime
i≥ξi−/Delta1k(xi,xr),ξ/prime/prime
i=ξi+/Delta1k(xi,xs),
xi∈I−:ξ/prime
i=ξi+/Delta1k(xi,xr),ξ/prime/prime
i≥ξi−/Delta1k(xi,xs),
xr:ξ/prime
r≥ξr−/Delta1(1−λ)k(xr,xr),ξ/prime/prime
r=ξr+/Delta1k(xr,xs),
xs:ξ/prime
s≥ξs−/Delta1k(xs,xr),ξ/prime/prime
s≥ξs+/Delta1(1−λ)k(xs,xs).
Now we choose the biggest /Delta1such that all inequalities for x i∈braceleftbig
I+,I−,r,r/primebracerightbig
become equalities and for x i∈{C+,C−}the r .h.s. equals zero. Then, the relative
68 Chapter 2
change in the objective function is given by
1
/Delta1msummationdisplay
i=1parenleftbig
ξ/prime
i+ξ/prime/prime
i−ξiparenrightbig
=summationdisplay
i∈I+(k(xi,xs)−k(xi,xr))
bracehtipupleft
bracehtipdownrightbracehtipdownleft
 bracehtipupright
change of intra −class distance−summationdisplay
i∈I−(k(xi,xs)−k(xi,xr))
bracehtipupleft
bracehtipdownrightbracehtipdownleft
 bracehtipupright
change of inter −class distance,
where we assume that k (xr,xr)=k(xs,xs). Since the cluster centers in feature
space /C3minimize the intra-class distance whilst maximizing the inter-class dis-
tances it becomes apparent that their αrwill be higher . Taking into account that
the maximum /Delta1considerable for this analysis is decreasing as λincreases we see
that, for suitable small λ, adaptive margin machines tend to only associate cluster
centers in feature space /C3with non-zero α’s.
2.6 Bibliographical Remarks
Linear functions have been investigated for several hundred years and it is virtually
impossible to identity their ﬁrst appearance in scientiﬁc literature. In the ﬁeldof artiﬁcial intelligence, however, the ﬁrst studies of linear classiﬁers go back tothe early works of Rosenblatt (1958), Rosenblatt (1962) and Minsky and Papert(1969). These works also contains the ﬁrst account of the perceptron learning
algorithm which was originally developed without any notion of kernels. The moregeneral ERM principle underpinning perceptron learning was ﬁrst formulated inV apnik and Chervonenkis (1974). In this book we introduce perceptron learningusing the notion of version space. This somewhat misleading name comes fromMitchell (1977), Mitchell (1982), Mitchell (1997) and refers to the fact that allclassiﬁers h∈V(z)are different “versions” of consistent classiﬁers. Originally,
T. Mitchell considered the hypothesis space of logic formulas only.
The method of regularization introduced in Section 2.2 was originally devel-
oped in Tikhonov and Arsenin (1977) and introduced into the machine learningframework in V apnik (1982). The adaptation of ill-posed problems to machinelearning can be found in V apnik (1982) where they are termed stochastic ill-posed
problems . In a nutshell, the difference to classical ill-posed problems is that the
solution yis a random variable of which we can only observe one speciﬁc sam-
ple. As a means to solving these stochastic ill-posed problems, V apnik suggestedstructural risk minimization .
The original paper which proved Mercer’s theorem is by Mercer (1909); the
version presented in this book can be found in König (1986). Regarding Remark
69 Kernel Classiﬁers from a Machine Learning Perspective
2.19, the work by Wahba (1990) gives an excellent overview of covariance func-
tions of Gaussian processes and kernel functions (see also Wahba (1999)). Thedetailed derivation of the feature space for polynomial kernels was ﬁrst publishedin Poggio (1975). In the subsection on string kernels we mentioned the possibilityof using kernels in the ﬁeld of Bioinformatics; ﬁrst approaches can be found inJaakkola and Haussler (1999b) and Karchin (2000). For a more detailed treatmentof machine learning approaches in the ﬁeld of Bioinformatics see Baldi and Brunak(1998). The notion of string kernels was independently introduced and developedby T. Jaakkola, C. Watkins and D. Haussler in Watkins (1998), Watkins (2000)
and Haussler (1999). A detailed study of support vector machines using these ker-
nels can be found in Joachims (1998) and Lodhi et al. (2001). For more traditionalmethods in information retrieval see Salton (1968). The Fisher kernel was origi-nally introduced in Jaakkola and Haussler (1999a) and later applied to the problemof detecting remote protein homologizes (Jaakkola et al. 1999). The motivation ofFisher kernels in these works is much different to the one given in this book andrelies on the notion of Riemannian manifolds of probability measures.
The consideration of RKHS introduced in Subsection 2.3.3 presents another
interesting aspect of kernels, that is, that they can be viewed as regularizationoperators in function approximation. By noticing that kernels are the Green’sfunctions of the corresponding regularization operator we can directly go fromkernels to regularization operators and vice versa (see Smola and Schölkopf (1998),Smola et al. (1998), Smola (1998) and Girosi (1998) for details). The original proofof the representer theorem can be found in Schölkopf et al. (2001). A simpler
version of this theorem was already proven in Kimeldorf and Wahba (1970) and
Kivinen et al. (1997).
In Section 2.4 we introduced the support vector algorithm as a combination of
structural risk minimization techniques with the kernel trick. The ﬁrst appearanceof this algorithm—which has its roots in the early 1960s (V apnik and Lerner1963)—is in Boser et al. (1992). The notion of functional and geometrical margins
is due to Cristianini and Shawe-Taylor (1999). For recent developments in kernelmethods and large margin classiﬁers the interested reader is referred to Schölkopfet al. (1998) and Smola et al. (2000). The original perceptron convergence theorem(without using kernels) is due to Novikoff (1962) and was independently provedby Block (1962). The extension to general kernels was presented in Aizerman et al.(1964).
In the derivation of the support vector algorithm we used the notion of canon-
ical hyperplanes which is due to V apnik (1995); for more detailed derivations of
the algorithm see also V apnik (1998), Burges (1998) and Osuna et al. (1997). An
70 Chapter 2
extensive study of the computational complexity of the support vector algorithm
can be found in Joachims (1999). In the ﬁve years an array of different implemen-tations have been presented, e.g., SVM
light(Joachims 1998; Osuna et al. 1997),
SMO (Platt 1999; Keerthi et al. 1999a; Shevade et al. 1999) and NPA (Keerthiet al. 1999b).
It was noted that without the introduction of soft margins, classiﬁers found
by the support vector algorithm tend to overﬁt. This was already observed inpractice (Cortes 1995; Schölkopf et al. 1995; Osuna et al. 1997; Joachims 1999;Bennett 1998). This tendency is called the nonrobustness of the hard margin SVM
algorithm—a term which is due to Shawe-Taylor and Cristianini (2000). In order
to introduce soft margins we used the hinge loss (due to Gentile and Warmuth(1999)) whose relation to support vector machines was shown in Sollich (2000).The seminal paper, which introduced the linear soft margin algorithm is Cortesand V apnik (1995); it also mentions the possibility of quadratically penalizing theslacks. The empirical success of quadratic soft margin support vector machineshas been demonstrated in V eropoulos et al. (1999) and Brown et al. (2000). Theformer paper also noted that different values of λfor training points from different
classes can be used to compensate for unequal class probabilities (see also Osunaet al. (1997) for details). Experimental evidence of the advantage of normalizingtraining data in feature space before applying the support vector algorithm can befound in Schölkopf et al. (1995), Joachims (1998) and Joachims (1999); theoreticalevidence is given in Herbrich and Graepel (2001b).
It is interesting to remark that the research on linear classiﬁers has run rather
parallel in the computer science and the statistical physics community (see Guyon
and Storck (2000) for a recent overview). One of the earliest works about supportvector machines (which are called maximal stability perceptrons )i sb yL a m b e r t
(1969). After this work, many statistical physicists got involved in neural networks(Gardner 1988; Gardner and Derrida 1988). As a consequence, several large mar-gin alternative of the perceptron learning algorithm were devised, for example, theminimal overlap (MinOver) algorithm (Krauth and Mézard 1987) or the adatron
(Anlauf and Biehl 1989). Finally, a fast primal-dual method for solving the maxi-mum margin problem has been published in Ruján (1993).
In Subsection 2.4.4 several extensions of the original support vector algorithm
are presented. For more details on the extension to multiple classes see Westonand Watkins (1998), Platt et al. (2000), Hastie and Tibshirani (1998), Guermeuret al. (2000) and Allwein et al. (2000). There exits a vast literature on supportvector regression estimation; for an excellent overview see Smola and Schölkopf
(2001), Smola (1996), Smola (1998) and Smola and Schölkopf (1998). It has
71 Kernel Classiﬁers from a Machine Learning Perspective
also been shown that support vector machines can be applied to the problem
of density estimation (Weston et al. 1999; V apnik and Mukherjee 2000). Thereparameterization of the support vector algorithm in terms of ν, the fraction of
margin errors, was ﬁrst published in Schölkopf et al. (2000) where it was alsoapplied to the support vector algorithm for regression estimation.
Finally, in Section 2.5, we introduce the leave-one-out error of algorithms
which motivate an algorithm called adaptive margin machines (Weston and Her-brich 2000). The proof of the unbiasedness of the leave-one-out error can be foundin Lunts and Brailovsky (1969) and also in V apnik (1998, p. 417). The bound on
the leave-one-out error for kernel classiﬁers presented in Theorem 2.37 was proven
in Jaakkola and Haussler (1999b).
3 Kernel Classiﬁers from a Bayesian Perspective
This chapter presents the probabilistic, or Bayesian approach to learning kernel
classiﬁers. It starts by introducing the main principles underlying Bayesian infer-
ence both for the problem of learning within a ﬁxed model and across models.
The ﬁrst two sections present two learning algorithms, Gaussian processes and
relevance vector machines, which were originally developed for the problem of re-
gression estimation. In regression estimation, one is given a sample of real-valuedoutputs rather than classes. In order to adapt these methods to the problem of classi-ﬁcation we introduce the concept of latent variables which, in the current context,
are used to model the probability of the classes. The chapter shows that the prin-ciple underlying relevance vector machines is an application of Bayesian model
selection to classical Bayesian linear regression. In the third section we present amethod which directly models the observed classes by imposing prior knowledge
only on weight vectors of unit length. In general, it is impossible to analyticallycompute the solution to this algorithm. The section presents a Markov chain MonteCarlo algorithm to approximately solve this problem, which is also known as Bayes
point learning . Finally, we discuss one of the earliest approaches to the problem
of classiﬁcation learning—the Fisher linear discriminant . There are ways to apply
the kernel trick to all these algorithms thus rendering them powerful tools in theapplication of kernel methods to the problem of classiﬁcation learning.
3.1 The Bayesian Framework
In the last chapter we saw that a learning problem is given by the identiﬁcationof an unknown relationship h∈/CH
/CGbetween objects x∈ /CGand classes y∈ /CH
solely on the basis of a given iid sample z=(x,y)=((x1,y1),...,(xm,ym))∈
(
/CG× /CH)m= /CIm(see Deﬁnition 2.1). Any approach that deals with this problem
74 Chapter 3
starts by choosing a hypothesis space1/C0⊆ /CH
/CGand a loss function l: /CH× /CH→ /CA
appropriate for the task at hand. Then a learning algorithm /BT:∪∞
m=1
/CIm→ /C0aims
to ﬁnd the one particular hypothesis h∗∈ /C0which minimizes a pre-deﬁned risk
determined on the basis of the loss function only, e.g., the expected risk R[h]of
the hypothesis hor the empirical risk Remp [h,z]ofh∈ /C0on the given training
sample z∈ /CIm(see Deﬁnition 2.5 and 2.11). Once we have learned a classiﬁer/BT(z)∈ /C0it is used for further classiﬁcation on new test objects. Thus, all the
information contained in the given training sample is summarized in the singlehypothesis learned.
The Bayesian approach is conceptually different insofar as it starts with a mea-
sure P
Hover the hypotheses—also known as the prior measure— which expresses
the belief that h∈ /C0is the relationship that underlies the data. The notion of belief
is central to Bayesian analysis and should not be confused with more frequentisticinterpretations of the probability P
H(h). In a frequentistic interpretation, PH(h)is
the relative frequency with which hunderlies the data, i.e., PY|X=x(y)=Ih(x)=y,
over an inﬁnite number of different (randomly drawn) learning problems. As anexample consider the problem of learning to classify images of Kanji symbols al-ways using the same set/C0of classiﬁers on the images. Then PH(h)is the relative
frequency of Kanji symbols (and therefore learning tasks) for which his the best
classiﬁer in /C0. Clearly, this number is difﬁcult to determine and meaningless when
given exactly one learning problem. In contrast, a Bayesian interpretation sees thenumber P
H(h)as expressing the subjective belief that h∈ /C0models the unknown
relationship between objects and classes. As such the term “belief” is dependent on
the observer and unquestionably the “truth”—or at least the best knowledge about
the truth—for that particular observer. The link between frequentistic probabilitiesand subjective beliefs is that, under quite general assumptions of rational behavioron the basis of beliefs, both measures have to satisfy the Kolmogorov axioms, i.e.,the same mathematical operations apply to them.
Learning in the Bayesian framework is the incorporation of the observed train-
ing sample z∈/CImin the belief expression PH. This results in a so-called posterior
measure PH|Zm=z. Compared to the single summary h∗∈ /C0obtained through the
machine learning approach, the Bayesian posterior PH|Zm=zis a much richer repre-
sentation of the information contained in the training sample zabout the unknown
object-class relationship. As mentioned earlier, the Bayesian posterior PH|Zm=zis
1 In order to unburden the main text we again take the liberty of synonymously referring to /C0, /BYand /CF as the
hypothesis space and to h∈ /C0,f∈ /BYand w∈ /CF ashypothesis ,classiﬁer or just function (see also Section 2.1
and footnotes therein).
75 Kernel Classiﬁers from a Bayesian Perspective
obtained by applying the rules of probability theory (see Theorem A.22), i.e.,
∀h∈ /C0: PH|Zm=z(h)=PZm|H=h(z)PH(h)
EHbracketleftbig
PZm|H=h(z)bracketrightbig=likelihood of hbracehtipdownleft
bracehtipuprightbracehtipupleft
bracehtipdownright
PYm|Xm=x,H=h(y)prior of hbracehtipdownleft
bracehtipuprightbracehtipupleft
bracehtipdownright
PH(h)
EHbracketleftbig
PYm|Xm=x,H=h(y)bracketrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
evidence of /C0,(3.1)
where we have used the fact that PZm|H=h(z)=PYm|Xm=x,H=h(y)PXm(x)because
hypotheses h∈ /CH
/CGonly inﬂuence the generation of classes y∈ /CHmbut not objects
x∈ /CGm. Due to the central importance of this formula—which constitutes the main
inference principle in the Bayesian framework—the three terms in equation (3.1)deserve some discussion.
The Likelihood Let us start with the training data dependent term. Interpreted
as a function of h∈/C0this term expresses how “likely” it is to observe the class
sequence yif we are given mobjects xand the true relationship is h∈ /C0. Without
any further prior knowledge, the likelihood contains all information that can beobtained from the training sample zabout the unknown relationship
2. In the case
of learning, the notion of likelihood is deﬁned as follows.
Deﬁnition 3.1 (Likelihood) G i v e naf a m i l y /C8of models PY|X=x,H=hover the space/CHtogether with an observation z =(x,y)∈ /CIthe function /C4: /C0× /CI→ /CA+is
called the likelihood of h and is deﬁned by/C4(h,z)def=PY|X=x,H=h(y),
that is, the probability of observing y under the probability measure PY|X=x,H=h.
In order to relate this deﬁnition to the likelihood expression given in equation (3.1)
we note that, due to the independence assumption made, it holds that/C4(h,z)=PYm|Xm=x,H=h(y)=mproductdisplay
i=1PY|X=xi,H=h(yi).
Given an appropriately chosen loss function l: /CH× /CH→ /CAit is reasonable
to assume that the smaller the loss incurred by the hypothesis h∈ /C0on a given
2 In fact, among statisticians there is a school of thought which adheres to the so-called likelihood principle :A n y
inference about hypothesis h∈ /C0for a given training sample z∈ /CImshould only be done on the basis of the
likelihood function /C4: /C0→ /CA+.
76 Chapter 3
training sample z∈ /CI, the more likely it is that the function hunderlies the data.
This has been made more precise in the following likelihood model.
Deﬁnition 3.2 (Inverse loss likelihood) Given a ﬁxed loss function l : /CH× /CH→ /CA
the inverse loss likelihood for a ﬁxed z=(x,y)∈ /CIis deﬁned by/C4l(h,z)def=expparenleftbig
−β−1·l(h(x),y)parenrightbig
summationtext
ˆy∈ /CHexpparenleftbig
−β−1·lparenleftbig
h(x),ˆyparenrightbigparenrightbig, (3.2)
whereβ∈[0,∞)is known as the noise level.
In the limiting case β→∞ the inverse loss likelihood is a constant function, i.e.,/C4l(h,z)=1
|/CH|regardless of the hypothesis hconsidered. In this case no additional
information is conveyed by the training sample. The likelihood obtained in the no-noise case, i.e., β=0, is of particular importance to us and we shall call it the
PAC-likelihood.
3
Deﬁnition 3.3 (PAC-likelihood) Assume /CHto be a ﬁnite set of classes. Then the
PAC likelihood is deﬁned by/C4PAC(h,(x,y))def=Ih(x)=y.
The Prior The prior measure (or belief) PHis the crucial quantity in a Bayesian
analysis—it is all the knowledge about the relationship between objects and classesbefore training data has arrived , encapsulated in a probability measure. Of course,
there is no general rule for determining particular priors. At the time when compu-tational power was a scarce resource, practitioners suggested conjugate priors.
Deﬁnition 3.4 (Conjugate prior) Given a set/C8/CH={ PY|X=x,H=h|h∈ /C0}of
measures over the sample space /CH, a set /C8/C0={ Pθ
H|θ∈ /C9}of probability mea-
sures over the hypothesis space /C0is called a conjugate prior family to /C8/CHif, for
any prior PH∈ /C8/C0, the corresponding posterior PH|Z=zis still in the set /C8/C0for
all values of z, i.e.,
∀PH∈ /C8/C0:∀(x,y)∈ /CI: PH|Z=(x,y)∝parenleftbig
PY|X=x,H=hPHparenrightbig
∈ /C8/C0,
where the measure PH|Z=zis deﬁned in (3.1).
3 The abbreviation PAC is introduced in Part II, Section 4.2.
77 Kernel Classiﬁers from a Bayesian Perspective
The advantage of conjugate priors becomes apparent if we additionally assume that
the conjugate family /C8/C0is parameterized by a small number of parameters. Then,
inference on the basis of the data, z∈ /CIm, simpliﬁes to the computation of a few
new parameter values.
Example 3.5 (Conjugate prior) A popular example of a conjugate prior family is
the family of Beta distributions over the success probability p for the binomiallydistributed random variables (see also Table A.1), i.e., for P
P=Beta(α,β)and
PX=Binomial (n,p)we know that PP|X=i=Beta(α+i,β+n−i)because
fP|X=i(p)=PX|P=p(i)fP(p)
integraltext1
0PX|P=ˆp(i)fPparenleftbig
ˆpparenrightbig
dˆp
=parenleftbign
iparenrightbig
pi(1−p)n−i/Gamma1(α+β)
/Gamma1(α)/Gamma1(β)pα−1(1−p)β−1
integraltext1
0parenleftbign
iparenrightbig
ˆpiparenleftbig
1−ˆpparenrightbign−i/Gamma1(α+β)
/Gamma1(α)/Gamma1(β)ˆpα−1parenleftbig
1−ˆpparenrightbigβ−1dˆp
=pα+i−1(1−p)n+β−i−1
integraltext1
0ˆpα+i−1parenleftbig
1−ˆpparenrightbign+β−i−1dˆp.
Another example of a conjugate prior family is the family of Gaussian measures
over the mean µof another Gaussian measure, which will be discussed at more
length in Section 3.2.
It is worth mentioning that, apart from computational reasons, there is no moti-
vation for favoring conjugate priors over other prior measures PH. As a general
guideline, one should try to model the prior knowledge with a family of probabil-
ity measures that is quite ﬂexible but which leaves inference still computationally
feasible. Examples of such prior families are given in the subsequent sections.
Evidence of /C0 The denominator of equation (3.1) is called the evidence of the
model (or hypothesis space) /C0. It expresses how likely the observation of the class
sequence y∈ /CHmis, in conjunction with the mtraining objects x∈ /CGmunder
all different hypotheses h∈ /CH
/CGcontained in /C0, weighted by their prior belief
PH(h). Hence, this quantity is a function of the class sequence y∈ /CHmfor a ﬁxed
hypothesis space /C0and for the object sample x∈ /CGm.I nf a c t ,w h e nv i e w e d
as a function of the classes the evidence is merely a probability measure overthe space of all classiﬁcations at the mtraining objects x. As every probability
measure has the property that it must sum to one, we see that high values of the
78 Chapter 3
0 1simple
uniform0.00 0.04 0.08 0.12/DD/BD
/DD/BE
Figure 3.1 Effect of evidence maximization. For a training set size of m=5w eh a v e
arranged all possible classiﬁcations y∈{−1,+1}5on the interval [0 ,1] by g(y)=summationtext5
i=12−i+1Iyi=+ 1and depicted two different distributions EHibracketleftbig
PY5|X5=x,Hi=h(y)bracketrightbig
over
the space of all classiﬁcati ons on the 5 training objects x∈ /CG5(gray and white bars).
Since both probability mass functions sum up to one there must exist classiﬁcations y,
e.g., y1, for which the more simple model /C01(because it explains only a small number
of classiﬁcations) has a higher evidence than the more complex model /C02. Nonetheless, if
we really observe a complex classiﬁcation, e.g., y2, then the maximization of the evidence
leads to the “correct” model /C02.
evidence for some classiﬁcations ymust imply that other classiﬁcations, ˜y, lead
to a small evidence of the ﬁxed model /C0. Hence every hypothesis space has some
“preferred” classiﬁcations for which its evidence is high but, necessarily, also other“non-preferred” classiﬁcations of the observed object sequence x∈/CGm.
This reasoning motivates the usage of the evidence for the purpose of model
selection. We can view the choice of the hypothesis space /C0out of a given
set{/C01,..., /C0r}a as model selection problem because it directly inﬂuences the
Bayesian inference given in equation (3.1). Using the evidence would lead to thefollowing model selection algorithm:
Given a training sample z=(x,y)and rhypothesis spaces /C01,..., /C0r
choose the hypothesis space /C0such that EHibracketleftbig
PYm|Xm=x,Hi=h(y)bracketrightbig
is maxi-
mized.

79 Kernel Classiﬁers from a Bayesian Perspective
By the above reasoning we see that overly complex models /C0, which ﬁt almost
any possible classiﬁcation y∈ /CHmof a given sequence x∈ /CGmof training objects,
are automatically penalized. This is because the more classiﬁcations a hypothesisspace is capable of describing
4, the smaller the probability of a single classiﬁcation
under the ﬁxed model. If, however, we really observe a classiﬁcation ythat cannot
be accommodated by any of the simple models, the evidence of the complex model/C0is largest. This is also illustrated in Figure 3.1.
The evidence as a measure of the quality of a hypothesis space can also be
derived if we additionally consider the space /BW={/C01,..., /C0r}of all possible
hypothesis spaces considered. First, equation (3.1) can be rewritten as
PH|Zm=z,D= /C0i(h)=PYm|Xm=x,H=h,D= /C0i(y)PH|D= /C0i(h)
EH|D= /C0ibracketleftbig
PYm|Xm=x,H=h,D= /C0i(y)bracketrightbig
=PYm|Xm=x,H=h,D= /C0i(y)PH|D= /C0i(h)
PYm|Xm=x,D= /C0i(y),
where we have included the conditioning on the ﬁxed hypothesis space /C0i.N o w ,
using Theorem A.22 to compute the posterior belief in the hypothesis space /C0i
after having seen the training sample zwe see that
PD|Zm=z(
/C0i)=PZm|D= /C0i(z)PD(
/C0i)
EDbracketleftbig
PZm|D= /C0i(z)bracketrightbig∝PYm|Xm=x,D= /C0i(y)PD(
/C0i), (3.3)
because the denominator of equation (3.3) does not depend on /C0i. Without any
prior knowledge, i.e., with a uniform measure PD, we see that the posterior belief
is directly proportional to the evidence PYm|Xm=x,D= /C0i(y)of the model /C0i.A sa
consequence, maximizing the evidence in the course of model selection is equiva-lent to choosing the model with the highest posterior belief.
3.1.1 The Power of Conditioning on Data
From a purely Bayesian point of view, for the task of learning we are ﬁnished assoon as we have updated our prior belief P
Hinto the posterior belief PH|Zm=zusing
equation (3.1). Nonetheless, our ultimate goal is to ﬁnd one (deterministic) function
h∈ /CH
/CGthat best describes the relationship objects and classes, which is implicitly
4 We say that the hypothesis space /C0describes the classiﬁcation yat some given training points xif there exists
at least one hypothesis h∈ /C0which leads to a high likelihood /C4(h,(x,y)). Using the notion of an inverse
loss likelihood this means that there exists a hypothesis h∈ /C0that has a small empirical risk or training error
Remp [h,(x,y)] (see also Deﬁnition 2.11).
80 Chapter 3
expressed by the unknown measure PZ=PY|XPX. In order to achieve this goal,
Bayesian analysis suggests strategies based on the posterior belief PH|Zm=z:
If we are restricted to returning a function h∈ /C0from a pre-speciﬁed hypothesis
space /C0⊆ /CH
/CGand assume that PH|Zm=zis highly peaked around one particular
function then we determine the classiﬁer with the maximum posterior belief.
Deﬁnition 3.6 (Maximum-a-posteriori estimator) F or a given posterior belief
PH|Zm=zover a hypothesis space /C0⊆ /CH
/CG,t h e maximum-a-posteriori estimator
is deﬁned by5/BTMAP(z)def=argmax
h∈ /C0PH|Zm=z(h). (3.4)
If we use the inverse loss likelihood and note that the posterior PH|Zm=zis given
by the product of the likelihood and the prior we see that this scheme returns theminimizer of the training error and our prior belief, which can be thought of as aregularizer (see also Subsection 2.2.2). The drawback of the MAP estimator is thatit is very sensitive to the training sample if the posterior measure is multi modal.
Even worse, the classiﬁer/BTMAP(z)∈ /C0is, in general, not unique, for example if
the posterior measure is uniform.
If we are not conﬁned to returning a function from the original hypothesis space/C0then we can use the posterior measure PH|Zm=zto induce a measure PY|X=x,Zm=z
over classes y∈ /CHat a novel object x∈ /CGby
PY|X=x,Zm=z(y)=PH|Zm=z({h∈ /C0|h(x)=y}).
This measure can then be used to determine the class ywhich incurs the smallest
loss at a given object x.
Deﬁnition 3.7 (Bayes classiﬁcation strategy) Given a posterior belief PH|Zm=z
over a hypothesis space /C0and a loss function l : /CH× /CH→ /CAthe Bayes clas-
siﬁcation strategy Bayes zimplements the following classiﬁcation
Bayes z(x)def=argmin
y∈ /CHEH|Zm=zbracketleftbig
l(y,H(x))bracketrightbig
. (3.5)
5 If we have an inﬁnite number of hypotheses the quantity PH|Zm=z(h)is replaced by the corresponding value
of the density, i.e., fH|Zm=z(h).
81 Kernel Classiﬁers from a Bayesian Perspective
Assuming the zero-one loss l 0−1given in equation (2.10) we see that the Bayes
optimal decision at x is given by
Bayes z(x)def=argmax
y∈ /CHPH|Zm=z({h∈ /C0|h(x)=y}). (3.6)
It is interesting to note that, in the special case of the two-classes /CH={−1,+1},
we can write Bayes zas a thresholded real-valued function, i.e.,
Bayes z(x)=signparenleftbig
EH|Zm=zbracketleftbig
H(x)bracketrightbigparenrightbig
. (3.7)
If we are not restricted to returning a deterministic function h∈ /CH
/CGwe can
consider the so-called Gibbs classiﬁcation strategy .
Deﬁnition 3.8 (Gibbs classiﬁcation strategy) Given a posterior belief PH|Zm=z
over a hypothesis space /C0⊆ /CH
/CG,t h e Gibbs classiﬁcation strategy Gibbs zis given
by
Gibbs z(x)def=h(x), h∼PH|Zm=z,
that is, for a novel test object x ∈ /CGwe randomly draw a function h according to
PH|Zm=zand use this function to label x.
Although this classiﬁer is used less often in practice we will explore the full power
of this classiﬁcation scheme later in Section 5.1.
In the following three sections we consider speciﬁc instances of the Bayesian prin-
ciple which result in new learning algorithms for linear classiﬁers. It is worth men-tioning that the Bayesian method is not limited to the task of binary classiﬁcationlearning, but can also be applied if the output space is the set of real numbers.In this case, the learning problem is called the problem of regression estimation .
We shall see that in many cases, the regression estimation algorithm is the startingpoint to obtain a classiﬁcation algorithm.
3.2 Gaussian Processes
In this section we are going to consider Gaussian processes both for the purposeof regression and for classiﬁcation. Gaussian processes, which were initially de-veloped for the regression estimation case, are extended to classiﬁcation by using
82 Chapter 3
the concept of latent variables and marginalization. In this sense, the regression
estimation case is much more fundamental.
3.2.1 Bayesian Linear Regression
In the regression estimation problem we are given a sequence x=(x1,..., xm)∈/CGmofmobjects together with a sequence t=(t1,..., tm)∈ /CAmofmreal-valued
outcomes forming the training sample z=(x,t). Our aim is to ﬁnd a functional
relationship f∈ /CA
/CGbetween objects xand target values t. In accordance with
Chapter 2 we will again consider a linear model /BY/BY={x/mapsto→/angbracketleftx,w/angbracketright|w∈ /C3},
where we assume that xdef=φ(x)andφ: /CG→ /C3⊆/lscriptn
2is a given feature mapping
(see also Deﬁnition 2.2). Note that x∈ /C3should not be confused with the training
sequence x∈ /CGmwhich results in an m×nmatrix X=parenleftbig
x/prime
1;...;x/prime
mparenrightbig
whenφis
applied to it.
First, we need to specify a prior over the function space /BY. Since each function
fwis uniquely parameterized by its weight vector w∈ /C3it sufﬁces to consider
a prior distribution on weight vectors. For algorithmic convenience let the priordistribution over weights be a Gaussian measure with mean 0and covariance I
n,
i.e.,
PW=Normal(0,In). (3.8)
Apart from algorithmical reasons such a prior favors weight vectors w∈ /C3
with small coefﬁcients wibecause the log-density is proportional to −/bardblw/bardbl2=
−summationtextn
i=1w2
i(see Deﬁnition A.26). In fact, the weight vector with the highest a-
priori density is w=0.
Second, we must specify the likelihood model PTm|Xm=x,W=w. Let us assume
that, for a given function fwand a given training object x∈ /CG, the real-valued
output Tis normally distributed with mean fw(x)and variance σ2
t.U s i n gt h e
notion of an inverse loss likelihood such an assumption corresponds to using thesquared loss , i.e., l
2(f(x),t)=(f(x)−t)2when considering the prediction
task under a machine learning perspective. Further, it shall be assumed that the
real-valued outputs T1andT2atx1and x2/negationslash=x1are independent. Combining these
two requirements results in the following likelihood model:
PTm|Xm=x,W=w(t)=Normalparenleftbig
Xw,σ2
tImparenrightbig
. (3.9)
83 Kernel Classiﬁers from a Bayesian Perspective
A straightforward application of Bayes’ theorem then reveals that the posterior
measure PW|Xm=x,Tm=tis also a Gaussian measure (see Theorem A.28), i.e.,
PW|Xm=x,Tm=t= NormalparenleftBig
σ−2
tparenleftbig
σ−2
tX/primeX+Inparenrightbig−1X/primet,parenleftbig
σ−2
tX/primeX+Inparenrightbig−1parenrightBig
= NormalparenleftBigparenleftbig
X/primeX+σ2
tInparenrightbig−1X/primet,parenleftbig
σ−2
tX/primeX+Inparenrightbig−1parenrightBig
.
In order to predict at a new test object x∈ /CGusing the Bayes prediction strategy
we take into account that, by the choice of our likelihood model, we look for the
minimizer of squared loss, i.e.,
Bayes z(x)= argmin
t∈ /CAEW|Xm=x,Tm=t[l2(fW(x),t)]
= argmin
t∈ /CAEW|Xm=x,Tm=tbracketleftBig
(/angbracketleftx,W/angbracketright−t)2bracketrightBig
= EW|Xm=x,Tm=tbracketleftbig
/angbracketleftx,W/angbracketrightbracketrightbig
=angbracketleftbig
x,EW|Xm=x,Tm=tbracketleftbig
Wbracketrightbigangbracketrightbig
, (3.10)
=angbracketleftBig
x,parenleftbig
X/primeX+σ2
tInparenrightbig−1X/primetangbracketrightBig
,
where the third line follows from the fact that (/angbracketleftx,w/angbracketright−t)2is minimized at t=
/angbracketleftx,w/angbracketright. In the current form the prediction at xinvolves the inversion of the n×n
matrix X/primeX+σ2
tInwhich is the empirical covariance matrix of the training objects
in feature space /C3. This is an unfavorable property as it requires explicit evaluation
of the feature mapping φ: /CG→ /C3. In order to simplify this expression we apply
the Woodbury formula (see Theorem A.79) to the inverse of this matrix, i.e.,
parenleftbig
X/primeX+σ2
tInparenrightbig−1=σ−2
tIn−σ−4
tX/primeparenleftbig
Im+σ−2
tXX/primeparenrightbig−1X
=σ−2
tparenleftBig
In−X/primeparenleftbig
XX/prime+σ2
tImparenrightbig−1XparenrightBig
.
Thus, the Bayesian prediction strategy at a given object x∈ /CGcan be written as,
x/primeparenleftbig
X/primeX+σ2
tInparenrightbig−1X/primet=σ−2
tparenleftBig
x/primeX/prime−x/primeX/primeparenleftbig
XX/prime+σ2
tImparenrightbig−1XX/primeparenrightBig
t
=σ−2
tx/primeX/primeparenleftbig
XX/prime+σ2
tImparenrightbig−1parenleftbigparenleftbig
XX/prime+σ2
tImparenrightbig
−XX/primeparenrightbig
t
= x/primeX/primeparenleftbig
XX/prime+σ2
tImparenrightbig−1t. (3.11)
Note that this modiﬁcation only requires us to invert a m×mmatrix rather than the
n×nmatrix X/primeX+σ2
tIn. As a consequence, all that is needed for the prediction at
individual objects is the inner product function k(x,˜x)=angbracketleftbig
x,˜xangbracketrightbig
=/angbracketleftφ(x),φ(˜x)/angbracketright
84 Chapter 3
also known as the kernel for the mapping φ: /CG→ /C3⊆/lscriptn
2(see also Deﬁnition
2.14). Exploiting the notions of kernels the prediction at any x∈ /CGcan be written
as
f(x)=msummationdisplay
i=1ˆαik(x,xi), ˆα=parenleftbig
G+σ2
tImparenrightbig−1t, (3.12)
where the m×mmatrix G=XX/primeis deﬁned by Gij=kparenleftbig
xi,xjparenrightbig
and is called the
Gram matrix. From this expression we see that the computational effort involved in
ﬁnding the linear function from a given training sample is /C7parenleftbig
m3parenrightbig
since it involves
the inversion of the m×mmatrix G+σ2
tIm. However, by exploiting the fact that, for
many kernels, the matrix Ghas eigenvalues λ=(λ1,...,λ m)/primethat decay quickly
toward zero, it is possible to approximate the inversion of the matrix G+σ2
tImwith/C7parenleftbig
m2parenrightbig
computations.
In order to understand why this method is also called Gaussian process re-
gression we note that, under the assumptions made, the probability model of
the data PTm|Xm=x(t)is a Gaussian measure with mean vector 0and covariance
XX/prime+σ2
tI=G+σ2
tI(see Theorem A.28 and equations (3.8) and (3.9)). This is
the deﬁning property of a Gaussian process.
Deﬁnition 3.9 (Stochastic and Gaussian processes) Astochastic process T:/CG→(
/CA, /BU1,PT)is a collection of random variables indexed by x ∈ /CG
and is fully deﬁned by the probability distribution of any ﬁnite sequence T=
(T(x1),..., T(xm)).Gaussian processes are a subset of stochastic processes that
can be speciﬁed by giving only the mean vector ETbracketleftbig
Tbracketrightbig
and the covariance matrix
Cov(T)for any ﬁnite sample x∈ /CGm.
As can be seen, Bayesian regression involving linear functions and the prior and
likelihood given in equations (3.8) and (3.9), respectively, is equivalent to mod-eling the outputs as a Gaussian process having mean 0and covariance function
C(x,˜x)=angbracketleftbig
x,˜xangbracketrightbig
+σ
2
tIx/negationslash=˜x=k(x,˜x)+σ2
tIx/negationslash=˜x. The advantage of the Gaussian
process viewpoint is that weight vectors are avoided—we simply model the data
z=(x,t)directly. In order to derive the prediction fGP(x)of a Gaussian process
at a new object x∈ /CGwe exploit the fact that every conditional measure of a Gaus-
sian measure is again Gaussian (see Theorem A.29). According to equation (A.12)
85 Kernel Classiﬁers from a Bayesian Perspective
this yields PT|Tm=t,Xm=x,X=x=Normalparenleftbig
µt,υ2
tparenrightbig
with
µt= x/primeX/primeparenleftbig
G+σ2
tIparenrightbig−1t=msummationdisplay
i=1parenleftBigparenleftbig
G+σ2
tIparenrightbig−1tparenrightBig
ik(xi,x), (3.13)
υ2
t= x/primex+σ2
t−x/primeX/primeparenleftbig
G+σ2
tIparenrightbig−1Xx (3.14)
= k(x,x)+σ2
t−msummationdisplay
i=1msummationdisplay
j=1k(xi,x)·kparenleftbig
xj,xparenrightbig
·parenleftBigparenleftbig
G+σ2
tIparenrightbig−1parenrightBig
ij,
by considering the joint probability of the real-valued outputs (t;t)at the training
points x∈ /CGmand the new test object x∈ /CGwith covariance matrix
parenleftbigg
G+σ2
tIX x
x/primeX/primex/primex+σ2
tparenrightbigg
.
Note that the expression given in equation (3.13) equals the Bayesian prediction
strategy given in equation (3.11) or (3.12) when using a kernel. Additionally, theGaussian process viewpoint offers an analytical expression for the variance of theprediction at the new test point, as given in equation (3.14). Hence, under theassumption made, we cannot only predict the new target value at a test object but,also judge the reliability of that prediction. It is though important to recognize that
such error bars on the prediction are meaningless if we cannot guarantee that our
Gaussian process model is appropriate for the learning problem at hand.
Remark 3.10 (Covariance functions and kernels) It is interesting to compare
equation (3.12) with the expression for the change of the Gram matrix Gwhen
considering quadratic soft margin support vector machines (see equation (2.50)
and Remark 2.32). We can either treat the feature space mapping φ:/CG→ /C3and
the variance on the outputs t ∈ /CAseparately or incorporate the latter directly into
the kernel k: /CG× /CG→ /CAby changing the Gram matrix GintotildewideG
tildewideG=G+σ2
tI⇔ kσ2t(x,˜x)=k(x,˜x)+σ2
tIx=˜x. (3.15)
This equivalence allows us to view the parameter λin the support vector classi-
ﬁcation case as an assumed noise level on the real-valued output y i/angbracketleftw,xi/angbracketrightat all
the training points z i=(xi,yi). Note that the difference in the classiﬁcation case
is the thresholding of the target t ∈ /CAto obtain a binary decision y ∈{−1,+1}.
Under the Gaussian process consideration we see that all prior knowledge has been
incorporated in the choice of a particular kernel k: /CG× /CG→ /CAand variance
86 Chapter 3
σ2
t∈ /CA+. In order to choose between different kernels and variances we employ the
evidence maximization principle. For a given training sample z=(x,t)of object-
target pairs we maximize the expression PTm|Xm=x(t)w.r.t. the kernel parameters
and variance σ2
t. The appealing feature of the Gaussian process model is that this
expression is given in an analytical form. It is the value of the m–dimensional
Gaussian density with mean 0and covariance matrix G+σ2
tIatt∈ /CAm.I fw e
consider the log-evidence given by
lnparenleftbig
PTm|Xm=x(t)parenrightbig
=−1
2parenleftBig
mln(2π)+lnparenleftbigvextendsinglevextendsingleG+σ2
tIvextendsinglevextendsingleparenrightbig
+t/primeparenleftbig
G+σ2
tIparenrightbig−1tparenrightBig
,
we see that, in the case of a differentiable kernel function k, the gradient of the log-
evidence can be computed analytically and thus standard optimization methods canbe used to ﬁnd the most probable kernel parameters.
Example 3.11 (Evidence maximization with Gaussian processes) In Figure 3.2
we have shown an application of the maximization of the evidence for a simple
regression problem on the real line/CG= /CA. As can be seen from this example, the
evidence is often multi-modal which can make its maximization very difﬁcult—afew observations x
1,..., xras well as initial parameters θ0andσ0in the search
for the most probable parameter can have a large inﬂuence on the found localmaximum. One way to overcome this problem is to integrate over all possibleparameters θand variances σ
2
tand weight each prediction by its evidence.
Another interesting observation to be drawn from Figure 3.2 is of the ability of
the method to provide error bars on the prediction t ∈ /CA(dotted lines in the middle
and left plot). If we have chosen a model which assumes almost no variance on theoutputs then we have a small variance for test points which are near the trainingsample x(in the metric induced by the kernel). This is in accordance with the
intuitive notion of the variability of the target values for all test points having highcorrelation with the training sample.
Example 3.12 (Automatic relevance determination) An interesting application
of the analytical maximization of the evidence in Gaussian processes is for thedetermination of relevant dimensions in the case of an N –dimensional input space/CG⊆ /CAN. If we use the Mahalanobis kernel (see also Table 2.1) given by
k(/vectoru,/vectorv)=expparenleftBigg
−Nsummationdisplay
i=1(ui−vi)2
σ2
iparenrightBigg
87 Kernel Classiﬁers from a Bayesian Perspective
0.0 0.1 0.2 0.3 0.4 0.5 0.60.5 1.0 1.5 2.0 2.5 3.0 3.5
variancebandwidth
02468−1.5 −1.0 −0.5 0.0 0.5 1.0 1.5
xt(x)
02468−1.0 −0.5 0.0 0.5 1.0 1.5
xt(x)
Figure 3.2 (Left) The log-evidence for a simple regression problem on the real line/CG= /CA.T h e x–axis varies over different values of the assumed variance σ2
twhereas the
y–axis ranges over different values for the bandwidth σin an RBF kernel (see Table 2.1).
The training sample consists of the 6 observations shown in the middle plot (dots). The
dot (•) and cross (×) depict two values at which the gradient vanishes, i.e., local maxima
of the evidence. (Middle) The estimated function corresponding to the kernel bandwidth
σ=1.1 and variance σ2
t=0(•in the left picture). The dotted line shows the error bars
of one standard deviation computed according to equation (3.14). Note that the variance
increases in regions where no training data is available. (Right) The estimated function
corresponding to the kernel bandwidth σ=3 and variance σ2
t=0.5(×in the left picture).
This local maxima is attained because all observations are assumed to be generated by the
variance component σ2
tonly.
we see that, for the case of σi→∞ , the i th input dimension is neglected in the
computation of the kernel and can therefore be removed from the dataset (see alsoFigure 3.3). The appealing feature of using such a kernel is that the log-evidence
lnparenleftbig
P
Tm|Xm=x(t)parenrightbig
can be written as a differentiable function in the parameters
σ∈ /CA+and thus standard maximization methods such as gradient ascent, Newton-
Raphson and conjugate gradients can be applied. Moreover , in a Bayesian spirit itis also possible to additionally favor large values of the parameters σ
iby placing
an exponential prior on σ−2
i.
3.2.2 From Regression to Classiﬁcation
We shall now return to our primary problem, which is classiﬁcation. We are given
mclasses y=(y1,..., ym)∈ /CHm={−1,+1}mrather than mreal-valued outputs
t=(t1,..., tm)∈ /CAm. In order to use Gaussian processes for this purpose we are
faced with the following problem: Given a model for mreal-valued outputs t∈ /CAm
how can we model 2mdifferent binary vectors y∈ /CHm?
In order to solve this problem we note that, for the purpose of classiﬁcation,
we need to know the predictive distribution PY|X=x,Zm=z(y)where z=(x,y)is
88 Chapter 3
input dimension 1−10
−5
0
5
10input dimension 2
−10−50510function values
−10−505
input dimension 1−10
−5
0
5
10input dimension 2
−10−50510function values
−15−10−50
Figure 3.3 (Left) A function fwsampled from the ARD prior with σ1=σ2=√
5w h e r e/CG= /CA2. Considering the 1–D functions over the second input dimension for ﬁxed values
of the ﬁrst input dimension, we see that the functions change slowly only for nearby valuesof the ﬁrst input dimension. The size of the neighborhood is determined by the choice ofσ
1andσ2.(Right) A function fwsampled from the ARD prior with σ1=20σ2. As can
be seen the function is only changing very slowly over the ﬁrst input dimension. In thelimiting case σ
1→∞ any sample fwis a function of the second input dimension only.
the full training sample of object-class pairs. Given the predictive distribution at
a new test object x∈ /CGwe decide on the class ywith maximum probability
PY|X=x,Zm=z(y). The trick which enable the use of a regression estimation method
such as Gaussian processes is the introduction of a latent random variable T
which has inﬂuence on the conditional class probability PY|X=x.A sw es a wi n
the last subsection, each prediction fGP(x)of a Gaussian process at some test
object x∈ /CGcan be viewed as the real-valued output of a mean weight vector
wcm=EW|Xm=x,Tm=tbracketleftbig
Wbracketrightbig
in some ﬁxed feature space /C3(see equation (3.10)), i.e.,
the distance to the hyperplane with the normal vector wcm. Intuitively, the further
away a test object x∈ /CGis from the hyperplane (the larger the value of t), the
more likely it is that the object is from the class y=sign(t). One way to model
this intuitive notion is by
PY|T=t(y)=expparenleftbig
β−1·ytparenrightbig
expparenleftbig
β−1·ytparenrightbig
+expparenleftbig
−β−1·ytparenrightbig=expparenleftbig
2β−1·ytparenrightbig
1+expparenleftbig
2β−1·ytparenrightbig, (3.16)
89 Kernel Classiﬁers from a Bayesian Perspective
02468−1.0 −0.5 0.0 0.5 1.0 1.5
xt(x)
−1.5 −0.5 0.5 1.0 1.50.0 0.2 0.4 0.6 0.8 1.0
tπ(t)β=0.1
β=1.0
β=5.0
024680.0 0.2 0.4 0.6 0.8 1.0
xPY|X=x(+1)/D0/CP/D8/CT/D2 /D8 /DA /CP/D6/CX/CP/CQ/D0/CT /D7/CX/CV/D1/D3/CX/CS /CU/D9/D2/CR/D8/CX/D3/D2 /D4/D6/CT/CS/CX/CR/D8/CX/DA /CT /CS/CX/D7/D8/D6/CX/CQ/D9/D8/CX/D3/D2
Figure 3.4 Latent variable model for classiﬁcation with Gaussian processes. Each real-
valued function (left) is “transfered” through a sigmoid given by equation (3.16) (middle
plot). As a result we obtain the predictive distribution PY|X=x,T=t(+1)for the class +1
as a function of the inputs (right). By increasing the noise parameter βwe get smoother
functions g(x)=PY|X=x,T=t(+1). In the limit of β→ 0 the predictive distribution
becomes a zero-one valued function.
whereβcan be viewed as a noise level, i.e., for lim β→0PY|T=t(y)=Iyt≥0(see also
Deﬁnition 3.2 and Figure 3.4). In order to exploit the latent random variables wemarginalize over all their possible values (t,t)∈/CAm+1at the mtraining objects
x∈ /CGmand the test object x∈ /CG, i.e.,
PY|X=x,Zm=z(y)= ETm+1|X=x,Zm=zbracketleftbig
PY|X=x,Zm=z,Tm+1=(t,t)bracketrightbig
=integraldisplay/CAintegraldisplay/CAmPY|T=t(y)fTm+1|X=x,Zm=z((t,t))dtdt. (3.17)
A problem arises with this integral due to the non-Gaussianity of the term
PY|T=t(y)meaning that the integrand fTm+1|X=x,Zm=zis no longer a Gaussian den-
sity and, thus, it becomes analytically intractable. There are several routes we cantake:
1. By assuming that f
Tm+1|X=x,Zm=zis a uni-modal function in (t,t)∈ /CAm+1we
can consider its Laplace approximation . In place of the correct density we use
an(m+1)-dimensional Gaussian measure with mode µ∈ /CAm+1and covariance
/Sigma1∈ /CA(m+1)×(m+1)given by
µ= argmax
(t,t)∈ /CAm+1fTm+1|X=x,Zm=z((t,t)) (3.18)
90 Chapter 3
/Sigma1=−

∂2lnparenleftbig
fTm+1|X=x,Zm=z((t,t))parenrightbig
∂ti∂tjvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle
ti=µi,tj=µj
m+1,m+1
i,j=1
−1
. (3.19)
2. We can use a Markov chain to sample from PTm+1|X=x,Zm=zand use a Monte
Carlo approximation to the integral. So, given Ksamples(t1,t1),...,(tK,tK)we
approximate the predictive distribution by averaging over the samples
PY|X=x,Zm=z(y)≈1
KKsummationdisplay
i=1PY|T=ti(y).
Note that in order to generate samples ti∈ /CAwe also have to sample ti∈ /CAm
although these are not used in the ﬁnal approximation.
Let us pursue the ﬁrst idea and determine the maximizer µ=parenleftbigˆt,ˆtparenrightbig
offTm+1|X=x,Zm=z.
In Appendix B.7 we show that the maximization can be decomposed into a maxi-mization over the real-valued outputs t∈/CAmof the latent variables corresponding
to the mtraining objects and a maximization of the real-valued output t∈ /CAat the
new test object. We prove that the value ˆt∈ /CAmis formally given by
ˆt=argmax
t∈ /CAmmsummationdisplay
i=1lnparenleftbig
PY|T=ti(yi)parenrightbig
−t/primeG−1t. (3.20)
Having found this vector using an iterative Newton-Raphson update we can then
computeˆtdirectly using ˆt=ˆt/primeG−1Xx. As a consequence, by Theorem A.29, and
the results from Appendix B.7, it follows that
PT|X=x,Zm=z=NormalparenleftBig
ˆt/primeG−1Xx,x/primex−x/primeX/prime(I+PG)−1PXxparenrightBig
=Normalparenleftbigˆt,υ2parenrightbig
,
where Pis a m×mdiagonal matrix with entries β−1·PY|T=ˆti(1)parenleftbig
1−PY|T=ˆti(1)parenrightbig
.
The beneﬁt of this consideration is that the problem of determining the predictivedistribution (3.17) reduces to computing
P
Y|X=x,Zm=z(y)=integraldisplay/CAPY|T=t(y)fT|X=x,Zm=z(t)dt, (3.21)
which is now computationally feasible because fT|X=x,Zm=zis a normal density only
depending on the two parameters ˆtandυ2. In practice, we would approximate
the function PY|T=tby Gaussian densities to be able to evaluate this expression
numerically. However, if all we need is the classiﬁcation, we exploit the fact
91 Kernel Classiﬁers from a Bayesian Perspective
that signparenleftbigˆtparenrightbig
always equals the class y∈{−1,+1}with the larger probability
PY|X=x,Zm=z(y)(see Appendix B.7). In this case it sufﬁces to compute the vector
ˆt∈ /CAmusing equation (3.20) and to classify a new point according to
hGPC(x)=signparenleftBiggmsummationdisplay
i=1ˆαik(xi,x)parenrightBigg
, ˆα=G−1ˆt. (3.22)
In Appendix B.7 we derive a stable algorithm to compute the vector ˆα∈ /CAmof
expansion coefﬁcients6. The pseudocode of the algorithm can be found on page
326.
Remark 3.13 (Support vector classiﬁcation learning) A closer look at equation
(3.16) reveals that this likelihood is equivalent to the inverse loss likelihood for themargin loss given in equation (2.42). This equivalence allows us to directly relatelinear soft margin support vector machines and Gaussian process classiﬁcationwhen using a Laplace approximation:
1.Since we only require the maximizing vector ˆt∈/CAmof latent real-valued
outputs at the training objects x∈ /CGmto be found, we know that we effectively
search for one weight vector ˆw=summationtextm
i=1ˆαixi=X/primeˆα. In particular , using the linear
expansion of the weight vector in the mapped training objects, we see that
ˆt=Xˆw=XX/primeˆα=Gˆα,⇔ ˆα=G−1ˆt.
2.By the same argument we know that the term t/primeG−1tequals α/primeGα=/bardblw/bardbl2
(assuming that w=X/primeαexists in the linear span of the mapped training inputs).
Now, if we consider an inverse loss likelihood PY|T=tfor the loss l : /CA× /CH→ /CA
the maximizer ˆt∈ /CAm, of equation (3.20) must equal the minimizer ˆw∈ /C3of
−msummationdisplay
i=1lnparenleftbig
PY|T=ti(yi)parenrightbig
+/bardblw/bardbl2=msummationdisplay
i=1lsigmoid(/angbracketleftxi,w/angbracketright,yi)+/bardblw/bardbl2, (3.23)
where l sigmoid(t,y)=lnparenleftbig
1+expparenleftbig
2β−1·ytparenrightbigparenrightbig
−2β−1yt . Note that l sigmoid: /CA×/CH→ /CAis another approximation of the zero-one loss l 0−1(see Figure 3.5 (left)
and equation (2.9)). In this sense, Gaussian processes for classiﬁcation are another
6 Basically, a closer look at equation (3.22) and (3.20) shows that, in order to obtain ˆt, we need to invert the
Gram matrix G∈ /CAm×mwhich is then used again to compute ˆα. If the Gram matrix is badly conditioned, i.e.,
the ratio between the largest and smallest eigenvector of Gis signiﬁcantly large, then the error in computing ˆαby
(3.22) can be very large although we may have found a good estimate ˆt∈ /CAm. Therefore, the algorithm presented
avoids the “detour” via ˆtbut directly optimizes w.r.t. α. The more general difﬁculty is that inverting a matrix is
an ill-posed problem (see also Appendix A.4).
92 Chapter 3
−2.0 −1.5 −1.0 −0.5 0.0 0.5 1.001234
−yf(x)loss
Iyf(x)≤0β=1β=0.5
β=2
− 2 − 1 0120.0 0.2 0.4 0.6 0.8 1.0 1.2
tlossPY|T=t(+1) PY|T=t(−1)PY|T=t(−1)+PY|T=t(+1)
Figure 3.5 (Left) Approximation of the zero-one loss function Iyt≤0(solid line) by the
sigmoidal loss given by lsigmoid(t,y)=lnparenleftbig1+expparenleftbig2β−1·ytparenrightbigparenrightbig−2β−1yt(dashed and
dotted lines). Note that these loss functions are no longer upper bounds except whenβ→ 0. In this case, however, the loss becomes inﬁnitely large whenever yf(x)<0.
(Right) Likelihood model induced by the hinge loss l
lin(t,y)=max{1−yt,0}.N o t e
that in contrast to the model given in equation (3.16), this liklihood is not normalizable.
implementation of soft margin support vector machines .
3.Using the identity (3.23) we could also try to ﬁnd an interpretation of support
vector machines as Gaussian process classiﬁcation with a different likelihoodmodel P
Y|T=t. In fact, the likelihood model can easily be derived from (3.23) and
(2.47) and is given by
PY|T=t(y)=exp(−llin(t,y))=exp(−max{1−yt,0}).
In Figure 3.5 (right) we have plotted this likelihood model for varying values
of t∈ /CA. As can be seen from the plots the problem with this loss-function
induced likelihood model is that it cannot be normalized independently of the valuet=/angbracketleftx,w/angbracketright. Hence, it is not directly possible to cast support vector machines into a
probabilistic framework by relating them to a particular likelihood model.
3.3 The Relevance V ector Machine
In the last section we saw that a direct application of Bayesian ideas to the problemof regression estimation yields efﬁcient algorithms known as Gaussian processes.In this section we will carry out the same analysis with a slightly reﬁned prior P
W
on linear functions fwin terms of their weight vectors w∈ /C3⊆/lscriptn
2. As we will
93 Kernel Classiﬁers from a Bayesian Perspective
see in Section 5.2 an important quantity in the study of the generalization error
is the sparsity /bardblw/bardbl0=summationtextn
i=1Iwi/negationslash=0or/bardblα/bardbl0of the weight vector or the vector of
expansion coefﬁcients, respectively. In particular, it is shown that the expected riskof the classiﬁer f
wlearned from a training sample z∈ /CImis, with high probability
over the random draw of z,a ss m a l la s≈/bardblw/bardbl0
nor/bardblα/bardbl0
m,w h e r e nis the dimensionality
of the feature space /C3and w=summationtextm
i=1αixi=X/primeα. These results suggest favoring
weight vectors with a small number of non-zero coefﬁcients. One way to achievethis is to modify the prior in equation (3.8), giving
P
W=Normal(0,/Theta1),
where /Theta1=diag(θ)andθ=(θ1,...,θ n)/prime∈parenleftbig/CA+parenrightbignis assumed known. The idea
behind this prior is similar to the idea of automatic relevance determination givenin Example 3.12. By considering θ
i→ 0 we see that the only possible value for the
ith component of the weight vector wis 0 and, therefore, even when considering
the Bayesian prediction Bayes zthe ith component is set to zero. In order to make
inference we consider the likelihood model given in equation (3.9), that is, weassume that the target values t=(t
1,..., tm)∈ /CAmare normally distributed with
mean/angbracketleftxi,w/angbracketrightand variance σ2
t. Using Theorem A.28 it follows that the posterior
measure over weight vectors wis again Gaussian, i.e.,
PW|Xm=x,Tm=t=Normal(µ,/Sigma1),
where the posterior covariance /Sigma1∈ /CAn×nand mean µ∈ /CAnare given by
/Sigma1=parenleftbig
σ−2
tX/primeX+/Theta1−1parenrightbig−1,µ=σ−2
t/Sigma1X/primet=parenleftbig
X/primeX+σ2
t/Theta1−1parenrightbig−1X/primet.(3.24)
As described in the last section, the Bayesian prediction at a new test object x∈ /CG
is given by Bayes z(x)=/angbracketleftx,µ/angbracketright. Since we assumed that many of the θiare
zero, i.e., the effective number neff=/bardblθ/bardbl0of features φi: /CG→ /CAis small, it
follows that /Sigma1andµare easy to calculate7. The interesting question is: Given a
training sample z=(x,t)∈(
/CG× /CA)m, how can we “learn” the sparse vector
θ=(θ1,...,θ n)/prime?
In the current formulation, the vector θis a model parameter and thus we shall
employ evidence maximization to ﬁnd the value ˆθthat is best supported by the
given training data z=(x,t). One of the greatest advantages is that we know the
7 In practice, we delete all features φi: /CG→ /CAcorresponding to small θ–values and ﬁx the associated µ–values
to zero.
94 Chapter 3
evidence fTm|Xm=x(t)explicitly (see Theorem A.28),
fTm|Xm=x(t)=EWbracketleftbig
fTm|Xm=x,W=w(t)bracketrightbig
=(2π)−m
2vextendsinglevextendsingleσ2
tI+X/Theta1X/primevextendsinglevextendsingle−1
2expparenleftBigg
−t/primeparenleftbig
σ2
tI+X/Theta1X/primeparenrightbig−1t
2parenrightBigg
.(3.25)
In Appendix B.8 we derive explicit update rules for θandσ2
twhich, in case of
convergence, are guaranteed to ﬁnd a local maximum of the evidence (3.25). Theupdate rules are given by
θ
(new)
i=µ2
i
ζi,parenleftbig
σ2
tparenrightbig(new)=/bardblt−Xµ/bardbl2
m−summationtextn
i=1ζi,ζ i=1−θ−1
i/Sigma1ii.
Interestingly, during application of these update rules, it turns out that many of the
θidecrease quickly toward zero which leads to a high sparsity in the mean weight
vector µ. Note that, whenever θifalls below a pre-speciﬁed threshold, we delete the
ith column from Xas well as θiitself which reduces the number of features used
by one. This leads to a faster convergence of the algorithm as it progresses becausethe necessary inversion of the matrix σ
−2
tX/primeX+/Theta1−1in (3.24) is computationally
less demanding. After termination, all components ˆwiof the learned weight vector
ˆw∈ /CAn,f o rw h i c h θiis below the threshold, are set to exactly 0; the remaining
coefﬁcientsˆwiare set equal to corresponding values in µ=σ−2
t/Sigma1X/primet.
In order to apply this algorithm (which has so far been developed for the case of
regression estimation only) to our initial problem of classiﬁcation learning (recall,are given a sample z=(x,y)∈(/CG×{−1,+1})mof object-class pairs), we use
the idea outlined in the previous subsection. In particular, when computing thepredictive distribution P
Y|X=x,Zm=zof the class y∈{−1,+1}at a new test object
x∈ /CG, we consider m+1 latent variables T1,..., Tm,Tm+1at all the mtraining
objects x∈ /CGmand at the test object x∈ /CG, computed by applying a latent weight
vector Wto all the m+1 mapped objects (x,x)∈ /CGm+1. By marginalizing over
all the possible values w∈ /CAnofWwe obtain
PY|X=x,Zm=z(y)= EW|X=x,Zm=zbracketleftbig
PY|X=x,Zm=z,W=w(y)bracketrightbig
=integraldisplay/CAnPY|X=x,W=w(y)·fW|Zm=z(w)dw.
Note that PY|X=x,W=w(y)=PY|T=/angbracketleftx,w/angbracketright(y)where PY|T=tis given by equation
(3.16). Similarly to the Gaussian process case, the problem with this integral is thatit cannot be performed analytically because the integrand f
W|Zm=z(w)is no longer
95 Kernel Classiﬁers from a Bayesian Perspective
Gaussian. We shall therefore exploit the idea of using a Laplace approximation to
it, i.e., approximating this density by a Gaussian density with the mean µ∈ /CAn
and the covariance /Sigma1∈ /CAn×ngiven by
µ= argmax
w∈ /CAnfW|Zm=z(w), (3.26)
/Sigma1=

−∂2lnparenleftbig
fW|Zm=z(w)parenrightbig
∂w i∂w jvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle
wi=µi,w j=µj
n,n
i,j=1
−1
. (3.27)
As we essentially aim to ﬁnding ˆθ∈parenleftbig/CA+parenrightbignit turns out that the Laplacian
approximation is a perfect choice because it allows us to estimate ˆθby iterating
the following scheme:
1. For a ﬁxed valued θ∈parenleftbig/CA+parenrightbignwe compute the Laplacian approximation to
fW|Zm=zyielding µand a covariance matrix /Sigma1.
2. Using the current values of µand/Sigma1we make one update step on θ. Note that
in the classiﬁcation case we omit a variance σ2
t∈ /CA+on the latent variables Ti.
It is worth mentioning that we formulate the Laplacian approximation in terms of
the weight vectors wrather than the real-valued outputs t∈ /CAm. This is because,
for classiﬁcation, whenever /bardblθ/bardbl0<m(we identify fewer features than training
examples), the covariance matrix of tcannot have full rank, which would cause
numerical instabilities in the resulting algorithm. The two algorithms for regressionestimation and classiﬁcation are given on pages 327 and 328, respectively.
In order to understand why this algorithm is called a relevance vector machine
we note that it is also possible to use a kernel function k:/CG× /CG→ /CAevaluated
at the training objects x∈ /CGmasmfeaturesφi=k(xi,·). In this case the weight
vector wbecomes the vector α∈ /CAmof expansion coefﬁcients and the data matrix
X∈ /CAm×nis given by the Gram matrix G∈ /CAm×m. The algorithm aims to ﬁnd the
smallest subset of training objects such that the target values t∈ /CAm(regression
estimation) or the classes y∈{−1,+1}m(classiﬁcation) can be well explained by
f(·)=msummationdisplay
i=1αik(xi,·), h(·)=signparenleftBiggmsummationdisplay
i=1αik(xi,·)parenrightBigg
. (3.28)
All the training objects xi∈xwhich have a non-zero coefﬁcient αiare termed
relevance vectors because they appear the most relevant for the correct prediction
96 Chapter 3
−2 −1 0 1 2−10 −8 −6 −4
wlog(fWi(w))a=1e−2, b=1e2
a=1e−3, b=1e3
a=1e−4, b=1e4
second component of w−2
−1
0
1
2first component of w−2
−1
0
1
2marginalised prior density
−24−22−20−18
Figure 3.6 (Left) Marginalized log-prior densities fWiover single weight vector compo-
nents wiimplicitly considered in relevance vecto r machines. Relevance vector machines
are recovered for the case of a→ 0a n d b→∞ in which the prior is indeﬁnitely peaked
atw=0.(Right) Surface plot for the special case of n=2a n d b=a−1=1 000. Note
that this prior favors one zero weight vector component w1=0 much more that two very
small values|w1|and|w2|and is sometimes called a sparsity prior.
of the whole training sample.8The appealing feature when using models of the
form (3.28) is that we still learn a linear classiﬁer (function) in some feature space/C3. Not only does it allow us to apply all the theoretical results we shall obtain in
Part II of this book but the geometrical picture given in Section 2.1 is also still valid
for this algorithm.
Remark 3.14 (Sparsity in relevance vector machines) In a fully Bayesian treat-
ment, rather than using just one value ˆθof the parameters θwe should deﬁne a
prior PQover all possible values of θ∈ /CAnand then marginalize, i.e.,
fT|X=x,Xm=x,Tm=t(t)=EQbracketleftbig
EW|Q=θbracketleftbig
fTm+1|X=x,Xm=x,W=w((t,t))bracketrightbigbracketrightbig
EQbracketleftbig
EW|Q=θbracketleftbig
fTm|Xm=x,W=w(t)bracketrightbigbracketrightbig
=EQbracketleftbig
fTm+1|X=x,Xm=x,Q=θ((t,t))bracketrightbig
EQbracketleftbig
fTm|Xm=x,Q=θ(t)bracketrightbig.
8 Another reason for terming them relevance vectors is that the idea underlying the algorithm is motivated by
automatic relevance determination, introduced in Example 3.12 (personal communication with M. Tipping).
97 Kernel Classiﬁers from a Bayesian Perspective
The problem with the latter expression is that we cannot analytically compute the
ﬁnal integral. Although we get a closed form expression for the density fTm|Xm=x,Q=θ
(a Gaussian measure derived in equation (3.25)) we cannot perform the expecta-
tion analytically regardless of the prior distribution chosen. When using a productof Gamma distributions for P
Q, i.e., fQ(θ)=producttextn
i=1Gamma(a,b)parenleftbig
θ−1
iparenrightbig
,i tc a n
be shown, however , that, in the limit of a → 0and b→∞ , the mode of the
joint distribution fQTm|Xm=x(θ,t)equals the vector ˆθand ˆt=Xµ(see equation
(3.24)) as computed by the relevance vector machine algorithm. Hence, the rel-evance vector machine—which performs evidence maximization over the hyper-parameters θ∈/CAn—can also be viewed as a maximum-a-posteriori estimator
ofPWQ|Xm=x,Tm=tbecause t=Xw . As such it is interesting to investigate the
marginalized prior PW=EQbracketleftbig
PW|Q=θbracketrightbig
. In Figure 3.6 we have depicted the form of
this marginalized prior for a single component (left) and for the special case of atwo-dimensional feature space (right). It can be seen from these plots that, by the
implicit choice of this prior , the relevance vector machine looks for a mode ˆθin
a posterior density which has almost all a-priori probability mass on sparse solu-tions. This somewhat explains why the relevance vector machine algorithm tendsto ﬁnd very sparse solutions.
3.4 Bayes Point Machines
The algorithms introduced in the last two sections solve the classiﬁcation learningproblem by taking a “detour” via the regression estimation problem. For eachtraining object it is assumed that we have prior knowledge P
Wabout the latent
variables Ticorresponding to the logit transformation of the probability of xi
being from the observed class yi. This is a quite cumbersome assumption as we
are unable to directly express prior knowledge on observed quantities such as the
classes y∈ /CHm={−1,+1}m. In this section we are going to consider an algorithm
which results from a direct modeling of the classes.
Let us start by deﬁning the prior PW. In the classiﬁcation case we note that, for
anyλ> 0, the weight vectors wandλwperform the same classiﬁcation because
sign(/angbracketleftx,w/angbracketright)=sign(/angbracketleftx,λw/angbracketright). As a consequence we consider only weight vectors
of unit length, i.e. ,w∈ /CF, /CF={w∈ /C3|/bardblw/bardbl=1}(see also Section 2.1).
In the absence of any prior knowledge we assume a uniform prior measure PW
over the unit hypersphere /CF. An argument in favor of the uniform prior is that the
belief in the weight vector wshould be equal to the belief in the weight vector −w
98 Chapter 3
under the assumption of equal class probabilities PY(−1)and PY(+1). Since the
classiﬁcation y−w=(sign(/angbracketleftx1,−w/angbracketright),..., sign(/angbracketleftxm,−w/angbracketright))of the weight vector
−wat the training sample z∈ /CImequals the negated classiﬁcation −yw=
−(sign(/angbracketleftx1,w/angbracketright),..., sign(/angbracketleftxm,w/angbracketright))ofwit follows that the assumption of equal
belief in wand−wcorresponds to assuming that PY(−1)=PY(+1)=1
2.
In order to derive an appropriate likelihood model, let us assume that there is no
noise on the classiﬁcations, that is, we shall use the PAC-likelihood lPAC as given
in Deﬁnition 3.3. Note that such a likelihood model corresponds to using the zero-one loss l
0−1in the machine learning scenario (see equations (2.10) and (3.2)).
According to Bayes’ theorem it follows that the posterior belief in weight vectors
(and therefore in classiﬁers) is given by
fW|Zm=z(w)=PYm|Xm=x,W=w(y)fW(w)
PYm|Xm=x(y)
=braceleftbigg1
PW(V(z))ifw∈V(z)
0 otherwise. (3.29)
The set V(z)⊆ /CFis called version space and is the set of all weight vectors that
parameterize classiﬁers which classify all the training objects correctly (see alsoDeﬁnition 2.12). Due to the PAC-likelihood, any weight vector wwhich does not
have this property is “cut-off” resulting in a uniform posterior measure P
W|Zm=z
over version space. Given a new test object x∈ /CGwe can compute the predictive
distribution PY|X=x,Zm=zof the class yatx∈ /CGby
PY|X=x,Zm=z(y)=PW|Zm=z(sign(/angbracketleftx,W/angbracketright)=y).
The Bayes classiﬁcation strategy based on PY|X=x,Zm=zdecides on the class with
the larger probability. An appealing feature of the two class case /CH={−1,+1}is
that this decision can also be written as
Bayes z(x)=signparenleftbig
EW|Zm=zbracketleftbig
sign(/angbracketleftx,W/angbracketright)bracketrightbigparenrightbig
, (3.30)
that is, the Bayes classiﬁcation strategy effectively performs majority voting in-
volving all version space classiﬁers. The difﬁculty with the latter expression is thatwe cannot analytically compute the expectation as this requires efﬁcient integra-tion of a convex body on a hypersphere (see also Figure 2.1 and 2.8). Hence, weapproximate the Bayes classiﬁcation strategy by a single classiﬁer.
99 Kernel Classiﬁers from a Bayesian Perspective
Deﬁnition 3.15 (Bayes point) Given a training sample zand a posterior measure
PW|Zm=zover the unit hypersphere /CF,t h e Bayes point wbp∈ /CFis deﬁned
wbp=argmin
w∈ /CFEXbracketleftbig
l0−1(Bayes z(X),sign(/angbracketleftφ(X),w/angbracketright))bracketrightbig
,
that is, the Bayes point is the optimal projection of the Bayes classiﬁcation strategy
to a single classiﬁer wbpw.r .t. generalization error .
Although the Bayes point is easily deﬁned its computation is much more difﬁcult
because it requires complete knowledge of the input distribution PX. Moreover,
it requires a minimisation process w.r.t. the Bayes classiﬁcation strategy which
involves the posterior measure PW|Zm=z—a computationally difﬁcult task. A closer
look at equation (3.30), however, shows that a another reasonable approximationto the Bayes classiﬁcation strategy is given by exchanging sign (·)and expectation,
i.e.,
h
cm(x)=signparenleftbig
signparenleftbig
EW|Zm=zbracketleftbig/angbracketleftx,W/angbracketrightbracketrightbigparenrightbigparenrightbig
=sign
angbracketleftBigg
x,EW|Zm=zbracketleftbig
Wbracketrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
wcmangbracketrightBigg
.
The idea behind this “trick” is that, if the version space V(z)is almost point-
symmetric w.r.t. wcmthen, for each weight vector w∈V(z)in version space,
there exists another weight vector ˜w=2wcm−w∈V(z)also in version space
and, thus,
sign(/angbracketleftx,w/angbracketright)+signparenleftbigangbracketleftbig
x,˜wangbracketrightbigparenrightbig
=braceleftbigg2·sign(/angbracketleftx,wcm/angbracketright) if|/angbracketleftx,w/angbracketright|<|/angbracketleftx,wcm/angbracketright|
0 otherwise,
that is, the Bayes classiﬁcation of a new test object equals the classiﬁcation carried
out be the single weight vector wcm. The advantage of the classiﬁer wcm—which
is also the center of mass of version space V(z)—is that it can be computed or es-
timated without any extra knowledge about the data distribution. Since the centerof mass is another approximation to the Bayes classiﬁcation we call every algo-rithm that computes w
cmaBayes point algorithm , although the formal deﬁnition
of the Bayes point approximation is slightly different. In the following subsectionwe present one possible algorithm for estimating the center of mass.
100 Chapter 3
3.4.1 Estimating the Bayes Point
The main idea in computing the center of mass of version space is to replace the
analytical integral by a sum over randomly drawn classiﬁers, i.e.,
wcm=EW|Zm=zbracketleftbig
Wbracketrightbig
≈1
KKsummationdisplay
i=1wi wi∼PW|Zm=z.
Such methods are known as Monte-Carlo methods and have proven to be suc-
cessful in practice. A difﬁculty we encounter with this approach is in obtainingsamples w
idrawn according to the distribution PW|Zm=z. Recalling that PW|Zm=zis
uniform in a convex polyhedra on the surface of hypersphere in feature space wesee that it is quite difﬁcult to directly sample from it. A commonly used approachto this problem is to approximate the sampling distribution P
W|Zm=zby a Markov
chain. A Markov chain is fully speciﬁed by a probability distribution PW1W2where
fW1W2((w1,w2))is the “transition” probability for progressing from a randomly
drawn weight vector w1to another weight vector w2. Sampling from the Markov
chain involves iteratively drawing a new weight vector wi+1by sampling from
PW2|W1=wi. The Markov chain is called ergodic w.r .t. PW|Zm=zif the limiting distri-
bution of this sampling process is PW|Zm=zregardless of our choice of w0. Then, it
sufﬁces to start with a random weight vector w0∈ /CFand at each step, to obtain
a new sample wi∈ /CFdrawn according to PW2|W1=wi−1. The combination of these
two techniques has become known as the Markov-Chain-Monte-Carlo (MCMC)method for estimating the expectation E
W|Zm=zbracketleftbig
Wbracketrightbig
.
We now outline an MCMC algorithm for approximating the Bayes point by the
center of mass of version space V(z)(the whole pseudo code is given on page
330). Since it is difﬁcult to generate weight vectors that parameterize classiﬁersconsistent with the whole training sample z∈/CImwe average over the trajectory
of a ball which is placed inside version space and bounced like a billiard ball. As
a consequence we call this MCMC method the kernel billiard. We express each
position b∈ /CF of the ball and each estimate wi∈ /CF of the center of mass of
V(z)as a linear combination of the mapped training objects, i.e.,
w=msummationdisplay
i=1αixi, b=msummationdisplay
i=1γixi,α∈ /CAm,γ∈ /CAm.
101 Kernel Classiﬁers from a Bayesian Perspective
/BA/CQ/BF
/CU
/DB
/CY
/DD/BE
/CW
/DC/BE
/BN
/DB
/CX
/BP
/BC
/CV/CQ/BD/CU/DB/CY/DD/BD
/CW/DC/BD
/BN/DB/CX/BP/BC/CV
/CQ/BG/CU
/DB
/CY
/DD
/BF
/CW
/DC
/BF
/BN
/DB
/CX
/BP
/BC
/CV/CQ/BE
/CQ/BC
/CM/DB/CR/D1/CU
/DB
/CY
/DD
/BG
/CW
/DC
/BG
/BN
/DB
/CX
/BP
/BC
/CV
/CQ/BH
Figure 3.7 (Left) 5 samples b1,..., b5(white dots) obtained by playing billiards on
the sphere in the special case of /CF⊆ /CA3. In the update step, only the chord length (gray
lines) are taken into consideration. (Right) Schematic view of the kernel billiard algorithm.
Starting at w0∈V(z)a trajectory of billiard bounces b1,..., b5,... is computed and then
averaged over so as to obtain an estimate ˆwcmof the center of mass of version space.
Without loss of generality we can make the following assumption about the needed
direction vector v
v=msummationdisplay
i=1βixi,β∈ /CAm.
To begin we assume that w0=0⇔α=0. Before generating a billiard trajectory
in version space V(z)we ﬁrst run learning algorithm to ﬁnd an initial starting
point b0inside version space (e.g., kernel perceptron or support vector learning
(see Algorithm 2 and Section D.2)). The kernel billiard algorithm then consists of
three steps (see also Figure 3.7):
1. Determine the closest boundary starting from the position biin direction vi.
Since it is computationally very demanding to calculate the ﬂight time of thebilliard ball ongeodesics of the hypersphere/CF we make use of the fact that the
shortest distance in Euclidean space (if it exists) is also the shortest distance on thehypersphere/CF. Thus, for the ﬂight time τjof the billiard ball from position biin
direction vito the hyperplane with normal vector yjxjwe have
τj=−angbracketleftbig
bi,xjangbracketrightbig
angbracketleftbig
vi,xjangbracketrightbig. (3.31)
102 Chapter 3
After computing all mﬂight times, we look for the smallest positive one,
c=argmin
j:τj>0τj.
Computing the closest bounding hyperplane in Euclidean space rather than on
geodesics causes problems if the direction vector viis almost orthogonal to the
curvature of the hypersphere /CF, in which case τc→∞ . If this happens we
randomly generate a direction vector vipointing toward version space V(z).
Assuming that the last bounce took place at the hyperplane having normal yc/primexc/prime
this condition can easily be checked by yc/prime/angbracketleftvi,xc/prime/angbracketright>0.
2. Update the billiard ball’s position to bi+1and the new direction vector to vi+1.
The new point bi+1and the new direction vi+1are calculated from
bi+1= bi+τcvi, (3.32)
vi+1= vi−2/angbracketleftvi,xc/angbracketright
/bardblxc/bardbl2xc. (3.33)
Afterwards, the position bi+1must be normalized.
3. Update the center of mass wiof the whole trajectory by the new line segment
from bitobi+1calculated on the hypersphere /CF.
Since the solution w∞lies on the hypersphere /CF we cannot simply update the
center of mass using weighted vector addition. Instead we use the operation ⊕µ:/CF× /CF→ /CFacting on vectors of unit length and having the property that
vextenddoublevextenddoublem−parenleftbig
wi⊕µmparenrightbigvextenddoublevextenddouble=µ·/bardblm−wi/bardbl,
that is,µis the fraction between the resulting chord lengthvextenddoublevextenddoublem−parenleftbig
wi⊕µmparenrightbigvextenddoublevextenddoubleand
the total chord length /bardblm−wi/bardbl. It can be shown that
wi⊕µm=ρ1(/angbracketleftwi,m/angbracketright,µ)wi+ρ2(/angbracketleftwi,m/angbracketright,µ)m
where the explicit formulas for ρ1andρ2can be found in Appendix B.9. Since the
posterior density is uniform in version space, the whole line between biand bi+1
can be represented by the midpoint m∈V(z),g i v e nb y
m=bi+bi+1
/bardblbi+bi+1/bardbl.
Thus, we can update the center of mass of the trajectory by
wi+1=ρ1parenleftbigg
/angbracketleftwi,m/angbracketright,/Xi1i
/Xi1i+ξiparenrightbigg
wi+ρ2parenleftbigg
/angbracketleftwi,m/angbracketright,/Xi1i
/Xi1i+ξiparenrightbigg
m,
103 Kernel Classiﬁers from a Bayesian Perspective
whereξi=/bardblbi−bi+1/bardblis the length of the trajectory in the ith step and /Xi1i=summationtexti
j=1ξjis the accumulated length up to the ith step. Note that the operation ⊕µ
is only an approximation to the addition operation we sought because an exact
weighting would require arc lengths rather than chord lengths.
As a stopping criterion we compute an upper bound on ρ2, the weighting factor of
the new part of the trajectory. If this value falls below a prespeciﬁed threshold we
stop the algorithm. Note that an increase in /Xi1iwill always lead to termination.
3.5 Fisher Discriminants
In this last section we are going to consider one of the earliest approaches to the
problem of classiﬁcation learning. The idea underlying this approach is slightlydifferent from the ideas outlined so far. Rather than using the decompositionP
XY=PY|XPXwe now decompose the unknown probability measure PXY=PZ
constituting the learning problem as PXY=PX|YPY. The essential difference
between these two formal expressions becomes apparent when considering the
model choices:
1. In the case of PXY=PY|XPXwe use hypotheses h∈ /C0⊆ /CH
/CGto model the
conditional measure PY|Xof classes y∈ /CHgiven objects x∈ /CGand marginal-
ize over PX. In the noise-free case, each hypothesis deﬁnes such a model by
PY|X=x,H=h(y)=Ih(x)=y. Since our model for learning contains only predictors
h: /CG→ /CHthat discriminate between objects, this approach is sometimes called
the predictive ordiscriminative approach.
2. In the case of PXY=PX|YPYwe model the generation of objects x∈ /CGgiven
the class y∈ /CH={−1,+1}by some assumed probability model PX|Y=y,Q=θ
where θ=(θ+1,θ−1,p)∈ /C9parameterizes this generation process. We have
the additional parameter p∈[0,1]to describe the probability PY|Q=θ(y)by
p·Iy=+ 1+(1−p)·Iy=− 1. As the model /C9contains probability measures from
which the generated training sample x∈ /CGissampled , this approach is sometimes
called the generative orsampling approach.
In order to classify a new test object x∈ /CGwith a model θ∈ /C9in the generative
approach we make use of Bayes’ theorem, i.e.,
PY|X=x,Q=θ(y)=PX|Y=y,Q=θ(x)PY|Q=θ(y)
summationtext
˜y∈ /CHPX|Y=˜y,Q=θ(x)PY|Q=θ(˜y).
104 Chapter 3
In the case of two classes /CH={−1,+1}and the zero-one loss, as given in equation
(2.10), we obtain for the Bayes optimal classiﬁcation at a novel test object x∈ /CG,
hθ(x)= argmax
y∈{−1,+1}PY|X=x(y)
= signparenleftbigg
lnparenleftbiggPX|Y=+ 1,Q=θ(x)·p
PX|Y=− 1,Q=θ(x)·(1−p)parenrightbiggparenrightbigg
, (3.34)
as the fraction in this expression is greater than one if, and only, if PXY|Q=θ((x,+1))
is greater than PXY|Q=θ((x,−1)). In the generative approach the task of learning
amounts to ﬁnding the parameters θ∗∈ /C9or measures PX|Y=y,Q=θ∗and PY|Q=θ∗
which incur the smallest expected risk R[hθ∗]by virtue of equation (3.34). Again,
we are faced with the problem that, without restrictions on the measure PX|Y=y,
the best model is the empirical measure vxy(x),w h e r e xy⊆xis the sample of
all training objects of class y. Obviously, this is a bad model because vxy(x)as-
signs zero probability to all test objects not present in the training sample and thush
θ(x)=0, i.e., we are unable to make predictions on unseen objects. Similarly to
the choice of the hypothesis space in the discriminative model we must constrainthe possible generative models P
X|Y=y.
Let us consider the class of probability measures from the exponential family
fX|Y=y,Q=θ(x)=a0parenleftbig
θyparenrightbig
τ0(x)expparenleftbig
θ/prime
y(τ(x))parenrightbig
,
for some ﬁxed function a0: /C9y→ /CA,τ0: /CG→ /CAandτ: /CG→ /C3. Using this
functional form of the density we see that each decision function hθmust be of the
following form
hθ(x)= signparenleftBigg
lnparenleftBigg
a0(θ+1)τ0(x)expparenleftbig
θ/prime
+1(τ(x))parenrightbig
·p
a0(θ−1)τ0(x)expparenleftbig
θ/prime
−1(τ(x))parenrightbig
(1−p)parenrightBiggparenrightBigg
= sign
(θ+1−θ−1)bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
w(τ(x))+lnparenleftbigga0(θ+1)·p
a0(θ−1)(1−p)parenrightbigg
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
b
(3.35)
= sign(/angbracketleftw,τ(x)/angbracketright+b).
This result is very interesting as it shows that, for a rather large class of generative
models, the ﬁnal classiﬁcation function is a linear function in the model parametersθ=(θ
−1,θ+1,p). Now, consider the special case that the distribution PX|Y=y,Q=θ
of objects x∈ /CGgiven classes y∈{−1,+1}is a multidimensional Gaussian in
105 Kernel Classiﬁers from a Bayesian Perspective/CM/A6/CM/A6/CM /AM/B7/BD/CM /AM/A0 /BD/D2/DC /BE /CA
/BE/CY /CU/CG /CY /CH /BP/B7/BD /BN /C9 /BP/B4 /CM /AM/B7/BD
/BN
/CM/A6 /B5
/B4 /DC /B5/BP /CU/CG /CY /CH /BP /A0 /BD /BN /C9 /BP/B4 /CM /AM/A0 /BD
/BN
/CM/A6 /B5
/B4 /DC /B5
/D3
/DC/CX/AR/BE/A0/BD/B4/DB/B5
/AR/BE/B7/BD/B4/DB/B5/AM/A0/BD/B4/DB/B5
/D8/CX/BP/CW/DB/BN/DC/CX/CX
/AM/B7/BD/B4/DB/B5
/CU /DC /BE /CA
/BE/CY/CW /DB /BN /DC /CX /BP/BC /CV/DB
generative approach projective approach
Figure 3.8 (Left) The Fisher discriminant estimated from 80 data points in /CA2. The black
line represents the decision boundary. This must always be a linear function because both
models use the same (estimated) covariance matrix ˆ/Sigma1(ellipses). (Right) A geometrical
interpretation of the Fisher discriminant obj ective function (3.38). Given a weight vector
w∈ /C3, each mapped training object xis projected onto wby virtue of t=/angbracketleftx,w/angbracketright.T h e
objective function measures the ratio of the inter-class distance (µ+1(w)−µ−1(w))2and
the intra-class distance σ2
+1(w)+σ2
−1(w).
some feature space /C3⊆/lscriptn
2mapped into by some given feature map φ: /CG→ /C3,
fX|Y=y,Q=θ(x)=(2π)−n
2|/Sigma1|−1
2expparenleftbigg
−1
2parenleftbig
x−µµparenrightbig/prime/Sigma1−1parenleftbig
x−µyparenrightbigparenrightbigg
, (3.36)
where the parameters θyare the mean vector µy∈ /CAnand the covariance matrix
/Sigma1y∈ /CAn×n, respectively. Making the additional assumptions that the covariance
matrix /Sigma1is the same for both models θ+1andθ−1and p=PY|Q=θ(+1)=
PY|Q=θ(−1)=1
2we see that, according to equations (A.16)–(A.17) and (3.35),
τ(x)=x,w=/Sigma1−1parenleftbig
µ+1−µ−1parenrightbig
,b=1
2parenleftbig
µ/prime
−1/Sigma1−1µ−1−µ/prime
+1/Sigma1−1µ+1parenrightbig
.(3.37)
This results also follows from substituting (3.36) directly into equation (3.34) (see
Figure 3.8 (left)).
106 Chapter 3
An appealing feature of this classiﬁer is that it has a clear geometrical interpre-
tation which was proposed for the ﬁrst time by R. A. Fisher. Instead of workingwith n–dimensional vectors xwe consider only their projection onto a hyperplane
with normal w∈/C3.L e tµy(w)=EX|Y=ybracketleftbig
w/primeφ(X)bracketrightbig
be the expectation of the
projections of mapped objects xfrom class yonto the linear discriminant having
normal wandσ2
y(w)=EX|Y=ybracketleftBigparenleftbig
w/primeφ(X)−µy(w)parenrightbig2bracketrightBig
the variance of these pro-
jections. Then choose as the direction w∈ /C3of the linear discriminant a direction
along which the maximum of the relative distance between the µy(w)is obtained,
that is, the direction wFDalong which the maximum of
J(w)=(µ+1(w)−µ−1(w))2
σ2
+1(w)+σ2
−1(w)(3.38)
is attained. Intuitively, the numerator measures the inter-class distance of points
from the two classes {−1,+1}whereas the denominator measures the intra-class
distance of points in each of the two classes (see also Figure 3.8 (right)). Thus,the function Jis maximized if the inter-class distance is large and the intra-class
distance is small. In general, the Fisher linear discriminant w
FDsuffers from the
problem that its determination is a very difﬁcult mathematical and algorithmicalproblem. However, in the particular case of
9PX|Y=y,Q=θ=Normalparenleftbig
µy,/Sigma1parenrightbig
,a
closed form solution to this problem is obtained by noticing that T=w/primeφ(X)
is also normally distributed with PT|Y=y,Q=θ=Normalparenleftbig
w/primeµy,w/prime/Sigma1wparenrightbig
. Thus, the
objective function given in equation (3.38) can be written as
J(w)=parenleftbig
w/primeparenleftbig
µ+1−µ−1parenrightbigparenrightbig2
w/prime/Sigma1w+w/prime/Sigma1w=1
2·w/primeparenleftbig
µ+1−µ−1parenrightbigparenleftbig
µ+1−µ−1parenrightbig/primew
w/prime/Sigma1w,
which is known as the generalized Rayleigh quotient having the maximizer wFD
wFD=/Sigma1−1parenleftbig
µ+1−µ−1parenrightbig
.
This expression equals the weight vector wfound by considering the optimal
classiﬁcation under the assumption of a multidimensional Gaussian measure forthe class conditional distributions P
X|Y=y.
Unfortunately, as with the discriminative approach, we do not know the param-
etersθ=parenleftbig
µ+1,µ−1,/Sigma1parenrightbig
∈ /C9but have to “learn” them from the given training
sample z=(x,y)∈ /CIm. We shall employ the Bayesian idea of expressing our
prior belief in certain parameters via some prior measure PQ. After having seen the
9 Note that µy(w)∈ /CAis a real number whereas µy∈ /C3is an n–dimensional vector in feature space.
107 Kernel Classiﬁers from a Bayesian Perspective
training sample zwe update our prior belief PQ, giving a posterior belief PQ|Zm=z.
Since we need one particular parameter value we compute the MAP estimate ˆθ,
that is, we choose the value of θwhich attains the maximum a-posteriori belief
PQ|Zm=z(see also Deﬁnition 3.6). If we choose a (improper) uniform prior PQthen
the parameter ˆθequals the parameter vector which maximizes the likelihood and
is therefore also known as the maximum likelihood estimator . In Appendix B.10 it
is shown that these estimates are given by
ˆµy=1
mysummationdisplay
(xi,y)∈zxi, ˆ/Sigma1=1
msummationdisplay
y∈{−1,+1}summationdisplay
(xi,y)∈zparenleftbig
xi−ˆµyparenrightbigparenleftbig
xi−ˆµyparenrightbig/prime(3.39)
=1
mparenleftBigg
X/primeX−summationdisplay
y∈{−1,+1}myˆµyˆµ/prime
yparenrightBigg
,
where X∈ /CAm×nis the data matrix obtained by applying φ: /CG→ /C3to each
training object x∈xand myequals the number of training examples of class y.
Substituting the estimates into the equations (3.37) results in the so-called Fisher
linear discriminant wFD.The pseudocode of this algorithm is given at page 329.
In an attempt to “kernelize” this algorithm we note that a crucial requirement
is that ˆ/Sigma1∈ /CAn×nhas full rank which is impossible if dim (
/C3)=n/greatermuchm. Since the
idea of using kernels only reduces computational complexity in these cases we seethat it is impossible to apply the kernel trick directly to this algorithm. Therefore,
let us proceed along the following route: Given the data matrix X∈/CAm×nwe
project the mdata vectors xi∈ /CAninto the m–dimensional space spanned by the
mapped training objects using x/mapsto→ Xx and then estimate the mean vector and the
covariance matrix in /CAmusing equation (3.39). The problem with this approach is
that ˆ/Sigma1is at most of rank m−2 because it is an outer product matrix of two centered
vectors. In order to remedy this situation we apply the technique of regularization tothe resulting m×mcovariance matrix, i.e., we penalize the diagonal of this matrix
by adding λIto it where large values of λcorrespond to increased penalization. As
a consequence, the projected m–dimensional mean vector k
y∈ /CAmand covariance
matrix S∈ /CAm×mare given by
ky=1
mysummationdisplay
(xi,y)∈zXx i=1
myGparenleftbig
Iy1=y,..., Iym=yparenrightbig/prime,
S=1
mparenleftBigg
XX/primeXX/prime−summationdisplay
y∈{−1,+1}mykyk/prime
yparenrightBigg
+λI
108 Chapter 3
=1
mparenleftBigg
GG−summationdisplay
y∈{−1,+1}mykyk/prime
yparenrightBigg
+λI,
where the m×mmatrix Gwith Gij=angbracketleftbig
xi,xjangbracketrightbig
=kparenleftbig
xi,xjparenrightbig
is the Gram matrix.
Using kyand Sin place of µyand/Sigma1in the equations (3.37) results in the so-
called kernel Fisher discriminant. Note that the m–dimensional vector computed
corresponds to the linear expansion coefﬁcients ˆα∈ /CAmof a weight vector wKFD in
feature space because the classiﬁcation of a novel test object x∈ /CGby the kernel
Fisher discriminant is carried out on the projected data point Xx,i . e
h(x)= signparenleftBigangbracketleftbig
ˆα,Xxangbracketrightbig
+ˆbparenrightBig
=signparenleftBiggmsummationdisplay
i=1ˆαik(xi,x)+ˆbparenrightBigg
,
ˆα= S−1(k+1−k−1),ˆb=1
2parenleftbig
k/prime
−1S−1k−1−k/prime
+1S−1k+1parenrightbig
. (3.40)
It is worth mentioning that we would have obtained the same solution by exploiting
the fact that the objective function (3.38) depends only on inner products betweenmapped training objects x
iand the unknown weight vector w. By virtue of Theorem
2.29 the solution wFDcan be written as wFD=summationtextm
i=1ˆαixiwhich, inserted into
(3.38), yields a function in αwhose maximizer is given by equation (3.40). The
pseudocode of this algorithm is given on page 329.
Remark 3.16 (Least squares regression and Fisher discriminant) An additional
insight into the Fisher discriminant can be obtained by exploiting its relationshipwith standard least squares regression . In least squares regression we aim to ﬁnd
the weight vector w∈/C3which minimizes /bardblXw−t/bardbl2=(Xw−t)/prime(Xw−t),
where t∈ /CAmis a given vector of m real values. Maximizing this expression
w.r.t. wgives
∂/bardblXw−t/bardbl2
∂wvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle
w=ˆw=2X/primeXˆw−2X/primet=0,⇔ˆw=parenleftbig
X/primeXparenrightbig−1X/primet.
In order to reveal the relation between this algorithm and the Fisher linear
discriminant we assume that tildewideX∈ /CAm×(n+1)is a new data matrix constructed
from Xby adding a column of ones, i.e., tildewideX=(X,1). Our new weight vector
˜w=(w;b)∈ /CAn+1already contains the offset b. By choosing
t=m·(y1/my1,..., ym/mym),
109 Kernel Classiﬁers from a Bayesian Perspective
where m+1and m−1are the number of positively and negatively labeled examples
in the training sample, we see that the maximum condition tildewideX/primetildewideXhatwidetildewidew=tildewideX/primetcan also
be written
parenleftbigg
X/prime
1/primeparenrightbiggparenleftbigX1parenrightbigparenleftbiggˆw
ˆbparenrightbigg
=parenleftbigg
X/prime
1/primeparenrightbigg
t⇔parenleftbigg
X/primeXX/prime1
1/primeX1/prime1parenrightbiggparenleftbiggˆw
ˆbparenrightbigg
=parenleftbigg
X/primet
1/primetparenrightbigg
.
By construction 1/primet=mparenleftBig
m+1
m+1−m−1
m−1parenrightBig
=0and, thus, the last equation gives
1/primeXˆw+ˆb·1/prime1=0,⇔ˆb=−1
m1/primeXˆw. (3.41)
Inserting this expression into the ﬁrst equation and noticing that by virtue of
equation (3.39)
X/primet=m·parenleftbig
ˆµ+1−ˆµ+1parenrightbig
,
we see that
X/primeXˆw+X/prime1·ˆb=parenleftbigg
X/primeX−1
mX/prime11/primeXparenrightbigg
ˆw=m·parenleftbig
ˆµ+1−ˆµ+1parenrightbig
. (3.42)
A straightforward calculation shows that
1
mX/prime11/primeX=m+1ˆµ+1ˆµ/prime
+1+m−1ˆµ−1ˆµ/prime
−1−m+1m−1
mparenleftbig
ˆµ+1−ˆµ−1parenrightbigparenleftbig
ˆµ+1−ˆµ−1parenrightbig/prime.
Combining this expression with equation (3.42) results in
parenleftBig
ˆ/Sigma1+m+1m−1
mparenleftbig
ˆµ+1−ˆµ−1parenrightbigparenleftbig
ˆµ+1−ˆµ−1parenrightbig/primeparenrightBig
ˆw=m·parenleftbig
ˆµ+1−ˆµ+1.parenrightbig
where we used the deﬁnition of ˆ/Sigma1given in equation (3.39). Finally, noticing that
m+1m−1
mparenleftbig
ˆµ+1−ˆµ−1parenrightbigparenleftbig
ˆµ+1−ˆµ−1parenrightbig/primew=(1−c)parenleftbig
ˆµ+1−ˆµ−1parenrightbig
for some c∈ /CAthe latter expression implies that
ˆw=m·c·ˆ/Sigma1−1parenleftbig
ˆµ+1−ˆµ−1parenrightbig
,
that is, up to a scaling factor (which is immaterial in classiﬁcation) the weight
vectorˆw∈ /C3obtained by least square regression on t∝yequals the Fisher
discriminant. The value of the threshold ˆb is given by equation (3.41).
110 Chapter 3
3.6 Bibliographical Remarks
In the ﬁrst section of this chapter we introduced the Bayesian inference principle
whose basis is given by Bayes’ theorem (see equation (3.1)). Excellent monographsintroducing this principle in more detail are by Bernardo and Smith (1994) and byRobert (1994); for a more applied treatment of ideas to the problem of learningsee MacKay (1991) and MacKay (1999). It was mentioned that the philosophy
underlying Bayesian inference is based on the notion of belief. The link between
belief and probability is established in the seminal paper Cox (1946) where a min-imal number of axioms regarding belief are given. Broadly speaking, these axiomsformalize rational behavior on the basis of belief. A major concept in Bayesiananalysis is the concept of prior belief. In the book we have only introduced the ideaof conjugate priors. As the prior is the crux of Bayesian inference there exist, ofcourse, many different approaches to deﬁning a prior, for example on the basis ofinvariances w.r.t. parameterization of the likelihood (Jeffreys 1946; Jaynes 1968).In the context of learning, the model selection principle of evidence maximizationwas formulated for the ﬁrst time in MacKay (1992). In Subsection 3.1.1 we intro-duced several prediction strategies on the basis of posterior belief in hypotheses.Note that the term Bayes classiﬁcation strategy (see Deﬁnition 3.7) should not be
confused with the term Bayes (optimal) classiﬁer which is used to denote the strat-
egy which decides on the class ythat incurs minimal loss on the prediction of x
(see Devroye et al. (1996)). The latter strategy is based on complete knowledge
of the data distribution P
Zand therefore achieves minimal error (sometimes also
called Bayes error ) for a particular learning problem.
Section 3.2 introduced Bayesian linear regression (see Box and Tiao (1973))
and revealed its relation to certain stochastic processes known as Gaussian pro-cesses (Feller 1966); the presentation closely follows MacKay (1998, Williams(1998). In order to relate this algorithm to neural networks (see Bishop (1995))it was shown in Neal (1996) that a Gaussian process on the targets emerges inthe limiting case of an inﬁnite number of hidden neurons and Gaussian priors onthe individual weights. The extension to classiﬁcation using the Laplace approx-imation was done for the ﬁrst time in Barber and Williams (1997, Williams andBarber (1998). It was noted that there also exists a Markov chain approximation(see Neal (1997b)) and an approximation known as the mean ﬁeld approximation(see Opper and Winther (2000)). It should be noted that Gaussian processes for
regression estimation are far from new; historical details dating back to 1880 can
be found in Lauritzen (1981). Within the geostatistics ﬁeld, Matheron proposed a
111 Kernel Classiﬁers from a Bayesian Perspective
framework of regression identical to Gaussian processes which he called "kriging"
after D. G. Krige, a South African mining engineer (Matheron 1963). However,the geostatistics approach has concentrated mainly on low-dimensional problems.The algorithmical problem of inverting the Gram matrix has been investigated byGibbs and Mackay (1997) who also proposes a variational approximation to Gaus-sian processes; for other approaches to speeding Gaussian process regression andclassiﬁcation see Trecate et al. (1999), Williams and Seeger (2001) and Smola andBartlett (2001). Finally, the reasoning in Remark 3.13 is mainly taken from Sollich(2000).
The relevance vector machine algorithm presented in Section 3.3 can be found
in Tipping (2000) and Tipping (2001). This algorithm is motivated by automaticrelevance determination (ARD) priors which have been suggested in MacKay(1994) and Neal (1996) and empirically investigated in Neal (1998). There exists avariational approximation to this method found in Bishop and Tipping (2000).
In Section 3.4 we presented the Bayes point machine which is also known as the
optimal perceptron (Watkin 1993). This algorithm has received a lot of attention
in the statistical mechanics community (Opper et al. 1990; Opper and Haussler1991; Biehl and Opper 1995; Opper and Kinzel 1995; Dietrich et al. 2000). Thereit has been shown that the optimal perceptron is the classiﬁer which achieves bestgeneralization error on average and in the so-called thermodynamical limit, i.e.,the number of features nand the number samples mtend to inﬁnity although
their ratio m/n=βstays constant. The idea of using a billiard on the unit
hypersphere is due to Ruján (1997); its “kernelization” was done independently by
Ruján and Marchand (2000) and Herbrich et al. (2001). For an extensive overview
of other applications of Markov Chain Monte Carlo methods the interested readeris referred to Neal (1997a). There exist several extension to this algorithm whichaim to reduce the computational complexity (see Herbrich and Graepel (2001a)and Rychetsky et al. (2000)). A promising approach has been presented in Minka(2001) where the uniform posterior measure over version space is approximated bya multidimensional Gaussian measure. This work also presents a modiﬁcation ofthe billiard algorithm which is guaranteed to converge (Minka 2001, Section 5.8).
The algorithm presented in the last section, that is, Fisher linear discriminants,
has its roots in the ﬁrst half of the last century (Fisher 1936). It became part ofthe standard toolbox for classiﬁcation learning (also called discriminant analysiswhen considered from a purely statistical perspective). The most appealing fea-ture of Fisher discriminants is that the direction vector found is the maximizer of afunction which approximately measures the inter-class distance vs. the inner-class
distance after projection. The difﬁculty in determining this maximizer in general
112 Chapter 3
has been noticed in several places, e.g., V apnik (1982, p. 48). The idea of ker-
nelizing this algorithm has been considered by several researchers independentlyyet at the same time (see Baudat and Anouar (2000), Mika et al. (1999) and Rothand Steinhage (2000)). Finally, the equivalence of Fisher discriminants and leastsquares regression, demonstrated in Remark 3.16, can also be found in Duda et al.(2001).
It is worth mentioning that, beside the four algorithms presented, an interesting
and conceptually different learning approach has been put forward in Jaakkola et al.(2000) and Jebara and Jaakkola (2000). The algorithm presented there employs
the principle of maximum entropy (see Levin and Tribus (1978)). Rather than
specifying a prior distribution over hypotheses together with a likelihood modelP
Z|H=hfor the objects and classes, given a hypothesis h, which, by Bayes’ theorem,
result in the Bayesian posterior, we consider any measure PHwhich satisﬁes certain
constraints on the given training sample zas a potential candidate for the posterior
belief. The principle then chooses the measure PME
Hwhich maximizes the entropy
EHbracketleftbig
ln(PH(H))bracketrightbig
. The idea behind this principle is to use as little prior knowledge
or information as possible in the construction of PME
H. Implementing this formal
principle for the special case of linear classiﬁers results in an algorithm verysimilar to the support vector algorithm (see Section 2.4). The essential differenceis given by the choice of the cost function on the margin slack variables. A similarobservation has already been made in Remark 3.13.
II Learning Theory

4 Mathematical Models of Learning
This chapter introduces different mathematical models of learning. A mathematical
model of learning has the advantage that it provides bounds on the generalizationability of a learning algorithm. It also indicates which quantities are responsible
for generalization. As such, the theory motivates new learning algorithms. After
a short introduction into the classical parametric statistics approach to learning,the chapter introduces the PAC and VC models. These models directly study theconvergence of expected risks rather than taking a detour over the convergence ofthe underlying probability measure. The fundamental quantity in this frameworkis the growth function which can be upper bounded by a one integer summarycalled the VC dimension. With classical structural risk minimization , where the
VC dimension must be known before the training data arrives, we obtain a-priori
bounds, that is, bounds whose values are the same for a ﬁxed training error.
In order to explain the generalization behavior of algorithms minimizing a
regularized risk we will introduce the luckiness framework. This framework isbased on the assumption that the growth function will be estimated on the basisof a sample. Thus, it provides a-posteriori bounds; bounds which can only be
evaluated after the training data has been seen. Finally, the chapter presents a PAC
analysis for real-valued functions. Here, we take advantage of the fact that, in the
case of linear classiﬁers, the classiﬁcation is carried out by thresholding a real-valued function. The real-valued output, also referred to as the margin, allows us todeﬁne a scale sensitive version of the VC dimension which leads to tighter boundson the expected risk. An appealing feature of the margin bound is that we canobtain nontrivial bounds even if the number of training samples is signiﬁcantly
less than the number of dimensions of feature space. Using a technique, which isknown as the robustness trick, it will be demonstrated that the margin bound isalso applicable if one allows for training error via a quadratic penalization of thediagonal of the Gram matrix.
116 Chapter 4
4.1 Generative vs. Discriminative Models
In Chapter 2 it was shown that a learning problem is given by a training sample
z=(x,y)=((x1,y1),...,(xm,ym))∈(
/CG× /CH)m= /CIm, drawn iid according to
some (unknown) probability measure PZ=PXY, and a loss l: /CH× /CH→ /CA,w h i c h
deﬁnes how costly the prediction h(x)is if the true output is y. Then, the goal is to
ﬁnd a deterministic function h∈ /CH
/CGwhich expresses the dependency implicitly
expressed by PZwith minimal expected loss (risk) R[h]=EXYbracketleftbig
l(h(X),Y)bracketrightbig
while only using the given training sample z.We have already seen in the ﬁrst part
of this book that there exist two different algorithmical approaches to tackling thisproblem. We shall now try to study the two approaches more generally to see inwhat respect they are similar and in which aspects they differ.
1. In the generative (or parametric) statistics approach we restrict ourselves to
a parameterized space/C8of measures for the space /CI, i.e., we model the data
generation process. Hence, our model is given by1/C8=braceleftbig
PZ|Q=θ|θ∈ /C9bracerightbig
,w h e r e
θshould be understood as the parametric description of the measure PZ|Q=θ. With
aﬁ x e dl o s s leach measure PZ|Q=θimplicitly deﬁnes a decision function hθ,
hθ(x)=argmin
y∈ /CHEY|X=x,Q=θbracketleftbig
l(y,Y)bracketrightbig
. (4.1)
In order to see that this function has minimal expected risk we note that
Rθ[h]def=EXY|Q=θbracketleftbig
l(h(X),Y)bracketrightbig
=EX|Q=θbracketleftbig
EY|X=x,Q=θbracketleftbig
l(h(x),Y)bracketrightbigbracketrightbig
, (4.2)
where hθminimizes the expression in the innermost brackets. For the case of zero-
one loss l0−1(h(x),y)=Ih(x)/negationslash=yalso deﬁned in equation (2.10), the function hθ
reduces to
hθ(x)=argmin
y∈ /CHparenleftbig
1−PY|X=x,Q=θ(y)parenrightbig
=argmax
y∈ /CHPY|X=x,Q=θ(y),
which is known as the Bayes optimal decision based on PZ|Q=θ.
2. In the discriminative , or machine learning, approach we restrict ourselves to a
parameterized space /C0⊆ /CH
/CGof deterministic mappings hfrom /CGto /CH.A sa
consequence, the model is given by /C0={hw: /CG→ /CH|w∈ /CF},w h e r e wis the
parameterization of single hypotheses hw. Note that this can also be interpreted as
1 We use the notation PZ|Q=θto index different measures over /CIby some parameters θ. Note that it is neither
assumed nor true that the unknown data distribution PZfulﬁlls PZ=EQ[PZ|Q=θ]because this requires a
measure PQ. Further, this would not take into account that we conditioned on the parameter space /C9.
117 Mathematical Models of Learning
a model of the conditional distribution of classes y∈ /CHgiven objects x∈ /CGby
assuming that PY|X=x,H=h=Iy=h(x). Viewed this way, the model /C0is a subset of
the more general model /C8used in classical statistics.
The term generative refers to the fact that the model /C8contains different descrip-
tions of the generation of the training sample z(in terms of a probability measure).
Similarly, the term discriminative refers to the fact that the model /C0consists of dif-
ferent descriptions of the discrimination of the sample z. We already know that a
machine learning method selects one hypothesis /BT(z)∈ /C0given a training sample
z∈ /CIm. The corresponding selection mechanism of a probability measure PZ|Q=θ
given the training sample zis called an estimator.
Deﬁnition 4.1 (Estimator) Given a set /C8of probability measures PZover /CI,a
mapping /BX:uniontext∞
m=1
/CIm→ /C8is called an estimator . If the set /C8is parameterized
byθ∈ /C9then ˆθz∈ /C9is deﬁned by
ˆθz=θ⇔ /BX(z)=PZ|Q=θ,
that is, ˆθzreturns the parameters of the measure estimated using /BX.
If we view a given hypothesis space /C0as the set of parameters hfor the conditional
distribution PY|X=x,H=hthen we see that each learning algorithm /BT:∪∞
m=1
/CIm→/C0is a special estimator /BXfor only the class-conditional distribution PY|X=x.
However, the conceptual difference becomes apparent when we consider the typeof convergence results that have been studied for the two different models:
1. In the parametric statistics framework we are concerned with the convergence
of the estimated measure/BX(z)∈ /C8to the unknown measure PZwhere it is
often assumed that the model is correct, that is, there exists a θ∗such that PZ=
PZ|Q=θ∗∈ /C8. Hence, a theoretical result in the statistics framework often has the
form
PZmparenleftbig
ρparenleftbig/BX(Z),PZ|Q=θ∗parenrightbig
>εparenrightbig
<δ(ε,m), (4.3)
whereρis a metric in the space /C8of measures, for example the /lscript2normvextenddoublevextenddoublevextenddoubleˆθz−θ∗vextenddoublevextenddoublevextenddouble
2of the difference vector of the parameters θ.
2. In the machine learning framework we are concerned with the convergence of
the expected risk R[
/BT(z)]of the learned function /BT(z)to the minimum expected
118 Chapter 4
risk inf h∈ /C0R[h]=R[h∗]. A theoretical result in this framework has the form
PZmparenleftbig
Rbracketleftbig/BT(Z)bracketrightbig
−Rbracketleftbig
h∗bracketrightbig
>εparenrightbig
<δ(ε,m), (4.4)
where the expression in the parenthesis is also known as the generalization error
(see also Deﬁnition 2.10). In case R[h∗]=0 the generalization error equals the
expected risk. Note that each hypothesis h∈ /C0is reduced to a scalar R[h]so that
the question of an appropriate metric ρis meaningless2.S i n c e PZis assumed to be
unknown, the above inequality has to hold for all probability measures PZ.This
is often referred to as the worst case property of the machine learning framework.
The price we have to pay for this generality is that our choice of the predictivemodel/C0might be totally wrong (e.g., R[h∗]=0.5 in the case of zero-one loss
l0−1) so that learning /BT(z)∈ /C0is useless.
For the task of learning—where ﬁnding the best discriminative description of the
data is assumed to be the ultimate goal—the convergence (4.4) of risks appears themost appropriate. We note, however, that this convergence is a special case of theconvergence (4.3) of probability measures when identifying/C0and /C9and using
ρparenleftbig
PZ|H=h,PZ|H=h∗parenrightbig
=R[h]−R[h∗]. The interesting question is:
Does the convergence of probability measures always imply a convergence
of risks when using equation (4.1) regardless of ρ?
If this were the case than there would be no need to study the convergence of
risk but we could use the plethora of results known from statistics about theconvergence of probability measures. If, on the other hand, this is not the case thenit also follows that (in general) the common practice of interpreting the parametersw(orθ) of the hypothesis learned is theoretically not justiﬁed on the basis of
convergence results of the form (4.4). Let us consider the following example.
Example 4.2 (Convergence of probability measures
3)Let us consider the zero-
one loss l 0−1. Suppose /CH={1,2}, /CG= /CA, /C9= /CA2,PX|Y=y,Q=(θ1,θ2)uniform inbracketleftbig
−θy,0bracketrightbig
ifθy/negationslash=1and uniform inbracketleftbig
0,θ ybracketrightbig
ifθy=1, and PY(1)=PY(2)=1
2.L e t
us assume that the underlying probability measure is given by θ∗=(1,2). Given
a training sample z∈(
/CG× /CH)m, a reasonable estimate ˆθzofθ1andθ2would be
2 All norms on the real line /CA1are equivalent (see Barner and Flohr (1989, p. 15)).
3 This example is taken from Devroye et al. (1996, p. 267).
119 Mathematical Models of Learning/BA/A0 /BE /A0 /BD /BC /BD /BE /BF /BG
/BD/DC
/CU/CG /CY /CH /BP /DD
/B4 /DC /B5
Figure 4.1 True densities fX|Y=yunderlying the data in Example 4.2. The uniform
densities (solid lines) on [0 ,1] and [−2,0] apply for Y=1a n d Y=2, respectively.
Although with probability one the parameter θ∗
1= 1 will be estimated to arbitrary
precision, the probability that a sample point falls at exactly x= 1 is zero, whence
(ˆθZ)1/negationslash=1. Since the model /C8is noncontinuous in its parameters θ, for almost all training
samples the estimated densities are uniform on [−(ˆθZ)2,0]and[−(ˆθZ)1,0](dashed lines).
Thus, for all x>0 the prediction based on ˆθZis wrong.
parenleftBig
ˆθzparenrightBig
i=max(x,i)∈z|x|for i∈{1,2}because
∀ε> 0: lim
m→∞PZmparenleftBigvextenddoublevextenddoublevextenddoubleˆθZ−θ∗vextenddoublevextenddoublevextenddouble
2>εparenrightBig
=0,
or ˆθzconverges to θ∗in probability . However , as the class conditional measures
PX|Y=yare densities, we know that for both classes y ∈{1,2},
PZmparenleftbiggparenleftBig
ˆθZparenrightBig
y/negationslash=1parenrightbigg
=1.
As a consequence, with probability one over the random choice of a training
sample z, the expected risk RbracketleftBig
hˆθZbracketrightBig
equals1
2(see also Figure 4.1).
This simple example shows that the convergence of probability measures is not
necessarily a guarantee of convergence of associated risks. It should be noted, how-ever, that this example used the noncontinuity of the parameterization θof the prob-
ability measure P
Z|Q=θas well as one speciﬁc metric ρon probability measures.
The following example shows that along with the difference RbracketleftBig
hˆθzbracketrightBig
−R[hθ∗]in
expected risks there exists another “natural” metric on probability measures which
leads to a convergence of risks.
120 Chapter 4
Example 4.3 ( L1–Convergence of probability measures) In case of zero-one
loss l 0−1each function h ∈ /CH
/CGsubdivides the space /CIinto two classes: A set
Zc
h={(x,y)∈ /CI|l0−1(h(x),y)=0}of correctly classiﬁed points and its com-
plement Zi
h={(x,y)∈ /CI|l0−1(h(x),y)=1}of incorrectly classiﬁed points.
Clearly, the expected risk R [h]of a function h ∈ /C0has the property
R[h]=EXYbracketleftbig
l(h(X),Y)bracketrightbig
=0·PZparenleftbig
Zc
hparenrightbig
+1·PZparenleftbig
Zi
hparenrightbig
=PZparenleftbig
Zi
hparenrightbig
. (4.5)
Let us assume that our generative model /C8only consists of measures PZ|Q=θthat
possess a density fZ|Q=θover theσ–algebra /BUnof Borel sets in /CAn.T h et h e o r e m
of Scheffé states that
ρparenleftbig
PZ|Q=θ,PZ|Q=θ∗parenrightbigdef=vextenddoublevextenddoublefZ|Q=θ−fZ|Q=θ∗vextenddoublevextenddouble
1=2s u p
A∈ /BUnvextendsinglevextendsinglePZ|Q=θ(A)−PZ|Q=θ∗(A)vextendsinglevextendsingle.
Utilizing equation (4.5) and the fact that each measure PZ|Q=θdeﬁnes a Bayes
optimal classiﬁer h θby equation (4.1) we conclude
vextenddoublevextenddoublefZ|Q=θ−fZ|Q=θ∗vextenddoublevextenddouble
1= 2s u p
A∈ /BUnvextendsinglevextendsinglePZ|Q=θ(A)−PZ|Q=θ∗(A)vextendsinglevextendsingle
≥ 2s u p
˜θ∈ /C9vextendsinglevextendsingleRθbracketleftbig
h˜θbracketrightbig
−Rθ∗bracketleftbig
h˜θbracketrightbigvextendsinglevextendsingle
≥|Rθ[hθ]−Rθ∗[hθ]|+|Rθ[hθ∗]−Rθ∗[hθ∗]|
=|Rθ∗[hθ]−Rθ[hθ]|+|Rθ[hθ∗]−Rθ∗[hθ∗]|
≥|Rθ∗[hθ]−Rθ[hθ]+Rθ[hθ∗]−Rθ∗[hθ∗]|
=vextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextendsingleRθ∗[hθ]−Rθ∗[hθ∗]bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
≥0+Rθ[hθ∗]−Rθ[hθ]bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
≥0vextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextendsingle
≥ Rθ∗[hθ]−Rθ∗[hθ∗]
= R[hθ]−R[hθ∗],
where we use the triangle inequality in the ﬁfth line and assume PZ=PZ|Q=θ∗
in the last line. Thus we see that the convergence of the densities in L 1implies
the convergence (4.4) of the expected risks for the associated decision functionsbecause each upper bound onvextenddoublevextenddoublef
Z|Q=θ−fZ|Q=θ∗vextenddoublevextenddouble
1is also an upper bound on
R[hθ]−R[hθ∗].
As a consequence, bounding the L1–distance of densities underlying the training
sample implies that we are able to bound the difference in expected risks, too.
121 Mathematical Models of Learning
Note, however, that the convergence in expected risks could be much faster and
thus we lose some tightness of the potential results when studying the convergenceof probability measures.
The main problem in the last two examples is summarized in the following
statement made in V apnik (1995): When solving a given problem one should avoid
solving a more general problem as an intermediate step . In our particular case this
means that if we are interested in the convergence of the expected risks we shouldnot resort to the convergence of probability measures because the latter might notimply the former or might be a weaker convergence than required. Those who ﬁrst
estimate P
Zby /BX(z)∈ /C8and then construct rules based on the loss ldo themselves
a disservice.
4.2 PAC and VC Frameworks
As a starting point let us consider the huge class of empirical risk minimizationalgorithms/BTERM formally deﬁned in equation (2.12). To obtain upper bounds on
the deviation between the expected risk of the function /BTERM(z)(which minimizes
the training error Remp [h,z]) and the best function h∗=arginfh∈ /C0R[h],t h e
general idea is to make use of the following relation
Rempbracketleftbig
h∗,zbracketrightbig
≥Remp [
/BTERM(z),z]⇔ Rempbracketleftbig
h∗,zbracketrightbig
−Remp [
/BTERM(z),z]≥0,
which clearly holds by deﬁnition of hzdef= /BTERM(z). Then it follows that
R[
/BTERM(z)]−Rbracketleftbig
h∗bracketrightbig
≤ R[hz]−Rbracketleftbig
h∗bracketrightbig
+parenleftbig
Rempbracketleftbig
h∗,zbracketrightbig
−Remp [hz,z]parenrightbig
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
≥0
=vextendsinglevextendsingleparenleftbig
R[hz]−Remp [hz,z]parenrightbig
+parenleftbig
Rempbracketleftbig
h∗,zbracketrightbig
−Rbracketleftbig
h∗bracketrightbigparenrightbigvextendsinglevextendsingle
≤vextendsinglevextendsingleR[hz]−Remp [hz,z]vextendsinglevextendsingle+vextendsinglevextendsingleRbracketleftbig
h∗bracketrightbig
−Rempbracketleftbig
h∗,zbracketrightbigvextendsinglevextendsingle
≤ 2s u p
h∈ /C0vextendsinglevextendsingleR[h]−Remp [h,z]vextendsinglevextendsingle, (4.6)
where we have made use of the triangle inequality in the third line and bounded
the uncertainty about /BTERM(z)∈ /C0and h∗∈ /C0by the worst case assump-
tion of suph∈ /C0vextendsinglevextendsingleR[h]−Remp [h,z]vextendsinglevextendsinglefrom above. We see that, rather than study-
ing the generalization error of an empirical risk minimization algorithm directly,it sufﬁces to consider the uniform convergence of training errors to expected er-
rors over all hypotheses h∈/C0contained in the hypothesis space /C0because
122 Chapter 4
any upper bound on the deviation suph∈ /C0vextendsinglevextendsingleR[h]−Remp [h,z]vextendsinglevextendsingleis also an upper
bound on the generalization error R[
/BTERM(z)]−R[h∗]by virtue of equation
(4.6). The framework which studies this convergence is called the VC (V apnik-
Chervonenkis) or PAC (Probably Approximately Correct) framework due to their
different origins (see Section 4.5 for a detailed discussion about their originsand connections). Broadly speaking, the difference between the PAC frameworkand the VC framework is that the former considers only data distributions P
Z
where PY|X=x(y)=Ih∗(x)=y,f o rs o m e h∗∈ /C0, which immediately implies that
R[h∗]=0a n d Remp [
/BTERM(z),z]=0. Thus, it follows that
R[
/BTERM(z)]−Rbracketleftbig
h∗bracketrightbig
=R[
/BTERM(z)]≤ sup
{h∈ /C0|Remp [h]=0}R[h], (4.7)
because /BTERM(z)∈braceleftbig
h∈ /C0vextendsinglevextendsingleRemp [h,z]=0bracerightbig
⊆ /C0.
Deﬁnition 4.4 (VC and PAC g eneralization error bounds) Suppose we are given
a hypothesis space /C0⊆ /CH
/CGand a loss function l : /CH× /CH→ /CA. Then the function
εVC: /C6×(0,1]→ /CAis called a VC generalization error bound if, and only if, for
all training sample sizes m ∈ /C6,a l lδ∈(0,1]and all PZ
PZmparenleftbig
∀h∈ /C0:vextendsinglevextendsingleR[h]−Rempbracketleftbig
h,Zbracketrightbigvextendsinglevextendsingle≤εVC(m,δ)parenrightbig
≥1−δ.
Similarly, a function εPAC: /C6×(0,1]→ /CAis called a PAC generalization error
bound if, and only if,
PZm(∀h∈V/C0(Z):R[h]≤εPAC(m,δ))≥1−δ,
for all samples sizes m ∈ /C6,a l lδ∈(0,1]and all PZ.
Example 4.5 (Uniform convergence of frequencies to probabilities) There ex-
ists an interesting relationship between VC generalization error bounds and the
more classical problem of uniform convergence of frequencies to probabilities in
the special case of the zero-one loss l 0−1given in equation (2.10). As shown in
Example 4.3, in this case the expected risk R [h]of a single hypothesis h ∈ /C0is
the probability of the set Zi
h={(x,y)∈ /CI|l0−1(h(x),y)=1}⊆ /CIwhereas
the training error R emp [h,z]equals the empirical measure vzparenleftbig
Zi
hparenrightbig
. Hence we see
that
R[
/BTERM(z)]−Rbracketleftbig
h∗bracketrightbig
≤2s u p
Zi
h∈ /CIvextendsinglevextendsinglePZparenleftbig
Zi
hparenrightbig
−vzparenleftbig
Zi
hparenrightbigvextendsinglevextendsingle,
123 Mathematical Models of Learning
which inevitably shows that all we are concerned with is the uniform conver-
gence of frequencies vzparenleftbig
Zi
hparenrightbig
to probabilities PZparenleftbig
Zi
hparenrightbig
over the ﬁxed set /CI=braceleftbig
Zi
h⊆ /CI|h∈ /C0bracerightbig
of events. Note, however , that up to this point we have only
shown that the uniform convergence of frequencies to probabilities provides a suf-ﬁcient condition for the convergence of the generalization error of an empiricalrisk minimization algorithm. If we restrict ourselves to “non trivial” hypothesisspaces and the one-sided uniform convergence, it can be shown that this is also anecessary condition.
4.2.1 Classical PAC and VC Analysis
In the following three subsections we will only be concerned with the zero-oneloss l
0−1given by equation (2.10). It should be noted that the results we will obtain
can readily be generalized to loss function taking only a ﬁnite number values; thegeneralization to the case of real-valued loss functions conceptually similar but willnot be discussed in this book (see Section 4.5 for further references).
The general idea is to bound the probability of “bad training samples”, i.e.,
training samples z∈/CImfor which there exists a hypothesis h∈ /C0where the
deviation between the empirical risk Remp [h,z]and the expected risk R[h]is
larger than some prespeciﬁed ε∈[0,1]. Setting the probability of this to δand
solving for εgives the required generalization error bound. If we are only given a
ﬁnite number |/C0|of hypotheses hthen such a bound is very easily obtained by a
combination of Hoeffding’s inequality and the union bound.
Theorem 4.6 (VC bound for ﬁnite hypothesis spaces) Suppose we are given a
hypothesis space /C0having a ﬁnite number of hypotheses, i.e., |/C0|<∞. Then,
for any measure PZ, for allδ∈(0,1]and all training sample sizes m ∈ /C6, with
probability at least 1−δover the random draw of the training sample z∈ /CImwe
have
PZmparenleftbig
∃h∈ /C0:vextendsinglevextendsingleR[h]−Rempbracketleftbig
h,Zbracketrightbigvextendsinglevextendsingle>εparenrightbig
<2·|/C0|·expparenleftbig
−2mε2parenrightbig
. (4.8)
Proof Let /C0=braceleftbig
h1,..., h|/C0|bracerightbig
. By an application of the union bound given in
Theorem A.107 we know that PZmparenleftbig
∃h∈ /C0:vextendsinglevextendsingleR[h]−Rempbracketleftbig
h,Zbracketrightbigvextendsinglevextendsingle>εparenrightbig
is given
by
PZmparenleftBigg|/C0|logicalordisplay
i=1parenleftbigvextendsinglevextendsingleR[hi]−Rempbracketleftbig
hi,Zbracketrightbigvextendsinglevextendsingle>εparenrightbigparenrightBigg
≤|/C0|summationdisplay
i=1PZmparenleftbigvextendsinglevextendsingleR[hi]−Rempbracketleftbig
hi,Zbracketrightbigvextendsinglevextendsingle>εparenrightbig
.
124 Chapter 4
Since, for any ﬁxed h,R[h]and Remp [h,z]are the expectation and mean of a
random variable between 0 and 1, the result follows by Hoeffding’s inequality.
In order to generalize this proof to an inﬁnite number |/C0|of hypotheses we
use a very similar technique which, however, requires some preparatory work toreduce the analysis to a ﬁnite number of hypotheses. Basically, the approach canbe decomposed into three steps:
1. First, consider a double sample z˜z∈/CI2mdrawn iid where ˜zis sometimes re-
ferred to as a ghost sample. We upper bound the probability that there exists a
hypothesis h∈ /C0such that Remp [h,z]is more than εapart from R[h](see equa-
tion (4.7)) by twice the probability that there exists h/prime∈ /C0such that Rempbracketleftbig
h/prime,zbracketrightbig
is
more than ε/2 apart from Rempbracketleftbig
h/prime,˜zbracketrightbig
. This lemma has become known as the basic
lemma and the technique is often referred to as symmetrization by a ghost sample .
The idea is intuitive—it takes into account that it is very likely that the mean of arandom variable is close to its expectation (see Subsection A.5.2). If it is likely thattwo means estimated on iid samples z∈/CImand ˜z∈ /CImare very close then it ap-
pears very probable that a single random mean is close to its expectation otherwisewe would likely have observed a large deviation between the two means.
2. Since we assume the sample (and ghost sample) to be an iid sample it holds
that, for any permutation π:{1,..., 2m}→{1,..., 2m},
P
Z2m(ϒ(Z1,..., Z2m))=PZ2mparenleftbig
ϒparenleftbig
Zπ(1),..., Zπ(2m)parenrightbigparenrightbig
,
whatever the logical formula ϒ: /CI2m→{true,false}stands for. As a conse-
quence, for any set /Pi12mof permutations it follows that
PZ2m(ϒ(Z1,..., Z2m))=1
|/Pi12m|summationdisplay
π∈/Pi12mPZ2mparenleftbig
ϒparenleftbig
Zπ(1),..., Zπ(2m)parenrightbigparenrightbig
(4.9)
=integraldisplay/CI2mparenleftBigg
1
|/Pi12m|summationdisplay
π∈/Pi12mIϒ(zπ(1),..., zπ(2m))parenrightBigg
dFZ2m(z)
≤ max
z∈ /CI2mparenleftBigg
1
|/Pi12m|summationdisplay
π∈/Pi12mIϒ(zπ(1),..., zπ(2m))parenrightBigg
. (4.10)
The appealing feature of this step is that we have reduced the problem of bounding
the probability over /CI2mto a counting of permutations π∈/Pi12mfor a ﬁxed z∈/CI2m. This step is also known as symmetrization by permutation orconditioning .
125 Mathematical Models of Learning
3. It remains to bound the number of permutations π∈/Pi12msuch that there exists
a hypothesis h/prime∈ /C0on which the deviation of two empirical risks (on the training
sample zand the ghost sample ˜z) exceeds ε/2. Since we considered the zero-
one loss l0−1we know that there are at most 22mdifferent hypotheses w.r.t. the
empirical risks Rempbracketleftbig
h/prime,zbracketrightbig
and Rempbracketleftbig
h/prime,˜zbracketrightbig
. It we denote the maximum number
of such equivalence classes by /C6/C0(2m)then we can again use a combination of
the union bound and Hoeffding’s inequality to bound the generalization error. Notethat the cardinality |/C0|of the hypothesis space in the ﬁnite case has been replaced
by the number /C6/C0(2m).
Following these three steps we obtain the main VC and PAC bounds.
Theorem 4.7 (VC and PAC generalization error bound) F or all probability mea-
sures PZ, any hypothesis space /C0, the zero-one loss l 0−1given by equation (2.10)
and allε> 0
PZmparenleftbig
∃h∈ /C0:vextendsinglevextendsingleR[h]−Rempbracketleftbig
h,Zbracketrightbigvextendsinglevextendsingle>εparenrightbig
< 4 /C6/C0(2m)expparenleftbigg
−mε2
8parenrightbigg
,(4.11)
PZm(∃h∈V(Z):R[h]>ε)< 2 /C6/C0(2m)expparenleftBig
−mε
4parenrightBig
,(4.12)
PZmparenleftbig
Rbracketleftbig/BTERM(Z)bracketrightbig
−Rbracketleftbig
h∗bracketrightbig
>εparenrightbig
< 4 /C6/C0(2m)expparenleftbigg
−mε2
32parenrightbigg
.(4.13)
Proof The ﬁrst two results are proven in Appendix C.1. The ﬁnal result follows
from equation (4.6) using the fact that
parenleftbigg
2s u p
h∈ /C0vextendsinglevextendsingleR[h]−Remp [h,z]vextendsinglevextendsingle≤ε⇒ R[
/BTERM(z)]−Rbracketleftbig
h∗bracketrightbig
≤εparenrightbigg
⇔
parenleftbigg
R[
/BTERM(z)]−Rbracketleftbig
h∗bracketrightbig
>ε⇒ sup
h∈ /C0vextendsinglevextendsingleR[h]−Remp [h,z]vextendsinglevextendsingle>ε
2parenrightbigg
,
which proves the assertion.
Conﬁdence Intervals
Disregarding the fact that /C6/C0is unknown up to this point we see that, from these
assertions, we can construct conﬁdence intervals for the expected risk R[h]of the
function hby setting the r.h.s. of equations (4.11) and (4.12) to δ. Assuming that the
event (violation of the bound) has taken place (which will happen with probability
126 Chapter 4
not more than δover the random draw of training sample z) then with probability
at least 1−δover the random draw of the training sample zfor all probability
measures PZ, and simultaneously for all functions h∈ /C0
R[h]≤Remp [h,z]+radicalBigg
8
mparenleftbigg
lnparenleftbigg4
δparenrightbigg
+ln(
/C6/C0(2m))parenrightbigg
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
εVC(m,δ). (4.14)
Also, for all functions having zero training error Remp [h,z]=0
R[h]≤4
mparenleftbigg
lnparenleftbigg2
δparenrightbigg
+ln(
/C6/C0(2m))parenrightbigg
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
εPAC(m,δ). (4.15)
These two bounds constitute the basis results obtained in the VC and PAC frame-
work. There are some interesting conclusions we can draw:
1. If the function /C6/C0fulﬁlls /C6/C0(m)=2mthen both bounds are trivial because
lnparenleftbig
22mparenrightbig
=mln(4)>mwhence the r.h.s. of both inequalities is always greater
than one. Note this is a meaningless bound as 0 ≤R[h]≤1. In this case we
say that the hypothesis space /C0is too rich and thus we are unable to give any
guarantees about the learned function. As an example, if for all mand all training
samples z∈ /CImthere exists one hypothesis h∈ /C0which achieves zero training
error Remp [h,z], then the hypothesis space was much to rich.
2. In the general VC case the upper bound is of order /C7(radicalbig
ln(
/C6/C0(2m))/m)
whereas in the zero training error case it grows as /C7(ln( /C6/C0(2m))/m)due to the
exponent of εof one in equation (4.12). Thus, it seems that we can tighten bounds
by magnitudes if we can achieve zero training error. In fact, one can show that the
exponent of εin equation (4.11) smoothly decreases from the 2 to 1 as a function of
the minimum expected risk R[h∗]. For speciﬁc conditions on the hypothesis space/C0one can show that, even in the general case, the exponent of εis 1.
3. If the cardinality of /C0is ﬁnite we always know that /C6/C0(m)≤|/C0|for all
m. As a consequence, in the case of ﬁnite cardinality of the hypothesis space we
obtain our result (4.8) as a special case (with less favorable constants). A potentialapplication of this result is to obtain upper bounds on the generalization error fordecision tree learning. As the size of decision trees often grows exponentially inm, techniques like pruning effectively limit the number |/C0m|and thus guarantee a
small generalization error.
127 Mathematical Models of Learning
Remark 4.8 (Race for constants) The proof of Theorem 4.7 does not provide the
best constants possible. The best constants that can be achieved are 2as a coef-
ﬁcient of and 1in the exponent of the exponential term, respectively. We shall see
in Subsection 4.3 that an improvement of these results by orders of magnitude can
only be achieved if we give up the a-priori character of the bounds. Presently, the
bounds are of the same value for all decision functions that achieve the same train-ing error R
emp [h,z]. On the one hand, this characteristic is advantageous as it
gives us a general warranty however malicious the distribution PZis. On the other
hand, it only justiﬁes the empirical risk minimization method as this is the only data
dependent term entering the bound.
4.2.2 Growth Function and VC Dimension
In the previous subsection we used the function /C6/C0which characterizes the worst
case diversity of the hypothesis space /C0as a function of the training sample size.
Moreover, due to the exponential term for the deviation of two means, all thatmatters for bounds on the generalization error is the logarithm of this function.More formally, this function is deﬁned as follows.
Deﬁnition 4.9 (Covering number and growth function) Let/C0⊆ /CH
/CGbe a hy-
pothesis space. Then the function /C6/C0: /C6→ /C6is deﬁned as/C6/C0(m)def=max
z∈ /CIm|{(l0−1(h(x1),y1),···,l0−1(h(xm),ym))|h∈ /C0}|, (4.16)
that is, the maximum number of different equivalence classes of functions w.r .t. the
zero-one loss l 0−1on a sample of size m. This is called the covering number of /C0
w.r .t. zero-one loss l 0−1. The logarithm of this function is called the growth function
and is denoted by /BZ/C0, i.e.,/BZ/C0(m)def=ln(
/C6/C0(m)).
Clearly, the growth function depends neither on the sample nor on the unknown
distribution PZbut only on the sample size mand the hypothesis space /C0. Ideally,
this function would be calculated before learning and, as a consequence, we would
be able to calculate the second term of the conﬁdence intervals (4.14) and (4.15).Unfortunately, it is generally not possible to determine the exact value of thefunction/BZ/C0for an arbitrary hypothesis space /C0and any m. Therefore one major
interest in the VC and PAC community is to obtain tight upper bounds on the
128 Chapter 4
growth function. One of the ﬁrst such bounds is given by the following results
whose proof can be found in Appendix C.2.
Theorem 4.10 (Growth function bound and VC dimension) F or any hypothesis
space /C0, the growth function /BZ/C0either
1.satisﬁes the equality
∀m∈ /C6: /BZ/C0(m)=ln(2)·m,
2.or , there exists a natural number ϑ/C0∈ /C6such that/BZ/C0(m)braceleftBigg=ln(2)·mi f m ≤ϑ/C0
≤lnparenleftBigsummationtextϑ/C0
i=0parenleftbigm
iparenrightbigparenrightBig
if m>ϑ/C0. (4.17)
The number4ϑ/C0∈ /C6is called the VC dimension of the hypothesis space /C0and is
deﬁned by
ϑ/C0def=maxbraceleftbig
m∈ /C6vextendsinglevextendsingle/C6/C0(m)=2mbracerightbig
. (4.18)
This result is fundamental as it shows that we can upper bound the richness/C6/C0of the hypothesis space by an integer summary—the VC dimension. A lot
of research has been done to obtain tight upper bounds on the VC dimensionwhich has, by deﬁnition, the following combinatorial interpretation: If/BT/C0=
{{(x,y)∈ /CI|l0−1(h(x),y)=1}|h∈ /C0}is the induced set of events that a
hypothesis h∈ /C0labels(x,y)∈ /CIincorrectly, then the VC dimension ϑof/BT/C0is the largest natural number ϑsuch that there exists a sample z∈ /CIϑof
sizeϑwhich can be subdivided in all 2ϑdifferent ways by (set) intersection with/BT/C0. Then we say that /BT/C0shatters z. If no such number exists we say that the VC
dimension of /BT/C0or /C0is inﬁnite. Sometimes the VC dimension is also called the
shatter coefﬁcient .
In order to relate the above bound on the growth function in terms of the
VC dimension to the conﬁdence intervals (4.14) and (4.15) we make use of theinequality given in Theorem A.105 which states that for all m>ϑ
ϑsummationdisplay
i=0parenleftbiggm
iparenrightbigg
<parenleftBigem
ϑparenrightBigϑ
. (4.19)
4 We shall omit the subscript of ϑ/C0whenever the hypothesis space /C0is clear from context.
129 Mathematical Models of Learning
0.0 0.2 0.4 0.6 0.8 1.00.0 0.5 1.0 1.5ν
mcomplexity termν
m
ln
2m
ν+1


ν
m
0.000 0.010 0.020 0.0300.00 0.05 0.10 0.15ν
mcomplexity termν
m
ln
2m
ν+1


5ν
m
(a) (b)
Figure 4.2 Growth of the complexity termϑ
mparenleftBig
lnparenleftBig
2m
ϑparenrightBig
+1parenrightBig
in the VC conﬁdence
interval (4.14) as a function ofϑ
m.(a) On the whole interval [0 ,1] the increase is clearly
sub-linear. (b) For very small values ofϑ
m<1
30the growth is almost linear.
Therefore for all training sample sizes m>ϑ , the growth function /BZ/C0(m)≤
ϑparenleftbig
lnparenleftbigm
ϑparenrightbig
+1parenrightbig
is sub-linear in ϑdue to the lnparenleftbigm
ϑparenrightbig
term.
Remark 4.11 (Sufﬁcient training sample size) Using the upper bound (4.19) of
the upper bound (4.17) for the growth function /BZ/C0we obtain for the conﬁdence
interval (4.14) the following expression
∀2m>ϑ: R[h]≤Remp [h,z]+radicaltpradicalvertexradicalvertexradicalbt
8parenleftBigg
lnparenleftbig4
δparenrightbig
m+ϑ
mparenleftbigg
lnparenleftbigg2m
ϑparenrightbigg
+1parenrightbiggparenrightBigg
,
Neglecting the term ln(4/δ)/m (which decreases very quickly to zero for increas-
ing m) we plot the value ofϑ
mparenleftbig
lnparenleftbig2m
ϑparenrightbig
+1parenrightbig
as a function ofϑ
min Figure 4.2.
Clearly, form
ϑ>30the contribution of the VC term is less than 0.15and thus,
by the constant factor of 8, we will have nontrivial results in these regimes. V apnik
suggested this as a rule of thumb for the practicability of his bound. By the plots
in Figure 4.2 it is justiﬁable to say that ,f o rm
ϑ>30, the training sample size is
sufﬁciently large to guarantee a small generalization error of the empirical riskminimization algorithm.
Remark 4.12 (Data dependent hypothesis spaces) Another consequence of the
reasoning given above is that the hypothesis space/C0must be independent of the
training sample z. As we have seen in Chapter 2 there are two different viewpoints
130 Chapter 4Ꜷ/BD
Ꜷ/BEꜶ/BDꜶ/BF
Ꜷ/BD
Ꜷ/BE
n=1 n=2 n=3
Figure 4.3 Curse of dimensionality. In order to reliably estimate a density in /CAnwe sub-
divide the n–dimensional space into cells and estimate their probability by the frequency
that an example x∈xfalls into it. Increasing the number of cells would increase the
precision of this estimate. For a ﬁxed precision, however, the number of cells depends
exponentially on the number nof dimensions.
of margin maximization. First, having the norm of each normal vector wﬁxed,
margin maximization aims to minimize the margin loss l margin given by equation
(2.42). Second, deﬁning the hypothesis space /C0to achieve a minimum real-valued
output of one at each training point, this makes /C0data dependent and, thus,
inappropriate for theoretical studies. Nevertheless this formulation of the problem
is algorithmically advantageous.
An important property of the VC dimension is that it does not necessarily
coincide with the number of parameters used. This feature is the key to seeing that,by studying the convergence of expected risks, we are able to overcome a problemwhich is known as curse of dimensionality : The number of examples needed to
reliably estimate the density in an n–dimensional space/CGgrows exponentially
with n(see also Figure 4.3). In the following we will give three examples showing
that the VC dimension can be less than, equal to or greater than the number ofparameters. Note that these three examples are intended to illustrate the differencebetween number of parameters and the VC dimension rather than being practicallyuseful.
Example 4.13 (VC dimension and parameters) Let us use the following three
examples to illustrate the difference between the dimensionality of parameter spaceand the VC dimension (see Section 4.5 for references containing rigorous proofs).
131 Mathematical Models of Learning
1.Consider /CG= /CAand/C0=braceleftBigg
x/mapsto→ signparenleftBiggnsummationdisplay
i=1vextendsinglevextendsinglewixivextendsinglevextendsinglesign(x)+w0parenrightBigg
vextendsinglevextendsingle(w0,w 1,...,w n)∈ /CAn+1bracerightBigg
.
Clearly, all functions in h are monotonically increasing and have exactly one zero.
Thus the maximum size d of a training sample zthat can be labeled in all 2d
different ways is one. This implies that the VC dimension of /C0is one. As this
holds regardless of n the VC dimension can be much smaller than the number ofparameters. It is worth mentioning that for all n ∈/C6there exists a one-dimensional
parameterization of /C0—each w∈ /CAn+1is represented by its zero—which, however ,
the difﬁculty is to ﬁnd a-priori.
2.Consider /CG= /CAnand/C0=braceleftbig
x/mapsto→ sign(/angbracketleftw,x/angbracketright)vextendsinglevextendsinglew∈ /CAnbracerightbig
,
where xdef=φ(x)for some ﬁxed feature mapping φ: /CG→ /C3⊆/lscriptn
2(see Deﬁnition
2.2). Given a sample x=(x1,..., xm)of m objects we thus obtain the m ×n data
matrix X=parenleftbig
x/prime
1;...;x/prime
mparenrightbig
∈ /CAm×n. If the training sample size m is bigger than
the number n of dimensions the matrix Xhas at most rank n, i.e., Xw=thas, in
general, no solution. It follows that the VC dimension can be at most n. In the caseof m=n, by choosing the training sample (x
1,..., xm)such that xi=ei, we see
that Xw=Iw=w, that is, for any labeling y∈{−1,+1}m, we will ﬁnd a vector
w∈ /CAnthat realizes the labeling. Therefore the VC dimension of linear classiﬁers
equals the number n of parameters.
3.Consider /CG= /CAand/C0={x/mapsto→ sign(sin(wx))|w∈ /CA}.
Throughwwe can parameterize the frequency of the sine and thus, for uniformly
spaced training samples x∈ /CGmof any size m, we will ﬁnd 2m(extremely high)
values of wthat label the m points in all 2mdifferent ways. As a consequence the
VC dimension is inﬁnite though we have only one parameter .
4.2.3 Structural Risk Minimization
The analysis presented in the previous subsection revealed that the VC dimension
of /C0is the fundamental quantity that controls the uniform convergence of empiri-
cal risks to expected risks and, as such, the generalization error of an empirical risk
132 Chapter 4
minimization algorithm /BTERM . Ideally, we would like to make the VC dimension
itself a quantity that can be minimized by a learning algorithm; in particular, if wehave too small a training sample z∈/CImof size mfor too rich a hypothesis space/C0⊆ /CH
/CGhaving VC dimension ϑ/greatermuchm. A minimization of the VC dimension in
parallel to the training error is, however, theoretically not justiﬁed as the VC di-mension is only characterizing the complexity of/C0of empirical risk minimization
algorithms.
One possible method of overcoming this problem is to use the principle
of structural risk minimization (SRM) .B ya structure we mean a set /CB=
{/C01,..., /C0s}ofshypothesis spaces. It is often assumed that /C01⊂···⊂ /C0sand
thus the relation /C0i−1⊂ /C0iimpliesϑ/C0i−1≤ϑ/C0ifor the VC dimensions of /C0i−1
and /C0i. Then the idea of SRM is to compute a setbraceleftbig/BTERM, /C0i(z)∈ /C0ibracerightbigs
i=1of hy-
potheses which minimize the training error Remp [·,z]in the hypothesis space /C0i.
This set is later used to tradeoff the resulting training error Rempbracketleftbig/BTERM, /C0i(z),zbracketrightbig
versus the complexity (measured in terms of VC dimension ϑ/C0i) using the con-
ﬁdence interval (4.14) or (4.15). Clearly we cannot directly apply Theorems 4.7because they assume a ﬁxed hypothesis space. Further, we might have some prior
hope that the minimizer of the expected risk is within equivalence class/C0iwhich
we express by a probability distribution PS. In order to get a theoretically justiﬁed
result we make use of the following lemma which is the basis of multiple testing5.
Lemma 4.14 (Multiple testing) Suppose we are given a set {ϒ1,...ϒ s}of s mea-
surable logic formulas ϒ:uniontext∞
m=1
/CIm× /C6×(0,1]→{true,false}and a discrete
probability measure PSover the sample space {1,..., s}. Let us assume that
∀i∈{1,..., s}:∀m∈ /C6:∀δ∈(0,1]: PZm(ϒi(Z,m,δ))≥1−δ.
Then, for all m ∈ /C6andδ∈(0,1],
PZm(ϒ1(Z,m,δPS(1))∧···∧ϒs(Z,m,δPS(s)))≥1−δ.
Proof The proof is a simple union bound argument. By deﬁnition
PZm(ϒ1(Z,m,δPS(1))∧···∧ϒs(Z,m,δPS(s)))
=1−PZm(¬ϒ1(Z,m,δPS(1))∨···∨¬ ϒs(Z,m,δPS(s)))
≥1−ssummationdisplay
i=1PZm(¬ϒi(Z,m,δPS(i))) (by the union bound )
5 In the theory of multiple statistical tests, the resulting statistical procedure is often called a Bonferroni test.
133 Mathematical Models of Learning
>1−ssummationdisplay
i=1δPS(i)=1−δ. ( by assumption )
The lemma is proved.
This simple lemma is directly applicable to Theorem 4.7 by noticing that for each
training sample size mand for all hypothesis space /C0iin the structure /CBthe
corresponding logic formulas are given by
ϒi(z,m,δ)≡∀ h∈ /C0i:vextendsinglevextendsingleR[h]−Remp [h,z]vextendsinglevextendsingle≤radicalBigg
8
mparenleftbigg
lnparenleftbigg4
δparenrightbigg
+ /BZ/C0i(2m)parenrightbigg
,
ϒi(z,m,δ)≡∀ h∈ /C0i:Remp [h,z]/negationslash=0∨R[h]≤4
mparenleftbigg
lnparenleftbigg2
δparenrightbigg
+ /BZ/C0i(2m)parenrightbigg
,
where the ﬁrst formula is for the VC bound and the second for the PAC bound.
Thus, we know that, with probability at least 1 −δ, simultaneously for all hypothesis
spaces /C0i∈ /CBand all hypotheses h∈ /C0i
R[h]≤Remp [h,z]+radicalBigg
8
mparenleftbigg
lnparenleftbigg4
δparenrightbigg
+lnparenleftbigg1
PS(
/C0i)parenrightbigg
+ /BZ/C0i(2m)parenrightbigg
, (4.20)
and simultaneously for all hypothesis spaces /C0i∈ /CBand all hypotheses h∈ /C0i
achieving zero training error Remp [h,z]=0
R[h]≤4
mparenleftbigg
lnparenleftbigg2
δparenrightbigg
+lnparenleftbigg1
PS(
/C0i)parenrightbigg
+ /BZ/C0i(2m)parenrightbigg
. (4.21)
Apparently, we are able to trade the complexity expressed by /BZ/C0i(2m)against the
training error Remp [h,z](see also Figure 4.4) or we can simply stop increasing
complexity as soon as we have found a hypothesis space /C0icontaining a hypothe-
sis having zero training error at a price of −ln(PS(
/C0i)). Thanks to the exponential
decrease, this price is very small if the number sof hypothesis spaces in /CBis small.
Note that the SRM principle is a curious one: In order to have an algorithm it is
necessary to have a good theoretical bound on the generalization error of the em-
pirical risk minimization method. Another view of the structural risk minimizationprinciple is that it is an attempt to solve the model selection problem. In place ofthe ultimate quantity to be minimized—the expected risk of the learned function/BTERM, /C0i(z)—a (probabilistic) bound on the latter is used, automatically giving a
performance guarantee of the model selection principle itself.
134 Chapter 4
0 5 10 15 200.0 0.1 0.2 0.3 0.4 0.5 0.6
model indextraining/generalization error (bound)bound
VC complexity term
training error
Figure 4.4 Structural risk minimization in action. Here we used hypothesis spaces /C0i
such that ϑ/C0i=iand /C0i⊆ /C0i+1. This implies that the training errors of the empirical
risk minimizers can only be decreasing which leads to the typical situation depicted. Notethat lines are used for visualization purposes because we consider only a ﬁnite set/CBof
hypothesis spaces.
Remark 4.15 (The role of PS)The role of the numbers PS(
/C0i)seems somewhat
counterintuitive as we appear to be able to bias our estimate by adjusting theseparameters. The belief P
Smust, however , be speciﬁed in advance and represents
some apportionment of our conﬁdence to the different points where failure mightoccur . We recover the standard PAC and VC bound if P
Sis peaked at exactly one
hypothesis space. In the ﬁrst work on SRM it was implicitly assumed that these
numbers are1
s. Another interesting aspect of PSis that, thanks to the exponential
term in Theorem 4.7 using a uniform measure PSwe can consider up to /C7(em)
different hypothesis spaces before deteriorating to trivial bounds.
4.3 The Luckiness Framework
Using structural risk minimization we are able to make the complexity, as measured
by the VC dimension of the hypothesis space, a variable of a model selection
135 Mathematical Models of Learning
algorithm while still having guarantees for the expected risks. Nonetheless, we
recall that the decomposition of the hypothesis space must be done independently
of the observed training sample z.This rule certainly limits the applicability of
structural risk minimization to an a-priori complexity penalization strategy. Theresulting bounds effectively ignore the sample z∈/CImexcept with regard to the
training error Remp [
/BT(z),z]. A prominent example of the misuse of structural
risk minimization was the ﬁrst generalization error bounds for the support vectormachine algorithm. It has become commonly accepted that the success of supportvector machines can be explained through the structuring of the hypothesis space/C0of linear classiﬁers in terms of the geometrical margin γz(w)of a linear classiﬁer
having normal vector w(see Deﬁnition 2.30). Obviously, however, the margin itself
is a quantity that strongly depends on the sample zand thus a rigorous application
of structural risk minimization is impossible! Nevertheless, we shall see in thefollowing section that the margin is, in fact, a quantity which allows an algorithmto control its generalization error.
In order to overcome this limitation we will introduce the luckiness framework .
The goals in the luckiness framework are to
1. Formalize under which conditions we can use the training sample z∈/CImto
decompose a given hypothesis space /C0and
2. Provide PAC or VC like results, namely, uniform bounds on the expected risks
that still do not depend on the unknown probability measure PZ.
In contrast to the VC and PAC framework the new uniform bound on the expected
risk R[h]of all hypotheses h∈ /C0is allowed to depend on the training sample z
and the single hypothesis hconsidered6.
Deﬁnition 4.16 (Luckiness generalization error bound) Suppose we are given a
hypothesis space /C0⊆ /CH
/CGand a loss function l : /CH× /CH→ /CA. Then the function
εL: /C6×(0,1]×∪∞
m=1
/CIm× /C0→ /CA+is called a luckiness generalization error
bound if, and only if, for all training sample sizes m ∈ /C6,a l lδ∈(0,1]and all PZ
PZm(∀h∈ /C0:R[h]≤εL(m,δ,Z,h))≥1−δ.
6 Note that a VC and PAC generalization error bound is implicitly dependent on the training error Remp [h,z].
136 Chapter 4
Given such a result we have automatically obtained a bound for the algorithm
which directly minimizes the εL(|z|,δ, z,h), i.e.,/BTεL(z)def=argmin
h∈ /C0εL(|z|,δ, z,h). (4.22)
Note that at present only PAC results for the zero-one loss l0−1are available. Hence
we must assume that, for the training sample z, there exists at least one hypothesis
h∈ /C0such that Remp [h,z]=0.
The additional information we exploit in the case of sample based decomposi-
tions of the hypothesis space /C0is encapsulated in a luckiness function. The main
idea is to ﬁx in advance some assumption about the measure PZ, and encode this
assumption in a real-valued function Ldeﬁned on the space of training samples
z∈ /CImand hypotheses h∈ /C0. The value of the function Lindicates the extent
to which the assumption is satisﬁed for the particular sample and hypothesis. Moreformally, this reads as follows.
Deﬁnition 4.17 (Luckiness function and level) Let/C0⊆ /CH
/CGand /CI= /CG× /CH
be a given hypothesis and sample space, respectively. A luckiness function Li sa
permutation invariant function that maps each training sample zand hypothesis h
to a real value, i.e.,
L:∞uniondisplay
m=1
/CIm× /C0→ /CA.
Given a training sample z=(x,y),t h e level/lscriptLof a function h ∈ /C0relative to L
and zis deﬁned by
/lscriptL(z,h)def=|{(l0−1(g(x1),y1),..., l0−1(g(xm),ym))|g∈H(h,z)}|,
where the set H (h,z)is the subset of all hypotheses which are luckier on z, i.e.,
H(h,z)def={g∈ /C0|L(z,g)≥L(z,h)}⊆ /C0.
The quantity /lscriptLplays the central role in what follows. Intuitively speaking, for
a given training sample zand hypothesis hthe level /lscriptL(z,h)counts the number
of equivalence classes w.r.t. the zero-one loss l0−1in /C0which contain functions
g∈ /C0that are luckier or at least as lucky as h. The main idea of the luckiness
framework is to replace the coarse worst case argument—taking the covering num-
ber /C6/C0as the maximum number of equivalence classes with different losses for
137 Mathematical Models of Learning
an application of the union bound—by an actual sample argument (see Subsection
4.2.1).
Thanks to the symmetrization by a ghost sample we only needed to show
that for zero training error Remp [h,z]=0 on a sample of size m, the training
error on the ghost sample ˜zcannot exceedε
2with high probability and then use
a union bound over all the equivalence classes. As we now want to make use ofthe luckiness L(z,h)for the estimation of the number of equivalence classes,
we have to assume that also the luckiness (and thus the number of equivalenceclasses measured by /lscript
L) cannot increase too much. This is formally expressed in
the following deﬁnition.
Deﬁnition 4.18 (Probable smoothness of luckiness functions) A luckiness func-
tion L is probably smooth with respect to the function ω: /CA×[0,1]→ /C6,i ff o r
all m∈ /C6, all distributions PZand allδ∈[0,1]
PZ2m(∃h∈ /C0:/lscriptL(Z,h)>ω(L((Z1,..., Zm),h),δ))≤δ.
The intuition behind this deﬁnition is that it captures when the luckiness can be
estimated from the training sample (z1,..., zm)∈ /CImwith high probability.
We have to make sure that with small probability (at most δ) over the random
draw of a training and ghost sample there are more than ω(L((z1,..., zm),h),δ)
equivalence classes that contain functions that are luckier than hon the training
and ghost sample (z1,..., zm,zm+1,..., z2m). Now we are ready to give the main
result in the luckiness framework.
Theorem 4.19 (Luckiness bound) Suppose L is a luckiness function that is prob-
ably smooth w.r .t. the function ω. F or any probability measure PZ, any d∈ /C6and
anyδ∈(0,1], with probability at least 1−δover the random draw of the training
sample z∈ /CImof size m, if R emp [h,z]=0andωparenleftbig
L(z,h),δ
4parenrightbig
≤2dthen7
R[h]≤2
mparenleftbigg
d+ldparenleftbigg4
δparenrightbiggparenrightbigg
. (4.23)
The lengthy proof is relegated to Appendix C.3. By the probable smoothness of
L, the value of the function ω(L(z,h),δ/ 4)can never exceed 22mbecause, for
the zero-one loss l0−1, the maximum number /lscriptL(z,h)of equivalence classes on a
sample zof size maximally 2 mis, for any h∈ /C0, at most this number. Hence we
7 Note that the symbol ld denotes the logarithm to base 2 (see also page 331).
138 Chapter 4
can safely apply Lemma 4.14 using the following proposition
∀h∈ /C0:Remp [h,z]/negationslash=0∨ωparenleftbigg
L(z,h),δ
4parenrightbigg
>2i∨R[h]≤2
mparenleftbigg
i+ldparenleftbigg4
δparenrightbiggparenrightbigg
,
which holds with probability at least 1 −δover the random draw of the training
sample z. This means, simultaneously for all functions hwhich achieve zero
training error Remp [h,z]=0a n dω(m,L(z,h),δpd/4)≤2d, we know with
probability at least 1 −δover the random draw of the training sample z∈ /CIm,t h a t
R[h]≤2
mparenleftbigg
d+ldparenleftbigg4
δpdparenrightbiggparenrightbigg
,
where the 2 mnumbers pdmust be positive and sum to one. This result is very
impressive as it allows us to use the training sample z∈ /CImto decompose
the hypothesis space /C0. Such a decomposition is given by the data-dependent
structure /CB={/C01(z),..., /C02m(z)}where /C0i(z)is the set of all hypotheses
which lead to a complexity value ωless than or equal to 2i, i.e.,/C0i(z)=braceleftbigg
h∈ /C0vextendsinglevextendsinglevextendsinglevextendsingleωparenleftbigg
m,L(z,h),δ
4parenrightbigg
≤2ibracerightbigg
⊆ /C0.
We refer to ⌈ld(ω(m,L(z,h),·))⌉as an effective complexity— a complexity
which depends on the data zand is not a-priori ﬁxed. The price we pay for this
generality is the anytime applicability of the bound: There is no guarantee before
we have seen the training sample zthat ld(ω(m,L(z,h),·))will be small for
any hypothesis hwith zero training error Remp [h,z]. As soon as we make use of
z∈ /CImin the luckiness function Lthere will be a distribution PZwhich yields
ω(m,L(z,h),·)>2mfor any consistent hypothesis h∈V/C0(z)and thus we
are unable to give any guarantee on the expected loss of these hypotheses. Such
a distribution corresponds to the maximum violation of our belief in PZencoded
a-priori by the choice of the luckiness function L.
Remark 4.20 (Conditiona l conﬁdence intervals) It is worth mentioning that the
approach taken in the luckiness framework is far from new in classical statistics.The problem of conditional conﬁdence intervals as a branch of classical test theory
is very closely connected to the idea underlying luckiness. The main idea behindconditional conﬁdence intervals is that although a conﬁdence interval procedure/Phi1:/CIm×[0,1]→ /CAhas the property that, for all measures PZ,
∀δ∈[0,1]: PZm(∀h∈ /C0:R[h]∈/Phi1(Z,δ))≥1−δ,
139 Mathematical Models of Learning
there might exist a collection /CIof training samples z∈ /CImsuch that, for all
measures PZ,
∀δ∈[0,1]:∃κ∈[0,1]: PZm|Zm∈ /CI(∀h∈ /C0:R[h]∈/Phi1(Z,δ))≥1−δ−κ.
Such collections /CIare called positively biased relevant collections and can effec-
tively be used to tighten the conﬁdence interval /Phi1if the training sample zis wit-
nessing the prior belief expressed via positively biased relevant collections. Hence
it is necessary to detect if a given training sample zfalls into one of the prese-
lected positively biased relevant collections. The function ωin Deﬁnition 4.18 can
be considered to serve exactly this purpose.
Before ﬁnishing this section we will give two examples of luckiness functions.
For further examples the interested reader is referred to the literature mentioned inSection 4.5.
Example 4.21 (PAC luckiness) In order to show that the luckiness framework is,
in fact, a generalization of the PAC framework we consider the following luckinessfunction L (z,h)=−ϑ/C0whereϑ/C0is the VC dimension of /C0. Then, by the upper
bound given in Theorem A.105, we know that L is probably smooth w.r .t.
ω(L,δ)=parenleftbigg2em
−Lparenrightbigg−L
,
because the number of equivalence classes on a sample of size 2m can never exceed
that number . If we set p i=1if, and only if, i =ϑ/C0we see that, by the luckiness
bound (4.23), simultaneously for all functions h that achieve zero training error
Remp [h,z]=0
R[h]≤2
mparenleftbigg
ϑ/C0ldparenleftbigg2em
ϑ/C0parenrightbigg
+ldparenleftbigg4
δparenrightbiggparenrightbigg
,
which is, up to some constants, the same result as given by (4.15). Note that this
luckiness function totally ignores the sample zas mentioned in the context of the
classical PAC framework.
Example 4.22 (Empirical VC dimension luckiness) Suppose we are given a
training sample z. We deﬁne the empirical VC dimension as the largest natural
number d=ϑ/C0(z)such that there exists a subsetbraceleftbig
zi1,..., zidbracerightbig
⊆{z1,..., zm}
140 Chapter 4
on which the hypotheses h ∈ /C0incur all the 2dloss patterns;
ϑ/C0(z)def= maxbraceleftbig
j∈{1,...,|z|}vextendsinglevextendsingle/C6/C0(z,j)=2jbracerightbig
,/C6/C0(z,j)def= max
˜z⊆z:|˜z|=jvextendsinglevextendsinglebraceleftbigparenleftbig
l0−1(h(˜x1),˜y1),..., l0−1parenleftbig
hparenleftbig
˜xjparenrightbig
,˜yjparenrightbigparenrightbig|h∈ /C0bracerightbigvextendsinglevextendsingle.
Note that the classical VC dimension is obtained if zcontains all points of the
space /CI. Then we show in Appendix C.4 that L (z,h)=−ϑeff(z)is probably
smooth w.r .t. the function
ω(L,δ)=parenleftbiggem
−2L−2l n(δ)parenrightbigg−4L−4l n(δ)
,
for allδ∈bracketleftbig
0,1
2bracketrightbig
. This shows that we can replace the VC dimension ϑ/C0known
before the training sample arrives with the empirical VC dimension ϑ/C0(z)after
having seen the data.
Remark 4.23 (Vanilla luckiness) The main luckiness result as presented in Theo-
rem 4.19 is a simpliﬁed version of the original result. In the full version the notion
of probable smoothness is complicated by allowing the possibility of exclusion of adata-dependent fraction of the double sample before bounding the number of equiv-alence classes of luckier functions H (h,z). As a consequence the data-dependent
fraction is added to the r .h.s. of equation (4.23). Using the more complicated luck-iness result it can be shown that the margin γ
z(w)of a linear classiﬁer parame-
terized by wis a probably smooth luckiness function. However , in the next section
we shall present an analysis for linear classiﬁers in terms of margins which yieldsbetter results than the results in the luckiness framework. It is worth mentioningthat for some distributions the margin γ
z(w)of any classiﬁer h wcan be arbitrarily
small and thus the bound can be worse than the a-priori bounds obtained in theclassical PAC and VC frameworks.
4.4 PAC and VC Frameworks for Real-Valued Classiﬁers
In Section 4.2 we introduced the growth function as a description of the complexityof a hypothesis space/C0when using the zero-one loss l0−1and the empirical risk
minimization principle. This bound is tight as, for each training sample size m∈ /C6,
there exists a data distribution PZfor which the number of equivalence classes
141 Mathematical Models of Learning
equals the number given by the covering number /C6/C0(the exponentiated growth
function). In fact, assuming that this number of equivalence classes is attained bythe sample z
worst , this happens to be the case if PZm(zworst)=1.8
On the other hand, in the case of linear classiﬁers, i.e., x/mapsto→/angbracketleftx,w/angbracketrightwhere
xdef=φ(x)andφ: /CG→ /C3⊆/lscriptn
2(see also Deﬁnition 2.2), it seems plausible that
the margin, that is, the minimal real-valued output before thresholding, provides
conﬁdence about the expected risk. Taking the geometrical picture given in Figure
2.1 on page 23 into account we see that, for a given training sample z∈ /CIm,t h e
covering number /C6/C0on that particular sample is the number of different polyhedra
on the surface of the unit hypersphere. Having attained a functional margin of
˜γz(w)(which equals γz(w)if/bardblw/bardbl=1) when using hw(x)=sign(/angbracketleftx,w/angbracketright)for
classiﬁcation, we know that we can inscribe a ball of radius at least ˜γz(w)in one of
the equivalence classes—the version space (see also Subsection 2.4.3). Intuitivelywe are led to ask “how many equivalence classes can maximally be achieved if we
require the margin to be ˜γ
z(w)beforehand ?”. Ideally, we would like to use this
number in place of the number /C6/C0.T h em a r g i n ˜γz(w)is best viewed as the scale
at which we look on the hypothesis space /BYof real-valued functions. If the margin
is at least γthen two functions are considered to be equivalent if their real-valued
outputs differ by not more than γon the given training sample zbecause they must
correspond to the same classiﬁcation which is carried out by thresholding the real-valued outputs. The scale sensitive version of the covering number/C6/C0when using
real-valued functions f∈ /BYfor classiﬁcation learning is deﬁned as follows.
Deﬁnition 4.24 (Covering number of real-valued functions) Let /BY⊆ /CA
/CGbe a
set of real-valued functions mapping from /CGto /CA. F or a given sample x=
(x1,..., xm)∈ /CGmandγ> 0we deﬁne /C6∞/BY(γ,x)to be the smallest size of a
cover Fγ(x)⊂ /BYsuch that, for every f ∈ /BY, there exists a function ˆfi n t h e
cover F γ(x)with
vextenddoublevextenddoublevextenddoubleparenleftBig
f(x1)−ˆf(x1),..., f(xm)−ˆf(xm)parenrightBigvextenddoublevextenddoublevextenddouble
∞= max
i=1,..., mvextendsinglevextendsinglevextendsinglef(xi)−ˆf(xi)vextendsinglevextendsinglevextendsingle≤γ.
8 Since we already assumed that the training sample zworst is iid w.r.t. a ﬁxed distribution PZ, tightness of the
growth function based bounds is only achieved if
PZm(zworst)=1.
But, if there is only one training sample zworst this is impossible due to the well known “concentration of measure
phenomenon in product spaces” (see Talagrand (1996)).
142 Chapter 4
1.0 1.2 1.4 1.6 1.8 2.0−0.5 0.0 0.5 1.0
xf(x)
−1.0 −0.5 0.0 0.5 1.0−1.0 −0.5 0.0 0.5 1.0
            f (x1)f(x2)
Figure 4.5 (Left) 20 real-valued function (solid lines) together with two training points
x1,x2∈ /CA(crosses). The functions are given by f(x)=α1k(x1,x)+α2k(x2,x)where α
is constrained to fulﬁllvextenddoublevextenddoubleα/primeGαvextenddoublevextenddouble2≤1 (see Deﬁnition 2.15) and ki sg i v e nb yt h eR B Fk e r n e l
(see Table 2.1). (Right) A cover Fγ((x1,x2))for the function class /BY(not the smallest). In
t h es i m p l ec a s eo f m=2 each function f∈ /BYis reduced to two scalars f(x1)and f(x2)
and can therefore be represented as a point in the plane. Each big black dot corresponds
to a function ˆfin the cover Fγ((x1,x2)); all the gray dots in the box of side length 2 γ
correspond to the function covered.
The quantity /C6∞/BY(γ,x)is called the empirical covering number at scale γ.W e
deﬁne the covering number /C6∞/BY(γ,m)at scaleγby/C6∞/BY(γ,m)def= sup
x∈ /CGm
/C6∞/BY(γ,x).
Intuitively, the value /C6∞/BY(γ,x)measures how many “bricks” of side length 2 γwe
need to cover the cloud of points in /CAmgenerated by (f(x1),..., f(xm))over
the choice of f∈ /BY(see Figure 4.5). By deﬁnition, for each m∈ /C6, the covering
number is a function decreasing in γ. By increasing γwe allow the functions
f∈ /BYandˆf∈Fγ(x)to deviate by larger amounts and, thus, a smaller number
of functions may well sufﬁce to cover the set /BY. Further, the covering number/C6∞/BY(γ,m)at scaleγdoes not depend on the sample but only on the sample size
m. This allows us to proceed similarly to a classical PAC analysis. In order to use
this reﬁned covering number /C6∞/BYwe now consider the following event:
143 Mathematical Models of Learning
There exists a function fwthat achieves zero training error Remp [hw,z]on
the sample z∈ /CImand the covering number /C6∞/BY(˜γz(w)/2,2m)at the
measured scale ˜γz(w)/2 is less than 2dbut the expected risk R[hw]offw
exceeds some pre-speciﬁed value ε.
At ﬁrst glance, it may seem odd that we consider only the scale of half the
observed margin ˜γz(w)and a covering number for a double sample of size 2 m.
These are technical requirements which might be resolved using a different provingtechnique. Note that the covering number/C6∞/BY(γ,m)is independent of the sample
z∈ /CImwhich allows us to deﬁne a function9e: /C6→ /CAsuch that
e(d)def=minbraceleftbig
γ∈ /CA+vextendsinglevextendsingle/C6∞/BY(γ,2m)≤2dbracerightbig
⇒ /C6∞/BY(e(d),2m)≤2d,(4.24)
that is, e(d)is the smallest margin which ensures that the covering number/C6∞/BY(e(d),2m)is less than or equal to 2d. Note that we must assume that the
minimum γ∈ /CA+will be attained. Hence, the condition /C6∞/BY(˜γz(w)/2,2m)≤2d
is equivalent to ˜γz(w)≥2·e(d). Now, in order to bound the probability of the
above mentioned event we proceed in a similar manner to the PAC analysis.
1. By the basic lemma C.2 we know that, for all mε> 2,
PZmparenleftbig
∃fw∈ /BY:parenleftbig
Rempbracketleftbig
hw,Zbracketrightbig
=0parenrightbig
∧(R[hw]>ε)∧(˜γZ(w)≥2·e(d))parenrightbig
<2·PZ2m(J(Z)),
where the proposition Jparenleftbig
z˜zparenrightbig
with z,˜z∈ /CImis given by
∃fw∈ /BY:parenleftbig
Remp [hw,z]=0parenrightbig
∧parenleftBig
Rempbracketleftbig
hw,˜zbracketrightbig
>ε
2parenrightBig
∧(˜γz(w)≥2·e(d)).
2. Now we apply a technique known as symmetrization by permutation (see page
291 for more details). The core idea is to make use of the fact that the double
sample z∈ /CI2mis assumed to be an iid sample. Thus, deterministically swapping
the ith pair(xi,yi)∈(z1,..., zm)with(xi+m,yi+m)∈(zm+1,..., z2m)will not
affect the probability of J(Z). As a consequence we can consider the expected
probability of J(z)under the uniform distribution over all 2mdifferent swappings
(represented as binary strings of length m) and then exchange the expectation over
PZ2mand the permutations. This allows us to ﬁxthe double sample z∈ /CI2mand
simply count the number of swappings that satisfy the condition stated by J(Z).
9 This function is also known as the dyadic entropy number (see also Appendix A.3.1).
144 Chapter 4/CT /B4 /CS /B5/BC
/BA/BA
/CU /BE /BY/CM/CU /B4 /DC/BD
/B5 /AL /CT /B4 /CS /B5/CM/CU /B4 /DC/BE
/B5 /BO /CT /B4 /CS /B5/CU /B4 /DC/BE
/B5 /BO /BC
/CU /B4 /DC/BD
/B5 /AL /BE /A1 /CT /B4 /CS /B5/DC/BE
/DC/BD/CM/CU /BE /BY/CT /B4 /CS /B5
/B4/B4 /DC/BD
/BN/DC/BE
/B5/B5 /AQ /BY
Figure 4.6 Relation between the real-valued output of a cover element ˆf∈
Fe(d)((x1,x2))⊆ /BYand the real-valued output of the covered function f∈ /BY. For il-
lustrative purposes we have simpliﬁed to the case of m=1a n d z={(x1,+1),(x2,+1)}.
Note that the distance of the functions is the maximum deviation on the real-valued outputat the two points x
1and x2only and thus at most e(d). By assumption, fcorrectly clas-
siﬁes(x1,+1)with a margin greater than 2 ·e(d)and thusˆf(x1)≥e(d). Similarly, f
incorrectly classiﬁes (x2,+1)and thusˆf(x2)must be strictly less than e(d).
3. For a ﬁxed double sample z=(x,y)∈(
/CG× /CH)2mlet us consider a cover
Fe(d)(x)⊂ /BYat scale e(d). So, for all functions f∈ /BYthere exists a real-valued
functionˆf∈Fe(d)(x)whose real-valued output deviates by at most e(d)from the
real-valued output of fat the double sample x∈ /CG2m. By the margin condition
˜γ(z1,..., zm)(w)≥2·e(d)we know that for all fw∈ /BYwhich achieve zero training
error, Remp [hw,(z1,..., zm)]=0, the corresponding elements ˆfwof the cover
Fe(d)(x)have a real-valued output yiˆfw(xi)on all objects (x1,..., xm)of at least
e(d). Similarly, for all fw∈ /BYthat misclassify points in (zm+1,..., z2m)we know
that their corresponding elements ˆfwof the cover Fe(d)(x)achieve real-valued
outputs yiˆfw(xi)strictly less than e(d)on these points since a misclassiﬁcation
corresponds to a negative output at these points (see Figure 4.6). As a consequence,the probability of J(z)is upper bounded by the fraction of swapping permutations
π:{1,..., 2m}→{1,..., 2m}such that
∃ˆf∈F
e(d)(x):parenleftbigg
min
i=1,..., myπ(i)ˆfparenleftbig
xπ(i)parenrightbig
≥e(d)parenrightbigg
∧ (4.25)
1
mvextendsinglevextendsinglevextendsinglebraceleftBig
yiˆf(xi)<e(d)|i∈{π(m+1),...,π(2m)}bracerightBigvextendsinglevextendsinglevextendsingle>ε
2.
4. Suppose there exists a swapping permutation satisfying the logical formula
(4.25). Then the maximum number of points that can be swapped is m−εm
2because
145 Mathematical Models of Learning
swapping any of theεm
2or more examples (xi,yi)∈(zm+1,..., z2m)for which
yiˆf(xi)<e(d)into the ﬁrst mexamples would violate min i=1,...myπ(i)ˆfparenleftbig
xπ(i)parenrightbig
≥
e(d). Under the uniform distribution over all swappings this probability is less than
2−m·2m−εm
2=2−εm
2. Further, the number of functions ˆf∈Fe(d)(x)considered
is less than or equal to /C6∞/BY(e(d),2m)which by deﬁnition (4.24) is less than or
equal to 2d. Thus for a ﬁxed sample this probability is less than 2d−εm
2. It is worth
noticing that this last step is the point where we use the observed margin ˜γz(w)
to boil down the worst case number /C6/C0(when only considering the binary valued
functions) to the number 2dthat needs to be witnessed by the observed margin
˜γz(w).
Using the fact that for all d∈ /C6+,2d−εm
2≥1 whenever mε≤2, we have shown
the following theorem.
Theorem 4.25 (Covering number bound) Let /BY⊆ /CA
/CGbe a set of real-valued
functions parameterized by w∈ /CF whose associated classiﬁcations are /C0=
{x/mapsto→ sign(f(x))|f∈ /BY}. F or the zero-one loss l 0−1, for all d∈ /C6+andε> 0
PZmparenleftbigg
∃hw∈V/C0(Z):(R[hw]>ε)∧parenleftbigg/C6∞/BYparenleftbigg˜γZ(w)
2,2mparenrightbigg
≤2dparenrightbiggparenrightbigg
<2d+1−εm
2,
where the version space V/C0(z)is deﬁned in Deﬁnition 2.12.
An immediate consequence is, that with probability at least 1 −δover the random
draw of the training sample z∈ /CIm, the following statement ϒi(z,m,δ)is true
∀hw∈V/C0(z):parenleftbigg
R[hw]≤2
mparenleftbigg
i+ldparenleftbigg2
δparenrightbiggparenrightbiggparenrightbigg
∨parenleftbigg/C6∞/BYparenleftbigg˜γz(w)
2,2mparenrightbigg
>2iparenrightbigg
.
Noticing that the bound becomes trivial for i>⌈m/2⌉(because the expected risk is
at most one) we can safely apply the multiple testing lemma 4.14 with uniform PS
over the natural numbers i∈{1,...,⌈m/2⌉}. Thus we have shown the following
powerful corollary of Theorem 4.25.
Corollary 4.26 (Covering number bound) Let /BY⊆ /CA
/CGbe a set of real-valued
functions parameterized by w∈ /CF whose associated classiﬁcations are /C0=
{x/mapsto→ sign(f(x))|f∈ /BY}. F or the zero-one loss l 0−1, for any δ∈(0,1], with
probability at least 1−δover the random draw of the training sample z∈ /CIm,
for all hypotheses h wthat achieve zero training error R emp [hw,z]=0and whose
margin satisﬁes /C6∞/BY(˜γz(w)/2,2m)≤2m
2the expected risk R [hw]is bounded
146 Chapter 4
from above by
R[hw]≤2
mparenleftbiggceilingleftbigg
ldparenleftbigg/C6∞/BYparenleftbigg˜γz(w)
2,2mparenrightbiggparenrightbiggceilingrightbigg
+ld(m)+ldparenleftbigg1
δparenrightbiggparenrightbigg
. (4.26)
Although this result cannot immediately be used to uniformly bound the expected
risk of hwwe see that maximizing the margin ˜γz(w)will minimize the upper bound
on the expected error R[hw]. Thus it justiﬁes the class of large margin algorithms
introduced in Chapter 2.
Remark 4.27 (Bounds using the empirical covering number) By a more care-
ful analysis it is possible to show that we can use the empirical covering number/C6∞/BY(˜γz(w)/2,x)in place of the worst case covering number /C6∞/BY(˜γz(w)/2,2m)
where x∈ /CGmis the observed sample of m inputs. This, however , can only be
achieved at the price of less favorable constants in the bound because we do notobserve a ghost sample and therefore must use the training sample z∈/CImto es-
timate /C6∞/BY(˜γz(w)/2,2m). Further , for practical application of the result, it still
remains to characterize the empirical covering number /C6∞/BY(˜γz(w)/2,x)by an
easy-to-compute quantity of the sample z∈ /CIm.
4.4.1 VC Dimensions for Real-Valued Function Classes
It would be desirable to make practical use of equation (4.26) for bounds similar to
those given by Theorem 4.7. This is not immediately possible, the problem being
determining /C6∞/BYfor the observed margin. This problem is addressed using a one
integer summary which, of course, is now allowed to vary for the different scalesγ. Therefore, this summary is known as generalization of the VC dimension for
real-valued functions.
Deﬁnition 4.28 (VC Dimension of real-valued function classes) Let/BY⊆ /CA
/CG
be a set of real-valued functions from the space /CGto /CA. We say that a sample of
m points x=(x1,..., xm)∈ /CGmisγ–shattered by /BYif there are m real numbers
r1,..., rmsuch that for all 2mdifferent binary vectors y∈{−1,+1}mt h e r ei sa
function f y∈ /BYsatisfying
fy(xi)braceleftbigg
≥ri+γ if y i=+ 1
≤ri−γ if y i=− 1.
147 Mathematical Models of Learning/BC
/CU /B4 /DC /B5/BD/DC/BD
/DC/BE
/DC
/CU/BD
/CU/BE
/CU/BF
/CU/BG
/CU /B4 /DC /B5/BD/AD/B9/BD
/DC
Figure 4.7 (Left) Two points x1and x2on the real line. The set /BYis depicted by the
functions /BY={f1,..., f4}.(Right) The maximum γ≈0.37 (vertical bar) we can
consider for γ-shattering is quite large as we can shift the functions /BYby different values
r1and r2for x1and x2, respectively. The shifted set /BY−r2for x2is shown by dashed
lines. Note that f1−ri,f2−ri,f3−riand f4−rirealize y=(−1,−1),y=(−1,+1),
y=(+1,−1)and y=(+1,+1), respectively.
The fat shattering dimension fat/BY: /CA+→ /C6maps a value γ∈ /CA+to the size of
the largest γ–shattered set, if this is ﬁnite, or inﬁnity otherwise.
In order to see that the fat shattering dimension is clearly a generalization of the VC
dimension we note that, for γ→ 0, the fat shattering dimension lim γ→0fat/BY(γ)
equals the VC dimension ϑ/C0of the thresholded set /C0={sign(f)|f∈ /BY}of
binary classiﬁers. By using the scale parameter γ∈ /CA+we are able to study the
complexity of a set of real-valued functions proposed for binary classiﬁcation ata much ﬁner scale (see also Figure 4.7). Another advantage of this dimension isthat, similarly to the VC and PAC theory presented in Section 4.2, we can use itto bound the only quantity entering the bound (4.26)—the log-covering numberldparenleftbig/C6∞/BY(˜γz(w)/2,2m)parenrightbig
. In 1997, Alon et al. proved the following lemma as a
byproduct of a more general result regarding the characterization of Glivenko-Cantelli classes.
Lemma 4.29 (Bound on the covering number) Let/BY⊆ /CA
/CGbe a set of functions
from /CGto the closed interval [a,b]. F or all m∈ /C6and anyγ∈(a,b)such that
d=fat/BYparenleftbigγ
4parenrightbig
≤m,
ldparenleftbig/C6∞/BY(γ,m)parenrightbig
≤1+d·ldparenleftbigg2em(b−a)
dγparenrightbigg
ldparenleftBigg
4m(b−a)2
γ2parenrightBigg
.
148 Chapter 4
This bound is very similar to the bound presented in Theorem 4.10. The VC dimen-
sionϑ/C0has been replaced by the corresponding value fat/BY(γ)of the fat shattering
dimension. The most important difference is the additional ldparenleftbig
4m(b−a)2/γ2parenrightbig
term the necessity of which is still an open question in learning theory. The lemma
is not directly applicable to the general case of real-valued functions f∈ /BYbe-
cause these may be unbounded. Thus the idea is to truncate the functions into a
range [−τ,+τ]by the application of a truncation operator T τ,i.e.,
Tτ(
/BY)def={Tτ(f)|f∈ /BY}, Tτ(f)(x)def=

τ iff(x)>τ
f(x) if−τ≤f(x)≤τ
−τ iff(x)<−τ.
Obviously, for all possible scales γ∈ /CA+we know that the fat shattering dimen-
sion fat Tτ( /BY)(γ)of the truncated set of functions is less than or equal to the fat
shattering dimension fat/BY(γ)of the non-truncated set /BYsince every sample that
isγ–shattered by Tτ(
/BY)can beγ–shattered by /BY, trivially, using the same but
nontruncated functions. As a consequence we know that, for any value τ∈ /CA+we
might use for truncation, it holds that the log-covering number of the truncated set
Tτ(
/BY)of functions can be bounded in terms of the fat shattering dimension of /BY
and the value of τ
ldparenleftbig/C6∞
Tτ( /BY)(γ,m)parenrightbig
≤1+fat/BYparenleftBigγ
4parenrightBig
ldparenleftBigg
4emτ
fat/BYparenleftbigγ
4parenrightbig
·γparenrightBigg
ldparenleftbigg16mτ2
γ2parenrightbigg
.
In addition we know that, regardless of the value of τ∈ /CA+, the function Tτ(f)
performs the same classiﬁcation as f, i.e., for any training sample z∈ /CImand all
functions f∈ /BY
Rbracketleftbig
sign(f)bracketrightbig
=Rbracketleftbig
sign(Tτ(f))bracketrightbig
,Rempbracketleftbig
sign(f),zbracketrightbig
=Rempbracketleftbig
sign(Tτ(f)),zbracketrightbig
.
Using these two facts we aim to replace the log-covering number of the function
class /BYby the log-covering number ld ( /C6∞
Tτ( /BY)(˜γz(w)/2,2m))of the set Tτ(
/BY)of
truncated real-valued functions. Note that τ∈ /CA+must be chosen independently
of the training sample z∈ /CIm. In order to achieve this we consider the following
well deﬁned function ˜e: /C6→ /CA
˜e(d)def=minbraceleftBig
γ∈ /CA+vextendsinglevextendsinglevextendsingle
/C6∞
Tγ( /BY)(γ,2m)≤2dbracerightBig
⇒ /C6T˜e(d)( /BY)(˜e(d),2m)≤2d,
in place of the dyadic entropy number considered given in equation (4.24). By
deﬁnition, whenever /C6∞
T˜e(d)( /BY)(˜γz(w)/2,2m)≤2dit must follow that ˜γz(w)≥
2·˜e(d)which, together with Lemma 4.29, implies that the log-covering number
149 Mathematical Models of Learning
ld( /C6∞
T˜e(d)( /BY)(˜γz(w)/2,2m))cannot exceed
1+fat/BYparenleftbigg˜γz(w)
8parenrightbigg
ld
8em·˜e(d)
fat/BYparenleftBig
˜γz(w)
8parenrightBig
·˜γz(w)
2
ld
32m·(˜e(d))2
parenleftBig
˜γz(w)
2parenrightBig2

≤1+fat/BYparenleftbigg˜γz(w)
8parenrightbigg
ldparenleftbigg8em
fat/BY(˜γz(w)/8)parenrightbigg
ld(32m)
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
b(˜γz(w)).
In other words, by Lemma 4.29 we know that whenever the training sample z∈ /CIm
and the weight vector w∈ /C3under consideration satisfy b(˜γz(w))≤dthen
the log-covering number ld ( /C6∞
T˜e(d)( /BY)(˜γz(w)/2,2m))is upper bounded by d.B y
Theorem 4.25 it follows that, with probability at least 1 −δover the random draw
of the training sample z∈ /CIm, the statement
ϒi(z,m,δ)≡∀ hw∈V/C0(z):(b(˜γz(w))>i)∨parenleftbigg
R[hw]≤2
mparenleftbigg
i+ldparenleftbigg2
δparenrightbiggparenrightbiggparenrightbigg
is true. As a consequence, stratifying over theceilingleftbigm
2ceilingrightbig
different natural numbers i
using the multiple testing lemma 4.14 and a uniform PSgives Theorem 4.30.
Notice that by the assumptions of Lemma 4.29 the margin ˜γz(w)must be such
that fat/BY(˜γz(w)/8)is less than or equal to 2 m.
Theorem 4.30 (Fat shattering bound) Let /BY⊆ /CA
/CGbe a set of real-valued
functions parameterized by w∈ /CF whose associated classiﬁcations are /C0=
{x/mapsto→ sign(f(x))|f∈ /BY}. F or the zero-one loss l 0−1, for any δ∈(0,1], with
probability at least 1−δover the random draw of the training sample z∈ /CIm,
for all hypotheses h wthat achieve zero training error R emp [hw,z]=0and whose
margin˜γz(w)satisﬁesϑeff=fat/BY(˜γz(w)/8)≤2m the expected risk R [hw]is
bounded from above by
R[hw]≤2
mparenleftbiggceilingleftbigg
ϑeffldparenleftbigg8em
ϑeffparenrightbigg
ld(32m)ceilingrightbigg
+ld(m)+ldparenleftbigg2
δparenrightbiggparenrightbigg
. (4.27)
Ignoring constants, it is worth noticing that compared to the original PAC bound
given by equation (4.15) we have an additional ld (32m)factor in the complexity
term of equation (4.27) which is due to the extra term in Lemma 4.29. Note that incontrast to the classical PAC result, we do not know beforehand that the margin—
150 Chapter 4
whose fat shattering dimension replaces the VC dimension —will be large. As such,
we call this bound an a-posteriori bound .
4.4.2 The PAC Margin Bound
Using Lemma 4.29 we reduced the problem of bounding the covering number /C6∞/BY
to the problem of bounding the fat shattering dimension. If we restrict ourselves
to linear classiﬁers in a feature space /C3we have the following result on the fat
shattering dimension.
Lemma 4.31 (Fat shattering bound for linear classiﬁers) Suppose that X =
{x∈ /C3|/bardblx/bardbl≤ς}is a ball of radius ςin an inner product space /C3and con-
sider the linear classiﬁers/BY={x/mapsto→/angbracketleftw,x/angbracketright|/bardbl w/bardbl≤B,x∈X}
with norm bounded by B. Then
fat/BY(γ)≤parenleftbiggBς
γparenrightbigg2
. (4.28)
The proof can be found in Appendix C.5. In terms of Figure 2.6 we see that (4.28)
has an intuitive interpretation: The complexity measured by fat/BYat scaleγmust
be viewed with respect to the total extent of the data. If the margin has a small
absolute value, its effective incurred complexity is large only if the extent of the
data is large. Thus, for linear classiﬁers, the geometrical margin10γz(w)itself does
not provide any measure of the complexity without considering the total extent ofthe data. Combining Lemma 4.31 with the bound given in Theorem 4.30 we obtaina practically useful result for the expected risk of linear classiﬁers in terms of theobserved margin. Note that we must ensure that fat/BY(γz(w)/8)is at most 2 m.
Theorem 4.32 (PAC Margin bound) Suppose /C3is a given feature space. F or all
probability measures PZsuch that PX({x|/bardblφ(x)/bardbl≤ς})=1, for anyδ∈(0,1],
with probability at least 1−δover the random draw of the training sample z∈ /CIm,
if we succeed in correctly classifying m samples zwith a linear classiﬁer f whaving
a geometrical margin γz(w)of at least√
32/mς, then the expected risk R [hw]of
10 Note that for /bardblw/bardbl=1 functional margin ˜γz(w)and geometrical margin γz(w)coincide.
151 Mathematical Models of Learning
hww.r .t. the zero-one loss l 0−1is bounded from above by
2
mparenleftBiggceilingleftBigg
64ς2
(γz(w))2ldparenleftBigg
(γz(w))2em
8ς2parenrightBigg
ld(32m)ceilingrightBigg
+ldparenleftbigg2m
δparenrightbiggparenrightBigg
. (4.29)
This result is the theoretical basis of the class of large margin algorithms as it
directly allows us to make use of the attained geometrical margin γz(w)for giving
bounds on the expected risk R[hw]of a linear classiﬁers. An appealing feature
of the result is the subsequent capability of obtaining nontrivial bounds on theexpected risk even when the number nof dimensions of feature space is much
larger than the number mof training examples. Whilst this is impossible to achieve
in the parametric statistics approach we see that by directly studying the expected
risk we are able to defy the curse of dimensionality.
Remark 4.33 (Sufﬁcient training sample size) At ﬁrst glance the bound (4.29)
might represent progress. We must recall, however , that the theorem requiresthat the attained margin γ
z(w)satisﬁes m (γz(w))2/ς2≥ 32. Noticing that
(ς/γ z(w))2c a nb ev i e w e da sa n effective VC dimension ϑeffwe see that this is
equivalent to assuming thatm
deff≥32—the rule of thumb already given by V apnik!
However , calculating the minimum training sample size m for a given margin com-plexityϑ
eff=(ς/γ z(w))2, we see that equation (4.29) becomes nontrivial, i.e., less
than one, only for astronomically large values of m, e.g., m >34 816 forϑeff=1
(see Figure 4.8). Thus it can be argued that Theorem 4.32 is more a qualitative
justiﬁcation of large margin algorithms than a practically useful result. We shall
see in Section 5.1 that a conceptually different analysis leads to a similar boundfor linear classiﬁers which is much more practically useful.
4.4.3 Robust Margin Bounds
A major drawback of the margin bound given by Theorem 4.32 is its sensitivityto a few training examples (x
i,yi)∈z∈ /CImfor which the margin γi(w)of a
linear classiﬁer hwmay be small. In the extreme case we can imagine a situation
in which the ﬁrst m−1 training examples from zare correctly classiﬁed with a
maximum margin of γi(w)=ςbut the last observation has γm(w)=0. It does
not seem plausible that this single point has such a large impact on the expectedrisk of h
wthat we are unable to give any guarantee on the expected risk R[hw].
Algorithmically we have already seen that this difﬁculty can easily be overcome bythe introduction of soft margins (see Subsection 2.4.2). As a consequence, Shawe-
152 Chapter 4
2468 1 01e+05 2e+05 3e+05 4e+05
margin complexityminimal training set size
Figure 4.8 Minimal training sample size as a function of the margin complexity ς2/γ2
such that equation (4.29) becomes less than the one (ignoring the ld (2/δ)term due to the
astronomically large values of m).
Taylor and Cristianini called the existing margin bound “nonrobust”. The core
idea involved in making the margin bound (4.29) “robust” is to construct an inner
product space tildewide/C3from a given feature space /C3⊆/lscriptn
2such that, for a linear classiﬁer
hwthat fails to achieve only positive margins γi(w)on the training sample z,w e
can ﬁnd a corresponding linear classiﬁer h˜win the inner product space tildewide/C3achieving
a positive margin γz(tildewidew)on the mapped training sample whilst yielding the same
classiﬁcation as hwfor all unseen test objects. One way to achieve this is as follows:
1. Based on the given input space /CGand the feature space /C3with the associated
mapping φ: /CG→ /C3for each training sample size mwe set up a new inner product
space
tildewide/C3def= /C3×braceleftBiggjsummationdisplay
i=1Ixivextendsinglevextendsinglej∈{1,..., m},parenleftbig
x1,..., xjparenrightbig
∈ /CGjbracerightBigg
endowed with the following inner product11
/angbracketleft(w,f),(x,g)/angbracketrighttildewide/C3def=/angbracketleftw,x/angbracketright/C3+integraldisplay
f(x)g(x)dx, (4.30)
where the second term on the r.h.s. of (4.30) is well deﬁned because we only
consider functions that are non-zero on ﬁnitely many (at most m) points. The
inner product space tildewide/C3can be set up independently of a training sample z.G i v e na
positive value /Delta1> 0, each point xi∈xis mapped to tildewide/C3byτ/Delta1(xi)def=parenleftbig
xi,/Delta1Ixiparenrightbig
.
11 For the sake of clarity, we use a subscript on inner products /angbracketleft·,·/angbracketright/C3in this subsection.
153 Mathematical Models of Learning
2. For a given linear classiﬁer parameterized via its normal vector w∈ /C3we
deﬁne a mapping ω/Delta1,γ: /C3→tildewide/C3such that the minimum real-valued output (the
functional margin) is at least γ∈ /CA+, i.e.,
min
i=1,..., myiangbracketleftbig
ω/Delta1,γ(w),τ/Delta1(xi)angbracketrightbig
tildewide/C3≥γ> 0.
This can be achieved by the following mapping
ω/Delta1,γ(w)def=parenleftBigg
w,1
/Delta1summationdisplay
(xi,yi)∈zyi·d((xi,yi),w,γ)·IxiparenrightBigg
,
d((x,y),w,γ)def= max{0,γ−y/angbracketleftw,x/angbracketright/C3},
where d((x,y),w,γ)measures how much wfails at(x,y)∈ /CIto achieve a
functional margin ofγ. Using equation (4.30) for each pointparenleftbig
xj,yjparenrightbig
∈zin the
training sample it follows that the real-valued output in the new inner product space
tildewide/C3is at least γ
yjangbracketleftbig
ω/Delta1,γ(w),τ/Delta1parenleftbig
xjparenrightbigangbracketrightbig
tildewide/C3= yjangbracketleftbig
w,xjangbracketrightbig/C3+yjsummationdisplay
(xi,yi)∈zyi·d((xi,yi),w,γ)·IxiIxj
= yjangbracketleftbig
w,xjangbracketrightbig/C3+dparenleftbigparenleftbig
xj,yjparenrightbig
,w,γparenrightbig
≥ yjangbracketleftbig
w,xjangbracketrightbig/C3+γ−yjangbracketleftbig
w,xjangbracketrightbig/C3=γ.
Further, for each example (x,y)/∈znot contained in the training sample we see
that the real-valued output of the classiﬁer ω/Delta1,γ(w)equals the real-valued output
of the unmodiﬁed weight vector w, i.e.,
yangbracketleftbig
ω/Delta1,γ(w),τ/Delta1(x)angbracketrightbig
tildewide/C3= y/angbracketleftw,x/angbracketright/C3+ysummationdisplay
(xi,yi)∈zyi·d((xi,yi),w,γ)·IxiIx
= y/angbracketleftw,x/angbracketright/C3.
Hence we can use ω/Delta1,γ(w)to characterize the expected risk of wb u ta tt h es a m e
time exploit the fact that ω/Delta1,γ(w)achieves margin of at least γin the inner product
space.
3. Let us assume that PZis such that PX({x∈ /CG|/bardblx/bardbl/C3≤ς})=1. In order to
apply Theorem 4.32 for ω/Delta1,γ(w)and the set{τ/Delta1(x)|x∈ /CG}we notice that, for
ag i v e nv a l u eo f γand/Delta1,
154 Chapter 4
(a) the geometrical margin of ω/Delta1,γ(w)is at leastangbracketleftbig
ω/Delta1,γ(w),τ/Delta1parenleftbig
xjparenrightbigangbracketrightbig
tildewide/C3
vextenddoublevextenddoubleω/Delta1,γ(w)vextenddoublevextenddoubletildewide/C3≥γ
radicalbigg
/bardblw/bardbl2/C3+parenleftBig
D(z,w,γ)
/Delta1parenrightBig2,
where
D(z,w,γ)def=radicalBigg
summationdisplay
(xi,yi)∈z(d((xi,yi),w,γ))2. (4.31)
Note that (D(z,w,1))2exactly captures the squared sum of the slack variables
in the soft margin support vector machine algorithm given by (2.49).
(b) all mapped points are contained in a ball of radiusradicalbig
ς2+/Delta12because
∀x∈ /CG:/bardblτ/Delta1(x)/bardbl2
tildewide/C3=/bardblx/bardbl2/C3+/Delta12≤ς2+/Delta12.
Thus by an application of Lemma 4.31 to a classiﬁer ω/Delta1,γ(w)we have shown the
following lemma12.
Lemma 4.34 (Margin distribution) Suppose /C3is a given feature space. F or all
/Delta1> 0, for all probability measures PZsuch that PX({x∈ /CG|/bardblx/bardbl/C3≤ς})=1,
for anyδ∈(0,1], with probability at least 1−δover the random draw of the
training sample z∈ /CIm, for allγ∈(0,ς]the expected risk R [hw]of a linear
classiﬁer h ww.r .t. the zero-one loss l 0−1is bounded from above by
R[hw]≤2
mparenleftbiggceilingleftbigg
deff(/Delta1)ldparenleftbigg8em
deff(/Delta1)parenrightbigg
ld(32m)ceilingrightbigg
+ldparenleftbigg2m
δparenrightbiggparenrightbigg
,
where
deff(/Delta1)=64parenleftbigg
/bardblw/bardbl2/C3+parenleftBig
D(z,w,γ)
/Delta1parenrightBig2parenrightbiggparenleftbig
ς2+/Delta12parenrightbig
γ2(4.32)
must obey d eff(/Delta1)≤2m.
Note that the term D(z,w,γ)given in equation (4.31) is not invariant under
rescaling of w. For a ﬁxed value of γincreasing the norm /bardblw/bardbl/C3ofwcan only
lead to a decrease in the term D(z,w,γ). Thus, without loss of generality, we will
ﬁx/bardblw/bardbl/C3=1 in the following exposition.
12 With a slight lack of rigor we omitted the condition that there is no discrete probability PZon misclassiﬁed
training examples because ω/Delta1,γ(w)characterizes wonly at non-training examples.
155 Mathematical Models of Learning
Unfortunately, Lemma 4.34 is not directly applicable to obtaining a useful
bound on the expected risk in terms of the margin distribution (measured by
D(z,w,γ)) as we are required to ﬁx /Delta1in advance. The way to overcome this
problem is to apply Lemma 4.14 for different values of /Delta1. By Lemma 4.34 we
know that, with probability at least 1 −δover the random draw of the training
sample z∈ /CIm, the following statement is true
ϒi(z,m,δ)≡∀ w∈ /C3:(deff(/Delta1i)>2m)∨parenleftbigg
R[hw]≤2
mparenleftbiggceilingleftbigg
deff(/Delta1i)ldparenleftbigg8em
deff(/Delta1i)parenrightbigg
ld(32m)ceilingrightbigg
+ldparenleftbigg2m
δparenrightbiggparenrightbiggparenrightbigg
.
In Appendix C.6 we give an explicit sequence of /Delta1ivalues which proves the ﬁnal
margin distribution bound.
Theorem 4.35 (Robust margin bound) Suppose /C3⊆/lscriptn
2is a given feature space.
F or all probability measures PZsuch that PX({x∈ /CG|/bardblx/bardbl/C3≤ς})=1, for any
δ∈(0,1], with probability at least 1−δover the random draw of the training
sample z∈ /CIm, for allγ∈(0,ς]the expected risk R [hw]w.r .t. the zero-one loss
l0−1of a linear classiﬁer h wwith/bardblw/bardbl/C3=1is bounded from above by
R[hw]≤2
mparenleftbiggceilingleftbigg
deffldparenleftbigg8em
deffparenrightbigg
ld(32m)ceilingrightbigg
+ldparenleftbigg(16+ld(m))m
δparenrightbiggparenrightbigg
, (4.33)
where
deff=65(ς+3D(z,w,γ))2
γ2
must obey d eff≤2m.
Note that, by application of Lemma 4.14, we only gain an additional summand of
3+ldparenleftbig
ldparenleftbig√
mparenrightbigparenrightbig
in the numerator of equation (4.33). Coming back to our initial
example we see that, in the case of m−1 examples correctly classiﬁed with a
(maximum) geometrical margin of γi(w)=ςand the mth example misclassiﬁed
by a geometrical margin of 0, Theorem 4.35 gives us an effective dimensionalityd
effof 65·16=1040 and thus, for sufﬁciently large training sample size m,
we will get a nontrivial bound on the expected risk R[hw]ofhwalthough hw
admits training errors. Note, however, that the result is again more a qualitative
justiﬁcation of soft margins as introduced in Subsection 2.4.2 rather than beingpractically useful (see also Remark 4.33). This, however, is merely due to the fact
156 Chapter 4
that we set up the “robustness” trick on top of the fat shattering bound given in
Theorem 4.30.
Remark 4.36 (Justiﬁcation of soft margin support vector machines) One of the
motivations for studying robust margin bounds is to show that the soft marginheuristic introduced for support vector machines has a ﬁrm theoretical basis. Inorder to see this we note that in the soft margin case the norm /bardblw/bardbl/C3of the re-
sulting classiﬁer is not of unit length as we ﬁxed the functional margin to be one.Therefore, we consider the case of γ=
1
/bardblw/bardbl/C3and wnorm=w
/bardblw/bardbl/C3which gives
parenleftbigg
Dparenleftbigg
z,wnorm,1
/bardblw/bardbl/C3parenrightbiggparenrightbigg2
=msummationdisplay
i=1parenleftbigg
maxbraceleftbigg
0,1
/bardblw/bardbl/C3−yiangbracketleftbiggw
/bardblw/bardbl/C3,xiangbracketrightbigg/C3bracerightbiggparenrightbigg2
=1
/bardblw/bardbl2/C3msummationdisplay
i=1(max{0,(1−yi/angbracketleftw,xi/angbracketright/C3)})2
=1
/bardblw/bardbl2/C3msummationdisplay
i=1lquad(/angbracketleftw,xi/angbracketright/C3,yi)=1
/bardblw/bardbl2/C3msummationdisplay
i=1ξ2
i,
according to the slack variables ξiintroduced in equation (2.48) and (2.49). F or
the effective dimensionality d effit follows
deff= 65/bardblw/bardbl2/C3
ς+3
/bardblw/bardbl/C3radicaltpradicalvertexradicalvertexradicalbt
msummationdisplay
i=1ξ2
i
2
=65parenleftbig
ς/bardblw/bardbl/C3+3/bardblξ/bardbl2parenrightbig2(4.34)
≤ 65parenleftbig
ς/bardblw/bardbl/C3+3/bardblξ/bardbl1parenrightbig2, (4.35)
where we use the fact that /bardblξ/bardbl2≤/bardblξ/bardbl1. Since by the assumption that ξi>0we
know/bardblξ/bardbl1=summationtextm
i=1ξiand, thus, equation (4.35) and (4.34) are somewhat similar
to the objective function minimized by the optimization problems (2.48) and (2.49).
Application to Adaptive Margin Machines
In Section 2.5 we have introduced adaptive margin machines as a fairly robustlearning algorithm. In this subsection we show that a straightforward applicationof the margin distribution bound (4.33) reveals that the algorithm aims to mini-mize effective complexity although no direct margin maximization appears to be
included in the objective function (2.57). The key fact we exploit is that, due to the
157 Mathematical Models of Learning
constraints (2.58), we know, for each feasible solution αandξ,
∀i∈{1,..., m}: yimsummationdisplay
j=1αjyjangbracketleftbig
xj,xiangbracketrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
/angbracketleftw,xi/angbracketright≥1−ξi+λα ik(xi,xi)
which readily implies
∀i∈{1,..., m}: 1−/angbracketleftw,xi/angbracketright≤ξi−λα ik(xi,xi),
∀i∈{1,..., m}: max{0,1−/angbracketleftw,xi/angbracketright}≤ max{0,ξi−λα ik(xi,xi)}.(4.36)
Now for any linear classiﬁer parameterized by wlet us apply Theorem 4.35 with
wnorm=w
/bardblw/bardblandγ=1
/bardblw/bardbl. The resulting effective complexity measured by deffis
then given by
deff= 65/bardblw/bardbl2
ς+3radicaltpradicalvertexradicalvertexradicalbt
msummationdisplay
i=1parenleftbigg
maxbraceleftbigg
0,1
/bardblw/bardbl−yiangbracketleftbiggw
/bardblw/bardbl,xiangbracketrightbiggbracerightbiggparenrightbigg2
2
= 65
ς/bardblw/bardbl+3radicaltpradicalvertexradicalvertexradicalbt
msummationdisplay
i=1(max{0,1−yi/angbracketleftw,xi/angbracketright})2
2
. (4.37)
Combining equation (4.36) and (4.37) we have shown the following theorem for
adaptive margin machines.
Theorem 4.37 (Adaptive margin machines bound) Suppose /C3⊆/lscriptn
2is a given
feature space. F or all probability measures PZsuch that PX(/bardblφ(X)/bardbl≤ς)=1,f o r
anyδ∈(0,1], with probability at least 1−δover the random draw of the training
sample z, for all feasible solutions α≥0andξ≥0of the linear program (2.57)–
(2.58) the expected risk R [hw]w.r .t. the zero-one loss l 0−1of the corresponding
linear classiﬁer w=summationtextm
i=1αiyixiis bounded from above by
R[hw]≤2
mparenleftbiggceilingleftbigg
deffldparenleftbigg8em
deffparenrightbigg
ld(32m)ceilingrightbigg
+ldparenleftbigg(16+ld(m))m
δparenrightbiggparenrightbigg
,
where d eff≤2m with
deff=65parenleftBigg
ς/bardblw/bardbl+3msummationdisplay
i=1max{0,ξi−λα ik(xi,xi)}parenrightBigg2
. (4.38)
158 Chapter 4
Proof The proof is an immediate consequence of Theorem 4.35, equation (4.36)
and equation (4.37) using the fact that the max function in the inner sum alwaysreturns positive numbers c
iand hence
radicaltpradicalvertexradicalvertexradicalbt
msummationdisplay
i=1c2
i≤radicaltpradicalvertexradicalvertexradicalbt
parenleftBiggmsummationdisplay
i=1ciparenrightBigg2
=msummationdisplay
i=1ci.
The theorem is proved.
From this theorem we can get the following insight: As both the vector αof the
expansion coefﬁcients and the vector ξof the slack variables must be positive,
the effective dimensionality deffis minimized whenever ξi<λ α ik(xi,xi).L e tu s
consider a ﬁxed value of λand a ﬁxed linear classiﬁer parameterized by α.T h e n
the algorithm given by equations (2.57)–(2.58) aims to minimize the sum of theξ
i’s which, by equation (4.38), will minimize the resulting effective complexity of
α. The amount by which this will inﬂuence deffis controlled via λ, i.e., for small
values of λ(no regularization) the impact is very large whereas for λ→∞ (total
regularization) the minimization ofsummationtextm
i=1ξihas no further impact on the effective
complexity.
4.5 Bibliographical Remarks
This chapter reviewed different mathematical models for learning. We demon-strated that classical statistical analysis is not suited for the purpose of learningbecause it studies the convergence of probability measures (see Billingsley (1968),Pollard (1984) and Amari (1985)) and thus leads to observations such as the “curseof dimensionality” (Bellman 1961). Further, classical statistical results often have
to assume the “correctness” of the probabilistic model which is essential for the
maximum likelihood method to provide good convergence results (see Devroyeet al. (1996, Chapters 15, 16) for a discussion with some pessimistic results). Incontrast, it has been suggested that studying convergence of risks directly is prefer-able (see V apnik and Chervonenkis (1971), V apnik (1982), Kearns and V azirani(1994), Devroye et al. (1996), Vidyasagar (1997), Anthony (1997), V apnik (1998)and Anthony and Bartlett (1999)). In the case of empirical risk minimization algo-rithms this has resulted in the so-called VC and PAC framework. The PAC frame-work was introduced 1984 in the seminal paper of V aliant (1984) in which hespecializes the general question of convergence of expected risks to the problem
159 Mathematical Models of Learning
of learning logic formulas assuming that the hypothesis space /C0contains the tar-
get formula. Hence all uncertainty is due to the unknown input distribution13PX.
The restriction to logic formulas also simpliﬁed the matter because the number ofhypotheses then becomes ﬁnite even though it grows exponentially in the numberof binary features. Since then a number of generalizations have been proposed bydropping the assumption of ﬁnite hypothesis spaces and realizability , i.e., the “or-
acle” draws its target hypothesis h
∗from the hypothesis space /C0which we use
for learning (see Blumer et al. (1989) and Anthony (1997) for a comprehensiveoverview). The latter generalization became known as the agnostic PAC frame-
work (Kearns et al. 1992). Though we have ignored computational complexity and
computability aspects, the PAC model in its pure form is also concerned with thesequestions.
Apart from these developments, V . V apnik and A. Chervonenkis already studied
the general convergence question in the late 1960s. In honor of them, their frame-work is now known as the VC (V apnik-Chervonenkis) framework. They showedthat the convergence of expected risks is equivalent to the uniform convergenceof frequencies to probabilities over a ﬁxed set of events (V apnik and Chervo-nenkis 1991) (see V apnik (1998, Chapter 16) for a deﬁnition of “nontrivial” hy-pothesis spaces and Bartlett et al. (1996) for a constructive example). This equiv-alence is known as the key theorem in learning theory. The answer to a particular
case of this problem was already available through the Glivenko-Cantelli lemma(Glivenko 1933; Cantelli 1933) which says that the empirical distribution functionof a one dimensional random variable converges uniformly to the true distribution
function in probability. The rate of convergence was proven for the ﬁrst time in
Kolmogorov (1933). V apnik and Chervonenkis generalized the problem and askedthemselves which property a set of events must share such that this convergencestill takes place. As a consequence, these sets of events are known as Glivenko-Cantelli classes. In 1987, M. Talagrand obtained the general answer to the problemof identifying Glivenko-Cantelli classes (Talagrand 1987). Ten years later this re-sult was independently rediscovered by Alon et al. (1997). It is worth mentioningthat most of the results in the PAC framework are particular cases of more generalresults already obtained by V apnik and coworkers two decades before.
The main VC and PAC bounds given in equations (4.11) and (4.12) were ﬁrst
proven in V apnik and Chervonenkis (1974) and effectively differ by the exponentat the deviation of ε. In V apnik (1982, Theorem 6.8) it is shown that this expo-
nent continously varies from 2 to 1 w.r.t. the smallest achievable expected risk
13 In the original work of V aliant he used the term oracle to refer to the PX.
160 Chapter 4
inf h∈ /C0R[h](see also Lee et al. (1998) for tighter results in the special case of
convex hypothesis spaces). The VC and PAC analysis revealed that, for the caseof learning, the growth function of a hypothesis space is an appropriate a-priorimeasure of its complexity. As the growth function is very difﬁcult to compute,it is often characterized by a one-integer summary known as VC dimension (seeTheorem 4.10 and Sontag (1998) for an excellent survey of the VC dimension).The ﬁrst proof of this theorem is due to V apnik and Chervonenkis (1971) and wasdiscovered independently in Sauer (1972) and Shelah (1972); the former creditsErdös with posing it as a conjecture. In order to make the VC dimension a vari-
able of the learning algorithm itself two conceptually different approaches were
presented: By deﬁning an a-priori structuring of the hypothesis space—sometimesalso referred to as a decomposition of the hypothesis space/C0(Shawe-Taylor et al.
1998)—it is possible to provide guarantees for the generalization error with highconﬁdence by sharing the conﬁdence among the different hypothesis spaces. Thisprinciple, known as structural risk minimization, is due to V apnik and Chervo-nenkis (1974). A more promising approach is to deﬁne an effective complexity viaa luckiness function which encodes some prior hope about the learning problemgiven by the unknown P
Z. This framework, also termed the luckiness framework is
due to Shawe-Taylor et al. (1998). For more details on the related problem of con-ditional conﬁdence intervals the interested reader is referred to Brownie and Kiefer(1977), Casella (1988), Berger (1985) and Kiefer (1977). All examples given inSection 4.3 are taken from Shawe-Taylor et al. (1998). The luckiness framework ismost advantageous if we reﬁne what is required from a learning algorithm: A learn-
ing algorithm/BTis given a training sample z∈ /CImand a conﬁdence δ∈(0,1],
and is then required to return a hypothesis /BT(z)∈ /C0together with an accuracy
εsuch that in at least 1 −δof the learning trials the expected risk of /BT(z)is
less than or equal to the given ε. Y . Freund called such learning algorithms self
bounding learning algorithms (Freund 1998). Although, without making explicit
assumptions on PZ, all learning algorithms might be equally good, a self bounding
learning algorithm is able to tell the practitioner when its implicit assumptions aremet. Obviously, a self bounding learning algorithm can only be constructed havinga theoretically justiﬁed generalization error bound available.
In the last section of this chapter we presented a PAC analysis for the particular
hypothesis space of linear classiﬁers making extensive use of the margin as adata dependent complexity measure. In Theorem 4.25 we showed that the margin,
that is, the minimum real-valued output of a linear classiﬁer before thresholding,allows us to replace the coarse application of the union bound over the worst case
diversity of the binary-valued function class by a union bound over the number of
161 Mathematical Models of Learning
equivalence classes witnessed by the observed margin. The proof of this result can
also be found in Shawe-Taylor and Cristianini (1998, Theorem 6.8) and Bartlett(1998, Lemma 4). Using a scale sensitive version of the VC dimension known asthe fat shattering dimension (Kearns and Schapire 1994) we obtained bounds on theexpected risk of a linear classiﬁer which can be directly evaluated after learning .
An important tool was Lemma 4.29 which can be found in Alon et al. (1997).The ﬁnal step was an application of Lemma 4.31 which was proven in Gurvits(1997) and later simpliﬁed in Bartlett and Shawe-Taylor (1999). It should be noted,
however, that the application of Alon’s result yields bounds which are practically
irrelevant as they require the training sample size to be of order 10
5in order to
be nontrivial. Reinterpreting the margin we demonstrated that this margin bounddirectly gives a bound on the expected risk involving a function of the margindistribution. This study closely followed the original papers Shawe-Taylor andCristianini (1998) and Shawe-Taylor and Cristianini (2000). A further applicationof this idea showed that although not containing any margin complexity, adaptivemargin machines effectively minimize the complexity of the resulting classiﬁcationfunctions. Recently it has been demonstrated that a functional analytic viewpointoffers ways to get much tighter bounds on the covering number at the scale ofthe observed margin (see Williamson et al. (2000), Shawe-Taylor and Williamson(1999), Schölkopf et al. (1999) and Smola et al. (2000)).
5 Bounds for Speciﬁc Algorithms
This chapter presents a theoretical study of the generalization error of speciﬁc algo-
rithms as opposed to uniform guarantees about the expected risks over the wholehypothesis space. It starts with a PAC type or frequentist analysis for Bayesian
learning algorithms. The main PAC-Bayesian generalization error bound measures
the complexity of a posterior belief by its evidence. Using a summarization prop-erty of hypothesis spaces known as Bayes admissibility , it is possible to apply the
main results to single hypotheses. For the particular case of linear classiﬁers weobtain a bound on the expected risk in terms of a normalized margin on the train-ing sample. In contrast to the classical PAC margin bound, the new bound is anexponential improvement in terms of the achieved margin. A drawback of the newbound is its dependence on the number of dimensions of feature space.
In order to study more conventional machine learning algorithms the chapter
introduces the compression framework. The main idea here is to take advantageof the fact that, for certain learning algorithms, we can remove training exampleswithout changing its behavior. It will be shown that the intuitive notion of compres-sion coefﬁcients, that is, the fraction of necessary training examples in the wholetraining sample, can be justiﬁed by rigorous generalization error bounds. As an ap-
plication of this framework we derive a generalization error bound for the percep-
tron learning algorithm which is controlled by the margin a support vector machinewould have achieved on the same training sample. Finally, the chapter presents ageneralization error bound for learning algorithms that exploits the robustness of agiven learning algorithm. In the current context, robustness is deﬁned as the prop-erty that a single extra training example has a limited inﬂuence on the hypothesislearned, measured in terms of its expected risk. This analysis allows us to show thatthe leave-one-out error is a good estimator of the generalization error, putting thecommon practice of performing model selection on the basis of the leave-one-outerror on a sound theoretical basis.
164 Chapter 5
5.1 The PAC-Bayesian Framework
Up to this point we have investigated the question of bounds on the expected risk
that hold uniformly over a hypothesis space. This was done due to the assumptionthat the selection of a single hypothesis on the basis of the training sample z∈/CImis the ultimate goal of learning. In contrast, a Bayesian algorithm results in
(posterior) beliefs PH|Zm=zover all hypotheses. Based on the posterior measure
PH|Zm=zdifferent classiﬁcation strategies are conceivable (see Subsection 3.1.1
for details). The power of a Bayesian learning algorithm is in the possibilityof incorporating prior knowledge about the learning task at hand via the priormeasure P
H. Recently D. McAllester presented some so-called PAC-Bayesian
theorems which bound the expected risk of Bayesian classiﬁers while avoidingthe use of the growth function and related quantities altogether. Unlike classicalBayesian analysis—where we make the implicit assumption that the unknownmeasure P
Zof the data can be computed from the prior PHand the likelihood
PZ|H=hbyEHbracketleftbig
PZ|H=hbracketrightbig
—these results hold for any distribution PZof the training
data and thus fulﬁll the basic desiderata of PAC learning theory. The key ideato obtain such results is to take the concept of structural risk minimization to itsextreme—where each hypothesis space contains exactly one hypothesis. A direct
application of the multiple testing lemma 4.14 yields bounds on the expectedrisk for single hypotheses, which justify the use of the MAP strategy as one
possible learning method in a Bayesian framework. Applying a similar idea to
subsets of the hypothesis space/C0then results in uniform bounds for average
classiﬁcations as carried out by the Gibbs classiﬁcation strategy. Finally, the use ofa simple inequality between the expected risk of the Gibbs and Bayes classiﬁcationstrategies completes the list of generalization error bounds for Bayesian algorithms.It is worth mentioning that we have already used prior beliefs in the application ofstructural risk minimization (see Subsection 4.2.3).
5.1.1 PAC-Bayesian Bounds for Bayesian Algorithms
In this section we present generalization error bounds for the three Bayesianclassiﬁcation strategies presented in Subsection 3.1.1. We shall conﬁne ourselves tothe PAC likelihood deﬁned in Deﬁnition 3.3 which, in a strict Bayesian treatment,corresponds to the assumption that the loss is given by the zero-one loss l
0−1.N o t e ,
however, that the main ideas of the PAC-Bayesian framework carry over far beyondthis simple model (see Section 5.4 for further references).
165 Bounds for Speciﬁc Algorithms
A Bound for the MAP Estimator
Let us consider any prior measure PHon a hypothesis space /C0={hi}∞
i=1. Then,
by the binomial tail bound given in Theorem A.116, we know that, for all ε> 0,
∀hi∈ /C0: PZmparenleftbigparenleftbig
Rempbracketleftbig
hi,Zbracketrightbig
=0parenrightbig
∧(R[hi]>ε)parenrightbig
<exp(−mε),
that is, the probability that a ﬁxed hypothesis commits no errors on a sample
of size m, although its expected risk is greater than some prespeciﬁed ε, decays
exponentially in ε. This is clearly equivalent to the the following statement
ϒi(z,m,δ)≡parenleftbig
Remp [hi,z]/negationslash=0parenrightbig
∨parenleftBigg
R[hi]≤lnparenleftbig1
δparenrightbig
mparenrightBigg
, (5.1)
which holds with probability at least 1 −δover the random draw of the training
sample z∈ /CIm. Hence, applying Lemma 4.14 with PS=PHwe have proven our
ﬁrst PAC-Bayesian result.
Theorem 5.1 (Bound for single hypotheses) F or any measure PHand any mea-
sure PZ, for anyδ∈(0,1], with probability at least 1−δover the random draw of
the training sample z∈ /CImfor all hypotheses h ∈V/C0(z)that achieve zero train-
ing error R emp [h,z]=0and have PH(h)>0, the expected risk R [h]is bounded
from above by
R[h]≤1
mparenleftbigg
lnparenleftbigg1
PH(h)parenrightbigg
+lnparenleftbigg1
δparenrightbiggparenrightbigg
. (5.2)
This bound justiﬁes the MAP estimation procedure because, by assumption of the
PAC likelihood for each hypothesis hnot in version space V/C0(z), the posterior
measure PH|Zm=z(h)vanishes due to the likelihood term. Thus, the posterior mea-
sure PH|Zm=zis merely a rescaled version of the prior measure PH, only positive
inside version space V/C0(z). Hence, the maximizer /BTMAP(z)of the posterior mea-
sure PH|Zm=zmust be the hypothesis with maximal prior measure PHwhich is, at
the same time, the minimizer of equation (5.2).
A Bound for the Gibbs Classiﬁcation Strategy
Considering the Gibbs classiﬁcation strategy given in Deﬁnition 3.8 we see that,due to the non-deterministic classiﬁcation function, the expected risk of Gibbs
z
166 Chapter 5
based on PH|Zm=zcan be written as
R[Gibbs z]=EXYbracketleftbig
EH|Zm=zbracketleftbig
l0−1(H(X),Y)bracketrightbigbracketrightbig
=EH|Zm=zbracketleftbig
EXYbracketleftbig
l0−1(H(X),Y)bracketrightbigbracketrightbig
.
In case of the PAC likelihood we know that, for a given training sample z∈ /CIm,
the posterior probability can only be positive for hypotheses hwithin version
space V/C0(z). Let us study the more general case of a Gibbs classiﬁcation strategy
Gibbs H(z)over a subset H(z)⊆ V/C0(z)of version space (the original Gibbs
classiﬁcation strategy Gibbs zis retained by setting H(z)=V/C0(z)), i.e.,
Gibbs H(z)(x)=h(x), h∼PH|H∈H(z). (5.3)
The expected risk of this generalized classiﬁcation strategy can then be written as
Rbracketleftbig
Gibbs H(z)bracketrightbig
=EH|H∈H(z)bracketleftbig
EXYbracketleftbig
l0−1(H(X),Y)bracketrightbigbracketrightbig
=EH|H∈H(z)bracketleftbig
Rbracketleftbig
Hbracketrightbigbracketrightbig
. (5.4)
The main idea involved in obtaining a bound for this classiﬁcation strategy is to
split up the expectation value in equation (5.4) at some point ε∈(0,1]and to use
the fact that by the zero-one loss l0−1, for all hypotheses R[h]≤1,
Rbracketleftbig
Gibbs H(z)bracketrightbig
≤ε·PH|H∈H(z)bracketleftbig
Rbracketleftbig
Hbracketrightbig
≤εbracketrightbig
+1·PH|H∈H(z)bracketleftbig
Rbracketleftbig
Hbracketrightbig
>εbracketrightbig
.
Thus, it is necessary to obtain an upper bound on PH|H∈H(z)bracketleftbig
Rbracketleftbig
Hbracketrightbig
>εbracketrightbig
over the
random draw of the training sample z∈ /CIm. Fully exploiting our knowledge
about the probability of drawing a training sample zsuch that a hypothesis hin
version space V/C0(z)has an expected risk R[h]larger than ε, we use equation
(5.1) together with the quantiﬁer reversal lemma (see Lemma C.10 in AppendixC.7). This yields that, for all β∈(0,1), with probability at least 1 −δover the
random draw of the training sample z,
∀α∈(0,1]: P
H
(H∈V/C0(z))∧
Rbracketleftbig
Hbracketrightbig
>1
(1−β)lnparenleftBig
1
αβδparenrightBig
mbracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
ε

<α,
where we replace Rempbracketleftbig
H,zbracketrightbig
=0b yH∈V/C0(z)which is true by deﬁnition. Note
that we exploit the fact that PZ|H=h=PZwhich should not be confused with the
purely Bayesian approach to modeling the data distribution PZ(see Chapter 3). In
the current context, however, we consider the unknown true distribution PZwhich
isnot inﬂuenced by the (algorithmical) model h∈ /C0chosen. As by assumption
H(z)⊆V/C0(z)it easily follows that
167 Bounds for Speciﬁc Algorithms
PH|H∈H(z)parenleftbig
Rbracketleftbig
Hbracketrightbig
>εparenrightbig
=PHparenleftbig
(H∈H(z))∧parenleftbig
Rbracketleftbig
Hbracketrightbig
>εparenrightbigparenrightbig
PH(H(z))<α
PH(H(z)).
Finally, choosing α=PH(H(z))/mandβ=1/m, as well as exploiting the
fact that the function PH|H∈H(z)bracketleftbig
Rbracketleftbig
Hbracketrightbig
>εbracketrightbig
is monotonically increasing in ε,i ti s
readily veriﬁed that, with probability at least 1 −δover the random draw of the
training sample z∈ /CIm,
Rbracketleftbig
Gibbs H(z)bracketrightbig
≤ε·parenleftbigg
1−1
mparenrightbigg
+1
m
=1
mparenleftbigg
lnparenleftbigg1
PH(H(z))parenrightbigg
+2l n(m)+lnparenleftbigg1
δparenrightbigg
+1parenrightbigg
.
Thus we have shown our second PAC-Bayesian result.
Theorem 5.2 (Bound for subsets of hypotheses) F or any measure PHand any
measure PZ, for any δ∈(0,1], with probability at least 1−δover the random
draw of the training sample z∈ /CImfor all subsets H (z)⊆V/C0(z)such that
PH(H(z))>0, the expected risk of the associated Gibbs classiﬁcation strategy
Gibbs H(z)is bounded from above by
Rbracketleftbig
Gibbs H(z)bracketrightbig
≤1
mparenleftbigg
lnparenleftbigg1
PH(H(z))parenrightbigg
+2l n(m)+lnparenleftbigg1
δparenrightbigg
+1parenrightbigg
. (5.5)
As expected, the Gibbs classiﬁcation strategy Gibbs zgiven in Deﬁnition 3.8
minimizes the r.h.s. of equation (5.5). Remarkably, however, the bound on theexpected risk for the Gibbs classiﬁcation strategy is always smaller than or equalto the bound value for any single hypothesis. This is seemingly in contrast toa classical PAC analysis which views the learning process as a selection amonghypotheses based on the training sample z∈/CIm.
The Gibbs-Bayes Lemma
Finally, in order to obtain a PAC-Bayesian bound on the expected risk of the Bayes
classiﬁcation strategy given in Deﬁnition 3.7 we make use of the following simplelemma.
168 Chapter 5
Lemma 5.3 (Gibbs-Bayes lemma) F or any measure PH|Zm=zover hypothesis
space /C0⊆ /CH
/CGand any measure PXY over data space /CG× /CH= /CI, for all
training samples z∈ /CImand the zero-one loss l 0−1
R[Bayes z]≤|/CH|·R[Gibbs z]. (5.6)
Proof For any training sample z∈ /CImand associated measure PH|Zm=zconsider
the set
Zz={(x,y)∈ /CI|l0−1(Bayes z(x),y)=1}.
For all points (x,y)/∈ Zzin the complement, the r.h.s. of equation (5.6) is
zero and thus the bound holds. For all points (x,y)∈Zzthe expectation value
EH|Zm=zbracketleftbig
l0−1(H(x),y)bracketrightbig
(as considered for the Gibbs classiﬁcation strategy) will
be at least1
|/CH|because Bayes z(x)makes, by deﬁnition, the same classiﬁcation
as the majority of the h’s weighted by PH|Zm=z.A st h e r ea r e |/CH|different classes
the majority has to have a measure of at least1
|/CH|. Thus, multiplying this value by
|/CH|upper bounds the loss of one incurred on the l.h.s. by Bayes z. The lemma is
proved.
A direct application of this lemma to Theorem 5.2 ﬁnally yields our third PAC-Bayesian result.
Theorem 5.4 (Bound for the Bayes classiﬁcation strategy) F or any measure P
H
and any measure PZ, for any δ∈(0,1], with probability at least 1−δover the
random draw of the training sample z∈ /CIm, for all subsets H (z)⊆ V/C0(z)
such that PH(H(z))>0the expected risk of the generalized Bayes classiﬁcation
strategy Bayes H(z)given by
Bayes H(z)(x)def=argmax
y∈ /CHPH|H∈H(z)({h∈ /C0|h(x)=y})
is bounded from above by
Rbracketleftbig
Bayes H(z)bracketrightbig
≤|/CH|
mparenleftbigg
lnparenleftbigg1
PH(H(z))parenrightbigg
+2l n(m)+lnparenleftbigg1
δparenrightbigg
+1parenrightbigg
. (5.7)
Again, H(z)= V/C0(z)minimizes the bound (5.7) and, as such, theoretically
justiﬁes the Bayes optimal decision using the whole of version space withoutassuming the “correctness” of the prior. Note, however, that the bound becomestrivial as soon as P
H(V(z))≤exp(−m/|/CH|). An appealing feature of these
169 Bounds for Speciﬁc Algorithms
bounds is given by the fact that their complexity PH(V/C0(z))vanishes in the
most “lucky” case of observing a training sample zsuch that all hypotheses are
consistent with it.
If we have chosen too “small” a hypothesis space beforehand there might
not even exist a single hypothesis consistent with the training sample; if, on theother hand, the hypothesis space/C0contains many different hypothesis the prior
probability of single hypotheses is exponentially small. We have already seen thisdilemma in the study of the structural risk minimization framework (see Subsection4.2.3).
Remark 5.5 (Evidence and PAC-Bayesian complexity) If we consider the PAC-
likelihood P
Y|X=x,H=h(y)=Ih(x)=ywe see that the posterior belief PH|Zm=zis
a rescaled version of the prior belief PH|Zm=z. More interestingly, the evidence
EHbracketleftbig
PZm|H=hbracketrightbig
equals the prior probability of version space PH(V/C0(z)). Thus, in
the ﬁnal bound (5.7) the effective complexity is the negated log-evidence, i.e., max-imizing the log-evidence over a small number of different models is theoreticallyjustiﬁed by a PAC-Bayesian bound (together with Lemma 4.14) for any data dis-
tribution P
Z. This result puts the heuristic model selection procedure of evidence
maximization on a sound basis and furthermore removes the necessity of “correctpriors”.
Bounds with Training Errors
It is worth mentioning that the three results presented above are based on theassertion given in equation (5.1). This (probabilistic) bound on the expected risk of
hypotheses consistent with the training sample z∈/CImis based on the binomial tail
bound. If we replace this starting point with the corresponding assertion obtainedfrom Hoeffding’s inequality, i.e.,
ϒ
i(z,m,δ)≡R[hi]−Remp [hi,z]≤radicalBigg
lnparenleftbig1
δparenrightbig
2m
and perform the same steps as before then we obtain bounds that hold uniformly
over the hypothesis space (Theorem 5.1) or for all measurable subsets H⊆ /C0of
hypothesis space (Theorems 5.2 and 5.4). More formally, we obtain the following.
Theorem 5.6 (PAC-Bayesian bounds with training errors) F or any measure PH
and any measure PZ, for any δ∈(0,1], with probability at least 1−δover the
170 Chapter 5
random draw of the training sample z∈ /CIm, for all hypotheses h ∈ /C0such that
PH(h)>0,
R[h]≤Remp [h,z]+radicalBigg
1
2mparenleftbigg
lnparenleftbigg1
PH(h)parenrightbigg
+lnparenleftbigg1
δparenrightbiggparenrightbigg
.
Moreover , for all subsets H (z)⊆ /C0such that PH(H(z))>0the expected
risk Rbracketleftbig
Gibbs H(z)bracketrightbig
of the Gibbs classiﬁcation strategy Gi bbs H(z)is bounded from
above by
Remp [H(z),z]+radicalBigg
1
2mparenleftbigg
lnparenleftbigg1
PH(H(z))parenrightbigg
+2l n(m)+lnparenleftbigg1
δparenrightbiggparenrightbigg
+1
m, (5.8)
where R emp [H(z),z]def=EH|H∈H(z)bracketleftbig
Rempbracketleftbig
H,zbracketrightbigbracketrightbig
is the average training error
over all hypotheses in H (z).
Clearly, even in the case of considering hypotheses which incur training errors,
it holds that the bound is smaller for the Gibbs classiﬁcation strategy than forany single hypothesis found by the MAP procedure. Moreover, the result onthe expected risk of the Gibbs classiﬁcation strategy (or the Bayes classiﬁcationstrategy when using Lemma 5.3) given in equation (5.8) deﬁnes an algorithmwhich selects a subset H(z)⊆/C0of hypothesis space /C0so as to minimize the
bound. Note that by the selection of a subset this procedure automatically deﬁnesa principle for inferring a distribution P
H|H∈H(z)over the hypothesis space which is
therefore called the PAC-Bayesian posterior .
Remark 5.7 (PAC-Bayesian posterior) The ideas outlined can be taken one step
further when considering not only subsets H (z)⊆ /C0of a hypothesis space but
whole measures1QH|Zm=z. In this case, for each test object x ∈ /CGwe must consider
a (Gibbs) classiﬁcation strategy Gi bbs QH|Zm=zthat draws a hypothesis h ∈ /C0
according to the measure QH|Zm=zand uses it for classiﬁcation. Then, it is possible
to prove a result which bounds the expected risk of this Gibbs classiﬁcation strategy
Gibbs QH|Zm=zuniformly over all possible QH|Zm=zby
EQH|Zm=zbracketleftbig
Rempbracketleftbig
H,zbracketrightbigbracketrightbig
+radicalBigg
Dparenleftbig
QH|Zm=z/bardblPHparenrightbig
+ln(m)+lnparenleftbig1
δparenrightbig
+2
2m−1, (5.9)
1 With a slight abuse of notation, in this remark we use QH|Zm=zand qH|Zm=zto denote any measure and
density over the hypothesis space based on the training sample z∈ /CIm.
171 Bounds for Speciﬁc Algorithms
where2
Dparenleftbig
QH|Zm=z/bardblPHparenrightbig
=EQH|Zm=zbracketleftbigg
lnparenleftbiggqH|Zm=z(H)
fH(H)parenrightbiggbracketrightbigg
is known as the Kullback-Leibler divergence between QH|Zm=zand PH. Disregard-
ing the square root and setting 2m−1to m (both are due to the application of
Hoeffding’s inequality) we therefore have that the PAC-Bayesian posterior is ap-proximately given by the measure Q
H|Zm=zwhich minimizes
EQH|Zm=zbracketleftbig
Rempbracketleftbig
H,zbracketrightbigbracketrightbig
+Dparenleftbig
QH|Zm=z/bardblPHparenrightbig
+ln(m)+lnparenleftbig1
δparenrightbig
+2
m. (5.10)
Whenever we consider the negative log-likelihood as a loss function,
Remp [h,z]=−1
mmsummationdisplay
i=1lnparenleftbig
PZ|H=h((xi,yi))parenrightbig
=−1
mlnparenleftbig
PZm|H=h(z)parenrightbig
,
this minimizer equals the Bayesian posterior due to the following argument:
F or all training sample sizes m ∈ /C6we have that
EQH|Zm=zbracketleftbig
Rempbracketleftbig
H,zbracketrightbigbracketrightbig
=−1
mEQH|Zm=zbracketleftbig
lnparenleftbig
PZm|H=h(z)parenrightbigbracketrightbig
.
Dropping all terms which do not depend on QH|Zm=z, equation (5.10) can be
written as
1
mparenleftbigg
EQH|Zm=zbracketleftbigg
lnparenleftbigg1
PZm|H=h(z)parenrightbiggbracketrightbigg
+EQH|Zm=zbracketleftbigg
lnparenleftbiggqH|Zm=z(H)
fH(H)parenrightbiggbracketrightbiggparenrightbigg
=1
mparenleftbigg
EQH|Zm=zbracketleftbigg
lnparenleftbiggqH|Zm=z(H)
PZm|H=h(z)fH(H)parenrightbiggbracketrightbiggparenrightbigg
=1
mparenleftbigg
EQH|Zm=zbracketleftbigg
lnparenleftbiggqH|Zm=z(H)
fH|Zm=z(H)PZm(z)parenrightbiggbracketrightbiggparenrightbigg
=1
mparenleftbigg
EQH|Zm=zbracketleftbigg
lnparenleftbiggqH|Zm=z(H)
fH|Zm=z(H)parenrightbigg
−ln(PZm(z))bracketrightbiggparenrightbigg
.
This term is minimized if and only if qH|Zm=z(h)=fH|Zm=z(h)for all hypotheses
h∈ /C0. Thus, the PAC-Bayesian framework provides a theoretical justiﬁcation
for the use of Bayes’ rule in the Bayesian approach to learning as well as a
2 Note that qand fdenote the densities of the measures Qand P, respectively (see also page 331).
172 Chapter 5
quantiﬁcation of the “correctness” of the prior choice, i.e., evaluating equation
(5.9) for the Bayesian posterior PH|Zm=zprovides us with a theoretical guarantee
about the expected risk of the resulting Bayes classiﬁcation strategy.
5.1.2 A PAC-Bayesian Margin Bound
Apart from building a theoretical basis for the Bayesian approach to learning,the PAC-Bayesian results presented can also be used to obtain (training) data-dependent bounds on the expected risk of single hypotheses h∈/C0. One moti-
vation for doing so is their tightness, i.e., the complexity term −ln(PH(H(z)))
is vanishing in maximally “lucky” situations. We shall use the Bayes classiﬁcation
strategy as yet another expression of the classiﬁcation carried out by a single hy-pothesis h∈/C0. Clearly, this can be done as soon as we are sure that, for a given
subset H(h)⊆ /C0,Bayes H(h)behaves exactly the same as a single hypothesis
h∈ /C0on the whole space /CIw.r.t. the loss function considered. More formally,
this is captured by the following deﬁnition.
Deﬁnition 5.8 (Bayes admissibility) Given a hypothesis space /C0⊆ /CH
/CGand a
prior measure PHover /C0we call a subset H (h)⊆ /C0Bayes admissible w.r.t. h
and PHif, and only if ,
∀(x,y)∈ /CI: l0−1(h(x),y)=l0−1parenleftbig
Bayes H(h)(x),yparenrightbig
.
For general hypothesis spaces /C0and prior measures PHit is difﬁcult to verify the
Bayes admissibility of a hypothesis. Nevertheless, for linear classiﬁers in some
feature space /C3, i.e., x/mapsto→ sign(/angbracketleftx,w/angbracketright)where xdef=φ(x)andφ: /CG→ /C3⊆/lscriptn
2
(see also Deﬁnition 2.2), we have the following geometrically plausible lemma.
Lemma 5.9 (Bayes admissibility for linear classiﬁers in feature space) Fo r t h e
uniform measure PWover the unit hypersphere /CF⊂ /C3⊆/lscriptn
2each ball /BUτ(w)=
{v∈ /CF|/bardblw−v/bardbl<τ}⊆ /CFis Bayes admissible w.r .t. to its center
c=EW|W∈ /BUr(w)bracketleftbig
Wbracketrightbig
vextenddoublevextenddoubleEW|W∈ /BUr(w)bracketleftbig
Wbracketrightbigvextenddoublevextenddouble.
Proof The proof follows from the simple observation that the center of a ball is
always in the bigger half when bisected by a hyperplane.

173 Bounds for Speciﬁc Algorithms
Remarkably, in using a ball /BUτ(w)rather than wto get a bound on the expected
risk R[hw]ofhwwe make use of the fact that hwsummarizes all its neighboring
classiﬁers hv∈V/C0(z),v∈ /BUτ(w). This is somewhat related to the idea of a
covering already exploited in the course of the proof of Theorem 4.25: The coverelementˆf∈F
γ(x)carries all information about the training error of all the
covered functions via its real-valued output referred to as the margin (see page144 for more details).
In this section we apply the idea of Bayes admissibility w.r.t. the uniform
measure P
Wto linear classiﬁers, that is, we express a linear classiﬁer x/mapsto→
sign(/angbracketleftx,w/angbracketright)as a Bayes classiﬁcation strategy Bayes/BUτ(w)over a subset /BUτ(w)of
version space V(z)such that PW(
/BUτ(W))can be lower bounded solely in terms
of the margin. As already seen in the geometrical picture on page 57 we need tonormalize the geometrical margin γ
i(w)of a linear classiﬁer hwby the length /bardblxi/bardbl
of the ith training point in order to ensure that a ball of the resulting margin is
fully within version space V(z). Such a reﬁned margin quantity /Gamma1z(w)offers the
advantage that no assumption about ﬁnite support of the input distribution PXneeds
to be made.
Theorem 5.10 (PAC-Bayesian margin bound) Suppose /C3⊆/lscriptn
2is a given fea-
ture space of dimensionality n. F or all probability measures PZ, for anyδ∈(0,1],
with probability at least 1−δover the random draw of the training sample z∈ /CIm,
if we succeed in correctly classifying m samples zwith a linear classiﬁer f wachiev-
ing a positive normalized margin /Gamma1z(w),
/Gamma1z(w)def= min
i=1,..., myi/angbracketleftxi,w/angbracketright
/bardblw/bardbl·/bardblxi/bardbl>0, (5.11)
then the generalization error of h wis bounded from above by
R[hw]≤2
mparenleftBigg
dlnparenleftBigg
1
1−radicalbig
1−/Gamma12
z(w)parenrightBigg
+2l n(m)+lnparenleftbigg1
δparenrightbigg
+2parenrightBigg
. (5.12)
where d=min(m,n).
The proof is given in Appendix C.8. The most appealing feature of this new margin
bound is, of course, that in the case of maximally large margins, i.e., /Gamma1z(w)=1,
the ﬁrst term vanishes and the bound reduces to
2
mparenleftbigg
2l n(m)+lnparenleftbigg1
δparenrightbigg
+2parenrightbigg
.
174 Chapter 5
Here, the numerator grows logarithmically whilst the denominator grows linearly
hence giving a rapid decay to zero. Moreover, in the case of
/Gamma1z(w)>radicalBigg
2e x pparenleftbigg
−1
2parenrightbigg
−exp(−1)≈0.91
we enter a regime where −ln(1−radicalbig
1−/Gamma12
z(w)) <1
2and thus the troublesome
situation of d=mis compensated for by a large observed margin. The situation
d=moccurs if we use kernels which map the data into a high dimensional space
as with the RBF kernel (see Table (2.1)).
Example 5.11 (Normalizing data in feature space) Theorem 5.10 suggests the
following learning algorithm: Given a version space V (z)ﬁnd the classiﬁer w
that maximizes /Gamma1z(w). This algorithm, however , is given by the support vector
machine only if the training data in feature space /C3are normalized. In Figure 5.1
we plotted the expected risks of support vector machine solutions (estimated over100 different splits of the datasets
3thyroid (m=140 ,m test=75) and sonar
(m=124 ,m test=60)) with (dashed line) and without normalization (solid line)
as a function of the polynomial degree p of a complete polynomial kernel (seeTable 2.1). As suggested by Theorem 5.10 in almost all cases the normalizationimproved the performance of the support vector machine solution at a statisticallysigniﬁcant level.
Remark 5.12 (Sufﬁcient training sample size) It may seem that this bound on
the expected risk of linear hypotheses in terms of the margin is much tighter thanthe PAC margin bound presented in Theorem 4.32 because its scaling behavior
as a function of the margin is exponentially better . Nevertheless, the current result
depends heavily on the dimensionality n ∈/C6of the feature space /C3⊆/lscriptn
2whereas
the result in Theorem 4.32 is independent of this number . This makes the currentresult a practically relevant bound if the number nof dimensions of feature space/C3is much smaller than the training sample size. A challenging problem is to use
the idea of structural risk minimization. If we can map the training sample z∈ /CIm
in a low dimensional space and quantify the change in the margin solely in terms
of the number n of dimensions used and a training sample independent quantity,then we can use the margin plus an effective small dimensionality of feature spaceto tighten the bound on the expected risk of a single classiﬁer .
3 These datasets are taken from the UCI Benchmark Repository found at http://www.ics.uci.edu/~mlearn .
175 Bounds for Speciﬁc Algorithms
10 20 30 400.040 0.050 0.060 0.070
pgeneralisation error
10 20 30 400.16 0.18 0.20 0.22
pgeneralisation error
Figure 5.1 Expected risks of classiﬁers learned by a support vector machine with (solid
line) and without (dashed line) normalization of the feature vectors xi. The error bars
indicate one standard deviation over 100 random splits of the datasets. The plots are
obtained on the thyroid dataset (left) and the sonar dataset (right).
Remark 5.13 (“Risky” bounds) The way we incorporated prior knowledge into
this bound was minimal. In fact, by making the assumption of a uniform measureP
Won the surface of a sphere we have chosen the most uninformative prior pos-
sible. Therefore our result is solution independent; it is meaningless where (on theunit sphere) the margin /Gamma1
z(w)is observed. Remarkably, the PAC-Bayesian view
offers ways to construct “risky” bounds by putting much more prior probability ona certain region of the hypotheses space/C0. Moreover , we can incorporate unla-
beled data much more easily by carefully adjusting our prior PW.
5.2 Compression Bounds
So far we have have studied uniform bounds only; in the classical PAC and VC
framework we bounded the uniform convergence of training errors to expectedrisks (see Section 4.2.1). In the luckiness framework we bounded the expectedrisk uniformly over the (random) version space (see Theorem 4.19). In the PACBayesian framework we studied bounds on the expected risk of the Gibbs classiﬁ-cation strategy uniformly over all subsets of hypothesis (version) space (Theorem5.2 and 5.6), or possible posterior measures (equation (5.9)). We must recall, how-ever, that these results are more than is needed. Ultimately we would like to boundthe generalization error of a given algorithm rather than proving uniform boundson the expected risk. In this section we will present such an analysis for algorithms
176 Chapter 5
that can be expressed as so-called compression schemes. The idea behind compres-
sion schemes stems from the information theoretical analysis of learning where theaction of a learning algorithm is viewed as summarization or compression of thetraining sample z∈/CIminto a single function. Since the uncertainty is only within
the mclasses y∈ /CHm(given the mobjects x∈ /CGm) the protocol is as follows: The
learning algorithm gets to know the whole training sample z=(x,y)∈(
/CG× /CH)m
and must transfer dbits to a classiﬁcation algorithm that already knows the mtrain-
ing objects x∈ /CGm. The requirement on the choice of d∈ /C6is that the classiﬁ-
cation algorithm must be able to correctly classify the whole training sample by
just knowing the dbits and the objects x. If this is possible than the sequence yof
classes must contain some redundancies w.r.t. the classiﬁcation algorithm’s abilityto reproduce classes, i.e., the hypothesis space/C0⊆ /CH
/CGchosen. Intuitively, a small
compression coefﬁcient d/mshould imply a small expected risk of the classiﬁca-
tion strategy parameterized by the dbits. This will be shown in the next subsec-
tion. In the subsequent subsection we apply the resulting compression bound to theperceptron learning algorithm to prove the seemingly paradoxical result that thereexists an upper bound on its generalization error driven by the margin a supportvector machine would have achieved on the same training sample. This exampleshould be understood as an example of the practical power of the compressionframework rather than a negative result on the margin as a measure of the effectivecomplexity of single (real-valued) hypotheses.
5.2.1 Compression Schemes and Generalization Error
In order to use the notion of compression schemes for bounds on the generaliza-
tion error R[
/BT,z]of a ﬁxed learning algorithm /BT:∪∞
m=1
/CIm→ /C0⊆ /CH
/CGwe
are required to formally cast the latter into a compression framework. The learningalgorithm/BTmust be expressed as the composition of a compression and recon-
struction function. More formally this reads as follows:
Deﬁnition 5.14 (Compression scheme) Let the set I d,m⊂{1,..., m}dcomprise
of all index vectors of size exactly d ∈ /C6,
Id,m=braceleftbig
(i1,..., id)∈{1,..., m}d|i1/negationslash=···/negationslash=idbracerightbig
.
Given a training sample z∈ /CImand an index vector i∈Id,m,l e t zibe the
subsequence indexed by i,
zidef=parenleftbig
zi1,..., zidparenrightbig
.
177 Bounds for Speciﬁc Algorithms
The algorithm /BT:∪∞
m=1
/CIm→ /C0is said to be a compression scheme of size
d if, and only if, there exists a compression function /BVd:∪∞
i=d
/CIi→ Id,mand
areconstruction function /CAd: /CId→ /CH
/CGwhose composition yields the same
hypothesis as /BT(z), i.e.,
∀z∈ /CIm: /BT(z)= /CAdparenleftbig
z/BVd(z)parenrightbig
. (5.13)
The compression scheme is said to be permutation invariant if, and only if, the
reconstruction function /CAdis permutation invariant.
Before we proceed to present a generalization error bound for compression
schemes we will try to enhance the understanding of this formal deﬁnition bycasting a few of the algorithms presented in this book into this deﬁnition.
Example 5.15 (Perceptron learning algorithm) In the case of the perceptron
learning algorithm given in Algorithm 1 we see that the removal of all trainingexamples (x
i,yi)∈zthat were never used to update the weight vector would not
change the algorithm’s solution because the algorithm decides on an update usingonly the current weight vector w
tand the current example (xi,yi)∈z. Hence
we could run the perceptron learning algorithm to track only the indices iof all
training examples used in an update step (compression function /BV|i|). Afterwards
we run the perceptron learning algorithm again on the subsample zi(reconstruc-
tion function /CA|i|) which would give the same solution as running the algorithm on
the full training sample z∈ /CIm. Thus, by virtue of equation (5.13) the perceptron
learning algorithm is a compression scheme.
Example 5.16 (Support vector learning) In order to see that support vector
learning ﬁts into the compression framework we notice that, due to the station-
ary conditions, at the solutions ˆα∈ /CAm,ˆξ∈ /CAmto the mathematical programs
presented in Section B.5
∀i∈{1,..., m}:ˆαiparenleftBig
yiangbracketleftbig
xi,ˆwangbracketrightbig
−1+ˆξiparenrightBig
=0. (5.14)
Now imagine we run the support vector algorithm and ﬁnd all training samples
indices isuch that y iangbracketleftbig
xi,ˆwangbracketrightbig
=1−ˆξiwhere(xi,yi)∈z(compression function /BV|i|),
that is, all patterns that lie directly on the hyperplanesbraceleftbig
x∈ /C3vextendsinglevextendsingleangbracketleftbig
x,ˆwangbracketrightbig
=± 1bracerightbig
(if
ˆξi=0) and within the margin or even on the wrong side of the hyperplane (if
ˆξi>0). If we now rerun the support vector learning algorithm on ziwe know that
we obtain the same weight vector ˆw=summationtextm
i=1ˆαiyixibecause, by virtue of equation
178 Chapter 5
(5.14), the left-out training examples must have had expansion coefﬁcients of zero.
Further , the ordering of ziis irrelevant. As a consequence, the support vector
learning algorithm is a permutation invariant compression scheme.
It is interesting to note that the relevance vector machine algorithm (see Section
3.3) is not expressible as a compression scheme. Consider that we conduct a ﬁrstrun to select the training examples which have non-zero expansion coefﬁcients inthe ﬁnal expansion. A rerun on this smaller subset of the training sample would notobtain the same classiﬁer because the computation of the few nonzero expansion
coefﬁcients α
iuses all the mclasses y∈ /CHmand examples x∈ /CGmgiven (see
Algorithm 7).
In the following we conﬁne ourselves to the zero-one loss l0−1parenleftbig
ˆy,yparenrightbig
=Iˆy/negationslash=y.
As mentioned earlier this is not a severe restriction and can be overcome by usingdifferent large deviation bounds (see Subsection A.5.2). Let us start with the simplePAC case, that is, we assume that there exists a hypothesis h
∗∈ /CH
/CGsuch that
PY|X=x(y)=Ih∗(x)=y. Then, for a given compression scheme of size d≤mwe
will bound the probability of having training samples z∈ /CImsuch that the training
error Remp[ /CAd(z/BVd(z)),z]= 0 but the expected risk R[ /CAd(z/BVd(z))]of the function
learned is greater than ε. This probability can be upper bounded by the sum of the
probabilities that the reconstruction function /CA(zi)returns a hypothesis with this
property over the choice of i∈Id,m, i.e.,
PZmparenleftbigparenleftbig
Rempbracketleftbig/CAdparenleftbig
Z/BVd(Z)parenrightbig
,Zbracketrightbig
=0parenrightbig
∧parenleftbig
Rbracketleftbig/CAdparenleftbig
Z/BVd(Z)parenrightbigbracketrightbig
>εparenrightbigparenrightbig
≤PZmparenleftbig
∃i∈Id,m:parenleftbig
Rempbracketleftbig/CAd(Zi),Zbracketrightbig
=0parenrightbig
∧parenleftbig
Rbracketleftbig/CAd(Zi)bracketrightbig
>εparenrightbigparenrightbig
≤summationdisplay
i∈Id,mPZmparenleftbigparenleftbig
Rempbracketleftbig/CAd(Zi),Zbracketrightbig
=0parenrightbig
∧parenleftbig
Rbracketleftbig/CAd(Zi)bracketrightbig
>εparenrightbigparenrightbig
. (5.15)
Clearly, for any i∈Id,m, a correct classiﬁcation of the whole training sample
z∈ /CImimplies a correct classiﬁcation of the subsetparenleftbig
z\parenleftbig
zi1,..., zidparenrightbigparenrightbig
∈ /CIm−dof
training samples not used. Moreover, using the fact that PZmis a product measure,
the single summands in (5.15) are upper bounded by
EZdbracketleftbig
PZm−d|Zd=zparenleftbigparenleftbig
Rempbracketleftbig/CAd(z),Zbracketrightbig
=0parenrightbig
∧(R[
/CAd(z)]>ε)parenrightbigbracketrightbig
.
Note that in this expression the symbol Zdenotes the m−drandom training ex-
amples whereas the symbol z∈ /CIddenotes the dtraining examples used to re-
construct the hypothesis. Since all the m−dtraining examples Zare assumed
to be drawn iid from PZwe know that the innermost probability cannot exceed
(1−ε)m−ddue to the binomial tail bound. Further, we know that the number of
179 Bounds for Speciﬁc Algorithms
different index vectors i∈Id,mequals4parenleftbigm
dparenrightbig
d!which ﬁnally gives that the proba-
bility in (5.15) is strictly less thanparenleftbigm
dparenrightbig
d!(1−ε)m−d. This statement is equivalent
to the following assertion ϒi(z,m,δ)that holds with probability at least 1 −δ
over the random draw of the training sample z∈ /CImfor all compression schemes
(
/BVi, /CAi)of size i
parenleftbig
Remp [
/CAi(z, /BVi(z)),z]/negationslash=0parenrightbig
∨parenleftBigg
R[
/CAi(z, /BVi(z))]≤lnparenleftbigparenleftbigm
iparenrightbig
i!parenrightbig
+lnparenleftbig1
δparenrightbig
m−iparenrightBigg
.
Using Lemma 4.14 with uniform PSover the numbers i∈{1,..., m}we have
proven the following theorem.
Theorem 5.17 (PAC compression bound) Suppose we are given a ﬁxed learning
algorithm /BT:∪∞
m=1
/CIm→ /C0⊆ /CH
/CGwhich is a compression scheme. F or any
probability measure PZand anyδ∈(0,1], with probability at least 1−δover
the random draw of the training sample z∈ /CIm,i fR emp [
/BT(z),z]=0and /BT(z)
corresponds to a compression scheme of size d, the expected risk R [
/BT(z)]of the
function /BT(z)∈ /C0is bounded from above by
R[
/BT(z)]≤1
m−dparenleftbigg
lnparenleftbiggparenleftbiggm
dparenrightbigg
d!parenrightbigg
+ln(m)+lnparenleftbigg1
δparenrightbiggparenrightbigg
.
Furthermore, if /BTis a permutation invariant compression scheme, then
R[
/BT(z)]≤1
m−dparenleftbigg
lnparenleftbiggparenleftbiggm
dparenrightbiggparenrightbigg
+ln(m)+lnparenleftbigg1
δparenrightbiggparenrightbigg
. (5.16)
In order to understand the full power of this theorem we note that according to
Theorem A.105 for all d∈{1,..., m},parenleftbigm
dparenrightbig
<summationtextd
i=0parenleftbigm
iparenrightbig
<parenleftbigem
dparenrightbigdwhich shows
that for permutation invariant compression schemes the generalization error bound(5.16) can be written as
5
R[
/BT(z)]≤2
mparenleftbigg
dlnparenleftBigem
dparenrightBig
+ln(m)+lnparenleftbigg1
δparenrightbiggparenrightbigg
.
Disregarding the improved constants, this is the same bound as obtained in the
PAC framework (see equation (4.21) and (4.19)) with the important differencethat the number dof examples used is not known a-priori but depends on the
4 Note that in the case of permutation invariant compression schemes the factor of d!vanishes.
5 Note that this result is trivially true for d>m/2; in the other case we used 1 /(m−d)≤2/m.
180 Chapter 5
training sample z∈ /CImand learning algorithm /BT. Since we no longer consider
the empirical risk minimization algorithm we see that it is possible to obtainguarantees on the generalization error R[/BT]even if the hypothesis space /C0has
inﬁnite VC dimension ϑ/C0. It is worth mentioning that the result as it stands has
an intuitive interpretation: If we view d/mas a (data dependent) compression
coefﬁcient then Theorem 5.17 justiﬁes the statement that a small compression
coefﬁcient guarantees a small expected risk of the function learned.
From this derivation we see that the procedure can readily be generalized to the
case of a lossy compression scheme of size d, that is, the hypothesis reconstructed
by /CAd(z/BVd(z))∈ /C0still commits some training errors on the given training sample
z. If we ﬁx the maximum number of training errors committed to q∈{1,..., m}
we are interested in bounding the probability of having training samples z∈ /CIm
such that the training error Remp[ /CAd(z/BVd(z)),z]≤q
mbut with the expected risk
R[ /CAd(z/BVd(z))]of the function learned greater than ε. Using the same technique as
in the PAC case we obtain
PZmparenleftBigparenleftBig
Rempbracketleftbig/CAdparenleftbig
Z/BVd(Z)parenrightbig
,Zbracketrightbig
≤q
mparenrightBig
∧parenleftbig
Rbracketleftbig/CAdparenleftbig
Z/BVd(Z)parenrightbigbracketrightbig
>εparenrightbigparenrightBig
≤summationdisplay
i∈Id,mPZmparenleftBigparenleftBig
Rempbracketleftbig/CAd(Zi),Zbracketrightbig
≤q
mparenrightBig
∧parenleftbig
Rbracketleftbig/CAd(Zi)bracketrightbig
>εparenrightbigparenrightBig
.
Again, for any i∈Id,mwe know that if /CAd(zi)commits no more than qerrors
onz, then the number of errors committed on the subset (z\zi)∈ /CIm−dcannot
exceed q. Hence, any summand in the last expression is upper bounded by
EZdbracketleftbigg
PZm−d|Zd=zparenleftbiggparenleftbigg
Rempbracketleftbig/CAd(z),Zbracketrightbig
≤q
m−dparenrightbigg
∧(R[
/CAd(z)]>ε)parenrightbiggbracketrightbigg
.
Using Hoeffding’s inequality for any ﬁxed sample z∈ /CIdwe know that the
innermost probability cannot exceed expparenleftbig
−2(m−d)(ε−q/(m−d))2parenrightbig
.B ya n
application of the union bound over all theparenleftbigm
dparenrightbig
d!different index vectors i∈Id,m
we conclude that the following statement ϒi,q(z,m,δ)holds, with probability at
least 1−δover the random draw of the training sample z∈ /CIm, for all lossy
compression schemes of size iand maximal number of training errors q
parenleftBig
Remp [hz,z]>q
mparenrightBig
∨
R[hz]≤q
m−d+radicalBigg
lnparenleftbigparenleftbigm
dparenrightbig
d!parenrightbig
+lnparenleftbig1
δparenrightbig
2(m−d)
,
181 Bounds for Speciﬁc Algorithms
where we used the shorthand notation hzdef= /CAi(z/BVi(z)). Combining the m2different
statements for all the possible values of i∈{1,..., m}and q∈{1,..., m}and
using Lemma 4.14 with uniform PSwe have proven the following theorem.
Theorem 5.18 (Lossy compression bound) Suppose we are given a ﬁxed learn-
ing algorithm /BT:∪∞
m=1
/CIm→ /C0⊆ /CH
/CGwhich is a compression scheme. F or any
probability measure PZand anyδ∈(0,1], with probability at least 1−δover the
random draw of the training sample z∈ /CIm,i f /BT(z)corresponds to a compression
scheme of size d, the expected risk R [
/BT(z)]of the function /BT(z)∈ /C0is bounded
from above by
R[
/BT(z)]≤m
m−dRemp [
/BT(z),z]+radicalBigg
lnparenleftbigparenleftbigm
dparenrightbig
d!parenrightbig
+2l n(m)+lnparenleftbig1
δparenrightbig
2(m−d).
Furthermore, if /BTis a permutation invariant compression scheme, then
R[
/BT(z)]≤m
m−dRemp [
/BT(z),z]+radicalBigg
lnparenleftbigparenleftbigm
dparenrightbigparenrightbig
+2l n(m)+lnparenleftbig1
δparenrightbig
2(m−d).
This result and Theorem 5.17 constitute the basic results of the compression frame-
work. One of the most intriguing features of these inequalities is that, regardlessof any a-priori complexity measure (e.g., VC dimension ϑ/C0or the size|/C0|of the
hypothesis space /C0), they will always attain nontrivial values, provided that the
number dof training examples used is at least as small as half the training sample
size. To some extent, this is similar reasoning to that used in the luckiness frame-work. The difference, however, is that in the current framework we have consideredwhat we are actually interested in—the expected risk R[/BT(z)]of the hypothe-
sis /BT(z)∈ /C0learned—rather than providing uniform bounds over version space
V/C0(z)which introduce additional technical difﬁculties such as probable smooth-
ness (see Deﬁnition 4.18).
Remark 5.19 (Ghost sample) There exists an interesting relationship between the
technique of symmetrization by a ghost sample (see page 124) used in the PAC/VCframework and the compression framework. Since we consider only the expected
risk of the hypothesis learned by a ﬁxed learning algorithm and assume that thishypothesis can be reconstructed from d /lessmuchm training examples, the remaining m −
d training examples constitute a ghost sample on which the hypothesis succeeds(lossless compression) or commits a small number q of errors (lossy compression).
182 Chapter 5
Hence, by exploiting the high compressibility of the training sample, there is
no need for an extra ghost sample. In contrast, in the PAC/VC framework wecannot exploit the high compression coefﬁcient of the hypothesis learned since weconsider all consistent hypotheses uniformly. Furthermore, in this case the analysisis irrespective of the learning algorithm used.
5.2.2 On-line Learning and Compression Schemes
One of the most interesting applications of the compression framework is in thearea of on-line learning algorithms. Broadly speaking, an on-line algorithm is alearning algorithm that proceeds in trials. In each trial the algorithm is presentedwith an unlabeled example x
j∈xand produces a prediction hjparenleftbig
xjparenrightbig
using the
current hypothesis hj∈ /C0. It then receives a class yj∈yfor the example
xj∈xand incurs a mistake if the label differs from the current hypothesis’
prediction. After each revealed class yjthe algorithm is allowed to change the
current hypothesis hj. More formally this reads as follows.
Deﬁnition 5.20 (On-line learning algorithm) Given an input space /CG, a ﬁnite
output space /CHand a hypothesis space /C0⊆ /CH
/CG,a n on-line algorithm /BT/CDfor/C0can be written as/BT/CD(z)def= /CDparenleftbig
yj|j|,xj|j|, /CDparenleftbig
··· /CDparenleftbig
yj2,xj2, /CDparenleftbig
yj1,xj1,h0parenleftbig
xj1parenrightbigparenrightbigparenleftbig
xj2parenrightbigparenrightbigparenrightbigparenleftbig
xj|j|parenrightbigparenrightbig
,
where /CD: /CH× /CG× /CH→ /C0is an update function which maps the current
class y j∈ /CH, the current object x j∈ /CGand the prediction of the current
hypothesis h j∈ /C0to a (potentially) new hypothesis h j+1. The index vector
j=(j1,j2,...)∈∪∞
i=1{1,..., m}idetermines the deterministic order of the
training examples. Note that it is possible to present the same training example
(xi,yi)∈zseveral times.
An example of an on-line learning algorithm is the perceptron learning algorithm;
it starts at the hypothesis h0:x/mapsto→ sign(/angbracketleftx,0/angbracketright)and, in each step of the algorithm,
it checks whether the current weight vector correctly classiﬁes the new trainingobject. The current hypothesis is only changed if a mistake occurs. Such class ofalgorithms deserves special attention for our current analysis.
Deﬁnition 5.21 (Mistake-driven algorithm) An on-line learning algorithm/BT/CD
ismistake-driven if the update function only changes the hypothesis following
183 Bounds for Speciﬁc Algorithms
mistakes, i.e.,
∀x∈ /CG:∀y∈ /CH:∀h∈ /C0:(y=h(x))⇒ /CD(y,x,h(x))=h.
In the study of on-line learning algorithms it is particularly important to know its
performance, measured by the number of steps until convergence.
Deﬁnition 5.22 (Mistake bound) Given a hypothesis space /C0⊆ /CH
/CGand an input
sequence x∈ /CGmlet us assume that the sequence y∈ /CHmof classes is obtained
by y i=h(xi)for some hypothesis h ∈ /C0(also called the target concept). The
function M/BT: /CIm→ /C6is called a mistake bound for the on-line learning
algorithm /BTif it bounds the number of mistakes /BTincurs on z=(x,y)∈ /CIm
for any ordering j∈∪∞
i=1{1,..., m}i.
Since a mistake-driven on-line learning algorithm /BTeffectively disregards the
training examples on which it never makes a mistake we are able to cast it intoa compression framework. In fact, if we imagine we run the mistake-driven algo-rithm/BTon the training sample z∈ /CIm, only tracking the indices ion which it
makes a mistake (compression function /BVi) and re-run the on-line learning algo-
rithm on the reduced training sample6zi(reconstruction function /CA|i|) we obtain
by deﬁnition the same ﬁnal hypothesis. Thus we have the following theorem.
Theorem 5.23 (Mistake bounds into generalization error bounds) Suppose we
are given a mistake-driven on-line learning algorithm /BTfor /C0⊆ /CH
/CGtogether
with a mistake bound M/BT: /CIm→ /C6. F or any probability measure PZand any
δ∈(0,1], with probability at least 1−δover the random draw of the training
sample z=(x,y)∈ /CIm, if there exists a hypothesis h ∈ /C0such that y i=h(xi)
then the expected risk R [
/BT(z)]of the function /BT(z)is bounded from above by
R[
/BT(z)]≤2
mparenleftbigg
M/BT(z)·ln(em)+ln(m)+lnparenleftbigg1
δparenrightbiggparenrightbigg
. (5.17)
We present two applications of Theorem 5.23 which demonstrate the power of
this simple consideration by reproducing results already obtained (with much moreeffort) in the VC framework.
6 Here we assume that, in a given ordering, all indices to removed examples have been dropped.
184 Chapter 5
Example 5.24 (Perceptron learning algorithm) Let us consider again the per-
ceptron learning algorithm given at page 321. This algorithm is by deﬁnition amistake-driven algorithm having a mistake bound
M/BT(z)=max
w∈ /CFparenleftbiggmax xi∈x/bardblφ(xi)/bardbl
γz(w)parenrightbigg
=parenleftbiggmax xi∈x/bardblφ(xi)/bardbl
γz(wSVM)parenrightbigg2
as given in Theorem 2.31. Here, xdef=φ(x)andφ: /CG→ /C3⊆/lscriptn
2is some mapping
of the objects x ∈ /CGinto a feature space /C3(see also Deﬁnition 2.2). Remarkably,
this mistake bound is dominated by the margin a support vector machine would
have achieved on the same training sample z. Substituting this result directly into
equation (5.17) shows that we can give a tighter generalization error bound forthe perceptron learning algorithm by studying its properties than for the supportvector machine algorithm when using the uniform bounds presented in the lastchapter (see Section 4.4 and Theorem 4.32).
Example 5.25 (Halving algorithm) F or ﬁnite hypothesis spaces/C0, there exists a
mistake-driven learning algorithm which achieves a minimal mistake bound. This
on-line learning algorithm is called the halving algorithm and proceeds as follows:
1.Initially, all hypotheses h ∈ /C0are stored in the set C = /C0of consistent
classiﬁers.
2.Given a new training object x i∈xthe classˆy∈ /CHwhich receives the majority
of votes from all consistent classiﬁers h ∈C is predicted, that is,
ˆy=argmax
y∈ /CH|{h∈C|h(x)=y}|. (5.18)
3.In the case of a mistake, i.e., y i/negationslash=ˆy all hypotheses in C which are inconsistent
are removed, so, C ← C\{h∈C|h(xi)/negationslash=yi}.
4.If all training examples are correctly classiﬁed, it outputs any hypothesis h ∈C
from the ﬁnal set of consistent classiﬁers.
Clearly, this is a mistake-driven procedure. Further , if /CHhas only two classes the
maximum number of mistakes this algorithm incurs is ld(|/C0|)because, at each
mistake, the set C is at least halved (if not, then (5.18) would not have incurred amistake). Plugging ld(|/C0|)for M/BT(z)into equation (5.17) we see that we have
recovered the basic VC bound for ﬁnite hypothesis spaces (see Theorem 4.6). Sincethe halving algorithm outputs any consistent function, the resulting bound would
185 Bounds for Speciﬁc Algorithms
hold uniformly over version space C =V/C0(z). Interestingly, by construction this
is also true for the VC bound.
5.3 Algorithmic Stability Bounds
In this last section we present a very recently developed method for studyingthe generalization error of learning algorithms. In contrast to the compressionframework we now do not need to enforce the existence of compression andreconstruction functions. Instead, we take advantage of the robustness of a learningalgorithm. The robustness of a learning algorithm/BTis a measure of the inﬂuence
of an additional training example (˜x,˜y)∈ /CIon the learned hypothesis /BT(z)∈ /C0.
Here, the inﬂuence is quantiﬁed in terms of the loss achieved at any (potential) test
object x∈ /CG. We observe that a robust learning algorithm guarantees that both the
difference in expected risks and empirical risks of the function learned is boundedeven if we replace one training example by its worst counterpart. This observationis of great help when using McDiarmid’s inequality given in Theorem A.119—a large deviation result perfectly suited for the current purpose. This inequalitybounds the probability that a function of the training sample z∈/CIm(the difference
R[
/BT(z)]−Remp [
/BT(z),z]of the expected and empirical risk of the function
learned from the training sample z) deviates from its expected value in terms of
the maximum deviation between the function’s value before and after one exampleis changed. In fact, the deﬁnition of robustness of a learning algorithm is mainlychosen so as to be able to apply this powerful inequality to our current problem.
5.3.1 Algorithmic Stability for Regression
Because of its simplicity we shall start with the regression estimation case, that is,we consider a training sample z=(x,t)∈(/CG× /CA)mdrawn iid from an unknown
distribution PZ=PT|XPX. In this case the hypotheses are given by real-valued
functions f∈ /BYwhere /BY⊆ /CA
/CG. Further, the loss function l: /CA× /CA→ /CA
becomes a function of predicted real values ˆtand observed real values t(see, for
example the squared loss deﬁned on page 82). Before proceeding we introducesome abbreviations for the sake of notational simplicity. Given a sample z∈/CIm,
a natural number i∈{1,..., m}a n da ne x a m p l e z∈ /CIlet
z\idef=(z1,..., zi−1,zi+1,..., zm)∈ /CIm−1,
186 Chapter 5
zi↔zdef=(z1,..., zi−1,z,zi+1,..., zm)∈ /CIm,
be the sample with the ith element deleted or the ith element replaced by z,
respectively. Whenever the learning algorithm is clear from context, we use fzdef=/BT(z). Then the notion of robustness of a learning algorithm is formally deﬁned as
follows.
Deﬁnition 5.26 (Uniform stability) A learning algorithm /BT:∪∞
m=1
/CIm→ /BYis
said to be βm–stable w.r.t. the loss function l: /CA× /CA→ /CAif the following holds
for all i∈{1,..., m}
∀z∈ /CIm:∀(x,t)∈ /CI:vextendsinglevextendsinglel(fz(x),t)−lparenleftbig
fz\i(x),tparenrightbigvextendsinglevextendsingle≤βm.
It is worth pointing out that βm–stability of a learning algorithm /BTimplies ro-
bustness in the more usual sense of measuring the inﬂuence of an extra training
exampleparenleftbig
˜x,˜tparenrightbig
∈ /CI. This is formally expressed in the following theorem.
Theorem 5.27 (Robustness of βm–stable algorithms) Suppose we are given a
βm–stable learning algorithm /BT:∪∞
m=1
/CIm→ /BY w.r .t. the loss function
l: /CA× /CA→ /CA. Then, for any training sample z∈ /CIm, any˜z∈ /CI, any(x,t)∈ /CI
and all i∈{1,..., m}
vextendsinglevextendsinglel(fz(x),t)−lparenleftbig
fzi↔˜z(x),tparenrightbigvextendsinglevextendsingle≤2βm.
Proof First, we notice that that l(fz(x),t)−lparenleftbig
fzi↔˜z(x),tparenrightbig
equals
parenleftbig
l(fz(x),t)−lparenleftbig
fz\i(x),tparenrightbigparenrightbig
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
a+parenleftbig
lparenleftbig
fz\i(x),tparenrightbig
−lparenleftbig
fzi↔˜z(x),tparenrightbigparenrightbig
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
b.
From this, the result follows by the triangle inequality applied to aand band the
fact that the absolute value of aand bis by deﬁnition upper bounded by βm.
Note that the value of βmdepends on the training sample size m, so, for larger
training samples the inﬂuence of a single example (x,t)∈ /CIshould be decreasing
toward zero. We will call an algorithm “stable” if the decrease in βmis of order
one, lim m→∞βm·m−1=0. In order to compute values of βmfor a rather large
class of learning algorithms it is useful to introduce the following concept.
187 Bounds for Speciﬁc Algorithms
Deﬁnition 5.28 (Lipschitz continuous loss function) A loss function l : /CA× /CA→/CAis said to be Lipschitz continuous (in its ﬁrst argument) if
∀ˆt∈ /CA:∀˜t∈ /CA:∀t∈ /CA:vextendsinglevextendsinglelparenleftbigˆt,tparenrightbig
−lparenleftbig˜t,tparenrightbigvextendsinglevextendsingle≤Cl·vextendsinglevextendsingleˆt−˜tvextendsinglevextendsingle.
The value C l∈ /CA+is called the Lipschitz constant of the loss function l .
Thus, whenever we are given a Lipschitz continuous loss function we are able to
use the differencevextendsinglevextendsinglefz(x)−fz\i(x)vextendsinglevextendsingleto bound the difference of the losses incurred
by two functions fz∈ /BYand fz\i∈ /BYat any test object x∈ /CG. Let us give a few
examples of Lipschitz continuous loss functions which we have already used in theconsideration of learning algorithms for the regression estimation problem in PartI of this book.
Example 5.29 (Soft margin loss) If we consider the linear soft margin loss func-
tion given in equation (2.47), namely l
linparenleftbigˆt,yparenrightbig
=maxbraceleftbig
1−yˆt,0bracerightbig
where y∈
{−1,+1}, we see that
vextendsinglevextendsinglellinparenleftbigˆt,yparenrightbig
−llinparenleftbig˜t,yparenrightbigvextendsinglevextendsingle≤vextendsinglevextendsingley˜t−yˆtvextendsinglevextendsingle=vextendsinglevextendsingleyparenleftbig˜t−ˆtparenrightbigvextendsinglevextendsingle=vextendsinglevextendsingleˆt−˜tvextendsinglevextendsingle.
This shows that l linis Lipschitz continuous with the Lipschitz constant C llin=1.
Example 5.30 ( ε–insensitive loss) A closer inspection of the ε–insensitive loss
function (2.51), i.e., l εparenleftbigˆt,tparenrightbig
=maxparenleftbigvextendsinglevextendsinglet−ˆtvextendsinglevextendsingle−ε,0parenrightbig
, which is used for regression
estimation with support vector machines, shows that this loss function is Lipschitzcontinuous with the Lipschitz constant C
lε=1because
vextendsinglevextendsinglelεparenleftbigˆt,tparenrightbig
−lεparenleftbig˜t,tparenrightbigvextendsinglevextendsingle≤vextendsinglevextendsinglevextendsinglevextendsinglet−ˆtvextendsinglevextendsingle−vextendsinglevextendsinglet−˜tvextendsinglevextendsinglevextendsinglevextendsingle≤vextendsinglevextendsingle˜t−ˆtvextendsinglevextendsingle.
Using the concept of Lipschitz continuous loss functions we can upper bound the
value of βmfor a rather large class of learning algorithms using the following
theorem (see also Subsection 2.2.2).
Theorem 5.31 (Stability of regularized risk minimization algorithms) Let l:/CA× /CA→ /CAbe a convex Lipschitz continuous function in its ﬁrst argument with
Lipschitz constant C l. Given a reproducing kernel Hilbert space /BY⊆ /CA
/CGwith
kernel k: /CG× /CG→ /CA, any algorithm /BT:∪∞
m=1
/CIm→ /BYwhich can be written as/BT(z)=argmin
f∈ /BY1
msummationdisplay
(xi,ti)∈zl(f(xi),ti)+λ/bardblf/bardbl2, (5.19)
188 Chapter 5
whereλ> 0isβm–stable with respect to l with
βm≤C2
lκ2
2λm,
whereκ=supx∈ /CGk(x,x). Note that, in this formulation, the value m is ﬁxed for
any training sample z.
The proof of this result is given in Appendix C.9. By the generality of expression
(5.19) it is possible to cast most of the learning algorithms presented in Part I ofthis book into this framework. Now, in order to obtain generalization error boundsforβ
m–stable learning algorithms /BTwe proceed as follows.
1. Since we aim to use McDiarmid’s inequality we deﬁne a random variable g(Z)
which measures the difference of the expected risk R[fz]of the function fzand
some observable empirical quantity such as the training error Remp [fz,z]or the
leave-one-out error Rloo[
/BT,z](see Deﬁnition 2.35). An example of g(Z)might be
g(Z)=R[fZ]−Rempbracketleftbig
fZ,Zbracketrightbig
.
2. We then need to upper bound the expectation of gover the random draw of
training samples z∈ /CIm. This is because we are only interested in the probability
that g(Z)will be larger than some prespeciﬁed ε.
3. Another consequence of the usage of McDiarmid’s inequality is that we need
an upper bound on
sup
z∈ /CIm,˜z∈ /CI|g(z)−g(zi↔˜z)|,
which should preferably not depend on i∈{1,..., m}.
In Appendix C.9 we have carried out these steps to obtain generalization error
bounds both in terms of the training error as well as of the leave-one-out error.
This is summarized in the following theorem.
Theorem 5.32 (Algorithmic stability bound for regression estimation) Suppose
we are given a βm–stable learning algorithm /BTw.r .t. a loss function l : /CA× /CA→ /CA.
F or all probability measures PZ=PXTsuch that
PZm+1parenleftbig
lparenleftbig
f(Z1,...,Zm)(Xm+1),Tm+1parenrightbig
∈[0,b]parenrightbig
=1,
189 Bounds for Speciﬁc Algorithms
for anyε> 0we have
PZmparenleftbig
R[fZ]>Rempbracketleftbig
fZ,Zbracketrightbig
+ε+2βmparenrightbig
<expparenleftbigg
−mε2
2(4mβm+b)2parenrightbigg
,
PZmparenleftbig
R[fZ]>Rloobracketleftbig/BT,Zbracketrightbig
+ε+βmparenrightbig
<expparenleftbigg
−mε2
2(2m(βm+βm−1)+b)2parenrightbigg
.
At ﬁrst we note that these two bounds are essentially the same, i.e., the additive
correction is ≈βmand the decay of the probability is /C7(exp(−ε2/mβ2
m)).T h i s
comes as a slight surprise as VC theory appears to indicate that the training er-ror R
emp is only a good indicator of the generalization error of an algorithm when
the hypothesis space is of small VC dimension (see Theorem 4.7). In contrast theleave-one-out error disregards VC dimension and is an almost unbiased estima-tor of the expected generalization error of an algorithm (see Theorem 2.36). We
must recall, however, that VC theory is used in the study of empirical risk mini-
mization algorithms which only consider the training error as the cost function to
be minimized. In contrast, in the current formulation we have to guarantee a cer-tain stability of the learning algorithm. In particular, when considering the resultof Theorem 5.31 we see that, in the case of λ→ 0, that is, the learning algorithm
minimizes the empirical risk only, we can no longer guarantee a ﬁnite stability. Inlight of this fact, let us consider β
m–stable algorithms /BTsuch that βm≤ηm−1,
i.e., the inﬂuence of a single new training example is inversely proportional to thetraining sample size mwith a decay of η∈/CA+. With this the ﬁrst inequality in
Theorem 5.32 states that, with probability at least 1 −δover the random draw of
the training sample z∈ /CIm,
R[
/BT(z)]≤Remp [
/BT(z),z]+2η
m+radicalBigg
2(4η+b)2lnparenleftbig1
δparenrightbig
m.
This is an amazingly tight generalization error bound whenever η/lessmuch√
mbecause
the expression is dominated by the second term. Moreover, this result provides
us with practical guidelines on the possible values of the trade-off parameter λ.
Since for regularized risk minimization algorithms of the form (5.19) we know that
η≤C2
lκ2
2λ, it follows that λ≥C2
lκ2
bmbecause otherwise the bound would be trivial (as
large as b) regardless of the empirical term Remp [
/BT(z),z]. Before we proceed to
the classiﬁcation learning case we show an application of this new generalizationerror bound for a stable regression estimation algorithm presented in Part I.
190 Chapter 5
Example 5.33 (Support vector regression) In the case of linear functions f w∈/CA
/CGof the form f w=/angbracketleftw,x/angbracketright,w h e r e xdef=φ(x)andφ: /CG→ /C3⊆/lscriptn
2is some
mapping of the objects x ∈ /CGinto a feature space /C3(see also Deﬁnition 2.2),
we deﬁne/bardblfw/bardbl2as/bardblw/bardbl2. Then, if we consider the ε–insensitive loss as given by
equation (2.51) we retain the support vector regression algorithm/BTSVR(z)=fˆw∈ /CA
/CGsuch thatˆw=argmin
w∈ /C31
mmsummationdisplay
i=1lε(/angbracketleftw,xi/angbracketright,ti)+λ/bardblw/bardbl2.
Introducing 2m positive slack variables ξi∈ /CA+that capture the deviation of
/angbracketleftw,xi/angbracketrightfrom the observed value t ithis learning algorithm can also be expressed in
terms of the following mathematical program
minimize1
mξ/prime1+λ/bardblw/bardbl2
subject to t i−/angbracketleftw,xi/angbracketright≤ε+ξi, i∈{1,..., m},
/angbracketleftw,xi/angbracketright−ti≤ε+ξi+m, i∈{1,..., m},
ξ≥0.
If we combine the Lipschitz continuity of the ε–insensitive loss given in Example
5.30 with Theorems 5.31 and 5.32 we see that the support vector regression algo-
rithm has a generalization error bound of
R[
/BTSVR(z)]≤1
mparenleftbigg
ˆξ/prime1+κ2
λparenrightbigg
+radicaltpradicalvertexradicalvertexradicalbt
2parenleftBig
2κ2
λ+bparenrightBig2
lnparenleftbig1
δparenrightbig
m,
where ˆξ∈ /CA2mis the value of the slack variables at the minimum, κ=
supx∈ /CGk(x,x)and b∈ /CA+is a known upper bound on the values of the t i∈ /CA.
Note that R [
/BTSVR(z)]is the expected ε–insensitive loss of the learned function
fˆw. Besides providing a practically relevant generalization error bound the result
also has the intuitive interpretation that, for smaller values of λ, the term ˆξ/prime1is
non-increasing and competes with the increasing termκ2
λ.
5.3.2 Algorithmic Stability for Classiﬁcation
In classiﬁcation learning we are given a training sample z=(x,y)∈(
/CG× /CH)m
together with a hypothesis space /C0⊆ /CH
/CGof classiﬁers hmapping objects x∈ /CG
to classes y∈ /CH. We conﬁne ourselves to the zero-one loss l0−1parenleftbig
ˆy,yparenrightbig
=Iˆy/negationslash=y
191 Bounds for Speciﬁc Algorithms
−2.0 −1.5 −1.0 −0.5 0.0 0.5 1.00.0 0.2 0.4 0.6 0.8 1.0
−yf(x)clippedlossτ=1τ=2
τ=0.5
Figure 5.2 The clipped linear soft margin loss l τfor various values of τ> 0. Note that
forτ→ 0 the loss function approaches the zero-one loss I−yf(x)≥0.
although the following reasoning also applies to any loss that takes only a ﬁnite
set of values. Similarly to the results presented in the last subsection we wouldlike to determine the β
m–stability of a given classiﬁcation learning algorithm/BT:∪∞
m=1
/CIm→ /C0. It turns out, however, that the only two possible values of
βmare 0 and 1. The former case occurs if, for all training samples z∈ /CImand all
test examples (x,y)∈ /CI,
vextendsinglevextendsinglevextendsingleI/BT(z)(x)/negationslash=y−I/BT(z\i)(x)/negationslash=yvextendsinglevextendsinglevextendsingle=0,
which is only possible if /C0only contains one hypothesis. If we exclude this trivial
case from our considerations then we see that Theorem 5.32 only gives trivialresults for classiﬁcation learning algorithms. This is mainly due to the coarsenessof the loss function l
0−1.
In order to circumvent this problem we shall exploit the real-valued out-
put f(x)when considering classiﬁers of the form h(·)= sign(f(·)).S i n c e
our ultimate interest is in the generalization error R[h]= EXYbracketleftbig
Ih(X)/negationslash=Ybracketrightbig
=
EXYbracketleftbig
IY·f(X)≤0bracketrightbig
we will consider a loss function lτ: /CA× /CH→ [0,1]which is
an upper bound of the function Iyf(x)≤0. To see the advantage of such a loss func-
tion note that l0−1parenleftbig
ˆy,yparenrightbig
≤lτ(t,y)implies that EXYbracketleftbig
l0−1(sign(f(X)),Y)bracketrightbig
≤
192 Chapter 5
EXYbracketleftbig
lτ(f(X),Y)bracketrightbig
. Another useful requirement on the reﬁned loss function lτis
Lipschitz continuity with a small Lipschitz constant. This can be achieved by aslight reﬁnement of the linear soft margin loss l
linconsidered in Example 5.29. The
generalization is obtained by requiring a real-valued output of at least τon the cor-
rect side. Since the loss function has to pass through 1 for f(x)=0 it follows that
the steepness of the function is 1 /τ, giving the Lipschitz constant as 1 /τ. Finally
we note that lτshould always be in the interval [0,1]because the zero-one loss
l0−1will never exceed 1. Hence, we obtain the following version of the linear soft
margin loss which will serve our needs (see also Figure 5.2)
lτ(t,y)=

0i f yt>1
1−yt
τifyt∈[0,τ]
1i f yt<0. (5.20)
A direct application of Theorem 5.32 to the expected and empirical risks using
the loss function lτyields an algorithmic stability result for classiﬁcation learning
algorithms which use a thresholded real-valued function for classiﬁcation.
Theorem 5.34 (Algorithmic stability for classiﬁcation) Let /BY⊆ /CA
/CGbe a set of
real-valued functions and /BT:∪∞
m=1
/CIm→ /BYbe a given learning algorithm such
that the associated classiﬁcations are /C0={x/mapsto→sign(f(x))|f∈ /BY}.F o rt h e
zero-one loss l 0−1, for all probability measures PZsuch that PX(k(X,X)≤κ)=
1, for any τ∈ /CA+and anyδ∈(0,1], with probability at least 1−δover the
random draw of the training sample z∈ /CIm, the expected risk Rbracketleftbig
sign(
/BT(z))bracketrightbig
of
the classiﬁer /BT(z)∈ /BYis bounded from above by
Rbracketleftbig
sign(
/BT(z))bracketrightbig
≤Rτ
emp [
/BT(z),z]+κ2
λmτ2+radicaltpradicalvertexradicalvertexradicalbt
2parenleftBig
2κ2
λτ2+1parenrightBig2
lnparenleftbig1
δparenrightbig
m.
Note that the quantity Rτ
emp [f,z]is given by Rτ
emp [f,z]=1
msummationtextm
i=1lτ(f(xi),yi).
Again, we have the intuitive interpretation that, for larger values of τ, the term
Rτ
emp [f,z]=1
msummationtextm
i=1lτ(f(xi),yi)is provably non-increasing whereas the term
κ2
λmτ2is always increasing. It is worth considering this theorem for the special
case of linear soft margin support vector machines for classiﬁcation learning (seeSubsection 2.4.2). Without loss of generality let us assume that κ
2=1a sf o r
RBF kernels and normalized kernels (see Table 2.1). Noticing that the sumsummationtextm
i=1ˆξi
of the slacks ˆξ∈ /CAmat the solution upper bounds m·R1
emp [
/BT(z),z]we see
193 Bounds for Speciﬁc Algorithms
that the linear soft margin algorithm /BTSVC presented in Subsection 2.4.2 has a
generalization error bound w.r.t. the zero-one loss l0−1of
Rbracketleftbig
sign(
/BTSVC(z))bracketrightbig
≤1
mparenleftbigg
ˆξ/prime1+1
λparenrightbigg
+2radicalBigg
(1+λ)2lnparenleftbig1
δparenrightbig
λ2m.
This bound provides an interesting model selection criterion for linear soft margin
support vector machines. The model selection problem we considered here is theselection of the appropriate value of λ—the assumed noise level. In contrast to the
results of Subsection 4.4.3 this bound only holds for the linear soft margin support
vector machine and can thus be considered practically useful. This, however,
remains to be shown empirically. The results in this section are so recent that noempirical studies have yet been carried out.
Remark 5.35 (Leave-one-out bounds) In the current derivation we have only
presented the application of the training error variant of Theorem 5.32. We omitted
to show the application of the leave-one-out variant because the resulting bound
would involve the leave-one-out error w.r .t. the clipped loss l
τrather than the
zero-one loss l 0−1. Although there exist a plethora of bounds on the leave-one-
out error of most of the algorithms presented (e.g. Theorem 2.37) a computation ofthe leave-one-out error w.r .t. l
τrequires the invocation of the learning algorithm m
times which is computationally infeasible. An interesting area for further researchregards obtaining bounds on this quantity rather than on the usual leave-one-outerror w.r .t. the zero-one loss l
0−1.
5.4 Bibliographical Remarks
In this chapter we presented several frameworks for studying the generalization
error of speciﬁc learning algorithms. We started with a framework seemingly com-bining the best of two worlds: By studying Bayesian algorithms we have the powerof incorporating prior knowledge into the learning task via an explicit prior P
H
while we can still give PAC guarantees for the generalization error of Bayesian
classiﬁcation strategies. This framework, also known as the PAC-Bayesian frame-work, was introduced for the ﬁrst time in Shawe-Taylor and Williamson (1997,p. 4) where the authors cast a Bayesian algorithm in the luckiness framework. Re-markably, they concede that “... a Bayesian might say that luckiness is just a com-plicated way of encoding a prior. The sole justiﬁcation for our particular way of
194 Chapter 5
encoding is that it allows us to get the PAC like results we sought...”. In contrast to
their results—which hold for single classiﬁers drawn according to the posteriormeasure—McAllester (1998) considered classiﬁcation strategies which allowed
him to tighten the results and ease their proofs. Theorems 5.1, 5.2 and 5.6 canbe found in this paper; the more general result given in equation (5.9) togetherwith some remarks on how to generalize the framework to arbitrary loss functionscan be found in McAllester (1999). The simple relationship between the expected
risk of the Gibbs and the Bayes classiﬁcation strategies (Theorem 5.7) is takenfrom Herbrich and Graepel (2001b). The full power of the bound for the Bayesian
classiﬁer can be exploited by making use of the fact that for “benign” hypothesis
spaces the expected risk of one classiﬁer can be expressed as the generalizationerror of a subset of classiﬁers. This analysis, together with the ﬁnal PAC-Bayesianmargin bound (Theorem 5.10) can be found in Herbrich and Graepel (2001b). Re-cently, it has been shown that not only the evidence can be justiﬁed in a distributionfree framework, but also the estimated posterior probability P
H|Zm=z(H(x)=y)
leads to a decrease in expected risk when used as a rejection criterion (see Freund
et al. (2000)). In contrast to the bounds in the PAC-Bayesian framework, this paperstudies only the generalization error of their (pseudo)-Bayesian prediction methodwhich results in remarkably tight bounds. A work preceeding Shawe-Taylor andWilliamson (1997, p. 4) is by Haussler et al. (1994) where it was assumed thatP
His known to the learning algorithm and corresponds to the probability of target
concepts. Rather than studying the performance of Bayesian classiﬁcation strate-gies for a ﬁxed, but unknown, data distribution P
Zit was assumed that the prior
belief PHis used to govern PY|X=x. It was shown that the average generalization
error of classiﬁcation strategies over PHcan be arbitrarily bad without assuming
that the learning algorithm uses the same PH. It should be noted, however, that this
quantity does not satisfy the PAC desiderata of not knowing the data distribution.
In the following section we introduced the notion of compression schemes.
One of the earliest works in that area is by Littlestone and Warmuth (1986) whichwas summarized and extended to on-line learning algorithms in Floyd and War-muth (1995). Theorem 5.17 is taken from this paper; the lossy compression schemebound (Theorem 5.18) was proven in Graepel et al. (2000); see also Marchand andShawe-Taylor (2001) for a result that avoids the exponent two at the deviation ε.
Interestingly, all these results can be extended further by allowing the learning algo-rithm to save an additional bbits which would only incur an additional summand
of
b
min the resulting generalization error bound. An interesting combination of
large margins of the linear classiﬁer learned by an algorithm and sparsity w.r.t. the
expansion coefﬁcients is presented in Herbrich et al. (2000). The subsection on the
195 Bounds for Speciﬁc Algorithms
combination of compression schemes and mistake bounds for mistake-driven on-
line learning algorithms is taken from Floyd and Warmuth (1995). Example 5.24 isdiscussed in greater length in Graepel et al. (2001). The notion of on-line learningalgorithms is due to Littlestone (1988). This paper also introduced the halving algo-rithm together with its mistake bound (see Example 5.25). An interesting questionemerging from the analysis in the compression framework is the following: Givena learning algorithm which maps into a hypothesis space of VC dimension ϑ/C0,i s
it always possible to ﬁnd a compression scheme of size not more than ϑ/C0that will
be consistent, provided some target concept from /C0is used to label the data? This
is still an open problem; for ﬁrst attempts to solve it the interested reader is referred
to Floyd and Warmuth (1995).
Finally, we demonstrated that we can study the generalization error of learning
algorithms by considering their robustness. The notion of robustness of a learningalgorithm is far from new but was mainly considered in the analysis of the leave-one-out model selection procedure (see Devroye and Wagner (1979) and Kearnsand Ron (1999)). The results presented in Section 5.3 are mainly taken fromBousquet and Elisseeff (2000) and Bousquet and Elisseeff (2001). The interestedreader is referred to their work for further details.
III Appendices

A Theoretical Background and Basic Inequalities
The purpose of this appendix is twofold: On the one hand, it should serve as
a reference for the case that we need more exactness in the reasoning. On the
other hand, it gives brief introductions to probability theory, functional analysisand ill-posed problems. The section on probability theory is based on Feller (1966,Chapter 4) and Kockelkorn (2000). The following section about functional analysisis compiled from Barner and Flohr (1989), Cristianini and Shawe-Taylor (2000)and Debnath and Mikusinski (1998). The section about ill-posed problems is takenfrom Tikhonov and Arsenin (1977). Finally, we present a set of inequalities neededfor the derivation of some of the results in the book.
A.1 Notation
In addition to the special notation introduced in the following sections, it was myobjective to make things clearer by consistency. Thus, the general ideas underlyingthe notation are: Parentheses are used for the evaluation of a function, e.g., f(x),
whereas brackets should indicate the application of a functional, e.g., R[f];t h e
concept of bold face is to denote composed objects like tuples, vectors, matrices orvector valued functions
1, e.g., x,x,Xorφ; calligraphic letters specify spaces or
speciﬁc sets, e.g., /C3; fraktur letters should stand for collection of sets and algebras,
e.g., /BT; sans-serif letters indicate that the speciﬁc value of the object is subject to
chance, e.g., X. Deviations from these broad guidelines are indicated to avoid too
complicated a notation2.
1 Sometimes, the symbol /vectorxis also used for vectors. This will always be indicated in order to avoid confusion.
2 Due to the lack of available symbols we will use /C7to denote the order of a term and /BUto denote Borel
sets. Furthermore, we use the special symbols E,P,v,f,Fand Ito denote the expectation value, the probability
measure, the empirical probability measure, the dens ity, the distribution function and the indicator function.
200 Appendix A
A.2 Probability Theory
In general, sets are denoted by roman upper capital letters, e.g., X, whilst elements
are denoted by roman lower capital letters, e.g., x. For sets the indicator function
IXis deﬁned by
IX(x)def=braceleftbigg0i f x/∈X
1i f x∈X.
Ifϒ: /CG→{true,false}is a logical formula then Iϒ(x)is shorthand notation for
I{z∈ /CG|ϒ(z)=true}(x).
Deﬁnition A.1 ( σ–algebra) Given a set /CG, a collection /CGof sets X⊆ /CGis called
aσ–algebra over /CGif and only if
1.If a set X∈ /CGso is its complement Xc= /CG\X.
2.If X i∈ /CG,i=1,...,∞is any countable collection of sets in /CG, then also their
union∪∞
i=1Xi∈ /CGand intersection ∩∞
i=1Xi∈ /CGbelong to /CG.
In short, any σ–algebra /CGis closed under complementation and the formation of
countable unions and intersections.
Deﬁnition A.2 (Borel sets) Given /CG= /CAn,t h e Borel sets /BUnare the smallest
σ–algebra that contains all open intervals
braceleftbig
(x1,..., xn)∈ /CAn|∀i∈{1,..., n}:xi∈(ai,bi)bracerightbig
for all a i,bi∈ /CA. Note that /BUncontains an uncountable number of sets.
Deﬁnition A.3 (Measurable and probability space) Ameasurable space is de-
ﬁned by the tuple (
/CG, /CG).H e r e /CGis called the sample space and /CGis aσ–algebra
over /CG.A probability space is deﬁned by the triple (
/CG, /CG,P)where Pis a proba-
bility measure on /CG, i.e., P: /CG→ [0,1]such that P(
/CG)=1and for all countable
collections of non-overlapping sets X i∈ /CG,i=1,...,∞
PparenleftBigg∞uniondisplay
i=1XiparenrightBigg
=∞summationdisplay
i=1P(Xi).
201 Theoretical Background and Basic Inequalities
In most circumstances, the measurable space is clear from context. In order to
avoid ambiguities about the used probability measure Pwe shall use a sans serif
letter as a subscript. Thus, if ϒis a measurable logical formula over x∈ /CG, i.e.,
ϒ: /CG→{true,false}and{x∈ /CG|ϒ(x)=true}∈ /CG,
PX(ϒ(X))def=P({x∈ /CG|ϒ(x)=true})
denotes the probability of ϒ(x)when xis selected according to P.
Deﬁnition A.4 (Measurability) Given a measurable space (
/CG, /CG), the real-
valued function g : /CG→ /CAis called /CG–measurable (or simply measurable) if
and only if
∀z∈ /CA:{x∈ /CG|g(x)≤z}∈ /CG.
Deﬁnition A.5 (Random variable) Given a measurable space (
/CG, /CG),arandom
variable is a /CG–measurable real-valued function f : /CG→ /CA.
In order to distinguish random variables from ordinary functions we also use sans
serif letters to denote them, e.g., Y= f(X). Thus a random variable Y= f(X)
induces a measure PYwhich acts on the real line, i.e., /CH= /CAand for which the
σ–algebra /CHcontains at least the intervals {(−∞,z]|z∈ /CA}. The measure PYis
induced by the measure PXand f, i.e.,
∀Y∈ /BU1: PY(Y)def=PX({x∈ /CG|f(x)∈Y}).
Deﬁnition A.6 (Distribution function and density) F or a random variable Xthe
function FX: /CA→ [0,1]deﬁned by
FX(x)def=PX(X≤x)
is called the distribution function ofX. The function fX: /CA→ /CAis called the
density if
∀z∈ /CA: FX(z)=integraldisplay
x≤zfX(x)dx.
In the study of learning as well as statistics the expectation of a random variable is
of particular importance.
202 Appendix A
Deﬁnition A.7 (Expectation) Let f: /CG→ /CAbe a measurable function. The
expectation EXbracketleftbig
f(X)bracketrightbig
of f over the random draw of x is deﬁned by
EXbracketleftbig
f(X)bracketrightbigdef=integraldisplay/CAf(x)dFX(x).
The expectation value is only deﬁned ifintegraltext/CA|f(x)|dFX(x)<∞.
Deﬁnition A.8 (Variance) The variance V ar (X)of a random variable Xis deﬁned
by
Va r(X)def=EXbracketleftBig
(X−µ)2bracketrightBig
=EXbracketleftbig
X2bracketrightbig
−µ2,
whereµ=EXbracketleftbig
Xbracketrightbig
is the expectation of the random variable X.
Deﬁnition A.9 (Product space) Given two measurable spaces (
/CG, /CG)and(
/CH, /CH)
we deﬁne the product space by(
/CG× /CH, /CG× /CH).H e r e /CG× /CHdenotes the smallest
σ–algebra which contains the sets {X×Y|X∈ /CG,Y∈ /CH}.
Deﬁnition A.10 (Marginal and conditional measure) Given the joint probability
space(
/CG× /CH, /CG× /CH,PXY),t h e marginal probability measure PXis deﬁned by
∀X∈ /CG: PX(X)def=PXY(X× /CH).
Given Y∈ /CH,PY(Y)>0,t h e conditional probability measure PX|Y∈Yis given by
∀X∈ /CG: PX|Y∈Y(X)def=PXY(X×Y)
PY(Y).
(PYand PY|X∈Xare given in the same way).
Deﬁnition A.11 (Independence) We call the random variables XandYindepen-
dent (w.r .t. the measure PXY), if and only if
∀X∈ /CG:∀Y∈ /CH: PXY(X×Y)=PX(X)PY(Y).
In this case, the marginal distributions sufﬁce to deﬁne the whole product measure.
If(
/CG, /CG)equals(
/CH, /CH)we shall write PX2as an abbreviation for PXX.
Whenever we deal with a sequence of nrandom variables X1,..., Xnwe denote
the whole sequence by X. Such a sequence can either be a column or row vector,
203 Theoretical Background and Basic I nequa lities
which should be clear from the context. A particular element of the sample space/CGnis then denoted by the n–tuple x. Given an n–tuple x=(x1,..., xn),t h e
abbreviation x∈xshould be understood as ∃i∈{1,..., n}:xi=x.
Deﬁnition A.12 (Expectation of a n–dimensional random variable) Given n ran-
dom variables X=(X1,..., Xn)with a joint measure PX,t h e expectation EXbracketleftbig
Xbracketrightbig
is deﬁned by the n–tuple
EXbracketleftbig
Xbracketrightbigdef=parenleftbig
EX1bracketleftbig
X1bracketrightbig
,..., EXnbracketleftbig
Xnbracketrightbigparenrightbig
.
Deﬁnition A.13 (Covariance and covariance matrix) Given two random vari-
ables XandYwith a joint measure PXY,t h e covariance Cov (X,Y)is deﬁned
by
Cov(X,Y)def=EXYbracketleftbig
(X−µ)(Y−ν)bracketrightbig
,
whereµ=EXbracketleftbig
Xbracketrightbig
andν=EYbracketleftbig
Ybracketrightbig
. Note that Cov(X,X)=Va r(X). Given n
random variables X=(X1,..., Xn)and m random variables Y=(Y1,..., Ym)
having a joint measure PXY,t h en×mcovariance matrix Cov(X,Y)is deﬁned by
Cov(X,Y)def=
Cov(X1,Y1)··· Cov(X1,Ym)
.........
Cov(X
n,Y1)··· Cov(Xn,Ym)
.
IfX=Ywe abbreviate Cov(X,X)def=Cov(X).
Deﬁnition A.14 (Empirical measure) Given a measurable space (
/CG, /CG)and a
sequence x∈ /CGnwe call vxthe empirical measure deﬁned by
∀A∈ /CG: vx(A)def=|{i∈{1,..., n}|xi∈A}|
n.
A.2.1 Some Results for Random Variables
In this subsection we will present some results for the expectation and variance of
sums and products of random variables. These will prove to be useful for most of
Chapter 3.
204 Appendix A
Theorem A.15 (Expectation of sum and products) Given two independent ran-
dom variables XandY
EXYbracketleftbig
X·Ybracketrightbig
= EXbracketleftbig
Xbracketrightbig
·EYbracketleftbig
Ybracketrightbig
, (A.1)
EXYbracketleftbig
X+Ybracketrightbig
= EXbracketleftbig
Xbracketrightbig
+EYbracketleftbig
Ybracketrightbig
. (A.2)
whenever the two terms on the r .h.s. exist. Note that statement (A.2) is also true if
XandYare not independent.
Corollary A.16 (Linearity of the expectation) F or any n–dimensional random
variable X, any matrix A∈ /CAm×nand any ﬁxed vector b∈ /CAmwe have
EXbracketleftbig
AX+bbracketrightbig
=AEXbracketleftbig
Xbracketrightbig
+b.
Theorem A.17 (Variance decomposition) Given two independent random vari-
ables XandYwe have
Va r(X+Y)=Va r(X)+Va r(Y).
Proof Putµ=Ebracketleftbig
Xbracketrightbig
andν=EYbracketleftbig
Ybracketrightbig
. Exploiting Deﬁnition A.8 we know that
the variance V ar (X+Y)is given by
EXYbracketleftBigparenleftbig
X+Y−EXYbracketleftbig
X+Ybracketrightbigparenrightbig2bracketrightBig
=EXYbracketleftBig
((X−µ)+(Y−ν))2bracketrightBig
=EXYbracketleftBigparenleftBig
(X−µ)2+2(X−µ)(Y−ν)+(Y−ν)2parenrightBigbracketrightBig
=EXbracketleftBig
(X−µ)2bracketrightBig
+2EXYbracketleftbig
(X−µ)(Y−ν)bracketrightbig
+EYbracketleftBig
(Y−ν)2bracketrightBig
=EXbracketleftBig
(X−µ)2bracketrightBig
+2EXbracketleftbig
X−µbracketrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
=0EYbracketleftbig
Y−µbracketrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
=0+EYbracketleftBig
(Y−ν)2bracketrightBig
=Va r(X)+Va r(Y),
where the second line follows from Theorem A.15 and the ﬁfth line from the
assumed independence and Theorem A.15.
Theorem A.18 (Covariance decomposition) F or any pair of random variables X
andYwith a joint measure PXYand any numbers a ,b,c,d∈ /CA,
Cov(X,Y)= EXYbracketleftbig
XYbracketrightbig
−EXbracketleftbig
Xbracketrightbig
EYbracketleftbig
Ybracketrightbig
,
Cov(a+bX,c+dY)= bd·Cov(X,Y).
205 Theoretical Background and Basic I nequa lities
Proof The ﬁrst assertion follows directly from Deﬁnition A.13 and Theorem
A.15. For the second assertion let µ=EXbracketleftbig
Xbracketrightbig
andν=EYbracketleftbig
Ybracketrightbig
.T h e nw eh a v e
Cov(a+bX,c+dY)= EXYbracketleftbig
(a+bX−(a+bµ))(c+dY−(c+dν))bracketrightbig
= EXYbracketleftbig
bd·(X−µ)(Y−ν)bracketrightbig
=bd·Cov(X,Y),
where we the second line uses Theorem A.15 and Deﬁnition A.13.
Corollary A.19 (Variance scaling) F or any random variable Xand any c∈ /CAwe
have Va r(cX)=c2·Va r(X).
Corollary A.20 (Variance of sums of independent variables) Given n indepen-
dent identically distributed random variables X1,..., Xnwe have
Va rparenleftBigg
1
nnsummationdisplay
i=1XiparenrightBigg
=1
nVa r(Xi).
Corollary A.21 (Covariances of linear transformations) F or any n–dimensional
random variable X, any m–dimensional random variable Y, any r×nm a t r i x A,
s×mm a t r i x B,r×1vector aand s×1vector b,
Cov(AX+a,BY+b)=A·Cov(X,Y)·B/prime.
From the deﬁnition of conditional and marginal measures, we have the following
important theorem.
Theorem A.22 (Bayes’ theorem (Bayes 1763)) Given the joint probability space
(
/CG× /CH, /CG× /CH,PXY)then, for all X ∈ /CG,PX(X)>0and Y∈ /CH,PY(Y)>0
PX|Y∈Y(X)=PY|X∈X(Y)PX(X)
PY(Y).
If both XandYposses densities fXand fYthe theorem reads as follows
∀y∈ /CA:∀x∈ /CA: fX|Y=y(x)=fY|X=x(y)fX(x)
fY(y).
Another important theorem we need is the following as found in Scheffé (1947).
206 Appendix A
Theorem A.23 (Scheffé’s theorem) F or all densities fXand fYon the measurable
space(
/CAn, /BUn)
integraldisplay/CAnvextendsinglevextendsinglefX(x)−fY(x)vextendsinglevextendsingledx=2s u p
A∈ /BUn|PX(A)−PY(A)|. (A.3)
Proof Choose C=braceleftbig
x∈ /CAnvextendsinglevextendsinglefX(x)>fY(x)bracerightbig
∈ /BUnand Cc= /CAn\C∈ /BUn.
Then, for the /lscript1distance between fXand fY,
integraldisplay/CAnvextendsinglevextendsinglefX(x)−fY(x)vextendsinglevextendsingledx
=integraldisplay
CvextendsinglevextendsinglefX(x)−fY(x)vextendsinglevextendsingledx+integraldisplay
CcvextendsinglevextendsinglefX(x)−fY(x)vextendsinglevextendsingledx
=integraldisplay
Cparenleftbig
fX(x)−fY(x)parenrightbig
dx+integraldisplay
Ccparenleftbig
fY(x)−fX(x)parenrightbig
dx
=PX(C)−PY(C)+(1−PY(C))−(1−PX(C))
=2(PX(C)−PY(C)). (A.4)
For a geometrical argument see Figure A.1. Now, for all A∈ /BUn
|PX(A)−PY(A)|=vextendsinglevextendsinglevextendsinglevextendsingleintegraldisplay
A∩Cparenleftbig
fX(x)−fY(x)parenrightbig
dx+integraldisplay
A∩Ccparenleftbig
fX(x)−fY(x)parenrightbig
dxvextendsinglevextendsinglevextendsinglevextendsingle
=vextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextendsingleintegraldisplay
A∩CfX(x)−fY(x)bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
≥0dx−integraldisplay
A∩CcfY(x)−fX(x)bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
≥0dxvextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextendsingle
≤ maxparenleftbiggintegraldisplay
A∩CfX(x)−fY(x)dx,integraldisplay
A∩CcfY(x)−fX(x)dxparenrightbigg
≤ maxparenleftbiggintegraldisplay
CfX(x)−fY(x)dx,integraldisplay
CcfY(x)−fX(x)dxparenrightbigg
= PX(C)−PY(C),
where the second line follows by deﬁnition of Cand the third line is always true
because∀a>0,b>0:|a−b|≤max(a,b). We have shown that the supremum
in (A.3) is attained at C∈ /BUnand thus equation (A.4) proves the theorem.

207 Theoretical Background and Basic Inequalities
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/BA/DC
/CU/CG
/B4 /DC /B5/CU/CH
/B4 /DC /B5/BV
/BT/CA /D2 /BV /BP /BV
/CR
/C8/CG
/B4 /BV /B5 /A0 /C8/CH
/B4 /BV /B5/C8/CH
/B4 /BV
/CR/B5 /A0 /C8/CG
/B4 /BV
/CR/B5
Figure A.1 Geometrical proof of Scheffé’s theorem for /CA1. The quantityintegraltext/CAnvextendsinglevextendsinglefX(x)−fY(x)vextendsinglevextendsingledxis given by the sum of the two shaded areas excluding the striped
area A. Given the set C=braceleftbig
x∈ /CAvextendsinglevextendsinglefX(x)>fY(x)bracerightbig
the quantity PX(C)−PY(C)is
given by the light shaded area only. Since the area under both curves fXand fYis exactly
one it must hold that PX(C)−PY(C)=PY(Cc)−PX(Cc)because we subtract Afrom
both curves. This proves Scheffé’s theorem.
A.2.2 Families of Probability Measures
In this subsection we present commonly used probability measures together with
their expectation value and variance. We show that most of the distributions belong
to the rather large class of measures in the exponential family which has many
useful properties, e.g., canonical parameters and natural statistics (see Lindsey(1996) and Amari (1985)).
Probability Measures over the Natural Numbers /C6
For the following measures we assume that the sample space /CGis the set of all
natural numbers (including 0) and the σ–algebra is the collection of all subsets
of /C6. In Table A.1 we have summarized the most commonly used probability
measures on natural numbers. Note that, for the binomial distribution, we assumedthatparenleftbig
n
iparenrightbig
=0 whenever i>n.
The Bernoulli distribution is used to model the outcome of a coin toss with a
chance of pfor “heads”; 1 is used to indicate “head”. The binomial distribution
models the outcome of i“heads” in nindependent tosses of a coin with a chance
ofpfor “heads”. The Poisson distribution is the limiting case of the Binomial
distribution if the number of tosses tend to inﬁnity but the expectation value np=λ
remains constant.
208 Appendix A
Name
 Probability measure / density
 EXbracketleftbig
Xbracketrightbig
Va r(X)
Bernoulli (p)
 PX(1)=1−PX(0)=p
 p
 p(1−p)
Binomial (n,p)
 PX(i)=parenleftbign
iparenrightbig
pi(1−p)n−i
np
 np(1−p)
Poisson(λ)
 PX(i)=λi
i!exp(−λ)
 λ
 λ
Uniform(A)
 PX(i)=1
|A|Ii∈A
 A
 A2−parenleftbig
Aparenrightbig2
Normalparenleftbig
µ,σ2parenrightbig
fX(x)=1
√
2πσexpparenleftBig
−(x−µ)2
2σ2parenrightBig
µ
 σ2
Exp(λ)
 fX(x)=λexp(−λx)Ix≥0
1
λ
1
λ2
Gamma(α,β)
 fX(x)=xα−1
βα/Gamma1(α)expparenleftBig
−x
βparenrightBig
Ix>0
 αβ
 αβ2
Beta(α,β)
 fX(x)=/Gamma1(α+β)xα−1(1−x)β−1
/Gamma1(α)/Gamma1(β)Ix∈[0,1]
α
α+β
αβ
(α+β)2(α+β+1)
Uniform([a,b])
 fX(x)=1
b−aIx∈[a,b]
a+b
2
(b−a)2
12
Ta b l e A . 1 Summary of measures over the natural numbers /C6(ﬁrst four rows) and the
real line /CA1(last ﬁve rows). Note that /Gamma1(α)=integraltext∞
0tα−1exp(−t)dtdenotes the Gamma
function. For plots of these distributions see page 209 and 210. Furthermore, the symbols
Aand
 A2denote1
|A|summationtext
ai∈Aaiand1
|A|summationtext
ai∈Aa2
i, respectively.
Probability Measures on the Real Line /CA1
For the following measures we assume that the sample space /CGis the real line/CAand theσ–algebra is the Borel sets /BU1(see Deﬁnition A.2). In Table A.1
we summarized commonly used probability measures on /CA1by specifying their
density function. For a comprehensive overview of measures on /CA1see (Johnson
et al. 1994).
Note that the exponential distribution Exp(λ)is a special case of the Gamma
distribution because Gamma (1,β)= Expparenleftbig
β−1parenrightbig
.T h e Beta distribution is the
conjugate prior distribution of the success probability in a Binomial measure (seealso Section 3.1). Finally, the normal orGaussian distribution owes its importance
to the well known central limit theorem.
Theorem A.24 (Central limit theorem) LetX
1,X2,... be mutually independent
random variables with a common distribution FXthat satisﬁes
∀i∈ /C6:parenleftbig
EXbracketleftbig
Xibracketrightbig
=0parenrightbig
∧(Va r(Xi)=1). (A.5)
209 Theoretical Background and Basic I nequa lities
01p=0.2
p=0.5p=0.9
iP(X=i)
0.0 0.2 0.4 0.6 0.8
02468 1 0 1 2 1 4 1 6 1 8 2 0p=0.2
p=0.5p=0.9
iP(X=i)
0.00 0.05 0.10 0.15 0.20 0.25
02468 1 0 1 2 1 4 1 6 1 8 2 0λ=1
λ=2
λ=10
iP(X=i)
0.00 0.10 0.20 0.3002468 1 0 1 2 1 4 1 6 1 8 2 0b=1
b=5
b=20
iP(X=i)
0.0 0.1 0.2 0.3 0.4 0.5
Figure A.2 The probability mass function PXfor the measures in Table A.1. (Left)
Bernoulli and Poisson measure. (Right) Binomial and uniform measure. In the uniform
measure plot, we consider the sets Ab={0,..., b}.
Then, for all such probability measures PX,
∀x∈ /CA: lim
n→∞PXnparenleftbiggsummationtextn
i=1Xi
√
n≤xparenrightbigg
=integraldisplayx
−∞1
√
2πexpparenleftbigg
−t2
2parenrightbigg
dt,
that is, the distribution function of the normalized sum of identically and inde-
pendently distributed random variables that fulﬁll (A.5) approaches pointwise thenormal distribution function with increasing sample size n.
Probability Measure on /CAn
The only multidimensional probability measure we consider is the n–dimensional
normal distribution deﬁned over the sample space /CG= /CAnand theσ–algebra /BUn
(see Figure A.4).
210 Appendix A
−4 −2 0 2 40.0 0.2 0.4 0.6 0.8
xf(x)µ=0,σ=1µ=1,σ=0.5
µ=0,σ=2
0123450.0 0.2 0.4 0.6 0.8 1.0
xf(x)
λ=1λ=2
λ=10
0.0 0.2 0.4 0.6 0.8 1.0 1.201234
xf(x)α=2,β=0.1
α=5,β=0.1
α=1,β=0.25
0.0 0.2 0.4 0.6 0.8 1.00.0 0.5 1.0 1.5 2.0 2.5
xf(x)
α=0.5, β=0.5α=1,β=1α=5,β=5 α=2,β=5
Figure A.3 The densities fXfor the measures in Table A.1. (Left) Densities of the
Gaussian/normal and the Gamma measure. (Right) Densities of the exponential and Beta
measure.
Deﬁnition A.25 (Multidimensional Gaussian measure) Suppose we are given a
vector µ∈ /CAnand a deterministic matrix A∈ /CAn×m.L e t Y=(Y1,..., Ym)
be a sequence of m independent normally random variables Yiwith mean zero
and unit variance, i.e., Yi∼Normal(0,1).T h e n X=AY+µis said to be
normally orGaussian distributed with mean EXbracketleftbig
Xbracketrightbig
=µand covariance matrix
Cov(X)=/Sigma1=AA/prime. Since the measure PXis uniquely determined by these two
quantities we also write Y∼Normal(µ,/Sigma1).
Theorem A.26 (Density of a Gaussian measure) IfX∼Normal(µ,/Sigma1),t h e n X
possess a density fXif and only if /Sigma1is positive deﬁnite (see Deﬁnition A.57). The
density fXis given by
fX(x)=1
(2π)n
2|/Sigma1|1
2expparenleftbigg
−1
2(x−µ)/prime/Sigma1−1(x−µ)parenrightbigg
. (A.6)
211 Theoretical Background and Basic I nequa lities
x−3
−2
−1
0
1
2
3y
−3−2−10123density
0.050.100.15
x−3
−2
−1
0
1
2
3y
−3−2−10123density
0.00.10.20.3
Figure A.4 Density of the multidimensional normal distribution. (Left) Here, we used
/Sigma1=Iandµ=0.(Right) Density obtained from a transformation of the left density such
that Cov(X,Y)=0.5a n dµ=0.
Theorem A.27 (Linear transformation of multidimensional Gaussian measures)
Let X∼Normal(µ,/Sigma1)be an n–dimensional normally distributed random vari-
able, let A∈ /CAm×nbe a ﬁxed matrix and let b∈ /CAmbe a ﬁxed vector . Then, the
random variable Y=AX+bisY∼Normalparenleftbig
Aµ+b,A/Sigma1A/primeparenrightbig
.
Proof The theorem follows directly from Corollary A.16 and A.21.
Theorem A.28 (Convolutions of Gaussian measures) Let us assume that PX|Y=y=
Normal(Xy,/Xi1)is a Gaussian measures, where X∈ /CAm×nand/Xi1∈ /CAm×mare
ﬁxed matrices for all values of y∈ /CAn.I f PY=Normal(µ,/Sigma1)is a Gaussian
measure then
PY|X=x= Normalparenleftbig
/Psi1parenleftbig
X/prime/Xi1−1x+/Sigma1−1µparenrightbig
,/Psi1parenrightbig
. (A.7)
PX= Normalparenleftbig
Xµ,/Xi1+X/Sigma1X/primeparenrightbig
, (A.8)
where /Psi1=parenleftbig
X/prime/Xi1−1X+/Sigma1−1parenrightbig−1.
Proof By Theorem A.22 we know that
fY|X=x(y)=fX|Y=y(x)fY(y)
integraltext/CAnfX|Y=˜y(x)fYparenleftbig
˜yparenrightbig
d˜y=fX|Y=y(x)fY(y)
fX(x). (A.9)
212 Appendix A
First note that the denominator is independent of y. Thus let us start with the
numerator of (A.9). Using Deﬁnition A.26 we have that the latter is given by
c·expparenleftbigg
−1
2parenleftbig
(x−Xy)/prime/Xi1−1(x−Xy)+(y−µ)/prime/Sigma1−1(y−µ)parenrightbigparenrightbigg
,
where c=(2π)−m+n
2|/Xi1|−1
2|/Sigma1|−1
2is independent of xand y. From Theorem A.86
we know that this expression can be written as
c·expparenleftbigg
−1
2parenleftbig
(y−c)/primeC(y−c)+d(x)parenrightbigparenrightbigg
,
where
C= X/prime/Xi1−1X+/Sigma1−1,
Cc= X/prime/Xi1−1x+/Sigma1−1µ,
d(x)=(x−Xµ)/primeparenleftbig
/Xi1+X/Sigma1X/primeparenrightbig−1(x−Xµ).
Since d(x)is not a function of ythe term expparenleftbig
−1
2d(x)parenrightbig
can be incorporated in the
normalization constant cand, thus, equation (A.7) follows by equating /Psi1def=C−1.
In order to show the second assertion we use the deﬁnition of fX(x), i.e.,
fX(x)=integraldisplay/CAnc·expparenleftbigg
−1
2parenleftBigparenleftbig
˜y−cparenrightbig/primeCparenleftbig
˜y−cparenrightbig
+d(x)parenrightBigparenrightbigg
d˜y
= c·expparenleftbigg
−1
2d(x)parenrightbigg
·integraldisplay/CAnexpparenleftbigg
−1
2parenleftBigparenleftbig
˜y−cparenrightbig/primeCparenleftbig
˜y−cparenrightbigparenrightBigparenrightbigg
d˜y
= c·expparenleftbigg
−1
2d(x)parenrightbigg
·(2π)n
2|C|1
2=˜c·expparenleftbigg
−1
2d(x)parenrightbigg
=˜ c·expparenleftbigg
−1
2(x−Xµ)/primeparenleftbig
/Xi1+X/Sigma1X/primeparenrightbig−1(x−Xµ)parenrightbigg
,
where the third line follows from Deﬁnition A.26 and the fact that probability
densities always integrate to one. This proves equation (A.8).
Theorem A.29 (Marginal and conditional measures) Let X∼ Normal(µ,/Sigma1)
be an n–dimensional normally distributed random variable with /Sigma1> 0.L e t
X=(U,V)be partitioned into an r –dimensional random variable Uand an s–
dimensional random variable Vwhere n=r+s. Then for all v∈ /CAsand u∈ /CAr
PU= Normalparenleftbig
µU,/Sigma1UUparenrightbig
, (A.10)
213 Theoretical Background and Basic I nequa lities
PV= Normalparenleftbig
µV,/Sigma1VVparenrightbig
, (A.11)
PU|V=v= Normalparenleftbig
µU+/Sigma1UV/Sigma1−1
VVparenleftbig
v−µVparenrightbig
,/Sigma1UU−/Sigma1UV/Sigma1−1
VV/Sigma1VUparenrightbig
,(A.12)
PV|U=u= Normalparenleftbig
µV+/Sigma1VU/Sigma1−1
UUparenleftbig
u−µUparenrightbig
,/Sigma1VV−/Sigma1VU/Sigma1−1
UU/Sigma1UVparenrightbig
,(A.13)
where
µ=parenleftbiggµU
µVparenrightbigg
,/Sigma1=parenleftbigg/Sigma1UU/Sigma1UV
/Sigma1VU/Sigma1VVparenrightbigg
.
Proof The assertions (A.10) and (A.11) follow directly from Theorem A.27 con-
sidering that
U=parenleftbiggIr0
00parenrightbigg
X, V=parenleftbigg00
0I sparenrightbigg
X.
We shall prove equation (A.12) for the special case of µ=0only—the full result
follows from Theorem A.27. First we exploit the fact that
fU|V=v(u)=fX((u;v))
fV(v). (A.14)
Since we know the density fValready let us consider the joint density fXas a
function of uandv. To this end we use equation (A.27) of Theorem A.80 to obtain
a partitioned expression for the inverse /Sigma1−1of the covariance matrix /Sigma1, i.e.,
/Sigma1−1=parenleftbiggAB
B/primeDparenrightbigg
,
where the matrices A,Band Dare given by
A=parenleftbig
/Sigma1UU−/Sigma1UV/Sigma1−1
VV/Sigma1VUparenrightbig−1,
B=− A/Sigma1UV/Sigma1−1
VV,
D=/Sigma1−1
VV+/Sigma1−1
VV/Sigma1VUA/Sigma1UV/Sigma1−1
VV.
Now we can write the joint density fX((u;v))a saf u n c t i o no f uandv
c·expparenleftbigg
−1
2parenleftbig
u/prime,v/primeparenrightbig
/Sigma1−1(u;v)parenrightbigg
=c·expparenleftbigg
−1
2parenleftbig
u/primeAu+2u/primeBv+v/primeDvparenrightbigparenrightbigg
=c·expparenleftbigg
−1
2parenleftBigparenleftbig
u+A−1Bvparenrightbig/primeAparenleftbig
u+A−1Bvparenrightbig
+v/primeparenleftbig
D−B/primeA−1Bparenrightbig
vparenrightBigparenrightbigg
,
214 Appendix A
using the constant c=(2π)−n
2|/Sigma1|−1
2. The last line can be proven by expanding it
and making a term-wise comparison with the second line. Note that D−B/primeA−1B=
/Sigma1−1
VV, which follows from applying equation (A.27) to /Sigma1−1. Finally, using (A.14)
shows that the conditional density of Ugivenv∈ /CAsis again normal with mean
−A−1Bv=/Sigma1UV/Sigma1−1
VVvand covariance matrix A−1=/Sigma1UU−/Sigma1UV/Sigma1−1
VV/Sigma1VU.T h e
proof of equation (A.13) is analogous.
Exponential F amily
All of the above measures belong to the class of measures in the exponential family.Let us start by deﬁning formally the exponential family.
Deﬁnition A.30 (Exponential family) A probability measure P
Xis said to have
anexponential representation if its density fX(x)(continuous measures) or proba-
bility mass PX(x)(discrete measures) at x∈ /CGcan be written
p(x)=a0(θ)τ0(x)expparenleftbig
θ/prime(τ(x))parenrightbig
,
for some θ∈ /C9⊆ /CAn,τ0: /CG→ /CA,τ: /CG→ /CAn. The normalizing constant a 0(θ)
is given by
a0(θ)def=parenleftbiggintegraldisplay/CGτ0(x)expparenleftbig
θ/prime(τ(x))parenrightbig
dxparenrightbigg−1
(A.15)
and is assumed to be ﬁnite. The set of all probability measures PXthat have an
exponential representation are deﬁned as the exponential family .
In Table A.2 we have given the functions τ0andτtogether with the normalization
constant a0(θ)for all the one-dimensional measures introduced. In the case of X∼
Normal(µ,/Sigma1)where µ∈ /CAn, a straightforward manipulation of the deﬁnition
given in equation (A.6) shows that
θ=parenleftBigg
/Sigma1−1µ;−/Sigma1−1
11
2;−/Sigma1−1
12;...;−/Sigma1−1
22
2;−/Sigma1−1
23;...;−/Sigma1−1
nn
2parenrightBigg
, (A.16)
τ(x)=parenleftbig
x;x2
1;x1x2;...;x1xn;x2
2;x2x3;...;x2
nparenrightbig
,
τ0(x)= 1,
215 Theoretical Background and Basic I nequa lities
Name
 τ0(x)
 θ
 τ(x)
 a0(θ)
Bernoulli (p)
 1
 lnparenleftBig
p
1−pparenrightBig
x
 (1+exp(θ))−1
Binomial (n,p)
parenleftbign
xparenrightbig
lnparenleftBig
p
1−pparenrightBig
x
 (1+exp(θ))−n
Poisson(λ)
1
x!
ln(λ)
 x
 exp(−exp(θ))
Uniform(A)
 1
 —
 —
 (|A|)−1
Normalparenleftbig
µ,σ2parenrightbig
1
parenleftBig
µ
σ2;−1
2σ2parenrightBig
parenleftbig
x;x2parenrightbig
radicalBig
−θ2
πexpparenleftBig
−θ1
2parenrightBig
Exp(λ)
 1
 −λ
 x
 −θ
Gamma(α,β)
 x−1
parenleftBig
α;−1
βparenrightBig
(ln(x);x)
−θθ1
2·1
/Gamma1(θ 1)
Beta(α,β)
 x−1(1−x)−1
(α;β)
(ln(x);ln(1−x))
/Gamma1(θ 1+θ2)
/Gamma1(θ 1)/Gamma1(θ 2)
Uniform([a,b])
 1
 —
 —
 (b−a)−1
Ta b l e A . 2 Canonical parameterization of the measures given in Table A.1. Note that
/Gamma1(α)=integraltext∞
0tα−1exp(−t)dtdenotes the Gamma function.
is the parameterization of the multidimensional Gaussian in the exponential family.
The value of a0(θ)is calculated according to equation (A.15) and given by
a0(θ)=(2π)−n
2|/Sigma1|−1
2expparenleftbigg
−1
2µ/prime/Sigma1−1µparenrightbigg
. (A.17)
A.3 Functional Analysis and Linear Algebra
In this section we introduce the basic terms of functional analysis together with
some examples. This section is followed by a more detailed subsection aboutmatrix algebra together with some useful matrix identities. For a more detailedtreatment of matrices the interested reader is referred to (Harville 1997; Lütkepohl1996).
Deﬁnition A.31 (Vector space) A set
3/CGis a vector space if addition and multi-
plication by scalar are deﬁned such that, for x,y∈ /CG, and c∈ /CA,
x+y∈ /CG,cx∈ /CG,1x=x,0x=0.
3 The notational similarity of /CGas a vector space as well as the sample space (in probability theory) is intended
to indicate their similar roles in the two ﬁelds.
216 Appendix A
Here the addition operation x+yhas to satisfy that, for all x,y,z∈ /CG,
x+y= y+x,
(x+y)+z= x+(y+z),
∃0∈ /CG: x+0=0,
∃− x∈ /CG: x+(−x)=0,
as well as the distributive laws for scalar multiplication,c(x+y)=cx+cy,(c+d)x=cx+dx.
Deﬁnition A.32 (Metric space) Suppose/CGis a vector space. A metric space /CGis
deﬁned by the tuple (
/CG,ρ)whereρ: /CG× /CG→ /CA+is called a metric , i.e., for all
x,y,z∈ /CG,
ρ(x,y)≥ 0andρ(x,y)=0⇔x=y,
ρ(x,y)=ρ(y,x),
ρ(x,y)≤ρ(x,z)+ρ(z,y).
Deﬁnition A.33 (Normed space) Suppose /CGis a vector space. A normed space /CG
is deﬁned by the tuple (
/CG,/bardbl·/bardbl)where/bardbl·/bardbl: /CG→ /CA+is called a norm, i.e., for all
x,y∈ /CGand c∈ /CA,
/bardblx/bardbl≥ 0and/bardblx/bardbl=0⇔x=0,
/bardblcx/bardbl=|c|·/bardblx/bardbl,
/bardblx+y/bardbl≤/bardblx/bardbl+/bardbly/bardbl. (A.18)
This clearly induces a metric ρon /CGbyρ(x,y)=/bardblx−y/bardbl. Note that equation
(A.18) is known as the triangle inequality .
Deﬁnition A.34 ( /lscriptn
pand Lp)Given a subset X ⊆ /CG, the space L p(X)is the space
of all functions f :X→ /CAsuch that
integraldisplay
X|f(x)|pdx<∞ if p<∞,
sup
x∈X|f(x)|<∞ if p=∞.
217 Theoretical Background and Basic I nequa lities
Endowing this space with the norm
/bardblf/bardblpdef=braceleftBiggparenleftbigintegraltext
X|f(x)|pdxparenrightbig1
pif p<∞
supx∈X|f(x)| if p=∞
makes L p(X)a normed space (by Minkowski’s inequality). The space /lscriptn
pof se-
quences of length n is deﬁned by
/lscriptn
pdef=braceleftbigg
(x1,..., xn)∈ /CAnvextendsinglevextendsinglevextendsinglevextendsinglesummationtextn
i=1|xi|p<∞ if0<p<∞
max i=1,..., n|xi| if p=∞bracerightbigg
.
Deﬁnition A.35 ( /lscriptp–norms) Given x∈/lscriptn
pwe deﬁne the /lscriptp–norm/bardblx/bardblpby
/bardblx/bardblpdef=

summationtextn
i=1Ixi/negationslash=0 if p=0parenleftbigsummationtextn
i=1|xi|pparenrightbig1/pif0<p<∞
max i=1,..., n|xi| if p=∞.
Deﬁnition A.36 (Balls in normed spaces) Given a normed space /CG,t h e open ball/BUτ(x)⊆ /CGof radius τaround x∈ /CGis deﬁned by/BUτ(x)def={y∈ /CG|/bardblx−y/bardbl<τ}.
Equivalently, the closed ball
 /BUτ(x)⊆ /CGis deﬁned by
/BUτ(x)def={y∈ /CG|/bardblx−y/bardbl≤τ}.
Deﬁnition A.37 (Inner product space) Suppose we are given a vector space /CG.
An inner product space /CG(or pre-Hilbert space) is deﬁned by the tuple (
/CG,/angbracketleft·,·/angbracketright),
where/angbracketleft·,·/angbracketright: /CG× /CG→ /CAis called an inner product and satisﬁes the following
properties: F or all x,y,z∈ /CGand c,d∈ /CA,
/angbracketleftx,x/angbracketright≥ 0 (A.19)
/angbracketleftx,x/angbracketright= 0⇔ x=0, (A.20)
/angbracketleftcx+dy,z/angbracketright= c/angbracketleftx,z/angbracketright+d/angbracketlefty,z/angbracketright, (A.21)
/angbracketleftx,y/angbracketright=/angbracketlefty,x/angbracketright. (A.22)
Clearly, each inner product space is a normed space when deﬁning /bardblx/bardbldef=√
/angbracketleftx,x/angbracketright.
The function /angbracketleft·,·/angbracketright: /CG× /CG→ /CAis called generalized inner product if it only
satisﬁes equation (A.20)–(A.22).
218 Appendix A
Deﬁnition A.38 (Euclidean inner product) If /CG=/lscriptn
2we deﬁne the Euclidean
inner product between x,y∈ /CGby
/angbracketleftx,y/angbracketrightdef=x/primey=nsummationdisplay
i=1xiyi. (A.23)
Example A.39 ( /lscriptn
2and L2)Deﬁning an inner product /angbracketleft·,·/angbracketrightin/lscriptn
2and L 2(X)by
(A.23) and
/angbracketleftf,g/angbracketright=integraldisplay
Xf(x)g(x)dx (A.24)
makes these two spaces inner product spaces because
1./angbracketleftx,x/angbracketright=summationtextn
i=1x2
i≥0and/angbracketleftf,f/angbracketright=integraltext
X(f(x))2dx≥0.
2./angbracketleftx,x/angbracketright=summationtextn
i=1x2
i=0if and only if x=0. Similarly,/angbracketleftf,f/angbracketright=integraltext
X(f(x))2dx=
0if and only if f (x)=0almost everywhere.
3.Fo r t h e/lscriptn
2case we have
/angbracketleftcx+dy,z/angbracketright=nsummationdisplay
i=1(cx i+dy i)zi=cnsummationdisplay
i=1xizi+dnsummationdisplay
i=1yizi
= c/angbracketleftx,z/angbracketright+d/angbracketlefty,z/angbracketright.
Similarly,
/angbracketleftaf+bg,h/angbracketright=integraldisplay
X(af(x)+bg(x))h(x)dx
= aintegraldisplay
Xf(x)h(x)dx+bintegraldisplay
Xg(x)h(x)dx
= a/angbracketleftf,h/angbracketright+b/angbracketleftg,h/angbracketright.
4.The symmetry follows trivially from deﬁnition (A.23) and (A.24).
Deﬁnition A.40 (Positive (semi)deﬁniteness) Given a vector space /CG, a function
f: /CG× /CG→ /CAis said to be positive deﬁnite (positive semideﬁnite ) if, and only
if, for all n∈ /C6,a l l x1,..., xn∈ /CGand all a∈ /CAn,a/negationslash=0, it satisﬁes
nsummationdisplay
i=1nsummationdisplay
j=1aiajfparenleftbig
xi,xjparenrightbig
>0.parenleftBiggnsummationdisplay
i=1nsummationdisplay
j=1aiajfparenleftbig
xi,xjparenrightbig
≥0parenrightBigg
.
219 Theoretical Background and Basic Inequalities
Example A.41 (Positive semideﬁniteness) Consider any inner product /angbracketleft·,·/angbracketright=
f(·,·)on a vector space /CG. Then, for all n ∈ /C6,a l l a∈ /CAn,a/negationslash=0and any
sequence x1,..., xn∈ /CG,
nsummationdisplay
i=1nsummationdisplay
j=1aiajangbracketleftbig
xi,xjangbracketrightbig
=nsummationdisplay
i=1ainsummationdisplay
j=1ajangbracketleftbig
xi,xjangbracketrightbig
=nsummationdisplay
i=1aiangbracketleftBigg
xi,nsummationdisplay
j=1ajxjangbracketrightBigg
=angbracketleftBiggnsummationdisplay
i=1aixi,nsummationdisplay
j=1ajxjangbracketrightBigg
=vextenddoublevextenddoublevextenddoublevextenddoublevextenddoublensummationdisplay
i=1aixivextenddoublevextenddoublevextenddoublevextenddoublevextenddouble2
≥0,
where the second step follows from equation (A.21) and the last step is a direct
consequence of equation (A.19). Thus, the inner product is a positive semideﬁnitefunction by deﬁnition.
Deﬁnition A.42 (Cauchy sequence) A sequence (x
i)i∈ /C6in a normed space is said
to be a Cauchy sequence iflim n→∞ supm≥n/bardblxn−xm/bardbl=0. Note that all conver-
gent sequences are Cauchy sequences but the converse is not true in general.
Deﬁnition A.43 (Hilbert space) AHilbert space /CGis a complete inner product
space. A space is called complete if every Cauchy sequence converges.
Deﬁnition A.44 (Linear operator) Given two Hilbert spaces /C0and /BY, a map-
ping T: /C0→ /BYis called linear operator if and only if
1.Fo r a l l x∈ /C0and y∈ /C0,T(x+y)=Tx+Ty.
2.Fo r a l l x∈ /C0and all c∈ /CA,T(cx)=c·Tx.
Deﬁnition A.45 (Eigenvalue and eigenvector) Let T: /C0→ /C0be a linear
operator on a Hilbert space /C0. If there is a vector x∈ /C0,x/negationslash=0, such that
Tx=λxfor some scalar λ,t h e nλis an eigenvalue of T with the corresponding
eigenvector x.
Deﬁnition A.46 (Self-adjoint operators) A linear operator T : /C0→ /C0on a
Hilbert space /C0isself-adjoint , if, for all x,y∈ /C0,
/angbracketleftTx,y/angbracketright=/angbracketleftx,Ty/angbracketright.
220 Appendix A
A.3.1 Covering, Packing and Entropy Numbers
In this section we recall the notion of covering and packing numbers as well as
entropy numbers. We present an elementary relation for covering and packingnumbers; for further information the interested reader is referred to Kolmogorovand Fomin (1957), Carl and Stephani (1990) and Vidyasagar (1997).
Deﬁnition A.47 ( ε–cover and ε–packing) Let(/CG,ρ)be a metric space, let A ⊆/CGandε> 0. A set B⊆ /CGis anε–cover for A if for every a ∈A there exists
b∈B such that ρ(a,b)≤ε, i.e.,
A⊆uniondisplay
b∈B
/BUε(b).
T h ec o v e r Bi ss a i dt ob e proper if, and only if, B ⊆ A. The set B ⊆Ai sa n
ε–packing of A if, for all distinct b ,c∈B, d(b,c)>ε .
Deﬁnition A.48 (Covering and packing number) Let(
/CG,ρ)be a metric space,
let A⊆ /CGandε> 0.T h e covering number /C6ρ
A(ε)is the minimal cardinality of
anε–cover for A; if there is no such ﬁnite cover then it is deﬁned to be ∞.T h e
packing number /C5ρ
A(ε)is the maximal cardinality of an ε–packing of A; if there
is no such ﬁnite packing then it is deﬁned to be ∞.
In order to enhance understanding we have shown an ε–cover as well as an ε–
packing in Figure A.5. There exists an elementary relationship between packingand covering numbers ﬁrst proven in Kolmogorov and Tihomirov (1961); thecurrent proof is taken from Anthony and Bartlett (1999).
Theorem A.49 (Packing and covering numbers) Let(/CG,ρ)be a metric space.
Then, for all ε> 0and for every subset A ⊆ /CG, the packing and covering numbers
satisfy the following relation:/C5ρ
A(2ε)≤ /C6ρ
A(ε)≤ /C5ρ
A(ε).
Proof Let us begin with the leftmost inequality. Suppose that C⊆ /CGis anε–
cover of Aand that P⊆Ai sa2ε–packing of Aof maximum cardinality /C5ρ
A(2ε).
We need to show that |P|≤|C|which will be done by contradiction. Let us assume
that|P|>|C|.S i n c e Cis anε–cover of Awe know that, for every p∈P,t h e r e
221 Theoretical Background and Basic I nequa lities/BTꜼ
/BTꜼ
/BE
/AL Ꜽ
Figure A.5 (Left) ε–covering of the set A⊂ /CA2using the Euclidean metric. The black
dots represent the ε–cover. (Right)ε–packing of the same set A⊂ /CA2. Note that by
deﬁnition we can place balls of radiusε
2around the ε–packing and obtain a set of balls
which have an empty intersection with each other.
exists a c∈Csuch that ρ(p,c)≤ε. By the “pigeonhole4principle” there must be
some c∈Csuch that for two points p1/negationslash=p2inP,ρ(p1,c)≤εandρ(p2,c)≤ε.
Sinceρis a metric (see Deﬁnition A.32) we know that
ρ(p1,p2)≤ρ(p1,c)+ρ(p2,c)≤2ε,
which contradicts the assumption that Pis a 2ε–packing of A. Hence,|P|≤|C|
as desired.
To prove the rightmost inequality, suppose that Pis anε–packing of maximum
cardinality /C5ρ
A(ε). Then, for any a∈A, there must exist a p∈Pwithρ(p,a)≤
εbecause otherwise we could form the packing P∪{a}which contradicts the
4 The pigeonhole principle states that if npigeons are distributed over fewer than npigeonholes, some pigeon-
holes must contain more than one pigeon (for Trybulec (1990) for a rigorous proof).
222 Appendix A
assumption that Pis a maximal ε–packing. It follows that any maximum ε–packing
is anε–cover.
Sometimes it is more useful to work with the functional inverse of the covering and
packing number, deﬁned as follows.
Deﬁnition A.50 (Entropy numbers) Let(
/CG,ρ)be a metric space and let A ⊆ /CG.
Then the n th entropy number /epsilon1A(n)is the smallest number ε> 0such that/C6ρ
A(ε)≤n,
/epsilon1A(n)def=infbraceleftbig
ε> 0vextendsinglevextendsingle/C6ρ
A(ε)≤nbracerightbig
.
The n th inner entropy number ϕA(n)is deﬁned as the largest ε> 0such that/C5ρ
A(ε)>n,
ϕA(n)def=supbraceleftbig
ε> 0vextendsinglevextendsingle/C5ρ
A(ε)≥nbracerightbig
.
Corollary A.51 (Entropy and inner entropy numbers) Let(
/CG,ρ)be a metric
space. Then, for all n ∈ /C6+and for every subset A ⊆ /CG, the entropy and inner
entropy numbers satisfy
ϕA(n)≤/epsilon1A(n)≤2·ϕA(n).
Proof The result follows directly from Theorem A.49 noticing that /C6ρ
A(ε)and/C5ρ
A(ε)are non-increasing functions for increasing ε, that is, we know that there
exists a smallest /Delta1≥0 such that/C5ρ
A(2/epsilon1A(n)+/Delta1)bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
ϕA(n)= /C6ρ
A(/epsilon1A(n))=n.
This shows the rightmost inequality. The leftmost inequality can be shown in an
analogous way.
A.3.2 Matrix Algebra
V ectors, which are column vectors by deﬁnition, and matrices are denoted in bold
face5, e.g., xorX. V ector components are denoted by subscripts omitting bold
5 This should not be confused with the special symbols E,P,v,f,Fand Iwhich denote the expectation value,
the probability measure, the empirical probability measure, the density, the distribution function and the indicator
function, respectively. Whenever the symbol xis already in use, we use /vectorxto denote a vector to avoid confusion.
223 Theoretical Background and Basic I nequa lities
face, i.e., xi. Note that for matrices we do not omit the bold face, i.e., Xijis the
element of Xin the ith row and jth column. We have for the n×1 vector x
that x=(x1,..., xn)/prime=(x1;...;xn), i.e., a comma-separated list creates a row
vector whereas a semicolon-separated list denotes a column vector. The n×n
identity matrix is denoted by In. We omit the index nwhenever the size of the
matrix is clear from the context. The vector eidenotes the ithunit vector , i.e.,
all components are zero except the ith component which is one. The vector 1is
deﬁned bysummationtext
iei=(1;...;1). The main importance of matrix algebra stems from
the following theorem which builds the link between linear operators and matrices.
Theorem A.52 (Linear operators in ﬁnite dimensional spaces) All linear oper-
atorsφ: /CAn→ /CAmfor ﬁnite n ,m∈ /C6admit a representation of the form
φ(x)=Ax,
where A∈ /CAm×nis called the parameter matrix .
Proof Put x=summationtextn
i=1xiei. By the two properties of linear operators
φ(x)=φparenleftBiggnsummationdisplay
i=1xieiparenrightBigg
=nsummationdisplay
i=1xiφ(ei)=(φ(e1),...,φ(en))bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
Ax,
that is, the columns of the matrix Aare the images of the nunit vectors ei∈ /CAn.
Types of Matrices
Deﬁnition A.53 (Square matrix) Am a t r i x A∈ /CAn×mis called a square matrix if,
and only if, m =n.
Deﬁnition A.54 (Symmetric matrix) A square matrix Ais called a symmetric
matrix if, and only if, A/prime=A.
Deﬁnition A.55 (Lower and upper triangular matrix) A square matrix Ais a
called lower (upper) triangular matrix if, and only if, Aij=0⇐ i<j(i>j).
Deﬁnition A.56 (Diagonal matrix) A square matrix Ais called a diagonal matrix
if, and only if, Aij=0for all i/negationslash=j . They are denoted by diag(a1,..., an).
224 Appendix A
Deﬁnition A.57 (Positive (semi)deﬁnite matrix) A symmetric n ×nm a t r i x Ais
called positive deﬁnite , i.e., A>0, if, and only if,
∀c∈ /CAn,c/negationslash=0: c/primeAc>0.
If the inequality only holds with ≥then Ais called positive semideﬁnite .T h i si s
denoted by A≥0.
Deﬁnition A.58 (Orthogonal matrix) A square matrix Ais called an orthogonal
matrix if, and only if, A/primeA=I.
Deﬁnition A.59 (Singular matrix) A square matrix Aissingular if, and only if,
|A|=0; otherwise the matrix is called a non-singular matrix.
Transpose
Deﬁnition A.60 (Transpose of a matrix) F or any n×mm a t r i x Athe transpose
A/primeis an m×n matrix deﬁned by A/prime
ijdef=Aji.
Theorem A.61 (Transpose of matrix product) F or any n×mm a t r i x Aand m×r
matrix B,
(AB)/prime=B/primeA/prime.
Proof Follows trivially by comparing individual elements of both matrix prod-
ucts.
Rank
Deﬁnition A.62 (Rank of a matrix) Given an m×nm a t r i x Athe rank rk(A)is
the maximum number of columns which are linearly independent.
Theorem A.63 (Rank of the transpose) F or any m×nm a t r i x Awe know that
rk(A)=rkparenleftbig
A/primeparenrightbig
≤min{m,n}.
225 Theoretical Background and Basic I nequa lities
Determinant
Deﬁnition A.64 (Determinant of a matrix) The determinant|A|of an n×nm a -
trix Ais deﬁned by
|A|def= A, if n=1,
|A|def=braceleftbiggsummationtextn
i=1Aij·vextendsinglevextendsingleA[ij]vextendsinglevextendsingle·(−1)i+jfor any j∈{1,..., n}summationtextn
j=1Aij·vextendsinglevextendsingleA[ij]vextendsinglevextendsingle·(−1)i+jfor any i∈{1,..., n}, if n>1.
The(n−1)×(n−1)matrix A[ij]is obtained by deleting the i th row and j th
column from A.
Theorem A.65 (Determinants of the transpose) F or any n×nm a t r i x Awe have
|A|=vextendsinglevextendsingleA/primevextendsinglevextendsingle.
Proof The result is trivially true for n=1. Let us assume the assertion is true of
n∈ /C6. Then, for any (n+1)×(n+1)matrix A, by deﬁnition
|A|=n+1summationdisplay
j=1A1j·vextendsinglevextendsingleA[1j]vextendsinglevextendsingle·(−1)1+j=n+1summationdisplay
j=1Aj1·vextendsinglevextendsingleA[j1]vextendsinglevextendsingle·(−1)1+j
=n+1summationdisplay
j=1A/prime
1j·vextendsinglevextendsingleA/prime
[1j]vextendsinglevextendsingle·(−1)1+j=vextendsinglevextendsingleA/primevextendsinglevextendsingle,
where the second line follows by assumption and the deﬁnition of the transpose.
Theorem A.66 (Determinants of triangular matrices) The determinant |A|of a
lower (upper) triangular n ×nm a t r i x Ais given by the product of the diagonal of
A, i.e.,
|A|=nproductdisplay
i=1Aii.
Proof Let us assume that Ais lower triangular. The result follows by induction.
The case n=1 is covered by the Deﬁnition A.64. Let us assume the assertion is
true for n∈ /C6. Then, for any (n+1)×(n+1)matrix A, by deﬁnition
|A|=n+1summationdisplay
j=1A1j·vextendsinglevextendsingleA[1j]vextendsinglevextendsingle·(−1)1+j=A11·vextendsinglevextendsingleA[11]vextendsinglevextendsingle=A11·nproductdisplay
i=1Ai+1,i+1,
226 Appendix A
because, according to Deﬁnition A.55, all A1jfor j>1 are zero. The last step
follows from the fact thatvextendsinglevextendsingleA[11]vextendsinglevextendsingleis the determinant of the n×nlower triangular
sub-matrix of Aobtained by deletion of the ﬁrst row and column. The case of A
being upper triangular follows by an application of Theorem A.65.
Due to their lengths, the following three theorems are given without proof. Theinterested reader is referred to Mardia et al. (1979) and Harville (1997).
Theorem A.67 (Products of determinant) F or any two n ×n matrices Aand B,
|AB|=|A|·|B|.
Theorem A.68 (Determinant of triangular partitioned matrix) Let Mbe a par-
titioned n×nm a t r i x
M=parenleftbigg
AB
CDparenrightbigg
,
where A∈/CAs×s,B∈ /CAs×r,C∈ /CAr×s,D∈ /CAr×rand n=r+s. If either B=0or
C=0we have
|M|=|A|·|D|.
Theorem A.69 (Determinant of linear combinations) F or any n×nm a t r i x A=
(a1,..., an), any i,j∈{1,..., n}and anyλ∈ /CA
vextendsinglevextendsingleparenleftbig
a1,..., aj−1,aj+λai,aj+1,..., anparenrightbigvextendsinglevextendsingle=|A|.
Theorem A.70 (Determinant and rank) F or any n×nm a t r i x Awith rk(A)<n
we have that |A|=0.
Proof Since rk(A)<nwe know that there exists a column aiofAwhich can be
linearly combined from the remaining n−1 columns. Without loss of generality
suppose that this is the ﬁrst column a1, i.e., a1=summationtextn−1
j=1λjaj+1. According to
Theorem A.69 we know that
|A|=vextendsinglevextendsinglevextendsinglevextendsinglevextendsingleparenleftBigg
a1−n−1summationdisplay
j=1λjaj+1,a2,..., anparenrightBiggvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle=|(0,a2,..., an)|=0.
where we used Deﬁnition A.64 with the ﬁrst column of zeros.

227 Theoretical Background and Basic I nequa lities
Theorem A.71 (Scaling of determinant) F or any n×nm a t r i x A=(a1,..., an)
and any vector λ∈ /CAn
|(λ1a1,...,λ nan)|=|A|·nproductdisplay
i=1λi.
Proof Noticing that
(λ1a1,...,λ nan)=A·diag(λ1,...,λ n),
the result follows from Theorems A.66 and A.67.
Theorem A.72 (Determinant of a partitioned matrix) Let M be a partitioned
n×nm a t r i x
M=parenleftbigg
AB
CDparenrightbigg
,
where A∈ /CAs×s,B∈ /CAs×r,C∈ /CAr×s,D∈ /CAr×rand n=r+s. If A−1and D−1
exist then
|M|=vextendsinglevextendsinglevextendsinglevextendsingleAB
CDvextendsinglevextendsinglevextendsinglevextendsingle=|A|·vextendsinglevextendsingleD−CA
−1Bvextendsinglevextendsingle=|D|·vextendsinglevextendsingleA−BD−1Cvextendsinglevextendsingle.
Proof In order to prove the assertion we use the fact that Mcan be written as the
product of two partitioned block-triangular matrices, i.e.,
parenleftbiggIs 0
CA−1D−CA−1Bparenrightbiggparenleftbigg
AB
0I rparenrightbigg
=parenleftbigg
A−BD−1CB D−1
0I rparenrightbiggparenleftbigg
Is0
CDparenrightbigg
.
Applying Theorems A.67 and A.68 proves the result.
Trace
Deﬁnition A.73 (Trace of a matrix) The trace tr(A)of a square n ×nm a t r i x A
is deﬁned by
tr(A)def=nsummationdisplay
i=1Aii.
228 Appendix A
Theorem A.74 (Trace of matrix products) F or any n×mm a t r i x Aand m×n
matrix B,
tr(AB)=tr(BA).
Proof By deﬁnition we know that
tr(AB)=nsummationdisplay
i=1parenleftBiggmsummationdisplay
j=1AijBjiparenrightBigg
=msummationdisplay
j=1parenleftBiggnsummationdisplay
i=1BjiAijparenrightBigg
=tr(BA).
The theorem is proved.
Inverse
Deﬁnition A.75 (Inverse of a matrix) The square matrix A−1is called the inverse
ofA∈ /CAn×nif, and only if,
A−1A=AA−1=In.
The inverse exists if, and only if, Ais non-singular , i.e., |A|/negationslash=0.
Theorem A.76 (Inverse of square matrix) IfAand Bare any two n ×n matrices
and AB=Inthen B=A−1.
Proof From Theorem A.67 we know that |A|·|B|=|In|=1. Hence both A−1
and B−1exists because |A|/negationslash=0a n d|B|/negationslash=0. As a consequence A−1·(AB)=
A−1·In⇔ B=A−1which proves the theorem.
Theorem A.77 (Product and transpose of inverses) If the two square matrices A
and Bare invertible then
(AB)−1=B−1A−1,parenleftbig
A/primeparenrightbig−1=parenleftbig
A−1parenrightbig/prime.
Proof To prove the ﬁrst assertion we have to show thatparenleftbig
B−1A−1parenrightbig
(AB)=Iwhich
follows from Deﬁnition A.75. The second assertion follows fromparenleftbig
A/primeparenrightbig−1A/prime=parenleftbig
A−1parenrightbig/primeA/prime=parenleftbig
AA−1parenrightbig/prime=I/prime=Iby virtue of Theorem A.61.

229 Theoretical Background and Basic I nequa lities
Theorem A.78 (Inverse and determinant) Let Abe an invertible symmetric n ×n
matrix. Then the inverse A−1can be computed as
A−1=1
|A|
(−1)1+1·vextendsinglevextendsingleA[11]vextendsinglevextendsingle···(−1)1+n·vextendsinglevextendsingleA[1n]vextendsinglevextendsingle
.........
(−1)n+1·vextendsinglevextendsingleA[n1]vextendsinglevextendsingle···(−1)n+n·vextendsinglevextendsingleA[nn]vextendsinglevextendsingle
/prime
.
Proof In order to proof the theorem we need to show that A−1A=In.F o rt h e
i,j–th element of A−1Awe have
parenleftbig
A−1Aparenrightbig
ij=1
|A|·nsummationdisplay
l=1(−1)i+l·vextendsinglevextendsingleA[il]vextendsinglevextendsingle·Alj=1
|A|·nsummationdisplay
l=1(−1)i+l·vextendsinglevextendsingleA[il]vextendsinglevextendsingle·Ajl
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
qij.
By Deﬁnition A.64 for i=jwe see that qij=|A|. In the case of i/negationslash=j,qijcan
be viewed as the determinant of the matrix ˜Aobtained from Aby replacing the jth
column with the ith column. Hence rk (˜A)< nand therefore, by Theorem A.70,
we know that qij=0 which proves the theorem.
Theorem A.79 (Woodbury formula) Let Cbe an invertible n ×n matrix. Then,
for any matrix A∈ /CAn×mand B∈ /CAm×n,
(C+AB)−1=C−1−C−1Aparenleftbig
I+BC−1Aparenrightbig−1BC−1. (A.25)
The r .h.s. exists if and only if the l.h.s. exists.
Proof Put D=I+BC−1A. First we show that the r.h.s. of equation (A.25) has
the property that its product with (C+AB)equals I, i.e.,
parenleftBig
C−1−C−1Aparenleftbig
I+BC−1Aparenrightbig−1BC−1parenrightBig
(C+AB)
=parenleftbig
C−1−C−1AD−1BC−1parenrightbig
(C+AB)
=I+C−1AB−C−1AD−1B−C−1AD−1BC−1AB
=I+C−1Aparenleftbig
I−D−1−D−1BC−1Aparenrightbig
B
=I+C−1A
I−D−1parenleftbig
I+BC−1Aparenrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
D
B=I.
230 Appendix A
Since both the l.h.s. and r.h.s. of equation (A.25) are square matrices the result
follows from Theorem A.76.
Theorem A.80 (Partitioned inverse of a matrix) Let Mbe a partitioned invert-
ible n×nm a t r i x
M=parenleftbiggAB
CDparenrightbigg
,
where A∈ /CAs×s,B∈ /CAs×r,C∈ /CAr×s,D∈ /CAr×rand n=r+s. If A−1exists then
E=parenleftbig
D−CA−1Bparenrightbig−1also exists and
M−1=parenleftbigg
A−1+A−1BECA−1−A−1BE
−ECA−1Eparenrightbigg
. (A.26)
Further , if D−1exists then F=parenleftbig
A−BD−1Cparenrightbig−1also exists and
M−1=parenleftbiggF −FBD−1
−D−1CF D−1+D−1CFBD−1parenrightbigg
. (A.27)
Proof In order to prove equation (A.26) put
N=parenleftbiggA−10
−CA−1Irparenrightbigg
.
According to Theorem A.76
NM=parenleftbiggIs A−1B
0D−CA−1Bparenrightbigg
is invertible because Nand Mare square matrices and, by assumption, invertible.
Hence the rows of D−CA−1Bare linearly independent and therefore Eexists. It
remains to show that MM−1=Inwhich follows from
Aparenleftbig
A−1+A−1BECA−1parenrightbig
−BECA−1= Is+BECA−1−BECA−1=Is,
Cparenleftbig
A−1+A−1BECA−1parenrightbig
−DECA−1=parenleftbig
C+CA−1BEC−DECparenrightbig
A−1
=parenleftbig
E−1+CA−1B−Dparenrightbig
ECA−1=0,
−AA−1BE+BE= 0,
−CA−1BE+DE=parenleftbig
D−CA−1Bparenrightbig
E=Ir.
231 Theoretical Background and Basic I nequa lities
The proof of equation (A.27) follows by applying equation (A.26) to M/primeand
noticing that M−1=((M/prime)−1)/primedue to Theorem A.77.
Spectral Decomposition
Deﬁnition A.81 (Eigenvector and eigenvalue) Let Abe an n×n matrix. Then the
vector u∈ /CAn,u/negationslash=0is called an eigenvector of Awith the eigenvalue λif
Au=λu. (A.28)
Since each eigenvector u/negationslash=0must obey Au=λuwe know that each eigenvalue λ
is a non-trivial solution of (A−λI)u=0. This, however, requires that |A−λI|=
0.
Deﬁnition A.82 (Characteristic polynomial) Given an n×nm a t r i x A,t h e char-
acteristic polynomial /Phi1A: /CA→ /CAofAis deﬁned by
/Phi1A(λ)def=|A−λI|.
Note that the characteristic polynomial is a nth degree polynomial.
IfAis not only square but also symmetric, it can be shown that all roots of /Phi1Aare
real. Using this result we can prove the following powerful theorem.
Theorem A.83 (Spectral decomposition theorem) Any symmetric n ×nm a t r i x
Acan be written as
A=U/Lambda1U/prime, (A.29)
where U/primeU=Iand/Lambda1=diag(λ1,...,λ n).
Proof If we consider any two eigenvectors uiand ujthen we know that
0=u/prime
iparenleftbig
Au jparenrightbig
−parenleftbig
Au jparenrightbig/primeui=u/prime
iAu j−u/prime
jAu i=λju/prime
iuj−λiu/prime
jui=parenleftbig
λj−λiparenrightbig
u/prime
iuj,
where we exploit the symmetry of Aand equation (A.28). Thus any two eigen-
vectors ui,ujwith different eigenvalues λi,λ jare orthogonal. If ui1,..., uilare
leigenvectors with the same eigenvalue λthensummationtextl
j=1αluijis also an eigenvector
with the eigenvalue λfor anyα1,...,α l. This allows us to apply the Gram-Schmidt
orthogonalization to all eigenvectors uiwith equal eigenvalues. Hence we can as-
232 Appendix A
sume that all eigenvectors are orthogonal. Moreover, if uiis an eigenvector then
βuiis also an eigenvector with the same eigenvalue. Thus, without loss of gen-
erality, we assume that /bardblui/bardbl=1f o ra l l i. Let us arrange all neigenvectors of
unit length columnwise in an n×nmatrix U=(u1,..., un)in order of increas-
ing eigenvalues λi. By construction this matrix has the property that U/primeU=I.B y
virtue of equation (A.28) we have
AU=U/Lambda1, (A.30)
where /Lambda1=diag(λ1,...,λ n).S i n c e Uis a square matrix Theorem A.76 shows that
UU/prime=I. Multiplying equation (A.30) by U/primefrom the right results in A=U/Lambda1U/prime
which proves the theorem.
Theorem A.84 (Trace and Determinant) F or any symmetric n ×nm a t r i x Awith
eigenvalues λ1,...,λ n,
|A|=nproductdisplay
i=1λi, tr(A)=nsummationdisplay
i=1λi.
Proof Consider the spectral decomposition of A, i.e., A=U/Lambda1U/prime. Using Theorem
A.67 and U/primeU=Igives
|A|=vextendsinglevextendsingleU/Lambda1U/primevextendsinglevextendsingle=|U|·|/Lambda1|·vextendsinglevextendsingleU/primevextendsinglevextendsingle=vextendsinglevextendsingleU/primevextendsinglevextendsingle·|U|·|/Lambda1|=vextendsinglevextendsingleU/primeUvextendsinglevextendsingle·|/Lambda1|=|/Lambda1|.
The ﬁrst results follows by |/Lambda1|=|diag(λ1,...,λ n)|=producttextn
i=1λi. The second result
follows from the following argument
tr(A)=trparenleftbig
U/Lambda1U/primeparenrightbig
=trparenleftbig
/Lambda1U/primeUparenrightbig
=tr(/Lambda1)=nsummationdisplay
i=1λi,
where we use Theorem A.74 in the second step.
Theorem A.85 (Eigenvalues and positive semideﬁniteness) A symmetric n ×n
matrix Ais positive deﬁnite (positive semideﬁnite) if and only if all n eigenvalues
λiofAare strictly positive (non-negative).
Proof Let us assume the matrix Ais positive deﬁnite, that is, for all c∈ /CAn,
c/negationslash=0we know that c/primeAc>0. By Theorem A.83 we have A=U/Lambda1U/primefor
U=(u1,..., un),U/primeU=UU/prime=Iand/Lambda1=diag(λ1,...,λ n).U s i n g c=ui
we obtain u/prime
iU/Lambda1U/primeui=λi/bardblui/bardbl2=λi>0f o ra l l i∈{1,..., n}.
233 Theoretical Background and Basic I nequa lities
Now let us assume that all neigenvalues λiare strictly positive. Then, for all
vectors c∈ /CAn,c/negationslash=0,
c/primeAc=c/primeU/Lambda1U/primec=α/prime/Lambda1α=nsummationdisplay
i=1λiα2
i>0.
Note that U/primec=0⇔ c=0becausevextenddoublevextenddoubleU/primecvextenddoublevextenddouble2=c/primeUU/primec=/bardblc/bardbl2. The proof for the
case of positive semideﬁniteness follows from the same argument.
Quadratic forms
Theorem A.86 (Sum of quadratic forms) Let A∈ /CAn×nand B∈ /CAm×mbe
two symmetric, positive semideﬁnite matrices. Then, for any matrix X∈ /CAn×r,
Y∈ /CAm×r,a∈ /CAnand b∈ /CAm, we have that
D(µ)=(a−Xµ)/primeA(a−Xµ)+(b−Yµ)/primeB(b−Yµ), (A.31)
can be written as
D(µ)=(µ−c)/primeC(µ−c)+d (A.32)
where
C=X/primeAX+Y/primeBY, d=a/primeAa+b/primeBb−c/primeCc,
and c∈ /CArsatisﬁes
Cc=X/primeAa+Y/primeBb.
In the special case of C>0and Y=Iwe can write d ∈ /CAas
d=(a−Xb)/primeparenleftbig
A−1+XB−1X/primeparenrightbig−1(a−Xb). (A.33)
Proof The lengthy proof of the existence of c∈ /CArhas been omitted and can be
found in Kockelkorn (2000). Let us start by proving equation (A.32). Expanding(A.31) we obtain
D(µ)= a
/primeAa−2a/primeAXµ+µ/primeX/primeAXµ+µ/primeY/primeBYµ−2b/primeBYµ+b/primeYb
= a/primeAa−2µ/primeparenleftbig
X/primeAa+Y/primeBbparenrightbig
+µ/primeparenleftbig
X/primeAX+Y/primeBYparenrightbig
µ+b/primeBb
= a/primeAa−2µ/primeCc+µ/primeCµ+b/primeBb
=(µ−c)/primeC(µ−c)−c/primeCc+a/primeAa+b/primeBb,
234 Appendix A
where we used the symmetry of Aand Bseveral times. This shows equation (A.32).
In the special case of Y=Iwe obtain
C=X/primeAX+B. (A.34)
Let us introduce the following abbreviation udef=a−Xb⇔ a=u+Xb.T h e n
we know
Cc=X/primeAa+Bb=X/primeA(u+Xb)+Bb=X/primeAu+Cb,
where we have used equation (A.34). Since C>0 it follows that
c/primeCc= c/primeCC−1Cc=parenleftbig
X/primeAu+Cbparenrightbig/primeC−1parenleftbig
X/primeAu+Cbparenrightbig
= u/primeAXC−1X/primeAu+2u/primeAXb+b/primeCb. (A.35)
Further, we have
a/primeAa=(u+Xb)/primeA(u+Xb)=u/primeAu+2u/primeAXb+b/primeX/primeAXb. (A.36)
Combining equations (A.36), (A.35) and (A.34) thus yields
a/primeAa+b/primeBb−c/primeCc= u/primeAu−u/primeAXC−1X/primeAu+b/primeX/primeAXb+b/primeBb−b/primeCb
= u/primeAu−u/primeAXC−1X/primeAu+b/primeparenleftbig
X/primeAX+Bparenrightbig
b−b/primeCb
= u/primeparenleftbig
A−AXC−1X/primeAparenrightbig
u.
Finally, using the Woodbury formula given in Theorem A.79 we can write A−
AXC−1X/primeA=parenleftBigparenleftbig
A−AXC−1X/primeAparenrightbig−1parenrightBig−1
as
parenleftbig
A−(AX)parenleftbig
C−1X/primeAparenrightbigparenrightbig−1= A−1+Xparenleftbig
I−C−1X/primeAXparenrightbig−1C−1X/prime
= A−1+Xparenleftbig
C−X/primeAXparenrightbig−1X/prime=A−1+XB−1X/prime.
Putting all these results together proves equation (A.33).
Theorem A.87 (Rayleigh coefﬁcient) Let A∈ /CAn×nbe a symmetric, positive
semideﬁnite matrix with eigenvalues λ1≥···≥λn≥0. Then, for all x∈ /CAn,
λn≤x/primeAx
x/primex≤λ1,
where the λiare the eigenvalues of Asorted in decreasing order . Further , the right
hand side becomes an equality if xis the eigenvector u1ofAcorresponding to the
largest eigenvalue λ1.
235 Theoretical Background and Basic I nequa lities
Proof According to Theorem A.83 we know that each symmetric Acan be written
asA=U/Lambda1U/primewhere U/primeU=UU/prime=Iand/Lambda1=diag(λ1,...,λ n).F o rag i v e n
x∈ /CAnlet us consider y=U/primex. Then we know that
x/primeAx
x/primex=x/primeU/Lambda1U/primex
x/primeUU/primex=y/prime/Lambda1y
y/primey=summationtextn
i=1λiy2
i
summationtexty2
i. (A.37)
Sinceλn≤λiandλi≤λ1for all i∈{1,..., n}we know that
nsummationdisplay
i=1λny2
i≤nsummationdisplay
i=1λiy2
i≤nsummationdisplay
i=1λ1y2
i. (A.38)
The results follows directly from equation (A.37). Moreover, if y1=1a n d yi=0
for all i∈{2,..., n}then we attain an equality in (A.38). This is the case only for
xbeing the ﬁrst column of U, i.e., the eigenvector u1corresponding to the largest
eigenvalue λ1.
Theorem A.88 (Generalized Rayleigh coefﬁcient) Let A∈ /CAn×nbe a symmet-
ric, positive semideﬁnite matrix and B=C/primeCbe a positive deﬁnite n ×n matrix.
Then, for all x∈ /CAn,
λn≤x/primeAx
x/primeBx≤λ1, (A.39)
where the λiare the eigenvalues of (C−1)/primeAC−1sorted in decreasing order . Fur-
ther , the right hand side becomes an equality if x=C−1u1where u1is the eigen-
vector of (C−1)/primeAC−1corresponding to the largest eigenvalue λ1. In the special
case of A=aa/primewe know that λ1=a/primeB−1aand that the maximizer of (A.39) is
given by x=B−1a.
Proof Put z=Cx. Then for all x∈ /CAn
x/primeAx
x/primeBx=x/primeAx
x/primeC/primeCx=z/primeparenleftbig
C−1parenrightbig/primeAC−1z
z/primez,
and therefore the ﬁrst part follows from Theorem A.87. In the special case of
A=aa/primewe obtain (C−1)/primeAC−1=(C−1)/primeaa/primeC−1=vv/primewhere v=(C−1)/primea.
The matrix vv/primehas exactly one eigenvector vto the eigenvalue /bardblv/bardbl2because
(vv/prime)v=v(v/primev)=/bardblv/bardbl2·v.S i n c e/bardblv/bardbl2=a/primeC−1(C−1)/primea=a/prime(C/primeC)−1a=a/primeB−1a
and x=C−1v=C−1(C−1)/primea=(C/primeC)−1a=B−1athe special case is proved.

236 Appendix A
Kronecker Product
Deﬁnition A.89 (Kronecker product) Given an n×m and q×rm a t r i x Aand B,
respectively, the Kronecker product A⊗Bis the nq×mr matrix
A⊗Bdef=
a11B··· a1mB
.........
a
n1B··· anmB
.
Theorem A.90 (Matrix product of Kronecker products) Fo r a l l m,n,q,r,s,t∈/C6and any n×mm a t r i x A,r×qm a t r i x B,m×sm a t r i x Cand q×tm a t r i x D,
(A⊗B)(C⊗D)=(AC)⊗(BD).
Proof Let us represent the matrices Aand Bin terms of their rows and Cand D
in terms of their columns,
A=parenleftbig
a/prime
1;...;a/prime
nparenrightbig
,ai∈ /CAm,B=parenleftbig
b/prime
1;...;b/prime
rparenrightbig
,bj∈ /CAq,
C=(c1,..., cs), cu∈ /CAm,D=(d1,..., dt), dv∈ /CAq.
and i∈{1,..., n},j∈{1,..., r},u∈{1,..., s}andv∈{1,..., t}.L e t
i∗jdef=(i−1)·r+jand u∗vdef=(u−1)·t+v. Consider the element in
the i∗j–th row and u∗v–th column of (A⊗B)(C⊗D)
((A⊗B)(C⊗D))i∗j,u∗v=parenleftbig
ai1b/prime
j,..., aimb/prime
jparenrightbigparenleftbig
c1ud/prime
v,..., cmud/prime
vparenrightbig/prime
=msummationdisplay
l=1ailclub/prime
jdv
= a/prime
icu·b/prime
jdv
=(AC)iu·(BD)jv
=((AC)⊗(BD))i∗j,u∗v,
where the last step follows from Deﬁnition A.89.
Theorem A.91 (Eigenvalues of Kronecker products) Let Aand Bbe symmetric
n×n and m×m matrices, respectively. Then the eigenvalues of the matrix A⊗B
are all products of pairs of eigenvalues of Aand B.
237 Theoretical Background and Basic I nequa lities
Proof Let{(u1,λ 1),...,(un,λ n)}and{(v1,ω 1),...,(vm,ω m)}be the eigensys-
tems of Aand Bwhere we take the liberty of having a few λiandωizero (see
Theorem A.83). Then, for all i∈{1,..., n}and j∈{1,..., m}
(A⊗B)parenleftbig
ui⊗vjparenrightbig
=(Au i)⊗parenleftbig
Bv jparenrightbig
=(λiui)⊗parenleftbig
ωjvjparenrightbig
=parenleftbig
λiωjparenrightbigparenleftbig
ui⊗vjparenrightbig
,
where we used Theorem A.90. Further,
vextenddoublevextenddoubleui⊗vjvextenddoublevextenddouble2=parenleftbig
ui⊗vjparenrightbig/primeparenleftbig
ui⊗vjparenrightbig
=/bardblui/bardbl2·vextenddoublevextenddoublevjvextenddoublevextenddouble2=1
which shows that A⊗Bhas at least mn eigenvectors with eigenvalues given by the
product of all pairs of eigenvalues of Aand B. Since all eigenvectors are orthogonal
to each other A⊗B∈ /CAmn×mnhas at most mn eigenvectors.
Corollary A.92 (Positive deﬁniteness of Kronecker products) Let Aand Bbe
two positive deﬁnite (positive semideﬁnite) matrices. Then A⊗Bis positive deﬁnite
(positive semideﬁnite).
Proof IfAand Bare positive deﬁnite then all eigenvalues of Aand Bare strictly
positive (see Theorem A.85). Hence, by Theorem A.91 all eigenvalues of A⊗B
are strictly positive and thus A⊗Bis positive deﬁnite by Theorem A.85. The case
of positive semideﬁnite matrices proceeds similarly.
Derivatives of Matrices
Deﬁnition A.93 (Derivative of a vector-valued function) Letφ: /CAm→ /CAnbe a
ﬁxed function. Then the m ×nm a t r i x∂φ(x)
∂xof derivatives is deﬁned by
∂φ(x)
∂xdef=parenleftbigg∂φ j(x)
∂xiparenrightbiggm,n
i,j=1=
∂φ 1(x)
∂x1...∂φ n(x)
∂x1.........
∂φ 1(x)
∂xm···∂φ n(x)
∂xm
.
Theorem A.94 (Derivative of a linear function) Letφ: /CAm→ /CAnbe a linear
function, i.e., φ(x)=Ax+bfor a ﬁxed matrix A∈ /CAn×mand vector b∈ /CAn.
Then
∂φ(x)
∂x=A/prime.
238 Appendix A
Proof For any i∈{1,..., m}and j∈{1,..., n}let us consider the i,j–th
element of∂φ(x)
∂x.W eh a v e∂φ j(x)
∂xi=summationtextm
l=1Ajlxl
∂xi=Ajiwhich proves the theorem.
Theorem A.95 (Derivative of a quadratic form) Letφ: /CAn→ /CAbe a quadratic
form, i.e., φ(x)=x/primeAx for a ﬁxed symmetric matrix A∈ /CAn×n.T h e n
∂φ(x)
∂x=2Ax.
Proof For any i∈{1,..., n}let us consider the ith element of∂φ(x)
∂x.W eh a v e
∂φ(x)
∂xi=summationtextn
r=1summationtextn
s=1xrArsxs
∂xi=nsummationdisplay
s=1
s/negationslash=iAisxs+nsummationdisplay
r=1
r/negationslash=iArixr+2xiAii=Ax,
where the last equality follows from the symmetry of A.
Theorem A.96 (Derivative of the inverse) Let A: /CA→ /CAn×nbe a matrix-valued
function. Then
∂(A(x))−1
∂x=−(A(x))−1∂A(x)
∂x(A(x))−1.
Proof First note that, for all x∈ /CA, by deﬁnition A(x)(A(x))−1=I.S i n c e I
does not depend on xwe have
0=∂I
∂x=∂A(x)(A(x))−1
∂x=∂A(x)
∂x(A(x))−1+A(x)∂(A(x))−1
∂x,
where the second part follows by component-wise application of the product rule
of differentiation. The result follows by rearranging the terms.
Theorem A.97 (Derivative of the log-determinant) F or any symmetric n ×nm a -
trix A,
∂ln(|A|)
∂A=A−1.
239 Theoretical Background and Basic I nequa lities
Proof Let us consider the i,j–th element of the n×nmatrix of derivatives, i.e.,
∂ln(|A|)/∂Aij. By the chain rule of differentiation and Deﬁnition A.64 we know
∂ln(|A|)
∂Aij=dln(|A|)
d|A|·∂|A|
∂Aij=1
|A|·∂parenleftbigsummationtextn
l=1Alj·vextendsinglevextendsingleA[lj]vextendsinglevextendsingle·(−1)l+jparenrightbig
∂Aij
=1
|A|·vextendsinglevextendsingleA[ij]vextendsinglevextendsingle·(−1)i+j,
because all thevextendsinglevextendsingleA[lj]vextendsinglevextendsingleinvolve determinants of matrices which do not contain Aij.
Exploiting the symmetry of Aand Theorem A.78 proves the theorem.
The following theorem is given without proof; the interested reader is referred to
Magnus and Neudecker (1999).
Theorem A.98 (Derivative of a quadratic form) F or any non-singular n ×nm a -
trix Aand a,b∈ /CAn,
∂a/primeA−1b
∂A=−parenleftbig
A−1parenrightbig/primeab/primeparenleftbig
A−1parenrightbig/prime.
A.4 Ill-Posed Problems
The concept of well and ill-posed problems was introduced in Hadamard (1902)
in an attempt to clarify what types of boundary conditions are most natural for
various types of differential equations. The solution to any quantitative problem
usually ends in ﬁnding the “solution” yfrom given “initial data” x,
y=S(x). (A.40)
We shall consider xand yas elements of metric spaces /CGand /CHwith the metrics
ρ/CGandρ/CH. The metric is usually determined by the formulation of the problem.
Suppose that the concept of solution is deﬁned by equation (A.40).
Deﬁnition A.99 (Stable solution) The problem of determining the solution y=
S(x)in the space of /CHfrom the initial data x∈ /CGis said to be stable on the spaces
(
/CH, /CG)if, for every ε> 0, there exists a positive number δ(ε)>0such that
∀x1,x2∈ /CG:ρ/CG(x1,x2)≤δ(ε)⇒ρ/CH(S(x1),S(x2))≤ε.
240 Appendix A
Deﬁnition A.100 (Well-posed and ill-posed problems) The problem of deter-
mining the solution y=S(x)in the space of /CHfrom the initial data x∈ /CGis
said to be well-posed on the spaces (
/CH, /CG)if
1.for every element x∈ /CGthere exists a solution yin the space /CH.
2.the solution y=S(x)is unique.
3.the problem is stable on the spaces (
/CH, /CG).
Problems that do not satisfy these conditions are said to be ill-posed.
A.5 Basic Inequalities
A.5.1 General (In) equalities
This section collects some general results which are frequently used in the main
body. Each theorem is followed by its proof.
Theorem A.101 (Lower bound for the exponential) Fo r a l l x∈ /CAwe have
1+x≤exp(x),
with equality if and only if x =0.
Proof Consider the function f(x)= 1+x−exp(x). The ﬁrst and second
derivatives of this function aredf(x)
dx=1−exp(x)andd2f(x)
dx2=− exp(x). Hence
this function has a maximum at x∗=0 which implies that f(x)≤f(0)=0⇔
1+x≤exp(x).
Theorem A.102 (Euler’s inequality) Fo r a l l x >0and all a∈ /CA,a/negationslash=0
parenleftBig
1+a
xparenrightBigx
<exp(a).
Proof From Theorem A.101 we know that 1 +a/x<exp(a/x), because, by
assumption, a/negationslash=0. Since x>0 this implies (1+a/x)x<(exp(a/x))x=exp(a)
which proves the theorem.

241 Theoretical Background and Basic I nequa lities
Theorem A.103 (Binomial theorem) Fo r a l l x∈ /CAand all d∈ /C6we have
(1+x)d=dsummationdisplay
i=0parenleftbiggd
iparenrightbigg
xi.
Proof We proof the theorem by induction over d. The theorem is trivially true for
alld=0a n da l l x∈ /CA. Suppose the theorem is true for some d∈ /C6.T h e n
(1+x)d+1=(1+x)dsummationdisplay
i=0parenleftbiggd
iparenrightbigg
xi=dsummationdisplay
i=0parenleftbiggd
iparenrightbigg
xi+d+1summationdisplay
i=1parenleftbiggd
i−1parenrightbigg
xi
=parenleftbiggd
0parenrightbigg
x0+dsummationdisplay
i=1parenleftbiggparenleftbiggd
iparenrightbigg
+parenleftbiggd
i−1parenrightbiggparenrightbigg
xi+parenleftbiggd
dparenrightbigg
xd+1
=parenleftbiggd+1
0parenrightbigg
x0+dsummationdisplay
i=1parenleftbiggd+1
iparenrightbigg
xi+parenleftbiggd+1
d+1parenrightbigg
xd+1
=d+1summationdisplay
i=0parenleftbiggd+1
iparenrightbigg
xi,
where we have usedparenleftbiggd
iparenrightbigg
+parenleftbiggd
i−1parenrightbigg
=parenleftbiggd+1
iparenrightbigg
(A.41)
in the third line.
Corollary A.104 (Binomial coefﬁcients) Fo r a l l a,b∈ /CAand all d∈ /C6we have
(a+b)d=dsummationdisplay
i=0parenleftbiggd
iparenrightbigg
ai·bd−i.
Proof Using Theorem A.103 with the factorization (a+b)d=(b(a/b+1))d
proves the corollary.
Theorem A.105 (Upper bound for the sum of binomials) F or any m∈ /C6and
d∈{1,..., m}we have
dsummationdisplay
i=0parenleftbiggm
iparenrightbigg
<parenleftBigem
dparenrightBigd
.
242 Appendix A
Proof The result follows from Theorems A.103 and A.102. Noticingparenleftbigm
dparenrightbigd−i≥1
for all i∈{0,..., d}we see that
dsummationdisplay
i=0parenleftbiggm
iparenrightbigg
≤dsummationdisplay
i=0parenleftbiggm
iparenrightbiggparenleftBigm
dparenrightBigd−i
=parenleftBigm
dparenrightBigddsummationdisplay
i=0parenleftbiggm
iparenrightbiggparenleftbiggd
mparenrightbiggi
≤parenleftBigm
dparenrightBigdmsummationdisplay
i=0parenleftbiggm
iparenrightbiggparenleftbiggd
mparenrightbiggi
=parenleftBigm
dparenrightBigdparenleftbigg
1+d
mparenrightbiggm
<parenleftBigm
dparenrightBigd
exp(d)=parenleftBigem
dparenrightBigd
.
The theorem is proven.
Theorem A.106 (Cauchy-Schwarz inequality (Cauchy 1821)) F or any two ele-
ments xand yof an inner product space /CGwe have
|/angbracketleftx,y/angbracketright|≤/bardblx/bardbl·/bardbly/bardbl.
Proof Ify=0then the inequality is true because both sides are zero. Assume
then y/negationslash=0.F o ra n y c∈ /CAwe have
0≤/angbracketleftx+cy,x+cy/angbracketright=/bardblx/bardbl2+2c/angbracketleftx,y/angbracketright+c2/bardbly/bardbl2.
Now put c=−/angbracketleftx,y/angbracketright
/bardbly/bardbl2to obtain
0≤/bardblx/bardbl2−/angbracketleftx,y/angbracketright
/bardbly/bardbl2/angbracketleftx,y/angbracketright⇔|/angbracketleftx,y/angbracketright|≤/bardblx/bardbl·/bardbly/bardbl,
as/bardbly/bardbl2>0 by assumption.
Note that the Cauchy-Schwarz inequality remains valid even if equation (A.20) is
replaced by y=0⇒/bardbly/bardbl=0.
Theorem A.107 (Union bound) Let X 1,..., Xn∈ /CGbe a ﬁnite number of sets
from theσ–algebra /CG. Then, for any measure PX,
PX(X1∪···∪ Xn)≤nsummationdisplay
i=1PX(Xi).
243 Theoretical Background and Basic I nequa lities
Proof Consider two arbitrary sets A∈ /CGand B∈ /CG. By deﬁnition
PX(A∪B)=PX(A)+PX(B)−PX(A∩B)≤PX(A)+PX(B).
Hence
PX(X1∪···∪ Xn)≤PX(X1)+PX(X2∪···∪ Xn)≤···≤nsummationdisplay
i=1PX(Xi),
which proves the theorem.
A.5.2 Large Deviation Bounds
In this subsection we present a series of theorems which aim to bound the proba-
bility that a random variable Xis far from its expected value EXbracketleftbig
Xbracketrightbig
. We will only
scratch the surface of the theory of large deviation bounds; the interested readeris referred to Devroye et al. (1996), Feller (1950), Feller (1966) and Devroye andLugosi (2001) for further details.
The following important theorem shows that, in the limit of an inﬁnitely large
sample, there is no variation in the mean of the sample. The mean value of asequence of random variable is no longer random but is precisely given by theexpectation value of each single random variable.
Theorem A.108 (Law of large numbers) F or any random variable Xwith ﬁnite
expectation µ=E
Xbracketleftbig
Xbracketrightbig
and variance Va r(X)we have
∀ε> 0: lim
n→∞PXnparenleftBiggvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle1
nnsummationdisplay
i=1Xi−µvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle>εparenrightBigg
=0 (A.42)
We shall prove this theorem shortly. Now, the problem of large deviations is to
determine how fast the convergence (A.42) happens to be. We would like to knowhow likely it is that a mean of nindependently identically distributed ( iid) numbers
deviates from their common expectation by more than ε> 0. Let us start with a
simple theorem bounding the tail of any positive random variable.
Theorem A.109 (Markov’s inequality (Markov 1912)) If the random variable X
fulﬁlls F
X(0)=0then, for all λ> 0,
PXparenleftbig
X>λ EXbracketleftbig
Xbracketrightbigparenrightbig
<1
λ.
244 Appendix A
Proof By Deﬁnition A.7 we know that
EXbracketleftbig
Xbracketrightbig
=integraldisplay∞
0xdFX(x)>integraldisplay∞
λEX[X]xdFX(x)
≥λEXbracketleftbig
Xbracketrightbigintegraldisplay∞
λEX[X]dFX(x)≥λEXbracketleftbig
Xbracketrightbig
PXparenleftbig
X>λ EXbracketleftbig
Xbracketrightbigparenrightbig
.
Dividing both sides by λEXbracketleftbig
Xbracketrightbig
(which is always positive by FX(0)=0a n dt h e
choice of λ) gives the desired result.
A direct consequence of this theorem is Chebyshev’s inequality.
Theorem A.110 (Chebyshev’s inequality (Tschebyscheff 1936)) IfEXbracketleftbig
X2bracketrightbig
ex-
ists, then for all ε> 0
PX(|X|>ε)<EXbracketleftbig
X2bracketrightbig
ε2. (A.43)
In particular , we have for all ε> 0
PXparenleftbigvextendsinglevextendsingleX−EXbracketleftbig
Xbracketrightbigvextendsinglevextendsingle>εparenrightbig
<Va r(X)
ε2.
Proof Deﬁne a new random variable Y=X2.T h e n FY(0)=0,ε2>0a n d
PX(|X|>ε)=PYparenleftbig
Y>ε2parenrightbig
<EYbracketleftbig
Ybracketrightbig
ε2=EXbracketleftbig
X2bracketrightbig
ε2,
where the inequality follows from Theorem A.109.
Proof of Theorem A.108. Let us denote µ=EXbracketleftbig
Xbracketrightbig
. Then, by Chebyshev’s in-
equality , for all ε> 0,
PXnparenleftBiggvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle1
nnsummationdisplay
i=1Xi−µvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle>εparenrightBigg
= P
XnparenleftBiggvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle1
nnsummationdisplay
i=1Xi−EXnbracketleftBigg
1
nnsummationdisplay
i=1XibracketrightBiggvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle>εparenrightBigg
≤Va rparenleftbig
n−1summationtextn
i=1Xiparenrightbig
ε2.
By Corollary A.20 we know that, for niid variables Xi,V a rparenleftbig
n−1summationtextn
i=1Xiparenrightbig
=
1
nVa r(X)and thus, for all ε> 0, lim n→∞ Va rparenleftbig
n−1summationtextn
i=1Xiparenrightbig
·ε−2=0 whenever
Va r(X)is ﬁnite. The law of large numbers is proved.

245 Theoretical Background and Basic I nequa lities
Although the general applicability of Chebyshev’s inequality is an appealing fea-
ture the bound is, in general, very loose (see also Devroye and Lugosi (2001)).A key to obtaining tighter bounds comes through a more clever use of Markov’sinequality—a technique known as Chernoff ’s bounding method . The idea is very
simple: By Markov’s inequality and the monotonicity of f(z)=exp(sz),f o ra l l
s>0, we know that, for all ε> 0,
P
XnparenleftBigg
1
nnsummationdisplay
i=1Xi−EXbracketleftbig
Xbracketrightbig
>εparenrightBigg
=PXnparenleftBigg
expparenleftBigg
s
nnsummationdisplay
i=1parenleftbig
Xi−EXbracketleftbig
XbracketrightbigparenrightbigparenrightBigg
>exp(sε)parenrightBigg
<EXnbracketleftbig
expparenleftbigs
nsummationtextn
i=1parenleftbig
Xi−EXbracketleftbig
Xbracketrightbigparenrightbigparenrightbigbracketrightbig
exp(sε)
=producttextn
i=1EXibracketleftbig
expparenleftbigs
nparenleftbig
Xi−EXbracketleftbig
Xbracketrightbigparenrightbigparenrightbigbracketrightbig
exp(sε), (A.44)
where the third line follows from Theorem A.109 and the last line follows from
the independence of the Xiand Theorem A.15. Now the problem of ﬁnding tight
bounds for large deviations reduces to the problem of bounding the functionexpparenleftbig
sn
−1parenleftbig
X−EXbracketleftbig
Xbracketrightbigparenrightbigparenrightbig
which is also called the moment generating function (see
Feller (1966)).For random variables with ﬁnite support the most elegant bound isdue to Hoeffding (1963)
6.
Lemma A.111 LetXbe a random variable with EXbracketleftbig
Xbracketrightbig
=0,PX(X∈[a,b])=1.
Then, for all s >0,
EXbracketleftbig
exp(sX)bracketrightbig
≤expparenleftBigg
s2(b−a)2
8parenrightBigg
.
Proof By the convexity of the exponential function
∀x∈[a,b]: exp(sx)≤x−a
b−aexp(sb)+b−x
b−aexp(sa).
6 The proof presented can be found in Devroye et al. (1996).
246 Appendix A
Exploiting EXbracketleftbig
Xbracketrightbig
=0, and introducing the notation pdef=−a
b−awe have that
exp(ps(b−a))=exp(−sa). Thus, we get
EXbracketleftbig
exp(sX)bracketrightbig
≤pexp(sb)+(1−p)exp(sa)
=pexp(sb)exp(ps(b−a))
exp(ps(b−a))+(1−p)exp(sa)exp(ps(b−a))
exp(ps(b−a))
=1−p+pexp(s(b−a))
exp(ps(b−a))
=exp(g(u)),
where
udef=s(b−a)≥0, g(u)def=− pu+ln(1−p+pexp(u)).
By a straightforward calculation we see that the derivative of gis
dg(u)
du=− p+pexp(u)
1−p+pexp(u),
therefore g(0)=dg(u)
duvextendsinglevextendsinglevextendsingle
u=0=0. Moreover,
d2g(u)
du2=pexp(u)(1−p+pexp(u))−pexp(u)pexp(u)
(1−p+pexp(u))2
=(1−p)pexp(u)
(1−p+pexp(u))2,
and the maximum ofd2g(u)
du2is attained for u=0. Henced2g(u)
du2≤(1−p)p≤1
4.
Thus, by Taylor series expansion with remainder, for some u0∈[0,u],
g(u)=g(0)+u·dg(u)
duvextendsinglevextendsinglevextendsinglevextendsingle
u=0+u2
2·d2g(u)
du2vextendsinglevextendsinglevextendsinglevextendsingle
u=u0≤u2
8=s2(b−a)2
8.
The lemma is proved.
Using this lemma we can now prove Chernoff’s inequality (Chernoff 1952;
Okamoto 1958) which was later generalized by Hoeffding (1963).
Theorem A.112 (Hoeffding’s inequality) LetX1,..., Xnbe independent bounded
random variables such that, for all i ∈{1,..., n},PXi(Xi∈[a,b])=1and
247 Theoretical Background and Basic I nequa lities
EXibracketleftbig
Xibracketrightbig
=µ. Then, for all ε> 0,
PXnparenleftBigg
1
nnsummationdisplay
i=1Xi−µ>εparenrightBigg
<expparenleftbigg
−2nε2
(b−a)2parenrightbigg
(A.45)
and
PXnparenleftBiggvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle1
nnsummationdisplay
i=1Xi−µvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle>εparenrightBigg
<2e x pparenleftbigg
−2nε2
(b−a)2parenrightbigg
. (A.46)
Proof Noting that EXbracketleftbig
X−µbracketrightbig
=0 we can apply Lemma A.111 together with
equation (A.44) to obtain
PXnparenleftBigg
1
nnsummationdisplay
i=1Xi−µ>εparenrightBigg
<producttextn
i=1expparenleftBig
s2(b−a)2
8n2parenrightBig
exp(sε)=expparenleftbiggs2
8n(b−a)2−sεparenrightbigg
.
Minimization of this expression w.r.t. sgives s=4nε/(b−a)2. Hence we have
PXnparenleftBigg
1
nnsummationdisplay
i=1Xi−µ>εparenrightBigg
<expparenleftbiggs2
8n(b−a)2−sεparenrightbigg
=expparenleftbigg
−2nε2
(b−a)2parenrightbigg
.
This proves equation (A.45). By using Yi=−Xiwe see
PYnparenleftBigg
1
nnsummationdisplay
i=1Yi−EYbracketleftbig
Ybracketrightbig
>εparenrightBigg
= PXnparenleftBigg
µ−1
nnsummationdisplay
i=1Xi>εparenrightBigg
< expparenleftbigg
−2nε2
(b−a)2parenrightbigg
.
Thus, using Theorem A.107 we obtain equation (A.46).
This inequality is appropriate if we have only knowledge of the support of PX.
However, this bound does not take into account the variance of the random variableX. We shall provide a bound on the moment generating function taking into account
both support and variance.
248 Appendix A
Lemma A.113 LetXbe a random variable with EXbracketleftbig
Xbracketrightbig
=0,PX(|X|≤c)=1
andσ2=Va r(X)=EXbracketleftbig
X2bracketrightbig
. Then, for all s >0,
EXbracketleftbig
exp(sX)bracketrightbig
≤expparenleftbiggσ2
c2(exp(sc)−1−sc)parenrightbigg
.
Proof First we note that, for all j∈{2,...,∞},
EXbracketleftbig
Xjbracketrightbig
=EXbracketleftbig
Xj−2X2bracketrightbig
≤EXbracketleftbig
cj−2X2bracketrightbig
=cj−2σ2,
because, by assumption, the random variable is bounded by c. Exploiting the fact
that exp(x)=summationtext∞
j=0xj
j!we therefore obtain
EXbracketleftbig
exp(sX)bracketrightbig
= EXbracketleftBigg
1+sX+∞summationdisplay
j=2sjXj
j!bracketrightBigg
=1+∞summationdisplay
j=2sj
j!EXbracketleftbig
Xjbracketrightbig
≤ 1+∞summationdisplay
j=2sj
j!cj−2σ2
= 1+σ2
c2∞summationdisplay
j=2sjcj
j!
= 1+σ2
c2(exp(sc)−1−sc).
Finally, using Theorem A.101 proves the lemma.
Theorem A.114 (Bennett (1962)) LetX1,..., Xnbe independent random vari-
ables such that, for all i ∈{1,..., n},PXi(|Xi|≤c)=1and EXibracketleftbig
Xibracketrightbig
=0.
Then, for any ε> 0,
PXnparenleftBiggnsummationdisplay
i=1Xi>εparenrightBigg
<expparenleftbigg
−ε
cparenleftbiggparenleftbigg
1+nσ2
εcparenrightbigg
lnparenleftBig
1+εc
nσ2parenrightBig
−1parenrightbiggparenrightbigg
,
whereσ2=EXbracketleftbig
X2bracketrightbig
=Va r(X).
Proof Using equation (A.44) and the Lemma A.113 yields
PXnparenleftBiggnsummationdisplay
i=1Xi>εparenrightBigg
<expparenleftbiggnσ2
c2(exp(sc)−1−sc)−sεparenrightbigg
, (A.47)
249 Theoretical Background and Basic I nequa lities
which needs to be minimized w.r.t. s. Setting the ﬁrst derivative of the logarithm of
equation (A.47) to zero gives
nσ2
c2(cexp(sc)−c)−ε=0,
which implies that the minimum is at s=1
clnparenleftbig
1+εc
nσ2parenrightbig
. Resubstituting this value
in equation (A.47) results in the following bound
expparenleftbiggnσ2
c2parenleftBigparenleftBig
1+εc
nσ2parenrightBig
−1−lnparenleftBig
1+εc
nσ2parenrightBigparenrightBig
−ε
clnparenleftBig
1+εc
nσ2parenrightBigparenrightbigg
=expparenleftbiggε
c−nσ2
c2lnparenleftBig
1+εc
nσ2parenrightBig
−ε
clnparenleftBig
1+εc
nσ2parenrightBigparenrightbigg
=expparenleftbigg
−ε
cparenleftbiggparenleftbigg
1+nσ2
εcparenrightbigg
lnparenleftBig
1+εc
nσ2parenrightBig
−1parenrightbiggparenrightbigg
The theorem is proved.
The full power of this theorem becomes apparent if we boundparenleftbig
1+1
xparenrightbig
ln(1+x)
even further.
Theorem A.115 (Bernstein (1946)) Suppose we are given n independent random
variables X1,..., Xnsuch that for all i ∈{1,..., n},PXi(|Xi|≤c)=1and
EXibracketleftbig
Xibracketrightbig
=0. Then, for any ε> 0,
PXnparenleftBigg
1
nnsummationdisplay
i=1Xi>εparenrightBigg
<expparenleftbigg
−nε2
2σ2+cεparenrightbigg
,
whereσ2=EXbracketleftbig
X2bracketrightbig
=Va r(X).
Proof First we show that ln (1+x)≥2x/(2+x)which follows from con-
sidering the function f(x)=ln(1+x)−2x/(2+x). The function fhas the
derivative 1 /(1+x)−4/parenleftbig
(2+x)2parenrightbig
whose only positive zero is at x=0. Since
f(1)=ln(2)−2/3>0a n d f(0)=0 it follows that, for all positive x∈ /CA,
f(x)≥0⇔ ln(1+x)≥2x/(2+x).U s i n g x=εc
nσ2in Theorem A.114 shows
that, for all λ> 0,
PXnparenleftBiggnsummationdisplay
i=1Xi>λparenrightBigg
< expparenleftBigg
−λ
cparenleftBiggparenleftbigg
1+nσ2
λcparenrightbigg2λc
nσ2
2+λc
nσ2−1parenrightBiggparenrightBigg
250 Appendix A
= expparenleftBigg
−λ
cparenleftBigg2λc
nσ2+2
2+λc
nσ2−1parenrightBiggparenrightBigg
= expparenleftbigg
−2λ2c+2λnσ2
2cnσ2+λc2+λ
cparenrightbigg
= expparenleftbigg
−λ2
2nσ2+λcparenrightbigg
.
Substituting λ=nεproves the theorem.
If all we need is a bound on the probability that X1+···+ Xn=0 we can eliminate
the exponent 2 on εas opposed to Hoeffding’s and Bernstein’s inequality.
Theorem A.116 (Binomial tail bound) LetX1,..., Xnbe independent random
variables such that, for all i ∈{1,..., n},PXi(Xi=1)=1−PXi(Xi=0)=
EXibracketleftbig
Xibracketrightbig
=µ. Then, for all ε∈(0,µ),
PXnparenleftBigg
1
nnsummationdisplay
i=1Xi=0parenrightBigg
<exp(−nε).
Proof By the independence of the Xiwe have
PXnparenleftBigg
1
nnsummationdisplay
i=1Xi=0parenrightBigg
=(1−µ)n≤exp(−nµ)<exp(−nε),
where the second step follows from Theorem A.102.
Large Deviations of Functions of Random V ariables
Finally, there exists a further generalization of large deviation bounds when consid-
ering any function f: /CGn→ /CAofnrandom variables X1,..., Xn. Again, we aim
to bound the probability that f(X1,..., Xn)deviates from EXnbracketleftbig
f(X1,..., Xn)bracketrightbig
.
Before we start we need some additional quantities.
Deﬁnition A.117 (Martingale and martingale difference) A sequence of ran-
dom variables Y1,..., Ynis called a martingale w.r .t. another sequence X1,..., Xn
if for every i ∈{1,..., n},Yi=g(X1,..., Xi)is a function of X1,..., Xiand
PXiparenleftbig
EXi+1|Xi=xbracketleftbig
g((x,Xi+1))bracketrightbig
/negationslash=g(X)parenrightbig
=0.
251 Theoretical Background and Basic I nequa lities
A sequence of random variables V1,..., Vnis called a martingale difference
sequence w.r .t. another sequence X1,..., Xnif, for every i ∈{1,..., n},Vi=
g(X1,..., Xi)is a function of X1,..., Xiand
PXiparenleftbig
EXi+1|Xi=xbracketleftbig
g((x,Xi+1))bracketrightbig
/negationslash=0parenrightbig
=0.
In order to tackle this problem we use a slight modiﬁcation of equation (A.44)
already noticed in Hoeffding (1963): Whenever V1,..., Vnforms a martingale
difference sequence w.r.t. X1,..., Xnthen, for all s>0,
PXnparenleftBiggnsummationdisplay
i=1Vi>εparenrightBigg
<EXnbracketleftbigg
expparenleftbigg
snsummationtext
i=1Viparenrightbiggbracketrightbigg
exp{sε}
=nproducttext
i=1EXi|Xi−1=xbracketleftbig
exp(sVi)bracketrightbig
exp{sε}. (A.48)
However, the signiﬁcance of this simple extension was not recognized until 1989
when it triggered a revolution in certain applications (McDiarmid 1989). In thecurrent case of interest we note that
V
idef=EXn−i|Xi=(x,x)bracketleftbig
f((x,x,X))bracketrightbig
−EXn−i+1|Xi−1=xbracketleftbig
f((x,X))bracketrightbig
(A.49)
forms a martingale difference sequence w.r.t. X1,..., Xnwhich implies that all
we need is an upper bound on EXi|Xi−1=xbracketleftbig
exp(sVi)bracketrightbig
. We shall use the following
lemma.
Lemma A.118 F or any function f : /CGn→ /CAsuch that for all i ∈{1,... n}
sup
x∈ /CGn,˜x∈ /CG|f(x1,..., xn)−f(x1,..., xi−1,˜x,xi+1,... xn)|≤ci (A.50)
we know that, for all measures PX,a l l x∈ /CGi−1,a l lx∈ /CGand i∈{1,..., n},
vextendsinglevextendsingleEXn−i|Xi=(x,x)bracketleftbig
f(x,x,X)bracketrightbig
−EXn−i+1|Xi−1=xbracketleftbig
f(x,X)bracketrightbigvextendsinglevextendsingle≤|ci|.
Proof By deﬁnition we know that
vextendsinglevextendsingleEXn−i|Xi=(x,x)bracketleftbig
f(x,x,X)bracketrightbig
−EXn−i+1|Xi−1=xbracketleftbig
f(x,X)bracketrightbigvextendsinglevextendsingle
=vextendsinglevextendsingleEXn−i|Xi=(x,x)bracketleftbig
EXi+1bracketleftbig
f(x,x,X)−f(x,Xi,X)bracketrightbigbracketrightbigvextendsinglevextendsingle
252 Appendix A
≤EXn−i|Xi=(x,x)
EXi+1
|f(x,x,X)−f(x,Xi,X)|bracehtipupleft
bracehtipdownrightbracehtipdownleft
 bracehtipupright
≤|ci|

≤|ci|,
where the third line follows by the triangle inequality and from equation (A.50).
Theorem A.119 (McDiarmid’s inequality (McDiarmid 1989)) F or any function
f: /CGn→ /CAsuch that (A.50) holds we know that for all measures PX
PXnparenleftbig
f(X)−EXnbracketleftbig
f(X)bracketrightbig
>εparenrightbig
<expparenleftbigg
−ε2
2summationtextn
i=1c2
iparenrightbigg
Proof First we combine Lemma A.118 with Lemma A.111 to obtain
EXi|Xi−1=xbracketleftbig
exp(sVi)bracketrightbig
≤expparenleftbigg
−s2c2
i
2parenrightbigg
Using equation (A.48) this implies that
PXnparenleftbig
f(X)−EXnbracketleftbig
f(X)bracketrightbig
>εparenrightbig
<expparenleftbiggs2summationtextn
i=1c2
i
2−sεparenrightbigg
.
Minimizing w.r.t. sresults in s=ε/parenleftbigsummationtextn
i=1c2
iparenrightbig
. Resubstituted into the latter
expression proves the theorem.
Note that the original result in McDiarmid (1989) contains a slightly better con-stant of 2 rather than
1
2in the exponential term which is proven using the same
technique. As an example of the power of this theorem consider the simple func-tion f(x
1,..., xn)=1
nsummationtextn
i=1xiwhere xi∈[a,b]. Noticing that ci=a−b
nwe see
that Hoeffding’s inequality can easily be proven using McDiarmid’s inequality.
B Proofs and Derivations—Part I
This appendix gives all proofs and derivations of Part I in detail. If necessary the
theorems are restated before proving them. This appendix is not as self-containedas the chapters in the main body of this book; it is probably best to read it inconjunction with the corresponding chapter.
B.1 Functions of Kernels
In this section we present the proofs of Theorem 2.20 and Corollary 2.21.
Proof of Theorem 2.20. For all r∈ /C6and all sequences (x1,..., xr)∈ /CGrlet
K1,K2,K+,Kc,K+c,K∗and Kfbe the r×rmatrices whose i,j–th element is
given by k1parenleftbig
xi,xjparenrightbig
,k2parenleftbig
xi,xjparenrightbig
,k1parenleftbig
xi,xjparenrightbig
+k2parenleftbig
xi,xjparenrightbig
,c·k1parenleftbig
xi,xjparenrightbig
,k1parenleftbig
xi,xjparenrightbig
+c,
k1parenleftbig
xi,xjparenrightbig
·k2parenleftbig
xi,xjparenrightbig
and f(xi)·fparenleftbig
xjparenrightbig
, respectively. We need to show that K+,Kc,
K+c,K∗and Kfare positive semideﬁnite using only that K1and K2are positive
semideﬁnite, i.e., for all α∈ /CAr,α/primeK1α≥0a n dα/primeK2α≥0.
1.α/primeK+α=α/prime(K1+K2)α=α/primeK1α+α/primeK2α≥0.
2.α/primeKcα=c·α/primeK1α≥0.
3.α/primeK+cα=α/primeparenleftbig
K1+c11/primeparenrightbig
α=α/primeK1α+cvextenddoublevextenddouble1/primeαvextenddoublevextenddouble2≥0.
4. According to Corollary A.92 the r2×r2matrix H=K1⊗K2is positive
deﬁnite, that is, for all a∈ /CAr2,a/primeHa≥0. Given any α∈ /CAr, let us consider
a=parenleftbig
α1e/prime
1;...;αre/prime
rparenrightbig
∈ /CAr2. Then,
a/primeHa=r2summationdisplay
i=1r2summationdisplay
j=1aiajHij=rsummationdisplay
i=1rsummationdisplay
j=1αiαjHi+(i−1)r,j+(j−1)r
254 Appendix B
=rsummationdisplay
i=1rsummationdisplay
j=1αiαjk1parenleftbig
xi,xjparenrightbig
k2parenleftbig
xi,xjparenrightbig
=α/primeK∗α≥0.
5. For any function f: /CG→ /CAwe know that
α/primeKfα=rsummationdisplay
i=1rsummationdisplay
j=1αiαjf(xi)fparenleftbig
xjparenrightbig
=parenleftBiggrsummationdisplay
i=1aif(xi)parenrightBigg2
≥0.
Proof of Corollary 2.21. The ﬁrst assertion follows directly from propositions 3
and 4 of Theorem 2.20. For the proof of the second assertion note that
expparenleftbiggk1(x,˜x)
σ2parenrightbigg
=∞summationdisplay
i=01
σ2ii!ki
1(x,˜x)=1+∞summationdisplay
i=11
σ2ii!ki
1(x,˜x).
Hence, by propositions 1, 2 and 3 of Theorem 2.20 the second assertion is proved.
In order to prove the third assertion note that
expparenleftbigg
−k1(x,x)−2k1(x,˜x)+k1(˜x,˜x)
2σ2parenrightbigg
=expparenleftbigg
−k1(x,x)
2σ2parenrightbigg
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
f(x)·expparenleftbigg
−k1(˜x,˜x)
2σ2parenrightbigg
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
f(˜x)·expparenleftbiggk1(x,˜x)
σ2parenrightbigg
.
Now using propositions 4 and 5 of Theorem 2.20 and the second assertion of
this corollary proves the third assertion. The last assertion follows directly from
proposition 4 and 5 of Theorem 2.20 as
k(x,˜x)=k1(x,˜x)
radicalbig
k1(x,x)·k1(˜x,˜x)=radicalBigg
1
k1(x,x)
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
f(x)·radicalBigg
1
k1(˜x,˜x)
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
f(˜x)·k1(x,˜x).
The corollary is proved.
B.2 Efﬁcient Computation of String Kernels
In this section we prove that the recursions given in equations (2.26)–(2.27) and
(2.29)–(2.30) compute the kernel functions (2.25) and (2.28), respectively.
255 Proofs and Derivations—Part I
B.2.1 Efﬁcient Computation of the Substring Kernel
In order to compute the kernel (2.25) efﬁciently we note that, in the outer sum over
b∈/Sigma1s, it sufﬁces to consider all possible substrings of length sthat are contained
inu. Hence we can rewrite the kernel krby
kr(u,v)=rsummationdisplay
s=1|u|−s+1summationdisplay
i=1|v|−s+1summationdisplay
j=1λ2sIu[i:(i+s−1)]=v[j:(j+s−1)]
=|u|summationdisplay
i=1|v|summationdisplay
j=1λ2Iui=vj+|u|−1summationdisplay
i=1|v|−1summationdisplay
j=1λ4Iu[i:(i+1)]=v[j:(j+1)]+···
=|u|summationdisplay
i=1|v|summationdisplay
j=1λ2parenleftbig
Iui=vj+λ2parenleftbig
Iu[i:(i+1)]=v[j:(j+1)]+λ2(···)parenrightbigparenrightbig
.
The innermost nested sum can be evaluated recursively when we take advantage
of the fact that u[i:(i+s)]/negationslash=v[j:(j+s)]implies that u[i:(i+s+t)]/negationslash=
v[j:(j+s+t)]for all t∈ /C6. This proves equations (2.26)–(2.27).
B.2.2 Efﬁcient Computation of the Subsequence Kernel
The proof that the recursions given in equation (2.29)–(2.30) compute the kernel
given in equation (2.28) proceeds in two stages:
1. First, we establish that (2.30) computes
k/prime
r(u,v)=braceleftbigg1i f r=0summationtext
b∈/Sigma1rsummationtext
{i|b=u[i]}summationtext
{j|b=v[j]}λ|u|+|v|−i1−j1+2otherwise.(B.1)
2. Second, we directly show that (2.29) holds.
In order to prove equation (B.1) we analyze three cases:
1. If either|u|< ror|v|< rwe know that one of the sums in equation
(B.1) is zero because uorvcannot contain a subsequence longer than the strings
themselves. This justiﬁes the ﬁrst part of (2.30).
2. If r=0 then the second part of (2.30) is equivalent to the ﬁrst part of equation
(B.1).
3. For a given character u∈/Sigma1and a given string v∈/Sigma1∗consider Mu=
{b∈/Sigma1r|br=u}and Ju=braceleftbig
j∈{1,...,|v|}rvextendsinglevextendsinglevjr=ubracerightbig
, i.e., all subsequences
256 Appendix B
of length rsuch that the last character in bequals uand all index vectors over v
such that the last indexed character equals u. Then we know that
summationdisplay
b∈/Sigma1rsummationdisplay
{i|b=(uus)[i]}summationdisplay
{j|b=v[j]}λ|uus|+|v|−i1−j1+2
=summationdisplay
b∈Mussummationdisplay
{i|b=(uus)[i]}
summationdisplay
j∈Jusλ|uus|+|v|−i1−j1+2+summationdisplay
{j|b=v[j]}\Jusλ|uus|+|v|−i1−j1+2

+summationdisplay
b∈/Sigma1r\Mussummationdisplay
{i|b=(uus)[i]}summationdisplay
{j|b=v[j]}λ|uus|+|v|−i1−j1+2.
Now the ﬁrst term can be rewritten as
summationdisplay
b∈Mussummationdisplay
{i|b=(uus)[i]}summationdisplay
j∈Jusλ|uus|+|v|−i1−j1+2
=summationdisplay
b∈/Sigma1r−1summationdisplay
{i|b=u[i]}summationdisplay
{t|vt=us}summationdisplay
{j|b=(v[1:(t−1)])[j]}λ|uus|+|v|−i1−j1+2
=summationdisplay
{t|vt=us}λ|v|−t+2summationdisplay
b∈/Sigma1r−1summationdisplay
{i|b=u[i]}summationdisplay
{j|b=(v[1:(t−1)])[j]}λ|u|+(t−1)−i1−j1+2
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
k/prime
r−1(u,v[1:(t−1)]).
Since for all remaining subsequences b∈/Sigma1rthe last character does not match
with uswe can summarize the remaining terms by
λ·summationdisplay
b∈/Sigma1rsummationdisplay
{i|b=u[i]}summationdisplay
{j|b=v[j]}λ|u|+|v|−i1−j1+2
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
k/primer(u,v).
Thus, we have shown the third part of (2.30).
It remains to prove that (2.29) is true. Again, we analyze the two different cases:1. If either|u|< ror|v|< rwe know that one of the sums in equation
(2.28) is zero because uorvcannot contain a subsequence longer than the strings
themselves. This justiﬁes the ﬁrst part of (2.29).
2. Let M
uand Jube deﬁned as in the previous analysis. Then we know
kr(uus,v)=summationdisplay
b∈Mussummationdisplay
{i|b=(uus)[i]}summationdisplay
j∈Jusλl(i)+l(j)
257 Proofs and Derivations—Part I
+summationdisplay
b∈Mussummationdisplay
{i|b=(uus)[i]}summationdisplay
{j|b=v[j]}\Jusλl(i)+l(j)
+summationdisplay
b∈/Sigma1r\Mussummationdisplay
{i|b=(uus)[i]}summationdisplay
{j|b=v[j]}λl(i)+l(j).
Using Deﬁnition 2.24 the ﬁrst term can be written
summationdisplay
b∈Mussummationdisplay
{i|b=(uus)[i]}summationdisplay
j∈Jusλl(i)+l(j)=summationdisplay
b∈Mussummationdisplay
{i|b=(uus)[i]}summationdisplay
j∈Jusλir+jr−i1−j1+2
=summationdisplay
b∈/Sigma1r−1summationdisplay
{i|b=u[i]}summationdisplay
{t|vt=us}summationdisplay
{j|b=(v[1:(t−1)])[j]}λ|u|+1+(t−1)+1−i1−j1+2
=λ2·summationdisplay
{t|vt=us}summationdisplay
b∈/Sigma1r−1summationdisplay
{i|b=u[i]}summationdisplay
{j|b=(v[1:(t−1)])[j]}λ|u|+(t−1)+2
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
k/prime
r−1(u,v[1:(t−1)]).
Since the remaining sums run over all b∈/Sigma1rwhere bris not equal to us(or to
any symbol in vif it matches with us) they can be computed by kr(u,v).T h i s
completes the proof that the recursion given in equations (2.29)–(2.30) computes(2.28).
B.3 Representer Theorem
In this section we present the proof of Theorem 2.29 also found in Schölkopf et al.
(2001).
Proof Let us introduce the mapping /Phi1: /CG→ /BYdeﬁned by
/Phi1(x)=k(x,·).
Since kis a reproducing kernel, by equation (2.36) we know that
∀x,˜x∈ /CG:(/Phi1(x))(˜x)=k(x,˜x)=/angbracketleft/Phi1(x),/Phi1(˜x)/angbracketright. (B.2)
Now, given x=(x1,..., xm),a n y f∈ /BYcan be decomposed into a part that exists
in the span of the /Phi1(xi)and a part which is orthogonal to it,
f=msummationdisplay
i=1αi/Phi1(xi)+v
258 Appendix B
for some α∈ /CAmandv∈ /BYsatisfying that ∀xi∈x:/angbracketleftv,/Phi1(xi)/angbracketright=0. Using
equation (B.2), the application of fto any arbitrary training point xj∈xyields
fparenleftbig
xjparenrightbig
=angbracketleftBiggmsummationdisplay
i=1αi/Phi1(xi)+v,/Phi1parenleftbig
xjparenrightbigangbracketrightBigg
=msummationdisplay
i=1αiangbracketleftbig
/Phi1(xi),/Phi1parenleftbig
xjparenrightbigangbracketrightbig
=msummationdisplay
i=1αikparenleftbig
xi,xjparenrightbig
,
independent of v. Hence, the ﬁrst term in equation (2.38) is independent of v.
As for the second term, since vis orthogonal tosummationtextm
i=1αi/Phi1(xi)and gregis strictly
monotonic we get
greg(/bardblf/bardbl)= gparenleftBiggvextenddoublevextenddoublevextenddoublevextenddoublevextenddoublemsummationdisplay
i=1αi/Phi1(xi)+vvextenddoublevextenddoublevextenddoublevextenddoublevextenddoubleparenrightBigg
= g
radicaltpradicalvertexradicalvertexradicalbt
vextenddoublevextenddoublevextenddoublevextenddoublevextenddoublemsummationdisplay
i=1αi/Phi1(xi)vextenddoublevextenddoublevextenddoublevextenddoublevextenddouble2
+/bardblv/bardbl2

≥ gparenleftBiggvextenddoublevextenddoublevextenddoublevextenddoublevextenddoublemsummationdisplay
i=1αi/Phi1(xi)vextenddoublevextenddoublevextenddoublevextenddoublevextenddoubleparenrightBigg
,
with equality occurring if, and only if, v=0. Hence, setting v=0 does not affect
the ﬁrst term in equation (2.38) while strictly reducing the second term—henceany minimizer must have v=0. As a consequence, any minimizer takes the form
f=summationtext
m
i=1αi/Phi1(xi), so, using equation (B.2)
f(·)=msummationdisplay
i=1αik(xi,·).
The theorem is proved.
B.4 Convergence of the Perceptron
In this section we present the proof of Novikoff’s perceptron convergence theorem
(see Theorem 2.31) which makes extensive use of the geometry in a feature space/C3. This elegant proof is the heart of many mistake bounds for linear classiﬁers.
259 Proofs and Derivations—Part I
Proof Suppose wtis the ﬁnal solution vector after tmistakes. Then, by the
algorithm in Section D.1 on page 321 the last update step reads
wt=wt−1+yixi.
Hence the inner product with the vector w∗satisﬁes
angbracketleftbig
w∗,wtangbracketrightbig
=angbracketleftbig
w∗,wt−1angbracketrightbig
+yiangbracketleftbig
w∗,xiangbracketrightbig
≥angbracketleftbig
w∗,wt−1angbracketrightbig
+γzparenleftbig
w∗parenrightbig
≥···≥ tγzparenleftbig
w∗parenrightbig
,
where the last step follows from repeated applications up to step t=0 where by
assumption w0=0. Similarly, by deﬁnition of the algorithm,
/bardblwt/bardbl2=/bardblwt−1/bardbl2+2yi/angbracketleftwt−1,xi/angbracketrightbracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
≤0+/bardblxi/bardbl2
≤/bardblwt−1/bardbl2+ς2≤···≤ tς2.
Using the Cauchy-Schwarz inequality (see Theorem A.106) we thus have
tγzparenleftbig
w∗parenrightbig
≤angbracketleftbig
w∗,wtangbracketrightbig
≤vextenddoublevextenddoublew∗vextenddoublevextenddouble·/bardblwt/bardbl≤√
tς.
This is clearly equivalent to
t≤parenleftbiggς
γz(w∗)parenrightbigg2
.
The theorem is proved.
B.5 Convex Optimization Problems of Support V ector Machines
Here, we give a derivation of the dual optimization problems of SVMs. For the
sake of understandability we denote by Ydef=diag(y1,..., ym)the m×mdiagonal
matrix of classes ( −1a n d+1) and by Gdef=parenleftbigangbracketleftbig
xi,xjangbracketrightbigparenrightbigm,m
i,j=1the m×mGram matrix.
260 Appendix B
B.5.1 Hard Margin SVM
Consider the optimization problem given by equation (2.45). Written in terms of
the primal Lagrangian, the solution ˆwcan be expressed by1
parenleftbigˆw,ˆαparenrightbig
= argmin
w∈ /C3argmax
0≤αL(w,α),
L(w,α)=1
2/bardblw/bardbl2−msummationdisplay
i=1αiyi/angbracketleftxi,w/angbracketright+α/prime1.
Taking the derivative w.r.t. the primal variable wwe obtain
∂L(w,α)
∂wvextendsinglevextendsinglevextendsinglevextendsingle
w=ˆw=ˆw−msummationdisplay
i=1αiyixi=0⇔ˆw=msummationdisplay
i=1αiyixi.
Substitution into the primal Lagrangian yields the Wolfe dual, that is,
ˆα= argmax
0≤αW(α)
W(α)=1
2α/primeYGYα−α/primeYGYα+α/prime1=α/prime1−1
2α/primeYGYα.
B.5.2 Linear Soft Margin Loss SVM
Now consider the case involving the linear soft margin loss (see equation (2.48)).
First, let us multiply the objective function by the constant C=1
2λmwhich would
not change the solution but render the derivation much easier. Expressed in termsof the primal Lagrangian the solution ˆwcan be written as
parenleftBig
ˆw,ˆξ,ˆα,ˆβparenrightBig
= argmin
w∈ /C3,0≤ξargmax
0≤α,0≤βL(w,ξ,α,β),
L(w,ξ,α,β)=1
2/bardblw/bardbl2+Cξ/prime1−msummationdisplay
i=1αiyi/angbracketleftxi,w/angbracketright+α/prime1−α/primeξ−β/primeξ
=1
2/bardblw/bardbl2−msummationdisplay
i=1αiyi/angbracketleftxi,w/angbracketright+α/prime1+ξ/prime(C1−α−β).
1 Note that the constant positive factor of1
2does not change the minimum.
261 Proofs and Derivations—Part I
The corresponding dual is found by differentiation w.r.t. the primal variables wand
ξ,t h a ti s ,
∂L(w,ξ,α,β)
∂wvextendsinglevextendsinglevextendsinglevextendsingle
w=ˆw=ˆw−msummationdisplay
i=1αiyixi=0⇔ˆw=msummationdisplay
i=1αiyixi,
∂L(w,ξ,α,β)
∂ξvextendsinglevextendsinglevextendsinglevextendsingle
ξ=ˆξ= C1−α−β=0⇔α=C1−β. (B.3)
Substituting these stationarity conditions into the primal Lagrangian we obtain the
following dual objective function
parenleftBig
ˆα,ˆβparenrightBig
= argmax
0≤α,0≤βW(α,β),
W(α,β)=1
2α/primeYGYα−α/primeYGYα+α/prime1=α/prime1−1
2α/primeYGYα.
Sinceβ≥0, the second stationarity condition (B.3) restricts each αito be less than
or equal to C. As a consequence the ﬁnal Wolfe dual is given by
ˆα= argmax
0≤α≤C1W(α),
W(α)=α/prime1−1
2α/primeYGYα.
B.5.3 Quadratic Soft Margin Loss SVM
Consider the quadratic soft margin loss given by equation (2.49). Again, let us
multiply the objective function by the constant1
2λm. Expressed in terms of the
primal Lagrangian the solution ˆwcan be written as
parenleftBig
ˆw,ˆξ,ˆα,ˆβparenrightBig
= argmin
w∈ /C3,0≤ξargmax
0≤α,0≤βL(w,ξ,α,β),
L(w,ξ,α,β)=1
2/bardblw/bardbl2+1
2λmξ/primeξ−msummationdisplay
i=1αiyi/angbracketleftxi,w/angbracketright+α/prime1−α/primeξ−β/primeξ
=1
2/bardblw/bardbl2−msummationdisplay
i=1αiyi/angbracketleftxi,w/angbracketright+α/prime1+ξ/primeparenleftbigg1
2λmξ−α−βparenrightbigg
.
262 Appendix B
The corresponding dual is found by differentiation w.r.t. the primal variables wand
ξ,t h a ti s ,
∂L(w,ξ,α,β)
∂wvextendsinglevextendsinglevextendsinglevextendsingle
w=ˆw=ˆw−msummationdisplay
i=1αiyixi=0⇔ˆw=msummationdisplay
i=1αiyixi,
∂L(w,ξ,α,β)
∂ξvextendsinglevextendsinglevextendsinglevextendsingle
ξ=ˆξ=1
λmˆξ−α−β=0⇔ ˆξ=λm(α+β).
Substituting the stationarity conditions into the primal we obtain
parenleftBig
ˆα,ˆβparenrightBig
= argmax
0≤α,0≤βW(α,β),
W(α,β)=1
2α/primeYGYα−α/primeYGYα+α/prime1+λm(α+β)/primeparenleftbigg1
2(α+β)−α−βparenrightbigg
=1
2α/primeYGYα−α/primeYGYα+α/prime1+λm(α+β)/primeparenleftbigg
−1
2(α+β)parenrightbigg
=α/prime1−1
2α/primeYGYα−λm
2/bardblα+β/bardbl2.
Noticing that decreasing βwill always lead to an increase in W(α,β),w es i m p l y
set ˆβ=0. Hence, the ﬁnal Wolfe dual is given by
ˆα= argmax
0≤αW(α),
W(α)=α/prime1−1
2α/primeYGYα−λm
2α/primeα.
B.5.4ν–Linear Margin Loss SVM
Now consider the case involving the linear soft margin loss and the reparame-
terization by ν∈[0,1](see equation (2.52)). Expressed in terms of the primal
Lagrangian the solution w∗can be written as
parenleftBig
ˆw,ˆξ,ˆρ, ˆα,ˆβ,ˆδparenrightBig
= argmin
w∈ /C3,0≤ξ,0≤ρargmax
0≤α,0≤β,0≤δL(w,ξ,ρ,α,β,δ),
L(w,ξ,ρ,α,β,δ)=1
2/bardblw/bardbl2+ρparenleftbig
α/prime1−ν−δparenrightbig
+ξ/primeparenleftbigg1
m1−α−βparenrightbigg
−msummationdisplay
i=1αiyi/angbracketleftxi,w/angbracketright.
263 Proofs and Derivations—Part I
The corresponding dual is found by differentiation w.r.t. the primal variables w,ξ
andρ,t h a ti s ,
∂L(w,ξ,ρ,α,β,δ)
∂wvextendsinglevextendsinglevextendsinglevextendsingle
w=ˆw=ˆw−msummationdisplay
i=1αiyixi=0⇔ˆw=msummationdisplay
i=1αiyixi,
∂L(w,ξ,ρ,α,β,δ)
∂ξvextendsinglevextendsinglevextendsinglevextendsingle
ξ=ˆξ=1
m1−α−β=0⇔α=1
m1−β, (B.4)
∂L(w,ξ,ρ,α,β,δ)
∂ρvextendsinglevextendsinglevextendsinglevextendsingle
ρ=ˆρ=α/prime1−ν−δ=0⇔α/prime1=ν+δ. (B.5)
Resubstituting these stationarity conditions into the primal Lagrangian we obtain
the following dual objective function
parenleftBig
ˆα,ˆβ,ˆδparenrightBig
= argmax
0≤α,0≤β,0≤δW(α,β,δ),
W(α,β,δ)=1
2α/primeYGYα−α/primeYGYα+ˆρparenleftbig
α/prime1−ν−δparenrightbig
+ˆξ/primeparenleftbigg1
m1−α−βparenrightbigg
=−1
2α/primeYGYα.
Sinceβ≥0, the second stationarity condition (B.4) restricts each αito be less than
or equal to1
m.S i n c eδ≥0 the third stationarity condition (B.5) is equivalent to α/prime1
to be greater or equal to ν. Hence, the ﬁnal Wolfe dual is given by
ˆα= argmax
0≤α≤1
m1,α/prime1≥νW(α),
W(α)=−1
2α/primeYGYα.
B.6 Leave-One-Out Bound for Kernel Classiﬁers
Here we give the proof of Theorem 2.37. The proof is adapted from the original
proof given in Jaakkola and Haussler (1999b); we do not have to enforce convexityof the potential function Jand have dropped the assumption that α
i∈[0,1].
Proof of Theorem 2.37. The basic idea of this proof is to ﬁnd an expression of
the leave-one-out error of an algorithm using only the coefﬁcients ˆαobtained by
learning on the whole training sample. Thus we try to relate a leave-one-our error at
264 Appendix B
the tth example with the coefﬁcients obtained by joint maximization of the function
Wgiven by
W(α)=−1
2msummationdisplay
i=1msummationdisplay
j=1αiαjyiyjkparenleftbig
xi,xjparenrightbig
+msummationdisplay
i=1J(αi).
Some notational comments are in order: Subscripts on W refer to the left out
example, the subscript on αto the value of the particular component, and the
superscripts on αto the maximizer for the corresponding functions W.
Leaving out the tth example we know that the remaining α’s are obtained by
the maximization of
Wt(α)=−1
2msummationdisplay
i=1
i/negationslash=tmsummationdisplay
j=1
j/negationslash=tαiαjyiyjkparenleftbig
xi,xjparenrightbig
+msummationdisplay
i=1
i/negationslash=tJ(αi).
Let the learning algorithm /BTWresult in αt∈ /CAm, i.e.,
αt=argmax
0≤α≤uWt(α).
Naturally, αtis different from ˆαbecause the latter is jointly optimized with αtin
the objective function. In order to relate the decision function (2.54) based on αt
with the decision function (2.54) based on ˆαobtained by joint optimization we aim
to ﬁnd a function hatwideW: /CAm→ /CA
whose maximum is attained at ˆαand
which involves Wt.
In order to achieve this we construct Wfrom Wtby adding the missed summands
and ﬁxing αtto its optimal valueˆαt.T h i sg i v e s
hatwideW(α)= Wt(α)−1
2msummationdisplay
i=1
i/negationslash=tαiˆαtyiytk(xi,xt)−1
2msummationdisplay
j=1ˆαtαjytyjkparenleftbig
xt,xjparenrightbig
+Jparenleftbig
ˆαtparenrightbig
= Wt(α)−ˆαtytmsummationdisplay
i=1
i/negationslash=tαiyik(xi,xt)−1
2ˆαtˆαtk(xt,xt)+Jparenleftbig
ˆαtparenrightbig
, (B.6)
where we used the symmetry of the Mercer kernel k. Note that the last two terms
in (B.6) do not change the maximum because they only depend on the ﬁxed value
ˆαt. As a consequence we shall omit them in the following argument. Since ˆα
265 Proofs and Derivations—Part I
maximizeshatwideWwe know that
hatwideWparenleftbig
ˆαparenrightbig
≥hatwideWparenleftbig
αtparenrightbig
,
Wtparenleftbig
ˆαparenrightbig
−ˆαtytmsummationdisplay
i=1
i/negationslash=tˆαiyik(xi,xt)≥ Wtparenleftbig
αtparenrightbig
−ˆαtytmsummationdisplay
i=1
i/negationslash=tαt
iyik(xi,xt),
−ˆαtytmsummationdisplay
i=1
i/negationslash=tαt
iyik(xi,xt)≤−ˆαtytmsummationdisplay
i=1
i/negationslash=tˆαiyik(xi,xt)−parenleftbig
Wtparenleftbig
αtparenrightbig
−Wtparenleftbig
ˆαparenrightbigparenrightbig
.
As by deﬁnition αtmaximizes Wtwe have
Wtparenleftbig
αtparenrightbig
≥Wtparenleftbig
ˆαparenrightbig
⇔ Wtparenleftbig
αtparenrightbig
−Wtparenleftbig
ˆαparenrightbig
≥0,
which shows that
−ˆαtytmsummationdisplay
i=1
i/negationslash=tαt
iyik(xi,xt)≤− ˆαtytmsummationdisplay
i=1
i/negationslash=tˆαiyik(xi,xt)
−ytmsummationdisplay
i=1
i/negationslash=tαt
iyik(xi,xt)
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright/BTW((z1,..., zt−1,zt+1,..., zm))(xt)≤− ytmsummationdisplay
i=1
i/negationslash=tˆαiyik(xi,xt),
because, by assumption, ˆαtis positive. A leave-one-out error at the tth example
occurs if, and only if, the l.h.s. of the inequality is positive. This is as the bracedterm is exactly the real-valued output at x
twhen the tth example is left out during
learning. Thus the sum of step functions of the r.h.s. bounds the leave-one-out errorfrom above. The theorem is proved.
B.7 Laplace Approximation for Gaussian Processes
In this section we derive a method to compute the vector µ=parenleftbigˆt,ˆtparenrightbig
∈ /CAm+1
which maximizes the expression (3.18). As a byproduct we will also give the
explicit form of the covariance matrix /Sigma1of the Laplace approximation deﬁned in
equation (3.19). Finally, we derive a stable algorithm for computing the expansioncoefﬁcients α∈/CAmfor classiﬁcation using Gaussian processes.
266 Appendix B
B.7.1 Maximization of fTm+1|X=x,Zm=z
In order to ﬁnd the maximum of the density fTm+1|X=x,Zm=zwe use Bayes’ theorem
fTm+1|X=x,Zm=z((t,t))= fTm+1|X=x,Xm=x,Ym=y((t,t))
=PYm|Tm+1=(t,t),Xm=x,X=x(y)fTm+1|Xm=x,X=x((t,t))
PYm|Xm=x,X=x(y)
=PYm|Tm=t,Xm=x(y)fTm+1|Xm=x,X=x((t,t))
PYm|Xm=x(y),
where we use the fact that the test object x∈ /CGand its associated latent variable T
have no inﬂuence on the generation of the classes yat the training objects x.N o w ,
taking the logarithm will not change the maximum but will render optimizationmuch easier. Hence, we look for the vectorparenleftbigˆt,ˆtparenrightbig
which maximizes
J(t,t)=lnparenleftbig
P
Ym|Tm=t,Xm=x(y)parenrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
Q1(t)+lnparenleftbig
fTm+1|Xm=x,X=x((t,t))parenrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
Q2(t,t)−lnparenleftbig
PYm|Xm=x(y)parenrightbig
.
Note that the last term is a normalization constant which does not depend on
(t,t)and can thus be omitted from the optimization. Let us start by considering
the second term Q2(t,t)which effectively builds the link between Gaussian
processes for regression and for classiﬁcation. By assumption2PTm+1|Xm=x,X=x=
Normal(0,Gm+1)and thus, according to Deﬁnition A.26, this term is given by
Q2(t,t)=−1
2parenleftbigg
(m+1)ln(2π)+ln(|Gm+1|)+parenleftbig
t/prime,tparenrightbig
G−1
m+1parenleftbiggt
tparenrightbiggparenrightbigg
, (B.7)
where
Gm+1=parenleftbigg
XX/primeXx
x/primeX/primex/primexparenrightbigg
=parenleftbigg
Gm Xx
x/primeX/primex/primexparenrightbigg
and G−1
m+1=parenleftbigg
Mm
m/primeκparenrightbigg
(B.8)
are the(m+1)×(m+1)Gram matrix and its inverse of the training and test
object(s). Using Theorem A.80 for the inverse of a partitioned matrix Gm+1we
know that G−1
m+1can be written as in equation (B.8) where
M=G−1
m+1
κmm/prime, m=−κG−1
mXx,κ=parenleftbig
x/primex−x/primeX/primeG−1
mXxparenrightbig−1. (B.9)
2 For the sake of understandability we consider a regression model without any variance σ2t. Note, however,
that we can always incorporate the variance afterward s by changing the kernel according to equation (3.15) (see
Remark 3.10). This is particularly important if Gm+1is not of full rank.
267 Proofs and Derivations—Part I
Hence it follows that (B.7) can be written as
Q2(t,t)=−1
2parenleftbig
t/primeMt+2tt/primem+t2κparenrightbig
+c, (B.10)
where we summarize all terms independent of tand tinc∈ /CA. We note that Q1(t)
does not depend on tand thus, for any value of t∈ /CAm, we can analytically derive
the optimal value ˆtoftby maximizing Q2(t,·). Taking the derivative of (B.10)
w.r.t. tand setting this function to zero gives
∂Q2(t,t)
∂tvextendsinglevextendsinglevextendsinglevextendsingle
t=ˆt=2t/primem+2ˆtκ⇔ˆt=−t/primem
κ=t/primeG−1
mXx. (B.11)
Substituting this expression into (B.10) shows that this term equals
Q2(t)=−1
2parenleftbigg
t/primeMt−2
κt/primemm/primet+1
κt/primemm/primetparenrightbigg
+c=−1
2t/primeG−1
mt+c. (B.12)
Let us turn our attention to the ﬁrst term Q1(t)ofJ(t,t).I fw ed e ﬁ n e π(t)=
expparenleftbig
β−1·tparenrightbig
/parenleftbig
1+expparenleftbig
β−1·tparenrightbigparenrightbig
then the likelihood model (3.16) can be written
as
PY|T=t(y)=π(t)y+1
2(1−π(t))1−y
2,
where we use that y∈{−1,+1}. By exploiting the independence of the Yigiven
the value of Ti=tiwe can rewrite Q1(t)in the following form
Q1(t)=msummationdisplay
i=1lnparenleftbig
PYi|T=ti(yi)parenrightbig
=1
2msummationdisplay
i=1((yi+1)ln(π(ti))+(1−yi)ln(1−π(ti)))
=1
2msummationdisplay
i=1parenleftbig
(yi+1)β−1ti−2l nparenleftbig
1+expparenleftbig
β−1·tiparenrightbigparenrightbigparenrightbig
=1
2β(y+1)/primet−msummationdisplay
i=1lnparenleftbig
1+expparenleftbig
β−1·tiparenrightbigparenrightbig
. (B.13)
Combining equations (B.12) and (B.13) we obtain the following revised objective
function J(t)to be maximized over t∈ /CAm
J(t)=1
2β(y+1)/primet−msummationdisplay
i=1lnparenleftbig
1+expparenleftbig
β−1·tiparenrightbigparenrightbig
−1
2t/primeG−1
mt+c. (B.14)
268 Appendix B
A straightforward calculation reveals that the gradient vector is given by
∂J(t)
∂tvextendsinglevextendsinglevextendsinglevextendsingle
t=ˆt=1
2β(y+1)−1
βπparenleftbigˆtparenrightbig
−G−1
mˆt, (B.15)
where π(ˆt)=(π(ˆt1),...,π(ˆtm))/prime. As can be seen from this expression, due to the
termπ(ˆt), it is not possible to compute the roots ˆtof this equation in a closed form.
We use the Newton-Raphson method ,
ti+1=ti−η·H−1
ti·∂J(t)
∂tvextendsinglevextendsinglevextendsinglevextendsingle
t=ti,
where the m×m Hessian matrix Hˆtis given by
Hˆt=
∂J(t)
∂t1∂t1vextendsinglevextendsinglevextendsingle
t1=ˆt1···∂J(t)
∂t1∂tmvextendsinglevextendsinglevextendsingle
t1=ˆt1,tm=ˆtm.........
∂J(t)
∂tm∂t1vextendsinglevextendsinglevextendsingle
tm=ˆtm,t1=ˆt1···∂J(t)
∂tm∂tmvextendsinglevextendsinglevextendsingle
tm=ˆtm
=− P−G−1
m.
The diagonal matrix Pin the deﬁnition of Htis given by
P=1
β·diagparenleftbig
aparenleftbigˆt1parenrightbig
,..., aparenleftbigˆtmparenrightbigparenrightbig
, (B.16)
aparenleftbigˆtiparenrightbigdef=dπ(t)
dtvextendsinglevextendsinglevextendsinglevextendsingle
t=ˆti=1
βexpparenleftbig
β−1·ˆtiparenrightbig
parenleftbig
1+expparenleftbig
β−1·ˆtiparenrightbigparenrightbig2=1
βπparenleftbigˆtiparenrightbigparenleftbig
1−πparenleftbigˆtiparenrightbigparenrightbig
.(B.17)
Thus the update step of the Newton-Raphson method is given by
ti+1= ti+η·parenleftbig
G−1
m+Pparenrightbig−1parenleftbigg1
2β(y+1)−1
βπ(ti)−G−1
mtiparenrightbigg
,
whereη∈ /CA+has to be chosen such that J(ti+1)>J(ti). Once this procedure has
converged to ˆt∈ /CAm(which must provably happen because the negative Hessian
is always positive-deﬁnite) we can compute ˆt∈ /CAby equation (B.11).
B.7.2 Computation of /Sigma1
In order to ﬁnd the covariance matrix /Sigma1of the Laplace approximation we exploit
equations (B.10) and (B.9). A direct calculation reveals that inverse covariance
269 Proofs and Derivations—Part I
matrix /Sigma1−1is given by
/Sigma1−1=parenleftbiggM+Pm
m/primeκparenrightbigg
,
where M∈ /CAm×m,m∈ /CAmandκ∈ /CAare deﬁned in equation (B.8) and P∈ /CAm×m
is given in equation (B.16). Applying the second statement of Theorem A.80 we
can directly compute the covariance matrix /Sigma1for the Laplace approximation, i.e.,
/Sigma1=parenleftBiggparenleftbig
G−1
m+Pparenrightbig−1−κ−1parenleftbig
G−1
m+Pparenrightbig−1m
−κ−1m/primeparenleftbig
G−1
m+Pparenrightbig−1κ−1+κ−2m/primeparenleftbig
G−1
m+Pparenrightbig−1mparenrightBigg
.
This expression can be further simpliﬁed by noticing thatparenleftbig
G−1
m+Pparenrightbig−1=
(I+GmP)−1Gm. Hence, using the deﬁnitions in equation (B.8) we obtain that
−κ−1parenleftbig
G−1
m+Pparenrightbig−1m=(I+GmP)−1Xx,
κ−1+κ−2m/primeparenleftbig
G−1
m+Pparenrightbig−1m= x/primex−x/primeX/primeG−1
mXx+x/primeX/primeG−1
m(I+GmP)−1Xx
= x/primex−x/primeX/primeG−1
mparenleftbig
I−(I+GmP)−1parenrightbig
Xx
= x/primex−x/primeX/primeG−1
mparenleftbig
I−I+Gm(I+PG m)−1Pparenrightbig
Xx
= x/primex−x/primeX/prime(I+PG m)−1PXx,
where the fourth line follows from the Woodbury formula (see Theorem A.79). In
summary,
/Sigma1=parenleftbigg
(I+GmP)−1Gm (I+GmP)−1Xx
x/primeX/prime(I+GmP)−1x/primex−x/primeX/prime(I+PG m)−1PXxparenrightbigg
.
B.7.3 Stabilized Gaussian Process Classiﬁcation
If we are only concerned with the classiﬁcation of a new test object x∈ /CGwe
exploit the fact that signparenleftbigˆtparenrightbig
always equals the class y∈{−1,+1}with the larger
probability PY|X=x,Zm=z(y)(see equation (3.21) for a deﬁnition of this term). Let us
show thatˆt=0 implies PY|X=x,Zm=z(+1)=PY|X=x,Zm=z(−1)=1
2; the result fol-
lows by the monotonicity of PY|T=ta saf u n c t i o no f t. At ﬁrst we note that π(t)=
1−π(−t)whereπ(t)=PY|T=t(+1)=expparenleftbig
β−1·tparenrightbig
/parenleftbig
1+expparenleftbig
β−1·tparenrightbigparenrightbig
.U s i n g
270 Appendix B
this relation we have
PY|X=x,Zm=z(+1)=integraldisplay/CAPY|T=t(+1)bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
π(t)·1
√
2πσexpparenleftbigg
−t2
2σ2parenrightbigg
dt
=integraldisplay/CA(1−π(−t))·1
√
2πσexpparenleftbigg
−t2
2σ2parenrightbigg
dt
=integraldisplay/CAPY|T=s(−1)bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
1−π(s)·1
√
2πσexpparenleftbigg
−s2
2σ2parenrightbigg
ds
= PY|X=x,Zm=z(−1),
where the third line follows by s=− tand the assumption that ˆt=0. Since
ˆt=ˆt/primeG−1
mXx we know that the Gaussian process classiﬁcation function is given by
hGPC(x)=signparenleftBiggmsummationdisplay
i=1αi/angbracketleftxi,x/angbracketrightparenrightBigg
,α=G−1
mˆt.
In order to avoid unnecessary inversions of the Gram matrix Gm—which is an
ill-posed problem if Gmis almost singular—we shall reformulate the Newton-
Raphson method in terms of α∈ /CAmusing t=Gmα. Let the Gram matrix
Gm=parenleftbig
g/prime
1;...;g/prime
mparenrightbig
be given by its mrows g1,..., gm∈ /CAm. Then equation (B.14)
can be rewritten as
J(α)=1
2β(y+1)/primeGmα−msummationdisplay
i=1lnparenleftbig
1+expparenleftbig
β−1·g/prime
iαparenrightbigparenrightbig
−1
2α/primeGmα.
As a consequence the gradient and Hessian are given by
∂J(α)
∂αvextendsinglevextendsinglevextendsinglevextendsingle
α=α=1
2βGm(y+1)−1
βG/prime
mπ(Gmα)−Gmα,
Hα=− G/prime
mPG m−Gm=− Gm(PG m+I),
where π(Gmα)=parenleftbig
πparenleftbig
g/prime
1αparenrightbig
,...,πparenleftbig
g/prime
mαparenrightbigparenrightbig/primeand
P=1
β·diagparenleftbig
aparenleftbig
g/prime
1αparenrightbig
,..., aparenleftbig
g/prime
mαparenrightbigparenrightbig
.
271 Proofs and Derivations—Part I
The Newton-Raphson algorithm computes αi+1fromαiby
αi+1=αi+η·G−1
m(PG m+I)−1Gmparenleftbigg1
2β(y+1)−1
βπ(Gmαi)−αiparenrightbigg
=αi+η·(PG m+I)−1parenleftbigg1
βparenleftbiggy+1
2−π(Gmαi)parenrightbigg
−αiparenrightbigg
.
The adaptation of the parameter ηis done by incrementally choosing ηfrom the
sequenceparenleftbig
2−iparenrightbig
i∈ /C6. As soon as J(αi+1)≥J(αi)we update αiand re-compute P
andπ(Gmαi)making sure that inever exceeds a certain value3.
B.8 Relevance V ector Machines
In this section we derive an explicit update rule for computing the parameter vector
ˆθandˆσ2
twhich locally maximizes the evidence fTm|Xm=x(t). In order to ease the
optimization we consider the log-evidence given by
Eparenleftbig
θ,σ2
tparenrightbig
=−1
2
mln(2π)+lnparenleftbigvextendsinglevextendsingleσ2
tIm+X/Theta1X/primevextendsinglevextendsingleparenrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
Q1(θ,σ2t)+t/primeparenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1tbracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
Q2(θ,σ2t)
.
Due to its length we have divided the derivation into several parts. Afterwards,
we derive the relevance vector machine algorithm for classiﬁcation using ideasalready outlined in Section B.7. We shall compute the weight vector µ∈/CAn
which maximizes fW|Zm=ztogether with the covariance matrix /Sigma1∈ /CAn×ndeﬁned
in equation (3.27).
B.8.1 Derivative of the Evidence w.r .t. θ
As our goal is to maximize Eover the choice of θ∈ /CAnwe aim to compute the
derivative w.r.t. θ. At ﬁrst we have that
∂Eparenleftbig
θ,σ2
tparenrightbig
∂θ=−1
2parenleftBigg
∂Q1parenleftbig
θ,σ2
tparenrightbig
∂θ+∂Q2parenleftbig
θ,σ2
tparenrightbig
∂θparenrightBigg
.
3W e u s e imax=8 in our implementation.
272 Appendix B
Let us start with Q1parenleftbig
θ,σ2
tparenrightbig
. According to Theorem A.72 we know
vextendsinglevextendsingle/Theta1−1vextendsinglevextendsingle·vextendsinglevextendsingleσ2
tIm+X/Theta1X/primevextendsinglevextendsingle=vextendsinglevextendsingleσ2
tImvextendsinglevextendsingle·vextendsinglevextendsingle/Theta1−1+σ−2
tX/primeXvextendsinglevextendsingle,
which implies
Q1parenleftbig
θ,σ2
tparenrightbig
= lnparenleftbigvextendsinglevextendsingleσ2
tImvextendsinglevextendsingleparenrightbig
+lnparenleftbigvextendsinglevextendsingle/Theta1−1+σ−2
tX/primeXvextendsinglevextendsingleparenrightbig
−lnparenleftbigvextendsinglevextendsingle/Theta1−1vextendsinglevextendsingleparenrightbig
= mlnparenleftbig
σ2
tparenrightbig
+lnparenleftbigvextendsinglevextendsingle/Sigma1−1vextendsinglevextendsingleparenrightbig
+nsummationdisplay
i=1ln(θi). (B.18)
Here we use equation (3.24) for the deﬁnition of /Sigma1=parenleftbig
/Theta1−1+σ−2
tX/primeXparenrightbig−1.F o rt h e
sake of understandability we compute the derivative of Q1component-wise, that
is, we compute ∂Q1parenleftbig
θ,σ2
tparenrightbig
/∂θ j. By Theorem A.97 we know
∂Q1parenleftbig
θ,σ2
tparenrightbig
∂θ j=∂lnparenleftbigvextendsinglevextendsingle/Sigma1−1vextendsinglevextendsingleparenrightbig
∂θ j+1
θj=nsummationdisplay
r=1nsummationdisplay
s=1∂lnparenleftbigvextendsinglevextendsingle/Sigma1−1vextendsinglevextendsingleparenrightbig
∂parenleftbig
/Sigma1−1parenrightbig
rs·∂parenleftbig
/Sigma1−1parenrightbig
rs
∂θ j+1
θj
=nsummationdisplay
r=1nsummationdisplay
s=1/Sigma1rs·∂parenleftbig
/Theta1−1+σ−2
tX/primeXparenrightbig
rs
∂θ j+1
θj
=1
θj−1
θ2
j/Sigma1jj.
Now, let us consider the second term Q2parenleftbig
θ,σ2
tparenrightbig
. First, we use the Woodbury
formula (see Theorem A.79) to obtain
parenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1=σ−2
tIm−σ−4
tXparenleftbig
In+σ−2
t/Theta1X/primeXparenrightbig−1/Theta1X/prime
=σ−2
tIm−σ−4
tXparenleftbig
/Theta1parenleftbig
/Theta1−1+σ−2
tX/primeXparenrightbigparenrightbig−1/Theta1X/prime
=σ−2
tIm−σ−4
tXparenleftbig
/Theta1−1+σ−2
tX/primeXparenrightbig−1X/prime
=σ−2
tparenleftbig
Im−σ−2
tX/Sigma1X/primeparenrightbig
, (B.19)
by exploiting the deﬁnition of /Sigma1, as given in equation (3.24). Using the fact that
µ=σ−2
t/Sigma1X/primet=/Sigma1τ and the abbreviation τ=σ−2
tX/primetwe can rewrite Q2by
Q2parenleftbig
θ,σ2
tparenrightbig
= t/primeparenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1t=σ−2
tt/prime(t−Xµ)=σ−2
tt/primet−τ/primeµ.
Then the derivative of Q2w.r.t. toθjis given by
∂Q2parenleftbig
θ,σ2
tparenrightbig
∂θ j=∂parenleftbig
σ−2
tt/primet−τ/primeµparenrightbig
∂θ j=−τ/prime∂µ
∂θ j,
273 Proofs and Derivations—Part I
because µis the only term that depends on θj. Using Theorem A.96 we know
∂µ
∂θ j=∂/Sigma1τ
∂θ j=∂/Sigma1
∂θ jτ=∂parenleftbig
/Sigma1−1parenrightbig−1
∂θ jτ=−/Sigma1∂/Sigma1−1
∂θ j/Sigma1τ=−/Sigma1parenleftBigg
−1
θ2
j1jjparenrightBigg
/Sigma1τ,
where 1jj∈ /CAn×nis used to denote a matrix of zeros except for the j,j–th element
which is one. As a consequence,
∂Q2parenleftbig
θ,σ2
tparenrightbig
θj=−τ/prime∂µ
∂θ j=−τ/prime/Sigma1parenleftBigg
1
θ2
j1jjparenrightBigg
/Sigma1τ=−µ/primeparenleftBigg
1
θ2
j1jjparenrightBigg
µ=−µ2
j
θ2
j,
where we use the symmetry of /Sigma1∈ /CAn×n. Combining these results,
∂Eparenleftbig
θ,σ2
tparenrightbig
∂θ=−1
2parenleftbigg1
θ1−/Sigma111+µ2
1
θ2
1,...,1
θn−/Sigma1nn+µ2
n
θ2
nparenrightbigg/prime
. (B.20)
B.8.2 Derivative of the Evidence w.r .t. σ2
t
In order to compute the derivative w.r.t. σ2
twe again consider Q1and Q2separately.
Using Theorem A.97 we obtain
∂Q1parenleftbig
θ,σ2
tparenrightbig
∂σ2
t=∂lnparenleftbigvextendsinglevextendsingleσ2
tIm+X/Theta1X/primevextendsinglevextendsingleparenrightbig
∂σ2
t
=msummationdisplay
r=1msummationdisplay
s=1∂lnparenleftbigvextendsinglevextendsingleσ2
tIm+X/Theta1X/primevextendsinglevextendsingleparenrightbig
∂parenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig
rs·∂parenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig
rs
∂σ2
t
=msummationdisplay
r=1parenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1
rr=trparenleftBigparenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1parenrightBig
.
This expression can further be simpliﬁed exploiting equation (B.19), i.e.,
∂Q1parenleftbig
θ,σ2
tparenrightbig
∂σ2
t=trparenleftbig
σ−2
tparenleftbig
Im−σ−2
tX/Sigma1X/primeparenrightbigparenrightbig
=m·σ−2
t−σ−4
t·trparenleftbig
/Sigma1X/primeXparenrightbig
,
where we used Theorem A.74 and /Sigma1=parenleftbig
/Theta1−1+σ−2
tX/primeXparenrightbig−1as given in equation
(3.24). Finally, we see that
/Sigma1XX/prime=σ2
t/Sigma1parenleftbig
σ−2
tXX/prime+/Theta1−1−/Theta1−1parenrightbig
=σ2
tparenleftbig
In−/Sigma1/Theta1−1parenrightbig
274 Appendix B
from which it follows that
∂Q1parenleftbig
θ,σ2
tparenrightbig
∂σ2
t=m−nsummationtext
i=1parenleftBig
1−/Sigma1ii
θiparenrightBig
σ2
t.
In order to compute Q2we apply Theorem A.96 and obtain
∂Q2parenleftbig
θ,σ2
tparenrightbig
∂σ2
t=∂parenleftBig
t/primeparenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1tparenrightBig
∂σ2
t
= t/primeparenleftBig
−parenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1parenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1parenrightBig
t.
Using equation (B.19) together with µ=σ−2
t/Sigma1X/primet(see equation (3.24)) the
innermost term in the latter expression can be rewritten as
parenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1t=σ−2
tparenleftbig
Im−σ−2
tX/Sigma1X/primeparenrightbig
t=σ−2
t(t−Xµ),
w h i c ht h e nl e a d st o
∂Q2parenleftbig
θ,σ2
tparenrightbig
∂σ2
t=−parenleftBigparenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1tparenrightBig/primeparenleftBigparenleftbig
σ2
tIm+X/Theta1X/primeparenrightbig−1tparenrightBig
=−/bardblt−Xµ/bardbl2
σ4
t.
Putting both results ﬁnally gives the derivative of Ew.r.t.σ2
t
∂Eparenleftbig
θ,σ2
tparenrightbig
∂σ2
t=−1
2
σ2
tparenleftBig
m−summationtextn
i=1parenleftBig
1−/Sigma1ii
θiparenrightBigparenrightBig
−/bardblt−Xµ/bardbl2
σ4
t
. (B.21)
B.8.3 Update Algorithms for Maximizing the Evidence
Although we are able to compute the derivative of the evidence Ew.r.t. its param-
etersθandσ2
t(see equations (B.20) and (B.21)) we see that we cannot explicitly
compute their roots because the terms /Sigma1iiandµiinvolve the current solution θ
andσ2
t. However, in order to maximize the evidence (or log-evidence) w.r.t. the
parameters θ∈parenleftbig/CA+parenrightbigmandσ2
t∈ /CA+we exploit the fact that any rearrangement of
the gradient equation
∂Eparenleftbig
θ,σ2
tparenrightbig
∂θvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle
θ=ˆθ=ˆθ−gparenleftBig
ˆθparenrightBig
,
275 Proofs and Derivations—Part I
allows us to use the update rule θnew=g(θold)to compute a (local) maximum of
E, i.e., the ﬁxpoint of g: /CAn→ /CAn. A closer look at equation (B.20) shows that
θ(new)
i=/Sigma1ii+µ2
i, (B.22)
is a valid update rule. Introducing ζi=1−θ−1
i/Sigma1iiwe see that another possible
update rule is given by
θ(new)
i=µ2
i
ζi, (B.23)
which follows from (B.22) as
θi=/Sigma1ii+µ2
i,⇔θi−/Sigma1ii=µ2
i,⇔θiζi=µ2
i.
In practice it has been observed that the update rule given in equation (B.23)
leads to faster convergence although it does not beneﬁt from the guarantee of
convergence. According to equation (B.21) we see that
parenleftbig
σ2
tparenrightbig(new)=/bardblt−Xµ/bardbl2
m−summationtextn
i=1ζi,
is an update rule which has shown excellent convergence properties in our experi-
ments.
B.8.4 Computing the Log-Evidence
In the relevance vector machine algorithm it is necessary to compute the log-evidence Eparenleftbig
θ,σ
2
tparenrightbig
to monitor convergence. The crucial quantity for the compu-
tation of this quantity is the covariance matrix /Sigma1∈ /CAn×nand its inverse /Sigma1−1.I n
order to save computational time we use equation (B.18) to efﬁciently compute
Q1parenleftbig
θ,σ2
tparenrightbig
,
Q1parenleftbig
θ,σ2
tparenrightbig
=mlnparenleftbig
σ2
tparenrightbig
+lnparenleftbigvextendsinglevextendsingle/Sigma1−1vextendsinglevextendsingleparenrightbig
+nsummationdisplay
i=1ln(θi).
Since we already need to compute /bardblt−Xµ/bardbl2andµin each update step it is
advantageous to rewrite the expression Q2parenleftbig
θ,σ2
tparenrightbig
by
Q2parenleftbig
θ,σ2
tparenrightbig
=σ−2
tt/prime(t−Xµ)
=σ−2
t/bardblt−Xµ/bardbl2+σ−2
tt/primeXµ−σ−2
tµ/primeX/primeXµ
276 Appendix B
=σ−2
t/bardblt−Xµ/bardbl2+µ/prime/Sigma1−1µ−σ−2
tµ/primeX/primeXµ
=σ−2
t/bardblt−Xµ/bardbl2+µ/prime/Theta1−1µ,
w h e r ew eu s e µ=σ−2/Sigma1X/primetand/Sigma1=parenleftbig
/Theta1−1+σ−2
tX/primeXparenrightbig−1⇔/Theta1−1=
/Sigma1−1−σ−2
tX/primeXas given by equation (3.24).
B.8.5 Maximization of fW|Zm=z
In order to ﬁnd the maximum µ∈ /CAnof the density fW|Zm=zwe use Bayes’ theorem
fW|Zm=z(w)=fW|Xm=x,Ym=y(w)=PYm|W=w,Xm=x(y)fW(w)
PYm|Xm=x(y),
where we exploit the fact that fW|Xm=x=fWas objects have no inﬂuence on weight
vectors. Taking logarithms and dropping all terms which do not depend on wwe
end up looking for the maximizer µ∈ /CAnof
J(w)=lnparenleftbig
PYm|W=w,Xm=x(y)parenrightbig
+lnparenleftbig
fW(w)parenrightbig
.
According to Section B.7 we know that the ﬁrst term is given by1
2β(y+1)/primet−summationtextm
i=1lnparenleftbig
1+expparenleftbig
β−1·tiparenrightbigparenrightbig
where t∈ /CAmis the vector of latent activations at
the mtraining objects x. By deﬁnition, however, t=Xw which completes the
deﬁnition of the ﬁrst term. For the second term we know that PW=Normal(0,/Theta1).
Hence, representing X=parenleftbig
x/prime
1;...;x/prime
mparenrightbig
∈ /CAm×nby its mrows x/prime
iyields
J(w)=1
2β(y+1)/primeXw−msummationdisplay
i=1lnparenleftbig
1+expparenleftbig
β−1·x/prime
iwparenrightbigparenrightbig
−1
2w/prime/Theta1−1w+c,
where c=−1
2(m·ln(2π)+|/Theta1|)does not depend on w. Taking the derivative
w.r.t. wwe obtain
∂J(w)
∂wvextendsinglevextendsinglevextendsinglevextendsingle
w=w=1
2βX/prime(y+1)−1
βX/primeπ(Xw)−/Theta1−1w, (B.24)
where π(t)=(π(t1),...,π(tm))/prime∈ /CAmand the function π: /CA→ [0,1]deﬁned
byπ(t)=expparenleftbig
β−1·tparenrightbig
/parenleftbig
1+expparenleftbig
β−1·tparenrightbigparenrightbig
is known as the sigmoid resulting
from the likelihood model (3.16). Clearly, we cannot compute the root(s) of thisgradient equation due to the non-linear term π(Xw). Let us use the Newton-
Raphson method to ﬁnd a local maximum µiteratively. To this end we have to
compute the Hessian H
w,t h a ti s ,t h e n×nmatrix of second derivatives of J
277 Proofs and Derivations—Part I
evaluated at w. Using equation (B.24), the Hessian Hwis given by
Hw=− X/primePX−/Theta1−1,
where P∈ /CAm×mis a diagonal matrix
P=1
β2·diagparenleftbig
πparenleftbig
x/prime
1wparenrightbigparenleftbig
1−πparenleftbig
x/prime
1wparenrightbigparenrightbig
,...,πparenleftbig
x/prime
mwparenrightbigparenleftbig
1−πparenleftbig
x/prime
mwparenrightbigparenrightbigparenrightbig
.
As a consequence, the Newton-Raphson algorithm performs the following update
wi+1= wi−η·H−1
wi∂J(w)
∂wvextendsinglevextendsinglevextendsinglevextendsingle
w=wi
= wi+ηparenleftbig
X/primePX+/Theta1−1parenrightbig−1parenleftbigg1
βX/primeparenleftbiggy+1
2−π(Xw)parenrightbigg
−/Theta1−1wparenrightbigg
.
The parameter η∈ /CA+is chosen from the sequenceparenleftbig
2−iparenrightbig
i∈ /C6in such a way that
J(wi+1)>J(wi). After convergence of this update rule (which must converge
because the negative Hessian is positive deﬁnite) the solution wiis provably the
maximizer µ∈ /CAnoffW|Zm=z. Note that that the inverse of the negated Hessian Hµ
evaluated at the ﬁnal solution µis the covariance matrix /Sigma1deﬁned in (3.27). We
shall need this matrix to perform one update step on the (so far ﬁxed) parameter θ.
B.9 A Derivation of the Operation ⊕µ
Let us derive the operation ⊕µ: /CF× /CF→ /CFacting on vectors of unit length.
This function has to have the following properties (see Section 3.4.1)
vextenddoublevextenddoubles⊕µtvextenddoublevextenddouble2= 1, (B.25)vextenddoublevextenddoublet−s⊕µtvextenddoublevextenddouble=µ/bardblt−s/bardbl, (B.26)
s⊕µt=ρ1s+ρ2t, (B.27)
ρ1≥0,ρ 2≥0. (B.28)
Here we assume that /bardbls/bardbl2=/bardblt/bardbl2=1. Inserting equation (B.27) into (B.25) gives
/bardblρ1s+ρ2t/bardbl2=ρ2
1+ρ2
2+2ρ1ρ2/angbracketlefts,t/angbracketright=1. (B.29)
In a similar fashion combining equations (B.27) and (B.26) gives
vextenddoublevextenddoublet−s⊕µtvextenddoublevextenddouble2=µ2/bardblt−s/bardbl2
278 Appendix B
/bardbl(1−ρ2)t−ρ1s/bardbl2=µ2/bardblt−s/bardbl2
(1−ρ2)(1−ρ2−2ρ1/angbracketlefts,t/angbracketright)+ρ2
1= 2µ2(1−/angbracketlefts,t/angbracketright). (B.30)
Note that equation (B.29) is quadratic in ρ2and has the following solution
ρ2=−ρ1/angbracketlefts,t/angbracketright±radicalBig
ρ2
1(/angbracketlefts,t/angbracketright)2−ρ2
1+1
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
A. (B.31)
Let us substitute equation (B.31) into the l.h.s. of equation (B.30). This gives the
following quadratic equation in ρ1
(1−A+ρ1/angbracketlefts,t/angbracketright)(1−A−ρ1/angbracketlefts,t/angbracketright)+ρ2
1= 2µ2(1−/angbracketlefts,t/angbracketright)
(1−A)2−ρ2
1(/angbracketlefts,t/angbracketright)2+ρ2
1= 2µ2(1−/angbracketlefts,t/angbracketright)
1−A=µ2(1−/angbracketlefts,t/angbracketright)
ρ2
1parenleftbig
(/angbracketlefts,t/angbracketright)2−1parenrightbig
+1=parenleftbig
µ2(1−/angbracketlefts,t/angbracketright)−1parenrightbig2, (B.32)
whose solution is given by
ρ1=µradicalBigg
−µ2−µ2/angbracketlefts,t/angbracketright−2
/angbracketlefts,t/angbracketright+1.
Inserting this formula back into equation (B.31), and making use of the identity
(B.32), we obtain for ρ2
ρ2=−ρ1/angbracketlefts,t/angbracketright±radicalBig
ρ2
1parenleftbig
(/angbracketlefts,t/angbracketright)2−1parenrightbig
+1=−ρ1/angbracketlefts,t/angbracketright±parenleftbig
µ2(1−/angbracketlefts,t/angbracketright)−1parenrightbig
.
B.10 Fisher Linear Discriminant
Given a training sample z=(x,y)∈ /CIm, let us compute the maximum likelihood
estimates ˆµyand ˆ/Sigma1of the mean vector µy∈ /CAnand the covariance /Sigma1∈ /CAn×nof
ann-dimensional Gaussian measure, respectively. Let us assume that PY(+1)=
PY(−1)=1
2. Then the logarithm of the likelihood can be written as
Lparenleftbig
µy,/Sigma1parenrightbig
= lnparenleftBiggmproductdisplay
i=1(2π)−n
2|/Sigma1|−1
2expparenleftbigg
−1
2parenleftbig
xi−µyiparenrightbig/prime/Sigma1−1parenleftbig
xi−µyiparenrightbigparenrightbiggparenrightBigg
,
279 Proofs and Derivations—Part I
=−msummationdisplay
i=11
2parenleftBig
nln(2π)+ln(|/Sigma1|)+parenleftbig
xi−µyiparenrightbig/prime/Sigma1−1parenleftbig
xi−µyiparenrightbigparenrightBig
.
Let us start with the maximizer w.r.t. the mean vectors µy. Setting the derivative to
zero we obtain, for both classes y∈{−1,+1},
∂Lparenleftbig
µy,/Sigma1parenrightbig
∂µyvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle
µy=ˆµy=summationdisplay
(xi,y)∈zparenleftbig
/Sigma1−1xi−/Sigma1−1ˆµyparenrightbig
=0,
ˆµy=1
mysummationdisplay
(xi,y)∈zxi, (B.33)
where myequals the number of samples of class yinz∈ /CIm. Further, according
to Theorems A.97 and A.98 we know
∂Lparenleftbig
µy,/Sigma1parenrightbig
∂/Sigma1vextendsinglevextendsinglevextendsinglevextendsinglevextendsingle
/Sigma1=ˆ/Sigma1=−1
2msummationdisplay
i=1parenleftBig
ˆ/Sigma1−1−ˆ/Sigma1−1parenleftbig
xi−µyiparenrightbigparenleftbig
xi−µyiparenrightbig/primeˆ/Sigma1−1parenrightBig
=0,
mˆ/Sigma1−1= ˆ/Sigma1−1parenleftBiggmsummationdisplay
i=1parenleftbig
xi−µyiparenrightbigparenleftbig
xi−µyiparenrightbig/primeparenrightBigg
ˆ/Sigma1−1
ˆ/Sigma1=1
msummationdisplay
y∈{−1,+1}summationdisplay
(xi,y)∈zparenleftbig
xi−µyparenrightbigparenleftbig
xi−µyparenrightbig/prime.
If we substitute ˆµyas given in equation (B.33) for µywe obtain
ˆ/Sigma1=1
mparenleftBiggsummationdisplay
y∈{−1,+1}summationdisplay
(xi,y)∈zparenleftbig
xi−ˆµyparenrightbigparenleftbig
xi−ˆµyparenrightbig/primeparenrightBigg
=1
mparenleftBiggmsummationdisplay
i=1xix/prime
i−summationdisplay
y∈{−1,+1}parenleftBigg
2summationdisplay
(xi,y)∈zxiˆµ/prime
y−myˆµyˆµ/prime
yparenrightBiggparenrightBigg
=1
mparenleftBigg
X/primeX−summationdisplay
y∈{−1,+1}myˆµyˆµ/prime
yparenrightBigg
.
C Proofs and Derivations—Part II
This appendix gives all proofs and derivations of Part II in detail. If necessary the
theorems are restated before proving them. This appendix is not as self-containedas the chapters in the main body of this book; it is probably best to read it inconjunction with the corresponding chapter.
C.1 VC and PAC Generalization Error Bounds
In this section we present the proof of Theorem 4.7. It involves several lemmaswhich will also be of importance in other sections of this book. We shall thereforestart by proving these lemmas before proceeding to the ﬁnal proof. The version of
the proof presented closely follows the original paper V apnik and Chervonenkis
(1971) and its polished version, found in Anthony and Bartlett (1999).
C.1.1 Basic Lemmas
In this section we prove three basic lemmas —the key ingredients required to obtain
bounds on the generalization error in the VC, PAC and luckiness frameworks. Theoriginal proof of Lemma C.1 is due to V apnik and Chervonenkis (1971). We shallpresent a simpliﬁed version of the proof, as found in Devroye et al. (1996, p. 193).The proof of Lemma C.3 is the solution to Problem 12.7 in Devroye et al. (1996,
p. 209) and is only a special case of Lemma C.2 which uses essentially the same
technique as the proof of Lemma C.1. In order to enhance readability we shall use
the shorthand notation z
[i:j]def=parenleftbig
zi,..., zjparenrightbig
.
282 Appendix C/BO
Ꜽ
/BE/BQ Ꜽ/C8/CI
/B4 /BT /B4 /DE /B5/B5 /DA/DI /DE
/B4 /BT /B4 /DE /B5/B5 /DA/DE
/B4 /BT /B4 /DE /B5/B5
Figure C.1 Graphical illustration of the main step in the basic lemma. If vz(A(z))
deviates from PZ(A(z))by at least εbutv˜z(A(z))isε
2-close to PZ(A(z))then vz(A(z))
and v˜z(A(z))deviate by at leastε
2.
Lemma C.1 (VC basic lemma) F or all probability measures PZand all subsets /BT
of theσ–algebra /CIover the sample space /CI,i fmε2>2we have
PZmparenleftbigg
sup
A∈ /BT|P(A)−vZ(A)|>εparenrightbigg
<2PZ2mparenleftbigg
sup
A∈ /BTvextendsinglevextendsinglevZ[1:m](A)−vZ[(m+1):2m](A)vextendsinglevextendsingle>ε
2parenrightbigg
.
Proof Given a sample z∈ /CIm,l e t A(z)∈ /BTbe given by
A(z)=argsup
A∈ /BT|PZ(A)−vz(A)|.
Clearly, whenever for z,˜z∈ /CIm
(|vz(A(z))−PZ(A(z))|>ε)bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
Q1(z)∧parenleftBig
|v˜z(A(z))−PZ(A(z))|<ε
2parenrightBig
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
Q2(z˜z)
it follows that the proposition
Q3parenleftbig
z˜zparenrightbig
≡|vz(A(z))−v˜z(A(z))|>ε
2
is true as well (see also Figure C.1). Henceforth, we know that
PZ2m(Q3(Z))≥ PZ2mparenleftbig
Q1parenleftbig
Z[1:m]parenrightbig
∧Q2(Z)parenrightbig
= EZm
1bracketleftbig
IQ1(Z1)PZm
2|Zm
1=z1(Q2(z1Z2))bracketrightbig
.
Now, PZm
2|Zm
1=z1(Q2(z1Z2))is the probability that the mean of mrandom vari-
ables, taking values in {0,1}, does not exceed a distance ofε
2from their com-
mon expectation PZ(A(z1)). The variance of such a random variable is given
byPZ(A(z1))(1−PZ(A(z1)))
m≤1
4mand thus, by Chebyshev’s inequality (see Theorem
A.110) and the assumed independence of Z2from Z1, it follows that
PZm
2|Zm
1=z1(Q2(z1Z2))≥1−PZ(A(z1))(1−PZ(A(z1)))
mparenleftbigε
2parenrightbig2≥1−1
mε2>1
2,
283 Proofs and Derivations—Part II
where the last inequality follows from mε2>2 by assumption. Furthermore, we
know that whenever Q3(z)holds supA∈ /BT|vz(A)−v˜z(A)|>ε
2because A(z1)∈/BT. In summary
PZ2mparenleftbigg
sup
A∈ /BTvextendsinglevextendsinglevZ[1:m](A)−vZ[(m+1):2m](A)vextendsinglevextendsingle>ε
2parenrightbigg
>1
2PZm(Q1(Z))
=1
2PZmparenleftbigg
sup
A∈ /BT|PZ(A)−vZ(A)|>εparenrightbigg
.
The lemma is proved.
Lemma C.2 (Luckiness basic lemma) F or all probability measures PZ,a l lm e a -
surable logical formulas ϒ:uniontext∞
m=1
/CIm→{true,false}and all subsets /BTof the
σ–algebra /CIover the sample space /CI,i fmε> 2we have
PZm(∃A∈ /BT:(ϒ(Z))∧(vZ(A)=0)∧(PZ(A)>ε))<
2PZ2mparenleftBig
∃A∈ /BT:parenleftbig
ϒparenleftbig
Z[1:m]parenrightbigparenrightbig
∧parenleftbig
vZ[1:m](A)=0parenrightbig
∧parenleftBig
vZ[(m+1):2m](A)>ε
2parenrightBigparenrightBig
.
Proof Given a sample z∈ /CIm,l e t A(z)∈ /BTbe such that PZ(A(z))>
ε(z)∧vz(A(z))=0 if such a set exists or any set A∈ /BTotherwise. For any
z,˜z∈ /CImlet us deﬁne
Q1parenleftbig
z˜zparenrightbig
≡ v˜z(A(z))≥ε
2, Q2(z)≡(ϒ(z))∧(vz(A(z))=0),
Q3(z)≡ PZ(A(z))>ε.
First, it holds that
PZ2mparenleftbig
Q1(Z)∧Q2parenleftbig
Z[1:m]parenrightbigparenrightbig
≥ PZ2mparenleftbig
Q1(Z)∧Q2parenleftbig
Z[1:m]parenrightbig
∧Q3parenleftbig
Z[1:m]parenrightbigparenrightbig
= EZm
1bracketleftbig
IQ2(Z1)∧Q3(Z1)PZm
2|Zm
1=z1(Q1(z1Z2))bracketrightbig
.
By the indicator event we know that PZ(A(z1))>ε whenever we need to evaluate
PZm
2|Zm
1=z1(Q1(z1Z2))which is the probability that a binomially distributed vari-
able with expectation greater than εexceeds a value ofmε
2>1 as by assumption
of the theorem mε> 2 and the sample Z2is assumed to be independent of Z1.B y
the binomial tail bound (see Theorem A.116) this probability is lower bounded by
PZm
2|Zm
1=z1(Q1(z1Z2))≥1−exp(−mε)>1−exp(−2)>1
2,
284 Appendix C
where we have used the assumption mε> 2 of the theorem again. In summary
PZ2mparenleftBig
∃A∈ /BT:parenleftbig
ϒparenleftbig
Z[1:m]parenrightbigparenrightbig
∧parenleftbig
vZ[1:m](A)=0parenrightbig
∧parenleftBig
vZ[(m+1):2m](A)>ε
2parenrightBigparenrightBig
≥PZm
1Zm2parenleftbig
Q1(Z)∧Q2parenleftbig
Z[1:m]parenrightbigparenrightbig
>1
2PZm(Q2(Z)∧Q3(Z))
=1
2PZm(∃A∈ /BT:(ϒ(Z))∧(vZ(A)=0)∧(PZ(A)>ε)).
The lemma is proved.
Lemma C.3 (PAC basic lemma) F or all probability measures PZand all subsets/BTof theσ–algebra /CIover the sample space /CI,i fmε> 2we have
PZm(∃A∈ /BT:(vZ(A)=0)∧(PZ(A)>ε))
<2PZ2mparenleftBig
∃A∈ /BT:parenleftbig
vZ[1:m](A)=0parenrightbig
∧parenleftBig
vZ[(m+1):2m](A)>ε
2parenrightBigparenrightBig
.
Proof Usingϒ(z)=true in Lemma C.2 proves the assertion.
C.1.2 Proof of Theorem 4.7
Proof Let us start by proving equation (4.11). First, we note that, due to Lemma
C.1, it sufﬁces to bound the probability1
PZ2mparenleftBig
∃h∈ /C0:vextendsinglevextendsingleRempbracketleftbig
h,(Z1,..., Zm)bracketrightbig
−Rempbracketleftbig
h,(Zm+1,..., Z2m)bracketrightbigvextendsinglevextendsingle>ε
2parenrightBig
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
J(Z).
Since all 2 msamples Ziare drawn iid from PZwe know that, for any permutation
π:{1,..., 2m}→{1,..., 2m},
PZ2m(J(Z))=PZ2m(J(/Pi1(Z))),
where we use the shorthand notation /Pi1(Z)to denote the action of πon the
indices of Z=(Z1,..., Z2m), i.e.,/Pi1((Z1,..., Z2m))def=parenleftbig
Zπ(1),..., Zπ(2m)parenrightbig
.N o w
consider all 2mdifferent swapping permutations /Pi1sindexed by s∈{0,1}m, i.e.,
/Pi1s(z)swaps ziand zi+mif, and only if, si=1. Using the uniform measure PSm
1 Note that in due course of the proof we use the symbol z(and Z) to refer to a (random) training sample (drawn
iid from PZ)o fs i z e2 m.
285 Proofs and Derivations—Part II
where PS(0)=PS(1)=1
2we get
PZ2m(J(Z))=ESmbracketleftbig
PZ2m|Sm=s(J(/Pi1s(Z)))bracketrightbig
=EZ2mbracketleftbig
PSm|Z2m=z(J(/Pi1S(z)))bracketrightbig
,
Note that PZ2mSm=PZ2mPSm, hence the two measures are independent so that
PSm|Z2m=z=PSm. The advantage of this formulation is that we only need to ﬁnd
the probability of J(/Pi1S(z))over the random choice of permutations Sfor a ﬁxed
double sample z∈ /CI2m. Since the double sample zis ﬁxed, it follows that the
number of hypotheses hconsidered in J(/Pi1s(z))must effectively be ﬁnite because,
regardless of the permutation /Pi1s, any two hypotheses h∈ /C0and˜h∈ /C0with the
property
∀i∈{1,..., 2m}: h(xi)=˜h(xi)
lead to the same difference in training errors on (z1,..., zm)and(zm+1,..., z2m).
Thus, let /C6/C0(z)∈ /C6be the number of equivalence classes w.r.t. the zero-one loss/C6/C0(z)def=vextendsinglevextendsinglebraceleftbigparenleftbig
l0−1(h(x1),y1),... l0−1parenleftbig
hparenleftbig
x|z|parenrightbig
,y|z|parenrightbigparenrightbig|h∈ /C0bracerightbigvextendsinglevextendsingle≤2|z|,
and letˆh1,...,ˆh/C6/C0(z)∈ /C0be the corresponding hypotheses realizing the /C6/C0(z)
different loss patterns. By the union bound it follows that PSm|Z2m=z(J(/Pi1S(z)))
is less than or equal to/C6/C0(z)summationdisplay
i=1PSm|Z2m=zparenleftBiggvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle1
mmsummationdisplay
j=1IˆhiparenleftBig
xπS(j)parenrightBig
/negationslash=yπS(j)−1
mmsummationdisplay
j=1IˆhiparenleftBig
xπS(j+m)parenrightBig
/negationslash=yπS(j+m)vextendsinglevextendsinglevextendsinglevextendsinglevextendsingle>ε
2parenrightBigg
=
/C6/C0(z)summationdisplay
i=1PSm|Z2m=zparenleftBiggvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle1
mmsummationdisplay
j=1parenleftbigg
IˆhiparenleftBig
xπS(j)parenrightBig
/negationslash=yπS(j)−IˆhiparenleftBig
xπS(j+m)parenrightBig
/negationslash=yπS(j+m)parenrightbiggvextendsinglevextendsinglevextendsinglevextendsinglevextendsingle>ε
2parenrightBigg
,
where we used the deﬁnition of Remp [h,(z1,..., zm)]given in equation (22) and
z=((x1,y1),...,(x2m,y2m)). Since we consider the uniform measure over swap-
pings we know that each summand over j∈{1,..., m}is a uniformly dis-
tributed random variable with outcomes ±vextendsinglevextendsinglevextendsinglevextendsingleIˆhiparenleftBig
xπS(j)parenrightBig
/negationslash=yπS(j)−IˆhiparenleftBig
xπS(j+m)parenrightBig
/negationslash=yπS(j+m)vextendsinglevextendsinglevextendsinglevextendsingle.
As a consequence these random variables are always in the interval [−1,+1]with
expectation zero. Thus, a direct application of Hoeffding’s inequality (see TheoremA.112) yields
P
Z2m(J(Z))<EZ2mparenleftBigg/C6/C0(Z)summationdisplay
i=12e x pparenleftbigg
−mε2
8parenrightbiggparenrightBigg
=EZ2mbracketleftbig/C6/C0(Z)bracketrightbig
·2e x pparenleftbigg
−mε2
8parenrightbigg
.
286 Appendix C/DE/BD
/DE/BE
/DE/BF
/DE/BG
/DE/BH/DE/BH/B7/BD
/DE/BH/B7/BE
/DE/BH/B7/BF
/DE/BH/B7/BG
/DE/BH/B7/BH
/DE/BD
/DE/BF
/DE/BG
/DE/BH/DE/BH/B7/BD
/DE/BH/B7/BF
/DE/BH/B7/BG
/DE/BH/B7/BH
/DE/BH/B7/BE/DE/BE
Figure C.2 Counting swappings that ensure Remp[ˆhi,(z1,..., zm)]= 0 while
Remp[ˆhi,(zm+1,..., z2m)]>ε whereˆhi∈ /C0. Each example zj∈(zm+1,..., z2m)where
l0−1(ˆhi(xj),yj)=1 is shown as a gray cell. W e used m=5a n dε=2
m.(Left) Clearly,
whenever z6,z8orz10is swapped the training error in the ﬁrst half remains zero. (Right)
If we swap z7orz9into the ﬁrst half we will violate the zero training error condition and
therefore must not swap them.
Using the worst case quantity /C6/C0(2m)def=max z∈ /CI2m /C6/C0(z)completes the proof
of assertion (4.11).
The second equation (4.12) is proven in a similar way. First, according to
Lemma C.3 all we need to bound is the probability
PZ2mparenleftBig
∃h∈ /C0:Rempbracketleftbig
h,(Z1,..., Zm)bracketrightbig
=0∧Rempbracketleftbig
h,(Zm+1,..., Z2m)bracketrightbig
>ε
2parenrightBig
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
J(Z).
If we again consider all 2mswapping permutations πswe see that this probability
equals
EZ2mbracketleftBigg/C6/C0(Z)summationdisplay
i=1PSm|Z2m=zparenleftBig
QzparenleftBig
ˆhiparenrightBigparenrightBigbracketrightBigg
,
where the event QzparenleftBig
ˆhiparenrightBig
⊆{0,1}mis the set of all swappings such that ˆhiincurs
no training errors on the ﬁrst msamples(z1,..., zm)but at leastmε
2training errors
on the second msamples(zm+1,..., z2m), i.e.,
QzparenleftBig
ˆhiparenrightBig
=braceleftBigg
svextendsinglevextendsinglevextendsinglevextendsinglevextendsingleparenleftBiggmsummationdisplay
j=1Iˆhi(xπs(j))=yπs(j)=0parenrightBigg
∧parenleftBiggmsummationdisplay
j=1Iˆhi(xπs(j+m))/negationslash=yπs(j+m)>mε
2parenrightBiggbracerightBigg
.
Here, the set ˆh1,...ˆh/C6/C0(z)∈ /C0are again /C6/C0(z)different hypotheses w.r.t. the
training errors on z=(z1,..., z2m). In contrast to the previous case, the cardinality
ofQzparenleftBig
ˆhiparenrightBig
is easily upper bounded by 2m−mε
2because, whenever we swap any of
287 Proofs and Derivations—Part II
the at leastmε
2patternsparenleftbig
xj+m,yj+mparenrightbig
that incur a loss on the second msamples, we
violate the assumption of zero training error on the ﬁrst msamples (see also Figure
C.2). Since we use the uniform measure PSmit follows that
PZ2m(J(Z))≤EZ2mbracketleftBigg/C6/C0(Z)summationdisplay
i=12−m·2m−mε
2bracketrightBigg
=EZ2mbracketleftbig/C6/C0(Z)bracketrightbig
·2−mε
2.
Bounding the expectation EZ2mbracketleftbig/C6/C0(Z)bracketrightbig
by its maximum /C6/C0(2m)from above
and using 2−x=exp(−x·ln(2))≤expparenleftbig
−x
2parenrightbig
for all x≥0 proves equation
(4.12).
C.2 Bound on the Growth Function
In this section we prove Theorem 4.10 using proof by contradiction. This elegantproof is due to E. Sontag and is taken from Sontag (1998). At ﬁrst let us introducethe function /Phi1:/C6× /C6→ /C6deﬁned by
/Phi1(m,ϑ)def=ϑsummationdisplay
i=0parenleftbiggm
iparenrightbigg
.
Deﬁningparenleftbigm
iparenrightbig
=0 whenever i>mwe see that /Phi1(m,ϑ)=2mifϑ≥mbecause
by Theorem A.103,
/Phi1(m,m)=msummationdisplay
i=0parenleftbiggm
iparenrightbigg
=msummationdisplay
i=0parenleftbiggm
iparenrightbigg
·1i=(1+1)m=2m. (C.1)
Let us start with a central lemma which essentially forms the heart of the proof.
Lemma C.4 Let m∈ /C6,ϑ∈{0,..., m}and r>/Phi1(m,ϑ), and suppose that the
matrix A∈{0,1}m×ris such that all its r columns are distinct. Then, there is some
(ϑ+1)×2ϑ+1sub-matrix of Awhose 2ϑ+1columns are distinct.
Proof We proceed by induction over m∈ /C6. Note that the lemma is trivially true
forϑ=mbecause, according to equation (C.1), /Phi1(m,m)=2m. But, each binary
matrix with mrows has at most 2mdistinct columns; hence there exists no value
ofr. Let us start by proving the assertion for m=1: We have just shown that
we only need to consider ϑ=0. Then, the only possible value of ris 2 because
/Phi1(1,0)=1. For this value, however, the only (ϑ+1)×2ϑ+1=1×2 sub-matrix
288 Appendix C
of the m×r=1×2 matrix AisAitself which by assumption has 2 distinct
columns.
We next assume the result is true for m−1 and prove it for m. Let us consider
any matrix A∈{0,1}m×rwith r>/Phi1(m,ϑ)distinct columns. By interchanging
columns, this matrix can always be transfered into the form

0···01···1∗···∗
 B

 B

 C

,
where Band Care(m−1)×r1and(m−1)×(r−2r1)matrices, respectively,
and “∗” is a placeholder for either 0 or 1. Let us consider two matrices Band Cfor
the largest value of r1(number of columns of B). Then, by assumption, all r−r1
columns ofparenleftbigBCparenrightbig
must be distinct because
IfBwere to have two equal columns or Band Cwere to have a column
in common then Awould contain two equals columns which contradicts the
assumption.
IfCwere to have two equal columns then the corresponding ﬁrst entries in A
must be different and this contradicts the maximal choice of r1.
Bearing in mind that we only need to show the lemma for ϑ∈{0,..., m−1}we
now distinguish two cases:
1.r−r1>/Phi1(m−1,ϑ): In this case the inductive assumption applies toparenleftbigBCparenrightbig
, i.e., this (m−1)×(r−r1)matrix already contains a (ϑ+1)×2ϑ+1
sub-matrix as desired to hold for A.
2.r−r1≤/Phi1(m−1,ϑ): In this case the inductive assumption applies to B
because r1=r−(r−r1)>/Phi1(m,ϑ)−/Phi1(m−1,ϑ)=/Phi1(m−1,ϑ−1)where
the last step follows from equation (A.41). Since we know that Bcontains a ϑ×2ϑ
sub-matrix with 2ϑdistinct columns it follows that

0···01···1
 B

 B


contains a (ϑ+1)×2ϑ+1sub-matrix with 2ϑ+1distinct columns.
The lemma is proved.

289 Proofs and Derivations—Part II
We can now proceed to the main proof.
Proof of Theorem 4.10. Suppose that the VC dimension of /C0isϑ.F o ra l l m≥ϑ
consider a training sample z=(z1,..., zm)∈ /CImfor which the maximum of
equation (4.16) is attained. Let ˆh1,...,ˆh/C6/C0(m)∈ /C0be the hypotheses realizing
the /C6/C0(m)different zero-one loss patterns and arrange all these m–dimensional
binary vectors in an m× /C6/C0(m)matrix A, i.e.,
A=
l0−1parenleftBig
ˆh1(x1),y1parenrightBig
··· l0−1parenleftBig
ˆh/C6/C0(m)(x1),y1parenrightBig
.........
l
0−1parenleftBig
ˆh1(xm),ymparenrightBig
··· l0−1parenleftBig
ˆh/C6/C0(m)(xm),ymparenrightBig
.
If it were the case that /C6/C0(m)>/Phi1(m,ϑ)then Lemma C.4 states that there is
a sub-matrix with ϑ+1 rows and all possible distinct 2ϑ+1columns, i.e., there
exists a subsequence of zof length ϑ+1 which is shattered by /C0.T h i si sa
contradiction to the maximal choice of the VC dimension ϑ(see equation (4.18))
Hence, /C6/C0(m)≤/Phi1(m,ϑ)which proves Theorem 4.10.
C.3 Luckiness Bound
In this section we prove Theorem 4.19 which is the main result in the luckiness
framework. Note that this proof works “inversely”, i.e., instead of upper boundingthe probability that the expected risk is larger than εby some term δ(ε)and later
solving for ε, we show that our choice of εguarantees that the above mentioned
probability is less than δ. Let us restate the theorem.
Theorem C.5 Suppose L is a luckiness function that is probably smooth w.r .t. the
functionω. F or any δ∈[0,1], any probability measure P
Zand any d∈ /C6,
PZm(∃h∈ /C0:Q1(Z,h)∧Q2(Z,h)∧Q3(h))<δ,
where the propositions Q 1,Q2and Q 3are given by
Q1(z,h)≡ Remp [h,z]=0,Q2(z,h)≡ωparenleftbigg
L(z,h),δ
4parenrightbigg
≤2d,
Q3(h)≡ R[h]>ε(m,d,δ), andε(m,d,δ)=2
mparenleftbigg
d+ldparenleftbigg4
δparenrightbiggparenrightbigg
.
290 Appendix C
The result (4.23) follows from the fact that the negation of the conjunction says
that, for all hypotheses h∈ /C0, either Remp [h,z]/negationslash=0o rω(L(z,h),δ/ 4)>2dor
R[h]≤ε(m,d,δ).
Proof Due to the length of the proof we have structured it into three steps.
We will abbreviate ε(m,d,δ)byεand will use the shorthand notation z[i:j]def=parenleftbig
zi,zi+1,..., zjparenrightbig
.I f Qiand Qjare propositions, Qijdef=Qi∧Qj.
Symmetrization by a Ghost Sample
By Lemma C.2 we know that, for all m∈ /C6,
PZm(∃h∈ /C0:Q12(Z,h)∧Q3(h))≤
2·PZ2mparenleftbig
∃h∈ /C0:Q12parenleftbig
Z[1:m],hparenrightbig
∧Q4parenleftbig
Z[(m+1):2m],hparenrightbigparenrightbig
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
J(Z),
where the proposition Q4is given by
Q4(z,h)≡Remp [h,z]>ε
2.
In order to see that we consider the following logical formula ϒandσ–algebra /BT/C0
induced by /C0:
ϒ(z,h)≡ Q2(z,h),/BT/C0=braceleftBig
Ahdef={(x,y)∈ /CI|l0−1(h(x),y)=1}| h∈ /C0bracerightBig
.
Hence, R[h]=PZ(Ah),Remp [h,z]=vz(Ah)and, by the choice of εwe ensured
that mε> 2. Thus, it now sufﬁces to show that PZ2m(J(Z))≤δ
2.
Upper bounding the probability of samples where the growth function increases
too much
In order to make use of the probable smoothness of Lwe distinguish the event
that the number of equivalence classes w.r.t. the zero-one loss l0−1that contain
functions luckier than his larger than ωparenleftbig
m,Lparenleftbig
z[1:m],hparenrightbig
,d/4parenrightbig
and its negation. In
order to accomplish this we deﬁne the proposition Sby
S(z)≡∃ h∈ /C0:/lscriptL(z,h)>ω(L((z1,..., zm),h),δ/ 4).
291 Proofs and Derivations—Part II
We see that, by the probable smoothness of the luckiness Lgiven in Deﬁnition
4.18,
PZ2m(J(Z))= PZ2m(J(Z)∧S(Z))+PZ2m(J(Z)∧(¬S(Z)))
≤ PZ2m(S(Z))+PZ2m(J(Z)∧(¬S(Z)))
≤δ
4+PZ2m(J(Z)∧(¬S(Z))),
Now we upper bound PZ2m(J(Z)∧(¬S(Z)))byδ
4.
Symmetrization by Permutation
By deﬁning Q5(z,h)=Q2parenleftbig
z[1:m],hparenrightbig
∧(¬S(z)),t h a ti s ,
Q5(z,h)≡/lscriptL(z,h)≤2d,
we see that the proposition J(z)∧(¬S(z))is given by
Q(z)≡∃ h∈ /C0:Q1parenleftbig
z[1:m],hparenrightbig
∧Q4parenleftbig
z[(m+1):2m],hparenrightbig
∧Q5(z,h).
Now we shall use a technique which is known as symmetrization by permutation
and which is due to Kahane (1968) according to van der V aart and Wellner (1996).Since all 2 msamples Z
iare drawn iid from PZwe know that, for any permutation
π:{1,..., 2m}→{1,..., 2m},
PZ2m(Q(Z))=PZ2m(Q(/Pi1(Z))),
where we use the shorthand notation /Pi1(Z)to denote the action of πon the
indices of Z=(Z1,..., Z2m), i.e.,/Pi1((Z1,..., Z2m))def=parenleftbig
Zπ(1),..., Zπ(2m)parenrightbig
.N o w
consider all 2mdifferent swapping permutations /Pi1sindexed by s∈{0,1}m, i.e.,
/Pi1s(z)swaps ziand zi+mif, and only if, si=1. It follows that
PZ2m(Q(Z))=ESbracketleftbig
PZ2m|S=s(Q(/Pi1s(Z)))bracketrightbig
=EZ2mbracketleftbig
PS|Z2m=z(Q(/Pi1S(z)))bracketrightbig
for any discrete measure PS. Clearly, PZ2mS= PZ2mPSwhich implies that
PS|Z2m=z=PS. Hence, if we show that PS(Q(/Pi1S(z))) is at mostδ
4for each
double sample z∈ /CI2m, we have proven the theorem. The appealing feature of
the technique is that we can ﬁx zin the further analysis. In our particular case we
obtain that PS(Q(/Pi1S(z))) is given by
PSparenleftbig
∃h∈ /C0:Q1parenleftbig
/Pi1S(z)[1:m],hparenrightbig
∧Q4parenleftbig
/Pi1S(z)[(m+1):2m],hparenrightbig
∧Q5(z,h)parenrightbig
,(C.2)
292 Appendix C
where we used the fact that the luckiness function is permutation invariant. Since
the double sample z∈ /CI2mis ﬁxed, we can arrange the hypotheses h∈ /C0in
decreasing order of their luckiness on the ﬁxed double sample, i.e., i> j⇒
L(z,hi)≤Lparenleftbig
z,hjparenrightbig
.N o wl e t
c(i)def=vextendsinglevextendsinglebraceleftbigparenleftbig
l0−1parenleftbig
hj(x1),y1parenrightbig
,..., l0−1parenleftbig
hj(x2m),y2mparenrightbigparenrightbig
|j∈{1,..., i}bracerightbigvextendsinglevextendsingle
be the number of equivalence classes w.r.t. the zero-one loss incurred by the ﬁrst
ihypotheses. Finally, let i∗be such that c(i∗)≤2dbut c(i∗+1)>2d.T h e n
equation (C.2) can be rewritten as
PSparenleftbig
∃j∈braceleftbig
1,..., i∗bracerightbig
:Q1parenleftbig
/Pi1S(z)[1:m],hjparenrightbig
∧Q4parenleftbig
/Pi1S(z)[(m+1):2m],hjparenrightbigparenrightbig
,
because by construction we know that h1,..., hi∗+1are the only hypotheses that
are at least as lucky as hi∗+1onzbut/lscriptL(z,hi∗+1)>2d.S i n c e c(i∗)≤2dthere
are not more than q≤2dhypothesesˆh1,...,ˆhq⊆{h1,..., hi∗}which realize
the c(i∗)different zero-one loss function patterns. Thus, by an application of the
union bound we have that the probability in equation (C.2) is bounded from aboveby
qsummationdisplay
i=1PSparenleftBig
Q1parenleftBig
/Pi1S(z)[1:m],ˆhiparenrightBig
∧Q4parenleftBig
/Pi1S(z)[(m+1):2m],ˆhiparenrightBigparenrightBig
.
However, if we assume a uniform measure PSover the 2mdifferent swapping
permutations each summand cannot be bigger than 2m−εm
2·2−m=2−εm
2because,
whenever we swap one of the at leastεm
2examples that incur a mistake on the
second mexamples (according to Q4) into the ﬁrst mexamples, we violate Q1
(see also Figure C.2). Thus we see that
PZ2m(J(Z)∧(¬S(Z)))≤ PZ2m(Q(Z))
≤ q·2−m
2ε≤2d·2−d−ldparenleftBig
4
δparenrightBig
=δ
4,
which completes the proof.
C.4 Empirical VC Dimension Luckiness
In this section we proof the probable smoothness of the empirical VC dimension
(see Section 4.3). This proof is mainly taken from Shawe-Taylor et al. (1998).
293 Proofs and Derivations—Part II
Theorem C.6 (Probable smoothness of the empirical VC dimension luckiness)
Given a hypothesis space /C0, for any δ∈bracketleftbig
0,1
2bracketrightbig
the unluckiness function
U(z,h)=ϑ/C0(z)is probably smooth w.r .t. the function
ω(U,δ)=parenleftbigg2em
τ(U,δ)·Uparenrightbiggτ(U,δ)·U
,τ(U,δ)=4parenleftbigg
1+1
Ulnparenleftbigg1
δparenrightbiggparenrightbigg
.
Proof Given a double sample z1z2∈ /CI2m,|z1|=mwe note that, according
to Theorem 4.10 and A.105, ω(U,δ)=parenleftbig2em
τUparenrightbigτUis an upper bound on the
number of equivalence classes w.r.t. the zero-one loss l0−1on that double sample if
ϑ/C0(z1z2)≤τU. Thus it sufﬁces to show that, for any δ∈[0,1],
PZ2m(τ(ϑ/C0((Z1,..., Zm)),δ)·ϑ/C0((Z1,..., Zm))<ϑ/C0(Z))bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
Q(Z)≤δ.
Since all 2 msamples Ziare drawn iid from PZwe know that, for any permutation
π:{1,..., 2m}→{1,..., 2m},
PZ2m(Q(Z))=PZ2m(Q(/Pi1(Z))),
where we use the shorthand notation /Pi1(Z)to denote the action of πon the
indices of Z=(Z1,..., Z2m), i.e.,/Pi1((Z1,..., Z2m))def=parenleftbig
Zπ(1),..., Zπ(2m)parenrightbig
.N o w
consider all 2mdifferent swapping permutations /Pi1sindexed by s∈{0,1}m, i.e.,
/Pi1s(z)swaps ziand zi+mif, and only if, si=1. It follows that
PZ2m(Q(Z))=ESbracketleftbig
PZ2m|S=s(Q(/Pi1s(Z)))bracketrightbig
=EZ2mbracketleftbig
PS|Z2m=z(Q(/Pi1S(z)))bracketrightbig
for any discrete measure PS. Clearly, PZ2mS= PZ2mPSwhich implies that
PS|Z2m=z=PS. Hence, if we show that PS(Q(/Pi1S(z))) is at most δfor each dou-
ble sample z∈ /CI2mand the uniform measure PSon{0,1}m, we have proven the
theorem. Let d=ϑ/C0(z)be the empirical VC dimension on the ﬁxed double sam-
ple. By deﬁnition, there must exists at least one subsequence ˜z=parenleftbig
zi1,..., zidparenrightbig
⊂z
of length dthat is shattered by /C0. The important observation is that any sub-
sequence of length j∈{1,..., d}of ˜zmust also be shattered by /C0because,
otherwise, ˜zis not shattered by /C0.L e t j∗∈[0,m]be such that τ(j∗,δ)·j∗=d;
j∗=d
4+ln(δ). (C.3)
Whenever any swapping permutation πsis such that more than ⌊j∗⌋examples
of the subsequence ˜zare swapped into the ﬁrst half, Q(/Pi1s(z))cannot be true
294 Appendix C
because the empirical VC dimension on the ﬁrst half was at least ⌊j∗⌋+1a n dτis
monotonically increasing in its ﬁrst argument. Thus, PS(Q(/Pi1S(z))) is bounded
from above by
2−m·⌊j∗⌋summationdisplay
j=0Sd,j≤⌊j∗⌋summationdisplay
j=0parenleftbiggd
jparenrightbigg
2−d<1
2dparenleftbigged
j∗parenrightbiggj∗
<(eτ(j∗,δ))j∗
2τ(j∗,δ)·j∗,
where Sd,jis the number of swappings that swap exactly j of the dexamples into
the ﬁrst half. The second step follows directly from Lemma C.7 and the observationthat 4 j
∗< dfor allδ∈bracketleftbig
0,1
2bracketrightbig
. The last step is a consequence of Theorem
A.105 and equation (C.3). In order to complete the proof it sufﬁces to show that
j∗ln(eτ(j∗,δ))−j∗·τ(j∗,δ)·ln(2)<ln(δ). Using the deﬁnition of τand
Theorem A.101 we see that the latter term is given by
j∗parenleftbigg
1+lnparenleftbigg
4parenleftbigg
1−1
j∗ln(δ)parenrightbiggparenrightbigg
−4l n(2)parenleftbigg
1−1
j∗ln(δ)parenrightbiggparenrightbigg
<j∗parenleftbigg
1+ln(4)−1
j∗ln(δ)−4l n(2)+4l n(2)
j∗ln(δ)parenrightbigg
<(4l n(2)−1)ln(δ)<2l n(δ)<ln(δ),
because 1+ln(4)−4l n(2)<0a n dl n(δ)<0f o ra l lδ∈bracketleftbig
0,1
2bracketrightbig
. The theorem is
proved.
Lemma C.7 F or any double sample z∈ /CI2m, for any d≤m, for any subsample
˜z=parenleftbig
zi1,..., zidparenrightbig
⊂zand for any j <d/3, the number S d,jof swappings such
that exactly j examples of ˜zare within the ﬁrst m examples is bounded by
Sd,j≤parenleftbiggd
jparenrightbigg
·2m−d.
Proof First, let us assume that the subsample ˜zis such that no two indices ipand
iqhave the property thatvextendsinglevextendsingleip−iqvextendsinglevextendsingle=m(Figure C.3 (left)). Then we observe that
the number Sd,jis exactlyparenleftbigd
jparenrightbig
2m−ddue to the following argument: Since d≤m
and no two indices are the swapping counterpart of each other, there must existsa swapping π
s0such that all examples in ˜z⊂zare in the second half. In order to
ensure that exactly jof the dexamples are in the ﬁrst half we have to swap them
back into the ﬁrst half (starting from /Pi1s0(z)). Now there areparenleftbigd
jparenrightbig
many choices of
distinct examples to swap. Further, swapping any of the m−dexamples not in ˜z
295 Proofs and Derivations—Part II/DE/BE
/DE/BF
/DE/BG
/DE/BI
/DE/BJ/DE/BL
/DE/BD/BC
/DE/BD/BD
/DE/BD/BF
/DE/BD/BG
/DE/BD
/DE/BE
/DE/BF
/DE/BG
/DE/BH
/DE/BI
/DE/BJ/DE/BK
/DE/BL
/DE/BD/BC
/DE/BD/BD
/DE/BD/BE
/DE/BD/BF
/DE/BD/BG/DE/BK/DE/BD
/DE/BH
/DE/BD/BE
/A5/D7/BC
/B4 /DE /B5/DE/BE
/DE/BF
/DE/BG
/DE/BI
/DE/BJ/DE/BL
/DE/BD/BC
/DE/BD/BD
/DE/BD/BF
/DE/BD/BG
/DE/BD
/DE/BE
/DE/BF
/DE/BG
/DE/BH
/DE/BI
/DE/BJ/DE/BK
/DE/BL
/DE/BD/BC
/DE/BD/BD
/DE/BD/BE
/DE/BD/BF
/DE/BD/BG/DE/BH
/DE/BD/BE
/A5/D7/BC
/B4 /DE /B5/DE/BD/DE/BK
Figure C.3 Counting swappings such that exactly jof the d= 6 examples (gray
background) are within the ﬁrst m=7e x a m p l e s . (Left) Since no two of the dindices
are the swapping counterpart to each other we can swap all gray examples into the second
half and start counting. (Right) Since z1and z8are within the dexamples there will always
ber=1 gray example in the ﬁrst half.
that are in the second half of /Pi1s0(z)into the ﬁrst half would not alter the event;
hence the 2m−dterm.
Now let us assume that there are r∈{1,..., j}pairs of indices ipand iq
such thatvextendsinglevextendsingleip−iqvextendsinglevextendsingle= mand let Sr
d,jbe the number of swappings that satisfy
the condition stated (Figure C.3 (right)). In this case, whatever the swapping, r
examples of ˜zare in the ﬁrst half, and to make up the number to ja further j−r
indices have to be chosen out of the d−2r. Hence
Sr
d,j=parenleftbiggd−2r
j−rparenrightbigg
·2m−d+2r
because the remaining m−d−2rcan be swapped without affecting the condition
stated. Note that
Sr+1
d,j=parenleftbiggd−2r−2
j−r−1parenrightbigg
·2m−d+2r+2=g(j,r)·Sr
d,j,
where
g(j,r)=4(j−r)(d−j−r)
(d−2r)(d−2r−1).
296 Appendix C
It is easily veriﬁed that, for any r∈{1,..., j}, the function gattains its maximum
for j=d/2. However, as by assumption j<d/3 we know that
g(j,r)<4
9(d−3r)(2d−3r)
(d−2r)(d−2r−1)
in the possible range of j. Hence, the function g(j,r)is strictly less than 1 if d≥9
because this implies that
d2−9d+18r>0⇒ 4(d−3r)(2d−3r)<9(d−2r)(d−2r−1).
As a consequence, for d≥9 the result is true because
Sr
d,j<S0
d,j=Sd,j=parenleftbiggd
jparenrightbigg
·2m−d
for all r∈{1,..., j}.F o r d<9 the only possible cases are j=0 (trivial),
j=1,r=1a n d j=2,r∈{1,2}which can easily veriﬁed to be true. The
theorem is proved.
C.5 Bound on the Fat Shattering Dimension
This elegant proof of Lemma 4.31 can be found in Bartlett and Shawe-Taylor(1998) and dates back to Gurvits (1997). We will restate the original proof using
the shorthand notationsummationtextAdef=summationtext
ai∈Aai.
Proof The proof involves two lemmas that make extensive use of the geometry in
an inner product space /C3. We show that if S⊂Xisγ–shattered by /BY,t h e ne v e r y
subset S0⊆SsatisﬁesvextenddoublevextenddoublesummationtextS0−summationtext(S\S0)vextenddoublevextenddouble≥|S|γ
B. At the same time, for all
S⊂X,s o m e S0⊆SsatisﬁesvextenddoublevextenddoublesummationtextS0−summationtext(S\S0)vextenddoublevextenddouble≤√
|S|ς. Combining these
two assertions yields
1≥|S|γ
√
|S|Bς=radicalbig
|S|γ
Bς⇒|S|≤parenleftbiggBς
γparenrightbigg2
,
for every γ–shattered set S.T h i sp r o v e st h el e m m a .
Lemma C.8 If S⊂Xi sγ–shattered by /BY, then every subset S 0⊆S satisﬁes
vextenddoublevextenddoublevextenddoublesummationdisplay
S0−summationdisplay
(S\S0)vextenddoublevextenddoublevextenddouble≥|S|γ
B.
297 Proofs and Derivations—Part II
Proof Suppose S={x1,..., xm}isγ–shattered by /BYwitnessed by the mreal
numbers r1,..., rm. Then, for all y=(y1,..., ym)∈{−1,+1}mthere is a wy
withvextenddoublevextenddoublewyvextenddoublevextenddouble≤Bsuch that, for all i∈{1,..., m},yiparenleftbigangbracketleftbig
wy,xiangbracketrightbig
−riparenrightbig
≥γ.F i xa
subset S0⊆S. We consider two cases: If
summationdisplay
{ri|xi∈S0}≥summationdisplay
{ri|xi∈(S\S0)},
then we consider yi=+ 1 if, and only if, xi∈S0. In this case we haveangbracketleftbig
wy,xiangbracketrightbig
≥
ri+γifxi∈S0and−angbracketleftbig
wy,xiangbracketrightbig
≥− ri+γifxi∈(S\S0). If follows that
angbracketleftBig
wy,summationdisplay
S0angbracketrightBig
≥summationdisplay
{ri|xi∈S0}+|S0|γ
−angbracketleftBig
wy,summationdisplay
(S\S0)angbracketrightBig
≥−summationdisplay
{ri|xi∈(S\S0)}+|S\S0|γ,
which, combined together, gives
angbracketleftBig
wy,summationdisplay
S0−summationdisplay
(S\S0)angbracketrightBig
≥summationdisplay
{ri|xi∈S0}−summationdisplay
{ri|xi∈(S\S0)}+|S|γ
≥|S|γ.
Using the Cauchy-Schwarz inequality (see Theorem A.106) and the assumptionvextenddoublevextenddoublewyvextenddoublevextenddouble≤B, we know
Bvextenddoublevextenddoublevextenddoublesummationdisplay
S
0−summationdisplay
(S\S0)vextenddoublevextenddoublevextenddouble≥vextenddoublevextenddoublew
yvextenddoublevextenddouble·vextenddoublevextenddoublevextenddoublesummationdisplay
S
0−summationdisplay
(S\S0)vextenddoublevextenddoublevextenddouble
≥angbracketleftBig
w
y,summationdisplay
S0−summationdisplay
(S\S0)angbracketrightBig
≥|S|γ.
In the other case, we consider yi=+ 1 if, and only if, xi∈(S\S0), and use an
identical argument.
Lemma C.9 Fo r a l l S⊂X, s o m e S 0⊆S satisfy
vextenddoublevextenddoublevextenddoublesummationdisplay
S
0−summationdisplay
(S\S0)vextenddoublevextenddoublevextenddouble≤radicalbig
|S|ς.
Proof The proof uses the probabilistic method (Alon et al. 1991). Suppose S=
{x1,..., xm}. We choose S0randomly by deﬁning xi∈S0⇔Bi=+ 1, where
B1,..., Bmare independent random variables with PBi(+1)=PBi(−1)=1
2.
298 Appendix C
Then,
EBmbracketleftbiggvextenddoublevextenddoublevextenddoublesummationdisplay
S0−summationdisplay
(S\S0)vextenddoublevextenddoublevextenddouble2bracketrightbigg
=EBm
vextenddoublevextenddoublevextenddoublevextenddoublevextenddoublemsummationdisplay
i=1Bixivextenddoublevextenddoublevextenddoublevextenddoublevextenddouble2

=EBmbracketleftBiggangbracketleftBiggmsummationdisplay
i=1Bixi,msummationdisplay
j=1BjxjangbracketrightBiggbracketrightBigg
=msummationdisplay
i=1EBmbracketleftBiggangbracketleftBigg
Bixi,msummationdisplay
j=1BjxjangbracketrightBiggbracketrightBigg
=msummationdisplay
i=1EBmbracketleftBiggangbracketleftBigg
Bixi,summationdisplay
i/negationslash=jBjxj+BixiangbracketrightBiggbracketrightBigg
=msummationdisplay
i=1parenleftBiggsummationdisplay
i/negationslash=jEBmbracketleftbig
Bi·Bjbracketrightbigangbracketleftbig
xi,xjangbracketrightbig
+EBmbracketleftBig
/bardblBixi/bardbl2bracketrightBigparenrightBigg
=msummationdisplay
i=1EBmbracketleftBig
/bardblBixi/bardbl2bracketrightBig
≤|S|ς2,
where the last line follows from the fact that the Bihave zero mean and are
independent, i.e., EBmbracketleftbig
Bi·Bjbracketrightbig
=0f o r i/negationslash=j. Since the expectation is no more
than|S|ς2, there must be a set S0for whichvextenddoublevextenddoublesummationtextS0−summationtext(S\S0)vextenddoublevextenddouble2is no more
than|S|ς2.
C.6 Margin Distribution Bound
In course of the derivation of the sequence /Delta1iwe shall sometimes abbreviate
D(z,w,γ)by D. Let us consider the value of deff(/Delta1)given by equation (4.32)
for a ﬁxed value of γand/bardblw/bardbl=1, i.e.,
deff(/Delta1)=64parenleftBig
1+parenleftbigD
/Delta1parenrightbig2parenrightBigparenleftbig
ς2+/Delta12parenrightbig
γ2=64
γ2parenleftbigg
ς2+/Delta12+ς2D2
/Delta12+D2parenrightbigg
bracehtipupleft
bracehtipdownrightbracehtipdownleft
 bracehtipupright
f(/Delta1). (C.4)
Given an observed margin distribution Dwe would like to replace /Delta1in equation
(C.4) with the minimizing value /Delta1∗(D)of the term deff(/Delta1)which is equivalent to
299 Proofs and Derivations—Part II
the minimizer of f(/Delta1). A straightforward calculation shows that this value has to
be/Delta1∗(D)=√
ςDbecause
df
d/Delta1vextendsinglevextendsinglevextendsinglevextendsingle
/Delta1∗=2/Delta1∗(D)−2ς2D2
(/Delta1∗(D))3=0,d2f
d/Delta12vextendsinglevextendsinglevextendsinglevextendsingle
/Delta1=√
ςD=2+6
√
ςD>0.
In this case the value of f(/Delta1∗(D))equalsς2+2ςD+D2=(ς+D)2. First,
note that the largest value of Dis 2ς√
mbecause, in the worst case, wfails for all
mpoints to achieve a functional margin of γby at most 2 ς(all points are assumed
to be in a ball of radius less than or equal to ς) and, thus, D2≤4ς2m⇔ D≤
2ς√
m. Hence we set up an arithmetic series (/Delta1i)i=1,..., sof values before having
observed the data such that /Delta11=2ς√
mand/Delta1i+1=/Delta1i
2which ensures that, for
all values of D, there will be a /Delta1isuch that
/Delta1∗(D)
2=√
ςD
2≤/Delta1i≤radicalbig
ςD=/Delta1∗(D).
Using the lower bound√
ςD
2for/Delta1iin equation (C.4) we see that, for all D,
fparenleftbig
/Delta1∗(D)parenrightbig
≤ f(/Delta1i)≤fparenleftbigg√
ςD
2parenrightbigg
=ς2+1
4ςD+4ςD+D2≤(ς+3D)2
<65
64(ς+3D)2.
Finally note that it sufﬁces to consider the series untilς
64</Delta1 s≤ς
32because, for
allDsuch that /Delta1∗(D)=√
ςD<ς
32⇔radicalBig
D
ς≤1
32, it is readily veriﬁed that
fparenleftbig
/Delta1∗(D)parenrightbig
=(ς+D)2
≤ f(/Delta1s)=parenleftbigg
1+D2
/Delta12
sparenrightbiggparenleftbig
ς2+/Delta12
sparenrightbig
≤parenleftbigg
1+642D2
ς2parenrightbiggparenleftbigg
ς2+ς2
322parenrightbigg
≤ς2parenleftbigg
1+642
324parenrightbiggparenleftbigg
1+1
1024parenrightbigg
<65
64ς2<65
64(ς+3D)2.
The number sis easily determined by making use of the deﬁnition /Delta1s=2ς√
m·
2−s+1andς
64</Delta1 swhich yields s<8+1
2ld(m).
300 Appendix C
C.7 The Quantiﬁer Reversal Lemma
This section presents the quantiﬁer reversal lemma due to David McAllester (see
McAllester (1998)). This lemma is of particular importance in the derivation ofgeneralization error bounds in the PAC-Bayesian framework (see Section 5.1).Broadly speaking, if a logical formula acts on two random variables and we havethe formula true for allvalues of one of the random variables, then the quantiﬁer
reversal lemma allows us to move the all-quantiﬁer over that random variable into
a “all-but-a-fraction-of- δ” statement for a ﬁxed value of the other random variable.
Thus, it provides an upper bound on the conditional distribution of the randomvariable.
Lemma C.10 (Quantiﬁer reversal lemma) LetXandYbe random variables and
letδrange over (0,1].L e tϒ:/CG× /CH× /CA→{true,false}be any measurable
logical formula on the product space such that for any x ∈ /CGand y∈ /CHwe have
{δ∈(0,1]|ϒ(x,y,δ)}=(0,δmax]
for some δmax.I f
∀x∈ /CG:∀δ∈(0,1]: PY|X=x(ϒ(x,Y,δ))≥1−δ,
then, for any β∈(0,1), we have
∀δ∈(0,1]:PYparenleftBig
∀α∈(0,1]:PX|Y=yparenleftBig
ϒparenleftBig
X,y,(αβδ)1
1−βparenrightBigparenrightBig
≥1−αparenrightBig
≥1−δ.
Let us start with a simple lemma we need for of the proof.
Lemma C.11 LetXbe a random variable such that PX([0,1])=1and let g be
any measurable, monotonically decreasing function from the interval [0,1]to the
reals, i.e., g:[0,1]→ /CAis such that x ≥y implies g (x)≤g(y).I f
∀δ∈[0,1]: FX(δ)≤δ,
then
EXbracketleftbig
g(X)bracketrightbig
≤integraldisplay1
0g(x)dx. (C.5)
301 Proofs and Derivations—Part II
Proof By the deﬁnition of the expectation (Deﬁnition A.7) we know that
EXbracketleftbig
g(X)bracketrightbig
=integraldisplay1
0g(x)dFX(x)=−integraldisplay1
0FX(x)d(g(x))+bracketleftbig
g(x)·FX(x)bracketrightbig1
0
=integraldisplay1
0FX(x)d(−g(x))+g(1),
where the ﬁrst line follows from partial integration and the second line uses the fact
that FX(0)=0a n d FX(1)=1. Since−g(x)is, by assumption, a monotonically
increasing function we know that any positive difference g(x)−g(˜x)>0 implies
that x−˜x>0. Hence for the ﬁrst integral we can use the upper bound on FXto
obtain
EXbracketleftbig
g(X)bracketrightbig
≤integraldisplay1
0xd(−g(x))+g(1)
=integraldisplay1
0g(x)dx+[x·(−g(x))]1
0+g(1)=integraldisplay1
0g(x)dx.
The lemma is proved.
Using this lemma we can now proceed to prove the quantiﬁer reversal lemma.
Proof of Theorem C.10. Deﬁne f: /CG× /CH→ /CAin the following way
f(x,y)=braceleftbigg
0i f {δ∈(0,1]|ϒ(x,y,δ)}=(0,δmax]=∅
δmax if{δ∈(0,1]|ϒ(x,y,δ)}=(0,δmax]/negationslash=∅.
By deﬁnition, for any x∈ /CG,a n d y∈ /CHandδ∈(0,1]we know that ϒ(x,y,δ)=
true is equivalent to the fact that f(x,y)≥δ.F o rag i v e n x∈ /CGwe deﬁne the
new random variable Tdef= f(x,Y). Then the assumption of the theorem implies
that
∀x∈ /CG:∀δ∈(0,1]: PY|X=x(ϒ(x,Y,δ))≥1−δ⇔FT(δ)≤δ.
Now, note that for β∈(0,1),g(z)=zβ−1is an monotonically decreasing function
since the exponent is strictly negative. From Lemma C.11 we conclude
∀x∈ /CG:∀δ∈(0,1]: EY|X=xbracketleftbig
fβ−1(x,Y)bracketrightbig
=ETbracketleftbig
Tβ−1bracketrightbig
≤integraldisplay1
0zβ−1dz=1
β.
302 Appendix C
Taking the expectation over x∈ /CGgives
∀δ∈(0,1]: EXbracketleftbig
EY|X=xbracketleftbig
fβ−1(x,Y)bracketrightbigbracketrightbig
≤1
β.
We can exchange the expectation values by the theorem of repeated integrals (see
Feller (1966)). Thus, using Markov’s inequality given in Theorem A.109 we obtain
∀δ∈(0,1]: PYparenleftbigg
EX|Y=ybracketleftbig
fβ−1(X,y)bracketrightbig
≤1
βδparenrightbigg
≥1−δ.
Applying Markov’s inequality once again to the conditional expectation value
EX|Y=ybracketleftbig
fβ−1(X,y)bracketrightbig
gives
∀δ∈(0,1]:PYparenleftbigg
∀α∈(0,1]:PX|Y=yparenleftbigg
fβ−1(X,y)≤1
αβδparenrightbigg
≥1−αparenrightbigg
≥1−δ.
Finally, rearranging terms and using the fact that ϒ(x,y,δ)=true is equivalent
tof(x,y)≥δwe obtain
∀δ∈(0,1]:PYparenleftBig
∀α∈(0,1]:PX|Y=yparenleftBig
ϒparenleftBig
X,y,(αβδ)1
1−βparenrightBigparenrightBig
≥1−αparenrightBig
≥1−δ.
The theorem is proved.
C.8 A PAC-Bayesian Marin Bound
This section contains the proof of Theorem 5.10. In course of this proof we need
several theorems and lemmas which have been delegated to separate subsectionsdue to their length.
Proof of Theorem 5.10. Geometrically, the hypothesis space/C0is isomorphic the
unit sphere /CFin /CAn(see Figure 2.8). Let us assume that PWis uniform on the unit
sphere. Given the training sample z∈ /CImand a classiﬁer having normal w∈ /CF
we show in Theorem C.13 that the open ball/BU(w)=braceleftbigg
v∈ /CFvextendsinglevextendsinglevextendsinglevextendsingle/angbracketleftw,v/angbracketright>radicalBig
1−/Gamma12
z(w)bracerightbigg
⊆ /CF (C.6)
is fully within the version space V(z). Such a set /BU(w)is, by deﬁnition, point
symmetric w.r.t. wand hence we can use −ln(PW(
/BU(w)))to bound the expected
risk of hw.S i n c e PWis uniform on the unit sphere, the value −ln(PW(
/BU(w))) is
303 Proofs and Derivations—Part II
simply the logarithm of the volume ratio of the surface of the unit sphere to the
surface of all v∈ /CF satisfying equation (C.6). A combination of Theorem C.14
and C.15 shows that this ratio is given by
lnparenleftbigg1
PW(
/BU(w))parenrightbigg
= ln
integraltext2π
0sinn−2(θ)dθ
integraltextarccosparenleftBig√
1−(/Gamma1z(w))2parenrightBig
0 sinn−2(θ)dθ

≤ n·lnparenleftBigg
1
1−radicalbig
1−/Gamma12
z(w)parenrightBigg
+ln(2).
Using Theorem 5.4 and Lemma 5.9 and bounding ln (2)by one from above we
obtain the desired result. Note that mpoints{x1,..., xm}maximally span an
m–dimensional space and, thus, we can marginalize over the remaining n−m
dimensions of feature space /C3.T h i sg i v e s d=min(m,n).
C.8.1 Balls in V ersion Space
In this section we prove that the open ball/BU(w)=braceleftbigg
v∈ /CFvextendsinglevextendsinglevextendsinglevextendsingle/angbracketleftw,v/angbracketright>radicalBig
1−/Gamma12
z(w)bracerightbigg
around a linear classiﬁer having normal wof unit length contains classiﬁers within
version space V(z)only. Here, /Gamma1z(w)is the margin of the hyperplane won a set
of points normalized by the length /bardblxi/bardblof the xi(see equation (5.11) for a formal
deﬁnition). In order to prove this result we need the following lemma.
Lemma C.12 Suppose /C3⊆/lscriptn
2is a ﬁxed feature space. Assume we are given two
points w∈ /CFand x∈ /C3such that/angbracketleftw,x/angbracketright=γ> 0. Then, for all v∈ /CFwith
/angbracketleftw,v/angbracketright>radicalBigg
1−γ2
/bardblx/bardbl2(C.7)
it follows that /angbracketleftv,x/angbracketright>0.
Proof Since we only evaluate the inner product of any admissible v∈ /CF with
w∈ /CFand x∈ /C3, we can make the following approach
304 Appendix C/AB
/AB/DC/BD
/AB
/AD/CX
/CZ /DC/CX
/CZ
/DC/BE/DC/CX
/CZ /DC/CX
/CZ/CF /BP /CU
/DI/DB /CY /CZ
/DI/DB /CZ /BP /BD /CV/CU /DC /CY /CW /DC /BN /DB /CX /BP /BC /CV
/CU /DA /CY /CW /DC/CX
/BN /DA /CX /BP /BC /CV
/DB
Figure C.4 Suppose the point x1(or x2) is given. We must show that all classiﬁers
having normal ˜wof unit length andangbracketleftbigw,˜wangbracketrightbig>radicalBig
1−γ2
i//bardblxi/bardbl2a r eo nt h es a m es i d eo f
the hyperplane {v∈ /C3|/angbracketleftxi,v/angbracketright=0}, i.e.,angbracketleftbig˜v,xiangbracketrightbig
>0, where γi=/angbracketleftxi,w/angbracketright.F r o mt h e
picture it is clear that, regardless of /bardblxi/bardbl,s i n(α)=(γi//bardblxi/bardbl)or equivalently cos (α)=radicalbig
1−sin2(α)=radicalBig
1−γ2
i//bardblxi/bardbl2. Obviously, all vectors ˜wof unit length which enclose an
angle less than αwith ware on the same side (the dark cone). As cos (α)is monotonically
decreasing for α∈parenleftbig
0,π
2parenrightbig
, these classiﬁers must satisfyangbracketleftbig
w,˜wangbracketrightbig
= cosparenleftbig/CMparenleftbig
w,˜wparenrightbigparenrightbig
>radicalBig
1−γ2
i//bardblxi/bardbl2.
v=λx
/bardblx/bardbl+τparenleftbigg
w−γx
/bardblx/bardbl2parenrightbigg
.
Note that the vectorsx
/bardblx/bardbland w−γx
/bardblx/bardbl2are orthogonal by construction. Further-
more, the squared length of w−γx
/bardblx/bardbl2i sg i v e nb y1−γ2//bardblx/bardbl2. Therefore, the unit
norm constraint on vimplies that
τ2=1−λ2
1−γ2
/bardblx/bardbl2.
Furthermore, assumption (C.7) becomes
angbracketleftbigg
λx
/bardblx/bardbl+τparenleftbigg
w−γx
/bardblx/bardbl2parenrightbigg
,wangbracketrightbigg
>radicalBigg
1−γ2
/bardblx/bardbl2
305 Proofs and Derivations—Part II
λγ
/bardblx/bardbl±radicaltpradicalvertexradicalvertexradicalbt
1−λ2
1−γ2
/bardblx/bardbl2parenleftbigg
1−γ2
/bardblx/bardbl2parenrightbigg
>radicalBigg
1−γ2
/bardblx/bardbl2
λγ
/bardblx/bardbl−radicalBigg
1−γ2
/bardblx/bardbl2parenleftBig
1±radicalbig
1−λ2parenrightBig
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
f(λ)> 0.
In order to solve for λwe consider the l.h.s. as a function of λand determine the
range of values in which f(λ)is positive. A straightforward calculation reveals
that [0,λ max]with
λmax=2γ
/bardblx/bardblradicalBigg
1−γ2
/bardblx/bardbl2,
is the only range in which f(λ)is positive. As a consequence, the assumption
/angbracketleftw,v/angbracketright>radicalbig
1−γ2//bardblx/bardbl2is equivalent to
0<λ/bardblx/bardbl<2γradicalBigg
1−γ2
/bardblx/bardbl.
Finally, the inner product of any vwith xis given by
/angbracketleftv,x/angbracketright=angbracketleftbigg
λx
/bardblx/bardbl+τparenleftbigg
w−γx
/bardblx/bardblparenrightbigg
,xangbracketrightbigg
=λ/bardblx/bardbl+τ(γ−γ)>0,
where the last inequality follows from the previous consideration. The lemma is
proved. For a geometrical reasoning see Figure C.4.
Theorem C.13 Suppose /C3⊆/lscriptn
2is a ﬁxed feature space. Given a training sample
z=(x,y)∈(
/CG×{−1,+1})mand w∈ /CFsuch that /Gamma1z(w)>0, for all v∈ /CF
such that/angbracketleftw,v/angbracketright>radicalbig
1−/Gamma12
z(w)we have
∀i∈{1,..., m}: yi/angbracketleftv,xi/angbracketright>0.
Proof According to Lemma C.12 we know that all v∈Biwith
Bi=

v∈ /CFvextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextendsingle/angbracketleftw,v/angbracketright>radicalBigg
1−(yi/angbracketleftxi,w/angbracketright)2
/bardblxi/bardbl2

,
306 Appendix C
parameterize classiﬁers consistent with the ith point xi. Clearly, the intersection of
all Bigives the classiﬁers wwhich jointly satisfy the constraints yi/angbracketleftw,xi/angbracketright>0.
Noticing that the size of Bidepends inversely on yi/angbracketleftxi,w/angbracketrightwe see that all v
such that/angbracketleftw,v/angbracketright>/Gamma1 z(w)jointly classify all points xicorrectly. The theorem is
proved.
C.8.2 V olume Ratio Theorem
In this subsection we explicitly derive the volume ratio between the largest inscrib-able ball in version space and the whole parameter space for the special case oflinear classiﬁers in/CAn. Given a point w∈ /CFand a positive number γ> 0 we can
characterize the ball of radius γin the parameter space by/BUγ(w)=braceleftbig
v∈ /CFvextendsinglevextendsingle/bardblw−v/bardbl2<γ2bracerightbig
=braceleftbig
v∈ /CFvextendsinglevextendsingle/angbracketleftw,v/angbracketright>1−γ2/2bracerightbig
.
In the following we will calculate the exact value of the volume ratiovol( /CF)
vol(
/BUγ(w))
where wcan be chosen arbitrarily (due to the symmetry of the sphere).
Theorem C.14 Suppose we are given a ﬁxed feature space /C3⊆/lscriptn
2. Then the
fraction of the whole surface vol(
/CF)of the unit sphere to the surface volparenleftbig/BUγ(w)parenrightbig
with Euclidean distance less than γfrom any point w∈ /CFis given by
vol(
/CF)
volparenleftbig/BUγ(w)parenrightbig=integraltextπ
0sinn−2(θ)dθ
integraltextarccosparenleftBig
1−γ2
2parenrightBig
0 sinn−2(θ)dθ.
Proof As the derivation requires the calculation of surface integrals on the hyper-
sphere in /lscriptn
2we deﬁne each admissible w∈ /CFby its polar coordinates and carry
out the integration over the angles. Thus we specify the coordinate transformation
τ: /CAn→ /CAnfrom polar coordinates into Cartesian coordinates, i.e., every w∈ /CF
is expressed via n−2 angles θ=(θ1,...,θ n−2)/primeranging from 0 to π, one angle
0≤ϕ≤2π, and the radius function r(θ,ϕ)which is in the case of a sphere of
constant value r. This transformation reads
τ1(r,ϕ,θ)= r·sin(ϕ) sin(θ1)···sin(θn−2) (C.8)
τ2(r,ϕ,θ)= r·cos(ϕ) sin(θ1)···sin(θn−2)
............
τ
n−1(r,ϕ,θ)= r·cos(θn−3)sin(θn−2)
307 Proofs and Derivations—Part II
τn(r,ϕ,θ)= r·cos(θn−2). (C.9)
Without loss of generality we choose wto be ˜θ=0,˜ϕ=0. Hence the ball /BUγparenleftbig˜wparenrightbig
of radius γis the following set of angles
braceleftbigg
ϕ∈[0,2π],θ∈[0,π]n−2vextendsinglevextendsinglevextendsinglevextendsingleangbracketleftBig
τ(1,ϕ,θ),τparenleftBig
1,˜ϕ, ˜θparenrightBigangbracketrightBig
>1−γ2
2bracerightbigg
=braceleftbigg
ϕ∈[0,2π],θ∈[0,π]n−2vextendsinglevextendsinglevextendsinglevextendsinglecos(θ
n−2)> 1−γ2
2bracerightbigg
=braceleftbigg
ϕ∈[0,2π],θ∈[0,π]n−2vextendsinglevextendsinglevextendsinglevextendsingleθn−2<arccosparenleftbigg
1−γ2
2parenrightbiggbracerightbigg
.
As can be seen from this expression the margin γcharacterizing the ball simply
possesses a restriction on the angle θn−2in the integration. Thus, the quantity of
interest is given by
integraltext2π
0integraltextπ
0···integraltextπ
0vextendsinglevextendsingleJnparenleftbig
r,ϕ,θ 1,...,θ n−2parenrightbigvextendsinglevextendsingledθn−2···dθ1dϕ
integraltext2π
0integraltextπ
0···integraltext/Psi1
0vextendsinglevextendsingleJnparenleftbig
r,ϕ,θ 1,...,θ n−2parenrightbigvextendsinglevextendsingledθn−2···dθ1dϕ, (C.10)
where/Psi1=arccosparenleftbig
1−γ2/2parenrightbig
and Jnis the functional determinant of τgiven by
equation (C.8)–(C.9),
Jn(r,ϕ,θ 1,...,θ n−2)=|Jn|, (C.11)
where the Jacobian matrix Jnis formally deﬁned as
Jndef=
∂τ1(r,ϕ,θ)
∂rvextendsinglevextendsinglevextendsingle
r∂τ1(r,ϕ,θ)
∂ϕvextendsinglevextendsinglevextendsingle
ϕ···∂τ1(r,ϕ,θ)
∂θn−2vextendsinglevextendsinglevextendsingle
θn−2............
∂τn(r,ϕ,θ)
∂rvextendsinglevextendsinglevextendsingle
r∂τn(r,ϕ,θ)
∂ϕvextendsinglevextendsinglevextendsingle
ϕ···∂τn(r,ϕ,θ)
∂θn−2vextendsinglevextendsinglevextendsingle
θn−2
.
IfJn−1=(j1,..., jn−1)∈ /CA(n−1)×(n−1)is the Jacobian matrix for the mapping τ
when applied for points in /CAn−1then we see that
Jn=parenleftbiggsin(θn−2)·Jn−1 r·cos(θn−2)·j1 parenleftbigcos(θn−2)0··· 0parenrightbig
−r·sin(θn−2)parenrightbigg
. (C.12)
Hence the nth row of this matrix contains only two non-zero elements
∂τ n(r,ϕ,θ)
∂rvextendsinglevextendsinglevextendsinglevextendsingle
r=cos(θn−2),∂τ n(r,ϕ,θ)
∂θ n−2vextendsinglevextendsinglevextendsinglevextendsingle
θn−2=− r·sin(θn−2).
308 Appendix C
Now, using the Laplace expansion of (C.11) in the nth row (see Deﬁnition A.64)
we obtain
|Jn|=(−1)n+1cos(θn−2)vextendsinglevextendsingleJ[n,1]vextendsinglevextendsingle−(−1)n+n·rsin(θn−2)vextendsinglevextendsingleJ[n,n]vextendsinglevextendsingle,
where J[i,j]is the(n−1)×(n−1)sub-matrix obtained by deletion of the ith row
and the jth column of Jn. From equation (C.12) and Theorem A.71 it follows thatvextendsinglevextendsingleJ[n,n]vextendsinglevextendsingle=sinn−1(θn−2)·|Jn−1|. Further we know that
vextendsinglevextendsingleJ[n,1]vextendsinglevextendsingle=|(sin(θn−2)·j2,..., sin(θn−2)·jn−1,r·cos(θn−2)·j1)|
=(−1)n−2·|(r·cos(θn−2)·j1,sin(θn−2)·j2,..., sin(θn−2)·jn−1)|
=(−1)n−2·r·cos(θn−2)·sinn−2(θn−2)·|Jn−1|.
Hence,|Jn|is given by
|Jn|=− cos2(θn−2)·r·sinn−2(θn−2)·|Jn−1|−r·sinn(θn−2)·|Jn−1|,
=−|Jn−1|·r·sinn−2(θn−2)parenleftbig
cos2(θn−2)+sin2(θn−2)parenrightbig
=−|Jn−1|·r·sinn−2(θn−2),
which, substituted into equation (C.10) gives
vol(
/CF)
volparenleftbig/BUγ(w)parenrightbig=integraltextπ
0sinn−2(θn−2)dθn−2
integraltext/Psi1
0sinn−2(θn−2)dθn−2, (C.13)
where/Psi1=arccosparenleftbig
1−γ2/2parenrightbig
. The theorem is proved.
C.8.3 A V olume Ratio Bound
In this section we present a practically useful upper bound for the expression given
in equation (C.13). In order to check the usefulness of this expression we havecompared the exact value of (C.13) with the upper bound and found that in theinteresting regime of large margins the bound seems to be within a factor of 2 from
the exact value (see Figure C.5).
Theorem C.15 Fo r a l l j∈/C6and all 0<x≤1
lnparenleftBiggintegraltextπ
0sin2j+1(θ)dθ
integraltext/Psi1(x)
0sin2j+1(θ)dθparenrightBigg
≤lnparenleftbigg1
xparenrightbigg2j+1
+ln(2), (C.14)
where/Psi1(x)=arccos(1−x).
309 Proofs and Derivations—Part II
0.2 0.4 0.6 0.8 1.00 5 10 15 20
xlog volume ratioexact value
bound
0.2 0.4 0.6 0.8 1.00 50 100 150 200
xlog volume ratioexact value
bound
(a) (b)
Figure C.5 Comparison of the bound (C.14) (solid line) with the exact value (C.13)
(dashed line) over the whole range of possible values of xfor (a) n=10 and (b) n=100.
Interestingly, in the relevant regime of large values of xthe bound seems to be very tight
regardless of the number of dimensions.
Proof Without loss of generality, we consider a transformation of the variable
x/mapsto→ 2xwhich implies that the valid range of xequalsparenleftbig
0,1
2bracketrightbig
. From Bois (1961)
we know that, for all j∈ /C6,
integraldisplay
sin2j+1(θ)dθ=−cos(θ)
2j+1jsummationdisplay
i=0sin2i(θ)Bj,i, (C.15)
where
Bj,i=2(i+1)·2(i+2)····· 2j
(2i+1)·(2i+3)·····(2j−1)
=2·4···2j
1·3···(2j−1)·1·3···(2i−1)
2·4···(2i)
=4j(j!)2(2i)!
(2j)!(i!)24i=4j
4iparenleftbig2i
iparenrightbig
parenleftbig2j
jparenrightbig. (C.16)
Let us introduce the abbreviation
S(j,x)=integraldisplayarccos(1−2x)
0sin2j+1(θ)dθ.
310 Appendix C
Then the numerator of (C.14) (after the transformation x/mapsto→ 2x)i sg i v e nb y S(j,1)
whereas the denominator of (C.14) is simply S(j,x). From equation (C.15) we see
S(j,x)=−cos(θ)
2j+1jsummationdisplay
i=0sin2i(θ)Bj,ivextendsinglevextendsinglevextendsinglevextendsinglevextendsinglearccos(1−2x)
0
=4j
(2j+1)parenleftbig2j
jparenrightbigparenleftBigg
1+(2x−1)jsummationdisplay
i=0parenleftbigg2i
iparenrightbigg
xi(1−x)iparenrightBigg
,
where we have used (C.16) and
sin2i(θ)=parenleftbig
sin2(θ)parenrightbigi=parenleftbig
1−cos2(θ)parenrightbigi=parenleftbig
1−(1−2x)2parenrightbigi=parenleftbig
4x−4x2parenrightbigi.
Expanding the ﬁrst term of the sum we obtain for the logarithm of the fraction of
integrals
lnparenleftbiggS(j,1)
S(j,x)parenrightbigg
=lnparenleftBigg
2
2x+(2x−1)summationtextj
i=1parenleftbig2i
iparenrightbig
xi(1−x)iparenrightBigg
.
In Lemma C.20 we show that for any j∈ /C6+and 0≤x<1
2
jsummationdisplay
i=1parenleftbigg2i
iparenrightbigg
xi(1−x)i≤2xparenleftbig
(2x)2j−1parenrightbig
2x−1.
Inserting this into the last expression and taking into account that (2x−1)≤0i n
the relevant regime of xwe obtain
lnparenleftbiggS(j,1)
S(j,x)parenrightbigg
≤ ln
2
2x+(2x−1)2x((2x)2j−1)
(2x−1)
=lnparenleftbigg2
(2x)2j+1parenrightbigg
=−(2j+1)ln(x)+ln(2),
which proves the theorem. Note that in the case of x=1
2the problem reduces to
lnparenleftBigg
S(j,1)
Sparenleftbig
j,1
2parenrightbigparenrightBigg
=−(2j+1)ln(2x)bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
0+ln(2),
which ﬁnalizes the proof.

311 Proofs and Derivations—Part II
C.8.4 Bollmann’s Lemma
In the course of the proof of Theorem C.15 we needed a tight upper bound on the
growth ofsummationtextj
i=1parenleftbig2i
iparenrightbig
xi(1−x)ia saf u n c t i o no f x. In the following we present a
series of lemmas resulting in a reasonably accurate upper bound called Bollmann’s
lemma (Lemma C.20).
Lemma C.16 Fo r a l l i∈ /C6+
parenleftbigg2(i+1)
i+1parenrightbigg
=parenleftbigg2i
iparenrightbiggparenleftbigg
4−2
i+1parenrightbigg
.
Proof A straightforward calculation shows that
parenleftbigg2(i+1)
i+1parenrightbigg
=2(i+1)(2i+1)
(i+1)(i+1)parenleftbigg2i
iparenrightbigg
=parenleftbigg2i
iparenrightbigg4i+2
i+1
=parenleftbigg2i
iparenrightbiggparenleftbigg
4−2
i+1parenrightbigg
.
The lemma is proved.
Lemma C.17 Fo r a l l i∈ /C6+and j∈ /C6+
parenleftbigg2(j+1)
j+1parenrightbiggparenleftbigg2i
iparenrightbigg
≤2parenleftbigg2(i+j)
i+jparenrightbigg
.
Proof We prove the lemma by induction over i.F o r i=1 it follows that
parenleftbigg2(j+1)
j+1parenrightbiggparenleftbigg2
1parenrightbigg
=2parenleftbigg2(j+1)
j+1parenrightbigg
.
Assume the assertion is true for i∈ /C6+.T h e n
parenleftbigg2(j+1)
j+1parenrightbiggparenleftbigg2(i+1)
i+1parenrightbigg
=parenleftbigg2(j+1)
j+1parenrightbiggparenleftbigg2i
iparenrightbiggparenleftbigg
4−2
i+1parenrightbigg
≤ 2parenleftbigg2(i+j)
i+jparenrightbiggparenleftbigg
4−2
i+1parenrightbigg
≤ 2parenleftbigg2(i+j)
i+jparenrightbiggparenleftbigg
4−2
i+j+1parenrightbigg
312 Appendix C
= 2parenleftbigg2(i+j+1)
i+j+1parenrightbigg
,
where we used Lemma C.16 in the ﬁrst and last lines.
Lemma C.18 Fo r a l l 0≤x<1
2
∞summationdisplay
i=1parenleftbigg2i
iparenrightbigg
xi(1−x)i=2x
1−2x.
Proof This can be seen by considering
arcsin(u)= u+∞summationdisplay
i=1parenleftbigg2i
iparenrightbigg1
4iu2i+1
2i+1,
darcsin(u)
du= 1+∞summationdisplay
i=1parenleftbigg2i
iparenrightbigg1
4iu2i=1
√
1−u2.
Using u=2√
x(1−x)we obtain the result, i.e.,
∞summationdisplay
i=1parenleftbigg2i
iparenrightbigg1
4iparenleftBig
2radicalbig
x(1−x)parenrightBig2i
=1
√
1−4x(1−x)−1
∞summationdisplay
i=1parenleftbigg2i
iparenrightbigg
xi(1−x)i=1−√
1−4x(1−x)
√
1−4x(1−x)
=1−radicalbig
(1−2x)2
radicalbig
(1−2x)2.
The lemma is proved.
Lemma C.19 Fo r a l l 0≤x<1
2and j∈ /C6+
4x2∞summationdisplay
i=1parenleftbigg2(i+j)
i+jparenrightbigg
xi+j(1−x)i+j≤∞summationdisplay
i=1parenleftbigg2(i+j+1)
i+j+1parenrightbigg
xi+j+1(1−x)i+j+1.
313 Proofs and Derivations—Part II
Proof Put A(i,j,x)def=summationtext∞
i=1parenleftbig2(i+j)
i+jparenrightbig
xi+j(1−x)i+j. Then the result to be
proven simply reads 4 x2·A(i,j,x)≤A(i,j+1,x). By Lemma C.17 we have
∞summationdisplay
i=1parenleftbigg2i
iparenrightbiggparenleftbigg2(j+1)
j+1parenrightbigg
xi+j(1−x)i+j≤2·A(i,j,x).
Since 0<1−x≤1+2x, by Lemma C.18 it follows that
(1−x)∞summationdisplay
i=1parenleftbigg2i
iparenrightbiggparenleftbigg2(j+1)
j+1parenrightbigg
xi+j(1−x)i+j≤ 2(1+2x)·A(i,j,x),
(1−x)parenleftbigg2(j+1)
j+1parenrightbigg
xj(1−x)j 2x
1−2x≤ 2(1+2x)·A(i,j,x).
Multiplying both sides by1−2x
2(which is, by assumption, positive) yields
parenleftbigg2(j+1)
j+1parenrightbigg
xj+1(1−x)j+1≤parenleftbig
1−4x2parenrightbig
·A(i,j,x).
Rearranging terms gives
4x2·A(i,j,x)≤A(i,j,x)−parenleftbigg2(j+1)
j+1parenrightbigg
xj+1(1−x)j+1=A(i,j+1,x).
The lemma is proved.
Lemma C.20 F or any j∈ /C6+and 0<x<1
2
jsummationdisplay
i=1parenleftbigg2i
iparenrightbigg
xi(1−x)i≤2xparenleftbig
(2x)2j−1parenrightbig
2x−1.
Proof The assertion can be transformed into
jsummationdisplay
i=1parenleftbigg2i
iparenrightbigg
xi(1−x)i≤2xparenleftbig
(2x)2j−1parenrightbig
2x−1
=2xparenleftbig
1−(2x)2jparenrightbig
1−2x
≤2x
1−2x−(2x)2j+1
1−2x
314 Appendix C
≤∞summationdisplay
i=1parenleftbigg2i
iparenrightbigg
xi(1−x)i−(2x)2j+1
1−2x,
which is equivalent to
(2x)2j+1≤(1−2x)∞summationdisplay
i=1parenleftbigg2(i+j)
i+jparenrightbigg
xi+j(1−x)i+j.
We prove this by induction over j.F o r j=1w eh a v e
parenleftbigg2
1parenrightbigg
x(1−x)=2x−2x2≤2x+4x2=8x3−2x
2x−1=2xparenleftbig
(2x)2−1parenrightbig
2x−1.
Assume the assertion is true for j.T h e n
(2x)2(j+1)+1= 4x2(2x)2j+1
≤ 4x2parenleftBigg
(1−2x)∞summationdisplay
i=1parenleftbigg2(i+j)
i+jparenrightbigg
xi+j(1−x)i+jparenrightBigg
≤(1−2x)∞summationdisplay
i=1parenleftbigg2(i+j+1)
i+j+1parenrightbigg
xi+j+1(1−x)i+j+1,
where the second line is assumed to be true and the third line follows from Lemma
C.19. The lemma is proved.
C.9 Algorithmic Stability Bounds
In this section we present the proofs of the main theorems from Section 5.3.In order to enhance the readability of the proofs we use the same notation asintroduced on page 186, that is, given a sample z∈/CIm, a natural number
i∈{1,..., m}a n da ne x a m p l e z∈ /CIlet
z\idef=(z1,..., zi−1,zi+1,..., zm)∈ /CIm−1,
zi↔zdef=(z1,..., zi−1,z,zi+1,..., zm)∈ /CIm,
be the sample with the ith element deleted or the ith element replaced by z,
respectively. Whenever the learning algorithm is clear from the context, we use
fzdef= /BT(z)to denote the hypothesis learned by /BTgiven z∈ /CIm.
315 Proofs and Derivations—Part II
C.9.1 Uniform Stability of Functions Minimizing a Regularized Risk
This subsection proves Theorem 5.31. The proof is mainly taken from Bousquet
and Elisseeff (2000).
Proof of Theorem 5.31. In course of the proof we shall often consider the differ-
ence between the functions fz\iand fzobtained by learning on the reduced training
sample z\iand the full training sample z. Let us denote this difference by /Delta1fdef=parenleftbig
fz\i−fzparenrightbig
. Then we must bound the differencevextendsinglevextendsinglelparenleftbig
fz\i(x),tparenrightbig
−l(fz(x),t)vextendsinglevextendsinglefor
any(x,t)∈ /CI. Using the Lipschitz continuity of lwe know that
vextendsinglevextendsinglelparenleftbig
fz\i(x),tparenrightbig
−l(fz(x),t)vextendsinglevextendsingle≤Cl·vextendsinglevextendsinglefz\i(x)−fz(x)vextendsinglevextendsingle=Cl·|/Delta1f(x)|.
Since we consider a reproducing kernel Hilbert space /BYof real-valued functions
f∈ /CA
/CGwe know that (see also equations (2.36) and (2.37))
|/Delta1f(x)|=|/angbracketleft/Delta1f,k(x,·)/angbracketright|≤/bardbl/Delta1f/bardbl·k(x,x). (C.17)
Thus, it sufﬁces to have an upper bound on /bardbl/Delta1f/bardbl. We shall show shortly that
/bardbl/Delta1f/bardbl2≤Cl
2λm|/Delta1f(xi)|which, together with the last inequality implies that
/bardbl/Delta1f/bardbl2≤Cl
2λm|/Delta1f(xi)|≤Cl
2λm/bardbl/Delta1f/bardbl·k(xi,xi)⇔/bardbl/Delta1f/bardbl≤Cl
2λm·k(xi,xi).
Resubstituting this expression into equation (C.17) gives
vextendsinglevextendsinglelparenleftbig
fz\i(x),tparenrightbig
−l(fz(x),t)vextendsinglevextendsingle≤Cl·/bardbl/Delta1f/bardbl·k(x,x)≤C2
lκ2
2λm,
whereκis deﬁned by κ=supx∈ /CGk(x,x). It remains to prove the upper bound
on the/bardbl/Delta1f/bardbl2. At ﬁrst we exploit the fact that fz\iand fzare the minimizers of
equation (5.19) for the two different training samples z\i∈ /CIm−1and z∈ /CIm,
respectively. Formally this reads
Rreg[fz,z]−Rreg[fz+η·/Delta1f]≤0,Rregbracketleftbig
fz\i,z\ibracketrightbig
−Rregbracketleftbig
fz\i−η·/Delta1fbracketrightbig
≤0,
where we assume η∈(0,1)and Rregis deﬁned by
Rreg[f,z]=1
msummationdisplay
(xi,ti)∈zl(f(xi),ti)
bracehtipupleft
bracehtipdownrightbracehtipdownleft
bracehtipupright
Rm[f,z]+λ/bardblf/bardbl2.
316 Appendix C
Adding the above two inequalities and exploiting Rreg[f,z]= Rregbracketleftbig
f,z\ibracketrightbig
+
1
ml(f(xi),ti)we obtain
1
m(l(fz(xi),ti)−l((fz+η·/Delta1f)(xi),ti))+λ·A≤B, (C.18)
where Aand Bare given by
A=/bardblfz/bardbl2+vextenddoublevextenddoublefz\ivextenddoublevextenddouble2−/bardblfz+η·/Delta1f/bardbl2−vextenddoublevextenddoublefz\i−η·/Delta1fvextenddoublevextenddouble2,
B=Rmbracketleftbig
fz+η/Delta1 f,z\ibracketrightbig
+Rmbracketleftbig
fz\i+η/Delta1 f,z\ibracketrightbig
−Rmbracketleftbig
fz,z\ibracketrightbig
−Rmbracketleftbig
fz\i,z\ibracketrightbig
.
Using the deﬁnition of /Delta1fallows us to determine Adirectly
A= 2ηparenleftbig
−/angbracketleftfz,/Delta1 f/angbracketright+angbracketleftbig
fz\i,/Delta1 fangbracketrightbig
−η/bardbl/Delta1f/bardbl2parenrightbig
= 2ηparenleftbigangbracketleftbig
fz\i−fz,/Delta1 fangbracketrightbig
−η/bardbl/Delta1f/bardbl2parenrightbig
=2η(1−η)/bardbl/Delta1f/bardbl2.
Since the loss function lis assumed to be convex in its ﬁrst argument we know that
for all(x,t)∈ /CIand allη∈(0,1)
l((fz+η·/Delta1f)(x),t)−l((fz)(x),t)≤η·parenleftbig
lparenleftbigparenleftbig
fz\iparenrightbig
(x),tparenrightbig
−l((fz)(x),t)parenrightbig
.
This implies that the following two inequalities hold true
Rmbracketleftbig
fz+η/Delta1 f,z\ibracketrightbig
−Rmbracketleftbig
fz,z\ibracketrightbig
≤ηparenleftbig
Rmbracketleftbig
fz\i,z\ibracketrightbig
−Rmbracketleftbig
fz,z\ibracketrightbigparenrightbig
,
Rmbracketleftbig
fz\i−η/Delta1 f,z\ibracketrightbig
−Rmbracketleftbig
fz\i,z\ibracketrightbig
≤ηparenleftbig
Rmbracketleftbig
fz,z\ibracketrightbig
−Rmbracketleftbig
fz\i,z\ibracketrightbigparenrightbig
.
Adding these two inequalities shows that B≤0. Using the Lipschitz continuity of
the loss we see that equation (C.18) can be written as
/bardbl/Delta1f/bardbl2≤l((fz+η·/Delta1f)(xi),ti)−l(fz(xi),ti)
2η(1−η)λm
≤Cl·|(fz+η·/Delta1f)(xi)−fz(xi)|
2η(1−η)λm=Cl
2(1−η)λm|/Delta1f(xi)|.
Taking the limit of the latter expression for η→ 0s h o w st h a t /bardbl/Delta1f/bardbl2≤
Cl
2λm|/Delta1f(xi)|which completes the proof.
C.9.2 Algorithmic Stability Bounds
In this subsection we prove Theorem 5.32. We start with some simple lemmas
which help us to structure the main proof.
317 Proofs and Derivations—Part II
Lemma C.21 Let /BT:∪∞
m=1
/CIm→ /BYbe aβm–stable learning algorithm w.r .t. a
loss function l : /CA× /CA→ /CA. Then we have
EZmbracketleftbig
R[fZ]−Rempbracketleftbig
fZ,Zbracketrightbigbracketrightbig
≤2βm, EZmbracketleftbig
R[fZ]−Rloobracketleftbig/BT,Zbracketrightbigbracketrightbig
≤βm.
Proof By the independence of the training sample z∈ /CImfrom the test example
z=(x,t)∈ /CIwe note that the expectation EZmbracketleftbig
R[fZ]−Rempbracketleftbig
fZ,Zbracketrightbigbracketrightbig
can be
rewritten as
1
mmsummationdisplay
i=1integraldisplay/CImintegraldisplay/CIl(fz(x),t)−lparenleftbig
fzi↔(x,t)(x),tparenrightbig
bracehtipupleft
 bracehtipdownrightbracehtipdownleft
 bracehtipupright
q(z,(x,t))dFZ((x,t))dFZm(z).
By virtue of Theorem 5.27, for any i∈{1,..., m}the integrand q(z,(x,t))is
upper bounded by 2 βmthanks to the βm–stability of the learning algorithm /BT.
This proves the ﬁrst assertion. Similarly, for the second assertion we know thatE
Zmbracketleftbig
R[fZ]−Rloobracketleftbig/BT,Zbracketrightbigbracketrightbig
can be written as
1
mmsummationdisplay
i=1integraldisplay/CImintegraldisplay/CIl(fz(x),t)−lparenleftbig
fz\i(xi),tiparenrightbig
dFZ((x,t))dFZm(z).
Since, for any i∈{1,..., m}, the example zi=(xi,ti)is not used in ﬁnding fz\i
but has the same distribution as z=(x,t)the latter expression equals
1
mmsummationdisplay
i=1integraldisplay/CImintegraldisplay/CIl(fz(x),t)−lparenleftbig
fz\i(x),tparenrightbig
bracehtipupleft
bracehtipdownrightbracehtipdownleft
 bracehtipupright
q(z,(x,t))dFZ((x,t))dFZm(z).
By assumption /BTis aβm–stable algorithm w.r.t. lwhich implies that the integrand
is bounded from above by βm. The lemma is proved.
Lemma C.22 Let /BT:∪∞
m=1
/CIm→ /BYbe aβm–stable learning algorithm w.r .t. a
given loss function l : /CA× /CA→ [0,b]. Then, for any i ∈{1,..., m}, we have
sup
z∈ /CIm,˜z∈ /CIvextendsinglevextendsingleR[fz]−Rbracketleftbig
fzi↔˜zbracketrightbigvextendsinglevextendsingle≤ 2βm,
sup
z∈ /CIm,˜z∈ /CIvextendsinglevextendsingleRemp [fz,z]−Rempbracketleftbig
fzi↔˜z,zi↔˜zbracketrightbigvextendsinglevextendsingle≤ 2βm+b
m,
sup
z∈ /CIm,˜z∈ /CI|Rloo[
/BT,z]−Rloo[
/BT,zi↔˜z]|≤ 2βm−1+b
m.
318 Appendix C
Proof The ﬁrst assertion follows directly from Theorem 5.27 noticing that, by the
βm–stability of /BT,f o ra l l z∈ /CIm,a l l˜z∈ /CIand all i∈{1,..., m}
vextendsinglevextendsingleR[fz]−Rbracketleftbig
fzi↔˜zbracketrightbigvextendsinglevextendsingle≤EXTbracketleftbigvextendsinglevextendsinglel(fz(X),T)−lparenleftbig
fzi↔˜z(X),Tparenrightbigvextendsinglevextendsinglebracketrightbig
≤2βm.
In order to prove the second assertion we note that, for all i∈{1,..., m},
Remp [fz,z]=m−1
mRempbracketleftbig
fz,z\ibracketrightbig
+1
ml(fz(xi),ti).
Rempbracketleftbig
fzi↔˜z,zi↔˜zbracketrightbig
=m−1
mRempbracketleftbig
fzi↔˜z,z\ibracketrightbig
+1
mlparenleftbig
fzi↔˜z(˜x),˜tparenrightbig
.
As, by assumption, /BTis aβm–stable algorithm, using Theorem 5.27 shows thatvextendsinglevextendsingleRempbracketleftbig
fz,z\ibracketrightbig
−Rempbracketleftbig
fzi↔˜z,z\ibracketrightbigvextendsinglevextendsinglecannot exceed 2 βm. Further, by the ﬁniteness
of the loss function lit follows that
vextendsinglevextendsingleRemp [fz,z]−Rempbracketleftbig
fzi↔˜z,zi↔˜zbracketrightbigvextendsinglevextendsingle≤2m−1
mβm+b
m<2βm+b
m.
The proof of the ﬁnal assertion is analogous and exploiting that, for all i∈
{1,..., m}
Rloo[
/BT,z]=1
mmsummationdisplay
j=1
j/negationslash=ilparenleftbig
fz\jparenleftbig
xjparenrightbig
,tjparenrightbig
+1
mlparenleftbig
fz\i(xi),tiparenrightbig
,
Rloo[
/BT,zi↔˜z]=1
mmsummationdisplay
j=1
j/negationslash=ilparenleftBig
fz(i↔˜z)\jparenleftbig
xjparenrightbig
,tjparenrightBig
+1
mlparenleftbig
fz\i(˜x),˜tparenrightbig
.
Taking into account that fz\jis obtained by learning using a training sample of size
m−1 the third statement of the lemma follows immediately.
Using these two lemmas allows us to present the proof of Theorem 5.32.
Proof of Theorem 5.32. Let us start with the ﬁrst equation involving the training
error Remp [fz,z]. To this end we deﬁne the function g(Z)=R[fZ]−Rempbracketleftbig
fZ,Zbracketrightbig
of the mrandom variables Z1,..., Zm. By Lemma C.22 we know that for all
i∈{1,..., m}
sup
z∈ /CIm,˜z∈ /CI|g(z)−g(zi↔˜z)|≤4βm+b
m,
319 Proofs and Derivations—Part II
because the difference
|g(z)−g(zi↔˜z)|=vextendsinglevextendsingleR[fz]−Remp [fz,z]−parenleftbig
Rbracketleftbig
fzi↔˜zbracketrightbig
−Rempbracketleftbig
fzi↔˜z,zi↔˜zbracketrightbigparenrightbigvextendsinglevextendsingle
is bounded from above by the sum of the two termsvextendsinglevextendsingleR[fz]−Rbracketleftbig
fzi↔˜zbracketrightbigvextendsinglevextendsingleandvextendsinglevextendsingleRemp [fz,z]−Rempbracketleftbig
fzi↔˜z,zi↔˜zbracketrightbigvextendsinglevextendsingledue to the triangle inequality. Further, by
Lemma C.21 we know
g(z)>ε+2βm⇒ g(z)>ε+EZmbracketleftbig
g(Z)bracketrightbig
.
Thus, using McDiarmid’s inequality given in Theorem A.119 shows thatP
Zm(g(Z)>ε+2βm)≤ PZmparenleftbig
g(Z)−EZmbracketleftbig
g(Z)bracketrightbig
>εparenrightbig
< expparenleftbigg
−mε2
2(4mβm+b)2parenrightbigg
.
The proof for the case of the leave-one-out error Rloo[
/BT,z]is analogous: If we
deﬁne the function g(Z)= R[fZ]−Rloobracketleftbig/BT,Zbracketrightbig
of the mrandom variables
Z1,..., Zmthen, by Lemma C.22, for all i∈{1,..., m},
sup
z∈ /CIm,˜z∈ /CI|g(z)−g(zi↔˜z)|≤2(βm+βm−1)+b
m.
In addition, by Lemma C.21 we have that
g(z)>ε+βm⇒ g(z)>ε+EZmbracketleftbig
g(Z)bracketrightbig
.
The result follows again by an application of McDiarmid’s inequality to g(Z).

D Pseudocodes
This section contains all the pseudocodes of the algorithms introduced in the book.
A set of implementations in R(a publicly available version of S-PLUS ) can be
found at http://www.kernel-machines.org/ .
D.1 Perceptron Algorithm
Algorithm 1 Perceptron learning algorithm (in primal variables).
Require: A feature mapping φ: /CG→ /C3⊆/lscriptn
2
Ensure: A linearly separable training sample z=((x1,y1),...,(xm,ym))
w0=0;t=0
repeat
for j=1,..., mdo
ifyjangbracketleftbig
φparenleftbig
xjparenrightbig
,wangbracketrightbig
≤0then
wt+1=wt+yjφparenleftbig
xjparenrightbig
t← t+1
end if
end for
until no mistakes have been made within the for loop
return the ﬁnal weight vector wt
This section contains three different implementations of the classical percep-
tron algorithm (see Rosenblatt (1958)) which differ by the representation used forthe weight vector (Algorithms 1 and 2). The dual algorithm 2 can be sped up bycaching the real-valued outputs of the temporary solutions (Algorithm 3).
322 Appendix D
Algorithm 2 Perceptron learning algorithm (in dual variables).
Require: A feature mapping φ: /CG→ /C3⊆/lscriptn
2
Ensure: A linearly separable training sample z=((x1,y1),...,(xm,ym))
α=0
repeat
for j=1,..., mdo
ifyjsummationtextm
i=1αiangbracketleftbig
φ(xi),φparenleftbig
xjparenrightbigangbracketrightbig
≤0then
αj←αj+yj
end if
end for
until no mistakes have been made within the for loop
return the vector αof expansion coefﬁcients
Algorithm 3 Kernel perceptron learning algorithm (optimized).
Require: A kernel function k: /CG× /CG→ /CA
Ensure: A linearly separable training sample z=((x1,y1),...,(xm,ym))
o=α=0
repeat
for j=1,..., mdo
ifyjoj≤0then
αj←αj+yj
for i=1,..., mdo
oi← oi+yjkparenleftbig
xj,xiparenrightbig
end for
end if
end for
until no mistakes have been made within the for loop
return the vector αof expansion coefﬁcients

323 Pseudocodes
D.2 Support V ector and Adaptive Margin Machines
In the following subsections we give the pseudocode for support vector machines
and adaptive margin machines. We assume access to a solver for the quadraticprogramming problem which computes the solution vector x
∗to the following
problem
minimize1
2x/primeHx+c/primex
subject to A1x=b1.
A2x≤b2,
l≤x≤u. (D.1)
Packages that aim to solving these type of problem are, for example MINOS
(Murtagh and Saunders 1993), LOQO (V anderbei 1994) or CPLEX (CPLEX Op-timization Inc. 1994). An excellent introduction to the problem of mathematicalprogramming is given in Hadley (1962), Hadley (1964) and V anderbei (1997). We
used the PR LOQO package
1of A. Smola together with R, which is a publicly
available version of S-PLUS , for all experiments.
D.2.1 Standard Support V ector Machines
For the standard SVM with box constraints 0≤α≤1
2λ1we set
x=α,
H= YGY⇔ Hij=yiyjkparenleftbig
xi,xjparenrightbig
,
c=− 1m,
l= 0m,
u=1
2λm1m.
We obtain hard margin SVMs for λ→ 0 (in practice we used λm=10−20). In the
case of quadratic margin loss we apply a hard margin SVM with the diagonal of H
additively correct by λm·1(see Subsection 2.4.2).
1 Publicly available at http://www.kernel-machines.org/ .
324 Appendix D
D.2.2ν–Support V ector Machines
For theν- S V M sw es e t
x=α,
H= YGY⇔ Hij=yiyjkparenleftbig
xi,xjparenrightbig
,
c= 0m,
A2=− 1/prime
m,
b2=−ν,
l= 0m,
u=1
m1m.
D.2.3 Adaptive Margin Machines
Finally, in the case of Adaptive Margin Machines we set the variables as follows:
x=parenleftbiggα
ξparenrightbigg
, c=parenleftbigg0m
1mparenrightbigg
,
H= 02m,2m,
A2=parenleftbig
−YtildewideGY,−Imparenrightbig
,
b2=− 1m,
l=parenleftbigg
0m
0mparenrightbigg
,
where the m×mmatrixtildewideGis given by
tildewideGij=braceleftbigg
kparenleftbig
xi,xjparenrightbig
ifi/negationslash=j
kparenleftbig
xi,xjparenrightbig
−λ ifi=j.
325 Pseudocodes
D.3 Gaussian Processes
In this section we give the pseudocode for both Bayesian linear regression (Al-
gorithm 4) and Bayesian linear classiﬁcation (Algorithm 5). These algorithms arealso an implementation of Gaussian processes for regression and classiﬁcation.Note that the classiﬁcation algorithm is obtained by using a Laplace approxima-tion to the true posterior density f
Tm+1|X=x,Zm=z. For a Markov-Chain Monte-Carlo
implementation see Neal (1997b).
Algorithm 4 Gaussian processes regression estimation.
Require: A variance on the outputs σ2
t∈ /CA+
Require: A feature mapping φ: /CG→ /C3⊆/lscriptn
2
Require: A training sample z=((x1,t1),...,(xm,tm))∈(
/CG× /CA)m
G=parenleftBigparenleftbigangbracketleftbig
φ(xi),φparenleftbig
xjparenrightbigangbracketrightbigparenrightbigm
i,j=1+σ2
tImparenrightBig
∈ /CAm×m
α=G−1t
return the vector αof expansion coefﬁcients
With respect to Algorithm 5, it is advantageous to solve the equation H/Delta1=g
for/Delta1rather than explicitly computing the inverse H−1and carrying out the matrix-
vector product as shown in the inner loop in the pseudocode. Many softwarepackages would provide numerically stable algorithms such as Gauss-Jordan de-composition for solving systems of linear equations. Further note that we useπ(t)=1/(1+exp(−t))which equals (see Section B.7)
π(t)=exp(t)
1+exp(t)=exp(t)·exp(−t)
(1+exp(t))·exp(−t)=1
1+exp(−t)
but whose computation is much more stable as exp (−t)≈0 for moderately large
values of t.
D.4 Relevance V ector Machines
In this section we give the pseudocode for relevance vector machines—both in the
regression estimation (Algorithm 6) and classiﬁcation scenario (Algorithm 7). Inorder to unburden the algorithms we use the notation w
[n]to refer to the vector
326 Appendix D
Algorithm 5 Gaussian processes classiﬁcation using the Laplace approximation.
Require: A variance on the latent variables σ2
t∈ /CA+and a noise level β∈ /CA+
Require: A feature mapping φ: /CG→ /C3⊆/lscriptn
2
Require: A training sample z=((x1,y1),...,(xm,ym))∈(
/CG×{−1,+1})m
Require: A tolerance criterion TOL ∈(0,1)
G=1
β·parenleftBigparenleftbigangbracketleftbigφ(xi),φparenleftbigxjparenrightbigangbracketrightbigparenrightbigm
i,j=1+σ2
tImparenrightBig
∈ /CAm×m
α=0;t=Gα
J=1
2(y+1)/primet−summationtextm
i=1ln(1+exp(ti))−1
2α/primeGα
repeat
π=parenleftbig
(1+exp(−t1))−1,...,(1+exp(−tm))−1parenrightbig/prime
g=1
2(y+1)−π−α
H=−(diag(π1(1−π1),...,π m(1−πm))G+I)
/Delta1=H−1g,η=1
repeat
˜α=α−η/Delta1;˜t=G˜α
tildewideJ=1
2(y+1)/prime˜t−summationtextm
i=1lnparenleftbig
1+expparenleftbig˜tiparenrightbigparenrightbig
−1
2˜α/primeG˜α
η←η
2
untiltildewideJ>J
α=˜α,J=tildewideJ,t=˜t
until/bardblg/bardbl
m<TOL
return the vector αof expansion coefﬁcients
parenleftbig
wn1,...,w n|n|parenrightbig
obtained from wby arranging those components indexed by n=parenleftbig
n1,..., n|n|parenrightbig
. As an example consider w=(w1,...,w 10)and n=(1,3,6,10)
which gives w[n]=(w1,w 3,w 6,w 10). We have given the two algorithms in a
form where we delete feature φiif the associated hyper-parameter θifalls below
a prespeciﬁed tolerance, which should be close to the maximal precision of the
computer used. This is necessary because, otherwise, the inversion of /Sigma1would be
an ill-posed problem and would lead to numerical instabilities. We can monitorconvergence of the algorithm for classiﬁcation learning by inspecting the value
Jwhich should only be increasing. In contrast, when considering the regression
estimation case we should use the Cholesky decomposition of the matrix /Sigma1
−1to
efﬁciently compute the evidence. The Cholesky decomposition of the matrix /Sigma1−1is
given by /Sigma1−1=R/primeRwhere Ris an upper triangular matrix (see Deﬁnition A.55).
The advantage of this decomposition is that /Sigma1=R−1parenleftbig
R−1parenrightbig/primeby virtue of Theorem
A.77. Further, having such a decomposition simpliﬁes the task of computing the
327 Pseudocodes
determinant as (see Theorems A.15 and A.66)
lnparenleftbigvextendsinglevextendsingle/Sigma1−1vextendsinglevextendsingleparenrightbig
=lnparenleftbigvextendsinglevextendsingleR/primeRvextendsinglevextendsingleparenrightbig
=lnparenleftbigvextendsinglevextendsingleR/primevextendsinglevextendsingleparenrightbig
+ln(|R|)=2nsummationdisplay
i=1ln(Rii).
For a more detailed treatment of numerical issues in matrix algebra the interested
reader is referred to Golub and van Loan (1989) and Press et al. (1992). Thesealgorithms can also be applied to the expansion coefﬁcients α∈/CAmin a kernel
classiﬁer model hα(or kernel regression model fα)
fα(x)=msummationdisplay
i=1αik(xi,x), hα(x)=signparenleftBiggmsummationdisplay
i=1αik(xi,x)parenrightBigg
.
The only difference between the algorithms is that wmust be replaced by αand X
needs to be replaced by G=parenleftbig
kparenleftbig
xi,xjparenrightbigparenrightbigm,m
i,j=1∈ /CAm×m. It is worth mentioning that,
in principle, any function k: /CG× /CG→ /CAcould be used, that is, not only symmetric
positive semideﬁnite functions corresponding to Mercer kernels are allowed.
Algorithm 6 Regression estimation with relevance vector machines.
Require: A data matrix X∈ /CAm×nand mreal-valued outputs t∈ /CAm
Require: A vector θ∈parenleftbig/CA+parenrightbignand a variance σ2
t∈ /CA+
Require: The maximum number of iterations, imax; a tolerance for pruning TOL ∈ /CA+
for i=1,..., imax do
n=parenleftbig
j∈{1,..., n}vextendsinglevextendsingleθj>TOLparenrightbig
(all non-pruned indices)
tildewideX∈ /CAm×|n|contains the|n|columns from Xindexed by n
˜θ=θ[n]
/Sigma1=parenleftBig
σ−2
ttildewideX/primetildewideX+diagparenleftBig
˜θ−1
1,...,˜θ−1
|n|parenrightBigparenrightBig−1
w[n]=σ−2
t/Sigma1tildewideX/primet
ζ=1−parenleftBig
˜θ−1
1·/Sigma111,...,˜θ−1
|n|·/Sigma1|n|,|n|parenrightBig/prime
θnj=w2
nj
ζjfor all j∈{1,...,|n|}
σ2
t=vextenddoublevextenddoublet−tildewideXw [n]vextenddoublevextenddouble2
m−ζ/prime1
end for
return the weight vector w

328 Appendix D
Algorithm 7 Classiﬁcation learning with relevance vector machines.
Require: A data matrix X∈ /CAm×nand mclasses y∈{−1,+1}m
Require: A vector θ∈parenleftbig/CA+parenrightbign
Require: The maximum number of iterations, imax; a tolerance for pruning TOL ∈ /CA+
w=0
for i=1,..., imax do
n=parenleftbigj∈{1,..., n}vextendsinglevextendsingleθj>TOLparenrightbig(all non-pruned indices)
tildewideX∈ /CAm×|n|contains the|n|columns from Xindexed by n
˜θ=θ[n];/Theta1−1=diagparenleftBig
˜θ−1
1,...,˜θ−1
|n|parenrightBig
;t=tildewideXw [n]
J=1
2(y+1)/primet−summationtextm
i=1ln(1+exp(ti))−1
2w/prime
[n]/Theta1−1w[n]
repeat
π=parenleftbig
(1+exp(−t1))−1,...,(1+exp(−tm))−1parenrightbig/prime
g=tildewideX/primeparenleftBig
1
2(y+1)−πparenrightBig
−/Theta1−1w[n]
H=−parenleftbigtildewideX/prime·diag(π1(1−π1),...,π m(1−πm))·tildewideX+/Theta1−1parenrightbig
/Delta1=H−1g,η=1
repeat
˜w=w;˜w[n]=w[n]−η/Delta1;˜t=tildewideX˜w[n]
tildewideJ=1
2(y+1)/prime˜t−summationtextm
i=1lnparenleftbig
1+expparenleftbig˜tiparenrightbigparenrightbig
−1
2˜w/prime
[n]/Theta1−1˜w[n]
η←η
2
untiltildewideJ>J
w=˜w;J=tildewideJ;t=˜t
until/bardblg/bardbl
|n|<TOL
/Sigma1=− H−1
ζ=1−parenleftBig
˜θ−1
1·/Sigma111,...,˜θ−1
|n|·/Sigma1|n|,|n|parenrightBig/prime
θni=w2
ni
ζifor all i∈{1,...,|n|}
end for
return the weight vector w

329 Pseudocodes
D.5 Fisher Discriminants
In this section we present the Fisher discriminant algorithm both in primal and
dual variables (Algorithms 8 and 9). As mentioned earlier, when computing w=
ˆ/Sigma1−1parenleftbig
ˆµ+1−ˆµ−1parenrightbig
it is advantageous to solve ˆ/Sigma1w=parenleftbig
ˆµ+1−ˆµ−1parenrightbig
for winstead.
Many software packages would provide numerically stable algorithms such asGauss-Jordan decomposition for solving systems of linear equations. Note that we
have included the estimated class probabilities P
Y(y)in the construction of the
offset b.
Algorithm 8 Fisher discriminant algorithm (in primal variables).
Require: A feature mapping φ: /CG→ /C3⊆/lscriptn
2
Require: A training sample z=((x1,y1),...,(xm,ym))
Determine the numbers m+1and m−1of samples of class +1a n d−1
ˆµ+1=1
m+1summationtext
(xi,+1)∈zφ(xi);ˆµ−1=1
m−1summationtext
(xi,−1)∈zφ(xi)
ˆ/Sigma1=1
mparenleftbiggmsummationtext
i=1φ(xi)(φ(xi))/prime−m+1ˆµ+1ˆµ/prime
+1−m−1ˆµ−1ˆµ/prime
−1parenrightbigg
w= ˆ/Sigma1−1parenleftbigˆµ+1−ˆµ−1parenrightbig
b=1
2parenleftBig
ˆµ/prime
−1ˆ/Sigma1−1ˆµ−1−ˆµ/prime
+1ˆ/Sigma1−1ˆµ+1parenrightBig
+lnparenleftBig
m+1
m−1parenrightBig
return the weight vector w∈ /CAnand the offset b∈ /CA
Algorithm 9 Fisher discriminant algorithm (in dual variables).
Require: A training sample z=((x1,y1),...,(xm,ym))
Require: A kernel function k: /CG× /CG→ /CAand a regularization parameter λ∈ /CA+
Determine the numbers m+1and m−1of samples of class +1a n d−1
G=parenleftbig
kparenleftbig
xi,xjparenrightbigparenrightbigm,m
i,j=1∈ /CAm×m
k+1=1
m+1Gparenleftbig
Iy1=+ 1,..., Iym=+ 1parenrightbig/prime;k−1=1
m−1Gparenleftbig
Iy1=− 1,..., Iym=− 1parenrightbig/prime
S=1
mparenleftbigGG−m+1k+1k/prime
+1−m−1k−1k/prime
−1parenrightbig+λIm
α=S−1(k+1−k−1)
b=1
2parenleftbig
k/prime
−1S−1k−1−k/prime
+1S−1k+1parenrightbig
+lnparenleftBigm+1
m−1parenrightBig
return the vector αof expansion coefﬁcients and the offset b∈ /CA

330 Appendix D
D.6 Bayes Point Machines
This section contains the pseudocode of the kernel billiard for computing the
Bayes point (Algorithm 10). In the course of the algorithm’s implementation wesometimes need normalized vectors β
norm of the vector βof expansion coefﬁcients
found by,
βnorm=1
summationtextm
i=1summationtextm
j=1βiβjkparenleftbig
xi,xjparenrightbigβ. (D.2)
Algorithm 10 Kernel billiard algorithm (in dual variables).
Require: A tolerance criterion TOL ∈[0,1] andτmax∈ /CA+
Require: A training sample z=((x1,y1),...,(xm,ym))∈(
/CG×{−1,+1})m
Require: A kernel function k: /CG× /CG→ /CA
Ensure: for all i∈{1,..., m},yisummationtextm
j=1γjkparenleftbigxi,xjparenrightbig>0
α=0;β=random; normalize βusing (D.2)
/Xi1=ξmax=0;pmin=1
whileρ2(pmin,/Xi1/(/Xi1+ξmax))>TOL do
repeat
for i=1,..., mdo
di=yisummationtextm
j=1γjkparenleftbig
xj,xiparenrightbig
;νi=yisummationtextm
j=1βjkparenleftbig
xj,xiparenrightbig
;τi=− di/νi
end for
c/prime=argmini:τi>0τi
ifτc/prime≥τmax then
β=random, but ycsummationtextm
j=1βjkparenleftbig
xj,xcparenrightbig
>0; normalize βusing (D.2)
else
c=c/prime
end if
untilτc/prime<τ max
˜γ=γ+τcβ; normalize ˜γusing (D.2); βc=βc−2νcyc/k(xc,xc)
ζ=γ+˜γ; normalize ζusing (D.2)
ξ=radicalBig
summationtextm
i=1summationtextm
j=1(γi−˜γi)parenleftbig
γj−˜γjparenrightbig
kparenleftbig
xi,xjparenrightbig
p=summationtextm
i=1summationtextm
j=1ζiαjkparenleftbig
xi,xjparenrightbig
α=ρ1parenleftBig
p,/Xi1
/Xi1+ξparenrightBig
α+ρ2parenleftBig
p,/Xi1
/Xi1+ξparenrightBig
ζ
pmin=min(p,pmin);ξmax=max(ξ,ξ max);/Xi1=/Xi1+ξ;γ= ˜γ
end whilereturn the vector αof expansion coefﬁcients

List of Symbols
Whenever possible, the third column gives a pointer to the page of ﬁrst occurrence
or deﬁnition.
Symbol meaning page
/angbracketleft·,·/angbracketright inner product 217
/bardbl·/bardblp /lscriptp–norm 216
|A| determinant of the matrix A 225
A[ij] matrix obtained from Aby deletion of the ith
row and jth column225
⊗ Kronecker product 236
def= the l.h.s. is deﬁned by the r.h.s
0 vector of zeros 215
1 vector of ones 215
∧ logical “and”
∨ logical “or”
¬ logical “not”
A
/BT learning algorithm 24/BTERM empirical risk minimization algorithm 26/BT/Omega1 structural risk minimization algorithm 29/BTε bound minimization learning algorithm 136/BT/CD on-line learning algorithm 182
α∈ /CAmlinear expansion coefﬁcients of the weight
vector w32
332 List of Symbols
B
/BUn Borel sets over /CAn200/BUτ(x) open ball of radius τaround x 217
/BUτ(x) closed ball of radius τaround x 217
Bayes z Bayes classiﬁcation strategy 80
Bayes H(z) generalized Bayes classiﬁcation
strategy168
C
C∈ /CA2×2cost matrix 22
Cov(X,Y) covariance between XandY 203
Cov(X,Y) covariance matrix for Xand Y 203/BV(z) compression function 176
χ model parameter(s) 65
D
δ∈(0,1] conﬁdence level/BW model space 79
E
EXbracketleftbig
Xbracketrightbig
expectation of X 201
ε∈ /CA deviation or generalization error bound 122
ei ith unit vector 223/BX(z) estimator for a probability measure PZgiven
the sample z∈ /CIm117
e(d) dyadic entropy number 143
/epsilon1A(d) entropy number of A 222
333 List of Symbols
F
φi: /CG→ /CA feature on /CG 19
φ: /CG→ /C3 feature mapping 19/BY⊆ /CA
/CGreal-valued function space 21
fw: /CG→ /CA real-valued function 20
fz: /CG→ /CA real-valued function learned from z∈ /CIm186
f∗: /CG→ /CA optimal real-valued function 21
ˆf: /CG→ /CA real-valued function in a cover Fγ(x) 141
Fγ(x)⊂ /BY cover of /BYgiven the sample x 141
FX distribution function 201
fθ Fisher score at θ 45
fX density of the random variable X 201
fat/BY(γ) fat shattering dimension at scale γ 147
ϕA(d) inner entropy number 222
G
G∈ /CAm×mGram matrix 33
γi(w) geometrical margin of watzi 50
γz(w) geometrical margin of won the training set z 50
˜γi(w) functional margin of watzi 50
˜γz(w) functional margin of won the training set z 50
Gibbs z Gibbs classiﬁcation strategy 81
Gibbs H(z) generalized Gibbs classiﬁcation strategy 166
H
/C0⊆ /CH
/CGhypothesis space 19, 21
h: /CG→ /CH hypothesis 19
hw: /CG→ /CH binary hypothesis 20
hθ: /CG→ /CH induced classiﬁer for a given probabilitymodel P
Z|Q=θ116
h∗: /CG→ /CH optimal hypothesis 118
334 List of Symbols
I
I indicator function 200
I Fisher information matrix 45
i index vector 38, 41
Iv,u set of index vectors for vinu 41
Id,m set of index vectors 176
K
/C3⊆/lscriptn
2 feature (kernel) space 19
k(x,˜x) kernel value between x,˜x∈ /CG 32
K∈ /CAm×mkernel matrix 33
L
/lscriptn
2⊆ /CAnspace of square summable sequences of
length n218
/lscriptL(z,h) level of hgiven z 136
L2 space of square integrable functions 218
(λi)i∈ /C6 sequence of eigenvalues 35
lparenleftbig
ˆy,yparenrightbig
loss between ˆyand y 21
l0−1parenleftbig
ˆy,yparenrightbig
zero-one loss between ˆyand y 22
lCparenleftbig
ˆy,yparenrightbig
cost matrix loss between ˆyand y 23
lmargin(t) margin loss of t 52
llinparenleftbigˆt,yparenrightbig
linear soft margin loss between ˆtand y 54
lquadparenleftbigˆt,yparenrightbig
quadratic soft margin loss between
ˆtand y54
lεparenleftbigˆt,tparenrightbig
ε–insensitive loss between ˆtand t 59
l2parenleftbigˆt,tparenrightbig
squared loss 82/C4(θ) likelihood of the parameter θ 75
L(z,h) luckiness of hgiven z 136
ln(·) natural logarithm
ld(·) logarithm to base 2
335 List of Symbols
M
m training sample size 18/C5⊆/lscriptn
2 Mercer space 35/C5ρ
A(ε) packing number at scale ε 220
M/BT(z) mistake bound for /BT 183
N
/C6 natural numbers
n dimension of feature space 19
N dimension of input space 38/C6ρ
A(ε) covering number at scale ε 220/C6/C0(z) empirical covering number at zfor binary-
valued functions285/C6/C0(m) worst case covering number for binary-valued
functions286/C6∞/BY(γ,x) empirical covering number of /BYat scaleγ 141/C6∞/BY(γ,m) (worst case) covering number of /BYat scaleγ 141
ν fraction of margin errors 60
O
/C7(·) order of a term
P
PX probability measure on /CG 200/C8 family of probability measures 214
πs swapping permutation 284
336 List of Symbols
Q
/C9 rational numbers
θ∈ /C9 parameter vector 214/C9 parameter space 214
Q the random variable of θ; in Remark 5.7 a
measure such as P116, 170
ˆθz estimator for the parameter of the probability
measure PZestimated using /BX117
R
/CA real numbers
R[f] expected risk of f∈ /BY 22
R[h] expected risk of h∈ /C0 22
Rθ[h] expected risk of h∈ /C0under PZ|Q=θ 116
R[
/BT,z] generalization error of /BTgiven z∈ /CIm25
R[
/BT,m] generalization error of /BTfor training sample
size m61
Remp [f,z] empirical risk of f∈ /BYgiven z∈ /CIm25
Rreg[f,z] regularized risk of f∈ /BYgiven z∈ /CIm29/CA(z,i) reconstruction function 176
ρ metric 216
S
sign sign function, i.e., sign (x)=2·Ix≥0−1
/Sigma1 alphabet 41
/Sigma1 covariance matrix 38
ς radius of sphere enclosing training data 51
337 List of Symbols
T
tr(A) trace of the matrix A 227
t∈ /CAmsample of real-valued outputs 82
U
u∈/Sigma1rstring 41
/vectoru∈/lscriptN
2 vector in input space 38/CD(y,x,h) update algorithm 182
V
vx empirical probability measure 18, 203
V(z)⊆ /CF version space 26
V/C0(z)⊆ /C0 version space in /C0 26
Va r(X) variance of X 202
v∈/Sigma1rstring 41
/vectorv∈/lscriptN
2 vector in input space 38
ϑ/C0 VC dimension of /C0 128
ϑ/C0(z) empirical VC dimension of /C0 140
W
/CF⊂ /C3 unit hyper-sphere in /CAn21/CF(z) canonical hyperplanes 52
w∈ /C3 weight vector 20
W±1(x) hemispheres in /CFinduced by x 24
W0(x) decision boundary induced by x 24
Wz equivalence classes of weight vectors 24
W(α) Wolfe dual 53
/Omega1[f] regularization functional of f∈ /BY 29
338 List of Symbols
X
/CG input space 17
x∈ /CGmsample of training objects 18
x∈ /CG input point
xi∈x ith training point 18
/vectorx∈ /CG input vector if /CG∈/lscriptN
2 30
(/vectorx)i ith component of /vectorx 30
x=φ(x) mapped input point x 19
X∈ /CAm×ndata matrix of mapped input points 19
X±1(w) decision regions induced by w 24
X0(w)∈ /C3 decision boundary in feature space 24
tildewideX0(w)∈ /CG decision boundary in input space 24/CG σ–algebra over /CG 200
ξ vector of margin slack variables 54
Y
/CH output space (often {−1,+1})1 7
y∈ /CHmsample of training outputs 18
y∈ /CH output class
yi∈y class of ith training point 18
ψi: /CG→ /CA Mercer feature on /CG 34
ψ: /CG→ /C3 Mercer feature mapping 35
Z
/CI= /CG× /CH (labeled) data space 18
z∈ /CIm(labeled) training sample 18
z\i∈ /CIm−1training sample with the ith element deleted 186
zi↔z∈ /CImtraining sample with the ith element replaced
byz∈ /CI186
z[i:j] subsequenceparenleftbig
zi,..., zjparenrightbig
ofz 281
Z random training sample
References
Aizerman, M. A., É. M. Braverman, and L. I. Rozonoér (1964). Theoretical foundations
of the potential function method in pattern recognition learning. Automation and
Remote Control 25 , 821–837.
Allwein, E. L., R. E. Schapire, and Y . Singer (2000). Reducing multiclass to binary:
a unifying approach for margin classiﬁers. In P . Langley (Ed.), Proceedings of the
International Conference on Machine Learning , San Francisco, California, pp. 9–16.
Morgan Kaufmann Publishers.
Alon, N., S. Ben-David, N. Cesa-Bianchi, and D. Haussler (1997). Scale-sensitive
dimensions, uniform convergence, and learnability. Journal of the ACM 44 (4), 615–
631.
Alon, N., J. H. Spencer, and P . Erdös (1991). The Probabilsitic Method . John Wiley
and Sons.
Amari, S. (1985). Differential-Geometrical Methods in Statistics . Berlin: Springer.
Anlauf, J. K. and M. Biehl (1989). The AdaTron: an adaptive perceptron algorithm.
Europhysics Letters 10 , 687–692.
Anthony, M. (1997). Probabilistic analysis of learning in artiﬁcial neural networks: The
P AC model and its variants. Neural Computing Surveys 1 , 1–47.
Anthony, M. and P . Bartlett (1999). A Theory of Learning in Artiﬁcial Neural Networks .
Cambridge University Press.
Baldi, P . and S. Brunak (1998). Bioinformatics: The Machine Learning Approach .M I T
Press.
Barber, D. and C. K. I. Williams (1997). Gaussian processes for Bayesian classiﬁcation
via Hybrid Monte Carlo. In M. C. Mozer, M. I. Jordan, and T. Petsche (Eds.),Advances in Neural Information Processing Systems 9 , pp. 340–346. MIT Press.
Barner, M. and F . Flohr (1989). Analysis .d e G r y t e r .
Bartlett, P ., P . Long, and R. C. Williamson (1996). Fat-shattering and the learnability of
real-valued functions. Journal of Computer and System Sciences 52 (3), 434–452.
340 References
Bartlett, P . and J. Shawe-Taylor (1998). Generalization performance of support vector
machines and other pattern classiﬁers. In Advances in Kernel Methods—Support
V ector Learning , pp. 43–54. MIT Press.
Bartlett, P . L. (1998). The sample complexity of pattern classiﬁcation with neural
networks: The size of the weights is more important than the size of the network.IEEE Transactions on Information Theory 44 (2), 525–536.
Bartlett, P . L. and J. Shawe-Taylor (1999). Generalization performance of support vector
machines and other pattern classiﬁers. In B. Schölkopf, C. J. C. Burges, and A. J.
Smola (Eds.), Advances in Kernel Methods—Support V ector Learning , Cambridge,
MA, pp. 43–54. MIT Press.
Baudat, G. and F. Anouar (2000). Generalized discriminant analysis using a kernel
approach. Neural Computation 12 , 2385–2404.
Bayes, T. (1763). An essay towards solving a problem in the doctrine of chances.
Philiosophical Transactions of the Royal Socienty 53 , 370–418.
Bellman, R. E. (1961). Adaptive Control Processes . Princeton, NJ: Princeton University
Press.
Bennett, G. (1962). Probability inequalities for the sum of independent random vari-
ables. Journal of the American Statistical Association 57 , 33–45.
Bennett, K. (1998). 19, combining support vector and mathematical programming
methods for classiﬁcation. In Advances in Kernel Methods—Support V ector Learning ,
pp. 307–326. MIT Press.
Berger, J. (1985). The frequentist viewpoint and conditioning. In Proccedings of the
Berkley Symposium , pp. 15–44.
Bernardo, J. and A. Smith (1994). Bayesian Theory . Chichester: John Wiley and Sons.
Bernstein, S. (1946). The Theory of Probabilities . Moscow: Gastehizdat Publishing
House.
Biehl, M. and M. Opper (1995). Perceptron learning: The largest version space. In
Proceedings of W orkshop: Theory of Neural Networks: The Statistical MechanicsPerspective .
Billingsley, P . (1968). Convergence of Probability Measures . John Wiley and Sons.
Bishop, C. M. (1995). Neural Networks for Pattern Recognition . Oxford: Clarendon
Press.
341 References
Bishop, C. M. and M. E. Tipping (2000). V ari ational relevance vector machines. In
Proceedings of 16th Conference on Uncertainty in Artiﬁcial Intelligence UAI’2000 ,
pp. 46–53.
Block, H. D. (1962). The perceptron: A model for brain functioning. Reviews of Modern
Physics 34 , 123–135. Reprinted in Neurocomputing by Anderson and Rosenfeld.
Blumer, A., A. Ehrenfeucht, D. Haussler, and M. W armuth (1989). Learnability and the
Vapnik-Chervonenkis Dimension. Journal of the ACM 36 (4), 929–965.
Bois, G. P . (1961). T ables of Indeﬁnite Integrals . Dover Publications.
Boser, B. E., I. M. Guyon, and V . N. V apnik (1992, July). A training algorithm for op-
timal margin classiﬁers. In D. Haussler (Ed.), Proceedings of the Annual Conference
on Computational Learning Theory , Pittsburgh, P A , pp. 144–152. ACM Press.
Bousquet, O. and A. Elisseeff (2000). Stability and generalization. Technical report,
Centre de Mathematiques Appliquees.
Bousquet, O. and A. Elisseeff (2001). Algorithmic stability and generalization perfor-
mance. In T. K. Leen, T. G. Dietterich, and V . Tresp (Eds.), Advances in Neural
Information Processing Systems 13 , pp. 196–202. MIT Press.
Box, G. E. P . and G. C. Tiao (1973). Bayesian Inference in Statistical Analysis . Addison-
Wesley.
Brown, M. P . S., W . N. Grundy, D. Lin, N. Cristianini, C. Sugnet, T. S. Furey, M. Ares,
and D. Haussler (2000). Knowledge-based analysis of microarray gene expression
data using support vector machines. Proceedings of the National Academy of Sci-
ences 97 (1), 262–267.
Brownie, C. and J. Kiefer (1977). The ideas of conditional conﬁdence in the simplest
setting. Communications in Statistics—Theory and Methods 6 (8), 691–751.
Burges, C. J. C. (1998). A tutorial on support vector machines for pattern recognition.
Data Mining and Knowledge Discovery 2 (2), 121–167.
Cantelli, F. (1933). Sulla probabilita come limita della frequenza. Rend. Accad. Lin-
cei 26 (1), 39.
Carl, B. and I. Stephani (1990). Entropy, compactness, and the approximation of
operators . Cambridge, UK: Cambridge University Press.
Casella, G. (1988). Conditionally acceptable frequentist solutions. In Statistical Deci-
sion Theory , V olume 1, pp. 73–84.
342 References
Cauchy, A. (1821). Cours d’analyse de l’Ecole Royale Polytechnique: Analyse alge-
brique . Paris: Debure freres.
Chernoff, H. (1952). A measure of asymptotic efﬁciency of tests of a hypothesis based
on the sum of observations. Annals of Mathematical Statistics 23 , 493–507.
Cortes, C. (1995). Prediction of Generalization Ability in Learning Machines .P h . D .
thesis, Department of Computer Science, University of Rochester.
Cortes, C. and V . V apnik (1995). Support vector networks. Machine Learning 20 , 273–
297.
Cox, R. (1946). Probability, frequency, and reasonable expectations. American Journal
of Physics 14 , 1–13.
CPLEX Optimization Inc. (1994). Using the CPLEX callable library. Manual.
Cristianini, N. and J. Shawe-Taylor (1999). Bayesian voting schemes and large margin
classiﬁers. In B. Schölkopf, C. J. C. Burges, and A. J. Smola (Eds.), Advances in
Kernel Methods—Support V ector Learning , Cambridge, MA, pp. 55–68. MIT Press.
Cristianini, N. and J. Shawe-Taylor (2000). An Introduction to Support V ector Machines .
Cambridge, UK: Cambridge University Press.
Debnath, L. and P . Mikusinski (1998). Hilbert Spaces with Applications . Academic
Press.
Dempster, A. P ., N. M. Laird, and D. B. Rubin (1977). Maximum Likelihood from
Incomplete Data via the EM Algorithm. Journal of the Royal Statistical Society
B3 9 (1), 1–22.
Devroye, L., L. Györﬁ, and G. Lugosi (1996). A Probabilistic Theory of Pattern
Recognition . Number 31 in Applications of mathematics. New Y ork: Springer.
Devroye, L. and G. Lugosi (2001). Combinatorial Methods in Density Estimation .
Springer.
Devroye, L. P . and T. J. W agner (1979). Distribution-free performance bounds for
potential function rules. IEEE Transactions on Information Theory 25 (5), 202–207.
Dietrich, R., M. Opper, and H. Sompolinsky (2000). Support vectors and statistical
mechanics. In A. J. Smola, P . L. Bar tlett, B. Schölkopf, an d D. Schuurmans (Eds.),
Advances in Large Margin Classiﬁers , Cambridge, MA, pp. 359–367. MIT Press.
Duda, R. O. and P . E. Hart (1973). Pattern Classiﬁcation and Scene Analysis .N e w
Y ork: John Wiley and Sons.
343 References
Duda, R. O., P . E. Hart, and D. G. Stork (2001). Pattern Classiﬁcation and Scene
Analysis . New Y ork: John Wiley and Sons. Second edition.
Feller, W . (1950). An Introduction T o Probability Theory and Its Application , V olume 1.
New Y ork: John Wiley and Sons.
Feller, W . (1966). An Introduction T o Probability Theory and Its Application , V olume 2.
New Y ork: John Wiley and Sons.
Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. Annals
of Eugenics 7 , 179–188.
Floyd, S. and M. W armuth (1995). Sample compression, learnability, and the Vapnik
Chervonenkis dimension. Machine Learning 27 , 1–36.
Freund, Y . (1998). Self bounding learning algorithms. In Proceedings of the Annual
Conference on Computational Learning Theory , Madison, Wisconsin, pp. 247–258.
Freund, Y ., Y . Mansour, and R. E. Schapire (2000). Analysis of a pseudo-Bayesian
prediction method. In Proceedings of the Conference on Information Science and
Systems .
Gardner, E. (1988). The space of interactions in neural networks. Journal of Physics
A2 1 , 257–270.
Gardner, E. and B. Derrida (1988). Optimal storage properties of neural network models.
Journal of Physics A 21 , 271–284.
Gentile, C. and M. K. W armuth (1999). Linear hinge loss and average margin. In
M. S. Kearns, S. A. Solla, and D. A. Cohn (Eds.), Advances in Neural Information
Processing Systems 11 , Cambridge, MA, pp. 225–231. MIT Press.
Gibbs, M. and D. J. C. Mackay (1997). Efﬁcient implementation of Gaussian processes.
Technical report, Cavendish Laboratory, Cambridge, UK.
Girosi, F. (1998). An equivalence between sparse approximation and support vector
machines. Neural Computation 10 (6), 1455–1480.
Glivenko, V . (1933). Sulla determinazione empirica delle leggi di probabilita. Giornale
dell’Istituta Italiano degli Attuari 4 , 92.
Golub, G. H. and C. F. van Loan (1989). Matrix Computations . John Hopkins University
Press.
Graepel, T., R. Herbrich, and J. Shawe-Taylor (2000). Generalisation error bounds for
sparse linear classiﬁers. In Proceedings of the Annual Conference on Computational
Learning Theory , pp. 298–303.
344 References
Graepel, T., R. Herbrich, and R. C. Williamson (2001). From margin to sparsity. In
T. K. Leen, T. G. Dietterich, and V . Tresp (Eds.), Advances in Neural Information
Processing Systems 13 , Cambridge, MA, pp. 210–216. MIT Press.
Guermeur, Y ., A. Elisseeff, and H. Paugam-Moisy (2000). A new multi-class SVM
based on a uniform convergence result. In Proccedings of IJCNN 2000 .
Gurvits, L. (1997). A note on a scale-sensitive dimension of linear bounded function-
als in Banach spaces. In M. Li and A. Maruoka (Eds.), Proceedings of the Interna-
tional Conference on Algorithmic Learning Theory , LNAI-1316, Berlin, pp. 352–363.
Springer.
Guyon, I. and D. Storck (2000). Linear discriminant and support vector classiﬁers. In
A. J. Smola, P . L. Bartlett, B. Sch ölkopf, and D. Schuurmans (Eds.), Advances in
Large Margin Classiﬁers , Cambridge, MA, pp. 147–169. MIT Press.
Hadamard, J. (1902). Sur les problèmes aux dèrivèes partielles et leur signiﬁcation
physique. Bullentin Princeton University 13 , 49–52.
Hadley, G. (1962). Linear Programming . London: Addison-W esley.
Hadley, G. (1964). Nonlinear and Dynamic Programming . London: Addison-W esley.
Harville, D. A. (1997). Matrix Algebra From a Statistican’s Perspective . Springer.
Hastie, T. and R. Tibshirani (1998). Classiﬁcation by pairwise coupling. In M. I. Jordan,
M. J. Kearns, and S. A. Solla (Eds.), Advances in Neural Information Processing
Systems 10 , Cambridge, MA, pp. 507–513. MIT Press.
Haussler, D. (1999). Convolutional kernels on discrete structures. Technical Report
UCSC-CRL-99-10, Computer Science Department, University of California at Santa
Cruz.
Haussler, D., M. Kearns, and R. Schapire (1994). Bounds on the sample complexity
of Bayesian learning using information theory and the VC dimension. Machine
Learning 14 , 88–113.
Herbrich, R. (2000). Learning Linear Classiﬁers—Theory and Algorithms .P h . D .
thesis, Technische Universität Berlin.
Herbrich, R. and T. Graepel (2001a). Large scale Bayes point machines. In T. K. Leen,
T. G. Dietterich, and V . Tresp (Eds.), Advances in Neural Information Processing
Systems 13 , Cambridge, MA, pp. 528–534. MIT Press.
Herbrich, R. and T. Graepel (2001b). A P AC-Bayesian margin bound for linear classi-
ﬁers: Why SVMs work. In T. K. Leen, T. G. Dietterich, and V . Tresp (Eds.), Advances
in Neural Information Processing Systems 13 , pp. 224–230.  MIT Press.
345 References
Herbrich, R., T. Graepel, and C. Campbell (2001). Bayes point machines. Journal of
Machine Learning Research 1 , 245–279.
Herbrich, R., T. Graepel, and J. Shawe-Taylor (2000). Sparsity vs. large margins for lin-
ear classiﬁers. In Proceedings of the Annual Conference on Computational Learning
Theory , pp. 304–308.
Hoeffding, W . (1963). Probability inequalities for sums of bounded random variables.
Journal of the American Statistical Association 58 , 13–30.
Jaakkola, T., M. Meila, and T. Jebara (2000). Maximum entropy discrimination. In
S. A. Solla, T. K. Leen, and K.-R. Müller (Eds.), Advances in Neural Information
Processing Systems 12 , Cambridge, MA, pp. 470–476. MIT Press.
Jaakkola, T. S., M. Diekhans, and D. Haussler (1999). Using the ﬁsher kernel method
to detect remote protein homologies. In Proccedings of the International Conference
on Intelligence Systems for Molecular Biology , pp. 149–158. AAAI Press.
Jaakkola, T. S. and D. Haussler (1999a). Exploiting generative models in discriminative
classiﬁers. In M. S. Kearns, S. A. Solla, and D. A. Cohn (Eds.), Advances in Neural
Information Processing Systems 11 , Cambridge, MA, pp. 487–493. MIT Press.
Jaakkola, T. S. and D. Haussler (1999b). Probabilistic kernel regression models. In
Proceedings of the 1999 Conference on AI and Statistics .
Jaynes, E. T. (1968, September). Prior probabilities. IEEE Transactions on Systems
Science and Cybernetics SSC-4 (3), 227–241.
Jebara, T. and T. Jaakkola (2000). Feature selection and dualities in maximum entropy
discrimination. In Uncertainity In Artiﬁcial Intelligence .
Jeffreys, H. (1946). An invariant form for the prior probability in estimation problems.
Proceedings of the Royal Statistical Society A 186 , 453–461.
Joachims, T. (1998). Text categorization w ith support vector machines: Learning with
many relevant features. In Proceedings of the European Conference on Machine
Learning , Berlin, pp. 137–142. Springer.
Joachims, T. (1999). Making large-scale SVM learning practical. In B. Schölkopf,
C. J. C. Burges, and A. J. Smola (Eds.), Advances in Kernel Methods—Support V ector
Learning , Cambridge, MA, pp. 169–184. MIT Press.
Johnson, N. L., S. Kotz, and N. Balakrishnan (1994). Continuous Univariate Distribu-
tions. V olume 1 (Second Edition) . John Wiley and Sons.
Kahane, J. P . (1968). Some Random Series of Functions . Cambridge University Press.
346 References
Karchin, R. (2000). Classifying g-protein coupled receptors with support vector ma-
chines. Master’s thesis, University of California.
Kearns, M. and D. Ron (1999). Algorithmic stability and sanity-check bounds for leave-
one-out cross-validation. Neural Computation 11 (6), 1427–1453.
Kearns, M. J. and R. E. Schapire (1994). Efﬁcient distribution-free learning of proba-
bilistic concepts. Journal of Computer and System Sciences 48 (3), 464–497.
Kearns, M. J., R. E. Schapire, and L. M. Sellie (1992). Toward efﬁcient agnostic learning
(extended abstract). In Proceedings of the Annual Conference on Computational
Learning Theory , Pittsburgh, Pennsylvania, pp. 341–352. ACM Press.
Kearns, M. J. and U. V . V azirani (1994). An Introduction to Computational Learning
Theory . Cambridge, Massachusetts: MIT Press.
Keerthi, S. S., S. K. Shevade, C. Bhattacharyya, and K. R. K. Murthy (1999b). A fast
iterative nearest point algorithm for support vector machine classiﬁer design. Tech-
nical Report Technical Report TR-ISL-99-03, Indian Institute of Science, Bangalore.
http://guppy.mpe.nus.edu.sg/ ∼mpessk/npa_tr.ps.gz.
Keerthi, S. S., S. K. Shevade, C. Bhattacharyya, and K. R. K. Murthy (1999a). Im-
provements to Platt’s SMO algorithm for SVM classiﬁer design. Technical ReportCD-99-14, Dept. of Mechanical and Production Engineering, Natl. Univ. Singapore,Singapore.
Kiefer, J. (1977). Conditional conﬁdence statements and conﬁdence estimators. Journal
of the American Statistical Association 72 , 789–807.
Kimeldorf, G. S. and G. W ahba (1970). A correspondence between Bayesian estimation
on stochastic processes and smoothing by splines. Annals of Mathematical Statis-
tics 41 , 495–502.
Kivinen, J., M. K. W armuth, and P . Auer (1997). The perceptron learning algorithm
vs. winnow: Linear vs. logarithmic mistake bounds when few input variables arerelevant. Artiﬁcial Intelligence 97 (1–2), 325–343.
Kockelkorn, U. (2000). Lineare statistische Methoden . Oldenburg-V erlag.
Kolmogorov, A. (1933). Sulla determinazione empirica di una leggi di distribuzione.
Giornale dell’Istituta Italiano degli Attuari 4 , 33.
Kolmogorov, A. N. and S. V . Fomin (1957). Functional Analysis . Graylock Press.
Kolmogorov, A. N. and V . M. Tihomirov (1961). ε-entropy and ε-capacity of sets in
functional spaces. American Mathematical Society Translations, Series 2 17 (2), 277–
364.
347 References
König, H. (1986). Eigenvalue Distribution of Compact Operators . Basel: Birkhäuser.
Krauth, W . and M. Mézard (1987). Learning algorithms with optimal stability in neural
networks. Journal of Physics A 20 , 745–752.
Lambert, P . F. (1969). Designing pattern cat egorizers with extremal paradigm informa-
tion. In S. W atanabe (Ed.), Methodologies of Pattern Recognition , New Y ork, pp.
359–391. Academic Press.
Lauritzen, S. L. (1981). Time series analysis in 1880, a discussion of contributions made
by t. n. thiele. ISI Review 49 , 319–333.
Lee, W . S., P . L. Bartlett, and R. C. Williamson (1998). The importance of convexity in
learning with squared loss. IEEE Transactions on Information Theory 44 (5), 1974–
1980.
Levin, R. D. and M. Tribus (1978). The maximum entropy formalism. In Proceedings
of the Maximum Entropy F ormalism Conference . MIT Press.
Lindsey, J. K. (1996). Parametric Statistical Inference . Clarendon Press.
Littlestone, N. (1988). Learning quickly when irrelevant attributes abound: A new
linear-treshold algorithm. Machine Learning 2 , 285–318.
Littlestone, N. and M. W armuth (1986). Relating data compression and learnability.
Technical report, University of California Santa Cruz.
Lodhi, H., J. Shawe-Taylor, N. Cristianini , and C. W atkins (2001). Text classiﬁcation
u s i n gk e r n e l s . I nT .K .L e e n ,T .G .D i e t t e r i c h ,a n dV .T r e s p( E d s . ) , Advances in Neural
Information Processing Systems 13 , Cambridge, MA, pp. 563–569. MIT Press.
Lunts, A. and V . Brailovsky (1969). On estimation of characters obtained in statistical
procedure of recognition (in Russian). T echnicheskaya Kibernetica 3 .
Lütkepohl, H. (1996). Handbook of Matrices . Chichester: John Wiley and Sons.
MacKay, D. (1994). Bayesian non-linear modelling for the energy prediction competi-
tion. ASHRAE Transcations 4 , 448–472.
MacKay, D. J. (1999). Information theory, probability and neural networks. available
at http://wol.ra.phy.cam.ac.uk/mackay/itprnn.
MacKay, D. J. C. (1991). Bayesian Methods for Adaptive Models . Ph. D. thesis,
Computation and Neural Systems, California Institute of Technology, Pasadena, CA.
MacKay, D. J. C. (1992). The evidence framework applied to classiﬁcation networks.
Neural Computation 4 (5), 720–736.
348 References
MacKay, D. J. C. (1998). Introduction to Gaussian processes. In C. M. Bishop (Ed.),
Neural Networks and Machine Learning , pp. 133–165. Berlin: Springer.
Magnus, J. R. and H. Neudecker (1999). Matrix Differential Calculus with Applications
in Statistics and Econometrics (Revised Edition) . John Wiley and Sons.
Marchand, M. and J. Shawe-Taylor (2001). Learning with the set covering machine.
InProceedings of the International Conference on Machine Learning , San Francisco,
California, pp. 345–352. Morgan Kaufmann Publishers.
Mardia, K. V ., J. T. Kent, and J. M. Bibby (1979). Multivariate Analysis . Academic
Press.
Markov, A. A. (1912). W ahrscheinlichkeitsrechnung . Leipzig: B.G. Teubner V erlag.
Matheron, G. (1963). Principles of geostatistics. Economic Geology 58 , 1246–1266.
McAllester, D. A. (1998). Some P AC Bayesian theorems. In Proceedings of the Annual
Conference on Computational Learning Theory , Madison, Wisconsin, pp. 230–234.
ACM Press.
McAllester, D. A. (1999). P AC-Bayesian model averaging. In Proceedings of the
Annual Conference on Computational Learning Theory , Santa Cruz, USA, pp. 164–
170.
McDiarmid, C. (1989). On the method of bounded differences. In Survey in Combina-
torics , pp. 148–188. Cambridge University Press.
Mercer, J. (1909). Functions of positive and negative type and their connection with
the theory of integral equations. Philosophical Transactions of the Royal Society,
London A 209 , 415–446.
Mika, S., G. Rätsch, J. W eston, B. Schölkopf, and K.-R. Müller (1999). Fisher discrim-
inant analysis with kernels. In Y .-H. Hu, J. Larsen, E. Wilson, and S. Douglas (Eds.),Neural Networks for Signal Processing IX , pp. 41–48. IEEE.
Minka, T. (2001). Expectation Propagation for approximative Bayesian inference .P h .
D. thesis, MIT Media Labs, Cambridge, USA.
Minsky, M. and S. Papert (1969). Perceptrons: An Introduction T o Computational
Geometry . Cambridge, MA: MIT Press.
Mitchell, T. M. (1977). V ersion spaces: a candidate elimination approach to rule learn-
ing. In Proceedings of the International Joint Conference on Artiﬁcial Intelligence ,
Cambridge, Massachusetts, pp. 305–310. IJCAI.
Mitchell, T. M. (1982). Generalization as search. Artiﬁcial Intelligence 18 (2), 202–226.
349 References
Mitchell, T. M. (1997). Machine Learning . New Y ork: McGraw-Hill.
Murtagh, B. A. and M. A. Saunders (1993). MINOS 5.4 user’s guide. Technical Report
SOL 83.20, Stanford University.
Neal, R. (1996). Bayesian Learning in Neural Networks . Springer.
Neal, R. M. (1997a). Markov chain Monte Carl o method based on ’slicing’ the density
function. Technical report, Department of Statistics, University of Toronto. TR-9722.
Neal, R. M. (1997b). Monte Carlo implementation of Gaussian process models for
Bayesian regression and classiﬁca tion. Technical Report Technical Report 9702,
Dept. of Statistics.
Neal, R. M. (1998). Assessing relevance de termination methods using delve. In Neural
Networks and Machine Learning , pp. 97–129. Springer.
Novikoff, A. B. J. (1962). On convergence proofs on perceptrons. In Proceedings of
the Symposium on the Mathematical Theory of Automata , V olume 12, pp. 615–622.
Polytechnic Institute of Brooklyn.
Okamoto, M. (1958). Some inequalities relating to the partial sum of binomial proba-
bilities. Annals of the Institue of Statistical Mathematics 10 , 29–35.
Opper, M. and D. Haussler (1991). Generalization performance of Bayes optimal
classiﬁcation algorithms for learning a perceptron. Physical Review Letters 66 , 2677.
Opper, M. and W . Kinzel (1995). Statistical Mechanics of Generalisation , pp. 151.
Springer.
Opper, M., W . Kinzel, J. Kleinz, and R. Nehl (1990). On the ability of the optimal
perceptron to generalize. Journal of Physics A 23 , 581–586.
Opper, M. and O. Winther (2000). Gaussi an processes for classiﬁcation: Mean ﬁeld
algorithms. Neural Computation 12 (11), 2655–2684.
Osuna, E., R. Freund, and F. Girosi (1997). An improved training algorithm for support
vector machines. In J. Principe, L. Gile, N. Morgan, and E. Wilson (Eds.), Neural
Networks for Signal Processing VII—Proceedings of the 1997 IEEE W orkshop ,N e w
Y ork, pp. 276–285. IEEE.
Platt, J. (1999). Fast training of support v ector machines using sequential minimal
optimization. In B. Schölkopf, C. J. C. Burges, and A. J. Smola (Eds.), Advances
in Kernel Methods—Support V ector Learning , Cambridge, MA, pp. 185–208. MIT
Press.
350 References
Platt, J. C., N. Cristianini, and J. Shawe-Taylor (2000). Large margin DAGs for mul-
ticlass classiﬁcation. In S. A. Solla, T. K. Leen, and K.-R. Müller (Eds.), Advances
in Neural Information Processing Systems 12 , Cambridge, MA, pp. 547–553. MIT
Press.
Poggio, T. (1975). On optimal nonlinear associative recall. Biological Cybernetics 19 ,
201–209.
Pollard, D. (1984). Convergence of Stochastic Processess . New Y ork: Springer.
Press, W . H., S. A. Teukolsky, W . T. V etterling, and B. P . Flannery (1992). Numerical
Recipes in C: The Art of Scientiﬁc Computing (2nd ed.) . Cambridge: Cambridge
University Press. ISBN 0-521-43108-5.
Robert, C. P . (1994). The Bayesian choice: A decision theoretic motivation .N e y Y o r k :
Springer.
Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage
and organization in the brain. Psychological Review 65 (6), 386–408.
Rosenblatt, F . (1962). Principles of neurodynamics: Perceptron and Theory of Brain
Mechanisms . W ashington D.C.: Spartan-Books.
Roth, V . and V . Steinhage (2000). Nonlinear discriminant analysis using kernel func-
tions. In S. A. Solla, T. K. Leen, and K.-R. Müller (Eds.), Advances in Neural Infor-
mation Processing Systems 12 , Cambridge, MA, pp. 568–574. MIT Press.
Ruján, P . (1993). A fast method for calculating the perceptron with maximal stability.
Journal de Physique I France 3 , 277–290.
Ruján, P . (1997). Playing billiards in version space. Neural Computation 9 , 99–122.
Ruján, P . and M. Marchand (2000). Computing the Bayes kernel classiﬁer. In A. J.
Smola, P . L. Bartlett, B. Schölkopf, and D. Schuurmans (Eds.), Advances in Large
Margin Classiﬁers , Cambridge, MA, pp. 329–347. MIT Press.
Rumelhart, D. E., G. E. Hinton, and R. J. Williams (1986). Parallel Distributed Pro-
cessing . Cambridge, MA: MIT Press.
Rychetsky, M., J. Shawe-Taylor, and M. Glesner (2000). Direct Bayes point machines.
InProceedings of the International Conference on Machine Learning .
Salton, G. (1968). Automatic Information Organization and Retrieval .N e w Y o r k :
McGraw-Hill.
Sauer, N. (1972). On the density of families of sets. Journal of Combinatorial The-
ory 13 , 145–147.
351 References
Scheffé, H. (1947). A useful convergence theorem for probability distributions. Annals
of Mathematical Statistics 18 , 434–438.
Schölkopf, B., C. Burges, and V . V apnik (1995). Extracting support data for a given
task. In U. M. Fayyad and R. Uthurusamy (Eds.), Proceedings, First International
Conference on Knowledge Discovery & Data Mining , Menlo Park. AAAI Press.
Schölkopf, B., C. J. C. Burges, and A. J. Smola (1998). Advances in Kernel Methods .
MIT Press.
Schölkopf, B., R. Herbrich, and A. J. Smola (2001). A generalized representer theorem.
InProceedings of the Annual Conference on Computational Learning Theory .
Schölkopf, B., J. Shawe-Taylor, A. J. Smola, and R. C. Williamson (1999). Kernel-
dependent support vector error bounds. In Ninth International Conference on Artiﬁ-
cial Neural Networks , Conference Publications No. 470, London, pp. 103–108. IEE.
Schölkopf, B., A. Smola, R. C. Williamson, and P . L. Bartlett (2000). New support
vector algorithms. Neural Computation 12 , 1207–1245.
Shawe-Taylor, J., P . L. Bartlett, R. C. Williamson, and M. Anthony (1998). Structural
risk minimization over data-dependent hierarchies. IEEE Transactions on Informa-
tion Theory 44 (5), 1926–1940.
Shawe-Taylor, J. and N. Cristianini (1998). Robust bounds on generalization from
the margin distribution. NeuroCOL T Technical Report NC-TR-1998-029, ESPRIT
NeuroCOL T2 W orking Group, http://www.neurocolt.com.
Shawe-Taylor, J. and N. Cristianini (2000). Margin distribution and soft margin. In
A. J. Smola, P . L. Bartlett, B. Sch ölkopf, and D. Schuurmans (Eds.), Advances in
Large Margin Classiﬁers , Cambridge, MA, pp. 349–358. MIT Press.
Shawe-Taylor, J. and R. C. Williamson (1997). A P AC analysis of a Bayesian estimator.
Technical report, Royal Holloway, University of London. NC2-TR-1997-013.
Shawe-Taylor, J. and R. C. Williamson (1999). Generalization performance of classiﬁers
in terms of observed covering numbers. In P . Fischer and H. U. Simon (Eds.),Proceedings of the European Conference on Computational Learning Theory , V olume
1572 of LNAI , Berlin, pp. 285–300. Springer.
Shelah, S. (1972). A combinatorial problem; stability and order for models and theories
in inﬁnitary languages. Paciﬁc Journal of Mathematics 41 , 247–261.
Shevade, S. K., S. S. Keerthi, C. Bhattacharyya, and K. R. K. Murthy (1999). Improve-
ments to SMO algorithm for SVM regression. Technical Report CD-99-16, Dept. of
Mechanical and Production Engineering, Natl. Univ. Singapore, Singapore.
352 References
Smola, A. and B. Schölkopf (1998). From regularization operators to support vector
kernels. In M. I. Jordan, M. J. Kearns, and S. A. Solla (Eds.), Advances in Neural
Information Processing Systems 10 , Cambridge, MA, pp. 343–349. MIT Press.
Smola, A. and B. Schölkopf (2001). A tutorial on support vector regression. Statistics
and Computing . Forthcoming.
Smola, A., B. Schölkopf, and K.-R. Müller (1998). The connection between regulariza-
tion operators and support vector kernels. Neural Networks 11 , 637–649.
Smola, A. J. (1996). Regression estimation with support vector learning machines.
Diplomarbeit, Technische Universität München.
Smola, A. J. (1998). Learning with Kernels . Ph. D. thesis, Technische Universität
Berlin. GMD Research Series No. 25.
Smola, A. J. and P . L. Bartlett (2001). Sparse greedy Gaussian process regression. In
T. K. Leen, T. G. Dietterich, and V . Tresp (Eds.), Advances in Neural Information
Processing Systems 13 , pp. 619–625. MIT Press.
Smola, A. J., P . L. Bartlett, B. Schölkopf, and D. Schuurmans (2000). Advances in Large
Margin Classiﬁers . Cambridge, MA: MIT Press.
Smola, A. J. and B. Schölkopf (1998). On a kernel-based method for pattern recognition,
regression, approximation and operator inversion. Algorithmica 22 , 211–231.
Smola, A. J., J. Shawe-Taylor, B. Schölkopf, and R. C. Williamson (2000). The entropy
regularization information criterion. In S. A. Solla, T. K. Leen, and K.-R. Müller
(Eds.), Advances in Neural Information Processing Systems 12 , Cambridge, MA, pp.
342–348. MIT Press.
Sollich, P . (2000). Probabilistic methods for support vector machines. In S. A. Solla,
T. K. Leen, and K.-R. Müller (Eds.), Advances in Neural Information Processing
Systems 12 , Cambridge, MA, pp. 349–355. MIT Press.
Sontag, E. D. (1998). VC dimension of neural networks. In C. M. Bishop (Ed.), Neural
Networks and Machine Learning , pp. 69–94. Berlin: Springer.
Sutton, R. S. and A. G. Barto (1998). Reinforcement Learning: An Introduction .M I T
Press.
Talagrand, M. (1987). The Glivenko-Cantelli problem. Annals of Probability 15 , 837–
870.
Talagrand, M. (1996). A new look at independence. Annals of Probability 24 , 1–34.
353 References
Tikhonov, A. N. and V . Y . Arsenin (1977). Solution of Ill-posed problems .V . H . W i n s t o n
and Sons.
Tipping, M. (2001). Sparse bayesian learning and the relevance vector machine. Journal
of Machine Learning Research 1 , 211–244.
Tipping, M. E. (2000). The relevance vector machine. In S. A. Solla, T. K. Leen, and K.-
R. Müller (Eds.), Advances in Neural Information Processing Systems 12 , Cambridge,
MA, pp. 652–658. MIT Press.
Trecate, G. F., C. K. Williams, and M. Opper (1999). Finite-dimensional approximation
of Gaussian processes. In M. S. Kearns, S. A. Solla, and D. A. Cohn (Eds.), Advances
in Neural Information Processing Systems 11 , Cambridge, MA, pp. 218–224. MIT
Press.
Trybulec, W . A. (1990). Pigeon hole principle. Journal of F ormalized Mathematics 2 .
Tschebyscheff, P . L. (1936). W ahrscheinlichkeitsrechnung (in Russian) . Moskau:
Akademie V erlag.
V aliant, L. G. (1984). A theory of the learnable. Communications of the ACM 27 (11),
1134–1142.
van der V aart, A. W . and J. A. W ellner (1996). W eak Convergence and Empirical
Processes . Springer.
V anderbei, R. J. (1994). LOQO: An interior point code for quadratic programming. TR
SOR-94-15, Statistics and Operations Research, Princeton Univ., NJ.
V anderbei, R. J. (1997). Linear Programming: F oundations and Extensions . Hingham:
Kluwer Academic.
V apnik, V . (1995). The Nature of Statistical Learning Theory . New Y ork: Springer.
V apnik, V . (1998). Statistical Learning Theory . New Y ork: John Wiley and Sons.
V apnik, V . and A. Chervonenkis (1974). Theory of Pattern Recognition [in Russian] .
Moscow: Nauka. (German Translation: W . W apnik & A. Tscherwonenkis, Theorie
der Zeichenerkennung , Akademie-V erlag, Berlin, 1979).
V apnik, V . and A. Lerner (1963). Pattern recognition using generalized portrait method.
Automation and Remote Control 24 , 774–780.
V apnik, V . N. (1982). Estimation of Dependences Based on Empirical Data . Springer.
V apnik, V . N. and A. Y . Chervonenkis (1971). On the uniform convergence of relative
frequencies of events to their probabilities. Theory of Probability and its Applica-
tions 16 (2), 264–281.
354 References
V apnik, V . N. and A. Y . Chervonenkis (1991). The necessary and sufﬁcient conditions
for consistency in the empirical risk minimization method. Pattern Recognition and
Image Analysis 1 (3), 283–305.
V apnik, V . N. and S. Mukherjee (2000). Support vector method for multivariate density
estimation. In S. A. Solla, T. K. Leen, and K.-R. Müller (Eds.), Advances in Neural
Information Processing Systems 12 , Cambridge, MA, pp. 659–665. MIT Press.
V eropoulos, K., C. Campbell, and N. Cristianini (1999). Controlling the sensitivity
of support vector machines. In Proceedings of IJCAI W orkshop Support V ector
Machines , pp. 55–60.
Vidyasagar, M. (1997). A Theory of Learning and Generalization . New Y ork: Springer.
W ahba, G. (1990). Spline Models for Observational Data , V olume 59 of CBMS-NSF
Regional Conference Series in Applied Mathematics . Philadelphia: SIAM.
W ahba, G. (1999). Support vector machines, reproducing kernel Hilbert spaces and
the randomized GACV. In B. Schölkopf, C. J. C. Burges, and A. J. Smola (Eds.),
Advances in Kernel Methods—Support V ector Learning , Cambridge, MA, pp. 69–88.
MIT Press.
W atkin, T. (1993). Optimal learning with a neural network. Europhysics Letters 21 ,
871.
W atkins, C. (1998). Dynamic alignment kernels. Technical report, Royal Holloway,
University of London. CSD-TR-98-11.
W atkins, C. (2000). Dynamic alignment kernels. In A. J. Smola, P . L. Bartlett,
B. Schölkopf, and D. Schuurmans (Eds.), Advances in Large Margin Classiﬁers ,C a m -
bridge, MA, pp. 39–50. MIT Press.
W eston, J., A. Gammerman, M. Stitson, V . V apnik, V . V ovk, and C. W atkins (1999).
Support vector density estimation. In B. Schölkopf, C. J. C. Burges, and A. J. Smola(Eds.), Advances in Kernel Methods—Support V ector Learning , Cambridge, MA, pp.
293–306. MIT Press.
W eston, J. and R. Herbrich (2000). Adaptive margin support vector machines. In A. J.
Smola, P . L. Bartlett, B. Schölkopf, and D. Schuurmans (Eds.), Advances in Large
Margin Classiﬁers , Cambridge, MA, pp. 281–295. MIT Press.
W eston, J. and C. W atkins (1998). Multi-class support vector machines. Technical Re-
port CSD-TR-98-04, Department of Computer Science, Royal Holloway, Universityof London, Egham, TW20 0EX, UK.
355 References
Williams, C. K. I. (1998). Prediction with Gaussian processes: From linear regression
to linear prediction and beyond. In M. I. Jordan (Ed.), Learning and Inference in
Graphical Models . Kluwer Academic.
Williams, C. K. I. and D. Barber (1998). Bayesian classiﬁcation with Gaussian pro-
cesses. IEEE Transactions on Pattern Analysis and Machine Intelligence PAMI 20 (12),
1342–1351.
Williams, C. K. I. and M. Seeger (2001). Using the nystrom method to speed up kernel
m a c h i n e s . I nT .K .L e e n ,T .G .D i e t t e r i c h ,a n dV .T r e s p( E d s . ) , Advances in Neural
Information Processing Systems 13 , Cambridge, MA, pp. 682–688. MIT Press.
Williamson, R. C., A. J. Smola, and B. Schölkopf (2000). Entropy numbers of linear
function classes. In N. Cesa-Bianchi and S. Goldman (Eds.), Proceedings of the
Annual Conference on Computational Learning Theory , San Francisco, pp. 309–319.
Morgan Kaufmann Publishers.
W olpert, D. H. (1995). The Mathematics of Generalization . Addison-W esley.
Index
L1–convergence of measure, 120
βm–stability, 186 , 191, 317, 318
γ–shattering, 146, 148, 296
ν–support vector machine, 60, 71, 259, 324
σ–algebra, 120, 200
ε–cover, 220
ε–packing, 220
ε–insensitive loss, 59, 187, 190
a-posteriori bound, 150
a-priori bound, 127
adaptive margin machine, 67, 71, 156, 161, 323
Adatron, 70
agnostic PAC framework, 159
algorithm
ν–support vector machine, 60, 71, 259, 324
adaptive margin machine, 67, 71, 156, 161, 323
back-propagation algorithm, 5
Bayes point machine, 99, 111, 330
bound minimization algorithm, 136
clustering algorithm, 6
EM algorithm, 7
ERM algorithm, 26, 121, 123
Fisher discriminant, 105, 106, 107 , 111, 329
Gaussian process, 81, 87, 91, 265, 270, 325
halving algorithm, 184 , 195
kernel Fisher discriminant, 108 ,329
kernel perceptron algorithm, 32, 33, 101, 322
learning algorithm, 9, 24
leave-one-out machine, 64
mistake-driven algorithm, 182 , 184, 195
on-line algorithm, 182 , 194
perceptron learning algorithm, 26, 27, 28, 32, 47,
51, 68, 176, 177, 182, 184, 321
relevance vector machine, 95, 111, 178, 271, 325
self bounding learning algorithm, 160
soft margin support vector machine, 54, 60, 70,
156, 192, 259, 323
SRM algorithm, 29
stable learning algorithm, 186
support vector machine, 49, 64, 67, 69, 91, 101,
112, 135, 174, 176, 177, 184, 259, 323support vector regression, 59, 190
algorithmic stability bound, 188 , 192, 318
alphabet, 41
ARD, 111
artiﬁcial intelligence, 1, 68
automatic relevance determination, 38, 86, 93, 96,
111
back-propagation algorithm, 5
bag-of-words kernel, 42
ball, 141, 172, 217 , 302, 303
basic lemma, 124, 143, 281 , 284, 286, 290
Bayes admissibility, 172
Bayes admissibility for linear classiﬁers, 172
Bayes classiﬁcation strategy, 80, 83, 85, 93, 98, 99,
110, 164, 167, 194
Bayes classiﬁer, 110
Bayes error, 110
Bayes optimal decision, 81, 104, 116
Bayes point, 99, 100, 330
Bayes point machine, 99, 111, 330
Bayes’ theorem, 30, 75, 83, 98, 110, 112, 171, 205 ,
266, 276
Bayesian linear regression, 82, 110
belief, 74, 74, 98, 110, 164, 194
Bennett’s inequality, 248 , 249
Bernoulli distribution, 207
Bernstein’s inequality, 249
Beta distribution, 208
binary classiﬁcation, 4, 18
binomial distribution, 207
binomial tail bound, 165, 169, 178, 250 , 283
binomial theorem, 241 , 242
Bioinformatics, 69
Bollmann’s lemma, 311
Bonferroni test, 132
Borel sets, 120, 200 , 208
bound
a-posteriori bound, 150
a-priori bound, 127
algorithmic stability bound, 188 , 192, 318
binomial tail bound, 165, 169, 178, 250 , 283
358 Index
bound for single hypotheses, 165
bound for subsets of hypotheses, 167
bound for the Bayes classiﬁcation strategy, 168
bound on the covering number, 147
covering number bound, 145
fat shattering bound, 149 , 154
fat shattering bound for linear classiﬁers, 150
generalization error bound, 12, 133, 157, 179,
188, 190
PAC generalization error bound, 122
VC generalization error bound, 122
growth function bound, 128
lossy compression bound, 181 , 194
luckiness bound, 137 , 289
luckiness generalization error bound, 135
mistake bound, 183 , 195
mistake bound into generalization error bound,
183
PAC compression bound, 179
PAC generalization error bound, 125 , 133
PAC margin bound, 150 , 152, 161, 174
PAC-Bayesian bound with training error, 169
PAC-Bayesian generalization error bounds, 164
PAC-Bayesian margin bound, 173 , 194
risky bound, 175
robust margin bound, 155
union bound, 123, 125, 132, 137, 160, 178, 242 ,
247, 285, 287, 292
VC bound, 123 , 184
VC generalization error bound, 125 , 133
bound for the Bayes classiﬁcation strategy, 168
bound minimization algorithm, 136
bound on the covering number, 147
box constraint, 54,6 5
canonical hyperplane, 52, 52,6 9
canonical parameters, 207
Cauchy sequence, 48, 219
Cauchy-Schwarz inequality, 10, 20, 48, 242 , 259,
297, 315
center of mass, 58, 99, 102
central limit theorem, 208
characteristic polynomial, 231
Chebyshev’s inequality, 65, 244, 244 , 245, 282
Chernoff’s bounding method, 245
Chernoff’s inequality, 246
Cholesky decomposition, 326
class, 3, 18
classiﬁcation learning, 3, 17, 18, 103, 111, 190
clipped linear soft margin loss, 191
closed ball, 217clustering, 67
clustering algorithm, 6
clusters, 2
complete space, 219
complexity, 29, 52, 53, 132, 138, 147, 149, 160,
181
data-dependent complexity, 160
effective complexity, 138 , 157
compression coefﬁcient, 180
compression function, 177 , 183
compression scheme, 176, 177 , 194
lossy compression scheme, 180
concentration of measure, 141
conditional conﬁdence interval, 138 , 160
conditional measure, 103
conditional probability measure, 84, 202
conditioning, 124
conﬁdence, 5, 141
conﬁdence interval, 125 , 127, 128, 132, 138
conditional conﬁdence interval, 138 , 160
conjugate gradient, 87
conjugate prior, 76, 110
convergence, 28, 51, 69, 94, 158, 183 , 243, 258 ,
275
L1–convergence of measure, 120
convergence in probability, 119
convergence of measure, 117 , 118, 158
convergence of risk, 118, 158
uniform convergence, 121 , 122, 131, 159, 175
convex programming, 53
convolution of Gaussian measures, 211
cost matrix, 22,5 6
cost matrix loss, 23
covariance, 203
covariance function, 36, 69
covariance matrix, 89, 203 , 278
cover, 141 , 142, 144, 173
covering number, 127, 136, 141, 142, 147, 220
covering number bound, 145
empirical covering number, 142 , 146
CPLEX, 323
curse of dimensionality, 130 , 151, 158
DAG, 59
decision surface, 24, 30, 49
decomposition, 160
default classiﬁer, 22
density, 201 , 208
density estimation, 71
derivative of a matrix, 237
determinant of a matrix, 225
359 Index
diagonal matrix, 223
diagonal penalization, 56, 58, 107
directed acyclic graph, 59
discriminant analysis, 111
discriminative model, 103 , 104, 106, 116
distribution
Bernoulli distribution, 207
Beta distribution, 77, 208
binomial distribution, 77, 207
exponential distribution, 208
Gamma distribution, 97, 208
Gaussian distribution, 208
normal distribution, 208
Poisson distribution, 207
predictive distribution, 87, 90, 94, 98
uniform distribution, 207
distribution function, 201
DNA sequence, 41
dual space, 32
dyadic entropy number, 143 , 148
effective complexity, 138 , 157
effective VC dimension, 151
eigenfunction, 34
eigenvalue, 34, 84, 219 ,231
eigenvector, 219 ,231
EM algorithm, 7
empirical covering number, 142 , 146
empirical measure, 18, 104, 122, 203
empirical risk, 25
empirical risk minimization, 25, 26, 28, 29, 32, 68,
127, 129, 132, 133, 140, 158, 180, 189
empirical VC dimension, 139 , 292
empirical VC dimension luckiness, 139
entropy, 112
entropy number, 222
dyadic entropy number, 143 , 148
equivalence classes, 24, 136, 141, 285, 290, 292
ERM algorithm, 121, 123
error
generalization error, 25, 64, 118, 121, 123, 125,
160, 176, 185, 189, 193
leave-one-out error, 61,7 1
margin error, 60,7 1
training error, 25
error bar, 85, 86
estimation, 3
estimator, 117
Euclidean distance, 9, 57
Euclidean inner product, 218
Euler’s inequality, 240 , 242evidence, 77, 86, 87, 94, 169, 194, 271, 274
evidence maximization, 78, 78, 86, 93, 97, 110
expectation, 202 , 203
expectation value, 202 , 301
expected loss, 12, 22
expected risk, 22,61
exponential distribution, 208
exponential family, 46, 104, 207, 214
fat shattering bound, 149 , 154
fat shattering bound for linear classiﬁers, 150
fat shattering dimension, 147 , 148, 161, 296
feature, 19, 20, 32, 35, 38, 39, 45
feature mapping, 10, 19, 51, 82, 85, 131
feature selection, 32
feature space, 19, 34, 174
Fisher discriminant, 105, 106, 107 , 111, 329
Fisher information matrix, 45,4 6
Fisher kernel, 44, 46,6 9
Fisher score, 45
Fisher score mapping, 45
function learning, 5
functional margin, 50, 50, 52, 56, 60, 66, 69, 141,
153
Gamma distribution, 97, 208
Gamma function, 208
Gauss-Jordan decomposition, 325
Gaussian, 36, 37, 104, 210
Gaussian distribution, 208
Gaussian process, 36, 69, 81, 84, 87, 91, 110, 265,
270, 325
generalization error, 25, 64, 118, 121, 123, 125,
160, 176, 185, 189
generalization error bound, 12, 157, 179, 188, 190generalized inner product, 217
generalized Rayleigh coefﬁcient, 106, 235
generative model, 103 , 104, 116, 120
geometrical margin, 51, 52, 56, 57, 60, 69, 135, 151
geostatistics, 110ghost sample, 124 , 137, 146, 181
Gibbs classiﬁcation strategy, 81, 164, 165, 167, 194
Gibbs-Bayes lemma, 168 , 170
Glivenko-Cantelli classes, 147 , 159
Glivenko-Cantelli lemma, 159
Gram matrix, 33, 34, 43, 53, 56, 62, 64, 84, 85, 91,
95, 108, 111, 259, 266, 270, 327
Green’s function, 69
growth function, 127 , 128, 140, 160, 164, 287
growth function bound, 128
guaranteed risk, 29
360 Index
halving algorithm, 184 , 195
Heaviside step function, 55, 63, 65
Hessian matrix, 268 , 270, 276
Hilbert space, 219
hinge loss, 55, 63, 65, 70
Hoeffding’s inequality, 65, 123–125, 169, 246 ,
252, 285
hypothesis, 19
hypothesis space, 19, 21, 23, 53, 56, 74, 129
identity matrix, 223
IDF, 42
iid, 124, 243
ill-posed problem, 28, 68, 91, 240 , 270, 326
independence, 202
indicator function, 200
inequality
Bennett’s inequality, 248 , 249
Bernstein’s inequality, 249
Cauchy-Schwarz inequality, 10, 20, 48, 242 , 259,
297, 315
Chebyshev’s inequality, 65, 244, 244 , 245, 282
Chernoff’s inequality, 246
Euler’s inequality, 240 , 242
Hoeffding’s inequality, 65, 123–125, 169, 246 ,
252, 285
Markov’s inequality, 243 , 244, 245, 302
McDiarmid’s inequality, 185, 188, 252 , 319
Minkowski’s inequality, 217triangle inequality, 120, 121, 186, 216 , 252, 319
inference, 2
information retrieval, 69
information theory, 176inner entropy number, 222
inner product, 217
inner product space, 19, 34, 37, 217 , 296
input space, 17, 37, 38
inverse loss likelihood, 76, 79, 80, 82, 91
inverse of a matrix, 84, 228
inverse-document-frequency, 42
Jacobian matrix, 307
kernel, 11, 32, 32, 33–36, 48, 66, 84, 95, 253, 257
bag-of-words kernel, 42
Fisher kernel, 44, 46,6 9
Mahalanobis kernel, 37,8 6
Mercer kernel, 33, 35, 36, 37, 47, 48, 51, 52, 63,
264, 327
naive Fisher kernel, 46
normalized kernel, 37, 192polynomial kernel, 38, 39,6 9
RBF kernel, 37, 53, 66, 174, 192
string kernel, 41, 69, 254
subsequence kernel, 43,4 4
substring kernel, 42,4 4
kernel billiard, 101 , 111, 330
kernel classiﬁer, 11,61, 71, 327
kernel Fisher discriminant, 108 ,329
kernel matrix, 33, 33
kernel perceptron algorithm, 32, 33, 101, 322
kernel space, 33
key theorem in learning theory, 159
Kolmogorov axioms, 74
kriging, 111
Kronecker product, 236
Kullback-Leibler divergence, 171
Lagrangian, 260–262
Lagrangian multiplier, 53
Laplace approximation, 89, 91, 95, 110, 265, 268,
325
Laplace expansion, 225 , 308
large deviation theory, 12, 124, 178, 185, 243
large margin, 51, 54, 69, 130, 146, 151, 194
large margin principle, 49,5 1
latent variable, 82, 88, 94, 97
Law of large numbers, 243
learning
classiﬁcation learning, 3, 17, 18, 190
function learning, 5
machine learning, 1, 2
preference learning, 4
reinforcement learning, 2, 7
supervised learning, 2, 3,1 2
unsupervised learning, 2, 6
learning algorithm, 9, 24, 176
learning problem, 1, 2, 18, 20, 25, 73, 103, 116
learning theory, 11, 13
least squares regression, 108 , 112
leave-one-out error, 61,7 1
leave-one-out machine, 64
level, 136
lexicon, 42
likelihood, 75, 82, 91–93, 98, 110, 164, 278
inverse loss likelihood, 76, 79, 80, 82, 91
PAC likelihood, 76, 98, 164, 165, 169
likelihood principle, 75
linear classiﬁer, 20, 30, 36, 51, 81, 135, 160, 173
linear function, 10, 20, 68, 82
linear operator, 219 , 223
linear separability, 27, 53
361 Index
linear soft margin loss, 54, 59, 187, 260
Lipschitz constant, 187 , 192
Lipschitz continuity, 187 , 190, 315, 316
logistic regression, 5
LOOM, 64
LOQO, 323
loss
ε–insensitive loss, 59, 187, 190
clipped linear soft margin loss, 191
cost matrix loss, 23
expected loss, 12, 22
hinge loss, 55, 63, 65, 70
linear soft margin loss, 54, 59, 187, 260
margin loss, 52, 66, 91, 130
quadratic soft margin loss, 54, 55, 85, 261
sigmoidal loss, 91
squared loss, 82
zero-one loss, 22
loss function, 21
lossy compression bound, 181 , 194
lossy compression scheme, 180
lower triangular matrix, 223
luckiness, 136 , 138, 160, 292
empirical VC dimension luckiness, 139
PAC luckiness, 139
vanilla luckiness, 140
luckiness bound, 137
luckiness framework, 135 , 160, 175, 181, 193, 281,
289
luckiness generalization error bound, 135
machine learning, 1, 2
Mahalanobis kernel, 37,8 6
MAP , 80, 107, 164, 165
margin, 49, 54, 64, 140, 141, 160, 173, 176, 303
functional margin, 50, 50, 52, 56, 60, 66, 69, 141,
153
geometrical margin, 51, 52, 56, 57, 60, 69, 135,
151
large margin, 51, 54, 69
large margin principle, 49,51
normalized margin, 173
soft margin, 49, 63, 70, 156
margin distribution, 298
margin distribution lemma, 154
margin error, 60,7 1
margin loss, 52, 66, 91, 130
marginal probabiity measure, 202
marginalized prior measure, 97
Markov chain, 90, 100 , 110
Markov Chain Monte Carlo, 100 , 111Markov’s inequality, 243 , 244, 245, 302
martingale, 250
martingale difference sequence, 251
matrix
cost matrix, 22,5 6
covariance matrix, 89, 203 , 278
derivative of a matrix, 237
determinant of a matrix, 225
diagonal matrix, 223
Fisher information matrix, 45,4 6
Gram matrix, 33, 34, 43, 53, 56, 62, 64, 84, 85,
91, 95, 108, 111, 259, 266, 270, 327
Hessian matrix, 268 , 270, 276
identity matrix, 223
inverse of a matrix, 84, 228
Jacobian matrix, 307
kernel matrix, 33, 33
Kronecker product, 236
lower triangular matrix, 223
non-singular matrix, 224
orthogonal matrix, 224
parameter matrix, 223
partitioned inverse of a matrix, 230 , 266, 269
positive deﬁnite matrix, 224
positive semideﬁnite matrix, 34, 224
rank of a matrix, 33, 224
singular matrix, 224
square matrix, 223
symmetric matrix, 223
trace of a matrix, 227
transpose of a matrix, 224
triangular matrix, 223
upper triangular matrix, 223
maximal stability perceptron, 70
maximum entropy, 112
maximum likelihood, 107 , 158, 278
maximum-a-posteriori, 29, 80, 97, 107
McDiarmid’s inequality, 185, 188, 252 , 319
MCMC, 100
mean ﬁeld approximation, 110measurability, 201
measurable space, 200
measure, 112
conditional measure, 103conditional probability measure, 84, 202
empirical measure, 18, 104, 122, 203
marginal probabiity measure, 202
marginalized prior measure, 97
posterior measure, 74, 83, 110, 112, 164, 165
prior measure, 74, 76, 82, 92, 93, 97, 110
probability measure, 200
362 Index
Mercer feature, 35
Mercer kernel, 33, 35, 36, 37, 47, 48, 51, 52, 63,
264, 327
Mercer map, 35
Mercer space, 35
Mercer’s theorem, 33, 34,6 8
metric, 5, 216
Mahalanobis metric, 36
metric space, 216
Minkowski’s inequality, 217
MINOS, 323
MinOver, 70
mistake, 182
mistake bound, 183 , 195
mistake bound into generalization error bound, 183
mistake-driven algorithm, 182 , 184, 195
mixture model, 6, 44
model selection, 65, 78, 110, 133, 134, 193, 195
moment generating function, 245
Monte-Carlo, 90, 100
multiclass support vector machine, 58, 70multiple testing lemma, 132, 138, 145, 149, 164,
165, 179, 181
naive Fisher kernel, 46
natural statistics, 207
nearest-neighbor algorithm, 9
neural networks, 2, 70, 110Newton-Raphson method, 87, 90, 268 , 270, 276
noise, 58, 89, 98, 103, 193
non-singular matrix, 224
nonlinear classiﬁer, 30
normal distribution, 208
normalization, 70
normalized kernel, 37, 192
normalized margin, 173
normed space, 216
NPA, 70
occupancy problem, 40
on-line algorithm, 182 , 194
one-versus-one, 59
one-versus-rest, 58
open ball, 217 , 302, 303
optimal perceptron, 111
oracle, 159
orthogonal matrix, 224
outlier, 54, 60, 67
output space, 17
overﬁtting, 29,5 4PAC compression bound, 179
PAC framework, 122 , 126, 158, 281
PAC generalization error bound, 122 ,125 , 133
PAC likelihood, 76, 98, 164, 165, 169
PAC luckiness, 139
PAC margin bound, 150 , 161, 174
PAC-Bayesian framework, 164 , 175, 193, 300
PAC-Bayesian margin bound, 173 , 194
PAC-Bayesian posterior, 170
packing number, 220
parameter matrix, 223
partitioned inverse of a matrix, 230 , 266, 269
pattern recognition, 3perceptron learning algorithm, 26, 27, 28, 32, 47,
51, 68, 176, 177, 182, 184, 321
perceptrons, 1
pigeonhole principle, 221
Poisson distribution, 207
polynomial kernel, 38, 39, 69positive deﬁnite function, 218
positive deﬁnite matrix, 224
positive semideﬁnite function, 218
positive semideﬁnite matrix, 34, 224
positively biased relevant collections, 139
posterior measure, 74, 110, 112, 164, 165
pre-Hilbert space, 217
predictive distribution, 87, 90, 94, 98
predictive model, 103
preference learning, 4
primal space, 27
prior knowledge, 23, 77, 164, 193
prior measure, 74, 76, 92, 93, 97, 110
probabilistic method, 297
probability density, 2, 201 , 208
probability measure, 200
probability space, 200
probability theory, 11
probable smoothness, 137 , 181, 290, 292
product space, 202
pruning, 126
quadratic programming problem, 323
quadratic soft margin loss, 54, 55, 85, 261
quantiﬁer reversal lemma, 166, 300
random variable, 201
rank, 4,3 3
rank of a matrix, 224
Rayleigh coefﬁcient, 234
RBF kernel, 37, 53, 66, 174, 192
realizability, 159
363 Index
reconstruction function, 177 , 183
regression estimation, 58–60, 70, 81, 185
regularization, 29, 29, 49, 51, 54, 55, 64, 66, 68,
69, 107
regularized risk, 29, 48, 187
reinforcement learning, 2, 7
relevance vector machine, 95, 111, 178, 271
relevance vectors, 95
representation, 9, 19, 30, 41, 44, 47, 49, 321
representer theorem, 48, 69, 257
reproducing kernel Hilbert space, 47, 315
reproducing property, 48
ridge problem, 43
Riemannian manifold, 69
risk
empirical risk, 25
expected risk, 22,61
guaranteed risk, 29
regularized risk, 29,4 8
structural risk, 53
risky bound, 175
RKHS, 47, 48, 51, 69
robust margin bound, 155
robustness of a learning algorithm, 185, 186 , 195
robustness trick, 156
sampling model, 103
Scheffé’s theorem, 120, 206
self bounding learning algorithm, 160
self-adjoint operator, 219
shatter coefﬁcient, 128
shattering, 128 , 293
sigmoid, 88,8 9
sigmoidal loss, 91
similarity, 6, 19
singular matrix, 224
slack variable, 63, 112, 156, 158, 190, 192
SMO, 70
soft margin, 49, 63, 70, 156
soft margin support vector machine, 54, 60, 70,
156, 192, 259, 323
space
complete space, 219
dual space, 32
feature space, 19,3 4
Hilbert space, 219
hypothesis space, 19, 21, 23, 53, 56, 74, 129
inner product space, 19, 34, 37, 152, 217 , 296
input space, 17, 37, 38
kernel space, 33
measurable space, 200Mercer space, 35
metric space, 216
normed space, 216
output space, 17
pre-Hilbert space, 217
primal space, 27
probability space, 200
product space, 202
reproducing kernel Hilbert space, 47, 315
vector space, 215
version space, 27, 28, 57, 58, 68, 98, 100, 141,
165, 166, 168, 173, 185, 302, 303, 306
sparsity, 93, 94, 96, 194
square matrix, 223
squared loss, 82
SRM, 132 , 133
stability
βm–stability, 186 , 191
stability of regularized risk minimization, 187
stable learning algorithm, 186
stable solution, 239
statistical learning theory, 2
stochastic ill-posed problem, 68
stochastic process, 84, 110
string, 41
string kernel, 41, 69, 254
structural risk, 53
structural risk minimization, 29, 68, 132 , 133, 160,
164, 169, 174
structure, 132
data-dependent strucure, 138
subjective belief, 74
subsequence kernel, 43,4 4
substring kernel, 42,4 4
sufﬁcient statistic, 46,4 7
supervised learning, 2, 3,1 2
support vector, 63
support vector machine, 2, 5, 49, 64, 67, 69, 91,
101, 112, 135, 174, 176, 177, 184, 259, 323
support vector regression, 59, 190
SVM, 49, 54, 58, 70, 323
SVMlight,7 0
swapping permutation, 144, 284 , 286, 291–293
symmetric matrix, 223
symmetrization by a ghost sample, 124 , 181
symmetrization by permutation, 124 , 143, 291
target concept, 159, 183 , 194, 195
teacher perceptron, 27
thermodynamic limit, 111
trace of a matrix, 227
364 Index
training error, 25
training sample, 3, 18
transpose of a matrix, 224
triangle inequality, 120, 121, 186, 216 , 252, 319
triangular matrix, 223
truncation operator, 148
uniform convergence, 121 , 122, 131, 159, 175
uniform distribution, 207
union bound, 123, 125, 132, 160, 178, 242 , 247,
285, 287, 292
unit vector, 223
unsupervised learning, 2, 6
upper triangular matrix, 223
variance, 85, 202
VC dimension, 29, 128, 128 , 130–132, 134, 146,
160, 180, 181, 189, 195, 289
effective VC dimension, 151
VC framework, 122 , 126, 158, 183, 189, 281
VC generalization error bound, 122 ,125 , 133
vector space, 215
version space, 27, 28, 57, 58, 68, 98, 100, 141, 165,
166, 168, 173, 185, 302, 303, 306
volume ratio, 303 , 306
weight vector, 20, 26, 49, 50, 53, 56, 82, 84, 91, 92,
94, 95, 97, 105, 108, 149, 177, 182, 271, 321
well-posed problem, 240
Wolfe dual, 53, 54, 56, 260 , 261–263
Woodbury formula, 83, 229 , 234, 269, 272
words, 42
zero-one loss, 22
A K
PETERS Computer Algebra and Symbolic ComputationCohenElementary AlgorithmsComputer Algebra and
Symbolic Computation
Elementary AlgorithmsJOEL S. COHEN

/G67/G111/G109/G112/G117/G116/G101/G114/G32/G65/G108/G103/G101/G98/G114/G97/G32/G97/G110/G100/G32/G83/G121/G109/G98/G111/G108/G105/G99/G32/G67/G111/G109/G112/G117/G116/G97/G116/G105/G111/G110

/G67/G111/G109/G112/G117/G116/G101/G114/G32/G65/G108/G103/G101/G98/G114/G97/G32/G97/G110/G100/G32/G83/G121/G109/G98/G111/G108/G105/G99/G32/G67/G111/G109/G112/G117/G116/G97/G116/G105/G111/G110
/G69/G108/G101/G109/G101/G110/G116/G97/G114/G121/G32/G65/G108/G103/G111/G114/G105/G116/G104/G109/G115
/G74/G111/G101/G108/G32/G83/G46/G32/G67/G111/G104/G101/G110
/G68/G101/G112/G97/G114/G116/G109/G101/G110/G116/G32/G111/G102/G32/G67/G111/G109/G112/G117/G116/G101/G114/G32/G83/G99/G105/G101/G110/G99/G101
/G85/G110/G105/G118/G101/G114/G115/G105/G116/G121/G32/G111/G102/G32/G68/G101/G110/G118/G101/G114
/G65/G32/G75/G32/G80/G101/G116/G101/G114/G115
/G78/G97/G116/G105/G99/G107/G44/G32/G77/G97/G115/G115/G97/G99/G104/G117/G115/G101/G116/G116/G115
/G80/G114/G105/G110/G116/G101/G100/G32/G105/G110/G32/G67/G97/G110/G97/G100/G97
/G48/G54/G32/G32/G48/G53/G32/G32/G48/G52/G32/G32/G48/G51/G32/G32/G48/G50/G32/G32/G32/G32/G32/G32/G32/G49/G48/G32/G32/G57/G32/G32/G56/G32/G32/G55/G32/G32/G54/G32/G32/G53/G32/G32/G52/G32/G32/G51/G32/G32/G50/G32/G32/G49/G76/G105/G98/G114/G97/G114/G121/G32/G111/G102/G32/G67/G111/G110/G103/G114/G101/G115/G115/G32/G67/G97/G116/G97/G108/G111/G103/G105/G110/G103/G45/G105/G110/G45/G80/G117/G98/G108/G105/G99/G97/G116/G105/G111/G110/G32/G68/G97/G116/G97
/G67/G111/G104/G101/G110/G44/G32/G74/G111/G101/G108/G32/G83/G46/G32/G32/G32/G32/G32/G67/G111/G109/G112/G117/G116/G101/G114/G32/G97/G108/G103/G101/G98/G114/G97/G32/G97/G110/G100/G32/G115/G121/G109/G98/G111/G108/G105/G99/G32/G99/G111/G109/G112/G117/G116/G97/G116/G105/G111/G110/G32/G58/G32/G101/G108/G101/G109/G101/G110/G116/G97/G114/G121
/G97/G108/G103/G111/G114/G105/G116/G104/G109/G115/G32/G47/G32/G74/G111/G101/G108/G32/G83/G46/G32/G67/G111/G104/G101/G110/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G112/G46/G32/G99/G109/G46/G32/G32/G32/G32/G32/G32/G73/G110/G99/G108/G117/G100/G101/G115/G32/G98/G105/G98/G108/G105/G111/G103/G114/G97/G112/G104/G105/G99/G97/G108/G32/G114/G101/G102/G101/G114/G101/G110/G99/G101/G115/G32/G97/G110/G100/G32/G105/G110/G100/G101/G120/G46/G32/G32/G32/G32/G32/G73/G83/G66/G78/G32/G49/G45/G53/G54/G56/G56/G49/G45/G49/G53/G56/G45/G54/G32/G32/G32/G32/G32/G32/G49/G46/G32/G65/G108/G103/G101/G98/G114/G97/G150/G68/G97/G116/G97/G32/G112/G114/G111/G99/G101/G115/G115/G105/G110/G103/G46/G32/G73/G46/G32/G84/G105/G116/G108/G101/G46
/G81/G65/G49/G53/G53/G46/G55/G46/G69/G52/G32/G46/G67/G54/G51/G53/G32/G50/G48/G48/G50
/G53/G49/G50/G150/G100/G99/G50/G49/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G32/G50/G48/G48/G49/G48/G53/G53/G49/G53/G57/G69/G100/G105/G116/G111/G114/G105/G97/G108/G44/G32/G83/G97/G108/G101/G115/G44/G32/G97/G110/G100/G32/G67/G117/G115/G116/G111/G109/G101/G114/G32/G83/G101/G114/G118/G105/G99/G101/G32/G79/G102 /G102/G105/G99/G101
/G65/G32/G75/G32/G80/G101/G116/G101/G114/G115/G44/G32/G76/G116/G100/G46/G54/G51/G32/G83/G111/G117/G116/G104/G32/G65/G118/G101/G110/G117/G101/G78/G97/G116/G105/G99/G107/G44/G32/G77/G65/G32/G32/G48/G49/G55/G54/G48/G119/G119/G119/G46/G97/G107/G112/G101/G116/G101/G114/G115/G46/G99/G111/G109
/G67/G111/G112/G121/G114/G105/G103/G104/G116/G32/G32/G169/G32/G32/G50/G48/G48/G50/G32/G98/G121/G32/G65/G32/G75/G32/G80/G101/G116/G101/G114/G115/G44/G32/G76/G116/G100/G46/G65/G108/G108/G32/G114/G105/G103/G104/G116/G115/G32/G114/G101/G115/G101/G114/G118/G101/G100/G46/G32/G78/G111/G32/G112/G97/G114/G116/G32/G111/G102/G32/G116/G104/G101/G32/G109/G97/G116/G101/G114/G105/G97/G108/G32/G112/G114/G111/G116/G101/G99/G116/G101/G100/G32/G98/G121/G32/G116/G104/G105/G115/G32/G99/G111/G112/G121/G114/G105/G103/G104/G116/G32/G110/G111/G116/G105/G99/G101
/G109/G97/G121/G32/G98/G101/G32/G114/G101/G112/G114/G111/G100/G117/G99/G101/G100/G32/G111/G114/G32/G117/G116/G105/G108/G105/G122/G101/G100/G32/G105/G110/G32/G97/G110/G121/G32/G102/G111/G114/G109/G44/G32/G101/G108/G101/G99/G116/G114/G111/G110/G105/G99/G32/G111/G114/G32/G109/G101/G99/G104/G97/G110/G105/G99/G97/G108/G44/G32/G105/G110/G99/G108/G117/G100/G105/G110/G103/G112/G104/G111/G116/G111/G99/G111/G112/G121/G105/G110/G103/G44/G32/G114/G101/G99/G111/G114/G100/G105/G110/G103/G44/G32/G111/G114/G32/G98/G121/G32/G97/G110/G121/G32/G105/G110/G102/G111/G114/G109/G97/G116/G105/G111/G110/G32/G115/G116/G111/G114/G97/G103/G101/G32/G97/G110/G100/G32/G114/G101/G116/G114/G105/G101/G118/G97/G108/G32/G115/G121/G115/G116/G101/G109/G44/G119/G105/G116/G104/G111/G117/G116/G32/G119/G114/G105/G116/G116/G101/G110/G32/G112/G101/G114/G109/G105/G115/G115/G105/G111/G110/G32/G102/G114/G111/G109/G32/G116/G104/G101/G32/G99/G111/G112/G121/G114/G105/G103/G104/G116/G32/G111/G119/G110/G101/G114/G46
/G84/G111/G32/G109/G121/G32/G119/G105/G102/G101/G32/G75/G97/G116/G104/G114/G121/G110

Contents
Preface ix
1 Introduction to Computer Algebra 1
1.1 Computer Algebra and Computer Algebra Systems . . . . . 1
1 . 2 A p p l i c a t i o n so fC o m p u t e rA l g e b r a .............. 10
2 Elementary Concepts of Computer Algebra 29
2.1 Mathematical Pseudo-language (MPL). . . . . . . . . . . 29
2 . 2 E x p r e s s i o nE v a l u a t i o n..................... 49
2 . 3 M a t h e m a t i c a lP r o g r a m s.................... 58
2 . 4 S e t sa n dL i s t s ......................... 68
3 Recursive Structure of Mathematical Expressions 77
3.1 Recursive Deﬁnitions and Algorithms . . . . . . . . . . . . . 77
3 . 2 E x p r e s s i o nS t r u c t u r ea n dT r e e s................ 84
3 . 3 S t r u c t u r e - B a s e dO p e r a t o r s .................. 108
4 Elementary Mathematical Algorithms 119
4.1 Mathematical Algorithms . . . . . . . . . . . . . . . . . . . 119
4 . 2 M P L ’ sA l g o r i t h m i cL a n g u a g e................. 132
4.3 Case Study: First Order Ordinary Diﬀerential Equations . . 156
5 Recursive Algorithms 171
5 . 1 AC o m p u t a t i o n a lV i e wo fR e c u r s i o n ............. 171
5 . 2 R e c u r s i v eP r o c e d u r e s ..................... 176
5.3 Case Study: Elementary Integration Operator . . . . . . . . 199
vii
viii Contents
6 Structure of Polynomials and Rational Expressions 213
6.1 Single Variable Polynomials . . . . . . . . . . . . . . . . . . 214
6 . 2 G e n e r a lP o l y n o m i a lE x p r e s s i o n s ............... 223
6.3 Relationships Between Generalized Variables . . . . . . . . 242
6.4 Manipulation of General Polynomial Expressions . . . . . . 247
6.5 General Rational Expressions . . . . . . . . . . . . . . . . . 259
7 Exponential and Trigonometric Transformations 275
7.1 Exponential and Trigonometric Expansion . . . . . . . . . . 275
7.2 Exponential and Trigonometric Contraction . . . . . . . . . 289
Bibliography 307
Index 316
Preface
Computer algebra is the ﬁeld of mathematics and computer science that is
concerned with the development, implementation, and application of algo-
rithms that manipulate and analyze mathematical expressions. This bookand the companion text, Computer Algebra and Symbolic Computation:
Mathematical Methods , are an introduction to the subject that addresses
both its practical and theoretical aspects. This book, which addressesthe practical side, is concerned with the formulation of algorithms that
solve symbolic mathematical problems, and with the implementation of
these algorithms in terms of the operations and control structures avail-
able in computer algebra programming languages. Mathematical Methods ,
which addresses more theoretical issues, is concerned with the basic math-ematical and algorithmic concepts that are the foundation of the subject.
Both books serve as a bridge between texts and manuals that show how
to use computer algebra software and graduate level texts that describealgorithms at the forefront of the ﬁeld.
These books have been in various stages of development for over 15
years. They are based on the class notes for a two-quarter course sequence
in computer algebra that has been oﬀered at the University of Denver every
other year for the past 16 years. The ﬁrst course, which is the basis for El-
ementary Algorithms , attracts primarily undergraduate students and a few
graduate students from mathematics, computer science, and engineering.
The second course, which is the basis for Mathematical Methods , attracts
primarily graduate students in both mathematics and computer science.
The course is cross-listed under both mathematics and computer science.
ix
x Preface
Prerequisites
The target audience for these books includes students and professionals
from mathematics, computer science, and other technical ﬁelds who would
like to know about computer algebra and its applications.
In the spirit of an introductory text, we have tried to minimize the
prerequisites. The mathematical prerequisites include the usual two yearfreshman–sophomore sequence of courses (calculus through multivariable
calculus, elementary linear algebra, and applied ordinary diﬀerential equa-
tions). In addition, an introductory course in discrete mathematics is rec-ommended because mathematical induction is used as a proof technique
throughout. Topics from elementary number theory and abstract algebra
are introduced as needed.
On the computer science side, we assume that the reader has had some
experience with a computer programming language such as Fortran, Pascal,C, C++, or Java. Although these languages are not used in these books,
the skills in problem solving and algorithm development obtained in a be-
ginning programming course are essential. One programming techniquethat is especially important in computer algebra is recursion. Although
many students will have seen recursion in a conventional programming
course, the topic is described in Chapter 5 of Elementary Algorithms from
a computer algebra perspective.
Realistically speaking, while these prerequisites suﬃce in a formal sense
for both books, in a practical sense there are some sections as the texts
progress where greater mathematical and computational sophistication is
required. Although the mathematical development in these sections can bechallenging for students with the minimum prerequisites, the algorithms
are accessible, and these sections provide a transition to more advanced
treatments of the subject.
Organization and Content
Broadly speaking, these books are intended to serve two (complementary)
purposes:
To provide a systematic approach to the algorithmic formulation and
implementation of mathematical operations in a computer algebra
programming language.
Algorithmic methods in traditional mathematics are usually not pre-
sented with the precision found in numerical mathematics or conventional
computer programming. For example, the algorithm for the expansion of
products and powers of polynomials is usually given informally instead of
with (recursive)procedures that can be expressed as a computer program.
Preface xi
The material in Elementary Algorithms is concerned with the algorith-
mic formulation of solutions to elementary symbolic mathematical prob-
lems. The viewpoint is that mathematical expressions, represented as ex-
pression trees, are the data objects of computer algebra programs, and byusing a few primitive operations that analyze and construct expressions,
we can implement many elementary operations from algebra, trigonometry,
calculus, and diﬀerential equations. For example, algorithms are given forthe analysis and manipulation of polynomials and rational expressions, the
manipulation of exponential and trigonometric functions, diﬀerentiation,
elementary integration, and the solution of ﬁrst order diﬀerential equa-
tions. Most of the material in this book is not found in either mathematics
textbooks or in other, more advanced computer algebra textbooks.
To describe some of the mathematical concepts and algorithmic tech-
niques utilized by modern computer algebra software.
For the past 35 years, the research in computer algebra has been con-
cerned with the development of eﬀective and eﬃcient algorithms for many
mathematical operations including polynomial greatest common divisor
(gcd)computation, polynomial factorization, polynomial decomposition,
the solution of systems of linear equations and multivariate polynomial
equations, indeﬁnite integration, and the solution of diﬀerential equations.Although algorithms for some of these problems have been known since the
nineteenth century, for eﬃciency reasons they are not suitable as general
purpose algorithms for computer algebra software. The classical algorithmsare important, however, because they are much simpler and provide a con-
text to motivate the basic algebraic ideas and the need for more eﬃcient
approaches.
The material in Mathematical Methods is an introduction to the math-
ematical techniques and algorithmic methods of computer algebra. Al-
though the material in this book is more diﬃcult and requires greater math-
ematical sophistication, the approach and selection of topics is designed so
that it is accessible and interesting to the intended audience. Algorithms
are given for basic integer and rational number operations, automatic (ordefault)simpliﬁcation of algebraic expressions, greatest common divisor
calculation for single and multivariate polynomials, resultant computation,
polynomial decomposition, polynomial simpliﬁcation with Gr¨ obner bases,
and polynomial factorization.
xii Preface
Topic Selection
The author of an introductory text about a rapidly changing ﬁeld is faced
with a diﬃcult decision about which topics and algorithms to include in
the work. This decision is constrained by the background of the audience,
the mathematical diﬃculty of the material and, of course, by space limita-tions. In addition, we believe that an introductory text should really be an
introduction to the subject that describes some of the important issues in
the ﬁeld but should not try to be comprehensive or include all reﬁnementsof a particular topic or algorithm. This viewpoint has guided the selection
of topics, choice of algorithms, and level of mathematical rigor.
For example, polynomial gcd computation is an important topic in
Mathematical Methods that plays an essential role in modern computer
algebra software. We describe classical Euclidean algorithms for both sin-
gle and multivariate polynomials with rational number coeﬃcients and a
Euclidean algorithm for single variable polynomials with simple algebraic
number coeﬃcients. It is well known, however, that for eﬃciency rea-sons, these algorithms are not suitable as general purpose algorithms in
a computer algebra system. For this reason, we describe the more ad-
vanced subresultant gcd algorithm for multivariate polynomials but omitthe mathematical justiﬁcation, which is quite involved and far outside the
scope and spirit of these books.
One topic that is not discussed is the asymptotic complexity of the time
and space requirements of algorithms. Complexity analysis for computer
algebra, which is often quite involved, uses techniques from algorithm anal-ysis, probability theory, discrete mathematics, the theory of computation,
and other areas that are well beyond the background of the intended audi-
ence. Of course, it is impossible to ignore eﬃciency considerations entirelyand, when appropriate, we indicate (usually by example)some of the issues
that arise. A course based on Mathematical Methods is an ideal prerequi-
site for a graduate level course that includes the complexity analysis ofalgorithms along with recent developments in the ﬁeld
1.
Chapter Summaries
A more detailed description of the material covered in these books is given
in the following chapter summaries.
1A graduate level course could be based on one of the following books: Akritas [ 2],
Geddes, Czapor, and Labahn [ 39], Mignotte [ 66], Mignotte and S ¸tef˘anescu [ 67], Mishra
[68] ,v o nz u rG a t h e na n dG e r h a r d[ 96], Winkler [ 101], Yap [ 105], or Zippel [ 108].
Preface xiii
Elementary Algorithms
Chapter 1: Introduction to Computer Algebra. This chapter is
an introduction to the ﬁeld of computer algebra. It illustrates both the
possibilities and limitations for computer symbolic computation through
dialogues with a number of commercial computer algebra systems.
Chapter 2: Elementary Concepts of Computer Algebra. This
chapter introduces an algorithmic language called mathematical pseudo-
language (or simply MPL)that is used throughout the books to describe the
concepts, examples, and algorithms of computer algebra. MPL is a simple
language that can be easily translated into the structures and operationsavailable in modern computer algebra languages. This chapter also includes
a general description of the evaluation process in computer algebra software
(including automatic simpliﬁcation), and a case study which includes anMPL program that obtains the change of form of quadratic expressions
under rotation of coordinates.
Chapter 3: Recursive Structure of Mathematical Expressions.
This chapter is concerned with the internal tree structure of mathemati-
cal expressions. Both the conventional structure (before evaluation)and
the simpliﬁed structure (after evaluation and automatic simpliﬁcation)aredescribed. The structure of automatically simpliﬁed expressions is impor-
tant because all algorithms assume that the input data is in this form.
Four primitive MPL operators ( Kind,Operand ,Number
of
operands ,
andConstruct )that analyze and construct mathematical expressions are
introduced. The chapter also includes a description of four MPL opera-tors ( Free
of,Substitute ,Sequential
 substitute ,a n d Concurrent
 substitute )
which depend only on the tree structure of an expression.
Chapter 4: Elementary Mathematical Algorithms. In this chap-
ter we describe the basic programming structures in MPL and use these
structures to describe a number of elementary algorithms. The chapter
includes a case study which describes an algorithm that solves a class ofﬁrst order ordinary diﬀerential equations using the separation of variables
technique and the method of exact equations with integrating factors.
Chapter 5: Recursive Algorithms. This chapter describes recur-
sion as a programming technique in computer algebra and gives a number
of examples that illustrate its advantages and limitations. It includes a case
study that describes an elementary integration algorithm which ﬁnds theantiderivatives for a limited class of functions using the linear properties of
the integral and the substitution method. Extensions of the algorithm to
include the elementary rational function integration, some trigonometric
integrals, elementary integration by parts, and one algebraic function form
are described in the exercises.
xiv Preface
Chapter 6: Structure of Polynomials and Rational Expres-
sions. This chapter is concerned with the algorithms that analyze and ma-
nipulate polynomials and rational expressions. It includes computational
deﬁnitions for various classes of polynomials and rational expressions thatare based on the internal tree structure of expressions. Algorithms based
on the primitive operations introduced in Chapter 3 are given for degree
and coeﬃcient computation, coeﬃcient collection, expansion, and rational-ization of algebraic expressions.
Chapter 7: Exponential and Trigonometric Transformations.
This chapter is concerned with algorithms that manipulate exponential and
trigonometric functions. It includes algorithms for exponential expansionand reduction, trigonometric expansion and reduction, and a simpliﬁcation
algorithm that can verify a large class of trigonometric identities.
Mathematical Methods
Chapter 1: Background Concepts. This chapter is a summary
of the background material from Elementary Algorithms that provides a
frameworkfor the mathematical and computational discussions in the book.
It includes a description of the mathematical psuedo-language (MPL), a
brief discussion of the tree structure and polynomial structure of algebraic
expressions, and a summary of the basic mathematical operators that ap-pear in our algorithms.
Chapter 2: Integers, Rational Numbers, and Fields. This chap-
ter is concerned with the numerical objects that arise in computer algebra,
including integers, rational numbers, and algebraic numbers. It includesEuclid’s algorithm for the greatest common divisor of two integers, the
extended Euclidean algorithm, the Chinese remainder algorithm, and a
simpliﬁcation algorithm that transforms an involved arithmetic expressionwith integers and fractions to a rational number in standard form. In ad-
dition, it introduces the concept of a ﬁeld which describes in a general way
the properties of number systems that arise in computer algebra.
Chapter 3: Automatic Simpliﬁcation. Automatic simpliﬁcation
is deﬁned as the collection of algebraic and trigonometric simpliﬁcation
transformations that are applied to an expression as part of the evaluation
process. In this chapter we take an in-depth look at the algebraic compo-nent of this process, give a precise deﬁnition of an automatically simpliﬁed
expression, and describe an (involved)algorithm that transforms mathe-
matical expressions to automatically simpliﬁed form. Although automatic
simpliﬁcation is essential for the operation of computer algebra software,
this is the only detailed treatment of the topic in the textbook literature.
Preface xv
Chapter 4: Single Variable Polynomials. This chapter is con-
cerned with algorithms for single variable polynomials with coeﬃcients in
a ﬁeld. All algorithms in this chapter are ultimately based on polynomial
division. It includes algorithms for polynomial division and expansion, Eu-clid’s algorithm for greatest common divisor computation, the extended
Euclidean algorithm, and a polynomial version of the Chinese remainder
algorithm. In addition, the basic polynomial division and gcd algorithmsare used to give algorithms for numerical computations in elementary al-
gebraic number ﬁelds. These algorithms are then used to develop division
and gcd algorithms for polynomials with algebraic number coeﬃcients. The
chapter concludes with an algorithm for partial fraction expansion that is
based on the extended Euclidean algorithm.
Chapter 5: Polynomial Decomposition. Polynomial decomposi-
tion is a process that determines if a polynomial can be represented as a
composition of lower degree polynomials. In this chapter we discuss some
theoretical aspects of the decomposition problem and give an algorithmbased on polynomial factorization that either ﬁnds a decomposition or de-
termines that no decomposition exists.
Chapter 6: Multivariate Polynomials. This chapter generalizes
the division and gcd algorithms to multivariate polynomials with coef-
ﬁcients in an integral domain. It includes algorithms for three polyno-
mial division operations (recursive division, monomial-based division, andpseudo-division); polynomial expansion (including an application to the
algebraic substitution problem); and the primitive and subresultant algo-
rithms for gcd computation.
Chapter 7: The Resultant. This chapter introduces the resultant
of two polynomials, which is deﬁned as the determinant of a matrix whose
entries depend on the coeﬃcients of the polynomials. We describe a Eu-clidean algorithm and a subresultant algorithm for resultant computation
and use the resultant to ﬁnd polynomial relations for explicit algebraic
numbers.
Chapter 8: Polynomial Simpliﬁcation with Side Relations.
This chapter includes an introduction to Gr¨ obner basis computation with
an application to the polynomial simpliﬁcation problem. To simplify the
presentation, we assume that polynomials have rational number coeﬃcients
and use the lexicographical ordering scheme for monomials.
Chapter 9: Polynomial Factorization. The goal of this chapter is
the description of a basic version of a modern factorization algorithm forsingle variable polynomials in Q[x]. It includes square-free factorization
algorithms in Q[x]a n d Z
p[x], Kronecker’s classical factorization algorithm
forZ[x], Berlekamp’s algorithm for factorization in Zp[x], and a basic ver-
sion of the Hensel lifting algorithm.
xvi Preface
Computer Algebra Software and Programs
We use a procedure style of programming that corresponds most closely
to the programming structures and style of the Maple, Mathematica, and
MuPAD systems and, to a lesser degree, to the Macsyma and Reduce
systems. In addition, some algorithms are described by transformation
rules that translate to the pattern matching languages in the Mathematica
and Maple systems. Unfortunately, the programming style used here doesnot translate easily to the structures in the Axiom system.
The dialogues and algorithms in these books have been implemented
in the Maple 7.0, Mathematica 4.1, and MuPAD Pro (Version 2.0)sys-
tems. The dialogues and programs are found on a CD included with the
books. In each book, available dialogues and programs are indicated by theword “Implementation” followed by a system name Maple, Mathematica,
or MuPAD. System dialogues are in a notebook format (mws in Maple, nb
in Mathematica, and mnb in MuPAD), and procedures are in text (ASCII)
format (for examples, see the dialogue in Figure 1.1on page 3and the pro-
cedure in Figure 4.15on page 148). In some examples, the dialogue display
of a computer algebra system given in the text has been modiﬁed so that
it ﬁts on the printed page.
Electronic Version of the Book
These books have been processed in the L ATEX2εsystem with the hyperref
package, which allows hypertext links to chapter numbers, section numbers,displayed (and numbered)formulas, theorems, examples, ﬁgures, footnotes,
exercises, the table of contents, the index, the bibliography, and web sites.
An electronic version of the book (as well as additional reference ﬁles)in
the portable document format (PDF), which is displayed with the Adobe
Acrobat software, is included on the CD.
Acknowledgements
I am grateful to the many students and colleagues who read and helpeddebug preliminary versions of this book. Their advice, encouragement,
suggestions, criticisms, and corrections have greatly improved the style and
structure of the book. Thanks to Norman Bleistein, Andrew Burt, AlexChampion, the late Jack Cohen, Robert Coombe, George Donovan, Bill
Dorn, Richard Fateman, Clayton Ferner, Carl Gibbons, Herb Greenberg,
Jillane Hutchings, Lan Lin, Zhiming Li, Gouping Liu, John Magruder,
Jocelyn Marbeau, Stanly Steinberg, Joyce Stivers, Sandhya Vinjamuri, and
Diane Wagner.
Preface xvii
I am grateful to Gwen Diaz and Alex Champion for their help with
the L ATEX document preparation; Britta Wienand, who read most of the
text and translated many of the programs to the MuPAD language; Aditya
Nagrath, who created some of the ﬁgures; and Michael Wester who trans-lated many of the programs to the Mathematica, MuPAD, and Macsyma
languages. Thanks to Camie Bates, who read the entire manuscript and
made numerous suggestions that improved the exposition and notation,and helped clarify confusing sections of the book. Her careful reading dis-
covered numerous typographical, grammatical, and mathematical errors.
I also acknowledge the long-term support and encouragement of my
home institution, the University of Denver. During the writing of the
book, I was awarded two sabbatical leaves to develop this material.
Special thanks to my family for encouragement and support: my late
parents Elbert and Judith Cohen, Daniel Cohen, Fannye Cohen, and Louis
and Elizabeth Oberdorfer.
Finally, I would like to thank my wife, Kathryn, who as long as she can
remember, has lived through draft after draft of this book, and who with
patience, love, and support has helped make this book possible.
Joel S. Cohen
Denver, ColoradoSeptember, 2001
xviii Preface
1
Introduction to Computer Algebra
1.1 Computer Algebra and Computer Algebra Systems
The mathematical scientist models natural phenomena by translating ex-
perimental results and theoretical concepts into mathematical expressions
containing numbers, variables, functions, and operators. Then, using ac-cepted methods of mathematical reasoning, these expressions are carefully
manipulated or transformed into other expressions that reveal new knowl-
edge about the phenomenon being studied. This mathematical approach
to understanding the world has been an important component of the scien-
tiﬁc method in the physical sciences since the time of Galileo and Descartes.Following in the footsteps of these scientists, Isaac Newton used this ap-
proach to formulate an axiomatic, quantitative description of the motion of
objects. By using mathematical reasoning, he discovered the universal lawof gravitation and derived additional laws that describe the motion of the
tides and the orbits of the planets. Thus the science we call mechanics was
born, and the technique of manipulating and transforming mathematicalexpressions was ﬁrmly established as an important tool for discovering new
knowledge about the physical world.
In the past ﬁfty years, the computer has become an indispensable exper-
imental tool that greatly extends our ability to solve mathematical prob-lems. Mathematical scientists routinely use computers to obtain numerical
and graphical solutions to problems that are too diﬃcult or even impossible
to solve by hand. But computers are not just number crunchers. In fact, at
a basic level, computers simply manipulate symbols (0s and 1s) according
to well-deﬁned rules, and it is natural to ask what other parts of the math-
1
2 1. Introduction to Computer Algebra
ematical reasoning process are amenable to computer implementation. Of
course, it is unreasonable to expect a machine to formulate the axioms
of mechanics as Newton did or derive from scratch the important results
of the theory. However, one part of the mathematical reasoning process,the mechanical manipulation and analysis of mathematical expressions, is
surprisingly algorithmic. There are now computer programs that routinely
simplify algebraic expressions, integrate complicated functions, ﬁnd exactsolutions to diﬀerential equations, and perform many other operations en-
countered in applied mathematics, science, and engineering.
In this book we are concerned primarily with the development and
application of algorithms and computer programs that carry out this me-
chanical aspect of the mathematical reasoning process. The ﬁeld of mathe-
matics and computer science that is concerned with this problem is knownascomputer algebra orsymbol manipulation.
Computer Algebra Systems and Languages
Acomputer algebra system (CAS) or symbol manipulation system is a com-
puter program that performs symbolic mathematical operations. In Fig-
ure1.1we show an interactive dialogue with the Maple computer algebra
system developed by Waterloo Maple Inc. The statements that are pre-ceded by the prompt ( >) are inputs to the system that are entered at a
computer workstation. The commands factor ,convert ,compoly ,a n d
simplify are examples of mathematical operators in the Maple system. In
response to these statements, the program performs a mathematical oper-
ation and displays the result using a notation that is similar to ordinary
mathematical notation.
InF i g u r e 1.1, at the ﬁrst two prompts, a polynomial is assigned (with
the operator “ :=”) to a variable u1 and then factored in terms of irre-
ducible factors with respect to the rational numbers. (In other words, none
of the polynomials in the factored form can be factored further without
introducing radicals.) At prompts three and four, we enter a rational ex-
pression and then ﬁnd its partial fraction decomposition. At the next twoprompts, Maple’s compoly command determines that the polynomial u3i s
ac o m p o s i t e
u3=f(g(x)),f(x)=x
3+1 0+8x+3x2,g(x)=3x+x2.
The process of representing a polynomial as a composite of lower degree
polynomials is called polynomial decomposition . At the remaining prompts,
1.1. Computer Algebra and Computer Algebra Systems 3
> u1 := x^5-4*x^4-7*x^3-41*x^2-4*x+35;
u1:=x5−4x4−7x3−41x2−4x+35
> factor(u1);
(x+1)(x2+2x+7)(x2−7x+5)
> u2 := (x^4+7*x^2+3)/(x^5+x^3+x^2+1);
u2:=x4+7x2+3
x5+x3+x2+1
> convert(u2,parfrac,x) ;
11
61
x+1+2
3(4+x)
x2−x+1−3
2x+1
x2+1
> u3 := x^6+9*x^5+30*x^4+45*x^3+35*x^2+24*x+10;
u3:=x6+9x5+30x4+45x3+35x2+24x+10
> compoly(u3,x);
x3+10+8 x+3x2,x=3x+x2
> u4 := 1/(1/a+c/(a*b))+(a*b*c+a*c^2)/(b+c)^2;
u4:=1
1
a+c
ab+abc+ac2
(b+c)2
> simplify(u4);
a
> u5 := (sin(x)+sin(3*x)+sin(5*x)+sin(7*x))/(cos(x)+cos(3*x)
+cos(5*x)+cos(7*x))-tan(4*x);
u5:=sin(x)+sin(3 x)+sin(5 x)+sin(7 x)
cos(x)+cos(3x)+cos(5x)+cos(7x)−tan(4x)
> simplify(u5);
0
Figure 1.1. An interactive dialogue with the Maple system that shows some
symbolic operations from algebra and trigonometry. (Implementation: Maple
(mws),Mathematica (nb),MuPAD(mnb).)
4 1. Introduction to Computer Algebra
> u6 := cos(2*x+3)/(x^2+1);
u6:=cos(2x+3)
x2+1
> diff(u6,x);
−2sin(2x+3)
x2+1−2cos(2x+3)x
(x2+1)2
> u7 := cos(x)/(sin(x)^2+3*sin(x)+4);
u7:=cos(x)
sin(x)2+3sin(x)+4
> int(u7,x);
2
7√
7arctanW1
7(2sin(x)+3)√
7}
> u8 := diff(y(x),x) + 3*y(x) = x^2+sin(x);
u8:=W∂
∂xy(x)}
+3y(x)=x2+sin(x)
> dsolve(u8,y(x));
y(x)=1
3x2−2
9x+2
27−1
10cos(x)+3
10sin(x)+e(−3x)
C1
Figure 1.2. An interactive dialogue with the Maple system that shows some
symbolic operations from calculus and diﬀerential equations. (Implementation:
Maple(mws),Mathematica (nb),MuPAD(mnb).)
Maple simpliﬁes an involved algebraic expression u4 and then veriﬁes a
trigonometric identity1.
InF i g u r e 1.2, we again call on Maple to perform some operations from
calculus and diﬀerential equations2.T h e diffcommand at the second
1Algebraic simpliﬁcation is described in Sections 2.2and6.5, and trigonometric sim-
pliﬁcation is described in Section 7.2.
For further study, the reader may consult Cohen [ 24]: algebraic simpliﬁcation is dis-
cussed in Chapter 3, Section 6.3, and Chapter 8; partial fraction decomposition in Section4.4; polynomial decomposition in Chapter 5; and polynomial factorization in Chapter 9.
2We give algorithms in the book for all of these operations. Diﬀerentiation is de-
scribed in Section 5.2, elementary integration in Section 5.3, and the solution of diﬀer-
ential equations in Section 4.3.
1.1. Computer Algebra and Computer Algebra Systems 5
prompt is used for diﬀerentiation and the intcommand at the fourth
prompt is for integration. Notice that the output of the intoperator does
not include the arbitrary constant of integration. At the ﬁfth prompt we
assign a ﬁrst order diﬀerential equation3tou7, and at the sixth prompt
ask Maple to solve the diﬀerential equation. The symbol
 C1 is Maple’s
way of including an arbitrary constant in the solution4.
We use the term computer algebra language orsymbolic programming
language to refer to the computer language that is used to interact with a
CAS. Most computer algebra systems can operate in a programming mode
as well as an interactive mode (shown in Figures 1.1and1.2). In the pro-
gramming mode, the mathematical operators factor ,simplify ,e t c .,a r e
combined with standard programming constructs such as assignment state-
ments, loops, conditional statements, and subprograms to create programs
that solve more involved mathematical problems.
To illustrate this point, consider the problem of ﬁnding the formula for
the tangent line to the curve
y=f(x)=x2+5x+6
at the point x= 2. First, we ﬁnd a general formula for the slope by
diﬀerentiation
dy
dx=2x+5.
T h es l o p ea tt h ep o i n t x= 2 is obtained by substituting this value into
this expression
m=dy
dx(2) = 2(2) + 5 = 9 .
The equation for the tangent line is obtained using the point slope form
for a line:
y=m(x−2) +f(2) = 9( x−2) + 20 (1.1)
=9x+2.
To obtain the last formula, we have expanded the right side of Equa-
tion (1.1).
InF i g u r e 1.3we give a general procedure, written in the Maple com-
puter algebra language that mimics these calculations. The procedure com-
putes the tangent line formula for an arbitrary expression fat the point
3Maple displays the derivative of an unknown function y(x) using the partial deriva-
tive symbol instead of ordinary derivative notation.
4Maple includes an arbitrary constant in the solution of a diﬀerential equation, but
does not include the arbitrary constant for an antidiﬀerentiation. Inconsistencies of thissort are commonplace with computer algebra software.
6 1. Introduction to Computer Algebra
1 Tangent_line := proc(f,x,a)
2 local
3 deriv,m,line;4 deriv := diff(f,x);
5 m := subs(x=a,deriv);
6 line := expand(m*(x-a)+subs(x=a,f));7 RETURN(line)
8 end:
Figure 1.3. A procedure in the Maple language that obtains a formula for the
tangent line. The line numbers are not part of the Maple program. (Implemen-tation:Maple(txt),Mathematica (txt),MuPAD(txt).)
x=a. The operator diffin line 4 is used for diﬀerentiation and the
operator subsin line 5 for substitution. The expand operator in line 6 is
included to simplify the output. Once the procedure is entered into theMaple system, it can be invoked from the interactive mode of the system
(see Figure 1.4).
> Tangent_line(x^2+5*x+6, x, 2);
9x+2
Figure 1.4. The execution of the Tangent
 lineprocedure in the interactive
mode of the Maple system. (Implementation: Maple(mws),Mathematica (nb),
MuPAD(mnb).)
Commercial Computer Algebra Systems
In the last 15 years, we have seen the creation and widespread distribution
of a number of large (but easy to use) computer algebra systems. The most
prominent of the commercial and University packages are:
•Axiom – a very large CAS originally developed at IBM under the
name Scratchpad. Information about Axiom can be found in Jenks
and Sutor [ 50].
•Derive – a small CAS originally designed by Soft Warehouse Inc. for
use on a personal computer. Derive has also been incorporated in the
1.1. Computer Algebra and Computer Algebra Systems 7
TI-89 and TI-92 handheld calculators produced by Texas Instruments
Inc. Information about Derive can be found at the web site
http://www.derive.com .
•Macsyma – a very large CAS originally developed at M.I.T. in the
late 1960s and 1970s. There are currently a number of versions of the
original Macsyma system. Information about Macsyma can be found
in Wester [ 100].
•Maple – a very large CAS originally developed by the Symbolic
Computation Group at the University of Waterloo (Canada) and now
distributed by Waterloo Maple Inc. Information about Maple is found
in Heck [ 45]o ra tt h ew e bs i t e
http://www.maplesoft.com .
•Mathematica – a very large CAS developed by Wolfram Research
Inc. Information about Mathematica can be found in Wolfram [ 102]
or at the web site
http://www.wolfram.com .
•MuPAD – a large CAS developed by the University of Paderborn
(Germany) and SciFace Software GmbH & Co. KG. Information about
MuPAD can be found in Gerhard et al. [ 40]o ra tt h ew e bs i t e
http://www.mupad.com .
•Reduce – one of the earliest computer algebra systems originally
developed in the late 1960s and 1970s. Information about Reduce isfound in Rayna [ 83]o ra tt h ew e bs i t e
http://www.uni-koeln.de/REDUCE .
All of these packages are integrated mathematics problem solving sys-
tems that include facilities for exact symbolic computations (similar to
those in Figures 1.1,1.2,a n d 1.3), along with some capability for (ap-
proximate) numerical solution of mathematical problems and high quality
graphics. The examples in this book refer primarily to the computer al-
gebra capabilities of the Maple, Mathematica, and MuPAD systems, since
these systems are readily available and support a programming style that
is most similar to the one used here.
8 1. Introduction to Computer Algebra
Mathematical Knowledge in Computer Algebra Systems
Computer algebra systems have the capability to perform exact symbolic
computations in many areas of mathematics. A sampling of these capabil-
ities includes:
•Arithmetic – unlimited precision rational number arithmetic, com-
plex (rational number) arithmetic, transformation of number bases,
interval arithmetic, modulo arithmetic, integer operations (greatestcommon divisors, least common multiples, prime factorization), com-
binatorial functions.
•Algebraic manipulation – simpliﬁcation, expansion, factorization,
substitution operations.
•Polynomialoperations – structural operations on polynomials (de-
gree, coeﬃcient extraction), polynomial division, greatest common
divisors, factorization, resultant calculations, polynomial decomposi-tion, simpliﬁcation with respect to side relations.
•Solution of equations – polynomial equations, some non-linear
equations, systems of linear equations, systems of polynomial equa-
tions, recurrence relations.
•Trigonometry – trigonometric expansion and reduction, veriﬁcation
of identities.
•Calculus – derivatives, antiderivatives, deﬁnite integrals, limits, Tay-
lor series, manipulation of power series, summation of series, opera-
tions with the special functions of mathematical physics.
•Diﬀerentialequations – solution of ordinary diﬀerential equations,
solution of systems of diﬀerential equations, solution using series,solution using Laplace transforms, solution of some partial diﬀerential
equations.
•Advanced algebra – manipulations with algebraic numbers, group
theory, Galois groups.
•Linear algebra and related topics – matrix operations, vector
and tensor analysis.
•Code generation – formula translation to conventional program-
ming languages such as FORTRAN and C, formula translation to
mathematics word processing languages (L
ATEX).
1.1. Computer Algebra and Computer Algebra Systems 9
In addition, computer algebra systems have the capability to utilize this
mathematical knowledge in computer programs that solve other mathe-
matical problems.
Exercises
1. What transformation rules from algebra, trigonometry, or calculus must a
computer “know” to perform the following operations? Be careful not toomit any obvious arithmetic or algebraic rules that are used to obtain theresult in a simpliﬁed form.
(a)d(ax+xe
x2)
dx=a+ex2+2x2ex2.
(b)sec(x)
sin(x)−sin(x)
cos(x)−cot(x)=0.
(c)1
1/a+c/(ab)+abc+ac2
(b+c)2=a.
2. All computer algebra systems include an algebraic expansion command
that obtains transformations similar to
(x+2)(x+3)(x+4) = x3+9x2+26x+24,
(x+y+z)3=x3+y3+z3+3x2y+3x2z+3y2x
+3y2z+3z2x+3z2y+6xyz,
(x+1)2+(y+1)2=x2+2x+y2+2y+2,
((x+2)2+3)2=x4+8x3+30x2+56x+49.
(In Maple, the expandcommand; in Mathematica the Expandcommand;
in MuPAD, the expandcommand.)
What algorithm would you use to perform this operation? It is not nec-
essary to give the exact algorithm. Rather describe some of the issues
that arise when youtry to design a mechanical procedu re for this opera-
tion. What mathematical and computational techniques are useful for thisalgorithm?
3. The simpliﬁcation of mathematical expressions is an important aspect of
themathematical reasoning processandallcomputeralgebra systemshavesome capability to perform this operation (see Figure 1.1on page3). Al-
though simpliﬁcation is described in elementary mathematics textbooks,
it is deﬁned in a vague way. However, to give an algorithm that performssimpliﬁcation, we must have a precise deﬁnition of the term. Is it possibleto give a precise deﬁnition for simpliﬁcation?
10 1. Introduction to Computer Algebra
1.2 Applications of Computer Algebra
The Purpose of Applied Mathematics
In the fascinating book Mathematics Applied to Deterministic Problems in
the Natural Sciences ([63], SIAM, 1988, pages 5-7), Lin and Segel describe
the purpose of applied mathematics in the following way:
The purpose of applied mathematics is to elucidate scientiﬁc
concepts and describe scientiﬁc phenomena through the use of
mathematics, and to stimulate the development of new mathe-matics through such studies.
They discuss three aspects of this process that relate to the solution of
scientiﬁc problems:
(i) theformulation of the scientiﬁc problem in mathematical terms.
(ii) thesolution of the mathematical problems thus created.
(iii) theinterpretation of the solution and its empirical veriﬁcation in
scientiﬁc terms.
In addition, they mention a closely related adjunct of this process:
(iv) the generation of scientiﬁcally relevant new mathematics through cre-
ation, generalization, abstraction, and axiomatic formulation.
In principle, computer algebra can help facilitate steps (i), (ii), and (iv)
of this process. In practice, computer algebra is primarily involved in step
(ii) and to a much lesser degree in steps (i) and (iv).
Examples of Computer Algebra
In the remainder of this section, we give four examples that illustrate theuse of computer algebra software in the problem solving process. All of the
examples are concerned with the solution of equations.
Example 1.1. (Solution of a linear system of equations.) AC A S
is particularly useful for calculations that are lengthy and tedious but
straightforward. The solution of a linear system of equations with symbolic
coeﬃcients provides an example of this situation. The following system of
equations occurs in a problem in statistical mechanics5:
5The author encountered this system of equations while working on a problem in
statistical mechanics in 1982. At that time the solution of the system with pencil and
paper (including checking and re-checking the result) took two days. Unfortunately,the published result still contains a minor coeﬃcient error. See Cohen, Haskins, andMarchand [ 23].
1.2. Applications of Computer Algebra 11
d0+d1+d2+d3+d4=1,
d1+2d2+3d3+4d4=2 ( 1 −m),
3d0−d2+3d4=2γ2,0+γ1,1, (1.2)
φd0+ψd1−ψd3−φd4=m,
2φd0+ψd1+ψd3+2φd4=2γ1,0.
In this system the ﬁve unknown variables are d0,d1,d2,d3,a n dd4.T h e
coeﬃcients of these variables and the right-hand sides of the equations
depend on the six parameters m,φ,ψ,γ 1,0,γ1,1,a n dγ2,0, and the object is
to express the unknowns in terms of these parameters. Whether or not this
is a good problem for a CAS depends on the purpose of the computation. Inthis case a solution is needed to help understand the eﬀect of the various
parameters on the individual unknowns. What is needed is not just a
solution, but one that is compact enough to allow for an easy interpretationof the result.
The symbolic solution of ﬁve linear equations with ﬁve unknowns has
the potential to produce expressions with hundreds of terms. In this case,
however, the coeﬃcients are not completely random but instead contain
a symmetry pattern. Because of this there is reason to believe (but no
guarantee) that the solutions will simplify to expressions of reasonable size.
Figure 1.5shows an interactive dialogue with the Mathematica system
that solves the system of equations. The input statements in Mathematica
are indicated by the label “ In” followed by an integer in brackets and the
symbol “ :=”(In[1]:=, In[2]:= ,e t c . ) .T h es y m b o l s Out[1]=, Out[2]= ,e t c . ,
are labels that represent the output produced by each input line. The other
equal sign in lines In[1]through In[6]is an assignment symbol and the
symbol “ ==” is used for equality in an equation. The command to solve
the system of equations is given in In[6]and the solution to the system
is displayed in the lines following Out[6] . As we suspected, the solution
simpliﬁes to expressions of reasonable size. /square
One application of computer algebra systems is the exact solution of
polynomial equations. For polynomial equations with degree less than orequal to four it is always possible to obtain solutions in terms of expressions
with radicals, although for cubic and quartic equations these solutions are
often quite involved. For polynomials with degree ﬁve or greater, it istheoretically impossible to represent the solutions of all such equations
using expressions with radicals
6, although it is possible to solve some of
these equations.
6This statement follows from Galois theory, the algebraic theory that describes the
nature of solutions to polynomial equations.
12 1. Introduction to Computer Algebra
In[1]: = eq1=d[0]+d[1]+d[2]+d[3]+d[4]= = 1
Out[1]=d[0]+d[1]+d[2]+d[3]+d[4] == 1
In[2]: = eq2=d[1]+2∗d[2]+3∗d[3]+4∗d[4]= = 2∗(1−m)
Out[2]=d[1]+2 d[2]+3 d[3]+4 d[4] == 2(1 −m)
In[3]: = eq3=3∗d[0]−d[2]+3∗d[4]= = 2∗γ[2,0]+γ[1,1]
Out[3]: = 3 d[0]−d[2]+3 d[4] == γ[1,1]+2γ[2,0]
In[4]: = eq4=φ∗d[0]+ϕ∗d[1]−ϕ∗d[3]−φ∗d[4]= = m
Out[4]: =φd[0]+ϕd[1]−ϕd[3]−φd[4] == m
In[5]: = eq5=2∗φ∗d[0]+ϕ∗d[1]+ϕ∗d[3]+2∗φ∗d[4]= = 2∗γ[1,0]
Out[5]: = 2 φd[0]+ϕd[1]+ϕd[3]+2 φd[4] ==2 γ[1,0]
In[6]: = Solve[{eq1,eq2,eq3,eq4,eq5},{d[0],d[1],d[2],d[3],d[4]}]
Out[6]=
d[2]→−1
2(φ−2ϕ)(3ϕ−6γ[1,0]+2φγ[1,1]−ϕγ[1,1]+4φγ[2,0]
−2ϕγ[2,0]),
d[0]→−1
4(φ−2ϕ)(−2m+ϕ+4mϕ−2γ[1,0]+ϕγ[1,1]+2ϕγ[2,0]),
d[1]→−1
2(φ−2ϕ)(2m−φ−2mφ+4γ[1,0]−φγ[1,1]−2φγ[2,0]),
d[3]→−1
2(φ−2ϕ)(−2m−φ+2mφ+4γ[1,0]−φγ[1,1]−2φγ[2,0]),
d[4]→−1
4(φ−2ϕ)(2m+ϕ−4mϕ−2γ[1,0]+ϕγ[1,1]+2ϕγ[2,0])11
Figure 1.5. An interactive dialogue with the Mathematica system that solves a
system of linear equations. (Implementation: Maple(mws),Mathematica (nb),
MuPAD(mnb).)
Example 1.2. (Solution of cubic polynomial equations.) To exam-
ine the possibilities (and limitations) for symbolic solutions of polynomial
equations, consider the cubic equation
x3−2ax+a3=0 ( 1 . 3 )
1.2. Applications of Computer Algebra 13
where the symbol ais a parameter. We examine the nature of the solution
for various values of ausing the Maple system7in Figures 1.6,1.7,a n d1.8.
At the ﬁrst prompt ( >)i nF i g u r e 1.6, the equation is assigned to the vari-
able eq. At the second prompt, the equation is solved for xusing Maple’s
solve c o m m a n da n ds t o r e di nt h ev a r i a b l e general
 solution .T h e i n -
volved solution, which contains three expressions separated by commas, is
expressed in terms of an auxiliary expression for which Maple has chosenthe name %1 and the symbol Iwhich represents√
−1. In ordinary (and
more user friendly) mathematical notation the three solutions are
x=1
6r1/3+4a
r1/3,
−1
12r1/3−2a
r1/3+1/2ı√
3/parenleftbigg1
6r1/3−4a
r1/3/parenrightbigg
,
−1
12r1/3−2a
r1/3−1/2ı√
3/parenleftbigg1
6r1/3−4a
r1/3/parenrightbigg
,
where
r=−108a3+1 2/radicalbig
−96a3+8 1a6,ı =√
−1.
At the next prompt the subscommand8is used to substitute a=1i nt h e
general solution to obtain the solution s1. In this form the expressions are
so involved that it is diﬃcult to tell which roots are real numbers and whichones have an imaginary part. Since a cubic equation with real number
coeﬃcients can have at most two roots with non-zero imaginary parts, at
least one of the roots must be a real number. At the fourth prompt, we
attempt to simplify the solutions with Maple’s radsimp command, which
can simplify some expressions with radicals
9. In this case, unfortunately,
it only transforms the solution to another involved form.
To determine the nature (real or not real) of the roots, at the next
prompt we apply Maple’s evalc command, which expresses the roots in
7For the Maple dialogues in this section, the Output Display is set to the Typeset
Notation option. Other options display output expressions in other forms.
8This input statement has one unfortunate complication. Observe that in the subs
command we have placed the set braces {and}about general
 solution . The reason
for this has to do with the form of the output of Maple’s solve command. For this
equation, general
 solution consists of three expressions separated by commas which is
known as an expression sequence in the Maple language. Unfortunately, an expression
sequence cannot be input for the Maple subs command, and so we have included the two
braces so that the input expression is now a Maple setwhich is a valid input. Observe
that the output s1i sa l s oaM a p l es e t .
9Another possibility is the Maple command radsimp(s1,ratdenom) which is an op-
tional form that rationalizes denominators. This command obtains a slightly diﬀerentform, but not the simpliﬁed form.
14 1. Introduction to Computer Algebra
>e q: =x ∧3-2*a*x+a ∧3=0;
eq:=x3−2ax+a3=0
> general
 solution := solve(eq,x);
general
 solution :=1
6%1(1/3)+4a
%1(1/3),
−1
12%1(1/3)−2a
%1(1/3)+1
2I√
3(1
6%1(1/3)−4a
%1(1/3)),
−1
12%1(1/3)−2a
%1(1/3)−1
2I√
3(1
6%1(1/3)−4a
%1(1/3))
%1 := −108a3+1 2√
−96a3+8 1a6
> s1 := subs(a=1, {general
 solution });
s1: =M
1
6%1 +4
i−108 + 12√
−15J1/3,
−1
12%1−2
i−108 + 12√
−15J1/3+1
2I√
3~
1
6%1−1
i−108 + 12√
−15J1/3^
,
−1
12%1−2
i−108 + 12√
−15J1/3−1
2I√
3~
1
6%1−1
i−108 + 12√
−15J1/3^r
%1 :=i−108 + 12√
−15J1/3
> radsimp(s1);


1
6Q
−108 + 12 I√
15w(2/3)
+2 4
3
−108 + 12 I√
15,1
12−%1(2/3)−24 +I√
3% 1(2/3)−24I√
3
%1,
−1
12%1(2/3)+2 4+I√
3% 1(2/3)−24I√
3
%1,r
%1 := −108 + 12 I√
3√
5
> simplify(evalc(s1))
k
−1
3√
2(√
3 cos(%1) + 3 sin(%1)) ,−1
3√
2(√
3 cos(%1) −3s i n ( % 1 ) ) ,2
3√
2√
3 cos(%1)L
%1 := −1
3arctanW1
9√
3√
5}
+1
3π
Figure 1.6. An interactive dialogue with the Maple system for solving a cubic
equation. (Implementation: Maple(mws),Mathematica (nb),MuPAD(mnb).)
1.2. Applications of Computer Algebra 15
> eq2 := subs(a=1,eq);
eq2:=x3−2x+1=0
> solve(eq2,x);
1,−1
2+1
2√
5,−1
2−1
2√
5
Figure 1.7. Solving a cubic equation with Maple (continued). (Implementation:
Maple(mws),Mathematica (nb),MuPAD(mnb).)
terms of their real and imaginary parts, and then apply the simplify
command, which attempts to simplify the result. Observe that the solutions
are now expressed in terms of the trigonometric functions sin and cos andthe inverse function arctan. Although the solutions are still quite involved,
we see that all three roots are real numbers. We will show below that the
solutions can be transformed to a much simpler form, although this cannotbe done directly with these Maple commands.
Actually, a better approach to ﬁnd the roots when a= 1 is to substitute
this value in Equation ( 1.3), and solve this particular equation rather than
use the general solution. This approach is illustrated in Figure 1.7.A t
the ﬁrst prompt we deﬁne a new equation eq2, and at the second prompt
solve the equation. In this case the roots are much simpler since Maple can
factor the polynomial as x
3−2x+1=(x−1)(x2+x−1) which leads
to simple exact expressions. On the other hand the general equation ( 1.3)
cannot be factored for all values of a, and so the roots in Figure 1.6for
a= 1 are given by much more involved expressions.
This example illustrates an important maxim about computer algebra:
A general approach to a problem should be avoided when a par-
ticular solution will suﬃce.
Although the general solution gives a solution for a= 1, the expres-
sions are unnecessarily involved, and to obtain useful information requires
an involved simpliﬁcation, which cannot be done easily with the Maplesoftware
10.
Let’s consider next the solution of Equation ( 1.3)w h e na=1/2. In
Figure 1.8, at the ﬁrst prompt we deﬁne a new cubic equation eq3, and
10This simpliﬁcation can be done with the Mathematica system using the
FullSimplify command and with the MuPAD system using the radsimp command.
There are, however, other examples that cannot be simpliﬁed by any of the systems.See Footnote 6on page 145for a statement about the theoretical limitations of algorith-
mic simpliﬁcation.
16 1. Introduction to Computer Algebra
> eq3 := subs(a=1/2,eq);
eq3:=x3−x+1
8=0
> s2:=solve(eq3,x);
s2:=1
12%1 +4
(−108 + 12 I√
687)(1/3),
−1
24%1−2
(−108 + 12 I√
687)(1/3)+1
4I√
3(1
6%1−8
(−108 + 12 I√
687)(1/3)),
−1
24%1−2
(−108 + 12 I√
687)(1/3)−1
4I√
3(1
6%1−8
(−108 + 12 I√
687)(1/3))
%1 := ( −108 + 12 I√
687)(1/3)
> s3 := radsimp( {s2});
s3: =M
1
12(−108 + 12 I√
687)(2/3)+4 8
(−108 + 12 I√
687)(1/3),1
24−%1(2/3)−48 +I√
3%1(2/3)−48I√
3
%1(1/3),
−1
24%1(2/3)+4 8+I√
3% 1(2/3)−48I√
3
%1(1/3)r
%1 := −108 + 12 I√
3√
229
> simplify(evalc( {s2}))
k2
3√
3 cos(%1) ,−1
3√
3 cos(%1) −sin(%1),−1
3√
3 cos(%1) + sin(%1)L
%1 := −1
3arctanW1
9√
3√
229}
+1
3π
> evalf(s3)
{.9304029266 −.8624347141 10−10I,−1.057453771+ .4629268900 10−9I,
.1270508443 −.2120100566 10−9I}
Figure 1.8. Solving cubic equations with Maple (continued). (Implementation:
Maple(mws),Mathematica (nb),MuPAD(mnb).)
at the next three prompts solve it and try to simplify the roots. Again
the representations of the roots in s2ands3are quite involved, and it
is diﬃcult to tell whether the roots are real or include imaginary parts.
Again, to determine the nature of the roots, we apply Maple’s evalc and
simplify commands and obtain an involved representation in terms of
1.2. Applications of Computer Algebra 17
the trigonometric functions sin and cos and the inverse function arctan.
Although the solutions are still quite involved, it appears that all three
roots are real numbers.
In this case, nothing can be done to simplify the exact roots. In fact,
even though the three roots are real numbers, we can’t eliminate the symbol
ı=√
−1f r o m s2ors3without introducing the trigonometric functions
as in s4. This situation, which occurs when none of the roots of a cubic
equation is a rational number11, shows that there is a theoretical limitation
to how useful the exact solutions using radicals can be. The exact solutions
can be found, but cannot be simpliﬁed to a more useful form.
Given this situation, at the last prompt, we apply Maple’s evalf
command that evaluates the roots s3to an approximate decimal format.
The small non-zero imaginary parts that appear in the roots are due to
the round-oﬀ error that is inevitable with approximate numerical calcula-
tions. /square
Example 1.3. (Solution of higher degree polynomial equations.)
Although computer algebra systems can solve some higher degree polyno-
mial equations, they cannot solve all such equations, and in cases wheresolutions can be found they are often so involved that they are not useful
in practice (Exercise 2(a)). Nevertheless, computer algebra systems can
obtain useful solutions to some higher degree equations. This is shown in
the ﬁrst two examples in the MuPAD dialogue in Figure 1.9.
At the ﬁrst prompt (the symbol •) we assign a polynomial to the vari-
ableu, and then at the next prompt solve u=0f o rx. In this case MuPAD
obtains the solutions by ﬁrst factoring uin terms of polynomials with in-
teger coeﬃcients as
u=(x−1)(x
2+x+2 )(x2+5x−4),
and then using the quadratic formula for the two quadratic factors.
At the third prompt we assign a sixth degree polynomial to v,a n dt r yt o
factor it at the next prompt. Since MuPAD returns the same polynomial,
it is not possible to factor vin terms of lower degree polynomials that have
integer coeﬃcients. At the next prompt, however, MuPAD obtains the sixroots tov= 0. In this case MuPAD ﬁnds the solutions by ﬁrst recognizing
that the polynomial vcan be written as a composition of polynomials
v=f(g(x)),f(w)=w
3−2,w=g(x)=x2−2x−1.
11See Birkhoﬀ and Mac Lane [ 10], page 450, Theorem 22. An interesting historical
discussion of this problem is given in Nahin [ 74].
18 1. Introduction to Computer Algebra
•u:=x∧5+5∗x∧4−3∗x∧3+3∗x∧2−14∗x+8;
−14·x+3·x2−3·x3+5·x4+x5+8
•solve (u=0,x,MaxDegree =5);
M
1,−√
41
2−5
2,√
41
2−5
2,Q
−ı
2w
·√
7−1
2,Qı
2w
·√
7−1
2r
•v:=x∧6−6∗x∧5+4∗x∧3+9∗x∧4−9∗x∧2−6∗x−3;
−6·x−9·x2+4·x3+9·x4−6·x5+x6−3
•factor (v);
−6·x−9·x2+4·x3+9·x4−6·x5+x6−3
•solve (v=0,x,MaxDegree =6);


6
3√
2+2+1 ,−6
3√
2+2+1 ,−6
−8·3√
2+(−8·ı)·3√
2·√
3+3 2
4+1,
6
−8·3√
2+(−8·ı)·3√
2·√
3+3 2
4+1,−6
−8·3√
2+( 8 ·ı)·3√
2·√
3+3 2
4+1,
6
−8·3√
2+( 8 ·ı)·3√
2·√
3+3 2
4+1


•w:=x∧8−136∗x∧7+6476∗x∧6−141912 ∗x∧5+1513334 ∗x∧4
−7453176 ∗x∧3+13950764 ∗x∧2−5596840 ∗x+46225 ;
−5596840 ·x+ 13950764 ·x2−7453176 ·x3+ 1513334 ·x4−141912 ·x5
+ 6476 ·x6−136·x7+x8+ 46225
•solve (w=0,x,MaxDegree =8);
RootOfi
−5596840 ·X1 + 13950764 ·X12−7453176 ·X13+ 1513334 ·X14
−141912 ·X15+ 6476 ·X16−136·X17+X18+ 46225,X1J
•r:= (sqrt(2)+sqrt(3)+sqrt(5)+sqrt(7))∧2;
Q√
2+√
3+√
5+√
7w2
•expand (subs(w,x=r));
0
Figure 1.9. The solution of high degree polynomial equations using MuPAD.
(Implementation: Maple(mws),Mathematica (nb),MuPAD(mnb).)
In this form the solution to v= 0 is obtained by solving w3−2=0t o
obtain
w=21/3,−21/3
2+21/331/2
2ı,−21/3
2−21/331/2
2ı,
1.2. Applications of Computer Algebra 19
and then solving the three equations
x2−2x−1=21/3,
x2−2x−1= −21/3
2+21/331/2
2ı,
x2−2x−1= −21/3
2−21/331/2
2ı.
For example, by solving the ﬁrst of these equations we obtain the ﬁrst two
roots ofv=0i nF i g u r e 1.9.
Next, we assign an involved eighth degree polynomial to w, and attempt
to solve the equation w= 0. Even though the equation has the eight roots
x=(√
2±√
3±√
5±√
7)2, (1.4)
the MuPAD solve command is unable to ﬁnd them, and returns instead a
curious expression that simply says the solutions are roots of the original
equation. At the next two prompts we assign to the variable rone of the
roots in Equation ( 1.4), and then use the subsand expand commands to
verify that it is a solution to the equation. /square
A Word of Caution
It goes without saying (but let’s say it anyway), that there is more to
mathematical reasoning than the mechanical manipulation of symbols. Itis easy to give examples where a mechanical approach to mathematical
manipulation leads to an incorrect result. This point is illustrated in the
next example.
Example 1.4. Consider the following equation for x:
√
x+7+√
x+2=1, (1.5)
where we assume that the square root symbol represents a non-negative
number and x≥−2 so that the expressions under the radical signs are
non-negative. Suppose that the goal is to ﬁnd all real values of x that
satisfy this equation. First transform the equation to
√
x+7=1 −√
x+2. (1.6)
Squaring both sides of this equation and simplifying gives
−2=√
x+2. (1.7)
20 1. Introduction to Computer Algebra
By squaring both sides of this equation and solving for x,w eo b t a i n
x=2. (1.8)
However, this value is not a root of the original Equation ( 1.5). What is
wrong with our reasoning?
In this case, the problem lies with the interpretation of the square root
symbol. If we insist that the square roots are always non-negative, there
are no real roots. However, if we allow (somewhat arbitrarily) the secondsquare root in Equation ( 1.5) to be negative, the value x=2i sar o o t .
Indeed, the necessity of this assumption appears during the calculation in
Equation ( 1.7).
Let’s see what happens when we try to solve Equation ( 1.5)w i t ha
computer algebra system. Consider the dialogue with the Macysma systemin Figure 1.10. The input statements in Macysma are preceded by the letter
cfollowed by a positive integer ( (c1), (c2) ,e t c . ) . T h es y m b o l s( (d1),
(d2), etc.) are labels that represent the output produced by each input
line. The colon in line (c1)is the assignment symbol in Macysma. At
line(c1), we assign the equation to the variable eq1a n da t (c2)attempt
to solve the equation for x. Observe that Macysma simply returns the
equation in a modiﬁed form indicating that it cannot solve the equation
with its solve command.
We can, however, help Macysma along by directing it to perform ma-
nipulations similar to the ones in Equations ( 1.6) through ( 1.8). At (c3),
(c4),(c5),a n d (c6)we direct the system to put the equation in a form
that can be solved for xat(c7). Again we obtain the extraneous root
x= 2. Of course, at (c8)when we substitute this value into the original
equation, we obtain an inequality since Macysma assumes that all square
roots of positive integers are positive.
This example shows that it is just as important to scrutinize our com-
puter calculations as our pencil and paper calculations. The point is mathe-
matical symbols have meaning, and transformations that are correct in one
context may require subtle assumptions in other contexts that render themmeaningless. In this simple example it is easy to spot the ﬂaw in our rea-
soning. In a more involved example with many steps and involved output
we may not be so lucky. Additional examples of how incorrect conclusions
can follow from deceptive symbol manipulation are given in Exercises 10,
11,12,a n d13. /square
Exploring the Capabilities of a CAS
An important prerequisite for successful use of a CAS is an understanding
of its capabilities and limitations. Since some symbolic operations are
1.2. Applications of Computer Algebra 21
(c1)eq1 : sqrt(x+7)+sqrt(x+2)=1;
(d1)√
x+7+√
x+2=1
(c2)solve(eq1,x);
(d2) [√
x+7=1 −√
x+2]
(c3)eq2 : eq1 - sqrt(x+2);
(d3)√
x+7=1 −√
x+2
(c4)eq3 : expand(eq2 ∧2);
(d4) x+7= −2√
x+2+ x+3
(c5)eq4 : eq3 - x - 3;
(d5) 4=−2√
x+2
(c6)eq5 : eq4 ∧2;
(d6) 16 = 4( x+2)
(c7)solve(eq5,x);
(d7) [x=2 ]
(c8)subst(2,x,eq1);
(d8) 5=1
Figure 1.10. A Macsyma 2.1 dialogue that attempts to solve Equation ( 1.5)b y
mimicking the manipulations in Equations ( 1.6) through ( 1.8).
quite involved, it may not be practical to list in detail all the capabilities
of a particular command. For this reason, it is important to explore the
capabilities of a CAS. Some of the exercises in this section and others
throughout the book are designed with this objective in mind.
22 1. Introduction to Computer Algebra
Exercises
For the exercises in this section, the following operators are useful:
•In Maple, the diff,int,factor,solve,simplify,radsimp,subs,a n d
evalfoperators (Implementation: Maple(mws)).
•In Mathematica, the D, Integrate, Factor, Solve, Reduce, //N,
Simplify, FullSimplify, and ReplaceAll operators (Implementation:
Mathematica (nb)).
•In MuPAD the diff,int,Factor,solve,simplify,radsimp,subs,a n d
floatoperators (Implementation: MuPAD(mnb)).
1. Which of the following expressions can be factored with a CAS? Does the
CAS return the result in the form you expect?
(a)x2−1
4.
(b)x2−a2.
(c)x2−(√
2)2.
(d)x2+1=( x−ı)(x+ı).
(e)xy+1
xy+2=( x+1/y)(y+1/x).
(f) (exp( x))2−1=e xp (2 x)−1. (Notice that these two expressions
are equivalent. Can a CAS factor both forms?)
(g)x2n−1=(xn−1)(xn+1).
(h)xm+n−xn−xm+1 = ( xm−1)(xn−1).
(i)x2+√
3x+√
2x+√
2√
3.
(j)√
3x5−√
6x4+√
2x3−2x2+√
5x−√
10 = ( x−√
2) (√
3x4
+√
2x2+√
5).
(k)x4−10x2+1=( x+√
2+√
3)(x+√
2−√
3)(x−√
2+√
3)(x−√
2−√
3).
2. In this problem we ask youto explore the capability of a CAS to ﬁnd the
exact solutions to equations. Since the solution of equations is an involvedoperation, some computeralgebra systems haveeither more thanone com-
mand for this operation or optional parameters that modify the operation
of the commands. Before attempting this exercise, you should consult thesystem documentation to determine best use the of the commands. In
addition, a CAS may return a solution in a form that includes advanced
functions that you may not be familiar with. Again, consult the systemdocumentation for the deﬁnitions of these functions.
Solve each of the following with a CAS.
(a)x
4−3x3−7x2+2x−1=0f o r x. Are the roots real or do they have
non-zero imaginary parts?
1.2. Applications of Computer Algebra 23
(b)x8−8x7+28x6−56x5+70x4−56x3+28x2−8x−1=0for x.S i n c e
this equation has degree 8, a CAS ﬁnds the solution by using either
polynomial factorization or decomposition to reduce the problem to
the solution of lower degree polynomial equations. Which approachdoes the CAS use in this case? Hint:See Example 1.3.
(c)x−π/2=c o s( x+π)f o rxa real number. (Solution x=π/2.)
(d) sin( x)=1f o r xareal. (Solution x=π/2+2πn , n=0,±1,±2,....)
(e)√
x=1−xforx≥0. By squaring both sides of this equation
we obtain the equivalent equation x2−3x+1=0w hi c hha st w o
positive roots. However, only one of these roots is a root of the
original equation.
(f) 4(x2)2x=8f o r xa real number. By taking logarithms of both sides
of this equation, we obtain the equivalent equation 2 x2+x−3=0.
(g)x2=2xforxa real number. (Solution x=2,4,x≈−.7666.)
(h)ex2−4+x=3f o r xa real number. (Solution x=2 )
(i) i.x2−1
x+1=2 (Solution x=3 ).
ii.x2−1=2( x+1)(Solution x=3,−1).
Noticethat(i)and(ii)arealgebraically equivalentexceptatthepoint
x=−1. (Strictly speaking, (i) is not deﬁned at x=−1.) Does a
CAS distinguish between these two equations?
3. Let ( x,y) be the rectangular coordinates of a point in the plane, and let
(r, θ) be the polar coordinates. Then
r2=x2+y2,tan(θ)=y/x, (1.9)
and
x=rcos(θ),y=rsin(θ). (1.10)
(a) Can a CAS solve ( 1.9)f o rxandy?
(b) Can a CAS solve ( 1.10)f o rrandθ?
4. Use a CAS system to ﬁnd the antiderivative	
1/cos5(x)dx.Verify the
result with a CAS by diﬀerentiation and simpliﬁcation.
5. The following integral is given in an integral table
1
(x+1)√
xdx=−arcsinW1−x
1+x}
,x >0.(1.11)
(a) Evaluate the integral with a CAS. (All seven computer algebra sys-
t e m sd e s c r i b e di nS e c t i o n 1.1return a form diﬀerent from Equation
(1.11).)
(b) Is it possible to use a CAS to show that the antiderivative obtained
in part (a) diﬀers by at most a constant from the one given by the
integral table?
24 1. Introduction to Computer Algebra
6. Consider the six equations with six unknowns {x1,x2,y1,y2,z1,z2}:
a=m1x1+m2x2
m1+m2,
b=m1y1+m2y2
m1+m2,
c=m1z1+m2z2
m1+m2,
rsin(θ)cos(φ)= x1−x2,
rsin(θ)sin(φ)= y1−y2,
rcos(θ)= z1−z2.
Solve these equations with a CAS. Do you expect the solution to simplify
to expressions of reasonable size?
7. Use a CAS to help ﬁnd the exact value of the bounded area between the
curves
u=2x−1
x+2
x2,
v=x+2.
Assume that x>0.
8. (a) Consider the equation x3−a2x2+(a+3)x−a=0 .U s eaC A St o
ﬁndareal valuefor asothattheequation hasoneroot of multiplicity
2 and one of multiplicity 1. Hint:At a root x0of multiplicity 2, both
the polynomial and its derivative evaluate to 0.
(b) Consider the equation x3+ax2+a2x+a3=0 . F o r a=0t h e
equation has the root x= 0 with multiplicity 3. Use a CAS to show
that it is impossible to ﬁnd an aso that the equation has one root of
multiplicity 2 and one of multiplicity 1.
9. Giveageneralformulaforthe nthderivativeoftheproductoftwofunctions
f(x)a n dg(x). A CAS can be useful for this problem. Use a CAS to ﬁnd
thenth derivative of the product f(x)g(x)f o rn=1,2,3,4. Use this
data to ﬁnd a general expression for the pattern youobserve.
10. In each of the following manipulations we ostensibly show that 1 = −1.
What is the fallacy in the reasoning in each case?
(a) 1 =√
1=√
ı4=ı2=−1w h e r e ı=√
−1.
(b) 1 =√
1=
(−1)(−1) =√
−1√
−1=ı2=−1.
11. Inthefollowingmanipulationsweostensiblyshowthateverycomplexnum-
ber is real and positive. Let z=reıθbe a complex number in the polar
representation where r>0. Certainly, if θ=0 ,t h e n z=rwhich is real
and positive. If θ/negationslash=0 ,the nf o r α=eıθ,
α2π/θ=Q
eıθw2π/θ
=e2πı=c o s(2 π)+ısin(2π)=1.
1.2. Applications of Computer Algebra 25
Therefore,
α=Q
α2π/θwθ/(2π)
=1θ/(2π)=1.
Therefore z=rwhich is real and positive. What is wrong with our rea-
soning?
12. Consider the following sequence of steps that ostensibly shows that 2=1.
Let
a=b. (1.12)
Then
a2=ab,
a2−b2=ab−b2,
(a+b)(a−b)= b(a−b),
a+b=b.
SubstitutingEquation ( 1.12) intothis last expression we obtain 2 b=band
so 2 = 1. What is the fallacy in the reasoning?
13. Consider the indeﬁnite integral
dx
xln(x).
To evaluate this integral we use the integration by parts formula	
ud v=
uv−	
vd uwithu=1/ln(x)a n ddv=dx/xand obtain
dx
xln(x)=1+dx
xln(x).
Subtracting the integral from both side of this equation we obtain 0 = 1.
What is wrong with our reasoning?
14. Consider the system equations
(x2+y2+x)2=9 ( x2+y2), (1.13)
x2+y2=1. (1.14)
(a) Solve this system of equations for xandywith a CAS.
(b) Let’strytosolvethissystemofequationsusingsymbolmanipulation.
Substituting Equation ( 1.14)i n(1.13)w eh a v e( x+1 )2=9a n d
sox=2,−4. Substituting x=2i n(1.13)w eo b t a i na f t e rs o m e
manipulation y2(y2+3)=0 which has the real root y= 0. However,
x=2,y= 0isnotobtainedbyaCASasasolutionofEquation( 1.14).
What is the fallacy in our reasoning?
26 1. Introduction to Computer Algebra
Further Reading
1.1Computer Algebra and Computer Algebra Systems. Kline [54]g i v e s
an interesting discussion of the use of mathematics to discover new knowledge
about the physical world.
Additional information on computer algebra can be found in Akritas [ 2],
Buchberger et al. [ 17], Davenport, Siret, and Tournier [ 29], Geddes, Czapor, and
Labahn [39], Lipson [ 64], Mignotte [ 66], Mignotte and S ¸tef˘anescu[67], Mishra
[68], von zur Gathen and Gerhard [ 96], Wester [ 100], Winkler [ 101], Yap [105],
and Zippel [ 108]. Two older (butinteresting) discussions of computeralgebra are
found in Pavelle, Rothstein, and Fitch [ 77] and Yun and Stoutemyer [ 107].
Simon ([90]and[89]) and Wester [ 100] (Chapter3) give acomparison of com-
mercialcomputeralgebrasoftware. Comparisonsofcomputeralgebrasystemsare
also found at
http://math.unm.edu/~wester/cas_review.html .
Information about computer algebra and computer algebra systems can be
found at the following Internet sites.
•SymbolicNet:
http://www.SymbolicNet.org .
•Computer Algebra Information Network (CAIN):
http://www.riaca.win.tue.nl/CAN/ .
•COMPUTER ALGEBRA, Algorithms, Systems and Applications:
http://www-troja.fjfi.cvut.cz/~liska/ca/ .
•sci.math.symbolic discussion site:
http://mathforum.org/discussions/about/sci.math.symbolic.html
The Association for Computing Machinery (ACM) has a Special Interest
GrouponSymbolicandAlgebraicManipulation(SIGSAM) .This grouppublishes
a quarterly journal the SIGSAMBulletin which provides a forum for exchanging
ideas about computer algebra. In addition, SIGSAM sponsors an annual con-
ference, the International Symposium on Symbolic and Algebraic Computation
(ISSAC). Information about SIGSAM can be found at the Internet site
http://www.acm.org/sigsam .
The main research journal in computer algebra is the Journal of Symbolic
Computation published by Academic Press. Information about this journal can
be found at
http://www.academicpress.com/jsc .
1.2. Applications of Computer Algebra 27
Computers have also been used to prove theorems. See Chou [ 20] for an
introduction to computer theorem proving in Euclidean geometry.
Computers have even been used to generate mathematical conjectures or
statementswhich haveahigh probability ofbeingtrue. SeeCipra[ 21]for details.
Therehasalsobeensomeworktouseartiﬁcialintelligencesymbolicprograms
to help interpret the results of numerical computer experiments and even to
suggest which experiments should be done. See Kowalik [ 58] for the details.
See Kajler [ 51] for a discussion of research issues in human-computer inter-
action in symbolic computation.
1.2Applications ofComputer Algebra. The article by Nowlan [ 76]h a sa
discussion of the consequences a purely mechanical approach to mathematics.
Stoutemyer [ 94], which describes some problems that arise with CAS software,
should be required reading for any user of this software.
Bernardin (see [ 7]o r[8]) compares the capability to solve equations for six
computer algebra systems. Some of the equations in Exercise 2on page22are
from these references.
Exercise11on page24is fromThe College Mathematics Journal , Vol. 27,
No. 4, Sept. 1996, p. 283. This journal occasionally has examples of faultysymbolic manipulation in its section Fallacies,Flaws, andFlimﬂam. See
http://www.maa.org/pubs/cmj.html .

2
Elementary Concepts of
Computer Algebra
In this chapter we introduce a language that is used throughout the book
to describe the concepts, examples, and algorithms of computer algebra.The language is called mathematical pseudo-language or simply MPL. In
Sections 2.1and2.2we describe the form of an MPL mathematical ex-
pression and discuss what happens to an expression during the evaluation
process. In Section 2.3we consider elementary MPL programs and give
a case study that illustrates the concept. Finally, in Section 2.4we de-
scribe MPL lists and sets, which are two ways to represent collections of
mathematical expressions.
2.1 Mathematical Pseudo-language (MPL)
Mathematical pseudo-language (MPL) is a symbolic language that is used
in this book to describe the concepts, examples, and algorithms of com-
puter algebra. The term pseudo-language is used to emphasize that MPL
is not a real CAS language that has been implemented on a computer.
Although MPL is similar in spirit to real computer algebra languages, it
is less formal and utilizes both mathematical symbolism and ordinary En-glish when appropriate. The reader should have little diﬃculty following
discussions in MPL.
The reader may wonder, why introduce another algorithmic language?
Why not use the programming language associated with a particular CAS?
29
30 2. Elementary Concepts of Computer Algebra
One reason has to do with the current state of language and system de-
velopment in the computer algebra ﬁeld. There is now a proliferation of
computer algebra systems, and, undoubtedly, there will be new ones in
the future. Each system has its strong points and limitations, and its ownfollowing among members of the technical community. The systems are
distinguished from each other by the nature of the mathematical knowl-
edge encoded in the system and the language facilities that are availableto access and extend this knowledge. However, at the basic level, there are
more similarities than diﬀerences, and the organization of mathematical
concepts and language structures do not diﬀer signiﬁcantly from system to
system. By using a generic pseudo-language we are able to emphasize the
concepts and algorithms of symbolic computation without being conﬁnedby the details, quirks, and limitations of a particular language.
Perhaps the most important role for MPL is that it provides a way to
evaluate and compare computer algebra systems and languages. In fact,
a useful approach to this chapter is to read it with one or more computeralgebra systems at your side and, as MPL concepts and operations are
described, implement them in real software. Although you will ﬁnd that
MPL’s style is similar to real software, you will also ﬁnd diﬀerences be-tween it and real languages, and especially subtle diﬀerences between the
languages themselves.
Mathematical Expressions in MPL
To use a computer algebra system eﬀectively, it is important to have a
clear understanding of both the structure and meaning of mathematicalexpressions. Since there is much to say about this subject, mathematical
expressions will occupy much of our attention in this chapter and Chapter
3. In Chapter 4we introduce other elements of the MPL language.
Let’s begin by looking at the various forms an MPL expression can have.
Roughly speaking, MPL expressions are similar to those found in ordinary
mathematical symbolism with some allowance made to accommodate the
need for more precision in a computational environment. MPL expressions
are constructed using the following symbols and operators:
Integers and fractions. Software that performs the exact manipula-
tion of mathematical expressions must have the capability to perform exactarithmetic. Real ﬂoating point arithmetic, which is used by conventional
programming languages for purely numerical work, involves round-oﬀ er-
ror and is not appropriate for most computer algebra computation. Indeed,
even the small numerical errors that are inevitable with ﬂoating point arith-
metic can alter the mathematical properties of an expression. To illustrate
2.1. Mathematical Pseudo-language (MPL) 31
this point, consider the following two expressions which are identical except
for a small change in one coeﬃcient:
f=x2−1
x−1,g=x2−.99
x−1.
Although the numerical values of fandgare nearly the same for most
values ofx, the mathematical properties of the two expressions are diﬀerent.
First of all, fsimpliﬁes to the polynomial x+1w h e n x/negationslash= 1 while gdoes
not. Consequently, their antiderivatives diﬀer by a logarithmic term:
/integraldisplay
fd x =x2/2+x+C, x /negationslash=1,
/integraldisplay
gd x =x2/2+x+.01ln(x−1) +C, x /negationslash=1.
Furthermore, the graph of ghas an asymptote at x= 1, while fis simply
undeﬁned at x=1 .
To avoid these discrepancies, MPL utilizes exact arbitrary precision ra-
tional number arithmetic for most numerical computations rather than ap-
proximate ﬂoating point arithmetic. The term arbitrary precision means
an integer or fraction can have an arbitrary number of digits. Examplesinclude
2/3,−1/4,123456789 /987654321 ,2432902008176640000 .
Arithmetic calculations are performed using the ordinary rules for rational
number arithmetic.
All computer algebra systems utilize this type of arithmetic, however,
because a computer is a ﬁnite machine, there is a maximum number of
digits permitted in a number. This bound is usually quite large and rarely
a limitation in applications.
Realnumbers. In MPL, a real number is one that has a ﬁnite number
of digits, includes a decimal point, and may include an optional power of
10. Examples include
467.22,.33333333,6.02·10
23. (2.1)
Real number arithmetic is similar to real ﬂoating point arithmetic in a
conventional programming language. Since this mode of computation may
involve round-oﬀ error, it is, in general, inexact. Most computer algebra
systems support real numbers, and some systems allow for choice of nu-
merical precision.
32 2. Elementary Concepts of Computer Algebra
The deﬁnition of an MPL real number should not be confused with the
mathematical concept of a real number. Since all MPL real numbers have
a ﬁnite number of digits, they are really rational numbers in the mathe-
matical sense. In mathematics, a real number that is not rational is calledanirrational number . For example,√
2,π,a n deare irrational numbers,
and it is hard to imagine doing symbolic computation without them. Since
irrational numbers require an inﬁnite decimal representation which is notpossible in a computational setting, they are represented instead using re-
served symbols ( e,π), algebraic expressions (2 ∧(1/2)), or function forms
(ln(2)), all of which are described below.
Identiﬁers .InM P L ,a n identiﬁer is a string of characters constructed
with English letters, Greek letters, the digits 0 ,1,...,9, and the underscore
symbol “
”. An identiﬁer begins with an English or Greek letter. The
following are examples of MPL identiﬁers:
x, y1, α, general
 solution, ∆x.
Identiﬁers are used in MPL as programming variables that represent the re-
sult of a computation, as function, operator, or procedure names, as mathe-
matical symbols that represent indeterminates (or variables) in a mathemat-
ical expression, and as reserved symbols. All computer algebra languages
use identiﬁers in this way although the characters allowed in an identiﬁername vary from system to system.
Algebraic operators and parentheses . The algebraic operators in
MPL are listed in Figure 2.1. Parentheses are used as they are in math-
ematics to alter the structure of an expression. Examples of expressionsthat include the operators, numbers, and identiﬁers described so far are
(n−m)!,x∧2−5∗x+6,((x+∆x)∧2−x∧2)/∆x.
Mathematical Operation
 MPL Operator
addition, subtraction
 +,−
multiplication, division
 ∗,/
power
 ∧
factorial
 !
Figure 2.1. Algebraic operators in MPL.
Reservedsymbols. Areserved symbol is an identiﬁer or other mathe-
matical symbol that has mathematical meaning. In MPL, the reserved sym-
bols include π,e,ı(for√
−1),∞, and the logical constants trueandfalse.
2.1. Mathematical Pseudo-language (MPL) 33
MPL
 Maple
 Mathematica
 MuPAD
π
 Pi
 Pi
 PI
e
 exp(1)
 E
 E
ı
 I
 I
 I
∞
 infinity
 Infinity
 infinity
true
 true
 True
 TRUE
false
 false
 False
 FALSE
Figure 2.2. MPL reserved symbols in Maple, Mathematica, and MuPAD.
A few more reserved symbols are introduced in later sections. The corre-
sponding reserved symbols in three computer algebra systems are given in
Figure 2.2.
In a CAS, reserved symbols acquire mathematical meaning through the
actions of the transformation rules encoded in the system. For example,most computer algebra systems recognize the simpliﬁcations
sin(π/2)→1, (2.2)
arctan(1) →π/4, (2.3)
ln(e∧2)→2, (2.4)
ı∧2→− 1,
e∧(−ı∗π)→− 1
as either part of the evaluation process or the output of a simpliﬁcation
operator. (Implementation: Maple (mws), Mathematica (nb),MuPAD
(mnb).)
Function forms. In MPL, function forms are used for mathemat-
ical functions (sin( x), exp(x), arctan( x), etc.), mathematical operators
(Expand (u),Factor (u),Integral (u,x),etc.), and undeﬁned functions ( f(x),
g(x,y), etc.).
In a CAS, mathematical functions acquire meaning through the ac-
tions of transformation rules encoded in the system. For example, most
computer algebra systems obtain function transformations similar to thesimpliﬁcations ( 2.2), (2.3), and ( 2.4)a b o v e .
Function forms that manipulate and analyze mathematical expressions
are called mathematical operators . Although computer algebra systems
contain hundreds of mathematical operators, we use only a small number
of them in this book. Figure 2.3gives some of the MPL operators used in
the examples, algorithms, and exercises in this chapter, and Figure 2.4
34 2. Elementary Concepts of Computer Algebra
Mathematical
 MPL
 Example
Operation
 Operator
Absolute value, |u|
Absolute
 value (u)
Absolute
 value (−2)→2
Evaluate rational
 Decimal (u)
 Decimal (1/4)→.25
numbers, arithmetic
 Decimal (x+1/4)→x+.25
operations, and
 Decimal (sin(2) + 1 /2)→1.409297
numerical functions
in an expression u
to a real value
Substitution
 Substitute (u,t=r)
Substitute (2∗x+1,x=b+1 )
inuof each
 →2(b+1 )+1
occurrence of t
byr
ith operand in
 Operand (u,i)
 Operand (a+b+c,2)→b
an expression u
 Operand ({a,b,c},3)→c
Operand (a=b,2)→b
Degree in x
 Degree (u,x)
Degree (x∧2+5 ∗x+7,x)
of a polynomial
 →2
expression u
Coeﬃcient of
 Coeﬃcient (u,x,j )
Coeﬃcient (x∧2+5 ∗x+7,x , 1)
xjin a
 →5
polynomial
expression u
Algebraic
 Algebraic
 expand (u)
Algebraic
 expand (
expansion
 (x+2 )∗(x+3 ) )
→x2+5∗x+6
Polynomial
 Factor (u)
 Factor (x∧2+5 ∗x+6 )
factorization
 →(x+2 )(x+3 )
Solution of
 Solve (u,x)
 Solve (a∗x=b,x)
an equation
 →x=b/a
uforx
or a set of
 Solve ({u1,...,u n},
Solve (
equations
 {x1,...,x n})
{2∗x+4∗y=3,3∗x−y=7},
for a set of
 {x,y})
variables
 →{x=3 1/14,y=−5/14}
lim
x→au
 Limit (u,x,a )
Limit (1/x,x, ∞)→0
du
dx
Derivative (u,x)
Derivative (sin(x),x)→cos(x)
	ud x
 Integral (u,x)
Integral (cos(x),x)→sin(x)
Solution of
 Solve
ode(u,x,y )
Solve
ode(
a diﬀerential
 Derivative (y(x),x)=y(x),x,y)
equation u
 →C∗exp(x)
fory(x)
Figure 2.3. Some mathematical operators in MPL. In column 3, the expression
to the right of the evaluation symbol →is the result obtained by evaluating the
operator. The corresponding operators in three computer algebra systems are
giving in Figure 2.4.
2.1. Mathematical Pseudo-language (MPL) 35
MPL
 Maple
 Mathematica
 MuPAD
Absolute
 value (u)
 abs(u)
 Abs[u]
 abs(u)
Decimal (u)
 evalf(u)
 u//N
 float(u)
Substitute (u,t=r)
 subs(t=r,u)
 ReplaceAll[u,t->r]
 subs(u,t=r)
Operand (u,i)
 op(i,u)
 Part[u,i]
 op(u,i)
Degree (u,x)
 degree(u,x)
 Exponent[u,x]
 degree(u,x)
Coeﬃcient (u,x,j )
 coeff(u,x,j)
 Coefficient[u,x,j]
 coeff(u,x,j)
Algebraic
 expand (u)
 expand(u)
 Expand[u]
 expand(u)
Factor (u)
 factor(u)
 Factor[u]
 expr(factor(u))
Solve (u,x)
 solve(u,x)
 Solve[u,x]
 solve(u,x)
Limit (u,x,a )
 limit(u,x=a)
 Limit[u,x->a]
 limit(u,x,a)
Derivative (u,x)
 diff(u,x)
 D[u,x]
 diff(u,x)
Integral (u,x)
 int(u,x)
 Integrate[u,x]
 int(u,x)
Solve
ode(u,x,y )
dsolve(u,y(x))
 DSolve[u,y[x],x]
 solve(ode(u,y(x)))
Figure 2.4. Theoperators in theMaple, MuPAD,andMathematica systemsthat
correspond most closely to the MPL operators in Figure 2.3. (Implementation:
Maple(mws),Mathematica (nb),MuPAD(mnb).)
gives the operators in the Maple, Mathematica, and MuPAD systems that
correspond most closely to these operators.
Another important function form is the undeﬁned function which is an
expression in function notation (e.g., f(x),g(x,y),h(n+ 1)), where the
function is undeﬁned. In a computational setting this means there are no
transformation rules or other properties associated with the function be-
yond the implied dependence of the function name on the expressions in
parentheses. In ordinary mathematical notation, dependency relationshipsof this sort are usually understood from context. In the computational set-
ting, however, more precision is required, and undeﬁned functions provide
one way to represent this dependency.
One use of undeﬁned functions is in expressions that involve arbitrary
or unknown functions. For example, in the diﬀerentiation
Derivative (f(x)∗g(x),x)→df(x)
dxg(x)+f(x)dg(x)
dx,
MPL’s Derivative operator uses the dependency information to obtain a
general form of the product rule. Without this information, the Derivative
operator assumes that fandgdo not depend on x,a n ds o Derivative (f∗
g,x) evaluates to 0.
All computer algebra systems use function forms in the three ways
described above. In Figure 2.5, we give a Mathematica dialogue which
obtains the solution of the diﬀerential equation
dy
dx+y=x+e x p ( −2x) (2.5)
36 2. Elementary Concepts of Computer Algebra
In[1]: = u=D[y[x],x]+y[x]= = x+Exp[−2∗x]
Out[1] = y[x] + y/prime[x] == e−2x+x
In[2]: = DSolve [u,y[x],x]
Out[2]={{y[x]→e−x(−e−x+ex(−1+x ) )+e−xC[1]}}
Figure 2.5. A Mathematica dialogue which obtains the solution of a diﬀerential
equation. The Mathematica language uses the brackets [ and ] to representfunction forms. (Implementation: Maple(mws),Mathematica (nb),MuPAD
(mnb).)
which illustrates this point. At the ﬁrst prompt In[1], we enter the diﬀer-
ential equation using the function notation y[x]to represent the depen-
dency ofyonx,a n da t Out[1] , the system returns an expression where the
derivative is represented in symbolic form as y/prime[x]. At In[2],w ee n t e rt h e
command to solve the diﬀerential equation and obtain the general solution
inOut[2] . Observe that Mathematica represents the arbitrary constant in
the solution by C[1].
Relational operators and expressions. In MPL, a relational ex-
pression is one that expresses a relationship between two expressions using
one of the relational operators
=,/negationslash=,< , ≤,> , ≥.
Examples include x∧2+2 ∗x−1=0 ,i<n,a n d∆p∗∆x≥h.
Logical operators and expressions. An MPL logical expression is
one constructed using logical constants ( trueandfalse), relational expres-
sions, and identiﬁers combined together with one or more of the logical
operatorsand,or,a n dnot. As with algebraic expressions, parentheses
are used to alter the structure of an expression. Examples include
(trueandfalse )ortrue,not(pandq),0≤xandx≤1.
All computer algebra languages provide relational and logical expressions
(see Figure 2.6) although their roles in the languages vary from system to
system1
1We return to this point in Section 3.2(see pages 97-99).
2.1. Mathematical Pseudo-language (MPL) 37
MPL
Maple
Mathematica
 MuPAD
true
 true
 True
 TRUE
false
 false
 False
 FALSE
=
 =
 ==or===
 =
/negationslash=
 <>
 !=or=!=
 <>
<
 <
 <
 <
≤
 <=
 <=
 <=
>
 >
 >
 >
≥
 >=
 >=
 >=
and
 and
 &&
 and
or
 or
 ||
 or
not
 not
 !
 not
Figure 2.6. Relational operators, logical constants, and logical operators in
Maple, Mathematica, and MuPAD.
Sets and lists. InM P L ,b o t hs e t sa n dl i s t sa r eu s e dt or e p r e s e n t
collections of mathematical expressions. A set is expressed using the braces{and}and a list using the brackets [ and ]. Examples include
{2∗x+4∗y=3,3∗x−y=7},[1,x ,x ∧2,x∧3].
In MPL, a set or a list is considered a mathematical expression rather than
a data structure that contains mathematical expressions
2.In f a c t , a s e t
or a list can be a sub-expression of another mathematical expression. For
example, the expression
Solve({2∗x+4∗y=3,3∗x−y=7},{x,y})
which contains sets, is used to obtain the solution of a system of linear equa-
tions. Although both sets and lists are used for collections of expressions,they have diﬀerent mathematical properties and are used in diﬀerent ways
in our examples and algorithms. In Section 2.4, we discuss these diﬀerences
and describe the operations that are appropriate for each of them.
Most computer algebra languages provide lists and sets.
MPLmathematical expressions . An MPL mathematical expres-
sion is any valid mathematical expression that is formed using integers,
fractions, real numbers, identiﬁers, reserved symbols, function forms, sets,lists, and the algebraic, relational and logical operators described above.
(A few additional operators are introduced in later sections.) For our pur-
poses, any expression with appropriate operands for each operator and
2A data structure is a programming language structure that is used to organize data.
An array is an example of a data structure.
38 2. Elementary Concepts of Computer Algebra
balanced parentheses is valid. For example, {a,b,c}∗yis not valid because
the ﬁrst operand of ∗is not appropriate. The expression ( a+b)∗c)i sn o t
valid because there is a dangling right parenthesis.
Although this description of mathematical expressions is suﬃcient for
our purposes, a theoretician would rightfully complain that we haven’t
given a deﬁnition at all since the word validis not precisely deﬁned. A
more formal deﬁnition would include a set of syntax orgrammar rules that
deﬁne when a sequence of symbols is a valid expression in our language.The syntax rules would tell us, for example, that the expression m∗x+b
is a valid expression, while ( a+b)∗c)i sn o t .
The syntax rules for expressions are quite involved, even for expressions
as simple as those considered here. A precise listing of the rules is essential
for the designer of a computer algebra system, who must determine which
expressions are valid statements in a language. The syntax rules are en-
coded in a program called a parser that determines if an input expression is
a valid expression in the language, determines its structure, and translates
it into an internal form that is used by the CAS to manipulate and analyze
the expression. The structure of an expression involves the relationships
between the operators and operands that make up the expression. For ex-
ample, the expression m∗x+bhas the structure of a sum with operands
m∗xandbrather than a product with operands mandx+b.
Although syntax rules and parsing algorithms are important topics for
system design, they are not essential to the understanding of computer
algebra and are not addressed in this book. On the other hand, since
an understanding of expression structure is essential for computer algebraprogramming, we examine this topic in detail in Chapter 3.
Variable Initialization and Assignment
In MPL (as in a CAS), all variables are initially undeﬁned symbols. This
assumption allows a variable to fulﬁll its traditional role as an indetermi-
nate symbol in a mathematical expression.
A variable that is used in the programming sense to represent the result
of a computation is given a value with an assignment statement. In MPL,
the assignment operator is a colon followed by an equal sign (:=), and anassignment statement has the form:
variable := mathematical expression.
An assignment statement causes two actions to occur. First, the expression
to the right of the assignment symbol is evaluated giving a new expression.
2.1. Mathematical Pseudo-language (MPL) 39
Next, this new expression is assigned to the variable to the left of the
assignment symbol. For example in
y:=Factor (x∧2+5 ∗x+6 )
the right side evaluates to ( x+2)∗(x+3), which is assigned to the variable
y. In future manipulations, this expression is the value of y.
All computer algebra languages provide assignment statements that
operate in this way3.
Role of Mathematical Expressions in MPL
One aspect of computer algebra programming that distinguishes it fromconventional programming is the role of mathematical expressions. In
MPL, mathematical expressions have two (somewhat overlapping) roles
as either program statements that represent a computational step in a pro-
gram or as data objects that are processed by program statements. For
example, suppose xis an unassigned variable and consider the statement
f:=x∧2+5 ∗x+6. (2.6)
In this statement the polynomial expression which is assigned to fis a data
object that can be manipulated or analyzed by other program statements.
On the other hand, in
g:=Substitute (Derivative (f,x),x=c)∗(x−c)
+Substitute (f,x=c), (2.7)
the expression to the right of the assignment operator is a program state-
ment that obtains the formula for the tangent line to fatx=c, and assigns
the result to the variable g. For example, if cis assigned the expression
1/2a n dfis given by the statement ( 2.6), thengis assigned the new data
object, the expression 6 ∗(x−1/2) + 35/4.
Although this description of the role of expressions is useful for empha-
sizing their dual nature, the distinction should not be taken too literally.Indeed, the role of an expression can depend on other actions that have oc-
curred in a computation. For example, in Statement ( 2.6), the polynomial
is a data object as long as xhas not been assigned. On the other hand,
ifxhas been assigned the integer 3, the polynomial in Statement ( 2.6)
can be viewed as a program statement which upon evaluation obtains the
expression 30 which is then assigned to f.
3In Maple and MuPAD, the assignment symbol is the colon followed by the equal
sign ( :=); in Mathematica, the assignment symbol is the equal sign ( =).
40 2. Elementary Concepts of Computer Algebra
<1>Algebraic
expand((x+2)2∗(x+3));
→ x3+7x2+16x+12
<2>Factor(2∗x3+7∗x2∗y+4∗x2+14∗x∗y+18∗x+63∗y);
→(x2+2x+9)(2 x+7y)
<3>Integral(x∗sin(x),x);
→sin(x)−xcos(x)
Figure 2.7. An MPL dialogue. (Implementation: Maple(mws),Mathematica
(nb),MuPAD(mnb).)
Most computer algebra languages employ expressions as both program
statements and data objects, although a language may restrict the use of
some expression types to certain contexts4.
MPL Dialogues
An MPL dialogue which mimics the interactive dialogues found in real
computer algebra systems is given in Figure 2.7. In this simulation, the
prompt is represented by a positive integer surrounded by the symbols <
and>and the mathematical expression following each prompt represents
an input to our imaginary system. Following the practice in some computer
algebra systems, each input statement is terminated by a semicolon5.T h e
arrow “ →” to the left of the centered expressions means “evaluates to” and
indicates the result of evaluating the preceding input expression.
MPL Notation versus Ordinary Mathematical Notation
The notation for MPL expressions closely resembles the notation used forinput expressions in most computer algebra systems. However, as withmost programming notations, it is notoriously unreadable for large ex-
pressions. On the other hand, ordinary mathematical notation, which is
4The Maple, Mathematica and MuPAD systems allow all the expressions described
here both as program statements and data objects. On the other hand, the Macsyma
system does not permit some logical expressions as data objects. For example, thelogical expression p and q ,w i t h pand qundeﬁned symbols, cannot be entered in the
interactive mode in that system.
5The Mathematica system does not require a termination symbol at the end of an
expression. Most systems allow a choice of terminating symbol to provide an option todisplay or not display a result.
2.1. Mathematical Pseudo-language (MPL) 41
far more understandable, lacks the precision of MPL notation and is un-
suitable in some computational contexts. Since there is clearly a place for
both notations, we adopt the following strategy for using and intermingling
the two:
•We usually use MPL notation for input to MPL dialogues and for
statements, procedures, and examples that involve manipulations ina computational context. However, in some of these situations, MPL
notation is unwieldy and for clarity we resort to ordinary mathemati-
cal notation. For example, in the MPL dialogue in Figure 2.7,w eu s e
raised exponents for powers in the inputs <2>and<3>instead of
using the ∧operator.
•We usually use ordinary mathematical notation in theorems, exam-
ples, and discussions that are not in a computational context. In
addition, since most computer algebra systems display output in aform similar to ordinary mathematical notation, we use this form for
output in MPL dialogues as well (see Figure 2.7). There are, however,
some instances where the conciseness of MPL notation invites its use
in purely mathematical contexts.
We assume the reader can readily translate between the two notations.
Translating Mathematical Discourse into MPL
We conclude this section with an example that shows how a sequence of
operations in ordinary mathematical discourse is translated into a sequence
of statements in MPL.
Example 2.1. Consider the following equation which deﬁnes yimplicitly as
a function of x:
exp(x)+y4=4x2+y. (2.8)
Let’s consider the manipulations that are used to compute implicitly the
derivatives
dy
dxandd2y
dx2.
First, diﬀerentiating both sides of Equation ( 2.8) with respect to x,w eh a v e
exp(x)+4y3dy
dx=8x+dy
dx. (2.9)
Solving fordy
dx,w eo b t a i n
dy
dx=−exp(x)+8x
4y3−1. (2.10)
42 2. Elementary Concepts of Computer Algebra
To obtain the second derivative, we diﬀerentiate this expression
d2y
dx2=−exp(x)+8
4y3−1−12(−exp(x)+8x)y2dy
dx
(4y3−1)2, (2.11)
and then substitute the right side of Equation ( 2.10)f o rdy
dxto obtain
d2y
dx2=−exp(x)+8
4y3−1−12(−exp(x)+8x)2y2
(4y3−1)3. (2.12)
Let’s consider now the MPL operations that produce the manipulations
in Equations ( 2.8) through ( 2.12). Three operations are required: diﬀer-
entiations in ( 2.9)a n d( 2.11), a solution of a linear equation in ( 2.9), and
a substitution in ( 2.12). These manipulations are readily translated into
a sequence of statements in MPL (see Figure 2.8). We begin at <1>by
assigning Equation ( 2.8)t ou, where an undeﬁned function y(x)i su s e d
to represent the dependence of yonx. At statement <2>,w eu s et h e
Derivative operator to diﬀerentiate both sides of uand assign this result
<1>u:= exp( x)+y(x)4=4x2+y(x);
→exp(x)+y(x)4=4x2+y(x)
<2>v:=Derivative (u, x);
→exp(x)+4y(x)3dy(x)
dx=8x+dy(x)
dx
<3>First
derivative :=Solve(v,Derivative (y(x),x));
→dy(x)
dx=−exp(x)+8x
4y(x)3−1
<4>w:=Derivative (First
derivative ,x);
→d2y(x)
dx2=−exp(x)+8
4y(x)3−1−12(−exp(x)+8x)y(x)2dy(x)
dx
(4y(x)3−1)2
<5>Second
 derivative :=Substitute (w,First
derivative );
→d2y(x)
dx2=−exp(x)+8
4y(x)3−1−12(−exp(x)+8x)2y(x)2
(4y(x)3−1)3
Figure 2.8. The MPL manipulations that correspond to Equations ( 2.8) through
(2.12).
2.1. Mathematical Pseudo-language (MPL) 43
tov.A t<3>,w eu s et h e Solveoperator to solve the equation vfor the
expression
dy(x)
dx
and assign this result to First
 derivative . To obtain the second derivative,
at<4>we apply the Derivative operator to both sides of First
 derivative
and assign this result to w. Finally, at <5>we use the Substitute operator
to apply the substitution deﬁned by First
 derivative towand assign this
result to Second
 derivative . /square
Interactive Dialogues with Real Computer Algebra Systems
MPL provides a way to express a sequence of symbolic calculations in a
form that resembles the statements and operations in a real CAS. Although
the MPL dialogues indicate in a general way the sequence of manipulations
needed for a calculation, we caution the reader not to take the input state-
ments and outputs in the dialogues too literally. The actual implementation
of a dialogue in a real CAS language will vary from system to system.
To illustrate this point, we implement the MPL dialogue in Figure 2.8
in the Maple, Mathematica, MuPAD languages (see Figures 2.9,2.10,a n d
2.11). These dialogues use each system’s versions of MPL’s Derivative ,
Solve,a n d Substitute operators along with each system’s version of MPL’s
selection operator Operand (u,i) which returns the ith operand of the ex-
pressionu. For example, this operator obtains
Operand (a+b+c,2)→b,
Operand ({a,b,c},3)→c,
Operand (a=b,2)→b.
Although this operator was not needed in the MPL dialogue, it is re-
quired to handle the various forms of the input and output of the Solve
andSubstitute operators in a real CAS.
Maple
The Maple implementation of Figure 2.8is given in Figure 2.9.T h es t a t e -
ments at the ﬁrst two prompts are similar to those in the MPL dialogue,
although Maple displays the results as assignments and displays the deriva-
tive with partial derivative notation. At the third prompt, Maple solves
44 2. Elementary Concepts of Computer Algebra
> u := exp(x)+y(x)^4=4*x^2+y(x);
u:=ex+y (x)4=4x2+y (x)
> v := diff(u,x);
v:=ex+4y (x)3W∂
∂xy(x)}
=8x+W∂
∂xy(x)}
> d := solve(v,diff(y(x),x));
d:=−ex+8x
4y (x)3−1
> First_derivative := diff(y(x),x) = d;
First
derivative :=∂
∂xy(x)=−ex+8x
4y(x)3−1
> w := diff(First_derivative,x);
w:=∂2
∂x2y(x)=−ex+8
4y (x)3−1−12 (−ex+8x)y (x)2(∂
∂xy(x))
(4 y(x)3−1)2
> subs(First_derivative,w);
∂
∂x−ex+8x
4y (x)3−1=−ex+8
4y (x)3−1−12 (−ex+8x)2y(x)2
(4 y(x)3−1)3
> Second_derivative := diff(y(x),x,x) = subs(First_derivative,op(2,w));
Second
 derivative :=∂2
∂x2y(x)=−ex+8
4y (x)3−1−12 (−ex+8x)2y(x)2
(4 y(x)3−1)3
Figure 2.9. A Maple implementation of the MPL dialogue in Figure 2.8.( I m p l e -
mentation: Maple(mws).)
the equation vfordiff(y(x),x) , where the solution is returned as an
expression
−ex+8x
4y(x)3−1, (2.13)
rather than, as in the MPL dialogue, as an equation with the derivative
symbol on the left side. We compensate for this at the fourth prompt by
entering an equation with the derivative symbol on the left side. At the
ﬁfth prompt, we diﬀerentiate both sides of the equation First
 derivative ,
2.1. Mathematical Pseudo-language (MPL) 45
and at the sixth prompt apply Maple’s subscommand to substitute Ex-
pression ( 2.13) for the ﬁrst derivative symbol in the previous expression.
Unfortunately, we get a little more than we bargained for, since the left side
of the equation is returned as a ﬁrst derivative symbol applied to an ex-pression rather than as a second derivative symbol. The reason for this has
to do with Maple’s internal representation of the second derivative symbol
as nested ﬁrst derivatives
∂
∂x/parenleftbigg∂
∂xy(x)/parenrightbigg
.
Since Maple’s subsoperator replaces all occurrences of the ﬁrst derivative
symbol with Expression ( 2.13), we obtain the result shown in the dialogue.
Finally, at the seventh prompt, we compensate for this by using Maple’soperator op(which selects operands of an expression) to select the right
side of wand by applying the subsoperator to the resulting expression.
In addition, to obtain the MPL result, we include the second derivativesymbol on the left side of an equation.
Mathematica
The Mathematica implementation of Figure 2.8is given in Figure 2.10.T h e
statements at In[1]a n d In[2] are similar to those in the MPL dialogue.
Observe that Mathematica uses the equal sign ( =) for assignment, two
equal signs ( ==) for an equal sign in an equation, and the Doperator for
diﬀerentiation. At In[3], Mathematica’s Solve operator is used to solve
the equation vfor the derivative, where the result is returned as a set which
contains another set which contains the solution. The expression
y/prime[x]→−ex+8x
−1+4y[x]3, (2.14)
which is known as a transformation rule in the Mathematica language, is
the form Mathematica uses for the substitution operation later in the dia-
logue. However, if we insist that the solution be displayed as an equation,
we can obtain this form by using Mathematica’s Partoperator which selects
operands of an expression. At In[4], the expression Part[s,1] removes
the outer set braces, the next Partoperation removes the inner set braces,
and the outer Partoperation selects the right side of Expression ( 2.14).
We obtain the desired form by entering an equation with the derivative
symbol on the left side and then assign the result to FirstDerivative6.
6Since the underscore character (
 ) has special meaning in Mathematica, we
use the identiﬁers FirstDerivative and SecondDerivative instead of the identiﬁers
First
derivative andSecond
 derivative used in the MPL dialogue.
46 2. Elementary Concepts of Computer Algebra
In[1]: = u=e xp[ x]+y[x]ˆ4==4∗xˆ2+y[x]
Out[1]= ex+y[x]4==4x2+y[x]
In[2]: = v=D[u,x]
Out[2]= ex+4y[x]3y/prime[x]== 8x+y/prime[x]
In[3]: = s=Solve[v,D[y[x],x]]
Out[3]={{y/prime[x]→−ex+8x
−1+4y[x]3}}
In[4]: = FirstDerivative =D[y[x],x]] == Part[Part[Part[s,1],1],2]
Out[4]= y/prime[x] ==−ex+8x
−1+4y[x]3
In[5]: = w=D[FirstDerivative ,x]]
Out[5]= y/prime/prime[x] ==8−ex
−1+4y[x]3−12(−ex+8x)y[x]2y/prime[x]
(−1+4y[x]3)2
In[6]: = SecondDerivative =ReplaceAll [w,Part[Part[s,1],1]]
Out[6]= y/prime/prime[x] == −12(−ex+8x)2y[x]2
(−1+4y[x]3)3+8−ex
−1+4y[x]3
Figure 2.10. A Mathematica implementation of the MPL dialogue in Figure 2.8.
(Implementation: Mathematica (nb).)
To obtain the second derivative, at In[5] we diﬀerentiate both sides of
the equation FirstDerivative ,a n da t In[6], we obtain the substitution
with Mathematica’s ReplaceAll command. The substitution is deﬁned by
Part[Part[s,1],1] which selects the expression ( 2.14).
MuPAD
The MuPAD implementation of Figure 2.8is given in Figure 2.11.T h e
statements at the ﬁrst two prompts are similar to those in the MPL dia-
2.1. Mathematical Pseudo-language (MPL) 47
•u:=exp(x)+y(x)∧4=4∗x∧2+y(x);
ex+y(x)4=y(x)+4·x2
•v:=diff(u,x);
ex+4·y(x)3·∂
∂xy(x)=8·x+∂
∂xy(x)
•v2:=subs(v,diff(y(x),x)=Dy);
ex+4·Dy·y(x)3=8·x+Dy
•d:=solve(v2,Dy,IgnoreSpecialCases );
k8·x−ex
4·y(x)3−1L
•First
 derivative :=diff(y(x),x)=op(d,1);
∂
∂xy(x)=8·x−ex
4·y(x)3−1
•w:=diff(First
 derivative ,x);
∂2
∂x2y(x)=−ex+8
4·y(x)3−1−12·y(x)2·∂
∂xy(x)·(8·x−ex)
(4·y(x)3−1)2
•Second
 derivative :=subs(w,First
 derivative );
∂2
∂x2y(x)=−ex+8
4·y(x)3−1−12·y(x)2·(8·x−ex)2
(4·y(x)3−1)3
Figure 2.11. A MuPAD implementation of the MPL dialogue in Figure 2.8.
(Implementation: MuPAD(mnb).)
logue. The next three prompts, however, correspond to the single state-
ment<3>in the MPL dialogue. At the third prompt, we use MuPAD’s
subsoperator to replace the derivative diff(y(x),x) in the previous ex-
pression by the symbol Dy. This step is required because MuPAD’s solve
operator cannot solve for the expression diff(y(x),x) , even though it can
solve for other function forms. At the fourth prompt, MuPAD’s Solve
operator solves the equation v2forDy. Notice that we have included the
option IgnoreSpecialCases because, without this, the system performs
a more detailed analysis of the equation and also includes solutions forwhich the denominator 4 ·y(x)
3−1 = 0. These special solutions are not
required in our dialogue. At the ﬁfth prompt, we use MuPAD’s opopera-
tor (which selects operands of an expression) to extract the solution from
the set dand include diff(y(x),x) on the left side of an equation so that
First
 derivative corresponds to the output of <3>in the MPL dialogue.
48 2. Elementary Concepts of Computer Algebra
The operations at the next two prompts are the same as those at <4>and
<5>in the MPL dialogue.
Exercises
For the exercises in this section, the following operators are useful:
•In Maple, the expand,diff,subs,solve,op,a n d dsolveoperators. (Im-
plementation: Maple(mws).)
•In Mathematica, the Expand,D,ReplaceAll ,Solve,Part,a n d DSolve
operators. (Implementation: Mathematica (nb).)
•In MuPAD, the expand,diff,subs,solve,op,a n d odeoperators. (Im-
plementation: MuPAD(mnb).)
1. In this exercise we ask youto give an interactive dialogu e in a CAS similar
to the one in Figure 2.8that simulates the mathematical discourse in Fig-
ure2.12. UseaCAS’scommandforsolvingadiﬀerentialequationtoobtain
the general solution as in Expression ( 2.16), but don’t use this command
to obtain the arbitrary constant in the solution. Rather, use statements
similar to those in Figure 2.8to set up an equation for the arbitrary con-
stant and solve the equation. The last statement in the dialogue should
return an equation similar to Expression ( 2.19).
Consider the diﬀerential equation and initial condition:
dy
dx+y=x+exp( −2x),y(1)=3 . (2.15)
The general solution to this equation is given by
y=x−1−exp(−2x)+cexp(−x), (2.16)
where cis an arbitrary constant. To ﬁnd c, we substitute the initial condition
y( 1 )=3i n t oE q ua t i o n( 2.16) and obtain an equation for c:
3=−e−2+ce−1. (2.17)
Solving for c, we obtain
c=3e+e−1. (2.18)
Substituting Equation ( 2.18)i n t oE q ua t i o n( 2.16), we obtain the particular so-
lution to the diﬀerential equation:
y=x−1−exp(−2x)+(3e+e−1)e x p ( −x). (2.19)
Figure 2.12. A mathematical discourse that obtains the arbitrary constant in
the solution of a diﬀerential equation.
2.2. Expression Evaluation 49
2. Consider the second order diﬀerential equation
d2y(x)
dx2+5dy(x)
dx+6y(x)=sin( x),y(0)=2 .dy
dx(0) =1 .
This equation has a general solution that involves two arbitrary constants
which are found by substituting the two initial conditions into both thegeneral solution and its derivative and then solving the resulting system of
linear equations.
Give an interactive dialogue in a CAS similar to the one in Figure 2.8,
which ﬁnds the general solution to the diﬀerential equation, sets up the
equations for the arbitrary constants, solves for the arbitrary constants,and then substitutes them back into the general solution. Use a CAS’s
command for solving a diﬀerential equation to obtain the general solution
to the diﬀerential equation, but don’t use this command to obtain thearbitrary constantsinthesolution. Rather, usestatementssimilar tothose
in Figure 2.8to obtain the arbitrary constants. The last statement in the
dialogue should return an equation equivalent to
y(x)=(1/10) sin( x)−(1/10) cos( x)+(36 /5)e
−2x−(51/10)e−3x.
3. (a) Consider the polynomial y=ax3+bx2+cx+d.Give an interactive
dialogue in a CAS that ﬁnds the coeﬃcients a, b, c,anddsuch that
atx=2 ,
y=5,dy
dx=−2,d2y
dx2=2,d3y
dx3=−3.
The last statement should return the polynomial with the numerical
values for the coeﬃcients.
(b) Use the dialogue to show there are inﬁnitely may expressions of the
formy=(ax+b)/(cx+d) that satisfy the conditions in part (a).
(c) Use the dialogue to show it is impossible to ﬁnd an expression of the
formy=(ax+b)/(cx+d) that satisﬁes the conditions
y=1,dy
dx=2,d2y
dx2=3,d3y
dx3=4.
2.2 Expression Evaluation
The term expression evaluation (or just evaluation ) refers to the actions
taken by a CAS in response to an input expression. These actions include:
1. the analysis of the structure of an expression and the translation
of this structure into an internal form that is used by the CAS to
represent the expression;
50 2. Elementary Concepts of Computer Algebra
2. the evaluation of assigned variables and mathematical operators that
appear in an expression; and
3. the application of some elementary algebraic and trigonometric sim-
pliﬁcation rules.
In this section we consider the evaluation of variables and operators,
and take a brief look at the simpliﬁcation process. Expression structure is
described in detail in Chapter 3.
Variable and Operator Evaluation
Figure 2.13shows an MPL dialogue that gives some examples of variable
and operator evaluation. At <1>the expression t+ 1 is assigned to xand
at<2>a polynomial in xis assigned to y.S i n c exhas been assigned, its
value is included in the expression for y. In a similar way at <3>,t h e
values for xandyare included in the expression and the Factor operator
is evaluated. Statements <4>and<5>show that the evaluation process
a p p l i e st of u n c t i o nn a m e sa sw e l la so t h e rv a r i a b l e si na ne x p r e s s i o n .
But now, what happens when the value of an assigned variable is an-
other expression which also contains assigned variables? Statements <6>
through<9>illustrate what can happen in this situation. At <6>,<7>,
and<8>,t h ev a r i a b l e s u,v,a n dware assigned values where all variables
to the right of the assignment symbols are unassigned. What is the value of
u2after the execution of these assignments? Statement <9>contains two
responses that illustrate two diﬀerent approaches to variable evaluation.In the ﬁrst approach, called single-level evaluation ,t h ev a l u eo f uis the
value it was originally assigned ( v+ 2), and the assigned value of vin this
expression is ignored. In other words, with single-level evaluation only onelevel of active assignments is used.
In the second approach, called multi-level evaluation , the evaluation
process uses all active assignments. In this case, the value of u
2is obtained
using three levels of assignments
u2→(v+2 )2→(w2+2 )2→((t+3 )2+2 )2. (2.20)
Since some systems provide a way to control the evaluation level, MPL
provides the Evaluate operator for this purpose. At <10>,w ee v a l u a t e u2
using two levels of assignments.
Occasionally, it is useful to suppress the evaluation of a variable or
operator. We denote this operation in MPL by placing the variable or
operator name in quotes. For example, at <11>we suppress evaluation of
theDerivative operator and at <12>suppress evaluation of the assigned
variablew. Finally, there are times when it is necessary to unassign or
2.2. Expression Evaluation 51
<1>x:=t+1;
→ x:=t+1;
<2>y:=x2+4∗x+4;
→ y:= (t+1)2+4(t+1)+4
<3>x ∗Factor(y);
→(t+1)(t+3)2
<4>z:=f;
→ f;
<5>z(x);
→ f(t+1)
<6>u:=v+2;
→ u:=v+2;
<7>v:=w2;
→ v:=w2;
<8>w:=t+3;
→ w:=t+3
<9>u2;
→(v+2)2(single-level evaluation)
→((t+3)2+2)2(multi-level evaluation)
<10>Evaluate(u2,2);
→(w2+2)2
<11>”Derivative ”(t2,t);
→d(t2)
dt
<12>Derivative (”w”,t);
→0
<13>Unassign(w);
→ w
<14>Algebraic
expand((w+1)∗(w+2));
→ w2+3w+2
Figure 2.13. An MPL dialogue that shows examples of variable and operator
evaluation. (Implementation: Maple(mws),Mathematica (nb),MuPAD(mnb).)
52 2. Elementary Concepts of Computer Algebra
MPL
 Maple
 Mathematica
 MuPAD
multi-level
 multi-level
 multi-level
 multi-level
(dialogues),
 (interactive mode),
 in
 (interactive mode),
single-level
 single-level
 interactive mode
 single-level
(in procedures)
 (in procedures)
 and
 (in procedures)
procedures
control
evaluation
level
Evaluate(u,n)
 eval(u,n)
 not available
 level(u,n)
suppress
evaluation
”u”
 ’u’
 HoldForm[u]
 hold(u)
”Derivative ”(u,x)
 ’diff’(u,x)
 HoldForm[D][u,x] ,
hold(diff)(u,x)
and release
suppressed
evaluation
with
ReleaseHold[u]
Unassign(u)
 unassign(’u’)
 u=.
 delete(u)
Figure 2.14. Evaluation concepts in Maple, Mathematica, and MuPAD.
remove the value of an assigned variable. In MPL, the Unassign operator
is used for this purpose. At <13>, we apply Unassign tow,w h i c hm e a n s
at<14>wacts as a symbol in the mathematical expression.
InF i g u r e 2.14, we summarize the evaluation concepts considered above
in the Maple, Mathematica, and MuPAD systems. Observe that all three
systems use multi-level evaluation in the interactive mode, while both
Maple and MuPAD switch to single-level evaluation inside procedures7.In
MPL, we also use multi-level evaluation in dialogues, and following Mapleand MuPAD, use single level evaluation in procedures.
Automatic Simplification
The term automatic (ordefault )simpliﬁcation refers to the mathematical
simpliﬁcation rules that are applied to an expression during the evaluation
process. In computer algebra systems, this usually involves the “obvious”
simpliﬁcation rules from algebra and trigonometry that remove extraneous
symbols from an expression and transform it to a standard form.
7Procedures in a CAS language are like procedures or functions in a conventional
programming language. A procedure in the Maple language is given in Figure 1.3on
page 6. We consider procedures in Chapter 4.
2.2. Expression Evaluation 53
<1>2+3/4+5/6;
→43
12
<2>x+y+2∗x;
→3x+y
<3>x ∗y∗x2;
→ x3y
<4>1∗x3+a∗x0+b∗x1+0∗x2;
→ a+bx+x3
<5>x ∗y+3∗y∗x;
→4xy
<6>sin(π/2);
→1
<7>ln(e2);
→2
<8>arctan(1);
→ π/4
<9>ı2;
→− 1
<10>e(−ı∗π);
→− 1
<11>0≤1and1≤2;
→ true
<12>P andPandQ;
→ PandQ
Figure 2.15. An MPL dialogue that shows some examples of automatic simpliﬁ-
cation. (Implementation: Maple(mws),Mathematica (nb),MuPAD(mnb).)
The MPL dialogue in Figure 2.15illustrates some of these obvious sim-
pliﬁcations. Example <1>shows a simpliﬁcation that involves the sum
of rational numbers. Example <2>shows that automatic simpliﬁcation
combines numerical coeﬃcients of like terms. The next example <3>illus-
trates a similar simpliﬁcation in which integer exponents of the common
basexare combined. Example <4>illustrates some simpliﬁcation rules
that involve the integers 0 and 1. Notice that after evaluation, the x3term
appears at the right end of the expression. This reordering, which is an
54 2. Elementary Concepts of Computer Algebra
application of the commutative law of addition, serves to put the result in
a more readable form and, in some cases, contributes to the simpliﬁcation
process8. The next example <5>illustrates this point. To simplify this
expression, the term 3 ∗y∗xis ﬁrst reordered (using the commutative law
for multiplication) to 3 ∗x∗yafter which the coeﬃcients of the two like
terms are combined. Examples <6>,<7>,a n d<8>illustrate automatic
simpliﬁcation rules that involve known functions, while Examples <9>and
<10>illustrate simpliﬁcation rules that involve reserved symbols.
Examples <11>and<12>illustrate the automatic simpliﬁcation rules
that are applied in some systems to logical expressions as data objects9.In
Example<12>,PandQare unassigned identiﬁers and the simpliﬁcation
follows from the general logical rule PandP→P.
The examples in Figure 2.15are roughly similar to what happens in a
real computer algebra system. However, since there is no consensus about
which simpliﬁcation rules should be included in automatic simpliﬁcation,
the process can vary somewhat from system to system.
Figure 2.16shows an interactive dialogue with the Macsyma system
that shows what happens when automatic simpliﬁcation is suppressed. At
the prompt (c1)we assign an expression to uand at (c2)turn oﬀ the
automatic simpliﬁer by assigning the value false to the variable simp.A t
(c3)we diﬀerentiate uand obtain an expression that is so involved it is
diﬃcult to interpret10.A t (c4)we turn the automatic simpliﬁer back on
and at (c5)obtain a much more reasonable form for the derivative.
In MPL (as in a CAS), all expressions in dialogues and computer pro-
grams operate in the context of automatic simpliﬁcation. This means:
•All input operands to mathematical operators are automatically sim-
pliﬁed before the operators are applied.
•The result obtained by evaluating an expression is in automatically
simpliﬁed form.
Since automatic simpliﬁcation is so central to the programming process, it
is a good idea to understand which simpliﬁcation rules are applied by the
process and which are not. For now, the exercises in this section can beused to explore the automatic simpliﬁcation process in a CAS.
8The reordering process in Mathematica and MuPAD is similar to what is described
here. The reordering process in Maple is handled in a diﬀerent way (see Cohen [ 24],
Section 3.1).
9Maple obtains <11>and<12>. Mathematica obtains <11>, but not <12>.M u -
PAD obtains <12>, but not <11>.
10Notice that Macsyma uses logarithmic diﬀerentiation to diﬀerentiate ex2. Logarith-
mic diﬀerentiation provides a way to diﬀerentiate general powers of the form f(x)g(x).
2.2. Expression Evaluation 55
(c1) u : a*x + x*exp(x ∧2);
(d1) xex2+ax
(c2) simp : false;
(d2) false
(c3) diﬀ(u,x);
(d3) 1a+0x+ex2/parenleftbig
e−1x20 + log(e)(2x)/parenrightbig
x+1ex2
(c4) simp : true;
(d4) true
(c5) diﬀ(u,x);
(d5) 2x2ex2+ex2+a
Figure 2.16. An interactive dialogue with the Macsyma system that shows what
happens when automatic simpliﬁcation is suppressed.
In Chapter 3, we show how automatic simpliﬁcation modiﬁes the struc-
ture of expressions, which in turn leads to simpler algorithms and programs.InC o h e n[ 24], Chapter 3, we give the formal algebraic properties of au-
tomatically simpliﬁed expressions and describe an algorithm that obtains
the simpliﬁed form.
Exercises
1. (a) Consider the following transformations of powers11:
i.x2x3→x5.
ii.x1/2x1/3→x5/6.
iii.xaxb→xa+b.
11Some of the power transformations in this problem are only valid in certain (real or
complex) contexts.
56 2. Elementary Concepts of Computer Algebra
iv. (x2)3→x6.
v. (xa)2→x2a.
vi. (x2)1/2→|x|.
vii. (x1/2)2→x.
viii. (x2)a→x2a.
ix. (xy)2→x2y2.
x. (xy)1/3→x1/3y1/3.
xi. (xy)a→xaya.
Which of these transformations is obtained with automatic simpliﬁ-
cation?
(b) Based on the data obtained in part (a), give a summary of how the
power translations are applied in automatic simpliﬁcation.
2. The algebraic operations addition and multiplication obey the following
distributive laws:
a·(b+c)=a·b+a·c,(a+b)·c=a·c+b·c
(a) Considerthefollowing transformationswhicharebasedontheselaws:
i. 2x+3x→5x.
ii. (1+ x)+2(1+ x)→3(1+ x).
iii. 2x+√
2x→(2+√
2)x.
iv.ax+bx→(a+b)x.
v. (a+b)x→ax+bx.
vi. 2(x+y)→2x+2y.
vii.−(x+y)→−x−y.
viii.a(x+y)→ax+ay.
Whichof thethese transformations are obtained with automatic sim-
pliﬁcation?
(b) Based on the data obtained in part (a), give a summary of how the
distributive laws are applied in automatic simpliﬁcation.
3. (a) Consider the following transformations of the sin function:
i. sin(0) →0.
ii. sin( π/2)→1.
iii. sin( π/5)→√
26
5−√
(5)
4.
iv. sin( π/60)→√
5+√
5
8−√
5+√
5√
3
8−Q
−√
5
4+1/4w√
2
4Q
−√
5
4+1/4w√
2√
3
4.
v. sin(15 π/16)→sin(π/16).
vi. sin( −x)→−sin(x).
vii. sin( −x+1)→−sin(x−1).
2.2. Expression Evaluation 57
viii. sin( x+π/2)→cos(x).
ix. sin( x+2π)→sin(x).
x. sin( a+b)→sin(a)c o s (b)+cos( a)s i n (b).
xi. sin( a)c o s (b)+cos( a)s i n (b)→sin(a+b).
xii. sin2(x)+cos2(x)→1.
Which of the these transformations is obtained with automatic sim-
pliﬁcation?
(b) Based on the data obtained in part (a), give a summary of the trans-
formationrulesforthesinfunctionwhichareobtainedwithautomatic
simpliﬁcation.
4. In this problem we ask youto explore how the indeterminate forms 0 /0
and 00are handled in automatic simpliﬁcation.
(a) Enter each of the following expressions in the interactive mode of a
CAS.
i. 0/0.
ii. 00.
iii. (a(x+y)−ax−ay)/(x−x).
iv. (x−x)/(a(x+y)−ax−ay).
v. (x−x)a(x+y)−ax−ay.
vi. (a(x+y)−ax−ay)x−x.
(b) Based on the data obtained in part (a), give a summary of how inde-
terminate forms are handled by automatic simpliﬁcation.
5. Enter each of the following expressions in the interactive mode of a CAS:
−b, a −2∗b,1/a2,a / b .
Although each of the expressions is returned in the form it was entered,
some “hidden”transformations have been applied. In other words, theinternal form used by the CAS is diﬀerent from the displayed form. Use
the operand selection operator in a CAS to determine the internal form.
(Use opin Maple and MuPAD, and Partin Mathematica.)
6. This exercise refers to the Macsyma dialogue in Figure 2.16on page55.
What simpliﬁcation rules are used to obtain (d5)instead of (d3)?
7. Consider a CAS such as Mathematica or MuPAD where terms in a sum
or factors in a product are reordered as part of automatic simpliﬁcation.
ExperimentwiththeCAStodeterminehowitcarriesouttheorderingpro-
cess. Try polynomials such as <4>in Figure2.15as well as more involved
expressions. For example, are any terms or factors in
i
1+zy
2+(a+1)b+cJ
(a+1)
reordered by automatic simpliﬁcation?
58 2. Elementary Concepts of Computer Algebra
2.3 Mathematical Programs
Simply put, an MPL mathematical program (ormathematical algorithm )i s
a sequence of statements in the MPL language that can be implemented
in terms of the operations and control structures available in a computeralgebra programming language. The design and implementation of math-
ematical programs is a major theme of this book.
In a sense, the MPL dialogue in Figure 2.8is an example of a simple
interactive program. What we really have in mind, however, are more
involved programs that have the following features:
1. The statements in the program are viewed collectively as a unit which
either is entered at a single prompt or input region in the interactive
mode or, for larger programs, is contained in a text ﬁle that is loaded
into the system.
2. The program statements include mathematical expressions, assign-
ment statements, decision statements, iteration statements, and func-
tion and procedure deﬁnitions
12.
3. As with conventional programs, some statements serve as input state-
ments, some statements are for intermediate calculations for which
the output is not displayed, and some statements serve as outputstatements that display the result of a computation.
4. The program is designed in a general way so that it performs a cal-
culation for a class of problems rather than for a single problem.
For an example of a program that incorporates some of these points,
let’s consider again the computation of the ﬁrst and second derivatives of
an implicitly deﬁned function such as
exp(x)+y
3=4x2+y.
This problem, which was considered in Section 2.1, involves the manip-
ulations in Equations ( 2.8) through ( 2.12), and anMPL dialogue that
performs the calculations is given in Figrue 2.8on page 42. This dialogue
assumes that xis the independent variable, yis the dependent variable,
and requires that ybe expressed as the function form y(x).
In this section we modify the program to permit a choice of mathe-
matical variable names and do not require that the dependent variable be
12Decision statements, iteration statements, and function and procedure deﬁnitions
are described in Chapter 4.
2.3. Mathematical Programs 59
1 u
in:= exp( s)+t4=4∗s2+t:
2x
var:=s:
3y
var:=t:
4 u
new:=Substitute (u
in,y
var=y
var(x
var)):
5 u
p:=Derivative (u
new,x
var):
6First
derivative :=Solve(u
p,Derivative (y
var(x
var),x
var);
7 u
pp:=Derivative (First
derivative,x
var):
8Second
 derivative :=Substitute (u
pp,First
derivative );
Figure 2.17. An MPL mathematical program that obtains the ﬁrst and second
derivativesofanimplicitfunction. (Implementation: Maple(mws),Mathematica
(nb),MuPAD(mnb).)
expressed as a function form. By simply modifying the input statements,
we can obtain
dy
dx,d2y
dx2ordx
dy,d2x
dy2,
or, for that matter, if the input expression is expressed in terms of the
variablessandtas exp(s)+t3=4s2+t,the derivatives
dt
ds,d2t
ds2ords
dt,d2s
dt2.
An MPL program that performs these calculations is given in Fig-
ure2.17. Observe that some statements are terminated by a colon (lines 1,
2, 3, 4, 5, and 7) and some by a semicolon (lines 6 and 8). This notationis interpreted as follows: statements that end with a colon suppress the
display of the output, while those that end with a semicolon display the
output. Most computer algebra systems allow control of output display,
although the termination symbols vary from system to system
13.
Lines 1 through 3 serve as input statements for the program. Since the
program is designed to allow a choice of mathematical variable names, we
have chosen programming variable names ( u
in,x
var,y
var,etc.)t h a ta r e
unlikely to be used as mathematical variables. At line 1 we assign an input
expression, and at lines 2 and 3, we initialize two programing variables
x
varandy
varwhich contain the mathematical variables ( sandtfor
13In both Maple and MuPAD, statements that are terminated with a colon suppress
the output, while those that are terminated with a semicolon display the output. InMathematica, statements that are terminated with a semicolon suppress the output,while those without a terminating symbol display the output.
60 2. Elementary Concepts of Computer Algebra
this input) which serve as the independent and dependent variables. With
these two assignments, the output of the program is the derivatives
dt
dsandd2t
ds2.
The derivative operations at lines 5 and 7 require that the dependent vari-
abletbe expressed as the function form t(s). Since this is not done in line
1, we account for this at line 4 with a substitution that replaces each tin
u
inbyt(s). Except for changes in notation, lines 5 through 8 are similar
to those in Figure 2.8. With the choice of input, the outputs from lines 6
and 8 are
dt(s)
ds=−exp(s)+8s
4t(s)3−1, (2.21)
d2t(s)
ds2=−exp(s)+8
4t(s)3−1−12(−exp(s)+8s)2t(s)2
(4t(s)3−1)3.(2.22)
Observe that the dependent variable tis expressed in function notation
t(s), even though this is not done in the input at line 1. In Exercise 1we
describe a modiﬁcation of the program that removes this function notationfrom the output.
Case Study: General Quadratic Equations and Rotation of Axes
We conclude this section with a more involved MPL program that ob-tains the change of form of a quadratic equation under rotation of coordi-
nate axes.
A general quadratic equation in xandyhas the form
Ax
2+Bxy+Cy2+Dx+Ey+F=0, (2.23)
where the coeﬃcients are rational numbers and at least one of the coef-
ﬁcientsA,B,C /negationslash= 0. This equation represents one of the following eight
graphs in the plane:
1. a circle (such as x2+y2−1=0 ) .
2. an ellipse (such as x2+2y2−1=0 ) .
3. a single point (such as x2+y2=0o r(x,y)=( 0,0)).
4. an empty graph (such as x2+y2=−1).
2.3. Mathematical Programs 61
5. a hyperbola (such as x2−y2=1 ) .
6. a parabola (such as x2−y=0 ) .
7. two intersecting lines (such as x2−y2=0o rx=±y).
8. a single line (such as x2+2xy+y2=(x+y)2=0o rx=−y).
IfB=0i nE q u a t i o n( 2.23), it is a simple matter to determine the
type of graph and some of its important features by using the techniques of
analytical geometry. If B/negationslash= 0, the analysis is more involved. However, by
rotating the coordinate system, it is possible to transform Equation ( 2.23)
into a general quadratic equation in terms of new variables ( u,v)s ot h a t
the coeﬃcient of the uvterm is zero.
Consider the coordinate rotation shown in Figure 2.18,w h e r et h e( u,v)
coordinate system is rotated by an angle αfrom the ( x,y) system. To ﬁnd
a relationship between the ( x,y)a n d(u,v)c o o r d i n a t e s ,w eh a v e
x=rcos(α+β)y=rsin(α+β) (2.24)
and
u=rcos(β)v=rsin(β). (2.25)
xy
yuvP(x, y )o r( u, v )
xu
αβv
Figure 2.18. The point Pin the ( x,y)a n d( u,v)c o o r d i n a t es y s t e m s .
62 2. Elementary Concepts of Computer Algebra
By expanding the trigonometric expressions in Equations ( 2.24), we obtain
x=rcos(α)cos(β)−rsin(α)sin(β), (2.26)
y=rsin(α)cos(β)+rcos(α)sin(β). (2.27)
Substituting Equations ( 2.25)i n t oE q u a t i o n( 2.27), we obtain the coordi-
nate transformation
x=ucos(α)−vsin(α),y=usin(α)+vcos(α). (2.28)
By substituting Equations ( 2.28) into the original Equation ( 2.23), we ob-
tain a quadratic equation in the ( u,v)s y s t e m
A/primeu2+B/primeuv+C/primev2+D/primeu+E/primev+F/prime=0, (2.29)
where
A/prime=Acos2(α)+Bcos(α)sin(α)+Csin2(α),
B/prime=B(cos2(α)−sin2(α)) + 2(C−A)s i n (α)c o s (α),
C/prime=Asin2(α)−Bsin(α)cos(α)+Ccos2(α), (2.30)
D/prime=Dcos(α)+Esin(α),
E/prime=−Dsin(α)+Ecos(α),
F/prime=F.
To ﬁnd an αso that the coeﬃcient of the uvtermB/prime=0 ,w eu s et h e
trigonometric reduction rules
2sin (α)cos(α)=s i n ( 2α),cos2(α)−sin2(α)=c o s ( 2α),
so that the second equation in ( 2.30) becomes
B/prime=Bcos(2α)+(C−A)s i n ( 2α).
SettingB/prime= 0, we obtain when B/negationslash=0
cot(2α)=A−C
B. (2.31)
(WhenB= 0, a rotation is not needed and so α=0 . )W h e n0 <α<π/ 2,
the function cot(2 α) takes on all real values. Therefore, Equation ( 2.31)
deﬁnes a unique rotation αin this interval.
Example 2.2. Consider the quadratic equation x2+2xy+y2=0 . S i n c e
the left side can be factored as ( x+y)2, the quadratic equation represents
2.3. Mathematical Programs 63
the straight line y=−x. To ﬁnd the equation of the line in the ( u,v)
system, we have from Equation ( 2.31)
cot(2α)=A−C
B=1−1
2=0
and soα=π/4. Using Equation ( 2.30), we obtain the simple equation
u= 0 for the line in the new coordinate system. /square
To apply Equation ( 2.30) in more involved situations, we need expres-
sions for sin( α)a n dc o s ( α). Since 0 <2α<π,c o s ( 2α) has the same sign
as cot(2α). Therefore Equation ( 2.31) implies
cos(2α)=B
|B|A−C
/radicalbig
(A−C)2+B2(2.32)
whereB/|B|is included so that cos(2 α) has the correct sign. We obtain
values for sin( α)a n dc o s ( α) with Equation ( 2.32) and the identities
cos(α)=/radicalbigg
1+c o s ( 2α)
2,sin(α)=/radicalbigg
1−cos(2α)
2.
By using these identities together with Equation ( 2.32), we obtain the
coeﬃcients in Equation ( 2.30) in the new system without ﬁnding α.
Before giving a program that performs these calculations, we describe
two polynomial operators that are available in most computer algebra sys-
tems. Consider the polynomial in x
w=wnxn+wn−1xn−1+···+w0, (2.33)
where the coeﬃcients wjcan be integers, fractions, symbols, or even more
involved expressions, xrepresents a variable or a more involved expres-
sion, and nis a non-negative integer. Recall, the largest power of xin a
polynomial is called the degree of the polynomial.
The two most important operators for polynomials are the Degree and
Coeﬃcient operators14. The operator Degree (w,x) returns the degree of
the polynomial wwith respect to an expression x.
Example 2.3.
Degree (3x2+x+5,x)→2,
Degree (asin2(x)+bsin(x)+c,sin(x))→2.
14TheDegree andCoeﬃcient operators are described in greater detail in Chapter
6. In Chapter 6, these operators are called Degree
gpeandCoeﬃcient
 gpe,w h e r et h e
suﬃxgpestands for general polynomial expression (see Deﬁnition 6.14 on page 223).
64 2. Elementary Concepts of Computer Algebra
Observe that in the second example the expression is considered a polyno-
mial in the function form sin( x). (Implementation: Maple (mws), Mathe-
matica (nb),MuPAD (mnb).) /square
The operator Coeﬃcient (w, x, j ) returns the coeﬃcient wjofxjin
Equation ( 2.33).
Example 2.4.
Coeﬃcient (3x2+x+5,x ,2)→3,
Coeﬃcient (asin2(x)+bsin(x)+c,sin(x),2)→a,
Coeﬃcient (ax+bx+c, x,1)→a+b,
Coeﬃcient (Coeﬃcient (2x2+3xy+4y2+5x+6y+7,x,1),y ,0)→5.
In the last example, the inner application of the Coeﬃcient operator obtains
3y+5 and the outer application obtains the value 5. Maple (mws), Math-
ematica (nb), MuPAD (mnb).) Maple (mws), Mathematica (nb),MuPAD
(mnb).) /square
The degree and coeﬃcient operations in Maple, Mathematica and Mu-
PAD are given in Figure 2.4on page 35.
An MPL program that obtains an expression for the polynomial in the
(u,v) coordinate system is given in Figure 2.19. The input to the program
is given in the assignment at line 1. Notice that we permit both sidesof the equation to contain terms of the polynomial and combine the two
sides using the Operand selection operator. The output of the program
is the equation obtained by evaluating the expression in line 17. For the
expression in line 1, the output is the equation (1 /2)u
2−(1/2)v2−1=0 .
The programs considered so far are quite elementary. In later chapters
we introduce other MPL mathematical operators and language featuresthat enable us to construct more involved and interesting programs.
Exercises
For the exercises in this section, the following operators are useful:
•In Maple, the coeff,expand,abs,diff,subs,solve,op,int,a n d dsolve
operators. (Implementation: Maple(mws).)
•In Mathematica, the Coefficient ,Expand,Abs,D,Derivative ,
ReplaceAll ,Solve,Part,Integral,a n d DSolveoperators. (Imple-
mentation: Mathematica (nb).)
•In MuPAD, the coeff,expand,abs,diff,subs,solve,op,int,a n d ode
operators (Implementation: MuPAD(mnb).)
2.3. Mathematical Programs 65
1 eq:=x∗y=1:
2 w:=Operand(eq,1)−Operand(eq,2) :
3 A:=Coeﬃcient (w,x,2) :
4 B:=Coeﬃcient (Coeﬃcient (w,x,1),y,1) :
5 C:=Coeﬃcient (w,y,2) :
6 D:=Coeﬃcient (Coeﬃcient (w,x,1),y,0) :
7 E:=Coeﬃcient (Coeﬃcient (w,y,1),x,0) :
8 F:=Coeﬃcient (Coeﬃcient (w,x,0),y,0) :
9 g:=B/Absolute
value(B)∗(A−C)/((A−C)2+B2)1/2:
10 ca:=((1+ g)/2)1/2:
11 sa:= ((1 −g)/2)1/2:
12 Ap:=A∗ca2+B∗ca∗sa+C∗sa2:
13 Cp:=A∗ca2−B∗ca∗sa+C∗sa2:
14 Dp:=D∗ca+E∗sa:
15 Ep:=−D∗sa+E∗ca:
16Fp:=F:
17 Ap∗u2+Cp∗v2+Dp∗u+Ep∗v+Fp=0 ;
Figure 2.19. An MPL program that transforms a quadratic polynomial in xand
yto a quadratic polynomial in uandvwithout the u∗vterm. (Implementation:
Maple(mws),Mathematica (nb),MuPAD(mnb).)
1. The output of the program in Figure 2.17i sg i v e ni nE q ua t i o n s( 2.21)a n d
(2.22). Observe that the dependent variable tis displayed as a function
form. Modifytheprogramsothattheoutputisdisplayedwithoutfunction
forms including the function forms that appear in the derivative symbols.
2. An implicit equation f(x,y)=Kdeﬁnes a family of curves that depends
on the parameter K. We deﬁne two families f(x,y)=Kandg(x,y)=C
to beorthogonal trajectories if, whenever a curve f(x,y)=Kintersects a
curveg(x,y)=C, thetangent lines (derivatives)to the curvesat the point
of intersection are perpendicular. For example, the circles x2+y2=K
(with K>0) and the straight lines y/x=Care orthogonal trajectories.
Indeed, using implicit diﬀerentiation, a circle has a tangent with slope
dy
dx=−x/y,
while the straight line has slope
dy
dx=y/x.
Therefore, at a point of intersection, the circle and line have derivatives
that are negative reciprocals and so they intersect at a right angle.
66 2. Elementary Concepts of Computer Algebra
For a given family f(x,y)=K, we can ﬁnd the family of curves that is
orthogonal to it by solving a diﬀerential equation. For example, for the
family of parabolas f(x,y)=y−x2=K, we ﬁrst diﬀerentiate (implicitly)
to obtain a diﬀerential equation satisﬁed by the family of curves
dy
dx−2x=0.
Next, we obtain the diﬀerential equation for the orthogonal family by re-
placing the derivative symbol by its negative reciprocal. Therefore, the
orthogonal family to the parabolas satisﬁes the diﬀerential equation
dy
dx+1/2x=0.
Solving this equation we obtain the orthogonal family g(x,y)=l o g |x|+
2y=C.
Now let urepresent a family of curves in the form f(x,y)=K.G i v e
a program that ﬁnds the orthogonal family to f(x,y)=K.T e s t y o ur
program for the families x2+y2=K,y−x2=K,a n dx2−y2=K.
3. Let wbea general quadraticEquation ( 2.23)i nxandywithA/negationslash=0 ,C/negationslash=0
andB= 0. Give a program that completes the square in xandy.F o r
example, the program should transform 2 x2+3y2−4x−12y+10=0
to 2(x−1)2+3(y−2)2−4 = 0. (Do not use the Factoroperator in this
program.)
4. A ﬁrst order linear diﬀerential equation has the form
dy
dx=p(x)y+q(x). (2.34)
It is shown in books on diﬀerential equations that the general solution to
this equation is
y=(1/u)W
uqdx}
+C(1/u), (2.35)
where
u=e xpW
−
p(x)dx}
andCis an arbitrary constant. The arbitrary constant is found by substi-
tuting an initial condition y(x0)=y0into the general solution and solving
for the constant. Give a program that ﬁnds the general solution to a lin-
ear diﬀerential equation and uses an initial condition to ﬁnd the arbitrary
constant. For example, for
dy(x)
dx=xy(x)+x, y(1)=2 , (2.36)
the solution returned is equivalent to
y(x)=−1+3exp( −1/2) exp(( −1/2)x2).
Assume the input to your program is similar to Equations ( 2.36).
2.3. Mathematical Programs 67
5. A linear diﬀerential Equation ( 2.34) has a general solution of the form
y=f(x)+Cg(x) (2.37)
where Cis an arbitrary constant (see Equation ( 2.35) above). In this
problem, we are given an expression in the form ( 2.37) and ﬁnd the ﬁrst
order linear diﬀerential equation which has the expression as a generalsolution. For example, given
y=xln(x)+Cx , (2.38)
we can ﬁnd the diﬀerential equation by ﬁrst solving Equation ( 2.38)f o r
the arbitrary constant
C=y−xln(x)
x. (2.39)
Diﬀerentiating Equation ( 2.38)w eo b t a i n
dy
dx=1+l n( x)+C,
and substituting the value for Cin Equation ( 2.39) into this expression we
obtain
dy
dx=y/x+1.
Give a program that ﬁnds the diﬀerential equation using steps similar to
the ones in this example. Assume the input expression has the form ( 2.37)
where g(x)/negationslash= 0. Test your program for the functions y=xln(x)+Cx,
y=x+Csin(x), and y=e xp ( x)+Csin(x).
6. A linear second order diﬀerential equation has the form
d2y
dx2=p(x)dy
dx+q(x)y+r(x). (2.40)
This equation has a general solution of the form
y=c1f(x)+c2g(x)+h(x), (2.41)
where c1andc2are arbitrary constants. In this problem, we are given
an expression in the form ( 2.41) and ﬁnd a second order linear diﬀerential
equation which has the expression as a general solution. For example, for
y=c1x+c2x2+x3,
we obtain
d2y
dx2=(2/x)dy
dx−(2/x)y+2x.
GiveaprogramthathasanexpressionoftheformEquation( 2.41)asinput
andﬁndsthe diﬀerential equation. The approachis similar totheone used
68 2. Elementary Concepts of Computer Algebra
in Exercise 5,exceptnowwemusteliminate twoarbitrary constants c1and
c2fromthesecondderivativeoftheinputexpression. Thisprobleminvolves
thesolutionasystemoftwoequationsforthetwounknowns c1andc2,a n d
to guarantee a solution to the system, assume that f(x)g/prime(x)−f/prime(x)g(x)
is not identically 0.
7. ThemethodofLagrangemultipliersisatechniqueforﬁndingthemaximum
andminimumvaluesofafunctionofseveralvariableswhentheindependentvariables are subject to one or more constraints
15. For example, to ﬁnd
the maximum and minimum values of f(x,y)w h e r e xandyare subject to
t h es i d er e l a t i o n g(x,y)=c, form a new function
L(x,y,λ)=f(x,y)−λg(x,y),
where the variable λis called the Lagrange multiplier. Next solve the
following three simultaneous equations for the unknowns x,y,a n dλ:
∂L
∂x=0,∂L
∂y=0,∂L
∂λ=0. (2.42)
Themaximumandminimumvalues(iftheyexist)occuratthepoints( x,y)
that are solutions to this system. For example, if f=x−xy+2andthe
side relation is theline x−2y=1, thenEquations ( 2.42)ha v etheso lutio n
λ=3/4,x=3/2,y=1/4,
and the maximum value of foccurs at this point. Give a program that
sets up the equations in ( 2.42) and ﬁnds their solution.
8. Let wbe a general quadratic equation in xandywithA=−C/negationslash=0 .
(a) Show there is a rotation of axes αthat gives A/prime=0a nd C/prime=0 .
(b) Give a program that ﬁnds the equation in the ( u,v) system deﬁned
by the rotation in part (a).
(c) Usethealgorithminpart(b)toﬁndtheequationfor x2+xy−y2−1=
0i nt h e( u,v)s y s t e m .
2.4 Sets and Lists
In computer algebra languages both sets and lists are used to represent
collections of mathematical expressions. In this section we give the math-ematical properties of sets and lists, and describe the operations that are
a p p l i e dt oe a c ho ft h e m .
15See Simmons [ 88] for an elementary discussion of the method.
2.4. Sets and Lists 69
Sets
Inm a t h e m a t i c s ,a setis deﬁned as simply a collection of objects. In MPL,
a set is a ﬁnite collection of expressions that is surrounded by the braces {
and}. For example, the expression
{x+y=1,x−y=2}
represents a set with two members, the equations x+y=1a n dx−y=2 .
Following mathematical convention, MPL sets satisfy the two proper-
ties:
1.The contents of a set does not depend on the order of the elements in
the set. This means that {u, v}and{v, u}are the same set.
2.The elements of a set are distinct. In other words, a set cannot
contain duplicate elements.
In MPL, sets are used in situations where the order of expressions in the
set is not signiﬁcant. For example, sets are used in the expression
Solve({2x+4y=3,3x−y=7},{x, y}),
since the order of both the equations and the variables does not change the
result of the operation.
Algebraic Operations On Sets
LetAandBrepresent sets and let xrepresent an arbitrary expression.
The following operations are deﬁned for sets:
•Union of Sets ,A∪B.T h e union of setsAandBis a new set that
contains all the elements in Aor inBor in both sets. For example,
{a, b, c, d }∪{c, d, e, f }→{a, b, c, d, e, f }.
•Intersection of Sets ,A∩B.T h e intersection of setsAandBis a
new set that contains all the elements that are in both AandB.F o r
example,
{a, b, c, d }∩{c, d, e, f }→{c, d}.
•Diﬀerence of Sets ,A∼B.T h e diﬀerence of setsAandBis a new
set that contains all the elements that are in Abut not in B.F o r
example,
{a, b, c, d }∼{c, d, e, f }→{a, b}.
70 2. Elementary Concepts of Computer Algebra
MPL
 Maple
 Mathematica
 MuPAD
set notation
{a,b,c}
 {a,b,c }
 {a,b,c }
 {a,b,c }
∅
 {}
 {}
 {}
A∪B
 A union B
 Union[A,B]
 A union B
A∩B
 A intersect B
 Intersection[A,B]
 A intersect B
A∼B
 A minus B
 Complement[A,B]
 A minus B
x∈A
 member(x, A)
 MemberQ[x,A]
 contains(A,x)
Figure 2.20. Set operations in Maple, Mathematica, and MuPAD. (Implementa-
tion:Maple(mws),Mathematica (nb),MuPAD(mnb).)
•Set membership, x∈A.The expression x∈Aevaluates to trueifx
is inA, and otherwise evaluates to false. For example,
a∈{a, b, c, d }→true,
e∈{a, b, c, d }→false.
In the course of manipulating sets, we might obtain the empty set or
the set with no elements. Following mathematical convention, we representthis set with the reserved symbol ∅. For example, {a,b,c}∩{d,e,f }→∅.
Most computer algebra systems provide sets along with the algebraic
operations described above (see Figure 2.20).
Set Operations on Symbols
Some computer algebra systems allow variable symbols as operands of the
set operations ∪,∩,a n d ∼, and obtain general set identities as either part
of the automatic simpliﬁcation process or as the output of an operator.
This facility is illustrated in the MuPAD dialogue in Figure 2.21.A t t h e
ﬁrst three prompts, automatic simpliﬁcation obtains the identities
A∪A∪B=A∪B,
A∩∅=∅,
(A∩B)∼(B∩A)= ∅,
and at the fourth prompt, the expand operator obtains the distributive law
for sets
A∩(B∪C)=(A∩B)∪(A∩C).
Similar results are obtained with the Maple system.
2.4. Sets and Lists 71
•A union A union B ;
A∪B
•A intersect {};
∅
•(A intersect B )minus (B intersect A );
∅
•expand (A intersect (B union C ));
A∩B∪A∩C
Figure 2.21. General set identities in MuPAD (Implementation: Maple(mws),
MuPAD(mnb).)
Lists
An MPL listis a ﬁnite collection of expressions that is surrounded by the
brackets [ and ]. For example, the expression [ y(x)=3,x=1 ]i sa
list with two equations. The empty list, which contains no expressions, is
represented by [ ].
Lists are distinguished from sets by the following two properties:
1.The order of expressions in a list is signiﬁcant. This means the ex-
pressions [ y(x)=3,x=1 ]a n d[ x=1,y(x) = 3] represent diﬀerent
lists.
2.Duplicate elements are permitted in a list. This means the expressions
[x,y]a n d[x,y,y] represent diﬀerent lists.
In MPL, lists are used in situations where the order or duplication of
expressions is signiﬁcant. For example, Figure 2.22illustrates the eﬀect of
order on the sequential substitution operation. The Sequential
 substitute
operator shown in the dialogue performs a sequence of substitutions. Sincethe outcome of this operation depends on the order of substitutions, a list
is used to indicate this order. In <1>, the substitution y(x) = 3 occurs
beforex= 2 while in <2>this order is reversed. Multiple substitutions,
including the Sequential
substitute operator, are described in greater detail
in Section 3.3.
72 2. Elementary Concepts of Computer Algebra
<1>Sequential
substitute(y(x)=m∗x+b,[y(x)=3,x=2 ] );
→3=2m+b
<2>Sequential
substitute(y(x)=m∗x+b,[x=2,y(x)=3]);
→ y(2)=2 m+b
Figure 2.22. An MPL dialogue that illustrates the eﬀect of order in a list on the
Sequential
substitute operation. (Implementation: Maple(mws),Mathematica
(nb),MuPAD(mnb).)
Primitive Operations on Lists
LetL,M,a n dNrepresent lists and let xrepresent an arbitrary expression.
The MPL operations for lists reﬂect the order preserving property:
•First(L). IfLcontains one or more expressions, the operator returns
the ﬁrst expression in L.IfL= [ ], the operator returns the symbol
Undeﬁned . For example,
First([a,b,c])→a.
•Rest(L). IfLcontains one or more expressions, the operator returns
a new list that contains all expressions in Lexcept the ﬁrst expression.
The original list Lis not changed by this operation. If L=[] ,t h e
operator returns the symbol Undeﬁned . For example,
Rest([a,b,c])→[b,c].
•Adjoin (x,L). The operator returns a new list that contains the ex-
pressionxfollowed by expressions in L. The original list Lis not
changed by this operation. For example,
Adjoin (d,[a,b,c])→[d,a,b,c ].
•Join(L,M,...,N ). The operator returns a new list that contains the
expressions in the list Lfollowed by the expressions in Mand so on.
For example,
Join([a,b],[b,c],[c,d,e])→[a,b,b,c,c,d,e ].
2.4. Sets and Lists 73
MPL
 Maple
 Mathematica
 MuPAD
list notation
[a,b,c ]
 [a,b,c]
 {a,b,c }
 [a,b,c]
empty list
[]
 []
 {}
 []
First (L)
 op(1,L)
 First[L]
 op(L,1)
Rest(L)
 [op(2..nops(L),L)]
 Rest[L]
 [op(L,2..nops(L)]
Adjoin (x,L)
 [x,op(L)]
 Prepend[L,x]
 append(L,x)
Join(L,M )
 [op(L),op(M)]
 Join[L,M]
 concat(L,M)
Reverse (L)
 see Fig. 2.24
 Reverse[L]
 see Fig. 2.25
Delete (x,L)
 see Fig. 2.24
 Delete[L,
 listlib ::
Position[L,x]]
 setDifference (L,[x])
x∈L
 member(x,L)
 MemberQ[x,L]
 contains(L,x)
Figure 2.23. List operations in Maple, Mathematica, and MuPAD. (Implemen-
tation:Maple(mws),Mathematica (nb),MuPAD(mnb).)
•Reverse (L). The operator returns a new list with elements of the
listLin reverse order. The original list Lis not changed by this
operation. For example,
Reverse ([a,b,c])→[c,b,a].
•Delete (x,L). This operator returns a new list with all instances of x
removed from L. The original list Lis not changed by this operation.
For example,
Delete (b,[a,b,c,b ])→[a,c].
•List membership, x∈L. The operator returns trueifxis inL,a n d
otherwise returns false. For example,
b∈[a,b,c]→true.
Most computer algebra languages provide lists and most of the list
operations described above (see Figure 2.23). Although Maple does not
provide the Reverse andDelete operators, and MuPAD does not provide
theReverse operator, these operations can be deﬁned with procedures (see
Figures 2.24and2.25).
Exercises
1. Let A={a,b,c,d },B={b,d,e,f },a n dC={a,c,e,f }.
(a) Evaluate
i.A∪B.
ii.A∩B∩C.
74 2. Elementary Concepts of Computer Algebra
Reverse:=proc(L)
#Input
# L: a list#Output
# a new list with the elements of L in reverse order
i fL=[]o r nops(L)=1 then RETURN(L)
else RETURN([op(Reverse([op(2..nops(L),L)])),op(1,L)])
fi
end:
Delete:=proc(x,L)
#Input
# L: a list
#Output# a new list with all instances of x removed from L
local position;
if member(x,L,position) then
RETURN([op(1..position-1,L),
op(Delete(x,[op(position+1..nops(L),L)]))])
else RETURN(L)
fi
end:
Figure 2.24. Mapleproceduresfor ReverseandDelete. (Implementation: Maple
(txt).)
iii. (A∪B)∩C.
iv. (A∪B)∼C.
v.d∈A.
(b) Implement each of the operations in part (a) with a CAS.
2. Let L=[a,b,c,d],M=[b,d,e,f]a n dN=[a,c,e,f].
(a) Evaluate
i.Rest(Join(L, M,N)).
ii.Adjoin(First(L),M).
iii.Join(Delete(a,L),Reverse(N)).
(b) Implement each of the operations in part (a) with a CAS.
2.4. Sets and Lists 75
Reverse := proc(L)
/*Input
L: a list
Output
a new list with the elements of L in reverse order */
beginif L = [ ] or nops(L)=1 then return(L)
else return([op(Reverse([op(L,2..nops(L))])),op(L,1)])
end_ifend_proc:
Figure 2.25. A MuPAD procedure for Reverse. (Implementation: MuPAD
(txt).)
3. Let M=[a,b,c,d].
(a) Give a sequence of MPL statements that performs each of the follow-
ing operations:
i. Obtain the last element of M.
ii. Form a new list with the expression eadded to the end of M.
iii. Form a new list with the second expression removed from M.
(b) Implement each of the operations in part (a) with a CAS.
Further Reading
2.2Expression Evaluation. The evaluation process in computer algebra sys-
t e m si sd e s c r i b e di nF a t e m a n[ 37]. Evaluation in Maple is described in Heal,
Hansen, and Rickard [ 44]. Evaluation in Mathematica is described in Wolfram
[102]. Evaluation in MuPAD is described in Gerhard et al. [ 40].
2.3Mathematical Programs. Programming in Maple is described in Mon-
agan et al. [ 69]. Programming in Mathematica is described in Wolfram [ 102].
Programming in MuPAD is described in Gerhard et al. [ 40].
2.4Sets and Lists. Sets and set operations are described in Maurer and Ral-
ston [65].

3
Recursive Structure of
Mathematical Expressions
This chapter is concerned with the structure of mathematical expressions.
Since mathematical expressions are the data objects in computer algebra,
an understanding of this structure is essential for computer algebra pro-gramming.
In Section 3.1we introduce the concept of recursion and describe a
number of ways it is used in mathematics and mathematical algorithms.In this chapter, recursion’s main role is to describe the structure of ex-
pressions. Since recursion is also an essential programming technique in
computer algebra, this topic is covered in detail in Chapter 5.
In Section 3.2we describe two structural forms for mathematical ex-
pressions that correspond to the internal forms used by computer algebra
systems before and after automatic simpliﬁcation. In addition, we intro-duce four primitive operators that provide a way to analyze and construct
expressions. Finally, in Section 3.3we describe a number of operators, in-
cluding the Free
ofandSubstitute operators, for which the actions depend
primarily on the structure of an expression.
3.1 Recursive Definitions and Algorithms
Inm a t h e m a t i c s ,a recursive deﬁnition or algorithm is one that is deﬁned
in terms of a simpler version of itself or sometimes in terms of just an-
other version of itself. The recursion concept is fundamental to nearly all
of computer algebra. Indeed, recursiveness in one form or another plays
a crucial role in the implementation of many standard operations in com-
77
78 3. Recursive Structure of Mathematical Expressions
puter algebra including simpliﬁcation, substitution, factorization, solution
of equations, diﬀerentiation, and integration. In this section, we give a
brief introduction to recursion, and explain why it plays such an important
role in the manipulation of expressions.
For a simple example, let’s consider the operation n! which we ﬁrst
deﬁne in a non-recursive way:
n!=/braceleftbigg1i f n=0 ,
1·2···(n−1)·nifn>0.(3.1)
Forn≥1, the factorial operation is deﬁned as the product of all integers
from 1 to n. This description does not apply for n=0 . In s t e a d ,w e
deﬁne 0! = 1. This convention is a convenient and consistent one for manyapplications that involve the factorial operation
1.
As a consequence of the deﬁnition ( 3.1), forn>0,n!=n·(n−1)!.
This relationship forms the basis for a recursive deﬁnition of the factorialoperation:
n!=/braceleftbigg1i f n=0 ,
n·(n−1)! ifn>0.(3.2)
This deﬁnition is recursive since for n>0,n!i sd e ﬁ n e di nt e r m so fa
simpler factorial ( n−1)!. In this case the adjective simpler refers to the
factorial operation for a smaller integer value.
The approach in ( 3.2) is more than just another way to deﬁne the
factorial operation; it actually suggests another way to implement the cal-culation. To see what we mean by this, consider ﬁrst a computation based
on the non-recursive deﬁnition ( 3.1). An MPL procedure that performs
this calculation is given in Figure 3.1.
The procedure is expressed in the MPL notation and terminology that is
used throughout the book to describe mathematical algorithms. Althoughwe will have much to say about this aspect of our pseudo-language in
Chapter 4, the examples in this section are simple enough to be understood
without a detailed description of the language.
Here is a brief description of the terminology we use in the procedure.
A procedure deﬁnition in MPL is similar to a function deﬁnition in a con-
ventional programming language. The procedure declaration at the top of
Figure 3.1gives the name Iter
factto the sequence of statements in lines 1
through 7. The procedure can be invoked by a statement such as
Iter
fact(4)→24.
1For example, by deﬁning 0! = 1, the binomial theorem can be expressed in the
compact form
(x+y)n=n
i=0n!
i!(n−i)!xn−iyi.
3.1. Recursive Definitions and Algorithms 79
Procedure Iter
fact(n);
Input
n: non-negative integer;
Output
n!;
Local Variables
f,i;
Begin
1 ifn=0then
2Return(1)
3 else
4 f:= 1;
5 fori=1tondo
6 f:=f∗i;
7Return(f)
End
Figure 3.1. An MPL iterative procedure for n!. (Implementation: Maple(txt),
Mathematica (txt),MuPAD(txt).)
Communication with the procedure is through the input parameter ( nin
this case) and the Return statements in lines 2 and 7. The if-then-else
statement provides a way to select the appropriate course of action as
required by the deﬁnition ( 3.1), and theforstatement provides a loop that
performs the computation. Since this procedure is based primarily on thislooping process, it is called an iterative procedure.
Let’s compare the iterative procedure to a factorial procedure based on
the recursive deﬁnition ( 3.2). First, observe how a numerical computation
b a s e do n( 3.2) proceeds:
4! = 4(3!) = 4(3(2!)) = 4(3(2(1!))) = 4(3(2(1(0!))))
= 4(3(2(1(1)))) (3.3)
=2 4.
To perform the calculation, we repeatedly apply the deﬁnition ( 3.2)u n t i l
the casen= 0 is encountered. Once this point is reached, the value 0!
is replaced by the value 1, and the numerical computation proceeds as
indicated by the parentheses in the second line of Equation ( 3.3).
Although this computation has an iterative ring to it, we can give an
MPL procedure that is a direct translation of the recursive deﬁnition which
does not utilize an explicit iteration statement (see Figure 3.2). Forn>0,
80 3. Recursive Structure of Mathematical Expressions
Procedure Rec
fact(n);
Input
n: non-negative integer;
Output
n!;
Local Variables
f;
Begin
1 ifn=0then
2 f:= 1
3 else
4 f:=n∗Rec
fact(n−1);
5Return(f)
End
Figure 3.2. An MPL recursive procedure for n!. (Implementation: Maple(txt),
Mathematica (txt),MuPAD(txt).)
the operator simulates the looping operation by calling on itself (line 4) to
perform a simpler version of the calculation. A procedure that calls itself
directly (as in this example) or indirectly through a sequence of procedures
is called a recursive procedure .T h e c a s e n= 0 (lines 1 and 2) is referred
to as a termination condition for the procedure since it is deﬁned directly
and does not require further calls on Rec
fact.A s i n E q u a t i o n ( 3.3), for
n>0 the calculation is eventually reduced to the termination condition
that stops the process. Each recursive procedure must have one or more
termination conditions.
TheRec
factprocedure is presented to illustrate simply what is meant
by recursion in mathematics and to show how a recursive procedure isexpressed in MPL. However, there is more to recursive programming than
is shown by this example, and the topic will be discussed in greater detail
in Chapter 5.
Recursive Structure of Expressions
One reason recursion is essential to symbolic computation has to do with
therecursive structure of mathematical expressions. This structure is de-
scribed using the terms in the following deﬁnition:
Definition 3.1. Mathematical expressions are classiﬁed as either atomic
expressions or compound expressions:
3.1. Recursive Definitions and Algorithms 81
1. An atomic expression is an integer, real, symbol, or reserved symbol
(e,∞,true, etc.). The atomic expressions are the atoms or basic
building blocks of more involved mathematical expressions.
2. A compound expression is composed of an operator with operands.
The operator can be an algebraic operator ( +,−, etc.), a relational
operator ( =,<, etc.), a logical operator ( and,or,not), a set oper-
ator ( ∪,∩,∼), a function or operator name, or the terms setor
list. An operand of an operator can be either an atomic expression
or another compound expression. Depending on the operator, each
operator can have one or more operands. /square
Example 3.2. Consider the expression m∗x+b. Since it is common
practice in mathematics to give higher precedence to ∗than +, we view
the expression as a sum with two operands: the compound expression m∗x
and the atomic expression b. The operator ∗has two operands, the atomic
expressions mandb. In a similar way, the equation y=m∗x+bhas the
operator = with two operands, the atom yand the compound expression
m∗x+b. /square
Example 3.3. The expression n! has one operator ! with one operand the
symboln. /square
Example 3.4. Consider the expression Integral (sin(x),x). The Integral
operator has two operands, the compound expression sin( x)a n dt h es y m b o l
x. The function sin( x) has the operator sin with the single operand the
symbolx. /square
Example 3.5. Consider the list [ a,b,c]. In MPL, a list is viewed as a math-
ematical expression with the term listas the operator and the members
of the list, a,b,a n dc, as operands. It may seem odd to think of the term
listas an operator since it is not as “action oriented” as an operator like
+. However, this view of lists gives a uniform structure for all compoundexpressions. In a similar way, the set {a,b,c}is a compound expression
with operator set. /square
Deﬁnition 3.1is a recursive description of a mathematical expression
since a compound expression is constructed with an operator and simpler
expressions (the operands) that are either compound expressions them-
selves or termination symbols (atomic expressions). Although it may sound
as if we are using a recursive deﬁnition to state the obvious, we shall see that
82 3. Recursive Structure of Mathematical Expressions
the recursive structure of expressions implies that a recursive algorithm is
appropriate (or even essential) for many mathematical operations.
Recursion in Mathematics
Although the recursion concept is discussed in textbooks on computer sci-ence, it is rarely mentioned in textbooks on algebra, trigonometry, andcalculus. Therefore, you may ﬁnd it surprising that you often use recursion
when doing pencil and paper manipulations. For example, consider the
algebraic simpliﬁcation of the expression
3·(x+x)+x
2/x→7·x (3.4)
using the simpliﬁcation rules ordinarily found in automatic simpliﬁcation.
To simplify the sum we ﬁrst simplify each of its operands. And to simplify
the ﬁrst operand
3·(x+x), (3.5)
we ﬁrst simplify each of its operands 3 and x+x. The expression 3 is an
atom and requires no further simpliﬁcation. To simplify x+x,w eﬁ r s t
simplify its operands (the two xsymbols which are atoms and require no
simpliﬁcation) and then apply a simpliﬁcation rule to obtain 2 ·x.A tt h i s
point Expression ( 3.5) has been transformed to the form 3 ·(2·x), and we
apply simpliﬁcation rules to obtain 6 ·xfor the ﬁrst term in Expression
(3.4). In a similar way, we simplify the second term in ( 3.4)t oxand apply
the simpliﬁcation rules to 6 ·x+xto obtain 7 ·x.
An outline of the Automatic
 simplify procedure2we have used to sim-
plify this expression is shown in Figure 3.3. This simpliﬁcation process
is recursive since a compound expression uis simpliﬁed by ﬁrst applying
Automatic
 simplify (line 4) to each of its operands (the simpler expres-
sions) followed by an application of the appropriate rules. In fact, any
mathematical operation that involves a systematic examination of all parts
of an expression is most likely recursive.
Recursion can arise in computer algebra for another reason. Many
mathematical problems are solved by transforming the original probleminto another problem. If the new problem involves the same operation as
the original problem, then the process is recursive. For example, consider
the evaluation of the indeﬁnite integral/integraltext
xsin(x
2)dx. Using the substitu-
tionu=x2, the integral is transformed to
/integraldisplay
xsin(x2)dx=/integraldisplaysin(u)
2du.
2The interested reader may consult Cohen [ 24], Section 3.2, for the full version of the
Automatic
 simplify algorithm.
3.1. Recursive Definitions and Algorithms 83
Procedure Automatic
simplify(u);
Input
u: an algebraic expression;
Output
A simpliﬁed version of u;
Begin
1 ifuis an atomic expression then
2Return(u)
3 else
4 v:= the new expression formed by applying the
Automatic
simplifyprocedure to each operand of u;
5 w:= the new expression formed by applying the
appropriate simpliﬁcation rules to v;
6Return(w)
End
Figure 3.3. An outline of an MPL recursive simpliﬁcation procedure.
To evaluate the original integral, the Integral operator must choose the
proper substitution and apply itself to a new integral. Since the integration
is deﬁned in terms of another (simpler) integration, the process is recursive.
In Section 5.3we describe a recursive algorithm for a basic Integral operator
that can evaluate integrals similar to the one above.
Exercises
1. Explain why each of the operations can be viewed as a recursive process,
and give a termination condition for the recursion:
(a) The diﬀerentiation operation.
(b) The operation lim
x→af(x).
(c) Polynomial division.
(d) The expansion of products and powers of polynomials. For example,
i
(x+1)2+2J2(x+3)→x5+7x4+22x3+42x2+45x+27.
2. Describe (in words) a recursive algorithm that ﬁnds the set of symbols in
an expression.
84 3. Recursive Structure of Mathematical Expressions
3.2 Expression Structure and Trees3
Although Deﬁnition 3.1provides a descriptive language for the recursive
structure of an expression, it does not give a scheme for associating aunique structure with an expression. For example, what is the structure of
x+y+z?Isi tt h es u mo f x+yandz,o rt h es u mo f xandy+z,o re v e n
a sum with three operands x,y,a n dz? Since mathematical expressions
are the data objects in computer algebra programming, an understanding
of the relationships between their operators and operands is essential. In
this section we describe two views of expression structure. The ﬁrst, which
is called the conventional structure, corresponds to the structure in both
mathematics and conventional programming languages. The second view,which is called the simpliﬁed structure, corresponds to the structure after
automatic simpliﬁcation.
To simplify matters, we focus initially on the algebraic expressions de-
scribed in the following deﬁnition.
Definition 3.6. Analgebraicexpression uis one that satisﬁes one of the
following rules:
1.uis an integer.
2.uis a symbol.
3.uis a sum, product, power, diﬀerence, quotient, factorial, or function
form, where each operand of uis also an algebraic expression. /square
The algebraic expressions are the ones we manipulate using the trans-
formation rules of elementary algebra. Notice that the deﬁnition is recur-
sive because Rule (3) requires that the operands of a compound algebraicexpression are algebraic expressions.
Example 3.7. The expressions
2,1/2,sin(x),x∧2+c o s (x),f(x,y,z)
are algebraic expressions, while
[a,b,c],x+1=2,aandb
are not. /square
3In this section, to help clarify expression structure, we use ∗for the multiplication
operator and ∧for the power operator.
3.2. Expression Structure and Trees 85
Operator Classification
The following terminology for operators is used to describe expression struc-
ture.
Definition 3.8. Two operators in an algebraic expression uare atdiﬀerent
parentheses levels if one of the operators is inside a pair of matching
parentheses, while the other is not. On the other hand, when two operators
are not at diﬀerent levels, they are considered at the same parentheses
level.
Example 3.9. Ina∗(b+c), the operators ∗and + are at diﬀerent parentheses
levels. In a∗(b+c)/d, the operators ∗and/are at the same level, while
+ is at a diﬀerent level from either one of them. /square
Operators in an expression are also classiﬁed according to the number
of operands and the location of the operands relative to an operator. These
properties are described with the following terminology:
•Aunary postﬁx operator is one with one operand that immediately
precedes the operator. For example, in n!, the factorial operator is a
unary postﬁx operator.
•Aunary preﬁx operator is one with one operand that immediately
follows the operator. For example, in −x, the diﬀerence operator is
a unary preﬁx operator.
•Afunction preﬁx operator is an expression in function notation with
one or more operands. For example, in f(x,y), the function name f
is a function preﬁx operator with two operands xandy.
•Abinary inﬁx operator is one with two operands, one that immedi-
ately precedes the operator and the other that immediately followsthe operator. For example, in a+b, the + is a binary inﬁx operator.
Furthermore, with the conventional view of expressions (described
below), both + operators in a+b+care binary inﬁx operators. In
this view, the ﬁrst + has operands aandb, and the second + has
operandsa+bandc.
•Ann-ary inﬁx operator is one with two or more operands that are
adjacent to some occurrence of the operator at the same parentheses
level. For example, in the simpliﬁed view of algebraic expression
structure (described below), both + and ∗are n-ary inﬁx operators.
Int h i sv i e w , a+b+c+dis an n-ary sum with four operands a,b,c,
andd.
86 3. Recursive Structure of Mathematical Expressions
Conventional Structure of Algebraic Expressions
Theconventional structure of an expression is similar to the structure as-
sumed in both mathematics and conventional programming languages, and,
in some computer algebra languages, corresponds to the structure before
automatic simpliﬁcation. The following structural assumptions (Deﬁni-tion3.10) and precedence rules (Deﬁnition 3.11) describe the conventional
structure of an expression.
Definition 3.10. (Structuralassumptionsforconventionalalgebraic
expressions.) Letube an algebraic expression. The algebraic operators
inusatisfy the following structural assumptions:
1. The operators +and−are either unary preﬁx or binary inﬁx opera-
tors.
2. The operators ∗,/,a n d ∧are binary inﬁx operators.
3. The operator !is a unary postﬁx operator.
The relationship between operators and operands is deﬁned by the fol-
lowing operator precedence rules.
Definition 3.11. (Conventional precedence rules.) Letube an alge-
braic expression.
1. The relative precedence of operators in uat the same parentheses level
is given by the precedence hierarchy4
(highest level)
functionnames
!
∧
∗,/
+,−
(lowest level).
If one operator is below another in the table, that operator has lower
precedence. If two al gebraic operators in uare at the same level in
the table, the relative precedence is determined by the following rules:
(a) If the operators are +or−operators, ∗or/operators, or !
operators, then the operator to the right has lower precedence.
4Some authors assign unary + and −higher precedence than ∗and/.W e d o n o t
make this distinction here.
3.2. Expression Structure and Trees 87
(b) If the operators are ∧operators, then the operator to the left has
lower precedence.
2. For two operators at diﬀerent parentheses levels, the operator outside
a pair of parentheses has lower precedence than the operator inside
the parentheses.
When an expression is adjacent to two operators, it is an operand of
the operator with highest precedence.
Example 3.12. Inm∗x+b, the operator + has lower precedence than ∗
which implies the expression is equivalent to ( m∗x)+b.
Ina∗b∗c, both operators operate in a binary fashion and the ∗on the
right has lower precedence than the ∗on the left. From the conventional
viewpoint, this expression is equivalent to ( a∗b)∗c.
In2∗sin(x+ 1), the operator ∗has lowest precedence, the function
name sin is next, and the operator + has highest precedence.
Finally, in a∗b∧c∧d∗e, the operators in order of lowest to highest
precedence are: the ∗on the right, the ∗on the left, the ∧on the left,
and the ∧on the right. From a conventional viewpoint, this expression is
equivalent to ( a∗b∧(c∧d))∗e. /square
Expression Trees
The structure of an expression comprises the relationships between its op-
erators and operands. An expression tree is a diagram that displays this
structure. For example, the expression
c+d∗x∧2 (3.6)
is represented by the expression tree in Figure 3.4.
Each operator and atom in an expression is represented by a position or
nodein the tree. The contents of the nodes and the relationships between
the nodes are determined by the operator precedence rules. The operator
with lowest precedence in an expression appears at the top of the tree.
This top node is called (oddly enough) the root node of the tree. According
to the precedence rules, the operator + has lowest precedence in c+d∗
x∧2, and so appears at the root. This root operator is also called the
main operator of the expression, a designation that emphasizes that c+
d∗x∧2 is viewed as a sum with two operands candd∗x∧2. The lines
that emanate below an operator node connect the operator to each of its
operands, and the part of the tree that represents an operand is called a
branch orsub-tree . In this case, the ﬁrst operand of + is the symbol c,
which is represented by the left branch with a node containing c.T h er i g h t
88 3. Recursive Structure of Mathematical Expressions
❅
❅
❅
❅ 
  
 
❅
❅
 
 
xd+
c ∗
∧
2
Figure 3.4. The conventional expression tree for c+d∗x∧2.
branch, which represents the expression d∗x∧2, is constructed by applying
the above process (recursively) to this sub-expression. The main operatorof this branch is ∗, and the two branches correspond to the operands dand
x∧2. Continuing in this fashion, we construct the tree that represents the
structure of the expression
5.
Example 3.13. Figure 3.5(a) contains the expression tree for −a∗(b+c).
Notice that the operator −has lower precedence than ∗and therefore
appears at the root node of the tree.
Figure 3.5(b) contains the expression tree for Integral (sin(x),x). The
operator Integral , which has lowest precedence, appears at the root node
of the tree, and the two operands sin( x)a n dxare branches that emanate
from this node. In a similar way, the function name sin appears at the root
of the branch for sin( x).
Figure 3.5(c) contains the expression tree for 1 /(a∗x∗y).In the con-
ventional view, both ∗operators act in a binary fashion. /square
5In Mathematica, the operator TreeForm[u] displays the tree structure of an expres-
sion. However, the displayed structure corresponds to the simpliﬁed structure described
in Deﬁnition 3.14 and Deﬁnition 3.16.
In MuPAD, the operator prog::exprtree displays the tree structure. The con-
ventional structure is obtained with prog::exprtree(hold(u)) , while the simpli-
ﬁed structure (described in Deﬁnition 3.14 and Deﬁnition 3.16) is obtained with
prog::exprtree(u) . In MuPAD, the conventional structure is similar to the structure
described here with two modiﬁcations. First, both + operators and ∗operators are
represented as n-ary operators. Next, numerical fractions have a special form with the
operator DOM
RATat the root.
The current release of Maple (7) does not have an operator to display the tree. How-
ever, the tree structure can be obtained using the structure operators (see Figure 3.18
on page 106).
3.2. Expression Structure and Trees 89
❅
❅ 
  
 
❅
❅
−
b∗
+
ca
(a) A conventional expression tree for −a∗(b+c).
❅❅
  
sinIntegral
x
x
(b) A conventional expression tree for Integral (sin(x),x).
❅❅
  ❅❅
    ❅❅
/
y
a x∗∗ 1
(c) A conventional expression tree for 1 /(a∗x∗y).
Figure 3.5. Conventional expression trees.
90 3. Recursive Structure of Mathematical Expressions
Simplified Structure of Algebraic Expressions
Since mathematical expressions encountered as data objects in computer
algebra programs are in automatically simpliﬁed form, the structure of
these expressions is particularly important to us. This simpliﬁed structure(described below) simpliﬁes the programming process by eliminating ex-
traneous operators from an expression and by providing easier access to
its operands. The following structural assumptions (Deﬁnition 3.14)a n d
precedence rules (Deﬁnition 3.16) describe some properties of simpliﬁed ex-
pressions.
Definition 3.14. (Structural assumptions for simpliﬁed algebraic
expressions) Letube an automatically simpliﬁed algebraic expression.
The operators in usatisfy the following structural assumptions:
1. The operator +is an n-ary inﬁx operator with two or more operands
and none of its operands is a sum. In addition, at most one operandof+is an integer or fraction.
In the simpliﬁed view, the expression a+b+cis viewed as a sum with three
operands a,b,a n dcrather than the conventional view as a binary sum
with operands a+bandc(see Figure 3.6(a)). Furthermore, the expression
a+(b+c) is not in automatically simpliﬁed form because one of the operands
of the main operator + is also a sum. Indeed, the automatically simpliﬁed
form of this expression is a+b+c. Finally, Rule (1) implies that the unary
sum +xis not automatically simpliﬁed because a sum must have at least
two operands. The simpliﬁed form of + xisx.
2. The operator ∗is an n-ary inﬁx operator with two or more operands
and none of its operands is a product. In addition, at most oneoperand of ∗is an integer or fraction, and when an integer or fraction
is an operand of a product, it is the ﬁrst operand
6.
This rule implies the simpliﬁed form of a∗2∗(b∗c) is the n-ary product
2∗a∗b∗c.
3. The unary operator −and the binary operator −do not appear in
simpliﬁed expressions.
6In both Maple and Mathematica, an integer or fraction operand in a product is the
ﬁrst operand.
In MuPAD, however, an integer or fraction operand in a product is represented inter-
nally as the last operand even though the displayed form indicates it is the ﬁrst operand.Since some algorithms in later chapters assume an integer or fraction in a product is theﬁrst operand, the MuPAD implementations are modiﬁed to account for this diﬀerence.
3.2. Expression Structure and Trees 91
  ❅❅
  ❅❅
✟✟✟✟
❍❍❍❍
b a+
c + a b c+
conventional simpliﬁed
(a) Conventional and simpliﬁed structures for a+b+c.
  
  ❅❅
❅❅  
  ❅❅
❅❅
2a−
b∗
b∗+
a
−2
conventional simpliﬁed
(b) Expression trees for a−2∗band its simpliﬁed form a+(−2)∗b.
❅❅
❅❅
    
❅❅
  
✟✟✟✟
❍❍❍❍
✟✟✟✟
❍❍❍❍−
∗
x/
y 33 −1y x∗
fraction
conventional simpliﬁed
(c) Expression trees for −x∗y/3 and its simpliﬁed form ( −1/3)∗x∗y.
Figure 3.6. Conventional and simpliﬁed expression trees.
92 3. Recursive Structure of Mathematical Expressions
This rule implies the expression −xis not automatically simpliﬁed. The
simpliﬁed form of this expression is the product ( −1)∗x,w h e r et h e −sign
in the parentheses is not considered a unary operator, but instead is part
of the integer negative one. In a similar way, the automatically simpliﬁedform of the expression a−2∗bisa+(−2)∗b(see Figure 3.6(b)).
4. The binary operator /does not appear in simpliﬁed expressions.
Simpliﬁed quotients are represented using products, powers, and special
forms for fractions (described below). For example, the simpliﬁed form for
1/cisc
−1and the simpliﬁed form for c/d2isc∗d−2.
5. Numerical fractions satisfy the following:
(a)A quotient that represents a fraction c/d,w h e r ec/negationslash=0andd/negationslash=0
are integers is represented by an expression tree with operator
the symbolfraction ,ﬁ r s to p e r a n d c, and second operand d.
(b)A negative fraction has a negative numerator and positive de-
nominator.
This rule implies that the expression 1 /2 is not viewed as a quotient but
instead as an expression with operator fraction and operands 1 and 2. In
addition, the expression −1/2 has the operator fraction and operands −1
and 2.
6. The operator ∧is a binary operator. In addition, if u=v∧n,w h e r e
nis an integer, then vcannot be an integer, fraction, product, or
power.
This rules implies the following: ( a∗b)∧2 has the simpliﬁed form ( a∧2)∗
(b∧2); (x∧2)∧3 has the simpliﬁed form x∧6; and 3−1has the simpliﬁed
form the fraction 1 /3.
7. The operator !is a unary postﬁx operator whose operand is not a
non-negative integer.
This rule implies that the simpliﬁed form of 3! is 6.
Example 3.15. Consider the conventional expression −x∗y/3. Figure 3.6(c)
shows the expression trees for the conventional and simpliﬁed forms ofthis expression. Using Rules (3) and (4), the unary minus and quotient
operators are removed. Therefore, using the Rules (2), (5), and (6), the
simpliﬁed structure is (( −1)/3)∗x∗y,w h e r e ∗is an n-ary operator with
three operands, the −is part of the integer −1, and the fraction ( −1)/3
has main operator fraction . /square
3.2. Expression Structure and Trees 93
Definition 3.16. (Simpliﬁed precedence rules) Letube an automati-
cally simpliﬁed algebraic expression.
1. The relative precedence of operators in uat the same parentheses level
is given by the precedence hierarchy
(highest level)
functionnames
fraction
!
∧
∗
+
(lowestlevel)
If two !operators are at the same parentheses level, then the one to
the right has lower precedence. If two ∧operators are at the same
parentheses level, then one to the left has lower pr ecedence.
2. For operators at diﬀerent parentheses levels, operators outside a pair
of parentheses have lower precedence than operators inside the paren-
theses.
Because of the structural assumptions, the precedence rules for simpli-
ﬁed expressions are simpler than those for conventional expressions. For
example, since multiple occurrences of the + operator at the same paren-
theses level coalesce to a single operator in an expression tree, there is noneed to account for this situation in the precedence rules. Notice that the
fraction operator has higher precedence than ∗,∧, and ! so that a frac-
tion is isolated as an operand relative to these operators. This point is
illustrated in Figure 3.6(c).
Using the structural assumptions in Deﬁnition 3.14and the precedence
rules in Deﬁnition 3.16, the deﬁnition of an algebraic expression can be
modiﬁed in the following way.
Definition 3.17. An expression uis anautomatically simpliﬁedalge-
braic expression (ASAE) if it satisﬁes one of the following rules:
1.uis an integer.
2.uis a fraction c/dwherec/negationslash=0,d/negationslash=0are integers.
3.uis a symbol.
94 3. Recursive Structure of Mathematical Expressions
4.uis a sum, product, power, factorial, or function form, where each
operand of uis also an automatically simpliﬁed algebraic expression.
Although the structural assumptions and precedence rules describe
some important properties of automatically simpliﬁed expressions, they
are not by any means a complete description of these expressions. For
example, the structural assumptions do not describe all the ordering prop-
erties of operands in sums and products, the properties of powers or the
special rules involving the integers 0 and 1. Since a complete descriptionof automatically simpliﬁed expressions is quite involved, it is not included
here
7. At this point our intent is to give a description that is suﬃcient to
begin computer algebra programming. Additional structural rules can befound by experimentation with computer algebra software (see Exercise 3).
Most computer algebra systems use an internal form for automatically
simpliﬁed algebraic expressions that is similar to the one described here,although the displayed form may disguise the actual structure. We illus-
trate this point in Figure 3.7, which shows a Mathematica session together
with the simpliﬁed structure of a/b+c−d. The command TreeForm at
In[2] displays a representation of the expression tree. Observe that the dis-
played form of the simpliﬁed expression at Out[1] includes the quotient and
diﬀerence operators, even though the Mathematica internal tree structure
does not.
Since the simpliﬁed structure of an expression may not be apparent
from its displayed form, an operator may transform an expression in an
unexpected way. To illustrate this point, consider the Maple dialogue in
Figure 3.8that obtains the derivative of f(x)/g(x). Since the simpliﬁed
form of this expression is f(x)∗g(x)
(−1), the derivative is obtained with
the diﬀerentiation product and power rules rather than the quotient rule.
Similar results are obtained with both Mathematica and MuPAD.
Functions Transformations for Exponential Functions
and Powers in Automatic Simplification
In ordinary mathematical notation, the expressions exand exp(x)a r et w o
forms that are used to represent the exponential function. Some computer
algebra systems allow both representations for input but may use only
one form in automatically simpliﬁed expressions. In a similar way, a CAS
may allow both√
x(or sqrt(x)) andx1/2for the square root function, but
7For this description, consult Cohen [ 24], Chapter 3, where a complete description
is needed for an algorithm that transforms an algebraic expression to automaticallysimpliﬁed form.
3.2. Expression Structure and Trees 95
In[1]:= a/b+c−d
Out[1]=a
b+c−d
In[2]:= TreeForm[a/b+c−d]
Out[2] //TreeForm =
Plus[ | ,c ,| ]
Times[a ,| ]T i m e s [ −1,d]
Power[b ,−1]
Times
 Times✟✟✟✟✟✟✟✟❍❍❍❍❍❍❍❍
 
  
❡
❡
❡❡ 
 
  ❅
❅❅
❅
❅❅
 
  Plus
Power
−1−1a
bc
d
Figure 3.7. A Mathematica session with the simpliﬁed structure for the expres-
siona/b+c−d.
choose one internal simpliﬁed form for both. In MPL, we represent the
exponential function with the function form exp( x)a n dt h es q u a r er o o t
function with the power x1/2.InF i g u r e 3.9,w eg i v et h er e p r e s e n t a t i o n so f
these functions in Maple, Mathematica, and MuPAD.
96 3. Recursive Structure of Mathematical Expressions
> u := f(x)/g(x);
u:=f(x)
g(x)
> diff(u, x);
∂
∂xf(x)
g(x)−f(x)(∂
∂xg(x))
g(x)2
Figure 3.8. A Maple dialogue that shows that the derivative of f(x)/g(x)i s
obtained with the product rule and power rule.
expression
 MPL
 Maple
 Mathematica
 MuPAD
exp(x)
exp(x)
exp(x)
 Ex
exp(x)
ex
exp(x)
exp(1)x
Ex
exp(x)
√
x
x1/2
x1/2
x1/2
x1/2
x1/2
x1/2
x1/2
x1/2
x1/2
Figure 3.9. Simpliﬁed structure of the exponential and power functions in MPL,
Maple, Mathematica, and MuPAD.
Simplified Structure for Non-Algebraic Expressions
We describe brieﬂy some issues related to the structure of expressions that
include relational operators, logical operators, lists, and sets. For these
expressions, the internal forms are more involved and, in some cases, varyfrom system to system.
Relationalexpressions. For expressions with one relational operator
(=,<, etc.), most systems use a binary structure with relative precedence
levels for relational operators below the levels for algebraic operators. Fig-
ure3.10gives the simpliﬁed structure for the expression for x+1<2∗x.
Maple, Mathematica, and MuPAD use a similar internal form for this ex-
pression.
Both the Mathematica and MuPAD systems provide for more involved
relational expressions that contain two or more relational operators. For ex-
ample, in Figure 3.11we show the internal form for the expression x<y<z
in these systems. Observe that Mathematica represents the expression us-
ing an n-ary form, while MuPAD uses a nested binary form.
3.2. Expression Structure and Trees 97
 
 
  ❅
❅
❅❅
❅
❅
 
 ❅
❅ 
 
2 x+
x∗<
1
Figure 3.10. The MPL simpliﬁed structure for the expression x+1<2∗x.
Figure 3.12gives the internal forms in Mathematica and MuPAD for
the expression x≤y<z , which has two diﬀerent relational operators.
Observe that Mathematica represents the expression using a form thatincludes relational operators as operands of the main operator Inequality ,
while MuPAD represents this expression using a nested binary form.
Finally, in both the Maple and MuPAD systems, expressions with >
and≥are converted by automatic simpliﬁcation to equivalent expressions
with<and≤. For example, in both of these systems, a>b is simpliﬁed
tob<a.
Logical expressions. The relative precedence levels of the logical
operators is
(lowest)
not
and
or
(highest),
and the logical operators have lower precedence than relational operators.
Although logical expressions are used primarily as Boolean tests in both
decision and looping structures, some computer algebra languages allow
logical expressions as program statements or data objects. For example,the expression
pornotqandr
is a mathematical expression with structure shown in Figure 3.13(a).
98 3. Recursive Structure of Mathematical Expressions
 
 
  ❅
❅
❅❅
Less
xyz
(a) Mathematica
❅
❅
❅❅ 
 
  
 
 
  ❚
❚
❚❚
less
less
xyz
(b) MuPAD
Figure 3.11. The internal form for x<y<z in Mathematica and MuPAD.
(Implementation: Mathematica (nb),MuPAD(mnb).)
InF i g u r e 3.13(b), we show the structure of an expression with logical,
relational, and algebraic operators. Maple, Mathematica, and MuPADallow expressions to be used in this way
8.
In Mathematica and MuPAD, logical expressions have simpliﬁed forms
in which both the andandoroperators are n-ary inﬁx operators with
8In Maple, there is one curious exception to this statement. Suppose x,y,a n d
zare unassigned symbols. Although, in this system, the expression x<y and y<z
is not changed by automatic simpliﬁcation, the similar expression x<y and y =zis
transformed to false . This occurs since, in this context, y=zevaluates to false because
yand zare distinct symbols. On the other hand, the expression y=zby itself remains
unchanged by automatic simpliﬁcation.
3.2. Expression Structure and Trees 99
✁
✁
✁✁❜❜❜❜❜❜L
L
LL❅
❅
❅❅✧✧✧✧✧✧
Inequality
LessEqual Lessxy z
(a) Mathematica
❅
❅
❅❅ 
 
  
 
 
  
❚
❚
❚❚
leequal
less
xyz
(b) MuPAD
Figure 3.12. The internal form for the expression x≤y<zin Mathematica and
MuPAD. (Implementation: Mathematica (nb),MuPAD(mnb).)
operands of a diﬀerent type. (For example, the operator andcannot have
an operand that is also an and.) In Figure 3.14(a),(b), we give Mathemat-
ica and MuPAD representations of the simpliﬁed form of the expression
worxandyornotz (3.7)
which has two oroperators at the same level.
On the other hand, in the Maple system, the simpliﬁed forms for and
andorremain as binary operators. The internal form for Expression ( 3.7)
in this system is shown in Figure 3.14(c).
100 3. Recursive Structure of Mathematical Expressions
. 
  
 
  
❅
❅❅
❅
❅❅and
notp
qror
(a) The MPL simpliﬁed structure for the expression pornotqandr.
 
  
 
❅
❅
❅
❅
❅
❅
❅❅
❅
❅
 
 
 
 
  
and
<
x + y
xy1<
(b) The MPL simpliﬁed structure for the expression x<yandx+y<1.
Figure 3.13. MPL structures for logical expressions.
Sets and Lists. In MPL, both sets and lists are viewed as expressions
with main operator setorlistalong with operands that are the expressions
in the set or the list. In addition, the expression tree for the empty set ∅or
empty list [ ] is the tree with a single node setorlist.F i g u r e s 3.15(a),(b)
illustrate the tree structures for expressions with sets and lists. Both Maple
and MuPAD represent sets and lists in this way. Mathematica, which uses
the brace notation {and}f o rb o t hs e t sa n dl i s t s ,u s e st h es y m b o l Listas
the main operator for these expressions
3.2. Expression Structure and Trees 101
Or
✔
✔✔L
LL
◗◗◗◗◗◗
##
###
Not And
zy xw
(a) Mathematica
y
❚
❚❚
✡
✡✡
◗◗◗◗◗◗
 ✚✚✚✚✚
and
xnot
zor
w
(b) MuPAD
or
or✪
✪✪❅
❅❅

✜
✜✜
❚
❚❚
✡
✡✡
xand
ynot
w z
(c) Maple
Figure 3.14. The simpliﬁed structure of the expression worxandyor not z
in Mathematica, MuPAD, and Maple.
102 3. Recursive Structure of Mathematical Expressions
✏✏✏✏✏
✁✁❆❆PPPPPset
ab c d
(a) The MPL simpliﬁed structure for the set {a,b,c,d }.
 
 ❅
❅
❅
❅ 
 list
b ac +
(b) The MPL simpliﬁed structure for the list[ a+b,c].
Figure 3.15. Expression tress for a set and a list.
In some CAS languages, the set operators ( ∪,∩,∼), can have symbols
(instead of sets) as operands and these expressions can act as data objects.When used in this way, these expressions have a simpliﬁed form where
∪and∩are n-ary operators with operands of a diﬀerent type, and ∼is
a binary operator. (For example, in simpliﬁed form, ∪cannot have an
operand that is also a ∪.) Both Maple and MuPAD allow set expressions
to be used in this way, although the operator precedence levels are not
the same. In Figure 3.16, we give the relative precedence levels of these
MPL
∩
∼
∪Maple
intersect
union,minusMuPAD
intersect
minus
union
Figure 3.16. The relative precedence of set operations in MPL, Maple, and
MuPAD.
3.2. Expression Structure and Trees 103
operators in MPL, Maple, and MuPAD. Observe that in both MPL and
MuPAD the operators are at three diﬀerent levels, while in Maple union
andminus are at the same level.
InF i g u r e 3.17, we give the simpliﬁed representations in Maple and Mu-
PAD for the expression
A∪B∪C∩D∼E.
C
 D✪
✪✪❅
❅❅
✜
✜✜
❧
❧❧
✪✪❡❡E∼
A∪
∩B
(a) Maple
C
 D✜
✜✜
❧
❧❧
❡❡
✔✔❏❏✪✪AB
E ∩∪
∼
(b) MuPAD
Figure 3.17. The structure of the expression A∪B∪C∩D∼Ein Maple and
MuPAD.
104 3. Recursive Structure of Mathematical Expressions
Observe that the meaning of the expression in Maple is
(A∪B∪(C∩D))∼E,
while the meaning in MuPAD is
A∪B∪((C∩D)∼E).
Primitive Operations on Simplified Mathematical Expressions
In order to analyze and manipulate a mathematical expression, we must
access its operators and operands. MPL uses three primitive operators toperform these tasks.
Definition 3.18. The operator
Kind(u)
is deﬁned by the following rules:
1. Ifuis an atomic expression, Kind (u)returns the type of expression
(e.g.,integer ,real,o rsymbol ).
2. Ifui sac o m p o u n de x p r e s s i o n ,K i n d (u)returns the operator at the
root of the expression tree.
Example 3.19.
Kind(x)→symbol,
Kind(3)→integer,
Kind(2.1)→real,
Kind(π)→symbol,
Kind(m∗x+b)→+,
Kind((a+b)∗sin(x∧2))→∗,
Kind((a/b)→∗,
Kind(2/3)→fraction,
Kind(sin(x))→sin,
Kind(a=b)→=,
Kind({a,b,c,d })→set,
Kind(xandy)→and,
Kind(x−x+2 ) →integer.
3.2. Expression Structure and Trees 105
In the last example, the operand is simpliﬁed by automatic simpliﬁcation to
the integer 2. (Implementation: Maple (mws), Mathematica (nb),MuPAD
(mnb).) /square
Definition 3.20. Ifuis a compound expression, the operator
Number
 of
operands (u)
returns the number of operands of the main operator of u.I fuis not a
compound expression, then Number
 of
operands returns the global symbol
Undeﬁned .
Example 3.21.
Number
 of
operands (m∗x+b)→2,
Number
 of
operands (f(x,y))→2,
Number
 of
operands ({a,b,c,d })→4,
Number
 of
operands (n!)→1,
Number
 of
operands (x)→Undeﬁned .
In the last example, the input expression xis not a compound expression.
(Implementation: Maple (mws), Mathematica (nb),MuPAD (mnb).) /square
Definition 3.22. Ifuis a compound expression, the operator
Operand (u,i)
returns the ithoperand of u.I fuis not a compound expression or u
does not have an ithoperand, then Operand returns the global symbol
Undeﬁned .
Example 3.23.
Operand (m∗x+b,2)→b,
Operand (x∧2,1)→x,
Operand (Operand (m∗x+b,1),2)→x,
Operand ({a,b,c,d },2)→b,
Operand (x−x,1)→Undeﬁned ,
Operand (2/(−3),2)→3.
The last two examples are based on the simpliﬁed form of the expression.
(Implementation: Maple (mws), Mathematica (nb),MuPAD (mnb).)
106 3. Recursive Structure of Mathematical Expressions
MPL
 Maple
 Mathematica
 MuPAD
Kind (u)
 whattype(u)
 Head(u)
 type(u)
and
 and
op(0,u)
 op(u,0)
for function
 for undeﬁned
names
 function names
Operand (u,i)
 op(i,u)
 Part[u,i]
 op(u,i)
and Numerator[u]
and Denominator[u]
for fractions
Number
 of
operands (u)
 nops(u)
 Length[u]
 nops(u)
Construct (f,L)
 see Figure 3.19
 Apply[f,L]
 see Figure 3.20
Figure 3.18. The primitive MPL structural operators in Maple, Mathematica,
and MuPAD.
Keep in mind, because automatic simpliﬁcation in a computer algebra
system may apply the commutative law to reorder the operands in a sumor product, the Operand operator may obtain an unexpected result. For
example, if b+ais reordered to a+b,w eo b t a i n
Operand (b+a,2)→b./square
The operators Kind,Number
of
operands ,a n d Operand are the three
basic operations that are used to analyze and manipulate mathematical
expressions, and most computer algebra systems have versions of these
operators (see Figure 3.18).
Construction of Expressions
In some instances, we need to construct an expression with a given operator
and list of operands. The MPL operator Construct is used for this purpose.
Definition 3.24. Letfbe an operator ( +,∗,=, etc.) or a symbol, and let
L=[a,b,...,c ]be a list of expressions. The operator
Construct (f,L)
returns an expression with main operator fand operands a,b,...,c .
Example 3.25.
Construct (” + ”,[a,b,c])→a+b+c,
Construct (”∗”,[a+b,c+d,e+f])→(a+b)∗(c+d)∗(e+f),
Construct (g,[a,b,c])→g(a,b,c),
(Implementation: Maple (mws), Mathematica (nb),MuPAD (mnb).) /square
3.2. Expression Structure and Trees 107
Construct := proc(f,L)
local g,s;
if f = ‘!‘ then RETURN(op(L)!);elif member(f,{‘and‘,‘or‘}) then RETURN(convert(L,f))
elif f = ‘not‘ then RETURN(not op(L))
elif f = set then RETURN({op(L)})elif f = list then RETURN(L)
else s := subsop(0=f,g(op(L))); RETURN(eval(s))
fi
end:
Figure 3.19. A Maple procedure to implement MPL’s Construct operator. (Im-
plementation: Maple(txt).)
Construct := proc(f,L)
begin
if f = _divide then return(op(L,1)/op(L,2))
elif f = _subtract of f = _negate then return(op(L,1)-op(L,2))elif f = DOM_SET then return({op(L)})
elif f = DOM_LIST then return(L)
else return(f(op(L)))end_if
end_proc:
Figure 3.20. A MuPAD procedure to implement MPL’s Construct operator.
(Implementation: MuPAD(txt).)
While Mathematica has an operator that constructs expressions (see
Figure 3.18), Maple and MuPAD do not. However, in both of these lan-
guages, the operation can be simulated with a procedure (see Figures 3.19
and3.20).
Exercises
1. Experiment with a CAS to determine the simpliﬁed structure of the ex-
pressions in Figure 3.6. Are the structures the same as those shown in the
ﬁgure?
108 3. Recursive Structure of Mathematical Expressions
2. For each of the following, give the conventional and simpliﬁed structures
of the expression. In addition, for each of the expressions, compare the
simpliﬁed structure based on the rules in thetext to the simpliﬁed internal
structure in a CAS.
(a)a/b−c/d.
(b) (x∧a)∧3.
(c) (x∧2)∧(1/2).
(d)3
2∗a∗(x−1).
(e) (−2∗x)∧(−3).
(f) ((x−y)+z)+w.
(g) ((x−y)∗y/2)∧2.
(h)x∧2−1
x−1.
(i)1
x∧y.
(j)−x∗(a/b)
c.
(k)2
a+b∗3
c+d.
(l)x∧2+cos(1 /x−2).
(m)x=−b+(b∧2−4∗a∗c)∧(1/2)
2∗a.
3. Experimentwith a CASto determinesome additional structuralrules that
describe automatically simpliﬁed algebraic expressions. For example:
(a) Can a sum or product have two identical operands?
(b) How are operands in sums and products combined?
(c) Can the ﬁrst operand of the power operator ∧also be a power?
(d) What are the special rules that involve 0 and 1? For example, can a
0 or 1 be an operand of a sum, product, power, or factorial?
Exercise1on page55is helpful for this exercise. For further discussion of
structural assumptions for automatically simpliﬁed algebraic expressions,
see Cohen [ 24], Chapter 3.
3.3 Structure-Based Operators
In this section we describe four operators for which the operations are based
only on the simpliﬁed structure of an expression. First, we introduce the
terminology that is used in the deﬁnitions of these operators.
3.3. Structure-Based Operators 109
 
 
❍❍❍❍
✟✟✟✟
❍❍❍❍
 
 ❅
❅
sin
2 c∧ b 1+
a∗
Figure 3.21. A simpliﬁed expression tree for sin( a)∗(1+b+c∧2).
Complete Sub-Expressions
Definition 3.26. Letube an automatically simpliﬁed expression. A com-
plete sub-expression ofuis either the expression uitself or an operand
of some operator in u.
In terms of expression trees, the complete sub-expressions of uare either
the expression tree for uor one of its sub-trees.
Example 3.27. Consider the expression
sin(a)∗(1 +b+c∧2), (3.8)
which has the expression tree shown Figure 3.21. This expression contains
the following complete sub-expressions:
sin(a)∗(1 +b+c∧2),sin(a),a ,
1+b+c∧2,1,b ,c ∧2,c ,2.
There are some parts of an expression that are sub-expressions in a math-
ematical sense but are not complete sub-expressions. For example in Ex-
pression ( 3.8), 1 +bis not a complete sub-expression since it is not the
operand of an operator. /square
110 3. Recursive Structure of Mathematical Expressions
TheFree
 ofOperator
TheFree
ofoperator determines if an expression uis free of an expression t
(or does not contain t).
Definition 3.28. Letuandt(for target) be mathematical expressions. The
operator
Free
of(u,t)
returnsfalse whentis identical to some complete sub-expression of uand
otherwise returns true.
Example 3.29.
Free
of(a+b, b)→false,
Free
of(a+b, c)→true,
Free
of((a+b)∗c, a+b)→false,
Free
of(sin(x)+2∗x,sin(x))→false,
Free
of((a+b+c)∗d, a+b)→true, (3.9)
Free
of((y+2∗x−y)/x, x)→true, (3.10)
Free
of((x∗y)2,x∗y)→true. (3.11)
In Statement ( 3.9),a+bis not a complete sub-expression of ( a+b+c)∗dand
so the operator returns true. In Statement ( 3.10), automatic simpliﬁcation
simpliﬁes the ﬁrst operand to 2 and so the expression no longer contains anx. In a similar way, in Statement ( 3.11) automatic simpliﬁcation transforms
(x∗y)
2tox2∗y2which gives the output true. (Implementation: Maple
(mws), Mathematica (nb),MuPAD (mnb).) /square
To perform Free
of(u,t), each complete sub-expression of uis checked
to determine if it is structurally identical to the target t. This is easily done
using a recursive search through the expression tree. Brieﬂy, the process
goes as follows: ﬁrst compare utot,a n di fu=tthe search is done and
falseis returned. If u/negationslash=tanduis an atom, there is nowhere else to
search and so trueis returned. On the other hand, if u/negationslash=tanduis
a compound expression, the search continues by recursively applying theprocess just described to each of the (simpler) operands of u.C o n t i n u i n g
in this fashion, we compare tto each of the complete sub-expressions of u.
For example, if u=3∗x+y∗(z+ 2), the scheme compares a target tto
the complete sub-expressions of uin the following order:
3∗x+y∗(z+2 ),3∗x,3,x ,y ∗(z+2 ),y ,z +2,z ,2.
3.3. Structure-Based Operators 111
MPL
 Maple
 Mathematica
 MuPAD
Free
of(u,t)
 not(has(u,t))
 FreeQ[u,x]
 not(has(u,t))
Substitute (u,t=r)
 subs(t=r,u)
 ReplaceAll [u,t->r]
 subs(u,t=r)
or
u /.t ->r
Sequential
 substitute
(u,[t1=r1,t2=r2])
subs(t1=r1,
t2=r2,u)
u/ .t 1->r1
/. t 2->r2
subs(u,t1=r1,
t2=r2)
Concurrent
 substitute
(u,{t1=r1,t2=r2})
subs([t1=r1,
t2=r2],u)
u/ .{t1->r1,
t2->r2}
subs(u,[t1=r1,
t2=r2])
Figure 3.22. Structural operators in Maple, Mathematica, and MuPAD that
correspond most closely to MPL’s structural operators.
An MPL procedure for the Free
ofoperator is given in Section 5.2.A n
operator similar to Free
ofis available in most computer algebra systems
(see Figure 3.22).
TheSubstitute Operator
Substitution is one of the essential operations used to manipulate and sim-
plify mathematical expressions. The Substitute operator performs a par-
ticularly simple form of substitution, called structural substitution ,t h a ti s
based solely on the tree structure of an expression.
Definition 3.30. Letu,t,a n drbe mathematical expressions. The struc-
tural substitution operator has the form
Substitute (u, t=r).
It forms a new expression with each occurrence of the target expression
tinureplaced by the replacement expression r. The substitution occurs
whenever tis structurally identical to a complete sub-expression of u.
Keep in mind that Substitute does not change u, but instead creates
an entirely new expression. Some examples of the use of the operator are
given in the MPL dialogue in Figure 3.23.
The statements at <1>,<2>,a n d<3>illustrate that uis not changed
by the substitution operation. In <6>, the substitution does not occur
sincea+bis not a complete sub-expression of a+b+c. However, in <7>,
we obtain the substitution intended in <6>by modifying the form of the
substitution.
Like the Free
ofoperator, the Substitute operator searches an expres-
sionuin a recursive manner and compares each complete sub-expression
112 3. Recursive Structure of Mathematical Expressions
<1>u:=a+b;
→ u:=a+b
<2>v:=Substitute (u, b=x);
→ v:=a+x
<3>u / v;
→a+b
a+x
<4>Substitute (1/a+a, a=x);
→1
x+x
<5>Substitute ((a+b)2+1,a+b=x);
→ x2+1
<6>Substitute (a+b+c, a+b=x);
→ a+b+c
<7>Substitute (a+b+c, a=x−b);
→ x+c
Figure 3.23. AnMPLdialoguethatillustratestheuseofthe Substitute operator.
(Implementation: Maple(mws),Mathematica (nb),MuPAD(mnb).)
ofuto the target t.( S e e E x e r c i s e 10on page 195for an MPL proce-
dure for the operator.) Most computer algebra systems have a form of the
Substitute operator (see Figure 3.22).
Substitution and Evaluation
In both the Maple and MuPAD systems, structural substitution may re-
turn an expression with an operator in unevaluated form. This point isillustrated in the Maple dialogue in Figure 3.24, which gives a sequence of
statements to verify the solution of a diﬀerential equation. At the ﬁrst
prompt, we assign a diﬀerential equation to w, and at the second prompt,
substitute a speciﬁc function for y(x). Notice that the diﬀerentiation op-
erator in the second display has not been evaluated. At the third prompt,
we force this evaluation by applying Maple’s evaloperator to the out-
put of the subsoperator. The MuPAD system also requires this forced
evaluation.
3.3. Structure-Based Operators 113
> w := diff(y(x),x) + 2*y(x)=5*sin(x);
w:=W∂
∂xy(x)}
+2y(x)=5sin( x)
> subs(y(x) = -cos(x)+2*sin(x)+exp(-2*x),w);
W∂
∂x(−cos(x)+2sin( x)+e(−2x))}
−2cos(x)+4sin( x)+2e(−2x)=5s i n( x)
> eval(subs(y(x) = -cos(x)+2*sin(x)+exp(-2*x),w));
5sin(x)=5s i n( x)
Figure 3.24. AMapledialoguethatveriﬁesthesolutionofadiﬀerentialequation.
(Implementation: Maple(mws),MuPAD(mnb).)
Although the Mathematica system does not, in general, require a forced
evaluation after substitution, the substitution of a speciﬁc function for an
undeﬁned function in a derivative requires a special form. This point is
illustrated in the Mathematica dialogue in Figure 3.25.A t In[1],w ea s -
sign a diﬀerential equation to w,a n da t In[2],u s et h e ReplaceAll op-
erator to substitute a speciﬁc function in the diﬀerential equation. No-tice that the substitution has not occurred in the derivative term y
/prime[x].
The issue here is that Mathematica represents y[x]with the internal form
Derivative[1][y][x] which does not contain the function form y[x].T o
obtain the substitution, it is necessary to represent the speciﬁc function in
a form that Mathematica calls a pure function :
Function [x,−Cos[x]+2∗Sin[x]+Exp[−2∗x]],
and substitute this expression for the function name y. We have performed
this substitution at In[3],a n dt h e na t In[4], veriﬁed the solution of the
diﬀerential equation by using the Expand operator to simplify the left side
of the previous equation9.
9The Expand operator in In[4] is not required in either Maple or MuPAD. In both
of these systems, automatic simpliﬁcation obtains the distributive transformation
2( e x p ( −2x)−cos(x)+2s i n ( x))→2e x p ( −2x)−2c o s (x)+4s i n ( x).
This transformation is not obtained by automatic simpliﬁcation in Mathematica.
114 3. Recursive Structure of Mathematical Expressions
In[1]:= w=D[y[x],x]+2∗y[x]= = 5∗Sin[x]
Out[1]=2y[x]+y/prime[x]==5Sin[x]
In[2]:= ReplaceAll [w,y[x]→− Cos[x]+2∗Sin[x]+Exp[−2∗x]]
Out[2]=2(e−2x−Cos[x]+2 ∗Sin[x])+y/prime[x]==5Sin[x]
In[3]:= z=ReplaceAll [w,y→Function[x,−Cos[x]+2∗Sin[x]+Exp[−2∗x]]]
Out[3]= −2e−2x+2Cos[x]+Sin[x]+2(e−2x−Cos[x]+2 ∗Sin[x])==5Sin[x]
In[4]:= Expand[Part[z,1]]
Out[4]=5Sin[x]
Figure 3.25. A Mathematica dialogue that veriﬁes the solution of a diﬀerential
equation. (Implementation: Mathematica (nb).)
Multiple Substitution
Amultiple structural substitution is one in which a collection of structural
substitutions is applied to an expression with a single operation. Since
the individual substitutions may not be independent (i.e., one substitution
may aﬀect the action of another one), both the order of the substitutionsand the mechanics of the process may aﬀect the result. We describe below
two models for multiple substitution, sequential substitution andconcurrent
substitution .
Definition 3.31. Letube an expression and let Lbe a list of equations
L=[t1=r1,t2=r2,...,t n=rn]
where the targets tiare distinct. The sequentialstructuralsubstitution
operator has the form
Sequential
 substitute (u,L).
The operator returns the expression unthat is deﬁned by the sequence of
structural substitutions
u1:=Substitute (u, t1=r1);
3.3. Structure-Based Operators 115
u2:=Substitute (u1,t2=r2);
...
un:=Substitute (un−1,tn=rn);
Example 3.32.
Sequential
 substitute (x+y,[x=a+1,y=b+2 ] ) →a+b+3,
Sequential
 substitute (x+y,[x=a+1,a=b+2 ] ) →b+3+y,
Sequential
 substitute (f(x)=a∗x+b,[f(x)=2,x=3 ] )
→2=3 ∗a+b, (3.12)
Sequential
 substitute (f(x)=a∗x+b,[x=3,f(x)=2 ] )
→f(3) = 3 ∗a+b. (3.13)
The operations ( 3.12)a n d( 3.13) show that sequential substitution is de-
pendent on the order of the substitutions. (Implementation: Maple (mws),
Mathematica (nb),MuPAD (mnb).) /square
Example 3.33. Consider the three polynomials
u(x)=x2+x+2,v(x)=x2+3∗x−7,w (x)=x2−5∗x+4.
InF i g u r e 3.26we give an MPL dialogue that obtains the functional com-
positionsu(v(w(x))) andu(w(v(x))). Since the composition operation is a
not commutative, we use sequential substitution to determine the order of
the compositions. /square
Definition 3.34. Letube an expression and let Sbe the set of equations
S={t1=r1,t2=r2,...,t n=rn},
where the targets t1,t2,...,t nare distinct. The concurrent structural sub-
stitution operator has the form
Concurrent
 substitute (u,S).
The operator returns a new expression deﬁned in the following way: recur-
sively search through the expression tree of uand compare each complete
sub-expression vto each of the (distinct) targets t1,t2,...,t n.I fvis iden-
tical to some ti, substitute the corresponding replacement riforv.
Since each complete sub-expression of uis identical to at most one
target, the order of the substitutions is not signiﬁcant, and so concurrent
substitution is deﬁned in terms of a set Srather than a list.
116 3. Recursive Structure of Mathematical Expressions
<1>u:=x2+x+2;
→ u:=x2+x+2
<2>v:=x2+3∗x−7;
→ v:=x2+3∗x−7;
<3>w:=x2−5∗x+4;
→ w:=x2−5x+4
<4>Algebraic
expand(Sequential
substitute(u,[x=v,x=w]));
→ x8−20x7+172x6−830x5+2439 x4−4390x3+4573 x2−2365x+464
<5>Algebraic
expand(Sequential
substitute(u,[x=w,x=v]));
→ x8+12x7+16x6−234x5−407x4+2202 x3+1479 x2−10089x+7834
Figure 3.26. An MPL dialogue that obtains a composition of polynomials us-
ing sequential substitution. (Implementation: Maple(mws),Mathematica (nb),
MuPAD(mnb).)
Example 3.35.
Concurrent
 substitute ((a+b)∗x,{a+b=x+c, x=d})→(x+c)∗d.
In this case, the complete sub-expression a+bis replaced by x+cand the
complete sub-expression xis replaced by d. Notice since the replacement
x+cis not part of the original expression, its xis not replaced by d.If
this additional substitution is intended, it is obtained with
Sequential
 substitute ((a+b)∗x,[a+b=x+c, x=d])→(d+c)∗d.
Another example is
Concurrent
 substitute (f(x)=a∗x+b,{x=3,f(x)=2})→2=3 ∗a+b.
In this case, the substitution x= 3 does not aﬀect the substitution f(x)=2
as it does with sequential substitution. (Compare this with Expression
(3.13) where the order of the substitutions aﬀects the result). (Implemen-
tation: Maple (mws), Mathematica (nb),MuPAD (mnb).) /square
3.3. Structure-Based Operators 117
Most computer algebra systems allow some form of multiple structural
substitution (see Figure 3.22). In Exercise 10on page 195we describe MPL
procedures for these operators.
Since structural substitution is obtained by simply comparing a tar-
get expression to the complete sub-expressions of an expression, it cannot
obtain all substitutions which occur in symbolic calculations. For more
information about algorithms for general substitution operations basedon polynomial division, the reader may consult Cohen [ 24], Sections 4.1
and 6.2.
Exercises
1. For each of the following, give the set of complete sub-expressions of the
automatically simpliﬁed form of the expression:
(a)a∗b/c.
(b) (a+b)+(c−d).
(c) 1/(2∗x).
(d) ((x−y)∗y/2)2.
(e)x=−b+(b2−4∗a∗c)1/2
2∗a.
2. (a) Explain why the operation Free
of(a∗(b/c),b / c)r e t ur n s true.
(b) Explore the capacity of the Free
ofoperator in a CAS (see Fig-
ure3.22). Does the operator have the same capacity as the Free
of
operator in the text?
(c) One extension of the Free
ofoperator is to allow a target to be a
function name or an algebraic operator. Experiment with a CAS tosee if theFree
ofoperator in that system has this capability.
3. (a) Explore the capacity of the substitution operator in a CAS (see Fig-
ure3.22). Does the operator have the same capacity as the Substitute
operator in the text?
(b) One extension of the Substitute operator is to allow a target to be an
algebraic operator or a function name. For example, in this case
Substitute (a+b,”+”=” ∗”)→a∗b.
Can a CAS do this with its substitution operator?
(c) Perform each of the following substitutions with a single application
of theSubstitute operator. (In each case, it is necessary to ﬁnd a
“clever” substitution.)
i. Replace a∗bbyxina∗b∗cto get x∗c.
ii. Replace u+1by xin (u+1)2+u+1toget x2+x.
iii. Replace a+bby 1 in a∗(a+b)+bto get 1.
118 3. Recursive Structure of Mathematical Expressions
(d) Is it possible to replace all occurrences of the tan function in an
expression with its representation in terms of sin and cos with a sin-
gle application of the Substitute operator? For example, is it possi-
ble to obtain the transformation tan( x)+tan( y)→sin(x)/cos(x)+
sin(y)/cos(y) with a single substitution? (Don’t use a multiple sub-
stitution here.)
4. Can theSolveoperator in a CAS solve an equation for a complete sub-
expression? Canthe Solveoperatorsolveanequationforanexpressionthat
is not acomplete sub-expression? InMaple use solve, inMathematica use
Solve,a n di nM uP A Dus e solve.
5. Evaluate each of the following:
(a)Sequential
substitute(x∗(x+y),[x=2,x+y=3 ] ).
(b)Concurrent
substitute(x∗(x+y),{x=2,x+y=3}).
(c)Sequential
substitute(x+y2,[x=y, y=x]).
(d)Concurrent
substitute(x+y2,{x=y, y=x}).
(e)Sequential
substitute(a+b+c,[a=b,b=c,c=a]).
(f)Concurrent
substitute(a+b+c,{a=b,b=c, c=a}).
6. (a) Let ube an algebraic expression. Give a sequence of statements
that gives a new expression with each occurrence of xreplaced by y
and each occurrence of yreplaced by x. For example, x2+2∗yis
transformed to y2+2∗x. (Don’t use a multiple substitution here.)
(b) Is it possible to do the operation in part (a) with a single statement
that involves a multiple substitution?
7. Let ube a mathematical expression and suppose t1,r1,t2,r2are distinct
symbols. Prove or disprove:
Sequential
substitute(u,[t1=r1,t2=r2]) =
Sequential
substitute(u,[t2=r2,t1=r1]).
Further Reading
3.1Recursive Deﬁnitions and Algorithms. Recursion for algorithms is
discussedinMaurerandRalston[ 65]. Aninterestingpopularaccountofrecursion
is found in Hofstadter [ 48].
3.2Expression Trees and Primitive Operations. Expression trees in a
conventionalprogrammingcontextarediscussedinmostbooksondatastructures
andalgorithms. Forexample,seeWeiss[ 98]. ExpressiontreesintheMathematica
system are discussed in Wolfram [ 102].
4
Elementary Mathematical
Algorithms
In this chapter we extend the concept of a mathematical algorithm to in-
clude function and procedure deﬁnitions, decision structures, and iterationstructures. In Section 4.1we discuss the general concept of a mathematical
algorithm and examine some properties of mathematical operators that are
used in an algorithm. In Section 4.2we describe the basic programming
structures that are used in MPL and give examples of procedures that
use these structures. Finally, in the case study in Section 4.3we describe a
more involved algorithm that ﬁnds the solution of some ﬁrst order ordinary
diﬀerential equations.
4.1 Mathematical Algorithms
Broadly speaking, a mathematical algorithm is a step by step process for
solving a mathematical problem that is suitable for computer implemen-tation. Although this deﬁnition includes much of what is found in math-
ematics texts, it is too broad to be useful in practice. We are primarily
interested in those algorithms that can be expressed in terms of a computer
program using the operators and programming structures available in CAS
languages.
119
120 4. Elementary Mathematical Algorithms
Properties of an Algorithm
Computer scientists are quite explicit about the properties a process must
have to be called an algorithm. Ideally, a mathematical algorithm should
have the following properties.
1.Each step in the algorithm is precisely deﬁned.
2.Each step in the algorithm is eﬀective which means it is suﬃciently
basic so that it can be performed with ﬁnite computational resources(time and memory).
For example, the operation of multiplying two rational numbers is
eﬀective while the operation of multiplying two (mathematical) real
numbers that are represented by inﬁnite decimals is not.
3.The algorithm terminates in a ﬁnite number of steps for an appro-
priate class of input expressions.
Computer algebra programming diﬀers from conventional programming
because the programs contain statements that mimic the symbolic manip-
ulations that are done with pencil and paper calculations. While many
of these operations are conceptually well-deﬁned, they are not always al-gorithmically well-deﬁned in either a theoretical or practical sense. For
example, suppose that an algorithm requires the solution of an equation
f(x) = 0. The algorithm may fail because it is impossible to ﬁnd a solution
forf(x) = 0 in terms of a speciﬁc class of functions or simply because of
the limitations of a CAS’s operator for solving equations. One way to re-
solve the problem is to restrict the algorithm’s input to expressions where
all operations in the algorithm are well-deﬁned and produce meaningful
results. In many cases, however, this is not practical because a descriptionof the valid input would be too involved to be useful.
In some instances, subtle diﬀerences in the evaluation process or the
actions of operators may cause implementations of an algorithm to per-form diﬀerently in various computer algebra systems. For example, in Sec-
tion7.2we give a procedure Simplify
trig(u) that can verify a large class
of trigonometric identities. Implementations of the algorithm in Maple,
Mathematica, and MuPAD obtain the simpliﬁcation
(cos(x)+s i n (x))4+( c o s (x)−sin(x))4+c o s ( 4x)−3→0.
On the other hand, while the Maple and Mathematica implementations
obtain the simpliﬁcation
sin3(x)+c o s3/parenleftBig
x+π
6/parenrightBig
−sin3/parenleftBig
x+π
3/parenrightBig
+3s i n ( 3x)
4→0,
4.1. Mathematical Algorithms 121
the MuPAD implementation obtains
→−sin(x−y)
2−sin(−x+y)
2. (4.1)
This discrepancy is explained by the observation that in both Maple and
Mathematica the automatic simpliﬁcation process transforms
sin(−x+y)→−sin(x−y), (4.2)
which simpliﬁes the expression ( 4.1) to zero, while the automatic simpliﬁ-
cation process in MuPAD does not obtain the transformation ( 4.2).
If we were to strictly adhere to the formal requirements for an algorithm,
we would severely restrict the range of problems that would be attempted
in a computer algebra context. Therefore, in describing mathematical al-
gorithms, we take a middle ground between the computer scientist’s needfor precision and the mathematical scientist’s need for practical approaches
for solving a problem. In this spirit, we try as much as possible to adhere
to the guidelines set down by computer scientists, but also accept that forsome input, the theoretical or practical limitations of an operation may
cause the algorithm to return an inappropriate result in some instances.
Mathematical Operators in Algorithms
Large computer algebra systems contain more than a thousand mathemat-
ical operators in a wide variety of areas. For the algorithms and exercises
in this book, we use only a small subset of these operators that perform
the basic operations from arithmetic, algebra, trigonometry, calculus, ele-mentary logic, and set theory.
The mathematical operators that are utilized in MPL algorithms are
listed below. Some of these operators have been deﬁned informally inprevious chapters, and some additional ones are described below.
Algebraic Operators .T h e s ea r e+ , −,∗,/,∧,a n d! .
Relational and Logical Operators . The relational operators are =, <,≤,
>,≥,a n d /negationslash=, and the logical operators are and,or,a n dnot. (See Section
2.1and Figure 2.6on page 37.)
Set Operators .T h e s e a r e ∪,∩,∼,a n d ∈. (See Section 2.4and Fig-
ure2.20on page 70.)
List Operators .T h e s e a r e First,Rest,Adjoin ,Join,Reverse ,Delete ,
and∈. (See page 72and Figure 2.23on page 73.)
122 4. Elementary Mathematical Algorithms
Primitive Structure Operators . These include the structural operators
Kind,Operand ,Number
 of
operands ,a n d Construct . (See pages 104-106
and Figure 3.18on page 106.)
Structure-based Operators . These include the structure-based operators
Free
of,Substitute ,Sequential
 substitute ,a n d Concurrent
 substitute which
are based on the tree structure of an expression. (See pages 110-115and
Figure 3.22on page 111.)
Integer Operators . These operators perform the basic operations on
integers. For integers aandb/negationslash= 0, using integer division, we obtain a unique
quotientqand remainder rwith 0 ≤r≤|b|−1, such that a=q·b+r.
The following operators obtain qandr:
Iquot(a,b)→q, Irem(a,b)→r.
In addition, the operator Integer
 gcd(a,b) obtains the greatest common di-
visor ofaandb. For further discussion of these operators, see Cohen [ 24],
Section 2.1. The corresponding operators in Maple, Mathematica, and Mu-
PAD are given in Figure 4.1. (Implementation: Maple (mws), Mathematica
(nb),MuPAD (mnb).)
Calculus Operators . These include the operators Limit,Derivative ,a n d
Integral . (See page 34and Figure 2.4on page 35.)
Solution Operators. These are the operator Solvethat obtains the so-
lutions to some polynomial equations, some systems of polynomial equa-
tions, and some algebraic and trigonometric equations, and the operator
Solve
 odethat obtains the solutions to some ordinary diﬀerential equations.
(See page 34and Figure 2.4on page 35.)
Structure Operators for Polynomials. These are the operators Degree
andCoeﬃcient . (See page 63and Figure 2.4on page 35.)
Algebraic Manipulation Operators for Polynomials . These include the
operators Factor andAlgebraic
 expand . (See page 34and Figure 2.4on
page35.)
Structure Operators for Rational Expressions. A rational expression
is deﬁned as a quotient u=p/qwherepandqare polynomials. Two
important structural operators for rational expressions are
Numerator (u)→p,Denominator (u)→q.
4.1. Mathematical Algorithms 123
For example,
Numerator (x/(x+1 ) ) →x,Denominator (x2+4x)→1.
The last expression shows that a polynomial is considered a rational expres-
sion with denominator 1. The Numerator andDenominator operators are
described in greater detail on page 260, and the corresponding operators
in Maple, Mathematica, and MuPAD are given in Figure 4.1. (Implemen-
tation: Maple (mws), Mathematica (nb),MuPAD (mnb).)
Simpliﬁcation Operators . Simpliﬁcation is such an involved process that
it cannot be adequately described in a brief space. For now we utilize two
simpliﬁcation operators. The ﬁrst one is automatic simpliﬁcation which is
part of the evaluation process described in Sections 2.2and3.2. The second
one is Rational
 simplify which transforms an algebraic expression to the
form of a rational expression with no common factors in the numerator and
denominator.
Example 4.1.
Rational
 simplify (1/a+1/b)→a+b
ab,
Rational
 simplify/parenleftbiggx2−1
x−1/parenrightbigg
→x+1,
Rational
 simplify/parenleftBigg
1
1/a+c/(ab)+abc+ac2
(b+c)2/parenrightBigg
→a.
(Implementation: Maple (mws), Mathematica (nb),MuPAD (mnb).) /square
The corresponding operators in Maple, Mathematica, and MuPAD are
given in Figure 4.1. For more detail on the Rational
 simplify operator,
consult Cohen [ 24], Section 6.3.
Numerical Operators. The operator Absolute
 value(u) obtains the ab-
solute value of u. The operator Decimal (u) transforms numerical sub-
expressions of an expression to a decimal format. For example, Decimal (x+
1/2)→x+.5. (See page 34and Figure 2.4on page 35.)
Most of these operators and many others are described in greater detail
in later chapters.
124 4. Elementary Mathematical Algorithms
MPL
 Maple
 Mathematica
 MuPAD
Iquot(a,b)
 iquo(a,b)
 Quotient[a,b]
 iquo(a,b)
Irem(a,b)
 irem(a,b)
 Mod[a,b]
 irem(a,b)
Integer
gcd(a,b)
 igcd(a,b)
 GCD[a,b]
 igcd(a,b)
Numerator (u)
 numer(u)
 Numerator (u)
 numer(u)
Denominator (u)
 denom(u)
 Denominator (u)
 denom(u)
Rational
simplify(u)
normal(u)
 Together(u)
 normal(u)
Figure 4.1. The operators in Maple, Mathematica, and MuPAD that correspond
most closely to the MPL operators that are introduced in this section.
Operator Selection
It often happens that a CAS has a number of mathematical operators that
can perform a mathematical operation. For example, suppose that a step
in a program requires simpliﬁcations similar to
x2−1−(x+1 )(x−1)→0. (4.3)
InF i g u r e 4.2we give a Mathematica dialogue that shows three commands
that can obtain this simpliﬁcation. First, the Expand operator, which
In[1]: = u=xˆ2−1−(x+1)∗(x−1)
Out[1]=−1+x2−(−1+x)(1+x)
In[2]: = Expand[u]
Out[2]= 0
In[3]: = Together[u]
Out[3]= 0
In[4]: = Simplify[u]
Out[4]= 0
Figure 4.2. A Mathematica dialogue that shows a numberof mathematical oper-
ators that perform an algebraic simpliﬁcation. (Implementation: Maple(mws),
Mathematica (nb),MuPAD(mnb).)
4.1. Mathematical Algorithms 125
is Mathematica’s version of MPL’s Algebraic
 expand operator, applies the
distributive law to products and positive integer powers in an algebraic
expression. Next, the Together operator, which is similar to MPL’s
Rational
 simplify operator, performs algebraic expansion as well as more
involved operations such as the cancellation of common factors in the nu-
merator and denominator of a rational expression. Finally, the Simplify
operator is a general purpose simpliﬁcation operator that applies a largenumber of algebraic and trigonometric simpliﬁcation rules to an expression.
Similar choices are available in both Maple and MuPAD.
When selecting mathematical operators, to obtain simpler and more
eﬃcient programs, we subscribe to the following minimal power principle :
Always use the least powerful mathematical operator that per-
forms a given mathematical operation.
For example, if we know that our program will only encounter simpliﬁca-
tions similar to Expression ( 4.3), the CAS’s version of the Algebraic
expand
operator is the most appropriate one to use.
Finally, there are situations where it is clearly inappropriate to use a
particular operator in a program. For example, in Section 4.3we describe
a program that ﬁnds the solutions to some ﬁrst order diﬀerential equations.
It goes with out saying that a CAS’s analogue of the Solve
 odeoperator
should not be used in this program.
Semantic Capacity of Mathematical Operators
The capability of a mathematical operator can vary from system to sys-tem (sometimes dramatically) and may change signiﬁcantly when a newversion of a system is introduced. For example, most computer algebra
systems have the capability to compute the limit of a function or an inﬁ-
nite sequence. In mathematics, the limit operation is used in many diﬀerentcontexts, some very concrete and some very abstract. For example:
lim
x→∞x2
ex=0, (4.4)
lim
x→∞xn
ex=0,(nan unassigned symbol) , (4.5)
lim
∆x→0f(x+∆x)−f(x)
∆x=df
dx, (4.6)
lim
n→∞n/summationdisplay
j=1f(j/n)
n=/integraldisplay1
0f(x)dx, (4.7)
126 4. Elementary Mathematical Algorithms
lim
n→∞rn=

0 −1<r< 1,
1 r=1,
∞ r>1,
undeﬁned r<−1.(4.8)
For which limit operations should we expect a CAS to obtain a correct re-
sult? (Implementation: Maple (mws), Mathematica (nb),MuPAD (mnb).)
To create programs in a CAS language, we must have a clear idea about
the capabilities of its mathematical operators. We use the term semantic
capacity (or just capacity ) to refer to the mathematical capabilities of an
operator. Since the algorithms for mathematical operations can be quite
involved, it is often diﬃcult to describe semantic capacity in a simple way.
Nevertheless, the concept is an important one even if it cannot be describedprecisely in some instances. In practice, a useful approach is simply to
experiment with a CAS to see what an operator can do. (See Exercise 1
on page 22,E x e r c i s e 2on page 22, and the exercises at the end of this
section.)
The following two concepts, properly posed operations andsimpliﬁca-
tion context , describe some aspects of operator capacity that are useful for
understanding the capacity of an operator.
Properly Posed Operations
Informally speaking, a mathematical operation is properly posed if all the
information needed to perform the operation in an unambiguous manner
is available. If an operation is not properly posed, a CAS may not perform
the operation, may request additional information, or may return a result
that is only correct in some contexts.
InF i g u r e 4.3, we give a Maple dialogue that illustrates three examples
of operations that are not properly posed and show how they are handled
by this system. At the ﬁrst prompt, Maple evaluates the indeﬁnite integral
/integraldisplay
xndx
wherenis a symbol. This statement is improperly posed because the result
depends on whether or not n/negationslash=−1 which is unknown at this point. Notice
that Maple assumes that n/negationslash=−1 and returns the form of the integral for
this case.
At the next prompt, we assign to ua second order diﬀerential equa-
tion with the unassigned symbols a,b,a n dc, and at the third prompt
ask Maple to solve the diﬀerential equation. This statement is improperly
posed because the form of the solution depends on the value of b2−4ac.
4.1. Mathematical Algorithms 127
> int(x^n, x);
x(n+1)
n+1
> u := a*diff(y(x),x,x) + b*diff(y(x),x) + c*y(x) = 0;
u:=aW∂2
∂x2y(x)}
+bW∂
∂xy(x)}
+cy(x)=0
> dsolve(u, y(x));
y(x)=
C1e~
−1/2(b−√
b2−4ac)x
a^
+
C2e~
−1/2(b+√
b2−4ac)x
a^
> w := exp(-s*t)*sin(t);
w:=e(−st)sin(t)
> int(w, t = 0..infinity);
Deﬁnite integration: Can’t determine if the integral is convergent.
Need to know the sign of −−>s
Will now try indeﬁnite integration and then take limits.
lim
t→∞−e(−st)cos(t)+se(−st)cos(t)−1
s2+1
> assume(s>0);
> normal(int(w, t = 0..infinity));
1
s2
˜+1
Figure 4.3. A Maple interactive dialogue that demonstrates statements that are
improperly posed. (Implementation: Maple(mws),Mathematica (nb),MuPAD
(mnb).)
In this case, Maple returns the form of the solution when b2−4ac>0,
although when b2−4ac= 0, the correct form is
y(x)=c1e−b/2ax+c2xe−b/2ax.
128 4. Elementary Mathematical Algorithms
At the next two prompts, we ask Maple to evaluate the improper
integral/integraldisplay∞
0exp(−st)s i n (t)dt.
This integral is not properly posed because the convergence of the integral
depends on the sign of s.W h e ns>0, the integral converges, and otherwise
it diverges. Observe that following the ﬁfth prompt, Maple displays amessage indicating that it can’t evaluate the integral because it doesn’t
know the sign of sand then returns an unevaluated limit. At the next
prompt, we use Maple’s assume command to assign the positive property
to the symbol s, and at the last prompt we reevaluate the integral and
simplify the result with Maple’s normal command
1.
Similar results are obtained with Mathematica and MuPAD for all three
examples.
The question of when an operation is properly posed is an important
aspect of operator capacity. A CAS will often make assumptions about thenature of variables in an expression, which means the result returned by
an operator may not be correct in all contexts. This can be particularly
troubling in an involved program when one of these exceptional situations
occurs early in the calculations, remains undetected, and contaminates later
calculations. Unfortunately, many mathematical operations that involvegeneral expressions with arbitrary symbols are not properly posed (Exercise
1), and if we try to avoid these situations at all costs our programs will be
unnecessarily complicated.
Simplification Context
For eﬃciency reasons, it is unreasonable to expect a CAS to apply all its
simpliﬁcation rules during the course of a computation. The designer of
a CAS must choose which simpliﬁcation rules are appropriate for a par-
ticular operator. We use the term simpliﬁcation context to refer to those
simpliﬁcation rules that are applied during the evaluation of a mathemat-ical operator. The simpliﬁcation context often determines the form of the
output of an operator and in some cases determines whether or not a CAS
can even correctly perform an operation.
For example, consider the Maple interactive dialogue in Figure 4.4.A t
the ﬁrst prompt, uis assigned a polynomial in xin factored form, and
at the second prompt, we ask Maple to obtain the degree of uinx.In
this case algebraic expansion (with respect to the symbol x)i sp a r to ft h e
1Observe that the symbol sin the output of the normal command is followed by a
tilde ( ˜). The Maple system includes this symbol to indicate that shas been given a
property.
4.1. Mathematical Algorithms 129
> u := (x+1)*(x+2);
u:= (x+1)(x+2)
> degree(u,x);
2
> v := (y^2-1-(y+1)*(y-1))*x^2+x+1;
v:= (y2−1−(y+1)(y−1))x2+x+1
> degree(v,x);
2
Figure 4.4. A Maple interactive dialogue that demonstrates a simpliﬁcation
context. (Implementation: Maple(mws),Mathematica (nb)MuPAD(mnb).)
simpliﬁcation context of the degree operator which returns the value 2.
At the third prompt, vis assigned a polynomial in xwith one coeﬃcient
that is a polynomial in y(in unexpanded form), and at the next prompt,
we ask Maple to obtain the degree of vinx. Notice that the value 2 is
returned even though the coeﬃcient of x2simpliﬁes to 0. For this system,
expansion with respect to the auxiliary symbol yis apparently not part of
the simpliﬁcation context of the degree operator. On the other hand, both
Mathematica’s Exponent operator and MuPAD’s degree operator evaluate
the degree of vto 1.
Figure 4.5shows how the simpliﬁcation context of the numerator oper-
ator can vary from system to system. First, for the expression ( ax+bx)/c,
Maple returns the numerator in a factored form, while Mathematica returnsan expanded form. Next, consider the expression 1 /a+1/b.InM a p l et h e
terms in the sum are combined over a common denominator, and a+bis
returned as the numerator. On the other hand, in Mathematica the terms
in the sum are not combined, and the entire expression is returned as the
numerator.
Simpliﬁcation context is a rather loosely deﬁned concept. For exam-
ple, does it refer to the simpliﬁcation rules that are applied before, during,
or after an operation? In addition for some operators a simpliﬁcation rule
130 4. Elementary Mathematical Algorithms
> u := (a*x+b*x)/c;
u:=ax+bx
c
> numer(u);
(a+b)x
> u := 1/a+1/b;
‘ u:=1
a+1
b
> numer(u);
a+b
(a) Maple.
In[1]: = u=(a∗x+b∗x)/c
Out[1]=ax+bx
c
In[2]: = Numerator [u]
Out[2]= ax+bx
In[3]: = u=1/a+1/b
Out[3]=1
a+1
b
In[4]: = Numerator [u]
Out[4]=1
a+1
b
(b) Mathematica.
Figure 4.5. Interactive dialogues in Maple and Mathematica that show diﬀerent
simpliﬁcation contexts of the numerator operation. (Implementation: Maple
(mws),Mathematica (nb),MuPAD(mnb).)
4.1. Mathematical Algorithms 131
may be applied in some situations while not in others or may even depend
on other options or settings used in a session. Nevertheless, the concept
is an important aspect of operator capacity and serves as a warning that
unwarranted assumptions about the actions of an operator may cause aprogram to fail.
Exercises.
1. Explain why thefollowing operations are not properly posed without addi-
tional information about the arbitrary symbols that appear in the expres-sions. Implement each operation in a CAS.Isthesolution obtained correct
for all values of the arbitrary symbols?
(a)dx
x2+2ax+1.
(b)
sin(nx)s i n (mx)dx.
(c) Solve the diﬀerential equationdy2
dx2−y=e xp ( ax).
(d)1
01
xndx.
Useintanddsolvein Maple, Integrate andDSolveinMathematica, and
intand ode(with solve)i nM uP A D .
2. Experiment with a CAS to determine the simpliﬁcation context of the
following operators.
(a) TheCoeﬃcient operator. For example, can the operator obtain co-
eﬃcients if the input polynomial is not in expanded form? Is the
result returned in expanded form? Is rational simpliﬁcation part of
the simpliﬁcation context? (Use coeffin Maple and MuPAD and
Coefficient in Mathematica.)
(b) TheSolveoperator. For example, can this operator determine that
thequadratic equation ( a2−1−(a+1)(a−1))x2+x−1= 0 is really
a linear equation and return the solution x= 1? How about the
equation(sin2(a)+cos2(a)−1)x2+x−1= 0? Isrationalsimpliﬁcation
applied before and/or after a solution to the equation is found? (Usesolvein Maple and MuPAD and Solvein Mathematica.)
3. Is rational simpliﬁcation part of the simpliﬁcation context of the diﬀer-
entiation operator in a CAS? (Use diffin Maple and MuPAD and Din
Mathematica.)
4. Describe the semantic capacity of the factor operation in a CAS. The ex-
amples in Exercise 1, page22are useful for this exercise. (Use factorin
Maple and MuPAD and Factorin Mathematica.)
132 4. Elementary Mathematical Algorithms
5. SomeCASsoftwarehasthecapabilitytodiﬀerentiateandintegrateexpres-
sions with undeﬁned functions. In this exercise we ask you to explore the
capacity of diﬀerentiation and integration operators in a CAS to handle
undeﬁned functions.
(a) Apply the diﬀerentiation operator to the following expressions:
u(x),du(x)
dxu(x)v(x),u(x)/v(x), (4.9)
sin(u(x)),u(v(x)),x3du(x)
dx−3x2u(x)+x2/2.
Does the CAS obtain the results you expect? (Use diffin Maple
and MuPAD and DMathematica.)
(b) Suppose that you are given the derivatives of the expressions in
(4.9). Can a CAS integrate these derivatives to obtain the expres-
sions in ( 4.9) (up to a constant)? (Use intin Maple and MuPAD
and Integrate in Mathematica.)
6. Animportant aspect ofsemanticcapacity iswhatan operatordoeswhen it
is unable to perform the operation. Experiment with a CAS to determine
what each of the of the following operators does in this situation.
(a)Degree.
(b)Solve.
(c)Integral.
(d)Solve
ode.
For example, what does Degree(u,x) operator return when the input ex-
pression uis not a polynomial in x?( I n M a p l e us e degree, solve,
int,a n d dsolve; in Mathematica use Exponent, Solve, Integrate ,a n d
DSolve;a n di nM uP A Dus e degree, solve, int ,a n d ode(with solve).)
4.2 MPL’s Algorithmic Language
In this section we describe the basic language structures that are used in
MPL to control the ﬂow in an algorithm.
Function Definitions
In ordinary mathematical discourse, the statement, “let f(x)=x2+4,”
deﬁnes a computational scheme and does not perform a computation. A
computation occurs when the function is invoked with a statement such as
f(2)→8. In MPL, a function deﬁnition is used to mimic this operation.
4.2 MPL’s Algorithmic Language 133
InM P L ,a function deﬁnition has the form
f(x1,...,x l)function:=u,
wherefis the function name ,x1,...,x lis a sequence of symbols called the
formal parameters ,a n duis a mathematical expression. As with ordinary
mathematical notation, a function is invoked with an expression of the form
f(a1,...,a l), (4.10)
wherea1,...,a lis a sequence of mathematical expressions called the actual
parameters . When this expression is evaluated, each aiis evaluated and
substituted for the corresponding xiinu,a n dt h e n uis evaluated, and the
resulting expression is returned as the evaluated form of ( 4.10).
Example 4.2. Consider the function deﬁnition
f(x)function:=x2+4.
The function is invoked with an expression such as f(2). When this state-
ment is evaluated, the actual parameter 2 replaces formal parameter xin
x2+4 ,a n df(2)→8. /square
Example 4.3. Consider the function deﬁnition
T(y,x)function:=Derivative (y,x)+y.
The function is invoked with an expression such as T(sin(t)+t2,t). When
this statement is evaluated, the actual parameters sin( t)+t2andtare
substituted for the formal parameters yandx,a n dw eo b t a i n
T(sin(t)+t2,t)→cos(t)+2t+s i n (t)+t2. /square
InF i g u r e 4.6we give function deﬁnitions in Maple, Mathematica, and
MuPAD that implement the MPL deﬁnitions in Examples 4.2and4.3.
Procedure Definitions
MPL procedures extend the function concept to mathematical operators
that are deﬁned by a sequence of statements. The general form of a pro-
cedure is given in Figure 4.7. The ﬁrst line of the procedure gives the
procedure name and a sequence of formal parameters. The Input section
contains each of the formal parameters xialong with a brief description
134 4. Elementary Mathematical Algorithms
f := x -> x^2+4;
T := (y,x) -> diff(y,x)+y;
(a) Maple.
f[x_] := x^2 + 4
T[y_, x_] := D[y, x] + y
(b) Mathematica.
f := x -> x^2+4;
T := (y,x) -> diff(y,x)+y;
(c) MuPAD.
Figure 4.6. FunctiondeﬁnitionsinMaple, Mathematica, andMuPADthatcorre-
spond to the MPL deﬁnitions in Examples 4.2and4.3. (Implementation: Maple
(mws),Mathematica (nb),MuPAD(mnb).)
of the type of expression that replaces it when the procedure is invoked.
MPL procedures always return a mathematical expression as output, and
theOutput section contains a brief description of this expression.
TheLocalVariables section contains a sequence of local variables that
are known and used only by the procedure. The formal parameters and
the local variables make up the local environment of a procedure. In a real
CAS, each time a procedure is invoked, the variables in this environment are
given storage locations in the computer’s memory, and when the procedureterminates, these locations are released back to the system.
The statements between the delimiters Begin andEndrepresent the
bodyor the executable statements of the procedure. Each statement S
jis
either a mathematical expression, an assignment statement, or a decision
or iteration structure both of which are deﬁned later in this section.
A procedure is invoked like a function with an expression of the form
(4.10). When the procedure is invoked, each actual parameter aiis evalu-
ated and then substituted for the corresponding formal parameter xi,a f t e r
4.2 MPL’s Algorithmic Language 135
Procedure f(x1,...,x l);
Input
x1: description of input to x1;
...
xl: description of input to xl;
Output
description of output;
Local Variables
v1,...,v m;
Begin
S1;
S2;
...
Sn−1;
Sn
End
Figure 4.7. The general form of an MPL procedure.
which each statement Sjin the body is evaluated. In most cases, at least
one of the Sjincludes a return statement that has the form
Return (u),
whereuis a mathematical expression. When this statement is encountered,
three actions occur: ﬁrst, the procedure immediately terminates; second,
the evaluated form of uis returned as the evaluated form of Expression
(4.10); and ﬁnally, control is transferred back to the statement that invoked
the procedure. If a Return statement is not included, the actions are similar,
but now the evaluated form of the last statement Snis returned by the
procedure. We always include a Return statement to emphasize what is
returned by the procedure.
Example 4.4. We illustrate this concept by deﬁning a procedure that ob-
tains the equation of a tangent line to a function f(x)a tt h ep o i n t x=a.
Recall that the expression for the tangent line is given by
df
dx(a)(x−a)+f(a). (4.11)
The procedure deﬁnition in Figure 4.8is an algorithmic view of what is
done to obtain this expression in expanded form. We invoke the procedure
136 4. Elementary Mathematical Algorithms
Procedure Tangent
line(f,x,a);
Input
f:a nalgebraic expression (formula for a mathematical function);
x: a symbol (independent variable);
a:a nalgebraic expression (point of tangency);
Output
an algebraic expression that is the formula for the tangent line;
Local Variables
deriv,m,line;
Begin
1deriv:=Derivative (f,x);
2m:=Substitute (deriv,x=a);
3line:=Algebraic
expand(m∗(x−a)+Substitute (f,x=a));
4Return(line)
End
Figure 4.8. An MPL procedure that obtains the formula for a tangent line.
with an expression such as
Tangent
 line(1/z,z,3). (4.12)
When this expression is evaluated, the three actual parameters 1 /z,z,a n d
3 are substituted for the corresponding formal parameters f,x,a n da,a n d
then the statements in the procedure are evaluated:
deriv:=Derivative (1/z, z)→−1/z2,
m:=Substitute (−1/z2,z=3 )→−1/9,
line:=Algebraic
 expand/parenleftbig
(−1/9)∗(z−3) +Substitute (1/z, z=3 )/parenrightbig
→(−1/9)z+2/3.
Therefore
Tangent
 line(1/z,z,3)→(−1/9)z+2/3.
When we invoked the procedure in Expression ( 4.12), for clarity we
intentionally chose names for mathematical symbols that were diﬀerentfrom the formal parameter names of the procedure. There is no reason,
however, to restrict the actual parameters in this way. For example, the
procedure can also be invoked with
Tangent
line(1/x,x,3)→(−1/9)x+2/3. (4.13)
4.2 MPL’s Algorithmic Language 137
Keep in mind, however, that the actual parameter xin Statement ( 4.13)
and the formal parameter xin the procedure declaration
Procedure Tangent
 line(f,x,a) (4.14)
are diﬀerent symbols even though they have the same name. When State-
ment ( 4.13) is evaluated, each actual parameter is substituted for the cor-
responding formal parameter which means that fis replaced by 1 /x,t h e
formal parameter xin (4.14) by the actual parameter xin (4.13), anda
by 3. Therefore, the diﬀerentiation at line 1 is
Derivative (1/x,x)→−1/x2,
where the xthat appears here is the one in ( 4.13). Similar comments apply
to the other statements in the procedure. /square
Maple, Mathematica, and MuPAD provide procedures that operate
as described above. In Figures 4.9and4.10we give implementations of
Tangent
 linein these languages.
Global Symbols. A symbol that appears in a function or a procedure that
is not a formal parameter or a local variable is called a global symbol .
Global symbols, which are accessible to both the interactive mode and other
functions and procedures, provide another way to pass data to and from a
procedure without using the formal parameters or a Return statement.
For a simple example, consider a modiﬁcation of the Tangent
 linepro-
cedure in which the variable derivhas been removed from the local section
and therefore is considered global. In this case, after evaluating Statement
(4.12) the global variable derivhas the value −1/z2which can now be used
by other functions, procedures, or the interactive mode.
In our MPL procedures, global symbols are used primarily to return
information about the status of an operation. For example, in Figure 4.14
on page 144we give a procedure that tries to determine if a mathematical
function is even or odd. The procedure returns one of the global symbols
EvenorOddwhen the input expression is even or odd, or the global symbol
Unknown when the procedure cannot determine the property.
Use of Local Variables in MPL. Procedures provide a way to isolate part of
a computation so that programming variables in the local environment do
not conﬂict with variables with the same name in other functions, proce-
dures, or the interactive mode. However, in some systems local variables
138 4. Elementary Mathematical Algorithms
Tangent_line := proc(f,x,a)
#Input
# f: an algebraic expression (formula for a mathematical function)
# x: a symbol (independent variable)# a: an algebraic expression (point of tangency)
#Output
# an algebraic expression that is the formula for the tangent linelocal
deriv,m,line;
deriv := diff(f,x);m := subs(x=a,deriv);
line := expand(m*(x-a)+subs(x=a,f));
RETURN(line)end:
(a) Maple.
TangentLine[f_,x_,a_] := Module[
(*Input
f: an algebraic expression (formula for a mathematical function)x: a symbol (independent variable)a: an algebraic expression (point of tangency)
Output
an algebraic expression that is the formula for the tangent line
Local*)
{deriv,m,line},
deriv = D[f,x];m = ReplaceAll[deriv,x->a];
line = Expand[m*(x-a)+ ReplaceAll[f,x->a]];
Return[line]]
(b) Mathematica.
Figure 4.9. Implementations of the MPL procedure in Figure 4.8in Maple and
Mathematica. (Implementation: Maple(txt),Mathematica (txt).)
4.2 MPL’s Algorithmic Language 139
Tangent_line := proc(f,x,a)
/*Input
f: an algebraic expression (formula for a mathematical function)
x: a symbol (independent variable)
a: an algebraic expression (point of tangency)
Output
an algebraic expression that is the formula for the tangent line
*/local
deriv,m,line;
beginderiv := diff(f,x);
m := subs(deriv,x=a);
line := expand(m*(x-a)+subs(f,x=a));return(line)
end_proc:
Figure 4.10. A MuPAD implementation of the MPL procedure in Figure 4.8.
(Implementation: MuPAD(txt).)
can also act as mathematical symbols in an expression, and when this hap-
pens, name conﬂicts can occur that are not encountered with conventional
programming languages.
For example, suppose that a symbol xis declared local in a procedure,
and suppose that it is used as a mathematical symbol in an expression
that is returned by a procedure. When this happens, does xlose some
of its local characteristics? For example, when this xis returned to the
interactive mode, is it the same as a mathematical symbol xused elsewhere
in the interactive mode?
InF i g u r e 4.11we show how this situation is handled by the Maple
system. At the ﬁrst prompt, we deﬁne a procedure F(a) that returns the
expression a∗x2with the local x. At the second prompt, we call on the
procedure and assign the output to u. At the third prompt, we diﬀerentiate
uwith respect to xand obtain what appears to be an incorrect result. The
problem here is the local xin the procedure and the xin the diffcommand
are diﬀerent symbols even though they have the same displayed name inthe interactive mode.
In Mathematica, local variables in a procedure can act as mathemati-
cal symbols, although a procedure similar to the Maple procedure in Fig-
ure4.11returns the expression ax
2with the symbol name xreplaced by
another system-generated name.
140 4. Elementary Mathematical Algorithms
> F := proc(a)
local x;
RETURN(a*x^2)end:
> u := F(3);
u:= 3x
2
> diff(u,x);
0
Figure 4.11. A Maple dialogue in which a local mathematical symbol is returned
from a procedure. (Implementation: Maple(mws),Mathematica (nb),MuPAD
(mnb).)
The MuPAD system avoids this situation altogether by not permitting
unassigned local variables in a procedure to act as mathematical symbols.
To avoid conﬂicts of this sort and to provide a system-independent pro-gramming style, we follow MuPAD’s lead and adopt the following conven-
tion:
In MPL procedures, an unassigned local variable cannot appear
as a symbol in a mathematical expression.
In other words, in MPL procedures local variables can only act as program-
ming variables and must be assigned before they appear in a mathematicalexpression. In situations where a procedure requires a local mathemati-
cal symbol, we either pass the symbol through the parameter list or use a
global symbol.
Use of Formal Parameters in MPL. In conventional programming languages,
a procedure’s formal parameters can be used both to transmit data to and
from a procedure and as local variables. The situation with CAS languagesis more involved, however, because the actual parameters in a procedure
call can be mathematical expressions as well as variables. Because of this,
the language mechanism that is used to bind the formal parameters withthe actual parameters can be rather involved and can vary from system
to system. For this reason, the use of formal parameters for anything but
the transmission of data into a procedure is system dependent. Since our
goal is to present a system-independent programming style, we adopt the
following convention:
4.2 MPL’s Algorithmic Language 141
Formal parameters in MPL procedures are used only to transmit
data into a procedure and not as local variables or to return data
from a procedure.
When we need to return more than one expression from a procedure, we
return a list of expressions.
Decision Structures
Decision structures provide a way to control the ﬂow in an algorithm.MPL provides three decision structures. The simplest one is the ifstruc-
ture which has the general form shown in Figure 4.12-(a). The expression
ifcondition then
T1;
T2;
...
Tm;
(a) Theifstructure.
ifcondition then
T1;
T2;
...
Tm
else
F1;
F2;
...
Fn;
(b) Theif-else structure.
Figure 4.12. The general form of the MPL ifandif-elsedecision structures.
142 4. Elementary Mathematical Algorithms
condition is a logical (or relational) expression that evaluates to one of the
logical constants trueorfalse.E a c hTiis either a mathematical expres-
sion, an assignment statement, another decision structure, or an iteration
structure (described below).
Theifstructure usually operates in the following way: when condition
evaluates to true, the indented2statements T1,T2,...,T mare evaluated,
and when condition evaluates to falsethese statements are skipped. The
exception to this scheme arises when the ifstatement is included in a
procedure, and one of the indented statements includes a Return .In t h i s
case, when condition istrue, the statements controlled by the ifare
evaluated until the Return is encountered, at which point the procedure
terminates, and the evaluated form of the argument to Return is returned
by the procedure. This exception also applies to the other decision anditeration structures described below.
A more general decision structure is the if-else structure which al-
lows for two alternatives. It has the general form
3shown in Figure 4.12-
(b). When the expression condition evaluates to true, the statements
T1,T2,...,T mare evaluated, and when condition evaluates to false,t h e
statements F1,F2,...,F nare evaluated.
Example 4.5. Here is a simple example of an if-else structure:
if0≤xandx≤1then
f:=x2+ 4 (4.15)
else
f:=x2−1;
(Implementation: Maple (mws), Mathematica (nb),MuPAD (mnb).) /square
The most general MPL decision structure is the multi-branch decision
structure which allows for a sequence of conditions. It has the general
form shown in Figure 4.13. In this generality, the structure contains zero
or moreelseif sections and an optional elsesection. Upon evaluation, the
logical expressions condition 1,condition 2,...are evaluated in sequence. If
condition iis the ﬁrst one that evaluates to true, then the statements in
that section Si1,...,S im iare evaluated while all the other statements are
2Some computer algebra languages require a termination symbol (such as end
if,fi,
or]) to indicate the extent of statements controlled by the ifstructure. In MPL, these
statements are indicated by indentation without a termination symbol.
3As is common practice in some programming languages, in MPL we omit the
semicolon at the end of a statement that precedes an else,a n elseif (deﬁned below),
and an End.
4.2 MPL’s Algorithmic Language 143
ifcondition 1then
S11;
S12;
...
S1m1
elseifcondition 2then
S21;
S22;
...
S2m2
...
elseifconditionnthen
Sn1;
Sn2;
...
Snm n
else
F1;
F2;
...
Fr;
Figure 4.13. The MPL multi-branch structure that provides for a sequence of
alternatives.
s k i p p e d .Ifn o n eo ft h et e s t se v a l u a t et o true, the statements in the else
section (if included) are evaluated.
All computer algebra languages provide ifstructures and if-else struc-
tures, and some languages provide a version of the multi-branch decision
structure4.
The procedure in the next example utilizes a multi-branch structure.
4In Maple and MuPAD, use the ifstatement to implement MPL’s if,if-else ,a n d
multi-branch structures. In Mathematica, use the Ifstatement to implement MPL’s
ifand if-else structures and the Which statement to implement MPL’s multi-branch
structure.
144 4. Elementary Mathematical Algorithms
Example 4.6. Recall that a mathematical function u(x)i se v e ni f
u(x)−u(−x)=0
and odd if
u(x)+u(−x)=0.
For example, u(x)=x2−1i se v e n ,u(x)=x3is odd, while u(x)=x2+x3
is neither even nor odd.
A procedure that tries to determine if an algebraic expression uis even
or odd is given in Figure 4.14. The procedure is interesting for both what
it can do and what it cannot do. Observe that the procedure operates inthe simpliﬁcation context of automatic simpliﬁcation, and in this context
it can determine the nature (even or odd) of the ﬁrst two examples given
above.
Notice that when the procedure is unable to determine that uis even
or odd, it returns the symbol Unknown , rather than a symbol indicating
that the expression is neither even nor odd. We do this because automatic
simpliﬁcation applied at lines 2 and 4 may not simplify an expression to
zero even though the expression simpliﬁes to zero in a mathematical sense.For example, suppose that uis the even expression ( x+1 )(x−1), and
Procedure Even
 odd(u,x);
Input
u:a nalgebraic expression ;
x:as y m b o l ;
Output
one of the global symbols Even,Odd,o rUnknown;
Local Variables
v;
Begin
1 v:=Substitute (u, x=−x);
2 ifu−v=0then
3Return(Even)
4 elseif u+v=0then
5Return(Odd)
6 else
7Return(Unknown)
End
Figure 4.14. An MPL procedure that attempts to determine if uis even or odd.
(Implementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
4.2 MPL’s Algorithmic Language 145
let’s assume that algebraic expansion is not included in automatic simpli-
ﬁcation5.In t h i s c a s e , vis the expression ( −x+1 )( −x−1), andu−v
is the expression ( x+1 )(x−1)−(−x+1 )( −x−1), which does not sim-
plify to 0 with automatic simpliﬁcation. Although we can remedy this byapplying the Algebraic
expand operator at lines 2 and 4, there are other
expressions that are not handled in this simpliﬁcation context. For ex-
ample, 1/(x−1)−1/(x+ 1) is even, but this cannot be determined by
algebraic expansion and automatic simpliﬁcation. In this case, rational
simpliﬁcation (with Rational
 simplify ) is required at lines 2 and 4. But
then, sin(x/(x+1 ) )+s i n ( x/(x−1)) is even, but this is not handled by
rational simpliﬁcation.
While it is possible to increase the simpliﬁcation power at lines 2 and
4 to handle all of the above expressions, it is theoretically impossible to
increase the simpliﬁcation power to a level that the procedure can always
determine if an algebraic expression is even or odd6. /square
Iteration Structures
MPL contains two iteration structures that allow for repeated evaluation
of a sequence of statements. The ﬁrst iteration structure is the while
structure which has the general form
while conditiondo
S1; (4.16)
S2;
...
Sn;
where condition is a logical (or relational) expression. This structure is
evaluated by ﬁrst evaluating condition , and if it is to true, the indented
statements S1,S2,...,S mare evaluated. Once this is done, the process
repeats, and again if the logical condition istrue, the indented statements
are evaluated. The process continues in this way checking if condition is
trueand if so, evaluating the indented statements. On the other hand once
5In Maple, Mathematica, and MuPAD, algebraic expansion is not part of automatic
simpliﬁcation.
6The problem to determine if an expression simpliﬁes to 0 is known as the zero
equivalence problem . D. Richardson has shown that for the class of algebraic expres-
sions constructed with rational numbers, the symbol x,t h er e a ln u m b e r s πand ln(2),
the sin, exp, and absolute value functions, and sums, products, and powers with in-teger exponents, it is impossible to give an algorithm that can always determine if anexpression simpliﬁes to 0 (see Richardson [ 84]).
146 4. Elementary Mathematical Algorithms
condition evaluates to false, the indented statements are not evaluated, and
the structure terminates.
Example 4.7. The sum of the ﬁrst n+ 1 terms of a Taylor series for a
functionu(x)a b o u tx=ais given by
n/summationdisplay
i=0u(i)(a)
i!(x−a)i(4.17)
whereu(i)is theith derivative of u(x), andu(0)=u(x). When nis a
non-negative integer, the sum ( 4.17) is obtained with the following MPL
statements:
1i:= 1;
2s:=Substitute (u,x=a);
3whilei≤ndo
4u:=Derivative (u,x);
5s:=s+Substitute (u,x=a)/i!∗(x−a)i;
6i:=i+1 ;
The substitution in line 2 initializes stou(0)(a)=u(a), and each traversal
through the while loop adds one additional term of the Taylor series to s
and increases the counter iby 1. Eventually i=n+1, and so the condition
i≤nisfalse,a n dt h ewhile structure terminates.
For example, if u=s i n (x),n=3 ,a n da= 0, after executing the loop
we obtain s=x−x3/6. (Implementation: Maple (mws), Mathematica
(nb),MuPAD (mnb).) /square
The second iteration structure is the forstructure which has the general
form
fori:=starttoﬁnishdo
S1; (4.18)
S2;
...
Sn;
whereiis a variable and startandﬁnish are expressions that evaluate to
integer values. When start≤ﬁnish, the indented statements are evaluated
4.2 MPL’s Algorithmic Language 147
for each integer value of i=start,start +1,...,finish .Ifstart>finish ,
the indented statements are not evaluated7
Example 4.8. T h es u mo ft h eﬁ r s t n+1 terms of the Taylor series can also
be obtained using a forstructure:
1s:=Substitute (u,x=a);
2fori:= 1tondo
3u:=Derivative (u,x);
4s:=s+Substitute (u,x=a)/i!∗(x−a)i;
(Implementation: Maple (mws), Mathematica (nb),MuPAD (mnb).) /square
All computer algebra languages provide iteration structures similar to
while andfor8.
Evaluation of Logical Expressions. InM P L ,t h ev a l u e( trueorfalse)o fa
logical expression with main operator andor main operator oris obtained
by evaluating each of the operators in a left to right manner until thevalue of the entire expression is determined. In some cases this value is
obtained without evaluating all the operands of the logical expression. For
example, consider the following decision structure which tests if nis a
positive integer:
ifKind(n)=integerand n>0then (4.19)
...
Observe that the second relational expression only evaluates to trueor
falsewhennhas a numerical value. When nis not an integer, however,
the value of the entire logical expression ( false) is determined by the test
Kind(n)=integer , and there is no need to evaluate the expression n>0.
Most computer algebra systems evaluate logical expressions in decision
and iteration structures in a similar way
9.
7Some of our procedures contain Fo rloops that include a Return statement. (For
example, see lines 5-6 in the procedure Polynomial
 svin Figure 6.2on page 218.) In
this case, we intend that both the loop and the current procedure terminate when the
Return is encountered, and that the value returned by the procedure is the value of the
operand of the Return statement. The forstatements in both Maple and MuPAD work
in this way. However, in Mathematica, a Return in a Forstatement will only work in
this way if the upper limit contains a relational operator (e.g., i<=N). (Implementation:
Mathematica (nb).)
8In Maple and MuPAD, use the while and forstatements. In Mathematica, use the
While and Forstatements.
9Maple, Mathematica, and MuPAD use this approach to evaluate logical expressions
in decision and iteration structures.
148 4. Elementary Mathematical Algorithms
The procedure in the next example uses the concepts described in this
section.
Example 4.9. It is often necessary to separate the operands of a product
into two classes, those that depend on an expression (say x)a n dt h o s e
that do not. For example, this operation is needed when we use the linear
property of the integral to move the factors of a product that do not dependon the integration variable xoutside of the integral sign:
/integraldisplaycxsin(x)
2dx=c
2/integraldisplay
xsin(x)dx. (4.20)
A procedure Separate
 factors that performs the separation operation
is given in Figure 4.15. The procedure takes two algebraic expressions u
Procedure Separate
factors(u,x);
Input
u,x:algebraic expressions ;
Output
a list with two algebraic expressions ;
Local Variables
f,free
of
part,dependent
part,i;
Begin
1 ifKind(u)=” ∗”then
2free
of
part:= 1;
3dependent
part:= 1;
4 fori:= 1toNumber
of
operands(u)do
5 f:=Operand(u,i);
6 ifFree
of(f,x)then
7 free
of
part:=f∗free
of
part
8 else
9 dependent
part:=f∗dependent
part;
10Return([free
of
part,dependent
part])
11 else
12 ifFree
of(u,x)then
13 Return([u,1])
14 else
15 Return([1,u])
End
Figure 4.15. AnMPL procedurethatseparates factors ina productthatdepend
onxfrom those that do not. (Implementation: Maple(txt),Mathematica (txt),
MuPAD(txt).)
4.2 MPL’s Algorithmic Language 149
andxas input and returns a two-element list. The ﬁrst member of the
list contains the product of the factors of uthat are free of x, while the
second member contains the product of the remaining factors. If there are
no factors in a category, the integer 1 is returned for that category.
The procedure can be applied to both products and non-products.
Whenuis a product, the Free
ofoperator is applied to each factor which
is then placed in the appropriate category (lines 6-9). When uis not a
product, it is reasonable to apply Free
ofto the entire expression which
is then placed in the appropriate category (lines 12-15). The procedure is
invoked with an expression such as
Separate
 factors/parenleftbiggcxsin(x)
2,x/parenrightbigg
→[c/2,xsin(x)]. /square
Comparison of the MPL and CAS Languages
In Chapters 2,3, and this chapter we have introduced the main elements
of the MPL algorithmic language. The description includes the following
elements.
1.The MPL mathematical operators. A summary of these operators is
given on pages 121-123of this chapter. In later chapters many of
these operators are described in greater detail and many others are
introduced.
2.A description of the evaluation process including automatic simpli-
ﬁcation. All calculations in our programs are done in the context
of automatic simpliﬁcation. Automatic simpliﬁcation is described in
Chapters 2and3. For a more detailed discussion of automatic sim-
pliﬁcation consult Cohen [ 24], Chapter 3.
3.The structure of mathematical expressions. Mathematical expres-
sions are the data objects of computer algebra. The form of these
expressions in the context of automatic simpliﬁcation is described in
Chapter 3.
4.The MPL algorithmic structures. Functions, procedures, decision
structures, and iteration structures are described in this section, and
a few additional ones are described in later chapters.
Although MPL is similar to real CAS languages, it models only a small
subset of these languages. Large CAS languages contain over 1000 mathe-
matical operators and other language features that provide greater mathe-
matical power, facilitate the programming process, and enhance the com-
putational eﬃciency of programs.
150 4. Elementary Mathematical Algorithms
There is, however, much to be gained from MPL’s simplicity. MPL’s
algorithms can be implemented (usually with only minor modiﬁcations)
in many real CAS languages using only the basic operations of these lan-
guages. In fact, many mathematical operations can be formulated in termsof the analogues of MPL’s primitive operators ( Kind,Operand ,e t c . ) o r
in terms of other operators that are deﬁned in terms of these primitive
operators.
Exercises
Unless otherwise noted, each of the functions and procedures in the exercises
should be expressed in terms of a CAS’s version of the mathematical operators
given on pages 121-123.
1. Consider the function f(x)=1
1−x.
(a) Show that f(f(f(x)))=xwith pencil and paper.
(b) Deﬁne this function using a function deﬁnition in a CAS language.
(c) Use a CAS to show that f(f(f(x)))=x.
2. (a) The curvature of a function f(x)i sg i v e nb y
k(x)=|f/prime/prime(x)|
(1+(f/prime(x))2)3/2.
Give a procedure Curvature (f,x) that computes the curvature of an
algebraic expression fatx.
(b) Apply the Curvature operator to the function
f(x)=
4−x2.
Since this function represents the positive semicircle of radius 2, the
curvature result simpliﬁes to the value 1 /2. Can youobtain this
simpliﬁcation with a CAS?
3. Let ube an equation that represents a straight line in xandy,a n dl e t p
be a two-element list of rational numbers that represents the coordinates
of a point.
(a) Give a procedure Perpendicular
 line(u,x,y,p)that returnstheequa-
tion of a line perpendicular to uthat passes through the point p.
Be sure to include the cases for horizontal and vertical lines. For
example,
Perpendicular
 line(2x+3y=4,x ,y ,[1,2])→y−2=(3 /2)(x−1).
4.2 MPL’s Algorithmic Language 151
(b) Give a procedure
Distance
point
line(u,x,y,p)
that returns the shortest distance from the point pto the line u.F o r
example,
Distance
point
line(2x+3y=4,x ,y ,[1,2])→(4/13)√
13.
4. Let ubeamathematical expression . Giveaprocedure Operand
list(u)that
returns the operands of a compound expression in a list. (The operands
in the list should be in the same order as the operands in u.) Ifuis not a
compound expression, return the global symbol Undeﬁned .I fuis a list,
return u. For example,
Operand
list(a+b+c)→[a,b,c].
5. Let ube an equation of the form f=gwhere fandgare polynomials in
xwith coeﬃcients that are rational numbers such that f−ghas degree
≤2. Give a procedure Solve
quadratic(u,x) that ﬁnds the roots of the
equation f=g.B es ur et oc h e c ki f f−gis a constant, linear, or quadratic
polynomial. Do not use a CAS’s solve operator in this problem.
6. Let Sbe a set of polynomials in x. Give a procedure Find
min
deg(S,x)
that returns a polynomial of smallest degree in S.I fS=∅,r e t ur nt h e
global symbol Undeﬁned .
7. Theset product of sets AandBis the set of all lists [ x,y]w h e r e x∈A
andy∈B. This set is represented by A×B.I fe i t h e r A=∅orB=∅,
then, by deﬁnition, A×B=∅. Give a procedure Set
product(A,B)t h a t
returns A×B. For example,
Set
product({a,b},{c,d})→{[a,c],[a,d],[b,c],[b,d]}.
8. Let xbe a symbol, and let ube a polynomial in xwith rational number
coeﬃcients. Giveaprocedure Linear
factors(u,x)thatreturnstheproduct
of thelinear factors of u.I fuhasnolinear factors, return1. Use thefactor
operator in a CAS to obtain the factorization of u. For example,
Linear
factors(x2+x,x)→x(x+1),Linear
factors(x3+1,x)→x+1,
Linear
factors(x2+1,x)→1,Linear
factors(x2+2x+1,x)→(x+1)2.
9. Let ube a polynomial in xandywith rational number coeﬃcients. A
polynomial uissymmetric if it is not changed when the variables xand
yare interchanged. For example, the polynomial u=x2+2xy+y2is
symmetric. Give a procedure Symmetric (u,x,y) that returns trueifuis
symmetric and falseotherwise.
10. Let Lbe a list. Givea procedure Remove
duplicates (L) thatreturnsanew
list with all members that are identical to a previous member of the list
removed from u. For example, Remove
duplicates ([a,b,c,a,c])→[a,b,c].
152 4. Elementary Mathematical Algorithms
11. Let ube analgebraic expression .T h enumerical coeﬃcient part ofuis
deﬁned in the following way:
(a) If uis a rational number, the numerical coeﬃcient part of uisu.
(b) If uis a product, the numerical coeﬃcient part is the operand of u
that is a rational number. If this operand does not exist, then the
numerical coeﬃcient part is 1.
(c) If uis any other type of expression, then the numerical coeﬃcient
part is 1.
Letnbe the numerical coeﬃcient part of an expression. Give a proce-
dureNumerical
coeﬃcient (u) that returns a two-element list [ n, u/n]. For
example,Numerical
coeﬃcient (2/3xsin(x))→[2/3,xsin(x)].
12. Let ube analgebraic expression . Give a procedure Separate
sin
cos(u)
that returns a two-element list [ r, s] that is deﬁned using the following
rules.
(a) If uis a product, then sis the product of the operands of uthat are
sines, cosines, or positive integer powers of sines and cosines, and ris
theproductoftheremaining operandsof u. (Iftherearenooperands
in a category, return 1 for that category.)
(b) If uis a sine, cosine, or a positive integer power of a sine or cosine,
thens=uandr=1 .
(c) In all other cases, r=uands=1 .
For example,
Separate
sin
cos(3 sin( x)c o s (y))→[3,sin(x)c o s (y)],
Separate
sin
cos(1+sin( x))→[1+sin( x),1].
This procedure is used in the procedure Contract
trig
rulesin Figure 7.7,
page297.
13. Let ube analgebraic expression ,a n dl e t xandybe symbols. Give a
procedure
Separate
variables(u,x,y)
that determines if an expression uc a nb ef a c t o r e di nt h ef o r m u=p·q,
where pis free of y,a n dqis free of x. Use the factor operator in a CAS
to obtain the factorization of u.I fucan be factored in this form, return a
list [p,q], otherwise return false. For example,
Separate
variables(3xy+3x, x, y)→[3x, y+1],
Separate
variables(x+y, x, y)→false.
Thisprocedureisusedintheprocedure Separable
odedescribedinExercise
5on page168.
4.2 MPL’s Algorithmic Language 153
14. Let P=[ [x1,y1],...,[xr+1,yr+1]] be a list of 2 element lists, where xi
andyiare rational numbers. The Lagrange interpolation polynomial that
passes through these points is given by
L(x)=r+1
i=1yiLi(x).
where
Li(x)=(x−x1)···(x−xi−1)(x−xi+1)···(x−xr+1)
(xi−x1)···(xi−xi−1)(xi−xi+1)···(xi−xr+1).
Give a procedure Lagrange
polynomial (P,x) that returns the polynomial
L(x). For example,
Lagrange
polynomial ([[1,1],[2,−1]],x)→−2x+3.
15. Let ube an equation that involves xandy, and suppose that it is possible
to solve the equation for yas a linear expression in xusing algebraic op-
erations such as rational simpliﬁcation and expansion. Give a procedure
Line(u,x,y) that solves the equation for yand returns the result in the
formy=mx+b. Do not use the solve operator in a CAS in this exercise.
For example, your procedure should obtain the following transformations:
LineQx
2+y
3=1,x ,yw
→y=(−3/2)x+3,
LineQx
a=x+y
b,x ,yw
→y=b−a
ax,
LineWy/x−2
1−3/x=6,x ,y}
→y=8x−18.
16. A Taylor series for a function u(x,y) about the point ( a,b)i sg i v e nb y
T(x,y)=∞
i=0ui(x,y)/i!, (4.21)
where
ui(x,y)=i
j=0i!
(i−j)!j!∂iu(a,b)
∂xi−jyj(x−a)i−j(y−b)j.
For example, for u=e xp ( x)cos(y)a n d( a,b)=(0,0), the Taylor series is
T(x,y)=1+ x+(1/2)(x2−y2)+(1/6)(x3−xy2)−(1/3)xy2+···
Letu,a,a n dbbealgebraic expressions ,xandybe symbols, and nan o n -
negative integer. Give a procedure Taylor
2(u,x,y,a,b,n ) that obtains
the sum of the ﬁrst n+1 terms of the series ( 4.21).Note: A more eﬃcient
procedure is obtained byusing the expression ui−1(x,y)toobtain thenext
expression ui(x,y).
154 4. Elementary Mathematical Algorithms
17. Consider the diﬀerential equation and initial condition
dy(x)
dx=f(x,y(x)),y(a)=b. (4.22)
A Taylor series solution to this equation, which has the form
y(a)+dy(x)
dx(a)(x−a)+d2y(x)
dx2(a)(x−a)2
2!+···,
is found in the following way. The constant term in the series is given by
the initial condition in ( 4.22), and the second term is obtained using the
diﬀerential equation in ( 4.22)
dy(x)
dx(a)(x−a)=f(a,y(a))(x−a).
The third term is obtained by diﬀerentiating both sides of the diﬀerential
equation
d2y(x)
dx2=df(x,y(x))
dx,
and which gives
d2y(x)
dx2(a)(x−a)2
2!=df(x,y(x))
dxEEEE
x=a(x−a)2
2!.
The next term in the series is obtained in a similar way with the second
derivative of f(x,y(x)). For example, for the diﬀerential equation and
initial condition
dy(x)
dx=f(x,y(x))=x3+1
y(x)+3,y(0)=2 ,
the ﬁrstterm is y(0) = 2, and thesecond term is f(0,y(0))(x−0) = 7 /2x.
To obtain the third term, we ﬁrst obtain an expression for the secondderivative using the diﬀerential equation
d
2y(x)
dx2=df(x,y(x))
dx=3x2−dy(x)
dx
y(x)2=3x2−x3+1/y(x)+3
y(x)2,
and then using the substitutions y(x)=2and x=0 to obtain
d2y(x)
dx2(0)(x−0)2/2! =−7/16x2.
In a similar way the fourth term of the series is 35 /64x3.
Letwbe a diﬀerential equation in the form ( 4.22),xandybe symbols,
aandbbe algebraic expressions, and nbe a non-negative integer. Give a
procedure
Taylor
ode(w,x,y,a,b,n )
4.2 MPL’s Algorithmic Language 155
that obtains the sum of the ﬁrst n+1 terms of the Taylor series solution
to the diﬀerential equation. Note: Undersuitable conditions on f(x,y)the
Taylor series converges to y(x)f o rxin an interval about x=a.I nt h i s
case the polynomial obtained by Taylor
odeis an approximation to the
true solution to the diﬀerential equation.
18. Consider the two inﬁnite series
F=∞
n=0fn(t−t0)
n!,G=∞
n=0gn(t−t0)
n!, (4.23)
where the functions fn=fn(t)a n dgn=gn(t) are deﬁned by the relations
fn=dfn−1
dt−µ(t)gn−1, (4.24)
gn=fn−1+dgn−1
dt, (4.25)
with the initial functions given by
f0=1, (4.26)
g0=0. (4.27)
The two series in 4.23) are known in astronomy as the FandGseries
where they are used for orbit calculations.
The computation in this problem is one of the early (1965) applications of
computer algebra thatused theFORMAC computeralgebra system devel-oped at IBM(Bond et al.[ 11]). In thisproblem werestrict ourattention to
the symbolic computation problem associated with the computation of the
functions f
nandgn. Observe that Equation ( 4.24) contains an undeﬁned
function µ(t), which implies that fnandgnalsodependon t, and therefore
the diﬀerentiations in Equations ( 4.24)a n d(4.25) make sense. Using the
relations in ( 4.24)a n d(4.25) and the initial terms ( 4.26)a n d(4.27), the
next two terms of each sequence are given by
f1=0,g 1=1,f 2=−µ(t),g 2=0. (4.28)
Forlargervaluesof n, it iscustomaryin astronomical calculations todeﬁne
two additional functions σ(t)a n dλepsilonN(t) and to make the substitutions
dµ(t)
dt=−3µ(t)σ(t),dσ(t)
dt=λepsilonN(t)−2σ(t)2,dλepsilonN(t)
dt=−σ(t)(µ(t)+2λepsilonN(t)),
(4.29)
whenever these derivatives appear in the calculations. For example, tocompute f
3, we use Equations ( 4.24), (4.28), and (4.29)t oo b t a i n
f3=df2
dt−µ(t)g2=d(−µ(t))
dt−µ(t)·0=3µ(t)σ(t).
156 4. Elementary Mathematical Algorithms
In a similar way, we have
g3=−µ(t),f 4=−15µ(t)σ(t)2+3µ(t)λepsilonN(t)+µ(t)2,g 4=6µ(t)σ(t).
For larger values of n, the algebra becomes much more involved, and so
this is a good candidate for computer algebra.
(a) Using Equations ( 4.24), (4.25), (4.26), (4.27), and (4.28), show that
f5= 105 σ(t)3µ(t)−45µ(t)λepsilonN(t)σ(t)−15σ(t)µ(t)2,
g5=−45σ(t)2µ(t)+9λepsilonN(t)µ(t)+µ(t)2.
(b) Let nbe a positive integer, and let tbe a symbol. Give a procedure
FG(n,t) that returns the list [ fn,gn], where fnandgnare expressed
in terms of µ(t),σ(t), and λepsilonN(t).
4.3 Case Study: First Order Ordinary Differential
Equations
In this section we describe an algorithm that ﬁnds a solution to some
ﬁrst order diﬀerential equations using techniques similar to those found
in an elementary diﬀerential equations textbook. A ﬁrst order ordinary
diﬀerential equation is one in which the highest order derivative is a ﬁrstderivative. For example,
xdy
dx+y2=x−1
is a ﬁrst order diﬀerential equations, while
d2y
dx2+y=s i n (x)
is not. Although ﬁrst order diﬀerential equations are very diﬃcult to solve
in general, there are some speciﬁc forms that are solvable.
The solution technique we use involves the method of separation of
variables and the method of exact equations using integrating factors. In
the next few pages we describe these approaches in enough detail to allowus to formulate our procedures. Additional theory and examples can be
found in most diﬀerential equations textbooks
10.
10For example, see Simmons [ 87], Chapters 1 and 2, Boyce and DiPrima [ 12], Chapter
2, or Derrick and Grossman [ 32], Chapter 2.
4.3 Case Study: First Order Ordinary Differential Equations 157
Separation of Variables
A diﬀerential equation that can be expressed in the form
dy
dx=f(x)g(y) (4.30)
is called a separable diﬀerential equation. In this case, the notation implies
that the expression to the right of the equal sign can be factored as a
product of an expression that is free of yand one that is free of x.T os o l v e
the equation, divide both sides by g(y) and integrate with respect to x
/integraldisplay1
g(y)dy
dxdx=/integraldisplay
f(x)dx.
By the chain rule, this is equivalent to
/integraldisplaydy
g(y)=/integraldisplay
f(x)dx.
By integrating both sides of this equation, we obtain an implicit solution
to the diﬀerential equation.
Example 4.10. Consider the diﬀerential equation,dy
dx=2xy2. An implicit
solution is given by
/integraldisplaydy
y2=/integraldisplay
2xd x ,
−1
y=x2+C.
In this case, by solving for ywe obtain an explicit solution
y=−1
x2+C. (4.31)
In most cases, however, it is diﬃcult (or impossible) to express the solution
in explicit form. For this reason, our algorithm returns the result in implicit
form. /square
Exact Differential Equations and Integrating Factors
This technique applies to diﬀerential equations that can be transformed to
the form
M(x,y)+N(x,y)dy
dx=0. (4.32)
158 4. Elementary Mathematical Algorithms
Our goal is to ﬁnd an implicit solution to this equation that has the form
g(x,y)=C, (4.33)
whereCis an arbitrary constant. To obtain a solution algorithm, let’s
suppose this expression is a solution to Equation ( 4.32). Considering yas
a function of x, diﬀerentiating Equation ( 4.33) with the chain rule gives
dg
dx=∂g
∂x+∂g
∂ydy
dx=0. (4.34)
Comparing this equation to Equation ( 4.32), we obtain
∂g
∂x=M(x,y),∂g
∂y=N(x,y), (4.35)
and ﬁnd the solution to Equation ( 4.32) by solving these two equations for
g(x,y).
Example 4.11. Consider the diﬀerential equation
2x+3y2+( 6xy+y2)dy
dx=0. (4.36)
We ﬁnd a solution by solving the equations
∂g
∂x=2x+3y2,∂g
∂y=6xy+y2. (4.37)
Integrating the ﬁrst of these equations with respect to x,w eo b t a i n
g(x,y)=/integraldisplay∂g
∂xdx=/integraldisplay
2x+3y2dx=x2+3xy2+h(y).(4.38)
Since this operation inverts the partial diﬀerentiation operation, we assume
thatyis ﬁxed during the integration and obtain a constant of integration
h(y) that may depend on y, but is free of x. To ﬁndh(y), using Equation
(4.38) we diﬀerentiate g(x,y) with respect to y,
∂g(x,y)
∂y=∂(x2+3xy2+h(y))
∂y=6xy+h/prime(y),
and compare this result with the second equation in ( 4.37). Therefore,
6xy+h/prime(y)=6xy+y2,
4.3 Case Study: First Order Ordinary Differential Equations 159
which implies h/prime(y)=y2.Integrating with respect to y,w eo b t a i n h(y)=
y3/3, and therefore an implicit solution to the diﬀerential equation is
g(x,y)=x2+3xy2+y3/3=C. (4.39)
We can also start the process by integrating the second equation in ( 4.37)
with respect to y:
g(x,y)=/integraldisplay∂g
∂ydy=/integraldisplay
6xy+y2dy=3xy2+y3/3+k(x),
where now the constant of integration depends on x. Diﬀerentiating this
expression with respect to xand comparing the result with the ﬁrst ex-
pression in ( 4.37), we obtain k(x)=x2, which gives again the solution in
Equation ( 4.39). /square
The next example shows that the method does not always work.
Example 4.12. Consider the diﬀerential equation
2+3y/x+( 3+3y2/x)dy
dx=0,x > 0. (4.40)
We try to ﬁnd a solution by solving the equations
∂g
∂x=2+3y/x,∂g
∂y=3+3y2/x. (4.41)
Integrating the ﬁrst equation with respect to x,w eo b t a i n
g(x,y)=/integraldisplay∂g
∂xdx=/integraldisplay
(2 + 3y/x)dx=2x+3yln(x)+h(y).(4.42)
To ﬁndh(y), we diﬀerentiate this expression with respect to y
∂(2x+3yln(x)+h(y))
∂y=3l n (x)+h/prime(y)
and compare this result with the second equation in ( 4.41). We obtain
3l n (x)+h/prime(y)=3+3 y2/x, which implies h(y) is not free of xand so
the technique does not work. In addition, if we start the process by ﬁrst
integrating
∂g
∂y=3+3y2/x
with respect to yand then diﬀerentiating g(x,y) with respect to x,w e
ﬁnd that the constant of integration k(x) is not free of yand so again the
technique does not work. /square
160 4. Elementary Mathematical Algorithms
As we saw in the last example, for the technique to work the constants
of integration ( h(y)o rk(x)) must be free of the other variable ( xory).
Equations for which this happens are called exactdiﬀerential equations.
There is a simple test that determines if an equation is exact. It can beshown
11that an equation is exact if and only if
∂M
∂y=∂N
∂x. (4.43)
Using this relation, we can easily check that Equation ( 4.36) is exact, while
Equation ( 4.40)i sn o t .
When the equation is not exact, it may be possible to transform the
equation to one that is exact. We illustrate this in the next example.
Example 4.13. Consider again the diﬀerential equation from the last ex-
ample
2+3y/x+( 3+3y2/x)dy
dx=0,
wherex>0. If we multiply both sides of the equation by u(x,y)=x,w e
obtain a new diﬀerential equation
2x+3y+( 3x+3y2)dy
dx=0. (4.44)
Since∂M
∂y=3=∂N
∂x,
Equation ( 4.44) is exact, and the solution technique for exact equations
gives the implicit solution x2+3xy+y3=C. /square
The expression u(x,y) in the previous example is called an integrating
factor for the diﬀerential equation. Although an integrating factor always
exists in theory, it may be very diﬃcult to ﬁnd in practice12.T w o c a s e s
where simple integrating factors can be found are described in the followingtheorem.
Theorem 4.14. Consider the diﬀerential equation
M(x,y)+N(x,y)dy
dx=0.
11See Simmons [ 87], pp. 51-52, Boyce and DiPrima [ 12], page 84, Derrick and Gross-
man [ 32], page 41.
12For example, see Boyce and DiPrima [ 12], page 87, where it is shown that the
integrating factor is a solution to a partial diﬀerential equation. Unfortunately, it maybe very diﬃcult to solve the partial diﬀerential equation.
4.3 Case Study: First Order Ordinary Differential Equations 161
1. Let
F=∂M
∂y−∂N
∂x
N. (4.45)
IfFis free ofy, then an integrating factor is u=e x p/parenleftbig/integraltext
Fd x/parenrightbig
.
2. Let
G=∂N
∂x−∂M
∂y
M. (4.46)
IfGis free ofx, then an integrating factor is u=e x p/parenleftbig/integraltext
Gd y/parenrightbig
.
In either case, uM+uNdy
dx=0is an exact diﬀerential equation.
Example 4.15. Consider again the inexact equation
2+3y/x+( 3+3y2/x)dy
dx=0,x > 0.
We have
F=/parenleftBig
∂M
∂y−∂N
∂x/parenrightBig
N=3/x+3y2/x2
3+3y2/x=1/x, (4.47)
where the expression on the right is obtained with rational simpliﬁcation.
Since this expression is free of y,u=e x p (/integraltext
1/x dx)=xis an integrating
factor and we obtain the exact form of Equation ( 4.44).
On the other hand, since
G=/parenleftBig
∂N
∂x−∂M
∂y/parenrightBig
M=−3y2/x2−3/x
2+3y/x=−3x−3y2
2x2+3xy
is not free of x, this approach does not obtain an integrating factor that is
free ofx. /square
TheSolve
 ode Algorithm
An MPL algorithm that attempts to solve a ﬁrst order diﬀerential equation
is given in Figures 4.16and4.17. The algorithm returns either an implicit
solution to the diﬀerential equation, which may include some unevaluated
integrals, or the global symbol Failif it cannot ﬁnd a solution using the
methods described in this section. The main procedure of the algorithm is
162 4. Elementary Mathematical Algorithms
Procedure Solve
ode(w,x,y);
Input
w: a diﬀerential equation that can be transformed by
rational simpliﬁcation to the form M+Ndy
dx=0,
where the derivativedy
dxis represented by the function form d(y,x);
x,y:s y m b o l s ;
Output
An implicit solution to the diﬀerential equation or the global symbol Fail;
Local Variables
p,M,N,F ;
Begin
1 p:=Transform
ode(w,x,y);
2 M:=Operand(p,1);
3 N:=Operand(p,2);
4 F:=Separable
ode(M,N,x,y );
5 ifF=Fail then
6 F:=Solve
exact(M,N,x,y )
7Return(F)
End
Procedure Transform
ode(w,x,y);
Input
same asSolve
ode;
Output;
the list [ M,N];
Local Variables
v,n,M,N ;
Begin
1 v:=Rational
simplify(Operand(w,1)−Operand(w,2));
2 n:=Numerator (v);
3 M:=Coeﬃcient (n, d(y,x),0);
4 N:=Coeﬃcient (n,d(y,x),1);
5Return([M,N])
End
Figure 4.16. The MPL procedures Solve
odeandTransform
ode. (Implementa-
tion:Maple(txt),Mathematica (txt),MuPAD(txt).)
4.3 Case Study: First Order Ordinary Differential Equations 163
Procedure Solve
exact(M,N,x,y );
Input
M,N:algebraic expressions ;
x,y:s y m b o l s ;
Output
An implicit solution to the diﬀerential equation or the global symbol Fail;
Local Variables
My,Nx,d,u,F,G,g,h, hp;
Begin
1 ifN=0then
2Return(Fail)
3 elseif M=0then
4Return(y=C);
5My:=Derivative (M,y);
6Nx:=Derivative (N,x);
7 d:=My−Nx;
8 ifd=0then
9 u:= 1
10 else
11 F:=Rational
simplify(d/N);
12 ifFree
of(F,y)then
13 u:=exp(Integral(F,x));
14 d:= 0
15 else
16 G:=Rational
simplify(−d/M);
17 ifFree
of(G,x)then
18 u:= exp(Integral(G,y));
19 d:= 0;
20 ifd=0then
21 g:=Integral(u∗M,x);
22hp:=u∗N−Derivative (g,y);
23 h:=Integral(hp,y);
24Return(g+h=C)
25 else
26Return(Fail)
End
Figure 4.17. The MPLSolve
exactprocedure. (Implementation: Maple(txt),
Mathematica (txt),MuPAD(txt).)
164 4. Elementary Mathematical Algorithms
Solve
 ode(w,x,y ), wherewis the diﬀerential equation with the derivative
symbol
dy
dx
represented by the function form13d(y,x).
A tl i n e1 ,w ei n v o k et h e Transform
 odeprocedure which does some
preliminary manipulation of the equation and returns the list [ M,N]w i t h
the expressions M(x,y)a n dN(x,y)i n(4.32). This procedure, which is
shown in the bottom of Figure 4.16, permits some ﬂexibility in the form of
the input equation. For example, by preprocessing the equation with this
procedure we can handle equations with forms like
1−(2x+1 )d(y,x)=0,1−2xd(y,x)=−d(y,x),
or even
1/d(y,x)=2x+1. (4.48)
At line 1 of Transform
 odewe subtract the right side of the equation from
the left side and then simplify this expression using the Rational
 simplify
operator. Next, line 2 selects the numerator of v. For example, if wis given
by Equation ( 4.48), then after executing lines 1 and 2 we have
n:= 1−2xd(y,x)−d(y,x). (4.49)
In lines 3 and 4 we view nas a polynomial in d(y,x)a n dr e t r i e v e Mand
Nby selecting coeﬃcients of this polynomial. For example, for Equation
(4.48) the procedure returns [1 ,−2x−1].
At this point, control is returned to Solve
 odewhich obtains MandN
and then calls on Separable
 odeto ﬁnd a solution (lines 2, 3, and 4). This
procedure attempts to solve
dy
dx=−M/N
using the separation of variables technique. (The Separable
 odeprocedure
i sd e s c r i b e di nE x e r c i s e 5.) If this method fails, the Solve
 exactprocedure,
which attempts to solve the diﬀerential equation using the method of exact
equations, is invoked at line 6.
TheSolve
 exactprocedure is shown in Figure 4.17. To begin, two simple
cases are considered in lines 1-4. First, if N= 0, there is no ﬁrst derivative
13I nM a p l ea n dM u P A Dw er e p r e s e n tt h ed e r i v a t i v ew i t h d(y,x), while in Mathematica
we use d[y,x]. We use this notation instead of the derivative operator in a CAS because
the details of the Solve
odealgorithm are somewhat simpler with this representation.
This representation for the derivative is also used in Exercise 15on page 197and Exercise
15on page 240.
4.3 Case Study: First Order Ordinary Differential Equations 165
term in the equation, and so the procedure returns the global symbol Fail.
Next, ifN/negationslash=0a n dM= 0, the diﬀerential equation is equivalent to
dy
dx=0,
and so the constant solution is returned. Lines 5 and 6 compute the partial
derivatives in Expression ( 4.45) and line 7 evaluates the diﬀerence of these
derivatives so we can test if the equation is exact14. At line 8, if d=0
the equation is exact and an integrating factor is not required. Therefore,
uis assigned the expression 1 at line 9, and control is transferred to line
20. On the other hand, if at line 8 d/negationslash= 0, we assume the equation is not
exact and compute and test Fto determine if there is an integrating factor
that is free of y. Notice we apply the Rational
 simplify operator in line
11 since automatic simpliﬁcation may not remove the symbol yfromF
(see Example 4.15above). The free-of test is done in line 12, and if it is
successful we compute the integrating factor in line 13. The assignment inline 14 allows the procedure to proceed with the solution technique in line
20. If the test in line 12 fails we compute and test Gto determine if there
is an integrating factor that is free of x(lines 18 - 19).
In line 20, if d= 0, we apply the method of exact equations (lines 21-23)
and return an implicit solution at line 24. If at line 20, d/negationslash= 0 an integrating
factor has not been found, and so we return the symbol Failin line 26.
Theory versus Practice
In a theoretical sense, a separable equation can be solved using the method
of exact equations by expressing Equation ( 4.30) in the exact form
−f(x)+1
g(y)dy
dx=0.
In practice, however, the manipulations in the procedure Transform
 ode
may transform a separable equation in exact form to a non-exact equation
that cannot be solved by Solve
 exact. This point is illustrated in the next
example.
Example 4.16. Consider the separable equation
−x
x+2+y
y+1dy
dx=0.
14Observe that dis computed in the context of automatic simpliﬁcation. Although
this context is suﬃcient when MandNare polynomials in xandy,i ti sp o s s i b l et o
construct equations where additional simpliﬁcation power is needed.
166 4. Elementary Mathematical Algorithms
For this equation, the manipulations in Transform
 odeobtainM=−yx−x
andN=xy+2ywhich gives a diﬀerential equation in non-exact form. In
addition, at lines 11 and 16 in Solve
 exact,w eo b t a i n F=−(x+y)/(xy+
2y) which is not free of yandG=−(x+y)/(xy+x) which is not free of
x. Therefore, Solve
 exactcannot ﬁnd an integrating factor and so it cannot
ﬁnd a solution to the equation. /square
Unfortunately, there are other (non-separable) exact equations that
loose their exactness in Transform
 odeand cannot be solved with
Solve
 exact(see Exercise 3).
Appraisal of the Algorithm
Given appropriate input, the Solve
 odealgorithm ﬁnds the general solution
to many ﬁrst order diﬀerential equations found in textbooks on ordinary dif-
ferential equations. In addition, another approach for the integrating factor
and special techniques for homogeneous equations and Bernoulli equationsthat extend the capacity of the algorithm are described in Exercises 4,6,
and Exercise 16on page 241. However, compared to the diﬀerential equa-
tion solver found in a CAS, the algorithm is quite limited. The operators
in these systems include additional techniques for many special forms and
other general techniques
15.
In some cases the implicit solution that is found by our algorithm does
not describe all solutions to the diﬀerential equation.
Example 4.17. Consider the diﬀerential equation
dy
dx=2xy2(4.50)
given in Example 4.10. Our algorithm ﬁnds the solution in the form −x2−
1/y=Cwhich has the explicit form y=−1/(x2+C). Observe that y=0
is also a solution of the diﬀerential equation, but does not ﬁt the generalpattern. This solution, which is not found by our algorithm, is called a
singular solution of the diﬀerential equation. /square
In order for the MPL algorithm to produce an appropriate result, the
input diﬀerential equation must have a form that can be analyzed correctly
15In the Maple system, to see the methods used by the dsolve command, assign
infolevel[dsolve] := 3 . Try this for the diﬀerential equation
dy
dx=x+y+4
x−y−6
that cannot be solved by the algorithm in this section (including the additional tech-
niques in the exercises), but which can be solved by Maple.
4.3 Case Study: First Order Ordinary Differential Equations 167
by the Transform
 odeprocedure. A suitable form is one that can be trans-
formed by the operations in lines 1 and 2 of this procedure to a form where
the actions of the Coeﬃcient operator in lines 3 and 4 are well-deﬁned and
able to obtain the entire structure of the equation. If this is not so, theoutput of the algorithm may be meaningless. For example, for the equation
/parenleftbiggdy
dx/parenrightbigg1/2
+x=y,
the expression n=(d(y,x))∧(1/2)+x−yat line 2 is not a polynomial in
d(y,x) and so the coeﬃcient operations in lines 3 and 4 are undeﬁned. In
addition, for diﬀerential equations that contain higher order derivatives oran integer power of a derivative, the coeﬃcient operations may be deﬁned
but the output is meaningless since the algorithm does not apply to equa-
tions that include these forms. It is possible to modify Transform
odeso
that is does a more thorough analysis of the input equation to determine
if the equation has an appropriate form (see Exercise 14on page 240).
Exercises
1. Consider the diﬀerential equation
(2y−x2)+(2x−y2)dy
dx=0.
Solve the equation using the algorithm in the text.
2. Consider the diﬀerential equation ( y−1/x)dy
dx+y/x2=0 .
(a) Show that the equation is exact.
(b) Show that the manipulations in the Transform
odeprocedure trans-
form the equation to a non-exact equation.
(c) Show that the Solve
exactprocedure can ﬁndthe solution to the new
equation obtained in part (b) by ﬁnding an integrating factor.
3. Consider the diﬀerential equation1
x3y2+W1
x2y3+3y}dy
dx=0.
(a) Show that the equation is exact.
(b) Show that the manipulations in the Transform
odeprocedure trans-
form the equation to a non-exact equation.
(c) Show that the Solve
odeprocedure is unable to solve this equation
because it is unable to ﬁnd an integrating factor for the equation inpart (b). (However, see Exercise 4.)
168 4. Elementary Mathematical Algorithms
4. Let R=(∂M/∂y −∂N/∂x)/(N·y−M·x)andsupposethat Ris afunction
of the product xy. In this case, it can be shown that for z=xy,
u(x,y)=e xpW
R(z)dz}
is an integrating factor16. For example, for the diﬀerential equation
y+(x+3x3y4)dy
dx=0,x >0,y >0,
we have R=−3/(xy)=−3/zandu=1/(xy)3.E x t e n dt h e Solve
exact
procedure so that it determines when this integrating factor is appropriateand when this is so, uses it to ﬁnd a solution. Test the procedure on the
above equation. Hint:LetS=Substitute (R, x=z/y).IfRhas the proper
form, then Sis free of y.
5. Give a procedure Separable
ode(M,N,x,y ) that tries to determine if a
diﬀerential equation ( 4.32) can be transformed to the form of Equation
(4.30),and,whenthisisso, obtainsanimplicit solutionusingtheseparable
approach. If this technique does not apply, return the global symbol Fail.
Hint:TheSeparate
variables procedure described in Exercise 13on page
152is useful in this exercise.
6. A diﬀerential equation that can be transformed to the form
dy
dx=f(y/x) (4.51)
is called ahomogeneous17diﬀerential equation. For example, the equation
dy
dx=e x p ( y/x)+y/x
is homogeneous. A homogeneous diﬀerential equation can be solved by
deﬁning a new variable z=y/xand transforming the diﬀerential equation
to one in terms of z.U s i n gt h er e l a t i o n y=xz,w eh a v e
dy
dx=xdz
dx+z
and Equation ( 4.51) becomes
dz
dx=(f(z)−z)/x. (4.52)
This equation can be solved by separating the variables xandz. Then,
we obtain the solution to Equation ( 4.51) by substituting z=y/xinto the
solution to Equation ( 4.52). Give a procedure Homogeneous (M,N,x,y )
16See Simmons [ 87], Exercise 1 on page 59.
17The term homogeneous has a number of meanings with regard to diﬀerential equa-
tions. For example, two diﬀerent meanings are given in Exercises 6and7.
4.3 Case Study: First Order Ordinary Differential Equations 169
that determines if a ﬁrst order diﬀerential equation ( 4.32) is homogeneous
and, if so, solves the equation using the approach outlined above. If the
equation is not homogeneous, return the global symbol Fail.Hint:First,
represent the diﬀerential equation in the form
dy
dx=−M/N,
and let r=Substitute (f, y=zx). Ifris free-of x, the original equation is
homogeneous. Note that the equation
dy
dx=x+y
x−y
is homogeneous (dividethenumerator anddenominator by x). Inthis case
r=(x+xz)/(x−xz), and so we must apply a Rational
simplifyoperator
torto remove the x.
7. Consider the second order linear diﬀerential equation
ad2y
dx2+bdy
dx+cy=f, (4.53)
where a,b,a n d care rational numbers and fis analgebraic expression
that is free of y.
(a) If f= 0, the equation is called a homogeneous17equation and two
linearly independent solutions to the diﬀerential equation y1andy2
are obtained as follows: let D=b2−4ac.I fD>0, then
y1=e xp (( −b+√
D)/(2a)x),y 2=e xp(( −b−√
D)/(2a)x).
IfD=0 ,the n
y1=e xp ( −b/(2a)x),y 2=xexp(−b/(2a)x).
IfD<0, then
y1=e x p ( −b/(2a)x)s i n (√
−D/(2a)x),
y2=e x p ( −b/(2a)x)cos(√
−D/(2a)x).
Give a procedure
Homogeneous
 2(a,b,c,x)
that returns the list [ y1,y2].
(b) A particular solution ypto Equation ( 4.53) is obtained using the
methodvariation of parameters . Using this technique, yp=v1y1+
v2y2where y1andy2are the two linearly independent solutions to
the homogeneous equation (described above) and the derivatives v/prime
1
andv/prime
2satisfy the linear system
v/prime
1y1+v/prime
2y2=0,v/prime
1y/prime
1+v/prime
2y/prime
2=f/a.
170 4. Elementary Mathematical Algorithms
The expressions v1andv2are obtained from their derivatives by
integration. Giveaprocedure Variation
of
param(y1,y2,f,a,x)that
obtains yp.
(c) The general solution to the diﬀerential equation is given by
y=dy1+ey2+yp, (4.54)
where dandeare symbols that represent arbitrary constants. Give a
procedureSolve
ode
2(a,b,c,f,x,y )thatobtainsthegeneralsolution
toEquation( 4.53). Youshouldreturntheresultasanequation y=u
where uis the expression on the right side of Equation ( 4.54). A
related operator is considered in Exercise 15on page240.
8. See Exercise 14on page240and Exercise 16on page241.
Further Reading
4.2MPL’s Algorithmic Language. TheTaylorseriessolutiontoadiﬀerential
equation described in Exercise 17on page154is discussed in Zwillinger [ 109],
Section140. SeeSconzoetal. [ 86]foradiscussionoftheclassicalhandcalculation
ofFandGseries (see Exercise 18on page155) and a summary of the results
obtained with a CAS.
4.3Case Study: Solution ofFirst Order Ordinary Diﬀerential Equa-
tions.The techniques used in this section are described in Simmons [ 87], Boyce
and DiPrima [ 12], and Derrick and Grossman [ 32]. Zwillinger [ 109]a n dM ur p h y
[72] describe manytechniquesfor ﬁndinganalytical solutions todiﬀerentialequa-
tions. PostelandZimmermann[ 81]summarizestechniquesforsolvingdiﬀerential
equations in a computer algebra context.
5
Recursive Algorithms
In this chapter we examine how recursion is used to implement algorithms
in computer algebra. We begin, in Section 5.1, by describing how a sim-
ple recursive procedure is implemented by a CAS. In Section 5.2,w eg i v e
recursive procedures for a number of operators and describe an approach
using transformation rules that provides a simple way to implement some
recursive operations. Finally, in Section 5.3we describe a recursive algo-
rithm for a simple version of the Integral operator that utilizes some basic
integration rules together with the substitution method.
5.1 A Computational View of Recursion
In Chapter 3we gave the following recursive deﬁnition for the factorial
operation:
n!=/braceleftbigg1, ifn=0 ,
n·(n−1)!,ifn>0.(5.1)
Forn= 4, the computation based on this deﬁnition ( 5.1) proceeds as
follows:
4! = 4(3!) = 4(3(2!)) = 4(3(2(1!))) = 4(3(2(1(0!))))
= 4(3(2(1(1)))) (5.2)
=2 4.
To perform the calculation, we repeatedly apply ( 5.1)u n t i ln=0i se n -
countered. Once this point is reached, 0! is replaced by the value 1, and
the numerical computation proceeds as indicated by the parentheses in the
second line of Equations ( 5.2).
171
172 5. Recursive Algorithms
Procedure Rec
fact(n);
Input
n: non-negative integer;
Output
n!;
Local Variables
f;
Begin
1 ifn=0then
2 f:= 1
3 else
4 f:=n∗Rec
fact(n−1)
5Return(f)
End
Figure 5.1. An MPL recursive procedure for n!. (Implementation: Maple(txt),
Mathematica (txt),MuPAD(txt).)
Figure 5.1shows an MPL recursive procedure that performs this calcu-
lation. For the case n>0, the procedure calls on itself (line 4) to perform
a “simpler” version of the calculation. A procedure that calls on itself di-
rectly (as in this example) or indirectly through a sequence of proceduresis called a recursive procedure .T h ec a s e n= 0 (lines 1, 2) is called a ter-
mination condition for the procedure, since it is deﬁned directly and does
not require further calls on Rec
fact. For each positive integer n,t h ec a l -
culation is eventually reduced to the termination condition which stops the
recursion. Each recursive procedure must have one or more terminationconditions.
Let’s trace the execution of the procedure in response to the evaluation
ofRec
fact(4) from the interactive mode. When the procedure is invoked,
a CAS allocates a block of computer memory that includes storage loca-tions for the local variable f, the input variable n, and the next statement
executed by the system once Rec
factis done. The storage allocation for
Rec
fact(4) (before the calculation in line 4) is shown in Figure 5.2(a). At
this point, the local variable fhas not been assigned, and the “next state-
ment executed” refers to the interactive mode that invoked the procedure
and will display the result once the operation is done.
The actual calculation is done in line 4. But before this can be done, we
need the value for Rec
fact(3), and this requires another call on the pro-
cedure. To invoke Rec
fact(3), a CAS again allocates a block of memory
5.1. A Computational View of Recursion 173
n
f
next statement
executed
4
 interactive
mode
(a) The storage allocation stack for Rec
fact(4)
before calculation on line 4.
n
f
next statement
executed
3
 Rec
fact, line 4
(n=4c a s e )
4
 interactive
mode
(b) The storage allocation stack for Rec
fact(3)
andRec
fact(4). The local variable fhas not
been assigned a value in either block.
n
f
next statement
executed
0
1
Rec
fact, line 4
(n=1c a s e )
1
 Rec
fact, line 4
(n=2c a s e )
2
 Rec
fact, line 4
(n=3c a s e )
3
 Rec
fact, line 4
(n=4c a s e )
4
 interactive
mode
(c) The storage allocation stack for
the sequence of Rec
factprocedure
calls before the recursion unwinds.
Figure 5.2. The storage allocation stack for the procedure Rec
factat various
points in the computation of 4!.
to store the information associated with this procedure call. Figure 5.2(b)
illustrates the memory allocation for Rec
factat this point in the calcula-
tion. There are now two separate blocks of memory, one for the current
casen= 3 and one for the previous case n= 4 which is not yet done and
remains in memory. Notice that each block has its own storage locations
for the input variable nand the local variable f. In the computer’s mem-
ory, these two blocks reside in an internal data structure known as a stack.
174 5. Recursive Algorithms
Brieﬂy, a stack is a data structure for which data (or blocks of data) can
only be inserted or removed from the top of the stack1.In t h i s c a s e , t h e
top of the stack ( n= 3) contains the active version of Rec
fact,a n dl o w e r
levels of the stack contain previous versions of Rec
fact, which have been
invoked but are not yet done. For n=3 ,t h el o c a lv a r i a b l e fhas not been
assigned, and “next statement executed” refers to line 4 in the previous
version Rec
fact(4) which invoked Rec
fact(3).
Now, to compute Rec
fact(3), we need the value of Rec
fact(2), which
means we again invoke Rec
factand assign yet another block of memory
to the procedure. To complete the calculation, we continue invoking the
procedure for successively smaller integer values until the termination con-
ditionn= 0 is reached. The memory allocation stack at this point is shown
in Figure 5.2(c). Observe that the currently active version ( n=0 )i sa tt h e
top of the stack, and the other levels of the stack represent the previous
procedure calls that led to this place in the calculation. At this point, thevariablef(for then= 0 case) is assigned the value 1 (with lines 1, 2),
and this value is returned as the value of Rec
fact(0). Once this is done,
the block of memory allocated for Rec
fact(0) is no longer needed and is
removed from the top of the stack. Control is now transferred back to line
4i nRec
fact(1) which performs the multiplication and assignment:
f:= 1∗Rec
fact(0)→1∗1→1 (calculation in Rec
fact(1)).
This value is returned to Rec
fact(2) which invoked Rec
fact(1), and the
memory allocated for Rec
fact(1) is removed from the top of the stack.
The recursive process continues to unwind in this fashion, performing the
multiplication and assignment in line 4 for the diﬀerent versions of Rec
fact:
f:= 2 ∗Rec
fact(1)→2∗1→2 (calculation in Rec
fact(2)),
f:= 3 ∗Rec
fact(2)→3∗2→6 (calculation in Rec
fact(3)),
f:= 4 ∗Rec
fact(3)→4∗6→24 (calculation in Rec
fact(4)).
In each case, once an expression has been returned by Rec
fact(n−1) to
the calling procedure Rec
fact(n) (or the interactive mode), the block of
memory associated with Rec
fact(n−1) is removed from the top of the
stack. After the last calculation, the expression 24 is returned as the value
ofRec
fact(4).
TheRec
factprocedure is presented to illustrate simply what is meant
by a recursive procedure and to show how it is evaluated by a CAS. In
practice, the recursive procedure for n!i sl e s se ﬃ c i e n ti nt e r m so fc o m p u t e r
time and memory than a non-recursive iterative procedure.
1A useful metaphor for a stack data structure is a stack of food trays. For safety’s
sake, we always remove a tray from the top of the stack and add a tray to the stack byplacing it on the top.
5.1. A Computational View of Recursion 175
Infinite Recursive Loops
Ac a l lt o Rec
fact(n)t e r m i n a t e sa sl o n ga s nis a non-negative integer.
However, if nis a negative integer (or any expression that does not evaluate
to a positive integer), the termination condition in line 1 is never satisﬁed,
and so the process does not terminate. For example, when n=−1, we
obtain the inﬁnite sequence of procedure calls:
Rec
fact(−1),Rec
fact(−2),Rec
fact(−3),....
Since this problem is similar to the inﬁnite loops that can arise with itera-
tion structures, it is called an inﬁnite recursive loop .
Exercises
1. Let nbe a positive integer. The harmonic number H(n) is deﬁned by the
sum:
H(n)=1+1 /2+···+1/n.
Give a recursive procedure for H(n). The procedure should not use a for
structure or a whilestructure.
2. TheFibonacci numbersequence f0,f1,f2,...is deﬁnedusingtherecursive
deﬁnition:
fn=k1, whenn=0o r n=1 ,
fn−1+fn−2,whenn>1.(5.3)
(a) Compute f4.
(b) HereisarecursiveMPLprocedurethatcomputestheFibonaccinum-
bers:
Procedure Fibonacci (n);
Input
n: non-negative integer;
Output
fn;
Local Variables
f,g,r;
Begin
1 ifn=0orn=1then
2 r=1
3 else
4 f:=Fibonacci (n−1);
5 g:=Fibonacci (n−2);
6 r:=f+g;
7 Return(r)
End
176 5. Recursive Algorithms
Trace the ﬂow of the Fibonacci procedure for n= 4 showing all
changes in the storage allocation stack during the course of the com-
putation.
(c) Give a non-recursive procedure that uses iteration to compute fn.
(d) TheFibonaccicomputationisnotaparticularlygooduseofrecursion
since the non-recursive approach requires fewer additions than the
recursive approach. Explain why this is so.
3. Let Sbe a non-empty set that contains nexpressions, and for 0 ≤k≤n
letC(n,k) be the number of distinct subsets of size kofS. We can obtain
C(n, k) using the familiar combination formula
C(n, k)=n!
k!(n−k)!.
C(n, k) can also be obtained recursively using the recurrence relation
C(n, k)=k1, ifk=0o r k=n,
C(n−1,k−1)+C(n−1,k),otherwise.(5.4)
Give a procedure for C(n,k) that is based on Expression ( 5.4). Do not use
the factorial operation in this procedure.
5.2 Recursive Procedures
In this section we give a number of examples that illustrate the possibili-
ties and limitations of recursion as an algorithmic approach for computeralgebra.
TheComplete
 sub
expressions Operator
In this example we describe a procedure that obtains the set of complete
sub-expressions of an expression u. Since the solution of this problem
involves a systematic traversal of the expression tree for u, a recursive
procedure is the natural choice.
An MPL procedure that performs this operation is given in Figure 5.3.
Lines 1-2, which apply to atomic expressions, provide the termination con-dition for the recursion. For compound expressions, the statements in lines
4-7 obtain the set of sub-expressions by forming the set union of {u}and
the sets of sub-expressions of the operands of u.
Let’s see how the procedure works for u=a∗(x+1 )+3 ∗cos(y),
which is represented by the expression tree in Figure 5.4. The ﬂow of the
computation in response to the statement
Complete
sub
expressions (a∗(x+1 )+3 ∗cos(y)) (5.5)
5.2. Recursive Procedures 177
Procedure Complete
 sub
expressions (u);
Input
u:amathematical expression ;
Output
the set of complete sub-expressions of u;
Local Variables
s,i;
Begin
1 ifKind(u)∈{integer ,symbol ,real}then
2Return({u})
3 else
4 s:={u};
5 fori:= 1toNumber
of
operands(u)do
6 s:=s∪Complete
 sub
expressions (Operand(u,i));
7Return(s)
End
Figure 5.3. An MPL procedure that ﬁnds the set of complete sub-expressions of
u. (Implementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
 
 
  ❅
❅
❅❅
❅
❅
❅
❅ 
 
 
 
❅
❅ 
 
x ycos 3 +
1a+
∗∗
Figure 5.4. An expression tree for a∗(x+1)+3 ∗cos(y).
i ss h o w ni nF i g u r e 5.5. The arrows that point downward on solid lines
represent a recursive call to a procedure, and those that point upward on
dashed lines represent a return to the calling procedure. The expressions at
the nodes represent the input expression uon various calls of the procedure,
178 5. Recursive Algorithms
a{a∗(x+1 ),a ,
{1}
1{x}x+1a∗(x+1 )
{x+1,x , 1}{a∗(x+1 )+3 ∗cos(y),a∗(x+1 ),
x+1,x , 1}cos(y),y}a, x +1,x , 1,3∗cos(y),3,Interactive Mode
a∗(x+1 )+3 ∗cos(y)
x{3∗cos(y),3,cos(y),y}
3∗cos(y)
{3}
3{cos(y),y}{a}
ycos(y)
{y}
Figure 5.5. The sequence of recursive calls that obtains the set of complete
sub-expressions of a∗(x+1)+3 ∗cos(y).
and the sets of expressions to the right of the dashed lines above the nodes
represent the output of that call.
By tracing the path along the solid and dashed lines, we observe the
entire path of the computation. For example, to evaluate Expression ( 5.5),
the procedure must ﬁrst evaluate
Complete
 sub
expressions (a∗(x+1 ) ), (5.6)
Complete
 sub
expressions (3∗cos(y)). (5.7)
Observe that the entire computation associated with ( 5.6) is done before
(5.7) is invoked, and to obtain ( 5.6), the procedure must evaluate
5.2. Recursive Procedures 179
Complete
 sub
expressions (a),
Complete
 sub
expressions (x+1 ).
Continuing in this fashion, we systematically build up the set of sub-
expressions of a∗(x+1 )+3 ∗cos(y)t oo b t a i n
{a∗(x+1 )+3 ∗cos(y),a∗(x+1 ),a,x+1,x,1,3∗cos(y),3,cos(y),y}.
TheFree
 ofOperator
The procedure for the Free
of(u,t) operator (see Deﬁnition 3.28, page 110)
is another example that utilizes the recursive tree structure of an expres-
sion. Recall that the operator returns falsewhentis syntactically equal
to a complete sub-expression of u, and otherwise returns true.
An MPL procedure for the Free
ofoperator is given in Figure 5.6.L i n e s
1 and 3 serve as terminating conditions for the procedure. If the condition
in line 3 istrue, the procedure returns truebecause the condition in line
1i sfalseandudoes not have any operands. The loop (lines 7-10) applies
Procedure Free
of(u,t);
Input
u,t:mathematical expressions ;
Output
trueorfalse;
Local Variables
i;
Begin
1 ifu=tthen
2Return(false)
3 elseifKind(u)∈{symbol ,integer ,real}then
4Return(true)
5 else
6 i:= 1;
7 while i≤Number
of
operands(u)do
8 ifnotFree
ofOperand(u,i),t)then
9 Return(false);
10 i:=i+1;
11Return(true)
End
Figure 5.6. An MPL procedure for the Free
ofoperator. (Implementation:
Maple(txt),Mathematica (txt),MuPAD(txt).)
180 5. Recursive Algorithms
the procedure recursively to each operand of u. Notice when a recursive
call on some operand returns false, there is no need to check the remaining
operands and so the value falseis returned immediately. If all operands of
ua r ef r e eo f t, the procedure returns true(line 11).
In the current form, the Free
ofoperator cannot determine if an expres-
sion is free of an algebraic operator or function name. A modiﬁcation ofthe procedure that handles these cases is described in Exercise 1(b).
A useful extension of the Free
ofoperation is to check if uis free of
each expression in a set (or list) Sof expressions. The procedure for
Set
free
of(u,S) that performs this operation is a simple modiﬁcation of
the one for Free
of(u,t). The details of this extension are left to the reader
(Exercise 1(c)).
Pattern Matching, the Linear
 form Operator
Many operations in mathematics depend on recognizing that an expression
has a particular form. In this example we describe Linear
 form(u,x), a
simple pattern-matching procedure that checks if an algebraic expression
uhas the form ax+b, where the expressions aandbare free of x.W h e n
this is so, the procedure returns the list [ a,b], and otherwise returns the
global symbol Fail. We interpret this form in a broad sense to include
more involved sums (e.g., ax+2x+b+3 )a sw e l la se x p r e s s i o n st h a ta r e
not sums (e.g., 3, x,2x,x/a).
An MPL procedure for this operation is shown in Figure 5.7.L i n e s1 - 4
handle two simple cases that have the required form. Lines 5-11 check theform of a product, where lines 8-9 check if the symbol xis an operand of
the product. In lines 12-21, recursion is used to check if the operands of a
sum have the proper form. To do this, we apply the operator to the ﬁrst
operand of the sum (line 13) and the remaining operands (line 17), and
then combine the results (line 21). If some operand of the sum does nothave the proper form, the symbol Failis returned (lines 15, 19). Lines 22-
25 handle other expression types (e.g., powers, function forms, factorials),
which only have the proper form when they are free of x.
There are two places in this procedure where recursion is used, lines 13
and 17. We can eliminate this recursion by using an iteration structure tocheck the operands of a sum and by repeating the statements for the tests
in lines 1-11 and 22-25. Although recursion can be eliminated here, it is
used as a matter of convenience to obtain a shorter procedure.
Pattern-matching procedures are given for quadratic polynomials in
Exercise 8, and for more general polynomials in Chapter 6.
5.2. Recursive Procedures 181
Procedure Linear
form(u,x);
Input
u:a nalgebraic expression ;
x:as y m b o l ;
Output
the list [ a,b], where aandbarealgebraic expressions , or the global
symbol Fail;
Local Variables
f,r;
Begin
1 ifu=xthen
2Return([1,0])
3 elseifKind(u)∈{symbol ,integer ,fraction }then
4Return([0,u])
5 elseifKind(u)=” ∗”then
6 ifFree
of(u,x)then
7 Return([0,u])
8 elseifFree
of(u/x, x)then
9 Return([u/x,0])
10 else
11 Return(Fail)
12 elseifKind(u)=”+” then
13 f:=Linear
 form(Operand(u,1),x);
14 iff=Fail then
15 Return(Fail)
16 else
17 r:=Linear
 form(u−Operand(u,1),x);
18 ifr=Fail then
19 Return(Fail)
20 else
21 Return([Operand(f,1)+Operand(r,1),
Operand(f,2)+Operand(r,2)])
22 elseifFree
of(u,x)then
23Return([0,u])
24 else
25Return(Fail)
End
Figure 5.7. An MPL procedure that determines if uis a linear expression in x.
(Implementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
182 5. Recursive Algorithms
Transformation Rule Sequences, the Derivative Operator
In this example we describe an algorithm that computes the derivative of
a function. Since the diﬀerentiation rules for sums, products, powers, and
composite functions obtain the derivative of an expression in terms of thederivatives of its operands, the algorithm is recursive.
For this example, we describe the algorithm using a transformation
rule sequence rather than an MPL procedure. The description is somewhat
simpler in this format, and the transformation rules can be easily trans-
lated into an MPL procedure. In addition, some CAS languages have the
capability to implement transformation rules directly as a program.
Letube an algebraic expression and let xbe a symbol. The operator
Derivative (u,x), which evaluates the derivative of uwith respect to x,i s
deﬁned by the following transformation rules:
DERIV-1. Ifu=x,t h e n Derivative (u,x)→1.
DERIV-2. Ifu=v
w,t h e n
Derivative (u,x)→ (5.8)
w∗vw−1∗Derivative (v,x)+Derivative (w,x)∗vw∗ln(v).
This rule applies to expressions that are powers and accounts for expres-
sions where either vorwmay depend on x. ( T h er u l ei sd e r i v e du s i n g
logarithmic diﬀerentiation (Exercise 12).) Since the Derivative operator
appears on the right side of the rule, DERIV-2 is recursive. When wis free
ofx, the rule reduces (with automatic simpliﬁcation) to the familiar power
rule
d(vw)
dx=w·vw−1d(v)
dx.
DERIV-3. Supposeuis a sum and let v=Operand (u,1) andw=u−v.
Then
Derivative (u,x)→Derivative (v,x)+Derivative (w,x).
DERIV-4. Supposeuis a product and let v=Operand (u,1) andw=
u/v.T h e n
Derivative (u,x)→Derivative (v,x)∗w+v∗Derivative (w,x).
Rules DERIV-3 and DERIV-4 are the sum and product diﬀerentiation
rules. Again, the rules are recursive because the right side of each rule
refers to the Derivative operator. Notice that we obtain the derivative of
5.2. Recursive Procedures 183
a sum by diﬀerentiating both the ﬁrst operand and the remaining part of
the sum, which is obtained by subtracting the ﬁrst operand from uwith
automatic simpliﬁcation. A similar approach is used for a product.
A typical rule for a known function looks like the following:
DERIV-5. Ifu=s i n (v), then Derivative (u,x)→cos(v)∗Derivative (v,x).
Again, the chain rule implies the rule is recursive.DERIV-6. IfFree
of(u,x)=true,t h e n Derivative (u,x)→0.
This rule applies to integers, fractions, symbols, and compound expressions
(such asf(a)o rn!) that are free of the diﬀerentiation variable x.N o t i c e
that powers, sums, and products are not checked by this rule because they
are handled by one of the earlier rules DERIV-2, DERIV-3, or DERIV-4.For example, if bandeare symbols ( /negationslash=x), then
Derivative (b
e,x)→0
is obtained by ﬁrst applying DERIV-2, which applies DERIV-6 (recur-
sively) to both bande.
We have placed DERIV-6 at this point in the rule sequence to avoid
redundant calls on the Free
ofoperator. The reason for this has to do
with the recursive nature of Free
of. If DERIV-6 were at the beginning
of the rule sequence, then to compute the derivative (with respect to x)o f
u=( 1+a)2+x2,
the algorithm would ﬁrst check if uwere free of x, which involves the
comparison of each complete sub-expression of utoxuntil the symbol x
is found. Since this step would return false, we would next apply the sum
rule which obtains the derivative in terms of the derivatives of the two
operands (1 + a)2andx2. To ﬁnd the derivative of (1 + a)2,w ew o u l d
check (for the second time) if this expression were free of x.B y p l a c i n g
theFree
ofoperation later in the rule sequence, we avoid this redundant
calculation.
The ﬁnal transformation rule applies to any expression that is not cov-
ered by the earlier rules:
DERIV-7. Derivative (u,x)→”Derivative ”(u,x).
In other words, if none of the earlier rules apply to u, the expression is re-
turned in the unevaluated form Derivative (u,x). The Derivative operator
on the right is quoted to prevent a recursive evaluation of the operator be-
cause, without the quotes, the transformation leads to an inﬁnite sequence
184 5. Recursive Algorithms
of recursions. By including this rule, we obtain a representation for the
derivative of expressions that include undeﬁned functions such as
Derivative (f(x)∗g(x),x)→Derivative (f(x),x)∗g(x) (5.9)
+f(x)∗Derivative (g(x),x),
where the derivatives of f(x)a n dg(x) remain in unevaluated form. (See
Exercise 13(c) for an extension of this situation.)
Notice that the diﬀerentiation quotient rule is not included in our rule
sequence because we assume that automatic simpliﬁcation transforms quo-
tients to products or powers. In some instances, however, the quotient rule
returns the derivative of a quotient in a more useful form. Since it is notdiﬃcult to check when a product is a quotient, this is a useful extension of
the algorithm (Exercise 13(b)).
The DERIV rules are an example of a transformation rule sequence.
When describing an algorithm in this way, we assume that a rule is checked
only when all earlier rules do not apply. This approach simpliﬁes the pre-sentation because conditions that are handled by earlier rules need not be
repeated (in a negative sense) in a later rule.
It is a simple matter to express the DERIV rule sequence as an MPL
procedure. We leave the details of the procedure to the reader (Exercise 13).
Rule-Based Programming
Some CAS languages have the capability to implement a transformation
rule sequence directly.
Mathematica. Figure 5.8shows an implementation of the DERIV rules in
the Mathematica pattern matching language. Since Derivative is a pre-
deﬁned operator in this system, we have used the name Deriv instead.
Deriv[x_, x_ ] := 1;
Deriv[ v_^w_, x_] := w*v^(w-1)*Deriv[v,x] + Deriv[w,x]*v^w*Log[v];
Deriv[ u_ + v_, x_ ] := Deriv[u,x] + Deriv[v,x];Deriv[ u_ * v_, x_ ] := Deriv[u,x]*v + Deriv[v,x]*u;
Deriv[Sin[u_], x_ ] := Cos[u]*Deriv[u,x];
Deriv[u_,x_] := 0 /; FreeQ[u,x] === True;
Figure 5.8. Arule-basedprogramforthe Derivative operatorintheMathematica
pattern matching language. Since Derivative is a predeﬁned operator in the
Mathematica language, we have used the name Derivinstead. (Implementation:
Mathematica (nb).)
5.2. Recursive Procedures 185
In Mathematica, an underscore character (
 ) after a variable name
means the variable can stand for an arbitrary expression. The symbol
/;(in the last line) stands for the word “whenever,” and so the free of
condition following this symbol must hold for the rule to apply. Mathe-matica keeps re-applying the rules to an expression until changes do not
occur. For this reason, even though the sum and product rules are listed
with only two operands, the operator can diﬀerentiate sums or productswith more than two operands as well. Notice that we have omitted the
last rule DERIV-7 because if udoes not satisfy one of the input patterns,
Mathematica returns the operator in the unevaluated form Deriv[u,x] .
Once the transformation rules have been entered in a Mathematica
session, they are applied during evaluation whenever the Deriv operator
appears in an expression. In Mathematica, the execution order for rules
does not depend on the order in which they are listed. Rather, the system
applies more speciﬁc rules before it applies more general rules. For thisexample, however, the rule that involves the FreeQ operator is checked
after the other rules.
Maple. Figure 5.9shows an implementation of the DERIV rules in the
Maple pattern matching language. Notice that each symbol ( x,u,v,a n d
w) is followed by two colons ( ::) and one of the designations
name,algebraic ,nonunit(algebraic)
which deﬁnes the class of expressions that can replace the variable. The
form nonunit(algebraic) is included so that an expression is not matched
define(Derivative,
Derivative(x::name,x::name)=1,
Derivative(v::nonunit(algebraic)^w::nonunit(algebraic),x::name)
=w*v^(w-1)*Derivative(v,x)+Derivative(w,x)*v^w*ln(v),
Derivative(u::nonunit(algebraic)+v::nonunit(algebraic),x::name)
=Derivative(u,x)+Derivative(v,x),
Derivative(u::nonunit(algebraic)*v::nonunit(algebraic),x::name)
=Derivative(u,x)*v+Derivative(v,x)*u,
Derivative(sin(u::algebraic),x::name)=cos(u)*Derivative(u,x),
conditional(Derivative(u::algebraic,x::name)
=0,_type(u,freeof(x)))
);
Figure 5.9. A rule-based program for the Derivative operator in the Maple
pattern-matching language. (Implementation: Maple(mws).)
186 5. Recursive Algorithms
by an inappropriate rule. For example, this form is included in the product
rule so that the Maple’s pattern matching algorithm does not consider the
expression sin( x) to be a product 1 ∗sin(x). (Without this designation, the
execution of Derivative (sin(x),x) results in an inﬁnite recursive loop.)
The nonunit designation also permits sums and products in rules 3 and 4
to have more than two operands. The conditional statement in the last
rule implements the Free
oftest in DERIV-6 .N o t i c et h a t DERIV-7 is not
needed because when udoes not match any of the rules, Derivative (u,x)
is returned in unevaluated form.
In Maple, the transformation rules are checked in the order they are
listed, and once the rules have been entered in a session, the system createsa recursive procedure with the name Derivative .
Rule-based programming usually gives smaller programs because much
of the program logic is handled by the CAS’s pattern matching program.
On the other hand, because program logic is handled by the system, we give
up some control of the process. In addition, the approach requires a goodunderstanding of the workings (and limitations) of the pattern matching
program, and, in some cases, it can be diﬃcult (or even impossible) to
express a transformation in the required form.
TheTrig
 substitute Operator
Letube an algebraic expression. The operator Trig
substitute (u)f o r m sa
new expression, with all instances of the functions tan, cot, sec, and csc in
ureplaced by the equivalent representations in terms of sin and cos.
The operator utilizes the four transformation rules:
TRIGSUB-1. tan(v)→sin(v)
cos(v).
TRIGSUB-2. cot(v)→cos(v)
sin(v).
TRIGSUB-3. sec(v)→1
cos(v).
TRIGSUB-4. csc(v)→1
sin(v).
The easiest way to obtain these transformations is with the rule-based
operations that are available in some CAS languages. It is instructive,
however, to obtain the transformations with MPL procedures. We describe
two approaches, one based on the Construct operator described in Section
3.2and the other based on the Mapoperator described below.
5.2. Recursive Procedures 187
Procedure Trig
substitute (u);
Input
u:a nalgebraic expression ;
Output
a new expression, with all instances of the functions
tan, cot, sec, and csc replaced by the representationsusing sin and cos;
Local Variables
s,i,L;
Begin
1 ifKind(u)∈{integer ,fraction ,symbol }then
2Return(u)
3 else
4 L:= [ ];
5 fori:= 1toNumber
of
operands(u)do
6 L:=Join(L,[Trig
substitute (Operand(u,i))]);
7 ifKind(u)∈{tan,cot,sec,csc}then
8 s:=Operand(L,1);
9 ifKind(u)=ta n then
10 Return(sin(s)/cos(s));
11 ifKind(u)=c o t then
12 Return(cos(s)/sin(s));
13 ifKind(u)=s e c then
14 Return(1/cos(s));
15 ifKind(u)=c s c then
16 Return(1/sin(s))
17 else
18 Return(Construct (Kind(u),L))
End
Figure 5.10. An MPL procedure for Trig
substitute that uses the Construct
operator. (Implementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
ATrig
substitute procedure2that uses the Construct operator is given
in Figure 5.10. Lines 1-2 provide a termination condition for the recursion.
In lines 4-6, we construct a list Lthat contains the expressions obtained
2This procedure will not work in the Mathematica system using this system’s trigono-
metric functions ( Sin[x], Cos[x], Tan[x], etc.) because the automatic simpliﬁcation
rules cancel the operations of the procedure. For example, in this system, automatic
simpliﬁcation obtains the inverse transformation replacing Sin[x]/Cos[x] with Tan[x] .
To implement the procedure, it is necessary to override the automatic simpliﬁcationrules by using diﬀerent names for these functions. One possibility is to use functionnames that begin with lower case characters. (Implementation: Mathematica (nb).)
188 5. Recursive Algorithms
by applying Trig
substitute to each operand of u. Lines 7-16 apply the
TRIGSUB transformations where, for these cases, the operand list Lhas
only one operand. For all other compound expressions, we construct (line
18) a new expression using the same main operator as uand the operands
ofL.
For expressions whose main operator is an algebraic operator (+, ∗,∧,
or !), it is not necessary to use the Construct operator and the iteration
structure in lines 5-6. For example, for sums we obtain the same result by
returning the expression
Trig
substitute (Operand (u,1)) + Trig
substitute (u−Operand (u,1)).
However, we have used the Construct operator because each operator re-
quires its own statement similar to this one. In addition, we must use
Construct for function forms (such as f(tan(x),sec(x)+1 ) )t h a tc a nh a v e
an arbitrary number of operands but don’t satisfy an algebraic relation.
TheMap Operator
A basic operation in the Trig
substitute procedure is the creation of a
new expression with the same main operator as uand operands that are
obtained by recursively applying the procedure to each operand of u.S i n c e
this operation occurs frequently in computer algebra, it is useful to have anMPL primitive operator that performs the operation. The Mapoperator
serves this purpose.
Definition 5.1. Letube a compound expression with
n=Number
of
operands (u),
and letF(x)andG(x,y,...,z )be operators. The Map operator has two
forms:
Map(F,u), (5.10)
Map(G,u,y,...,z ). (5.11)
The statement Map (F,u)obtains the new expression with main operator
Kind(u)and operands
F(Operand (u,1)),F(Operand (u,2)),...,F (Operand (u,n)).
The statement Map (G,u,y,...,z )obtains the new expression with main
operator Kind(u)and operands
G(Operand (u,1),y,...,z ),G(Operand (u,2),y,...,z ),...,
G(Operand (u,n),y,...,z ).
5.2. Recursive Procedures 189
MPL
 Maple
 Mathematica
 MuPAD
Map(F,
 Map(F,a+b)
 Map[F,a+b]
 Map(a+b,F)
a+b)
Map(G,
 Map(G,a+b,d,e)
 Map[G[#,d,e]&,a+b]
 Map(a+b,G,d,e)
a+b,d,e)
Figure 5.11. Thesyntaxof Mapoperators inMaple, MuPAD,andMathematica.
(Implementation: Maple(mws),Mathematica (nb),MuPAD(mnb).)
Ifuis not a compound expression, the Map operator returns the global
symbolUndeﬁned .
Example 5.2. For the operator
F(x)function:=x2,
we have
Map(F,a+b)→a2+b2.
For the operator
G(x,y,z)function:=x2+y3+z4,
we have
Map(G,a+b,c,d)→G(a,c,d)+G(b,c,d)
=/parenleftbig
a2+c3+d4/parenrightbig
+/parenleftbig
b2+c3+d4/parenrightbig
=a2+b2+2c3+2d4. /square
Most CAS languages have some form of the Mapoperator (Figure 5.11).
A procedure3for trigonometric substitution that uses the Mapoperator
is given in Figure 5.12.
Computation of Legendre Polynomials
This example provides another simple example of the mechanics of recur-
sion and reveals one of its limitations.
The Legendre polynomials are the sequence of polynomials pn(x),n=
0,1,2,...that are deﬁned by the relations
p0(x)=1, (5.12)
p1(x)=x, (5.13)
pn(x)=1
n((2n−1)xpn−1(x)−(n−1)pn−2(x)),n≥2.(5.14)
3Mathematica users see footnote 2on page 187.
190 5. Recursive Algorithms
Procedure Trig
substitute
map(u);
Input
u:a nalgebraic expression ;
Output
a new expressions where all instances of the functions
tan, cot, sec, and csc are replaced by the representationsusing sin and cos;
Local Variables
U;
Begin
1 ifKind(u)∈{integer ,fraction ,symbol }then
2Return(u)
3 else
4 U:=Map(Trig
substitute
map,u);
5 ifKind(U)=ta n then
6 Return(sin(Operand(U,1))/cos(Operand(U,1)));
7 ifKind(U)=c o t then
8 Return(cos(Operand(U,1))/sin(Operand(U,1)));
9 ifKind(U)=s e c then
10 Return(1/cos(Operand(U,1)));
11 ifKind(U)=c s c then
12 Return(1/sin(Operand(U,1)))
13 else
14 Return(U)
End
Figure 5.12. AnMPLprocedurefortrigonometricsubstitutionthatusesthe Map
operator. (Implementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
The polynomials are named in honor of the French mathematician Adrien-
Marie Legendre (1752-1833), who ﬁrst used them in 1785 to study thegravitational attraction of solids of revolution. Today they have applica-
tions in numerical integration, the solution of diﬀerential equations, and
engineering.
The expression for p
n(x) is called a recurrence relation because for n≥
2,pn(x) is deﬁned in terms of the lower order polynomials pn−1(x)a n d
pn−2(x). The polynomials p0andp1serve as termination conditions for
the recursion. Using this deﬁnition, each succeeding polynomial ( n≥2) is
computed as follows:
p2(x)=1
2((2(2) −1)xp1(x)−(2−1)p0(x)) =3
2x2−1
2,
5.2. Recursive Procedures 191
p3(x)=1
3((2(3) −1)xp2(x)−(3−1)p1(x)=5
2x3−3
2x,
...
etc.
A recursive procedure for pn(x) is given in Figure 5.13. Lines 6-7 contain
recursive calls of the procedure, and line 8 contains an Algebraic
 expand
operator so that the polynomial is returned in expanded form.
Unfortunately, the Legendre procedure performs an excessive amount
of redundant calculation that makes it unsuitable for large values of n.A
trace of the recursive calls for Legendre (4,x) indicates why this is so (see
Figure 5.14). To compute Legendre (4,x), the procedure must compute re-
cursively Legendre (3,x)a n d Legendre (2,x). Observe that all recursive cal-
culations for Legendre (3,x) are done before any of the calculations for this
version of Legendre (2,x). In addition, to compute Legendre (3,x), the pro-
cedure must compute another version of Legendre (2,x)a n d Legendre (1,x).
The computation continues in this fashion until it encounters one of the
terminating conditions n=0o rn= 1. The cause of the redundant cal-
culations is apparent from the sequence of procedure calls shown in Fig-
Procedure Legendre(n,x);
Input
n: a non-negative integer;
x:as y m b o l ;
Output
pn(x);
Local Variables
f,g;
Begin
1 ifn=0then
2Return(1)
3 elseif n=1then
4Return(x)
5 else
6 f:=Legendre(n−1,x);
7 g:=Legendre(n−2,x);
8Return(Algebraic
expand((1/n)∗((2∗n−1)∗x∗f−(n−1)∗g)))
End
Figure 5.13. Computation of Legendre polynomials using recursion. (Implemen-
tation:Maple(txt),Mathematica (txt),MuPAD(txt).)
192 5. Recursive Algorithms
n=1 n=0 n=1n=2
n=1 n=0n=2n=3n=4Interactive Mode
Figure 5.14. The sequence of recursive calls for Legendre(4,x). An arrow that
points downward on a solid line represents a recursive call, and those that point
upward on a dashed line represent a return to the calling procedure.
ure5.14. Observe that there are two calls on Legendre (2,x), three calls
onLegendre (1,x), and two calls on Legendre (0,x). In each instance, the
procedure is not aware that the value is computed more than once. In gen-
eral, the number of recursive calls on the procedure increases exponentiallywithn.
For this computation, it is a simple matter to avoid the redundant cal-
culation by avoiding recursion altogether and using an iterative procedure.This is done by replacing lines 6-8 in Figure 5.13by the iteration:
f:= 1;
g:=x;
fori:= 2tondo
p:= (1/i)∗((2∗i−1)∗x∗g−(i−1)∗f;
f:=g;
g:=p;
Return (Algebraic
expand (p));
After executing the loop, pn(x) is contained in the variable p,w h i c hi s
then expanded in the last line. Although the iterative version is based on
the recurrence relation in Equation ( 5.14), it is not considered a recursive
algorithm because it does not call itself directly or indirectly.
5.2. Recursive Procedures 193
Legendre_remember := proc(x,n)
local f,g;
option remember;if n = 0 then
RETURN(1)
elif n = 1 then
RETURN(x)
else
f := Legendre_remember(x,n-1);g := Legendre_remember(x,n-2);
RETURN(expand((1/n)*((2*n-1)*x*f - (n-1)*g)))
fiend:
Figure 5.15. Computing Legendre polynomials with Maple using the option
remember . The option is also available in Mathematica and MuPAD. (Imple-
mentation: Maple(txt),Mathematica (txt),MuPAD(txt).)
Since the potential for redundant calculations occurs frequently in com-
puter algebra, it is useful to have a way to perform a calculation in a recur-
sive manner that avoids the redundant calculation. For example, the Maple
language has a feature called option remember that makes this possible (see
Figure 5.15). When this option is declared within a Maple procedure, the
system keeps a table of input/output expressions for all calls on the proce-dure. When the procedure is invoked, a check is made to see if the current
input is identical to the input of a previous procedure call. When this is so,
the output is returned from the value in the table. If the input expressionis not in the table, the output is calculated in the usual way and the new
input/output pair is stored in the table. Both Mathematica and MuPAD
also have remember options for procedures.
For the computation of Legendre polynomials, the remember option dra-
matically reduces the redundant calculation. In many situations, however,
redundant calculations can be eliminated by either avoiding recursion or by
modifying the algorithm. For example, we avoided redundant calculationswith the Derivative operator by placing the Free
ofoperation at the end of
the transformation sequence (see page 183). For this reason, the remember
feature is not used by any of the algorithms this book.
Recursive Chains
The procedures described so far are recursive because each procedure is
deﬁned directly in terms of another version of the same procedure. Recur-
194 5. Recursive Algorithms
sion may also come about indirectly. For example, suppose a procedure
u1does not call on itself directly, but calls on another procedure u2which
then calls on u1.In t h i s c a s e , u1is considered recursive because it calls
on itself indirectly through the intervening procedure u2.A ne x a m p l eo fa
recursive chain is given in the case study in Section 5.3.
Exercises
1. (a) Trace the ﬂow of the computation in response to the statement
Free
of(a(x+1)+3cos( y),x).
(b) Modify the Free
of(u, t)o p e r a t o rs ot h a ti tr e t ur n s falsewhen u
contains a target tthat is an algebraic operator or function name.
For example,
Free
of(f(x)+y, f)→false,
Free
of(y+z,”+”) →false.
(c) Give a procedure Set
free
of(u,S)t h a td e t e r m i n e si f uis free of all
expressions in a set (or list) S.T h eSet
free
ofoperator is used in
theMonomial
gpeprocedure in Figure 6.5on page227.
2. Give a procedure
Trig
free
of(u)
that returns thesymbol trueif analgebraic expression uis free of trigono-
metric functions (sin ,cos,tan,cot,sec,csc) and the symbol falseother-
wise.
3. Let ube amathematical expression . Give a procedure Symbols(u)t h a t
returns the set of symbols in u.
4. Give a procedure
Contain
parameters (u,x)
that returns trueif thealgebraic expression ucontains any symbols other
than the symbol xandfalseotherwise.
5. Let ube amathematical expression . Give a procedure
Algebraic
expression (u)
that returns trueifuis analgebraic expression andfalseif it is not
algebraic. (See Deﬁnition 3.17on page93.)
6. Let ube a polynomial in xwith rational number coeﬃcients. An eﬃcient
way to evaluate a polynomial numerically is to rewrite the polynomial ina nested form by introducing extra parenthesis. For example,
u=2x
3+3x2+4x+6=((2 x+3)x+4)x+6.
5.2. Recursive Procedures 195
In numerical methods texts, this method for evaluating a polynomial is
called Horner’s method (see Epperson [ 35]). Give a recursive procedure
Horner(u,x) that transforms a polynomial from the expanded form to the
nested form.
7. Anumerical expression uis one that is deﬁned by the rule sequence:
NUM-1. uis an integer or a fraction.
NUM-2. uis one of the symbols πore.
NUM-3. uis a compound expression with main operator +, ∗,∧,o ra
functionname(sin, f, etc.) suchthateachoperandof uisanumerical
expression.
For example, the following are numerical expressions
2+21/2,sin(3),f(3),2·π1/3,3+e.
Giveaprocedure Numerical (u)thatreturns trueifanalgebraic expression
uis a numerical expression and otherwise returns false.
8. Let ube analgebraic expression and let xbe a symbol. Give a procedure
Quadratic
form(u,x)t h a td e t e r m i n e si f uhas theform ax2+bx+cwhere
a,b,a n dcare free of x.I fuhas the proper form return [ a,b,c], otherwise
return Fail. Interpret this form in a broad sense to include more involved
sums (e.g., ax2+2x2+bx+3x+4 )a sw e l la se x p r e s s i o n st h a ta r en o t
sums (e.g., x2,2x,x/a,ab, and 3). The point of this exercise is to imple-
ment the procedure in terms of primitive operators ( Kind,Operand,e t c . )
and structure-based operators ( Free
of), and not in terms of polynomial
operators (Degree,Coeﬃcient ).
9. Let ube analgebraic expression . Deﬁne the tree-sizeofuas the num-
ber of symbols, integers, algebraic operators, and function names that oc-cur in u. For example, the expression ( x+s i n ( x)+2 ) ∗x
3consists of
x,+,sin,x,2,∗,x,∧,and 3 and so has a tree-size of 9. Give a procedure
Tree
size(u) that obtains the tree-size of u.
10. Give procedures for each of the following operators. In each case the pro-
cedures should be deﬁned in terms of the primitive operators as was done
in the text with the Trig
substitute andTrig
substitute
mapoperators.
(a) Let ube amathematical expression andvan equation. Give a pro-
cedure for the operator Substitute (u,v) that performs structural sub-
stitution. (See Deﬁnition 3.30on page111.)
(b) Let ube amathematical expression andLa list of equations. Give
a procedureSequential
substitute (u,L) that performs sequential sub-
stitution. (See Deﬁnition 3.31on page114.)
(c) Let ube amathematical expression andSa set of equations. Give a
procedureConcurrent
substitute (u,S) that performs concurrent sub-
stitution. (See Deﬁnition 3.34on page115.)
196 5. Recursive Algorithms
11. (a) Let Sbe a set of mathematical expressions and let kbe an integer
with 0 ≤k≤Number
of
operands(S). Give a procedure Comb(S,k)
that returns the set of all kelement subsets of S. For example, if
S={a,b,c,d },t h e n
Comb(S,2)→{ {a,b},{a,c},{a,d},{b,c},{b,d},{c, d}}.
The procedure can be deﬁned by the following recursive transforma-
tion rule sequence.
i. Ifk=Number
of
operands(S), thenComb(S,k)→{S}.
ii.Comb(S,0)→ {∅}.
iii. Let x=Operand(S,1),T=S∼{x},a n dD=Comb(T,k−1).
ForD={S1,...,S n},l e tE={S1∪{x},...,S n∪{x}}.T h e n
Comb(S,k)→Comb(T,k)∪E.
(b) Thepowerset ofaset Sisthesetofallsubsetsof S. Giveaprocedure
Power
set(S) that obtains the power set of a set S.
12. Derivethegeneraldiﬀerentiationpowerrulein DERIV-2.Hint:Lety=vw
and take logs of both sides of the expression.
13. Let ube analgebraic expression ,a n dl e t xbe a symbol.
(a) Give a procedure Derivative (u,x) that utilizes the DERIVrules de-
s c r i b e di nt h i ss e c t i o n .
(b) Although quotients are represented as powers or products, it is pos-
sible to recognize when an expression is a quotient and apply the
quotient rule instead of the product rule. Modify the Derivative pro-
cedure so that it recognizes when an expression is a quotient and,when this is so, applies the quotient rule.
(c) Although the DERIVtransformation rules allow for the diﬀerenti-
ation of some expressions with undeﬁned functions (see Statement(5.9)), the rules don’t handle expressions with compositions of un-
deﬁned functions such as f(g(x)) orh(x,g(x)) in an adequate way.
For these expressions the Derivative operator is returned in unevalu-
ated forminstead ofwitharepresentation thatutilizes thechainrule.Somecomputeralgebrasystemsgiverepresentationsofderivativesfor
these expressions that utilize the chain rule. Experiment with a CAS
to see how derivatives of these expressions are handled, and modifytheDerivative procedure to handle these derivatives.
(d) The DERIVtransformation rules provide for the diﬀerentiation of
anyalgebraic expression includingfactorials. (Accordingtotherules,Derivative (x!,x) is now returned in unevaluated form.) Although x!
is deﬁned only when xis a non-negative integer, there is a general-
ization of the factorial operation that involves the gamma function
5.2. Recursive Procedures 197
(Γ(x+1)= x!) where xisnolonger restricted in thisway4.W i t ht h i s
generalization, we can deﬁne transformation rules for the diﬀerentia-
tion of factorial expressions. Experiment with a CAS to see how the
diﬀerentiation operator handles factorials, and modify the Derivative
procedure to handle these expressions.
14. Let ube an equation with both sides of theequation algebraic expressions ,
xandyare symbols, and nis a non-negative integer. Give a recursive
procedure
Implicit
derivative (u,y,x,n)
that obtains the nth derivative of ywith respect to x.I f n = 0 , r e t ur n
u. Use either the diﬀerentiation operator in a CAS or the Derivative op-
erator in Exercise 13to perform the diﬀerentiations. (If a CAS has the
capability to perform implicit diﬀerentiation, do not use this capability.)
Assume that yis represented in the equation in function notation y(x)
and thatFree
of(u,y(x)) isfalse. Do not use an iteration structure in this
procedure. For example,
Implicit
derivative (x2+y(x)2=1,y ,x ,3)→−3xi
x2+y(x)2J
y(x)5.
15. Let ube analgebraic expression ,a n dl e t xandybe symbols. Give a
procedure
Derivative
order(u,x,y)
that determines the maximum order of the derivatives of ywith respect
toxinu. In this exercise d(y,x) represents the ﬁrst derivative and for
an integer n≥2,d(y,x,n) represents the derivative of order n.( W eus e
thisrepresentationratherthanarepresentationsuchas Derivative (y(x),x)
to conform with the presentation in Section 4.3.) In addition, the order
of the symbol yis 0, and the order of expressions without a yis−1.
To simplify matters, if ucontains function forms with the name dthat
contain operands diﬀerent from those in d(y,x)a n d d(y,x,n), return the
global symbol Undeﬁned . For example,
Derivative
order(d(y,x,2)+xd(y,x)+4y, x, y)→2,
Derivative
order(x+y, x, y)→1,
Derivative
order(x, x, y)→−1,
Derivative
order(d(y2,x),x ,y)→Undeﬁned ,
Derivative
order(d(y,b),x ,y)→Undeﬁned .
Note in the last two examples, the symbol Undeﬁned is returned because
the operands of the function form dare inappropriate.
TheDerivative
orderoperator is used in Exercise 14on page240.
4See Spanier and Oldham [ 92], Chapter 43 for a description of the gamma function
and its derivative.
198 5. Recursive Algorithms
16. (a) Let Sbe a set of rational numbers. Give a procedure Max(S)t h a t
returns the maximum value in S.I fSis empty, return the global
symbol Undeﬁned .
(b) Supposenowthat Sisaﬁnitesetof algebraic expressions . Generalize
the procedure Maxso that it determines the maximum value of the
expressions in Sthat can be compared. For the purposes of this
exercise two expressions fandgarecomparable iff−gis an integer
or fraction, and f>gwhenf−g>0 in automatic simpliﬁcation.
If all the expressions in Sare pairwise comparable, then return the
maximumexpression. Iftwoormoreexpressionscannotbecompared,then return an unevaluated form of Max. For example,
Max({a,2,3})→Max({a,3}),
Max({m,m+1})→m+1,
Max({3,Max({2,x}),})→Max(3,x),
Max({−5,m,m+1,2,3,√
2})→Max({3,m+1,√
2}).
Note that in the last example 3 and√
2 cannot be compared because
3−√
2 is not an integer or fraction in automatic simpliﬁcation.
This procedure returns a reasonable result as long as the input data
is appropriate. For example, if some of the expressions in Sare
complex number expressions, then the input is not appropriate (e.g.,
S={2,√
−1}).
TheMaxoperator is used in Exercise 17below and Exercise 13, page239.
17. Let ube analgebraic expression andxas y m b o l .G i v eap r o c e d ur e
Max
exponent(u,x)
that returns the largest exponent of xinu. If some exponents of xare not
integers or fractions, return an unevaluated Maxfunction as described in
Exercise16. For example,
Max
exponent(x2+x3,x)→3,
Max
exponent(x+x−1,x)→1,
Max
exponent(sin(x2+xm,x)→Max({2,m}),
Max
exponent(x(x2),x)→Max({2,x2}).
18. The absolute value function satisﬁes the following four properties:
(a)|a·b|→|a|·|b|.
(b) For nan integer, |an|→|a|n.
(c) For ı=√
−1,|ı|→1.
(d) If an expression has the form a+ıb,w h e r e a/negationslash=0a n d b/negationslash=0a r ef r e e
ofı,t h e n |a+bı|→(a2+b2)1/2.
5.3. Case Study: Elementary Integration Operator 199
Letubeanalgebraic expression . Give a procedure Absolute
value(u)t h a t
obtains the absolute value of integers and fractions and applies the above
rules when uis not an integer or fraction. If uis not an integer or fraction
or one the above forms, return the unevaluated form ” Absolute
value”(u).
For example,
Absolute
value(−1/2)→1/2,
Absolute
value(−2x)→2Absolute
value(x),
Absolute
value(x+y)→Absolute
value(x+y),
Absolute
value(x+2ı)→(x2+4)1/2.
This procedure returns a reasonable result as long as the input data is
appropriate. Forexample,sincetheproceduredoesnotperformananalysis
of involved expressions with radicals, it may return an inappropriate resultsuch as
Absolute
value~
1−6
2−√
5+ı^
→
2−6
2−√
5,
which is a complex number.
5.3 Case Study: An Elementary Indefinite Integration
Operator
In this case study we describe an algorithm that evaluates/integraltext
f(x)dxfor
a limited class of functions encountered in elementary calculus. The algo-
rithm utilizes the following:
1. an integration table,
2. the linear properties of the indeﬁnite integral,3. the “substitution” or “change of variable” method that is based on
the inversion of the chain rule, and
4. both expanded and unexpanded forms of the integrand f(x).
For example, the algorithm can evaluate the integrals
/integraldisplay
5xsin/parenleftbig
x
2/parenrightbig
cos/parenleftbig
x2/parenrightbig
dx,/integraldisplay
(cos(x)+2 )( s i n ( x)+3 )dx.
200 5. Recursive Algorithms
The Integration Table
The integration table includes the following standard elementary forms.
1. Expressions that are free of the integration variable x.
2. Powers xn,w h e r enis free of the integration variable x.S i n c em o s t
computer algebra systems return/integraltext
x−1dx=l n (x) (rather than the
more general form ln |x|), we include this form in the table.
3. The functions exp( x)a n dl n (x)a n dt h ep o w e r bx,w h e r ebis free of
the integration variable x.
4. The trigonometric functions.5. More involved expressions that occur as derivatives of the trigonomet-
ric functions or their inverses. For example, sec( x)tan(x)a p p e a r si n
the table because it is the derivative of sec( x).
Linear Properties
When the integrand is a product f(x)=cg(x)w i t hcfree ofx, the algo-
rithm applies the linear property
/integraldisplay
fd x=/integraldisplay
cgdx =c/integraldisplay
gd x (5.15)
and then evaluates recursively/integraltext
gd x. In some cases when the substitution
method is used to evaluate an integral, this step may seem counterproduc-
tive (see Equations ( 5.19)-(5.21) below). It is required, however, to match
expressions in the integration table, and its application does not hinder the
substitution method algorithm (see Example 5.4below).
Whenfis a sum, the algorithm applies the linear property
/integraldisplay
fd x=/integraldisplay n/summationdisplay
i=1fidx=n/summationdisplay
i=1/integraldisplay
fidx (5.16)
and then evaluates recursively each/integraltext
fidx.
The Substitution Method
The substitution method is a basic technique for evaluating integrals that
most readers are undoubtedly familiar with from the study of calculus. The
method depends on the inversion of the chain rule
/integraldisplay
u(v(x))v/prime(x)dx=/integraldisplay
u(v)dv=U(v(x)), (5.17)
5.3. Case Study: Elementary Integration Operator 201
whereU/prime(v)=u(v). It has the potential to obtain an anti-derivative when-
ever the integrand is a product of the form
f=u(v(x))v/prime(x). (5.18)
Once such a representation is chosen, the success of the method depends
on the evaluation of the new integral/integraltext
u(v)dv.For example, to evaluate
/integraldisplay
2xcos/parenleftbig
x2/parenrightbig
dx, (5.19)
let
v(x)=x2,u(v)=c o s (v). (5.20)
Sincev/prime=2x,
/integraldisplay
2xcos/parenleftbig
x2/parenrightbig
dx=/integraldisplay
cos(v)dv=s i n (v)=s i n/parenleftbig
x2/parenrightbig
. (5.21)
Notice that we have omitted the arbitrary constant of integration as is done
in most CAS software as well as the procedures in this section.
Although this example illustrates a general approach, the technique is
more involved in practice. The diﬃculty involves deciding how to choose
a substitution that eliminates the original integration variable x.Ins o m e
instances it is possible to represent the integrand in the form ( 5.18)i n
a number of ways and in others it may not be possible at all. For ouralgorithm, we need a set of trial substitutions and a way to test if a sub-
stitution is appropriate. Figure 5.16shows some typical substitutions used
to evaluate integrals using this method.
These examples suggest four possible forms for the substitution v(x).
1.Function forms. In
/integraldisplay(x+1 )l n ( c o s ( ( x+1 )
2)) sin((x+1 )2)
cos((x+1 )2)dx, (5.22)
the expressions
ln(cos((x+1 )2)),sin((x+1 )2),cos((x+1 )2)
are function forms.
2.Arguments of function forms. In(5.22), the expressions
cos((x+1 )2),(x+1 )2
are arguments of function forms.
202 5. Recursive Algorithms
Integral
 Substitution

sin(x)cos(x)dx=sin2(x)
2
v=s i n(x)

2xcosi
x2J
dx=s i ni
x2J
v=x2

2xi
x2+4J5dx=i
x2+4J6/6
v=x2+4

cos(x)2sin(x)dx=2sin(x)
ln(2)
v=s i n(x)
Figure 5.16. Evaluation of integrals using the substitution method.
3.Bases of powers. In(5.22), the expressions
cos((x+1 )2),x+1
are bases of powers. The ﬁrst expression is a base because the de-
nominator of the integrand in ( 5.22) has the internal representation
(cos((x+1 )2))−1.
4.Exponents of powers. Inc o s (x)2sin(x), the expression sin( x)i sa n
exponent of a power. In ( 5.22),−1 and 2 are also exponents, but
don’t give useful substitutions.
Using these substitution forms, the trial substitutions for the integrand in
(5.22)a r e
ln(cos((x+1 )2)),cos((x+1 )2),(x+1 )2,
x+1,sin((x+1 )2),−1,2. (5.23)
The ﬁrst four expressions give substitutions that transform the integrand
to the form in ( 5.18), while the last three do not. For example, the ﬁrst
substitution
v=l n ( c o s ( ( x+1 )2)),
transforms the integral to a form that is easily evaluated
5.3. Case Study: Elementary Integration Operator 203
/integraldisplay(x+1 ) l n ( c o s( x+1 )2)s i n ( (x+1 )2)
cos((x+1 )2)dx
=−(1/2)/integraldisplay
vd v=(−1/4)v2=(−1/4)/parenleftbig
ln(cos((x+1 )2))/parenrightbig2.
Substitutions using the next three expressions in ( 5.23) also lead to simpler
integrals although each one requires at least one additional substitution forevaluation. For example, if the substitution is v(x)=c o s ( (x+1 )
2), then
/integraldisplay(x+1 )l n ( c o s ( ( x+1 )2)) sin((x+1 )2)
cos((x+1 )2)dx
=−(1/2)/integraldisplayln(v)
vdv,
where the last integral is evaluated with another substitution w=l n (v).
A procedure for the substitution method must perform the following
steps.
1. Form the set Pof possible substitutions that contains the function
forms, function arguments, and bases and exponents of powers in f.
2. Check each v(x)i nPto determine if it is an appropriate substitu-
tion. There are two expressions that may be in P, but which can
be eliminated immediately. They are v(x)=xwhich is really no
substitution at all, and the expressions v(x)t h a ta r ef r e eo f x.Iff
has the factored form
f=u(v(x))·v/prime(x)
for somev(x)i nP, the new integrand u(v) is obtained by eliminating
the factor v/prime(x)f r o mfand substituting a symbol vfor the expression
v(x). This operation is obtained by
u(v)=Substitute/parenleftbiggf
v/prime(x),v(x)=v/parenrightbigg
, (5.24)
where the division operation is obtained with automatic simpliﬁca-
tion. For the process to work, the substitution and division musteliminate the original integration variable xfrom the integrand. This
condition is veriﬁed by checking that u(v)i sf r e eo f x.Ift h i si ss o ,w e
complete the integration by evaluating recursively/integraltext
u(v)dv,a n db y
substituting v(x)f o rv. Because of the division in Expression ( 5.24),
the substitution method is also called the derivative divides method.
204 5. Recursive Algorithms
Example 5.3. Consider again
/integraldisplay
2xcos/parenleftbig
x2/parenrightbig
dx.
The possible substitutions are
P={x,2,x2,cos/parenleftbig
x2/parenrightbig
}. (5.25)
Since the ﬁrst two expressions xand 2 are not useful substitutions, the third
onev(x)=x2is tried. In this case Expression ( 5.24)g i v e su(v)=c o s (v),
which is free of x, and so the anti-derivative is obtained with
Substitute/parenleftbigg/integraldisplay
cos(v)dv, v=x2/parenrightbigg
→sin/parenleftbig
x2/parenrightbig
.
On the other hand, with the fourth expression v(x)=c o s/parenleftbig
x2/parenrightbig
inP,E x -
pression ( 5.24)g i v e s
u(v)=−cos(v)
sin(x2),
which is not free of xand so this substitution does not work. /square
Expanded versus Unexpanded Integrands
There are instances where expansion of the integrand is required for evalu-
ation and others where expansion leads to more a diﬃcult integration. For
example, to evaluate/integraldisplay
(x+1 )(x+2 )dx, (5.26)
it is necessary to expand the integrand. On the other hand, while the
unexpanded form/integraldisplay
(2x+1 )c o s/parenleftbig
x2+x/parenrightbig
dx (5.27)
is easily evaluated with the substitution v(x)=x2+x, by expanding and
applying the linear property ( 5.16), we obtain
/integraldisplay
(2x+1 )c o s/parenleftbig
x2+x/parenrightbig
dx=/integraldisplay
2xcos/parenleftbig
x2+x/parenrightbig
dx+/integraldisplay
cos/parenleftbig
x2+x/parenrightbig
dx,
where the two integrals on the right cannot be evaluated using the elemen-
tary functions encountered in calculus.
To handle both ( 5.26)a n d( 5.27), the algorithm ﬁrst tries to evaluate
an integral without expanding f, and if it is not successful, tries again after
expanding f.
5.3. Case Study: Elementary Integration Operator 205
The Integration Algorithm
TheIntegral procedure, which serves as a main procedure for the algo-
r i t h m ,i ss h o w ni nF i g u r e 5.17. The procedure returns either/integraltextfd xor the
global symbol Failif it is unable to evaluate the integral. It calls on three
procedures (lines 1, 3, and 5) that also return either an evaluated integral
or the symbol Fail. The statement at line 1 invokes the Integral
 tablepro-
cedure, which compares fto a number of standard forms and serves as a
termination condition for the recursion. The procedure Integral
 tableis left
to the reader (Exercise 3(a)).
Iffis not in the table, then at lines 2-3 the procedure Linear
 properties
determines if either Equation ( 5.15)o rE q u a t i o n( 5.16) can be applied, and,
if so, applies the appropriate rule. This procedure is recursive because
it calls on Integral to evaluate the new integrals produced by the linear
properties. The procedure Linear
 properties is left to the reader (Exercise
3(b)).
If this step fails, the Substitution
 method procedure is applied at line 5.
This step is recursive because this procedure also calls on Integral .Ift h i s
step fails, the integrand is expanded (at line 7), and if this produces a new
expression, the procedure Integral is applied recursively at line 9.
TheSubstitution
 method procedure is shown in Figure 5.17.N o t i c et h a t
the procedure uses a global mathematical symbol vto avoid using a lo-
cal variable that would be used without being assigned. At line 1, the
Trial
 substitutions procedure creates a set Pof possible substitutions (Ex-
ercise 3(c)). In lines 4-10, we check each candidate ginPas a possible
substitution. Once one is found, the loop terminates and the procedure
returns the evaluated integral. The procedure is recursive because it callsonIntegral at line 9, which allows another check of the integration table
and further application of the linear properties, substitution method, and
expansion, all of which may be needed (Exercise 1).
There are two ways that the Substitution
method procedure can fail
to obtain the integral: ﬁrst, when none of the possible substitutions in P
works, and next, when the free-of test at line 8 succeeds but the Integral
operator at line 9 is unable to evaluate the new integral. In either case, the
symbolFailis returned at line 11.
Example 5.4. Consider the evaluation of
/integraldisplay
2xcos/parenleftbig
x2/parenrightbig
dx.
Figure 5.18shows the sequence of procedure calls that indicates the path
taken by the algorithm to evaluate the integral. (There are other procedure
206 5. Recursive Algorithms
Procedure Integral(f,x);
Input
f:a nalgebraic expression ;
x:as y m b o l ;
Output	
fd xor the global symbol Fail;
Local Variables F,g;
Begin
1 F:=Integral
table(f,x);
2 ifF=Fail then
3 F:=Linear
properties (f,x);
4 ifF=Fail then
5 F:=Substitution
method(f,x);
6 ifF=Fail then
7 g:=Algebraic
expand(f);
8 iff/negationslash=gthen
9 F:=Integral(g,x);
10Return(F)
End
Procedure Substitution
 method(f,x);
Input
f:a nalgebraic expression ;
x:as y m b o l ;
Output	
fd xor the global symbol Fail;
Local Variables P,F,i,u,g ;
Global v;
Begin
1 P:=Trial
substitutions (f);
2 F:=Fail;
3 i:= 1;
4 while F=Fail and i≤Number
of
operands(P)do
5 g:=Operand(P,i);
6 ifg/negationslash=xand notFree
of(g,x)then
7 u:=Substitute (f/Derivative (g,x),g=v);
8 ifFree
of(u,x)then
9 F:=Substitute (Integral(u,v),v=g);
10 i:=i+1;
11Return(F)
End
Figure 5.17. The MPLIntegralandSubstitution
 methodprocedures. (Imple-
mentations: Maple(txt),Mathematica (txt),MuPAD(txt).)
5.3. Case Study: Elementary Integration Operator 207
Operator
 Integrand
 Integration
Variable
1
Integral
 2xcosi
x2J
x
2
Linear
properties
 2xcosi
x2J
x
3
Integral
 xcosi
x2J
x
4
Substitution
method
 xcosi
x2J
x
5
Integral
 (1/2) cos( v)
 v
6
Linear
properties
 (1/2) cos( v)
 v
7
Integral
 cos(v)
 v
8
Integral
table
 cos(v)
 v
Figure 5.18. The sequence of procedure calls that contribute to the evaluation
of	
2xcosi
x2J
dx.
calls that return Failand don’t contribute to the evaluation.) At step 1,
Integral calls on Linear
 properties (step 2) where the leading constant 2 is
removed. At step 3, Linear
 properties passes the new expression xcos/parenleftbig
x2/parenrightbig
toIntegral which, at step 4, calls on Substitution
 method .T h i ss t e pi n t r o -
duces a new leading constant 1/2 and passes a new integrand to Integral
(step 5). At step 6, the leading constant 1 /2 is removed by another call
toLinear
 properties which again passes a new integrand to Integral (step
7). Finally, at step 8, Integral calls on Integral
 tablewhich terminates the
recursion and returns sin( v). At this point the recursion unwinds to give
/integraldisplay
2xcos/parenleftbig
x2/parenrightbig
dx=s i n/parenleftbig
x2/parenrightbig
. /square
Appraisal of the Algorithm
The algorithm can evaluate many integrals that depend on the application
of the linear properties and the inversion of the chain rule, but cannot
evaluate all such integrals. For example, for the integral
/integraldisplay2x
x4+1dx=a r c t a n/parenleftbig
x2/parenrightbig
,
the set of possible substitutions obtained by the algorithm is
P=/braceleftbig
x4+1,−1,x,4/bracerightbig
.
Since this integral is evaluated using the substitution v=x2, which is not
inP, the integration is not obtained with the algorithm5.
5The reader wishing to explore substitutions of this type should consult Cohen [ 24],
Section 4.4, Exercise 10(d).
208 5. Recursive Algorithms
In other cases, although the substitution is in P, the algorithm cannot
evaluate the integral because of the form of the integrand. For example,
consider the integral/integraldisplaydx
exp(x)+e x p ( −x).
In this form the substitution set is
P={exp(x)+e x p ( −x),exp(x),exp(−x),x , −x}.
Although this integral can be evaluated with v(x)=e x p (x), this substitu-
tion will not work with the integrand in this form. However, by multiplyingthe numerator and denominator of the integrand by exp( x), we obtain
/integraldisplayexp(x)
(exp(x))2+1dx=a r c t a n ( e x p ( x)),
which is evaluated with the substitution v(x)=e x p (x). Since our algorithm
does not perform the transformation
1
exp(x)+e x p ( −x)→exp(x)
(exp(x))2+1,
it cannot evaluate the integral.
Some extensions of the algorithm are described in Exercises 4,6,8,
and9.
Exercises
1. For each of the following integrals, give the sequence of procedure calls
that shows the path taken by the algorithm to evaluate the integral. For
some integrals, the sequence of procedure calls depends on the order of theexpressions in the substitution set P.
(a)
sec
3(x)tan(x)dx.
(b)
(sin(x)+4)3cos(x)dx.
(c)
x·~Wx2
2c+1}3
+2^
dx.
(d)
(sin(x)+1)(cos( x)+1) dx.
2. Explain why each of the following integrals can be evaluated with substi-
tution but cannot be evaluated by the algorithm in this section.
5.3. Case Study: Elementary Integration Operator 209
(a)x+2
x2+4x+2dx,l e t v=x2+4x+2.
(b)
sini
ax2+bx2J
xd x ,letv=ax2+bx2.
(c)1
(2x+3)
4x+5)dx=a rc ta n(√
4x+5),letv=√
4x+5.
3. (a) Give a procedure for Integral
table(f,x). Iffis not in the table,
return the global symbol Fail.
(b) Give a procedure for the Linear
properties (f,x) operator.
When fisaproduct,applyEquation( 5.15)byseparatingtheoperands
that are free of xfromfusing theSeparate
factorsprocedure (see
page148) and integrating the remaining expression with a recursive
call toIntegral. If none of the operands of fis free of x, this prop-
erty does not contribute to the evaluation of the integral, and so the
procedure returns the global symbol Fail.
When fis a sum, apply Equation ( 5.16) by evaluating the integral
of each operand using Integral. However, if some operand cannot be
integrated, then return Failbecause the algorithm cannot integrate
the entire sum.
Finally, if fis not a product or a sum, return Fail.
(c) Give a procedure Trial
substitutions (f) that ﬁnds all functions, ar-
guments of functions, and bases and exponents of powers that occur
inf. The result should be returned as a set.
4. This exercise describes a procedure that evaluates integrals of rational ex-
pressions of the formrx+s
ax2+bx+cdx, (5.28)
where a/negationslash=0 ,b,c,r,a n dsare free of x. The algorithm for this integral is
divided into two cases. First, when the integrand has the form
f=1
q,q=ax2+bx+c,
then
dx
q=

2arctanW
2ax+b
√
4ac−b2}
√
4ac−b2,ifb2−4ac<0,
−2arctanhW
2ax+b
 √
b2−4ac}
√
b2−4ac,ifb2−4ac>0,
−2
2ax+b, ifb2−4ac=0 .(5.29)
210 5. Recursive Algorithms
Next, when the integrand has the form f=rx+s
q,t h e n
rx+s
qdx=αln(q)+βdx
q,
where α=r/(2a),β=s−rb /(2a), and the integral on the right is
evaluated with Equation ( 5.29).
(a) Give a procedure Rational
form(f,x) that checks that fhas the
proper form and obtains the integral. If b2−4acis not an inte-
ger or fraction, which means that it cannot be compared to 0, return
the arctan form in ( 5.29). Iffdoes not have the form in ( 5.28), re-
turn the global symbol Fail.Hint:TheLinear
formprocedure (see
Figure5.7on page181)a n dt h eQuadratic
formprocedure (Exercise
8, page195) are useful for this exercise.
(b) Modifythe Rational
formproceduresothatitalsoevaluatesintegrals
of the form rx+s
bx+cdx,
where b/negationslash=0a n d r/negationslash=0 .( T h ec a s e s b=0o r r= 0 are handled by
other cases in Integral.)
(c) Modify themain Integralprocedure so that it calls on Rational
form.
(For further exploration of this operator and its generalization, the reader
may consult Cohen [ 24], Section 4.4, Exercise 10.)
5. Use theIntegraloperator together with the Rational
formoperator in Ex-
ercise4to evaluate
cos(x)
sin2(x)+3sin( x)+4dx.
6. This exercise describes a procedure that evaluates integrals of the form
1
(ax+b)√
rx+sdx,
where a/negationslash=0 ,b,r/negationslash=0 ,a nd sare free of x.
(a) Show that the integral can be transformed by the substitution v=√
rx+sto
1
(ax+b)√
rx+sdx=21
av2−as+brdv.
The new integral is evaluated using the Rational
formoperator (Ex-
ercise4).
(b) Give a procedure Radical
form(f,x)t h a tc h e c k si f fhas the proper
form, and, if so, applies the above transformation and returns the
result in terms of x.I ffdoes not have the proper form, return the
global symbol Fail.
5.3. Case Study: Elementary Integration Operator 211
(c) Modify the main Integralprocedure so that it calls on Radical
form
procedure.
7. UsetheIntegraloperatortogetherwiththe Radical
formoperator(Exercise
6)t oe v a l ua t e3cos(x)
(5sin(x)+1)
4sin(x)+7dx.
8. This exercise describes a procedure that evaluates integrals of the form

fd x=
sinm(x)c o sn(x)dx, (5.30)
where mandnare non-negative integers. Integrals of this form can be
evaluated using the reduction formulas

cosn(x)dx=(1/n)cosn−1(x)s i n (x)+n−1
n
cosn−2(x)dx,(5.31)

sinm(x)c o sn(x)dx=−sinm−1(x)c o sn+1(x)
m+n(5.32)
+m−1
m+n
sinm−2(x)c o sn(x)dx.
Notice that repeated use of Equation ( 5.32) reducestheintegrand in ( 5.30)
to the form sin( x)cosn(x)( w h e n mis odd) or to cosn(x)( w h e n mis
even). In the ﬁrst case, the remaining integral is evaluated by a call to
Substitution
methodand, in the second case, with Equation ( 5.31).
(a) Giveaprocedure Trig
form(f,x)thatc hec ksif fhastheproperform
and if so obtains the integral. If fdoes not have the proper form,
return the global symbol Fail.
(b) Modify the main Integralprocedure so that it calls on Trig
form.
Another approach for these integrals is described in Exercise 10, page306.
9. Let nbe a positive integer and let aandbbe free of x. The following
recurrence relations are derived using integration by parts:

xnexp(ax+b)dx= (5.33)
xn/aexp(ax+b)−n/a
xn−1exp(ax+b)dx,

xnsin(ax+b)dx= (5.34)
−xn/acos(ax+b)+n/a
xn−1cos(ax+b)dx,

xncos(ax+b)dx= (5.35)
xn/asin(ax+b)−n/a
xn−1sin(ax+b)dx.
212 5. Recursive Algorithms
(a) Give a procedure By
parts(f,x) that checks if the integrand is one
of these forms and when this is so evaluates the integral using the
appropriaterecurrencerelation. If fdoesnothaveoneoftheseforms,
return the global symbol Fail.
(b) Modify the main Integralprocedure so that it calls on the By
parts
procedure.
Further Reading
5.1A Computational View ofRecursion. A more detailed discussion of
how recursion is implemented in a computer system is given in Pratt [ 82].
5.2Recursive Procedures. Rule-based programming in Mathematica is de-
s c r i b e di nG a y l o r de ta l .[ 38]a n dG r a y[ 41].
5.3Case Study: An Elementary Indeﬁnite Integration Operator. Moses
[70] discusses the derivative divides method of integration. Symbolic integration
is a very diﬃcult mathematical and computational problem. Geddes, Czapor,
and Labahn [ 39], Chapter 11 is a good introduction to the subject. Bronstein
[13] gives a theoretical discussion of the subject.
6
Structure of Polynomials and
Rational Expressions
In Chapter 3we described the tree structure of an expression. An ex-
pression also has a semantic structure that is related to its mathematical
properties. For example, the expression 3 x2+4x+5/2 can be viewed both
as an expression tree and semantically as a polynomial in xwith degree 2
that has rational number coeﬃcients.
In this chapter, we describe the polynomial structure andrational ex-
pression structure of an algebraic expression. For polynomials, we give
three deﬁnitions of increasing generality: ﬁrst for single variable polynomi-als (Section 6.1); next for multivariate polynomials (Section 6.1); and ﬁnally
for general polynomial expressions (Sections 6.2and6.3). The deﬁnitions
are more involved than those found in mathematics textbooks, since theyfocus on computational concerns as well as the mathematical concept of
a polynomial. Along with these deﬁnitions, we give MPL procedures that
determine the polynomial structure of an expression. In Section 6.4,w e
use these structural concepts to describe the goals of two transformations,
coeﬃcient collection and algebraic expansion, and give MPL algorithms forthese operations. Finally, in Section 6.5we describe the rational expression
structure of an algebraic expression and give an algorithm that transforms
an expression to a particular rational form.
Although operators that determine the structure of polynomials and
rational expressions are available in most computer algebra languages, their
capacity varies from system to system. The concepts in this chapter provide
a framework to analyze and compare how these concepts are implemented
in various CAS languages.
213
214 6. Structure of Polynomials and Rational Expressions
6.1 Single Variable Polynomials
We begin by considering polynomials in a single variable with rational
number coeﬃcients.
Definition 6.1. (Mathematical Deﬁnition) Apolynomial uin a
single variable xis an expression of the form:
u=unxn+un−1xn−1+...+u1x+u0, (6.1)
where thecoeﬃcients ujare rational numbers, and nis a non-negative
integer. If un/negationslash=0,t h e nunis called the leading coeﬃcient ofuandnis
itsdegree . The expression u=0is called the zero polynomial ; it has
leading coeﬃcient 0and, according to mathematical convention has degree
−∞. The leading coeﬃcient is represented by lc(u,x)and the degree by
deg(u,x). When the variable xis evident from context, we use the simpler
notations lc(u)anddeg(u).
Observe that we have distinguished the zero polynomial from other
constant polynomials because it has no non-zero coeﬃcients, and so the
general deﬁnitions for leading coeﬃcient and degree do not apply1.
Example 6.2.
u=3x6+2x4−5/2,deg(u)=6,lc(u)=3,
u=x2−x+2,deg(u)=2,lc(u)=1, (6.2)
u=2x3,deg(u)=3,lc(u)=2, (6.3)
u=3,deg(u)=0,lc(u)=3. (6.4)
/square
Although Deﬁnition 6.1deﬁnes the concept of a polynomial in a math-
ematically precise way, it requires some interpretation and is not adequate
for computational purposes. For example, in the previous example, thedeﬁnition is interpreted in a broad sense to include expressions that have
coeﬃcients that are understood to be ±1 (as in Equation ( 6.2)) and those
that have a single term (as in Equations ( 6.3)a n d( 6.4)). The following
deﬁnition, which captures the essence of a single variable polynomial in a
1For the polynomial u= 0, both Maple’s degree operator and Mathematica’s
Exponent operator return a degree of −∞. On the other hand, MuPAD’s degree operator
returns a degree of 0.
6.1. Single Variable Polynomials 215
computational setting, can be easily expressed as an MPL procedure that
recognizes when an expression is a polynomial.
Definition 6.3. (Computational Deﬁnition) Amonomial in a single
variablexis an algebraic expression uthat satisﬁes one of the following
rules.
MON-1. uis an integer or fraction.
MON-2. u=x.
MON-3. u=xn,w h e r en>1is an integer.
MON-4. uis a product with two operands that satisﬁes either MON-1,
MON-2, or MON-3.
Apolynomial in a single variable xis an expression uthat satisﬁes one
of the following rules.
POLY-1. uis a monomial in x.
POLY-2. uis a sum, and each operand of uis a monomial in x.
Primitive Operations on Polynomials
TheMonomial
 svandPolynomial
 svOperators. The operators that are de-
scribed in the next deﬁnition recognize when an expression is a monomial
or a polynomial.
Definition 6.4. Letube an algebraic expression . The operator
Monomial
 sv(u,x)
returnstrue whenuis a monomial in xand otherwise returns false.( T h e
suﬃx “sv” stands for “single variable.”) The operator
Polynomial
 sv(u,x)
returnstrue whenuis a polynomial in xand otherwise returns false.
Example 6.5.
Monomial
 sv(2x3,x)→true,
Monomial
 sv(x+1,x)→false,
Polynomial
 sv(3x2+4x+5,x)→true,
Polynomial
 sv(1/(x+1 ),x)→false,
Polynomial
 sv(ax2+bx+c, x)→false.
216 6. Structure of Polynomials and Rational Expressions
The expression ax2+bx+cis not a polynomial in xbecause the coeﬃcients
are not rational numbers. It is, however, a multivariate polynomial (Deﬁni-
tion6.12, page 221), and a general polynomial expression (Deﬁnition 6.14,
page 223). /square
The operators described in Deﬁnition 6.4are understood to operate
within a computational environment deﬁned by an evaluation process thatincludes automatic simpliﬁcation. Since this process is applied to the input
arguments before the actual tests are done, an expression uis a polynomial
inxif the evaluation process transforms it to an expression that satisﬁes
Deﬁnition 6.3.Int h i ss e n s e ,s i n ( x)+x−sin(x) is a polynomial in x, because
the sin(x) terms are eliminated by automatic simpliﬁcation.
But now the question arises, should the operators apply any other trans-
formation rules to ubefore the tests are done? In other words, in what
simpliﬁcation context should we interpret our polynomial deﬁnition? Forexample, each of the expressions
(x+1 ) (x+3 ),x
2+s i n2(x)+c o s2(x),x2−1
x−1,cos(2arccos( x))
can be transformed to a polynomial in the sense of Deﬁnition 6.1. However,
if we assume a simpliﬁcation context of automatic simpliﬁcation, they are
not considered polynomials in xbecause the required transformation rules
are not applied by this process.
The question of which simpliﬁcation transformations to include in the
deﬁnition of Polynomial
 svdoes not have a simple answer. For example, if
the operator Algebraic
 expand were applied, the expression ( x+1 ) (x+3 )
would be a polynomial in x. There are, however, some cases when it is
not useful to apply Algebraic
 expand (for example, see Expression ( 6.9)o n
page224). For now, we take the conservative view that the these procedures
as well as the others in this section operate within the context of only
automatic simpliﬁcation.
Procedures for Monomial
 svandPolynomial
 svare given in Figures
6.1and6.2.InMonomial
 sv, the four MON tests are done in lines 1-11.
Notice that MON-4 (lines 10-11) is handled with two recursive calls on
the procedure. Any expression that is not handled by lines 1-11 is nota monomial in x,a n ds ofalseis returned (line 12). In a similar way,
Polynomial
svtests the two POLY rules in lines 1-7. Any expression not
handled here is not a polynomial, and so falseis returned at line 8.
The operators in the next three deﬁnitions provide a way to analyze
the polynomial structure of an expression.
6.1. Single Variable Polynomials 217
Procedure Monomial
sv(u,x);
Input
u:a nalgebraic expression ;
x:as y m b o l ;
Output
trueorfalse;
Local Variables
base,exponent;
Begin
1 ifKind(u)∈{integer ,fraction }then
2Return(true)
3 elseif u=xthen
4Return(true)
5 elseifKind(u)=” ∧”then
6base:=Operand(u,1);
7exponent :=Operand(u,2);
8 ifbase=xandKind(exponent)=integer and exponent >1then
9 Return(true)
10 elseifKind(u)=” ∗”then
11Return(Number
of
operands(u)=2andMonomial
sv(Operand(u,1),x)
andMonomial
sv(Operand(u,2),x));
12Return(false)
End
Figure 6.1. An MPL monomial recognition procedure. (Implementation: Maple
(txt),Mathematica (txt),MuPAD(txt).)
TheDegree
 svOperator
Definition 6.6. Letube an algebraic expression .I fuis a polynomial in x,
the operator
Degree
 sv(u,x)
returns deg(u,x).I fuis not a polynomial in x, the operator returns the
symbolUndeﬁned .
Example 6.7.
Degree
 sv(3x2+4x+5,x)→2,
Degree
 sv(2x3,x)→3,
Degree
 sv((x+1 ) (x+3 ),x)→Undeﬁned ,
Degree
 sv(3,x)→0. /square
218 6. Structure of Polynomials and Rational Expressions
Procedure Polynomial
sv(u,x);
Input
u:a nalgebraic expression ;
x:as y m b o l ;
Output
trueorfalse;
Local Variables
i;
Begin
1 ifMonomial
sv(u,x)then
2Return(true)
3 elseifKind(u)=”+” then
4 fori:= 1toNumber
of
operands(u)do
5 ifMonomial
sv(Operand(u,i),x)=false then
6 Return(false);
7Return(true);
8Return(false)
End
Figure 6.2. AnMPLpolynomialrecognition procedure. (Implementation: Maple
(txt),Mathematica (txt),MuPAD(txt).)
Procedures for the operator Degree
 sv(u,x), similar to the ones for
Monomial
 svandPolynomial
 sv,a r eg i v e ni nF i g u r e s 6.3and6.4.Int h i s
case, the procedure Degree
 monomial
 sv(u,x) gives the degree for mono-
mials, and Degree
 sv(u,x) is deﬁned in terms of this procedure. Observe
that in Degree
 monomial
 svat line 17, we use the structural assumption
that a constant in a product is the ﬁrst operand (Rule 2, page 90)2.
TheCoefficient
 svOperator
Definition 6.8. Letube an algebraic expression .I fuis a polynomial in x,
the operator
Coeﬃcient
 sv(u,x,j)
returns the coeﬃcient ujofxjin Equation ( 6.1). Ifj>deg(u,x),C o e ﬃ c i e n t
 sv
returns 0.I fuis not a polynomial in x, the operator returns the symbol
Undeﬁned .
2This assumption holds in both Maple and Mathematica. In MuPAD, however, since
the constant is the last operand in a product, line 17 is replaced by Return (s).
6.1. Single Variable Polynomials 219
Procedure Degree
monomial
sv(u,x);
Input
u:a nalgebraic expression ;
x:as y m b o l ;
Output
deg(u,x) or the global symbol Undeﬁned ;
Local Variables
base,exponent ,s,t;
Begin
1 ifu=0then
2Return(−∞)
3 elseifKind(u)∈{integer ,fraction }then
4Return(0)
5 elseif u=xthen
6Return(1)
7 elseifKind(u)=” ∧”then
8base:=Operand(u,1);
9exponent :=Operand(u,2);
10 ifbase=xandKind(exponent)=integer and exponent >1then
11 Return(exponent)
12 elseifKind(u)=” ∗”then
13 ifNumber
of
operands(u)=2then
14 s:=Degree
monomial
sv(Operand(u,1),x);
15 t:=Degree
monomial
sv(Operand(u,2),x);
16 ifs/negationslash=Undeﬁned and t/negationslash=Undeﬁned then
17 Return(t)
18Return(Undeﬁned )
End
Figure 6.3. An MPL procedure for Degree
monomial
sv. (Implementation:
Maple(txt),Mathematica (txt),MuPAD(txt).)
Example 6.9.
Coeﬃcient
 sv(x2+3x+5,x ,1)→3,
Coeﬃcient
 sv(2x3+3x, x,4)→0,
Coeﬃcient
 sv(3,x ,0)→3,
Coeﬃcient
 sv((x+1 ) (x+3 ),x ,2)→Undeﬁned ./square
TheCoeﬃcient
 svoperator is implemented with procedures similar to
those for Polynomial
 svandDegree
 sv(Exercise 6).
220 6. Structure of Polynomials and Rational Expressions
Procedure Degree
sv(u,x);
Input
u:a nalgebraic expression ;
x:as y m b o l ;
Output
deg(u,x) or the global symbol Undeﬁned ;
Local Variables
d,i,f;
Begin
1 d:=Degree
monomial
sv(u,x);
2 ifd/negationslash=Undeﬁned then
3Return(d)
4 elseifKind(u)=”+” then
5 d:= 0;
6 fori:= 1toNumber
of
operands(u)do
7 f:=Degree
monomial
sv(Operand(u,i),x);
8 iff=Undeﬁned then
9 Return(Undeﬁned )
10 else
11 d:=Max({d,f})
12Return(d);
13Return(Undeﬁned )
End
Figure 6.4. An MPL procedure for Degree
sv. (Implementation: Maple(txt),
Mathematica (txt),MuPAD(txt).)
TheLeading
 coefficient
 svOperator
Definition 6.10. Letube an algebraic expression .I fuis a polynomial in
x, the operator
Leading
 coeﬃcient
 sv(u,x)
returns lc(u,x)(Deﬁnition 6.1,p a g e 214). Ifuis not a polynomial in x,
the operator returns the symbol Undeﬁned .
Example 6.11.
Leading
 coeﬃcient
 sv(x2+3x+5,x)→1,
Leading
 coeﬃcient
 sv(3,x)→3./square
6.1. Single Variable Polynomials 221
TheLeading
 coeﬃcient
 svoperator can be obtained with a composition
of the Degree
 svandCoeﬃcient
 svoperators. For example, if u=3x2+
4x+ 5, the leading coeﬃcient is obtained with
Coeﬃcient
 sv(u,x,Degree
 sv(u,x))→3.
Another approach is to obtain it directly with procedures similar to those
forDegree
 sv(Exercise 7).
Multivariate Polynomials
Polynomials that contain more than one variable are called multivariate
polynomials .
Definition 6.12. (Mathematical Deﬁnition) Amultivariate poly-
nomialuin the set of symbols {x1,x2,...,x m}is a ﬁnite sum with (one
or more) monomial terms of the form
cxn1
1xn2
2···xnm
m,
where the coeﬃcient cis a rational number and the exponents njare non-
negative integers.
Example 6.13. The following are multivariate polynomials:
p+1/2ρv2+ρgy, ax2+2bx+3c, x2−y2,m c2,3x2+4./square
Although it is possible to give a computational deﬁnition for multivari-
ate polynomials that is similar to Deﬁnition 6.3and to extend the primitive
operations to this setting (Exercise 2), it is more convenient to do so in the
context of general polynomial expressions, which are deﬁned in the nextsection.
Exercises
For the exercises in this section, do not use the polynomial operators in a CAS.
1. Theheightof a polynomial is the maximum of the absolute values of its
coeﬃcients. Let ube analgebraic expression . Give a procedure
Polynomial
height(u,x)
that returns the height of a polynomial. If uis not a polynomial in x,
return the global symbol Undeﬁned .
2. (a) Give a computational deﬁnition for multivariate polynomials that is
similar to Deﬁnition 6.3.
222 6. Structure of Polynomials and Rational Expressions
(b) Give a procedure
Polynomial
mv(u,S)
that returns trueif analgebraic expression uis a multivariate poly-
nomial in a set Sof symbols and otherwise returns false.
3. Give a deﬁnition for a polynomial that includes expressions that contain
products and positive integer powers of expressions that satisfy Deﬁnition
6.3. For example,
x3+(x+1)(x+2)+4 ,(x2+x+1)3,1+(x+1)(x+2)2,((x+1)2+1)2
are polynomials according to this new deﬁnition. Give a procedure
Polynomial
sv
unexp(u,x)
that returns trueif analgebraic expression is a polynomial in this sense
and otherwise returns false.D on o tus et h e Algebraic
expandoperator as
part of the deﬁnition or the procedure.
4. Consider the class of expressions that are polynomials in ywith coeﬃ-
cients that are polynomials in xwith rational number coeﬃcients. For
example, u=( 1+ x2)y3+(2x−1)yis in this class. Give a procedure
Polynomial
xy(u,x,y) that returns trueif analgebraic expression is in
this class and otherwise returns false.
5. Consider theclass ofexpressionsthatarepolynomials in xwith coeﬃcients
that have the form c+d√
2w h e r e canddare rational numbers. For
example, the expressions x3+(1−√
2)x2+3+√
2a n d2√
2x−1a r ei n
this class. Give a procedure Polynomial
sq2(u,x) that returns trueif an
algebraic expression is in this class, and otherwise returns false.
6. Give a procedure for Coeﬃcient
sv(u,x,j).Hint:First give a procedure
Coeﬃcient
monomial
sv(u,x)
that returns a list [ c, m], where mi st h ed e g r e eo ft h em o n o m i a la n d cis
the coeﬃcient of xm.I fuis not a monomial, return the global symbol
Undeﬁned .
7. Give a procedure for Leading
coeﬃcient
sv(u,x) that does not use the
Degree
svorCoeﬃcient
svoperators.Hint:Modify the procedures for
Degree
sv. First give a procedure
Leading
coeﬃcient
monomial
sv(u,x)
that returns a list [ c, m], where mi st h ed e g r e eo ft h em o n o m i a la n d cis
the coeﬃcient of xm.I fuis not a monomial, return the global symbol
Undeﬁned .
6.2. General Polynomial Expressions 223
8. Let ube analgebraic expression .W h e n uis a polynomial in x, the pro-
cedureCoeﬃcient
list(u,x) returns the list of coeﬃcients of powers of x
inu.W h e n uis not a polynomial in x, the procedure returns the global
symbol Undeﬁned . For example,
Coeﬃcient
list(2x5+3x2+4x+5,x)→[2,3,4,5].
Give a procedure for Coeﬃcient
list(u,x).
9. A rational expression in xis an expression of the form p/q,w h e r e pand
qare polynomials with rational number coeﬃcients. The following are
rational expressions:
1
x+3,x+5
x2−2,x2−1,
where, in the third example, q=1 .Le t ubeanalgebraic expression .G i v e
a procedure
Rational
sv(u, x)
thatreturns truewhenuisarationalexpressionin xandotherwisereturns
false. Use the numerator and denominator operators in a CAS to obtain
pandq(Figure4.1on page124).
6.2 General Polynomial Expressions
There are many expressions that are polynomials in a computational con-
text that are not included in the previous deﬁnitions for polynomials. For
example, it is reasonable to consider the expression
u=a
(a+1 )x2+bx+1
a
as a polynomial in x, even though it does not satisfy the deﬁnitions in
Section 6.1. Indeed, a CAS views this expression as a polynomial when it
solves the quadratic equation u=0f o rx. In addition, it is reasonable to
view the expressions sin3(x)+2s i n2(x)+3a n d( x+1 )3+2(x+1 )2+3
as polynomials in terms of a complete sub-expression (sin( x)o r(x+ 1)).
On the other hand, the expression (3sin( x))x2+( 2l n (x))x+4i sn o ta
polynomial in xbecause the coeﬃcients of the powers of xalso depend
onx.
The next deﬁnition includes the more general polynomial expressions
given above.
Definition 6.14. (Mathematical Deﬁnition) Letc1,c2,...,c rbe al-
gebraic expressions and let x1,x2,...,x mbe algebraic expressions that are
224 6. Structure of Polynomials and Rational Expressions
not integers or fractions. A general monomial expression (GME) in
{x1,x2,...,x m}is an expression of the form
c1c2···crxn1
1xn2
2···xnm
m, (6.5)
where the exponents njare non-negative integers and each cisatisﬁes the
independence property
Free
of(ci,xj)→true,forj=1,2,...,m. (6.6)
The expressions xjare calledgeneralized variables because they mimic
t h er o l eo fv a r i a b l e s ,a n dt h ee x p r e s s i o n s ciare calledgeneralizedcoeﬃ-
cients because they mimic the role of coeﬃcients. The expression
xn1
1···xnm
m
is called the variablepart of the monomial, and if there are no generalized
variables in the monomial, the variable part is 1. The expression c1···cris
called thecoeﬃcientpart of the monomial, and if there are no generalized
coeﬃcients in the monomial, the coeﬃcient part is 1. An expression uis a
general polynomial expression (GPE) if it is either a GME or a sum
of GMEs in {x1,x2,...,x m}.
Example 6.15. The following are general polynomial expressions:
x2−x+1,(x1=x),
x2y−xy2+2,(x1=x, x2=y),
a
(a+1 )x2+bx+1
a,(x1=x), (6.7)
sin3(x)+2s i n2(x)+3,(x1=s i n (x)), (6.8)
(x+1 )3+2(x+1 )2+3,(x1=x+1 ), (6.9)√
2x2+√
3x+√
5,(x1=x). (6.10)
The deﬁnition is quite general. It includes the single variable polyno-
mials (Deﬁnition 6.3), multivariate polynomials (Deﬁnition 6.12) and allows
the more general Expressions ( 6.7), (6.8), (6.9), and ( 6.10). Notice that Ex-
pression ( 6.10) is a GPE, but not a single variable polynomial in the sense
of Deﬁnition 6.1because the coeﬃcients are not rational numbers. On the
other hand, the expression (sin( x))x2+(ln(x))x+4 is not a GPE in xalone
because the coeﬃcients sin( x)a n dl n (x) do not satisfy the independence
property in Equation ( 6.6).
The deﬁnition is also quite ﬂexible because it allows for a choice of which
parts of an expression act as variables and which parts act as coeﬃcients.
6.2. General Polynomial Expressions 225
For example, the expression 2 ax2+3bx+4cc a nb ev i e w e da sap o l y -
nomial in {a,b,c,x }with integer coeﬃcients or as a polynomial in xwith
coeﬃcients 2 a,3band 4c. In fact, it is possible to view the expression as
a polynomial in another variable (say z) with the entire expression as the
coeﬃcient part of z0. In addition, since a sum can be a generalized vari-
able, we can even designate the entire expression as a generalized variable
and view it as a polynomial in terms of itself. /square
The following deﬁnitions for a GME and GPE are more suitable for
computational purposes.
Definition 6.16. (ComputationalDeﬁnition) Ageneralmonomial
expression (GME) in a set of generalized variables
S={x1,x2,...,x m}
is an algebraic expression uthat satisﬁes one of the following rules.
GME-1. Free
of(u,xj)→true,f o rj=1,...,m .
GME-2. u∈S.
GME-3. u=xn,w h e r ex∈Sandn>1is an integer.
GME-4. uis a product, and each operand of uis a GME in S.
Ageneral polynomial expression (GPE) in a set Sof expressions
is an algebraic expression uthat satisﬁes one of the following rules.
GPE-1.uis a GME in S.
GPE-2.uis a sum and each operand of uis a GME in S.
This deﬁnition is similar to Deﬁnition 6.3for single variable polynomi-
als. In this case, however, rule GME-1, which expresses the independence
property in Equation ( 6.6), replaces rule MON-1, which only allows for
integers or fractions as coeﬃcients. Although the deﬁnition is in terms ofas e tSof generalized variables, a list Lof distinct generalized variables
would serve as well. There are a few instances in later sections where we
refer to a polynomial in a list of variables.
Primitive Operations for General Polynomial Expressions
The operators described in the following deﬁnitions obtain the polynomialstructure of an expression.
226 6. Structure of Polynomials and Rational Expressions
TheMonomial
 gpe andPolynomial
 gpe Operators
Definition 6.17. Letube an algebraic expression ,a n dl e t vbe either a
generalized variable xor a setSof generalized variables. The operator
Monomial
 gpe(u,v)
returnstrue whenever uis a GME in {x}or inS, and otherwise returns
false. The operator
Polynomial
 gpe(u,v)
returnstrue whenever uis a GPE in {x}or inS, and otherwise returns
false.
Example 6.18.
Monomial
 gpe(ax2y2,{x, y})→true,
Monomial
 gpe(x2+y2,{x, y})→false,
Polynomial
 gpe(x2+y2,{x, y})→true,
Polynomial
 gpe(sin2(x)+2s i n (x)+3,sin(x))→true,
Polynomial
 gpe(x/y+2y,{x,y})→false,
Polynomial
 gpe((x+1 )(x+3 ),x)→false./square
Procedures for the operators Monomial
 gpeandPolynomial
 gpeare
given in Figures 6.5and6.6. Although the procedures are based on the
rules in Deﬁnition 6.16, there are two modiﬁcations that are designed to
avoid redundant recursive calls on the Set
free
ofoperator. (The Set
free
of
operator determines if uis free of all of the expressions in a set S(Exercise
1, page 194).) First, in the Monomial
 gpeprocedure the independence
property GME-1 is checked at the end of the procedure in line 14 instead
of at the beginning. The reason for this has to do with the recursive call in
Monomial
 gpewhenuis a product (line 11), together with the recursive
nature of Set
free
of.IfGME-1 were at the beginning of the procedure,
theSet
free
ofoperator would test the operands of a product in GME-1 ,
and might need to re-check them again because of the recursive calls on
Monomial
 gpeat line 11. By placing the rule at the end of the procedure
we avoid this redundancy.
Next, in the Polynomial
 gpeprocedure, we check rule GPE-1 directly
only when uis not a sum (lines 2-3). Since a sum can be a monomial (for
example,u=a+bandS={a+b}), we check for this possibility separately
at line 5. By doing this we avoid redundant calls on Set
free
ofwhich would
6.2. General Polynomial Expressions 227
Procedure Monomial
gpe(u,v);
Input
u:a nalgebraic expression ;
v:ageneralized variable or a set of generalized variables ;
Output
trueorfalse;
Local Variables
i,S,base,exponent;
Begin
1 ifKind(v)/negationslash=set then S:={v}elseS:=v;
2 ifu∈Sthen
3Return(true)
4 elseifKind(u)=” ∧”then
5base:=Operand(u,1);
6exponent :=Operand(u,2);
7 ifbase∈SandKind(exponent)=integer and exponent >1then
8 Return(true)
9 elseifKind(u)=” ∗”then
10 fori:= 1toNumber
of
operands(u)do
11 ifMonomial
gpe(Operand(u,i),S)=false then
12 Return(false);
13Return(true);
14Return(Set
free
of(u,S))
End
Figure 6.5. An MPL procedure for the recognition of GMEs. (Implementation:
Maple(txt),Mathematica (txt),MuPAD(txt).)
occur if Monomial
 gpewere used to check if a sum is a monomial and then
applied again through Monomial
 gpeat line 7.
TheVariables Operator. The polynomial structure of a GPEdepends on
which expressions are chosen for the generalized variables. The operator
in the next deﬁnition deﬁnes a natural set of generalized variables for anexpression.
Definition 6.19. Letube an algebraic expression . The operator
Variables (u)
is deﬁned by the following transformation rules.
228 6. Structure of Polynomials and Rational Expressions
Procedure Polynomial
gpe(u,v);
Input
u:a nalgebraic expression ;
v:ageneralized variable or a set of generalized variables ;
Output
trueorfalse;
Local Variables
i,S;
Begin
1 ifKind(v)/negationslash=set then S:={v}elseS:=v;
2 ifKind(u)/negationslash=”+” then
3Return(Monomial
gpe(u,S))
4 else
5 ifu∈SthenReturn(true);
6 fori:= 1toNumber
of
operands(u)do
7 ifMonomial
gpe(Operand(u,i),S)=false then
8 Return(false);
9Return(true)
End
Figure 6.6. An MPL procedure for the recognition of GPEs. (Implementation:
Maple(txt),Mathematica (txt),MuPAD(txt).)
VAR-1. Ifuis an integer or a fraction, then
Variables (u)→∅.
VAR-2. Supposeuis a power. If the exponent of uis an integer that is
greater than 1, then
Variables (u)→{Operand (u,1)}
(the base of u),o t h e r w i s e
Variables (u)→{u}.
VAR-3. Supposeuis a sum. Then Variables (u)is the union of the gen-
eralized variables of each operand of uobtained using rules VAR-1,
VAR-2, VAR-4, or VAR-5.
VAR-4. Supposeuis a product. Then Variables (u)contains the union
of the generalized variables of each operand of udetermined by rules
VAR-1, VAR-2, or VAR-5, as well as any operand that is a sum.
6.2. General Polynomial Expressions 229
Observe that for a product we include an operand that is a sum in the
variable set (see Expression ( 6.11) below) even though a sum by itself is
not in the variable set (VAR-3).
VAR-5. Ifuis not covered by the above rules, then
Variables (u)→{u}.
The last rule covers symbols, function forms, and factorials.
Example 6.20. For a multivariate polynomial, the operator returns the set
of variables in the expression:
Variables (x3+3x2y+3xy2+y3)→{x,y}.
Other examples include
Variables (3x(x+1 )y2zn)→{x, x+1,y,zn}, (6.11)
Variables (asin2(x)+2bsin(x)+3c)→{a, b, c, sin(x)},
Variables (1/2)→∅,
Variables (√
2x2+√
3x+√
5)→{x,√
2,√
3,√
5}.
The last example shows that the Variables operator also selects expressions
that do not vary in the mathematical sense, but still act as natural place
holders in the expression. In fact, any algebraic expression uis always
aGPEin terms of Variables (u), and when it is viewed in this way, the
coeﬃcient part in each monomial is an integer or fraction (Exercise 7)./square
The procedure for Variables (u)i sl e f tt ot h er e a d e r( E x e r c i s e 6).
TheDegree
 gpe Operator. In the next deﬁnition we generalize the degree
concept to generalized polynomial expressions.
Definition 6.21. LetS={x1,...,x m}be a set of generalized variables. Let
u=c1···cr·xn1
1···xnm
m
be a monomial with non-zero coeﬃcient part. The degree ofuwith respect
to the set Sis the sum of the exponents of the generalized variables:
deg(u,S)=n1+n2+···+nm.
230 6. Structure of Polynomials and Rational Expressions
By mathematical convention, the degree of the 0monomial is deﬁned to
be−∞.
Ifuis aGPE that is a sum of monomials, then deg(u,S)is the max-
imum of the degrees of the monomials. If Scontains a single generalized
variablex, we use the simpler notation deg(u,x), and if the generalized
variables are understood from context, we use deg(u).
Example 6.22.
deg(3wx2y3z4,{x, z})=6,
deg(ax2+bx+c, x)=2,
deg(asin2(x)+bsin(x)+c,sin(x)) = 2,
deg(2x2yz3+wxz6,{x,z})=7./square
Definition 6.23. Letube an algebraic expression ,a n dl e tvbe a generalized
variablexor a setSof generalized variables. The degree operator has the
form:
Degree
 gpe(u,v).
Whenuis aGPE inv, the operator returns deg(u,v).I fuis not a GPE
inv, the operator returns the global symbol Undeﬁned .
Procedures for Degree
 gpe, which are similar to the ones for the oper-
ators Monomial
 gpeandPolynomial
 gpein Figures 6.5and6.6,a r el e f tt o
the reader (Exercise 8).
Definition 6.24. Letube an algebraic expression ,a n dl e t
S=Variables (u).
The operation deg(u,S)is called the total degree of the expression u.
Example 6.25. Ifu=ax2+bx+c,t h e nS={a, b, c, x }, and the total
degree is deg( u,{a,b,c,x })=3. /square
TheCoefficient
 gpe Operator
Definition 6.26. Letube an algebraic expression .I fuis aGPE in a
generalized variable xandj≥0is an integer, then the operator
Coeﬃcient
 gpe(u,x,j)
returns the sum of the coeﬃcient parts of all monomials of uwith variable
partxj. If there is no monomial with variable part xj, the operator returns
6.2. General Polynomial Expressions 231
0. Ifuis not a polynomial in x, the operator returns the global symbol
Undeﬁned .
Example 6.27.
Coeﬃcient
 gpe(ax2+bx+c, x,2)→a,
Coeﬃcient
 gpe(3xy2+5x2y+7x+9,x ,1)→3y2+7,
Coeﬃcient
 gpe(3xy2+5x2y+7x+9,x ,3)→0,
Coeﬃcient
 gpe((3 sin(x))x2+( 2l n (x))x+4,x ,2)→Undeﬁned .
/square
Procedures that obtain coeﬃcients are shown in Figures 6.7and6.8.
Whenuis aGMEinx,t h eCoeﬃcient
 monomial
 gpeprocedure returns a
list [c,m], wheremis the degree uinxandcis the coeﬃcient part of the
monomial. If uis not a monomial in x, the global symbol Undeﬁned is
returned. The case where uis a product is handled in lines 8-18. In lines
9 and 10, the assignments for candmassume initially that the degree is
zero anduis the coeﬃcient part. These values are only changed if some
operand of uis a monomial in xwith positive degree (lines 15-17). Since u
is an automatically simpliﬁed product3, this can happen with at most one
operand of u. Nevertheless, we must check each operand to determine that
uis a monomial in x.
TheCoeﬃcient
 gpeprocedure shown in Figure 6.8is similar to the
Polynomial
 gpeprocedure (Figure 6.6).
Although the Coeﬃcient
 gpeoperator is only deﬁned with respect to a
single generalized variable x, the coeﬃcient part of a more general mono-
mial can be obtained by composition. For example, if u=3xy2+5x2y+
7x+ 9, the coeﬃcient of xy2can be found with
Coeﬃcient
 gpe(Coeﬃcient
 gpe(u,x,1),y,2)→3.
However, if there are dependencies between the generalized variables, then
the order of the coeﬃcient operations is signiﬁcant. For example, if
u=3s i n (x)x2+2l n (x)x+4,
then to obtain the coeﬃcient of ln( x)x,we apply
Coeﬃcient
 gpe(Coeﬃcient
 gpe(u,ln(x),1),x,1)→2.
3We assume here that the power transformation xmxn→xn+m,f o rmandnin-
tegers, is applied during automatic simpliﬁcation, and so a product can have at mostone operand that is a power with base x. This transformation is obtained in Maple,
Mathematica, and MuPAD.
232 6. Structure of Polynomials and Rational Expressions
Procedure Coeﬃcient
monomial
gpe(u,x);
Input
u:a nalgebraic expression ;
x:ageneralized variable ;
Output
The list [ c, m]w h e r e mis the degree of the monomial and
cis the coeﬃcient of xmor the global symbol Undeﬁned ;
Local Variables
base,exponent ,i,c,m,f;
Begin
1 ifu=xthen
2Return([1,1])
3 elseifKind(u)=” ∧”then
4base:=Operand(u,1);
5exponent :=Operand(u,2);
6 ifbase=xandKind(exponent)=integer and exponent >1then
7 Return([1,exponent])
8 elseifKind(u)=” ∗”then
9 m:= 0;
10 c:=u;
11 fori:= 1toNumber
of
operands(u)do
12 f:=Coeﬃcient
monomial
gpe(Operand(u,i),x);
13 iff=Undeﬁned then
14 Return(Undeﬁned )
15 elseifOperand(f,2)/negationslash=0then
16 m:=Operand(f,2);
17 c:=u/xm;
18Return([c,m]);
19 ifFree
of(u,x)then
20Return([u,0])
21 else
22Return(Undeﬁned )
End
Figure 6.7. An MPL procedure for the Coeﬃcient
monomial
gpeoperator. (Im-
plementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
The reverse operation
Coeﬃcient
 gpe(Coeﬃcient
 gpe(u,x,1),ln(x),1)
does not work because the inner coeﬃcient operation returns Undeﬁned .
It is always possible, however, to order the coeﬃcient operations to deter-
6.2. General Polynomial Expressions 233
Procedure Coeﬃcient
gpe(u,x,j);
Input
u:a nalgebraic expression ;
x:ageneralized variable ;
j: a non-negative integer;
Output
The coeﬃcient of xjin the polynomial uor the global symbol Undeﬁned ;
Local Variables
i,c,f;
Begin
1 ifKind(u)/negationslash=”+” then
2 f:=Coeﬃcient
monomial
gpe(u,x);
3 iff=Undeﬁned then Return(Undeﬁned )
4 else
5 ifj=Operand(f,2)thenReturn(Operand(f,1))
6 elseReturn(0)
7 else
8 ifu=xthen
9 ifj=1thenReturn(1)elseReturn(0);
10 c:= 0;
11 fori:= 1toNumber
of
operands(u)do
12 f:=Coeﬃcient
monomial
gpe(Operand(u,i),x);
13 iff=Undeﬁned then Return(Undeﬁned )
14 elseifOperand(f,2) =jthen c=c+Operand(f,1);
15Return(c)
End
Figure 6.8. An MPL procedure for the Coeﬃcient
gpeoperator. (Implementa-
tion:Maple(txt),Mathematica (txt),MuPAD(txt).)
mine the desired coeﬃcient (Exercise 8, page 247). Of course, if uis aGPE
in both expressions, then the order of the coeﬃcient operations does notmatter.
The
Leading
 coefficient
 gpe Operator
Definition 6.28. Letube an algebraic expression .I fuis aGPE inx,t h e n
the leading coeﬃcient of uwith respect to xis deﬁned as the sum of the
coeﬃcient parts of all monomials with variable part xdeg(u,x). The leading
coeﬃcient is represented by lc(u,x),a n dw h e n xis understood from context,
by the simpler notation lc(u).
For example, lc(3 xy2+5x2y+7x2y3+9,x)=5y+7y3.
234 6. Structure of Polynomials and Rational Expressions
Definition 6.29. Letube aGPE inx. The operator
Leading
 coeﬃcient
 gpe(u,x)
returns lc(u,x).I fuis not a GPE inx, the operator returns Undeﬁned .
Leading
 coeﬃcient
 gpecan be obtained by composition of the operators
Degree
 gpeandCoeﬃcient
 gpeor directly with procedures similar to those
forDegree
 gpe(Exercise 11).
An Appraisal of the GPE
General polynomial expressions have been deﬁned so that many expres-
sions that are clearly polynomials are included in the deﬁnition and many
expressions that are not are excluded. In addition, the primitive oper-
ators associated with the deﬁnition work well in most contexts where itis necessary to examine the polynomial structure of an expression. Since
some computer algebra systems have similar operators, the deﬁnitions are
a good starting point to evaluate and compare the polynomial capacity of
CAS software (Exercise 1).
However, the deﬁnition has some limitations. The limitations are asso-
ciated with the restricted notion of coeﬃcient independence as expressed
by the Free
ofoperator in Equation ( 6.6) and are magniﬁed by the simpliﬁ-
cation context of automatic simpliﬁcation in which the operators perform.
The following examples illustrate these points.
Example 6.30. Consider the following operations:
Polynomial
 gpe(x(x2+1 ),x)→false, (6.12)
Polynomial
 gpe(y2(y4+1 ),y2)→true. (6.13)
In Expression ( 6.12), the Polynomial
 gpeoperator concludes that the ex-
pression is not a polynomial in x. In this instance the coeﬃcient of x(the
expression x2+ 1) is not free of x. Expression ( 6.13) is obtained from
Expression ( 6.12) with the structural substitution x=y2.In t h i s c a s e ,
however, the expression is a polynomial in y2. This follows because y2is
not a complete sub-expression of y4+1w h i c hm e a n st h a t y4+ 1 can act
as a coeﬃcient of y2. The problem here has to do with the limited view
of the coeﬃcient part of a monomial which is based on the actions of the
Free
ofoperator together with the actions of automatic simpliﬁcation. /square
6.2. General Polynomial Expressions 235
Example 6.31. Consider the expression u=a(x2+1 )2+(x2+1 )w h i c h
we want to consider as a polynomial in x2+ 1. However,
Polynomial
 gpe(u, x2+1 )→true, (6.14)
Degree
 gpe(u, x2+1 )→2, (6.15)
Coeﬃcient
 gpe(u, x2+1,1)→0, (6.16)
Coeﬃcient
 gpe(u, x2+1,0)→x2+1. (6.17)
In this case the simpliﬁed form of uis
a(x2+1 )2+x2+1. (6.18)
At this point the expression is still a GPEinx2+1w i t hd e g r e e2( E x -
pressions ( 6.14)a n d( 6.15)), although some of its polynomial structure has
been changed (Expressions ( 6.16)a n d( 6.17)). The problem here is the
sum on the right in Expression ( 6.18)x2+ 1 is no longer a complete sub-
expression of the entire polynomial. Since both x2and 1 are free of x2+1,
they are relegated to the role of a coeﬃcient even though the expression u
is a polynomial in the complete sub-expression x2+1 . /square
Example 6.32. Consider the expression u=2(x2)2+3(x2) and consider
the operations:
Polynomial
 gpe(u, x2)→true,
Degree
 gpe(u, x2)→1,
Coeﬃcient
 gpe(u, x2,2)→0,
Coeﬃcient
 gpe(u, x2,1)→3,
Coeﬃcient
 gpe(u, x2,0)→2x4. (6.19)
Automatic simpliﬁcation transforms uto 2x4+3x2which is still a poly-
nomial in x2, but now the degree is 1, and the polynomial structure has
been changed. Indeed, since x4is free ofx2it is considered a coeﬃcient
part in Expression ( 6.19). /square
What can we conclude from these examples? First, the deﬁnition works
best when the generalized variables are symbols, function forms or facto-rials. When the generalized variables are restricted to expressions of this
type, general polynomial expressions are similar to multivariate polynomi-
als with coeﬃcients that are more involved expressions.
The deﬁnitions are less reliable, however, when a generalized variable is
a sum because the polynomial structure of the expression may be altered
236 6. Structure of Polynomials and Rational Expressions
by automatic simpliﬁcation (see Example 6.31). One solution, of course, is
simply to modify the GPEdeﬁnition so that a generalized variable cannot
be a sum. We have resisted doing this because the current deﬁnition is use-
ful for deﬁning the actions of the Algebraic
 expand operator in Section 6.4.
The situation is even more discouraging when a generalized variable is
a power (see Example 6.32above) or a product (Exercise 2). Although, we
rarely get satisfactory results in these cases, we have included them in thedeﬁnition because there are a few instances when the primitive operators
described here give satisfactory results.
Extensions of the Basic Definitions and Procedures
There are a number of ways that we can remove some of the limitations
of our polynomial model. First, we could restrict the class of generalized
variables to expressions that are in the set Variables (u). It is noteworthy
that the set Variables (u) never contains a product or a power with integer
exponent ≥2, although it can contain a sum. Another possibility is to
extend the capabilities of the operators by performing a more involved
analysis of an expression. (For a more detailed discussion of this extension,
consult Cohen [ 24], Sections 4.1 and 6.2.)
There are two other extensions of the polynomial model that require
only minor modiﬁcations to the deﬁnitions and basic procedures. One pos-sibility is to allow generalized variables to have negative integer exponents
even though this is not ordinarily done in mathematical deﬁnitions for poly-
nomials. For example, when this is done the expression 2 /x+3/x
2is a
polynomial with deg(u)=−1. When negative exponents are allowed, it
is also useful to deﬁne the operation low
 deg(u,x) that returns the lowest
power ofxin the expression. For example, low
 deg(2/x+3/x2,x)=−2.
A particularly useful modiﬁcation of the model is to drop the indepen-
dence Free
ofcondition GME-1 in Deﬁnition 6.16. When this is done an
expression such as ( x+1 )x2+l n (x)x+s i n (x) is a polynomial in xeven
though the coeﬃcients x+1,l n (x), and sin( x) are not free of x. Although
this modiﬁcation causes expressions to lose some of their polynomial struc-ture, it does allow the degree and coeﬃcient operations to be applied in
some useful situations. The deﬁnitions and procedures for the basic oper-
ators for this model are described in Exercise 12.
Exercises
1. In thisexercise weask youtoexplorethepolynomial capabilities ofa CAS.
For a CAS, consider its versions of MPL’s Polynomial
gpe,Degree
gpeand
Coeﬃcient
gpeoperators.
6.2. General Polynomial Expressions 237
(a) In Maple consider the typecommand with polynomoption, and the
degreeand coeffoperators.
(b) In Mathematica consider the operators PolynomialQ ,Exponent,a n d
Coefficient .
(c) InMuPADconsiderthe typeoperator withthe PolyExpr option, and
thedegreeand coeffoperators.
Consider the following questions.
(a) Does the polynomial model in a CAS employ the same coeﬃcient
independence condition as the MPL model?
(b) Are sums, products, or powers permitted as generalized variables?
(c) Are negative integer exponents permitted in the polynomial model?
(d) Is expansion part of the simpliﬁcation context?
(e) Does the model extend the MPL model in signiﬁcant way?
2. Explain why it is usually not meaningful to view an expression uas a
polynomial in terms of an expression vthat is a product.
3. Let ubeandalgebraic expression andlet Sbeasetofgeneralizedvariables.
Give a procedure
Coeﬀ
var
monomial (u,S)
that returns a two element list with the coeﬃcient part andvariable part
ofu.I fuis not aGMEinS, the procedure returns the global symbol
Undeﬁned . (This procedure is used in the Collect
termsprocedure (see
Figure6.9on page249).)
4. Give a procedure
Bilinear
form(u,x,y)
thatreturns truewhen analgebraic expression uhas theform ax+by+c,
where xandyare symbols and a,b,a n d care free of xandy.I fu
does not have this form, return false. Interpret the form broadly to allow
2x+cx+3y+dy+4 to be in this form.
5. What is returned by the Variables operator, and what is the total degree
for each of the following?
(a) (x+1)(x+2)+( x+3).
(b)(x+1)2
(1−x)2.
(c)x2
a2+x
a+b.
(d)xm+sin(x)x+1/(xy).
6. Let ube analgebraic expression . Give a procedure for Variables(u).
238 6. Structure of Polynomials and Rational Expressions
7. Suppose an algebraic expression uis viewed as a GPEinVa r i a b l e s (u).
Explain why the coeﬃcient part of a monomial in umust be an integer or
af r a c t i o n .
8. Let ube analgebraic expression ,a n dl e t vbe ageneralized variable or a
set ofgeneralized variables . In this exercise we ask youto give procedu res
to compute deg(u,v) (see Deﬁnition 6.23). First, give a procedure
Degree
monomial
gpe(u,v)
thatﬁndsthedegree ofamonomial andthenaprocedure Degree
gpe(u,v).
9. Let ube analgebraic expression . Give a procedure Total
degree(u)t h a t
returns the total degree of u. To make the exercise interesting, do not use
theDegree
gpeorVariables operators.
10. Let ube a multivariate polynomial in xandywith rational number co-
eﬃcients. The polynomial is called a homogeneous polynomial if every
monomial term has the same total degree. For example, the polynomial
u=x2+2xy+y2is homogeneous. Give a procedure
Homogeneous
 polynomial (u,x,y)
that returns trueifuis homogeneous in xandyandfalseotherwise.
11. Let ube analgebraic expression ,a n dl e t xbe ageneralized variable .
(a) Give a procedure for Leading
coeﬃcient
gpe(u,x)t h a td o e sn o tus e
theDegree
gpeorCoeﬃcient
gpeoperators. If uis not aGPEinx,
return the global symbol Undeﬁned .
(b) Give a procedure Leading
coeﬀ
degree
gpe(u,x) that returns the list
[lc(u,x),deg(u,x)].
Ifuis not aGPEinx, return the global symbol Undeﬁned .D on o t
use theDegree
gpeorCoeﬃcient
gpeoperators in this exercise.
12. Let xbe a symbol. In this exercise we give an alternate deﬁnition of a
polynomial that does not require the coeﬃcients of powers of xto be free
ofx.
Analgebraic expression uis analternate general monomial expres-
sioninxif it satisﬁes one of the following rules.
GMEALT-1. u=x.
GMEALT-2. u=xnwhere n>1 is an integer.
GMEALT-3. uis a product, and each operand of uis either a sum or
satisﬁes one of the rules GMEALT-1, GMEALT-2, or GMEALT-4.
GMEALT-4. uis analgebraic expression that is not sum and does not
satisfy rules GMEALT-1, GMEALT-2, or GMEALT-3.
6.2. General Polynomial Expressions 239
Rules GMEALT-1 and GMEALT-2 give monomials of positive degree, and
rule GMEALT-3 gives a monomial of positive degree if oneof theoperands
satisﬁes GMEALT-1 or GMEALT-2 and otherwise has degree 0. Rule
GMEALT-4 gives monomials with degree 0 in xsuch as
2,3/2,a2,sin(x),1/(x+1).
In addition, according to this rule a sum is not a monomial of degree 0.
On the other hand, in GMEALT-3 a sum is allowed as an operand in a
product that is a monomial. This means that the following are monomials
inx:
(a+1)x2,(x+1)x2,(x+1)(x+2),(x+1)2,
where the ﬁrst two expressions have degree 2 in xand the last two expres-
sions have degree 0.
Analgebraicexpression uisalternate general polynomial expression
inxif it satisﬁes one of the rules:
GPEALT-1. uis an alternate general monomial expression in x.
GPEALT-2. uis a sum, and each operand of uis an alternate general
monomial expression in x.
With this deﬁnition
u=x2
x+1+sin(x)x+c
is a polynomial in xand operations such as deg(u,x)=2 are well deﬁned.
Give procedures
Degree
alternate(u,x),Coeﬃcient
alternate(u,x,j)
that obtain the degree and coeﬃcient operations in this context.
13. Let ube analgebraic expression ,a n dl e t xbe a symbol. In this exercise
we extend the basic deﬁnitions for monomials and polynomials so thatexponents of xcan be any algebraic expressions that are free of x.F o r
example, in this context the expression
u=x
m+1+3xn+4x3+5x+6x−1
is a polynomial in x. Give a procedure Degree
general(u,x) that obtains
the degree of these polynomial expressions. If uis not a polynomial in this
sense (e.g., xx), then return the global symbol Undeﬁned .F o rt h ea b o v e
polynomial u,
Degree
 general(u,x)→Max({m+1,n ,3}).
In other words, in instances where Degree
 generalis unable to actually
ﬁnd the maximum, an unevaluated Maxfunction form is returned. A
240 6. Structure of Polynomials and Rational Expressions
version ofMaxthat obtains this operation is described in Exercise 16on
page198.
The Mathematica Exponent operator performs an operation similar to the
one described here.
14. The ﬁrst step in the Solve
odealgorithm (see Figure 4.16on page162)
transforms a diﬀerential equation to the form
M+Ndy
dx=0. (6.20)
This operation is performed by the Transform
odeprocedure which re-
turns a list [ M,N]. TheTransform
odeassumes that the equation can be
transformed to this form but does not check that this is so. Modify the
Transform
odeprocedure so that it checks that the transformed equation
has the form of Equation ( 6.20), where MandNdo not contain the func-
tion form named d, and when this is so returns [ M,N]. If the expression
cannot be transformed to this form, return the symbol Fail. For example,
Transform
ode(x2=d(y,x)+y,x,y)→[x2−y,−1],
Transform
ode(x2=d(y,x,2),x,y)→Fail.
The procedures described in this section and the Derivative
orderproce-
dure (see Exercise 15on page197) are useful for this problem.
15. (a) Alineardiﬀerential operator is an expression of the form
andny
dxn+an−1dn−1y
dxn−1+···+a1dy
dx+a0y+f
where aiandfarealgebraic expressions that are free of y.L e tube
analgebraic expression . Give a procedure
Linear
derivative
order(u, x, y)
that determines if uis a linear diﬀerential operator and, when this is
so, returns the order of the highest derivative of yinu.I fuis linear
inybutcontains noneof its derivatives, theprocedure returns0. If u
does not contain yor its derivatives, the procedure returns −1. Ifu
is not a linear diﬀerential operator, the procedure returns the globalsymbol Undeﬁned .A si nS e c t i o n 4.3, represent the derivative
dy
dx
with the function notation d(y, x) and higher order derivatives
dny
dxn
6.2. General Polynomial Expressions 241
withd(y, x, n). To simplify matters, if ucontains any function forms
with the name dthat contain operands diﬀerent from those in d(y,x)
andd(y,x,n), return the symbol Undeﬁned . For example,
Linear
derivative
order(d(y,x,2)+2x, x, y)→2,
Linear
derivative
order(2y+3x, x, y)→0,
Linear
derivative
order(2x+3,x ,y)→−1,
Linear
derivative
order(d(y,x)+y2,x ,y)→Undeﬁned ,
Linear
derivative
order(d(b),x ,y)→Undeﬁned .
(b) In Exercise 7, page169we describe a procedure Solve
ode
2(a,b,c,f)
that obtains a solution to the diﬀerential equation
ad2y
dx2+bdy
dx+cy=f, (6.21)
where a,b,andcarerationalnumbersand fisanalgebraic expression
that is free of y. Give a procedure Transform
ode
2(w,x,y)t h a td e -
terminesifanequation wcan betransformed totheformofEquation
(6.21) by rational simpliﬁcation and if so returns the list [ a,b,c,f]. If
wcannot be transformed to this form, then return Fail.Hint:This
procedure is similar to the procedure Transform
odein Exercise 14
above. For example,
Transform
ode
2(2d(y,x,2)+3 y=x2,x ,y)→[2,0,3,x2],
Transform
ode
2Wx2
d(y,x,2)−3=0,x ,y}
→[−3,0,0,−x2],
Transform
ode
2(xd(y,x,2)+3 y=x2,x ,y)→Fail.
16. A diﬀerential equation that has the form
dy
dx=Py+Qyn(6.22)
where P/negationslash=0a nd Q/negationslash=0a ref re eo f yandn/negationslash=1i sf re eo f xandyis called
aBernoulli equation. For example
dy
dx=y+xy3
is a Bernoulli equation. This equation is solved by deﬁning a new variable
z=y1−n(6.23)
that transforms the equation to
1
1−ndz
dx=Pz+Q. (6.24)
Oncewesolvethisequation,weobtainthesolution toEquation( 6.22)with
the substitution in Expression ( 6.23).
242 6. Structure of Polynomials and Rational Expressions
(a) Show that Equation ( 6.24) can be solved using the algorithm in Sec-
tion4.3.
(b) Give a procedure Bernoulli(u,x,y) that tries to determine if a dif-
ferential equation uis a Bernoulli equation and if so uses the proce-
dureSolve
ode(see Figure 4.16on page162) to ﬁnd the solution to
Equation ( 6.24) and then obtains the solution in terms of ywith the
substitution in Expression ( 6.23).
6.3 Relationships Between Generalized Variables4
In this section we state and prove a number of mathematical properties of
theFree
ofoperator and use these properties to investigate the indepen-
dence of generalized variables.
Mathematical Properties of the Free
 ofOperator
Theorem 6.33. Letu,v,a n dwbe mathematical expressions.
1. Ifu/negationslash=v,t h e n (Free
of(u,v)orFree
of(v,u))→true.
2.(TransitiveProperty) IfFree
of(u,v)→false andFree
of(v,w)→
false,t h e n Free
of(u,w)→false.
Proof: Both statements are easily proved. To show (1), if Free
of(u,v)
andFree
of(v,u)a r eb o t hfalse,t h e nvis a complete sub-expression of u,
anduis a complete sub-expression of v. The only way this can happen is
foru=v. However, u/negationslash=v, and so either Free
of(u,v)o rFree
of(v,u)m u s t
betrue. (Of course, both can be true.)
To show (2), the hypothesis states that vis a complete sub-expression
ofu,a n dwis a complete sub-expression of v. Therefore, wis a complete
sub-expression of uandFree
of(u,w)→false. /square
The next theorem extends Theorem 6.33( 1 )t oas e t Sof expressions.
Theorem 6.34. LetS={x1,x2,...,x m}be a set of mathematical expres-
sions (with m≥2).T h e n ,t h e r ei sa n xjinSsuch that
Free
of(xk,xj)→true,fork=1,2,...,j −1,j+1,...,m.
4This section is more theoretical than the previous sections.
6.3. Relationships Between Generalized Variables 243
Proof: The theorem is proved with mathematical induction. First, for
the base case m= 2, the theorem follows from Theorem 6.33(1). Next,
suppose the theorem is trueforS∼{xm}. This implies that there is an
xj,w i t h1 ≤j≤m−1, such that
Free
of(xk,xj)→true,fork=1,2,...,j −1,j+1,...,m −1.(6.25)
To show that the theorem holds for S, we consider the two cases where
Free
of(xm,xj)i se i t h e rtrueorfalse. In the ﬁrst case, Free
of(xm,xj)i s
true, and this assumption, together with the induction hypothesis ( 6.25),
implies that xjsatisﬁes the theorem for Sas well.
For the second case, we assume that
Free
of(xm,xj)→false, (6.26)
and show that xmsatisﬁes the conclusion of the theorem. First, Theorem
6.33(1) applied to Expression ( 6.26) implies that
Free
of(xj,xm)→true. (6.27)
To complete the proof we must show that
Free
of(xk,xm)→true,fork=1,2,...,j −1,j+1,...,m −1.(6.28)
However, if for some k,Free
of(xk,xm)w e r efalse, then this fact, together
with Expression ( 6.26), would imply that Free
of(xk,xj)i sfalsewhich
contradicts the induction hypothesis ( 6.25). Therefore, ( 6.28), together
with (6.27), shows that xmsatisﬁes the conclusion of the theorem. /square
Example 6.35. Ifx1=s i n (x),x2=l n ( s i n (x)), andx3=x,t h e nj=2a n d
Free
of(x1,x2)= Free
of(sin(x),ln(sin(x)))→true,
Free
of(x3,x2)= Free
of(x,ln(sin(x)))→true. /square
Theorem 6.36. LetS={x1,x2,...,x m}be a set of (distinct) mathematical
expressions. Then, there is a permutation (reordering) of S,
[xj1,xj2,...,x jm]
such that (for i<m )
Free
of(xk,xji)→true,fork=ji+1,...,j m.
244 6. Structure of Polynomials and Rational Expressions
The involved notation makes the theorem seem more complicated than
it is. It simply states that we can rearrange the expressions in Sinto a list
so that any expression in the list is free of all expressions that precede it
in the list.
Proof: [Theorem 6.36 ]Let the ﬁrst expression in the list xj1be the expres-
sion described in the conclusion of Theorem 6.34. Then all expressions xk
inS∼{xj1}satisfy the property Free
of(xk,xj1)→true. In general, de-
ﬁnexjito be the expression from the set S∼{xj1,...,x ji−1}that satisﬁes
the conclusion of Theorem 6.34. /square
Example 6.37. Supposex1=s i n (x),x2=x,a n dx3= ln(sin(x)). A re-
ordering that satisﬁes the conclusion of the theorem is i1=3,i2=1,i3=2
or
[ln(sin(x)),sin(x),x].
Ino t h e rw o r d s
Free
of(xi2,xi1)= Free
of(sin(x),ln(sin(x)))→true,
Free
of(xi3,xi1)= Free
of(x,ln(sin(x)))→true,
Free
of(xi3,xi2)= Free
of(x,sin(x))→true./square
InE x e r c i s e 2we describe a procedure that ﬁnds the permutation of the
expressions guaranteed by Theorem 6.36.
Relationships Between Generalized Variables
Although the deﬁnition of a GPErequires the coeﬃcients cibe independent
of the generalized variables xj, it does not require the generalized variables
be independent of each other. For example, the expression
2x(ln(x))2+3x2ln(x) + 4 (6.29)
is a polynomial in {x,ln(x)}, even though the two expressions are not
independent (e.g., ln( x) depends on x). When a dependence relationship
like this exists, it is not possible to view the expression as a polynomialin one of the generalized variables. For example, although the expression
(6.29) is a polynomial in {x,ln(x)}and in ln(x) alone, it is not a polynomial
inxalone. In this regard, we have the following two theorems.
Theorem 6.38. Ifuis aGPE in each of the expressions x1,x2,...,x m
individually, then it is also a GPE in{x1,x2,...,x m}.
6.3. Relationships Between Generalized Variables 245
Theorem 6.39. Supposeuis aGPE inS={x1,x2,...,x m}, and suppose
that for some j
Free
of(xk,xj)→true, k =1,2,...,m, k /negationslash=j.
Thenuis aGPE inxjalone.
The proofs of the theorems are left to the reader (Exercises 4and5).
However, if uis a polynomial in a set of expressions, then it must also
be a polynomial in at least one of the generalized variables.
Theorem 6.40. Letube aGPE in the expressions S={x1,x2,...,x m}.
Thenuis also a GPE in somexj.
Proof: This theorem follows from Theorem 6.34and Theorem 6.39./square
Sometimes it is useful to replace the generalized variables in an expres-
sion by symbols. This can be done with concurrent substitution. Let ube a
GPEinS={x1,x2,...,x m}and lety1,y2,...,y mbe unassigned symbols.
The substitution
Concurrent
 substitute (u,[x1=y1,x2=y2,...,x m=ym])
creates a multivariate polynomial with each generalized variable xireplaced
by a symbol yi.
With sequential substitution, however, we may not obtain the intended
substitution. This point is illustrated in the next example.
Example 6.41. Consider the expression u=ssin(s) ln(sin(s)) as a poly-
nomial in S={s,sin(s),ln(sin(s))}. We obtain a multivariate polynomial
with the substitutions
Sequential
 substitute (u,[x=l n ( s i n (s)),y=s i n (s),z=s])→zyx.
On the other hand, if the order of substitutions is
Sequential
 substitute (u,[y=s i n (s),z=s, x= ln(sin(s))])→zyln(y),
we don’t eliminate all generalized variables. /square
However, Theorem 6.36implies that we can ﬁnd a re-ordering of the
generalized variables [ xj1,xj2,...,x jm] so that the substitution
Sequential
 substitute (u,[xj1=y1,xj2=y2,...,x jm=ym])
246 6. Structure of Polynomials and Rational Expressions
creates a multivariate polynomial with each generalized variable xjire-
placed by a symbol yi.
By substituting symbols for generalized variables, we alter some of the
polynomial structure of an expression. For example, the new expressionwill be a GPEin eachy
jindividually even though the original polynomial
may not be a GPEin terms of each of the generalized variables.
Exercises
1. Suppose
Free
of(u,v)→true,Free
of(v,w)→true.
Does this imply that Free
of(u,w)→true?
2. Let S={x1,x2,...,x m}be a set of (distinct) mathematical expressions.
Giveaprocedure Free
of
sort(S)thatreturnsthelistofre-orderedexpres-
sions described in Theorem 6.36.Hint:Any elementary sorting algorithm
(insertion sort, bubble sort, selection sort) will do where vprecedes uin
the list ifFree
of(u,v)→true.
3. Let Sbe a set of symbols, and suppose uis aGPEinS. Show that uis a
polynomial in each member of S.
4. Prove Theorem 6.38.
5. Prove Theorem 6.39.
6. Let ube an algebraic expression, and consider uas aGPEinVariables(u).
Give a procedure GPE
to
mult(u) that transforms uto a multivariate
polynomial. Note:This problem requires an arbitrary number of variable
names. The CAS must have the capability to generate variable names5or
provide subscripted variables.
7. (a) Let Lbe a list of symbols and let ube a multivariate polynomial in
the symbols of Lwith rational number coeﬃcients. The operator
Leading
numer
coeﬀ(u,L)
obtains the leading numerical coeﬃcient of an expression which is
deﬁned using the following rules.
LNC-1. IfL=[] ,the n
Leading
numer
coeﬀ(u,L)→u.
LNC-2. Letx=First(L,1) and l=Leading
coeﬃcient
gpe(u,x).
Then,
Leading
numer
coeﬀ(u,L)→Leading
numer
coeﬀ(l,Rest(L)).(6.30)
5For example, in Mathematica the Unique command creates symbol names, or in
Maple the catcommand concatenates variable names and integer values. (Implementa-
tion: Maple (mws), Mathematica (nb).)
6.4. Manipulation of General Polynomial Expressions 247
For example,
Leading
numer
coeﬀ(2x2y+3xy2,[x,y])→2,
Leading
numer
coeﬀ(2x2y+3xy2,[y,x])→3.
Notice that the leading numerical coeﬃcient depends on the order of
the symbols in L. Give a procedure for Leading
numer
coeﬀ(u,L).
(b) Let s=Leading
numer
coeﬀ(u,L). If u/negationslash= 0, deﬁne the polyno-
mial sign ofuwith respect to Las the sign (1 or −1) ofs.I n
addition deﬁne the polynomial sign of 0 as 0. Give a procedure for
Polynomial
sign(u,L) that returns the polynomial sign.
(c) Give a procedure Polynomial
sign
var(u) which obtains the polyno-
mial sign of uwith respect to the expressions in Variables(u). For
this operation it is necessary to replace the generalized variables in u
with symbols because the coeﬃcient computation in ( 6.30)m a yc r e -
atenewgeneralized variables(Exercise 6). Forexample, thishappens
withu=−c∗(x+y) which has the generalized variables candx+y.
However, by automatic simpliﬁcation the coeﬃcient of cis−x−y
which has two new generalized variables xandy.
Since the polynomial sign depends on the order of the expressions in
thesetVariables(u),it isusefultocreatealist of thegeneralized vari-
ables in a standard order. (Formore information on an orderrelation
that can be used for this purpose, consult Cohen [ 24], Section 3.1.)
8. Suppose that uis aGPEinS={x1,x2,...,x m},a n dl e t n1,...n mbe
non-negative integers.
(a) Explain why it is always possible to obtain the coeﬃcient of
xn1
1xn2
2···xnm
m
using a composition of Coeﬃcient
gpeoperators.
(b) Give a procedure Coeﬃcient
vars(u,L)w h e r e
L=[ [x1,n1],[x2,n2],...,[xm,nm]]
that implements the statement in part (a).
6.4 Manipulation of General Polynomial Expressions
In this section we describe two operators that manipulate general polyno-
mial expressions. Both of the operators are based on the two distributive
transformations:
a(b+c)=ab+ac, (a+b)c=ac+bc. (6.31)
248 6. Structure of Polynomials and Rational Expressions
TheCollect
 terms Operator
The collection of coeﬃcients of like terms in a polynomial occurs frequently
in algebraic manipulation. During automatic simpliﬁcation this operation
is applied only to monomials with coeﬃcient parts that are rational num-
bers. The collection of (rational and non-rational) coeﬃcients is obtained
with the Collect
 terms operator. The goal of this operator is given in the
next deﬁnition.
Definition 6.42. Analgebraic expression uis incollected form in a set
Sofgeneralized variables if it satisﬁes one of the following properties:
1.uis aGME inS.
2.uis a sum of GMEsinSwith distinct variable parts .
The deﬁnition is similar to Deﬁnition 6.16for general polynomial ex-
pressions (page 225), except now property (2) requires that the variable
parts be distinct.
Example 6.43. The expression
(2a+3b)xy+( 4a+5b)x (6.32)
is in collected form in S={x, y}, where the two distinct variable parts are
xyandx. On the other hand, the expanded form of Expression ( 6.32)
2axy+3bxy+4ax+5bx (6.33)
is not in collected form (in S) because there are two monomials with vari-
able partxyand two with variable part x.
The collected form depends, of course, on which expressions are taken
as the generalized variables. For example, if S={a,b}, the collected form
of Expression ( 6.33)i s( 2xy+4x)a+(3xy+5x)b.IfS={a,b,c,d,x,y },
then Expression ( 6.33) is already in collected form because the four mono-
mials in the sum have distinct variable parts. /square
Example 6.44. Strictly speaking, automatic simpliﬁcation prevents the
transformation of some expressions to collected form. For example, whenS={x}, the collected form of ax+bx+c+dis (a+b)x+(c+d).
However, the automatic simpliﬁcation rules remove the parentheses from
(c+d), giving two monomials canddwith variable part the integer 1. Given
that our procedures operate within the context of automatic simpliﬁcation,
this situation is unavoidable. /square
6.4. Manipulation of General Polynomial Expressions 249
Procedure Collect
terms(u,S);
Input
u:a nalgebraic expression ;
S: a non-empty set of generalized variables ;
Output
the collected form of uor the global symbol Undeﬁned ifuis
not aGPEinS;
Local Variables
f,combined ,i,j,N,T,v ;
Begin
1 ifKind(u)/negationslash=”+” then
2 ifCoeﬀ
var
monomial (u,S)=Undeﬁned then
3 Return(Undeﬁned )
4 elseReturn(u)
5 else
6 ifu∈SthenReturn(u);
7 N:= 0;
8 fori:= 1toNumber
of
operands(u)do
9 f:=Coeﬀ
var
monomial (Operand(u,i),S);
10 iff=Undeﬁned then Return(Undeﬁned )
11 else
12 j:= 1;
13 combined :=false;
14 while notcombined andj≤Ndo
15 ifOperand(f,2) =Operand(T[j],2)then
16 T[j]: =[Operand(f,1)+Operand(T[j],1),Operand(f,2)];
17 combined :=true;
18 j:=j+1;
19 ifnotcombined then
20 T[N+1]:= f;
21 N:=N+1;
22 v:= 0;
23 forj:= 1toNdo
24 v:=v+Operand(T[j],1)∗Operand(T[j],2);
25Return(v)
End
Figure 6.9. An MPL procedure that transforms an algebraic expression to col-
lected form. (Implementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
A procedure Collect
 terms that obtains a collected form is given in
Figure 6.9. The procedure returns either a collected form or the symbol
Undeﬁned whenuis not a GPEinS.
250 6. Structure of Polynomials and Rational Expressions
This procedure uses an array Tthat keeps track of the coeﬃcients of
the various monomials. Most computer algebra languages allow arrays to
be used in this way. In addition, at lines 2 and 9, the procedure uses the
operator Coeﬀ
 var
monomial (u,S) which is described in Exercise 3, page
237.W h e nuis aGME inS, this operator returns a two element list with
the coeﬃcient and variable parts of uand otherwise returns the symbol
Undeﬁned .
Collect
 terms begins (lines 1-5) by checking if an expression u,w h i c hi s
not a sum, is a monomial and when this is so, returns uwhich is in collected
form (Deﬁnition 6.42(1)). The remainder of the procedure applies to sums.
At line 6 we check if the sum uis inS, which means it is in collected
form. In lines 7-21, we create an array Twith entries that are two operand
lists that contain the coeﬃcient and distinct variable parts obtained so far.For each operand of u, we obtain, at line 9, a list fwith its coeﬃcient
and variable parts, and then check if the variable part corresponds to the
variable part of some earlier operand of uthat is in T(lines 12-18). If the
variable part of fcorresponds to an earlier variable part, the appropriate
element of Tis reassigned (line 16), and combined is assigned the symbol
true, which terminates the while loop. If the variable part of fdoes not
correspond to the variable part of some T[j], for 1 ≤j≤N, it is added
to the array T(lines 19-21). Finally, in lines 22-24, we use Tto create the
new expression vthat is the collected form.
Observe that Deﬁnition 6.42andCollect
terms require that ube a poly-
nomial in S. This means, for u=ax+s i n (x)x+b, the operator is unable
to collect coeﬃcients in xbecause the expression is not even a polynomial
inx. We can avoid the limitation by eliminating the free-of tests from the
procedure Coeﬀ
 var
monomial that is called in lines 2 and 10. We leave
these modiﬁcations to the reader (Exercise 3).
TheAlgebraic
 expand Operator
Ina na l g e b r a i cs e n s e ,t h e Algebraic
 expand operator applies the two dis-
tributive transformations in ( 6.31) in a left to right fashion to products
and powers that contain sums. With these transformations, the operator
obtains manipulations such as:
(x+2 )(x+3 )(x+4 ) →x3+9x2+2 6x+2 4, (6.34)
(x+y+z)3→x3+y3+z3+3x2y+3x2z+3y2x
+3y2z+3z2x+3z2y+6xyz,(6.35)
(x+1 )2+(y+1 )2→x2+2x+y2+2y+2, (6.36)
((x+2 )2+3 )2→x4+8x3+3 0x2+5 6x+4 9. (6.37)
6.4. Manipulation of General Polynomial Expressions 251
The last two examples show that Algebraic
 expand is recursive.
There are, however, other instances where it is less certain what the
operator should do. For example, should Algebraic
 expand perform the
following manipulations?
a
(x+1 )(x+2 )→a
x2+3x+2, (6.38)
(x+y)3/2→x(x+y)1/2+y(x+y)1/2. (6.39)
The ﬁrst example diﬀers from those above because a denominator contains
a product of sums, while the second example involves non-integer expo-
nents.
The next deﬁnition gives the form of the output of our Algebraic
 expand
operator.
Definition 6.45. Analgebraic expression uis inexpanded form if the
setVariables (u)does not contain a sum.
According to this deﬁnition, the expressions on the left in ( 6.34)-(6.37)
are in unexpanded form, while those on the right are in expanded form.For example,
Variables ((x+2 )(x+3 )(x+4 ) ) →{x+2,x+3,x+4},
while for the expanded form of this expression,
Variables (x
3+9x2+2 6x+ 24) →{x}.
On the other hand, the expressions on the left in ( 6.38)a n d( 6.39)a r e
already in expanded form, and so our Algebraic
 expand operator does not
obtain the manipulations shown for these expressions.
Deﬁnition 6.45only makes sense if it is understood in the context of
automatic simpliﬁcation. Without this context, some expressions that
are obviously not in expanded form satisfy the deﬁnition. For example,
u=/parenleftbig
(x+1 )2/parenrightbig2is certainly not in expanded form, and since automatic
simpliﬁcation obtains the transformation
/parenleftbig
(x+1 )2/parenrightbig2→(x+1 )4, (6.40)
we have Variables (u)={x+1}.On the other hand, without the trans-
formation in ( 6.40),Variables (u)={(x+1 )2}, which does not contain a
sum.
252 6. Structure of Polynomials and Rational Expressions
The Integer Exponent Case. We describe ﬁrst a simpliﬁed version of the
Algebraic
 expand algorithm which applies to algebraic expressions uwith
the restriction that all powers in uhave integer exponents.
Procedures for expansion in this setting are given in Figures 6.10and
6.11. The procedure Algebraic
 expand (u) ﬁrst recursively expands the
operands of sums, products, and powers with positive integer exponents
(lines 3, 6, and 11), and then calls on Expand
 product andExpand
 power
to apply the distributive laws to products and powers (lines 6 and 11). Line
12 is invoked when uis not a sum, product, or power.
The procedure Expand
 product (r,s), which expands the product of two
expanded expressions, uses a recursive approach to apply the right and left
distributive laws. If ris a sum, it applies the right distributive law (line
3), and if sis a sum, it apples the left distributive law by a recursive call
with the operands interchanged (line 5). (If both randsare sums, both
distributive laws are applied through recursion.) Line 7, which serves asa termination condition for the recursion, applies when neither rnorsis
a sum. The assumption that all exponents are integers is essential here
because without it the output of the procedure may not be in expanded
form (see Expression ( 6.43)b e l o w ) .
The procedure Expand
power(u,n), which expands an expanded ex-
pressionuto an integer power n≥2, is given in Figure 6.11.W h e nuis a
sum, the expanded form is obtained by letting
f=Operand (u,1),r=u−f,
and applying the binomial expansion
un=(f+r)n=n/summationdisplay
k=0/parenleftbigg/parenleftbiggn!
k!(n−k)!fn−k/parenrightbigg
rk/parenrightbigg
.
Observe that the automatically simpliﬁed form of the expression
n!
k!(n−k)!fn−k
is in expanded form. Indeed, fn−kis in expanded form because fis in
expanded form (by recursion), and fis not a sum because it is the operand
of a sum. The assumption that all exponents are integers is used herebecause without it f
n−kmay not be in expanded form (see Expression
(6.45) below). On the other hand, the base of rkc a nb eas u m ,a n ds o
this power must be expanded recursively. This operation is performed in
line 7, where Expand
 product is used to expand the product of these two
expressions.
6.4. Manipulation of General Polynomial Expressions 253
Procedure Algebraic
expand(u);
Input
u:a nalgebraic expression where all exponents of powers are integers;
Output
the expanded form of u;
Local Variables
v,base,exponent;
Begin
1 ifKind(u)=”+” then
2 v:=Operand(u,1);
3Return(Algebraic
expand(v)+Algebraic
expand(u−v))
4 elseifKind(u)=” ∗”then
5 v:=Operand(u,1);
6Return(Expand
product(Algebraic
expand(v),Algebraic
expand(u/v)))
7 elseif Kind(u)=” ∧”then
8base:=Operand(u,1);
9exponent :=Operand(u,2);
10 ifKind(exponent)=integer and exponent ≥2then
11 Return(Expand
power(Algebraic
expand(base),exponent));
12Return(u)
End
Procedure Expand
product(r,s);
Input
r,s : expanded algebraic expressions , where all exponents of powers are
integers;
Output
the expanded form of r∗s;
Local Variables
f;
Begin
1 ifKind(r)=”+” then
2 f:=Operand(r,1);
3Return(Expand
product(f,s)+Expand
product(r−f,s));
4 elseifKind(s)=”+” then
5Return(Expand
product(s,r))
6 else
7Return(r∗s)
End
Figure 6.10. MPL procedures for Algebraic
expandandExpand
product.( I m -
plementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
254 6. Structure of Polynomials and Rational Expressions
Procedure Expand
power(u,n);
Input
u: an expanded algebraic expression where all exponents of powers are
integers;
n: a non-negative integer;
Output
the expanded form of un;
Local Variables
f,r,k,s,c ;
Begin
1 ifKind(u)=”+” then
2 f:=Operand(u,1);
3 r:=u−f;
4 s:= 0;
5 fork:= 0tondo
6 c:=n!/(k!∗(n−k)!);
7 s:=s+Expand
product(c∗fn−k,Expand
power(r,k));
8Return(s)
9 else
10Return(un)
End
Figure 6.11. An MPL procedure for Expand
power. (Implementation: Maple
(txt),Mathematica (txt),MuPAD(txt).)
The Non-integer Exponent Case. Ifucontains powers with non-integer ex-
ponents, the Algebraic
 expand operator may return an expression that is
not in expanded form. To see how this happens, let’s suppose that the
transformations
uvuw=uv+w, (6.41)
(uv)n=unv,n an integer , (6.42)
are applied from left to right during automatic simpliﬁcation6.( T h e t w o
transformations hold for both the real and complex interpretations of the
6In Maple, automatic simpliﬁcation obtains the transformation ( 6.41), whenvand
ware rational numbers, and ( 6.42), whenvis a rational number.
In Mathematica, automatic simpliﬁcation obtains the transformations ( 6.41)a n d
(6.42).
In MuPAD, automatic simpliﬁcation obtains the transformation ( 6.41), when vand
ware rational numbers, and ( 6.42).
For a summary of the power transformations in Maple, Mathematica, and MuPAD,
see Cohen [ 24], Section 3.1.
6.4. Manipulation of General Polynomial Expressions 255
power operation.) In this context, Algebraic
 expand together with the
transformation ( 6.41) obtains
Algebraic
 expand/parenleftBig
(x(y+1 )3/2+1 )(x(y+1 )3/2−1)/parenrightBig
→x2(y+1 )3−1 (6.43)
=x2y3+3x2y2+3x2y+x2−1, (6.44)
and together with the transformation ( 6.42) obtains
Algebraic
 expand/parenleftBig
(x(y+1 )1/2+1 )4/parenrightBig
→x4(y+1 )2+4x3(y+1 )3/2(6.45)
+6x2(y+1 )+4x(y+1 )1/2+1
=x4y2+2x4y+x4+4x3(y+1 )3/2(6.46)
+6x2y+6x2+4x(y+1 )1/2+1.
Algebraic
 expand obtains Expressions ( 6.43)a n d( 6.45), and the expanded
forms are shown in Expressions ( 6.44)a n d( 6.46). In both examples, the
output of Algebraic
 expand is not in expanded form, because in each case
the output of the Variables operator contains the generalized variable y+1.
In the ﬁrst example, the input to Algebraic
 expand is a product, and the
output contains a new product and a new power that are not in expandedform. This situation arises from line 7 in Expand
product whenr=s=
x(y+1 )3/2, and so by the transformation ( 6.41),r∗s=x2(y+1 )3which
is not in expanded form. In the second example, the input is a power, andthe output contains new products and powers that are not in expanded
form. This situation arises from line 7 in Expand
power. For example,
whenf=x(y+1 )1/2andn−k= 4, the transformation ( 6.42) implies
fn−k=x4(y+1 )2which is not in expanded form.
One way to expand an expression u0with non-integer exponents is to
apply a sequence of expansions
u1:=Algebraic
 expand (u0),
u2:=Algebraic
 expand (u1),
...
ui:=Algebraic
 expand (ui−1),
...
where the process stops when ui=ui−1. The problem with this approach
is that it performs unnecessary work by trying to expand parts of an ex-
pression that are already in expanded form. Another approach is to modify
256 6. Structure of Polynomials and Rational Expressions
the algorithm in Figures 6.10and6.11so that new unexpanded products
and powers obtained with Expand
 product andExpand
 power are expanded,
although we must take care to avoid introducing redundant recursion or
inﬁnite recursive loops. We leave the details of this modiﬁcation to thereader (Exercise 9(a)).
Extensions of the
Algebraic
 expand Operator. There are two extensions of
theAlgebraic
 expand operator that obtain manipulations beyond the ex-
panded form described in Deﬁnition 6.45. The ﬁrst extension is based on
theexpand operator in the Macsyma system which returns an expression
with the following properties.
1. Each complete sub-expression of an expression is in expanded form,
2. The denominator of each complete sub-expression in an expression is
in expanded form.
These properties include Deﬁnition 6.45and imply the following expan-
sions:
sin(a(b+c))→sin(ab+ac), (6.47)
a
b(c+d)→a
bc+bd. (6.48)
In each of these examples, the expression on the left satisﬁes Deﬁnition 6.45
because
Variables (sin(a(b+c)))→{sin(a(b+c))},
Variables/parenleftbigga
bc+bd/parenrightbigg
→{a,1/b,1/(c+d)}.
However, in Expression ( 6.47), sin(a(b+c)) has a complete sub-expression
that is not in expanded form, and in Expression ( 6.48), the denominator of
a
b(c+d)
is not in expanded form. An extension of the Algebraic
 expand operator
that obtains these transformations is described in Exercise 8.
The second extension of Algebraic
 expand , which has to do with frac-
tional exponents, is based on the Expand operator in Mathematica. Let
ube an algebraic expression, and let fbe a positive fraction (that is not
an integer). According to Deﬁnition 6.45, the expression ufis in expanded
form. However, another expanded form for ufis obtained by separating f
6.4. Manipulation of General Polynomial Expressions 257
into the sum of an integer and a fraction mwith 0<m< 1. We obtain
this representation with
f=⌊f⌋+m,
where
⌊f⌋= largest integer ≤f, m =f−⌊f⌋.
The function ⌊f⌋is called the ﬂoor function off.W eh a v e
uf=umu⌊f⌋, (6.49)
and obtain an expanded form by expanding u⌊f⌋and multiplying each term
of this expansion by um. For example, with ⌊5/2⌋=2 ,w eh a v e
(x+1 )5/2=(x+1 )1/2(x+1 )2
=(x+1 )1/2x2+2(x+1 )1/2x+(x+1 )1/2.(6.50)
An extension of Expand
 power that obtains this transformation is described
in Exercise 9(b).
Exercises
1. Suppose uis in collected form with respect to a set S.
(a) Is ualso in collected form with respect to a subset of S?
(b) Is each complete sub-expression of ualso in collected form with re-
spect to S?
2. Let ube a sum. A common algebraic operation is to combine terms that
have denominators with the same variable part into a single term. For
example,
a
2bc+d
3bc=a/2+d/3
bc. (6.51)
In this example, both denominators have the variable part bc.G i v eap r o -
cedureCombine(u) that combines terms in a sum uwhose (non-constant)
denominators diﬀer byat most a rational numberfactor into a single term.
Ifuis not a sum, then return u. This exercise requires a Denominator
operator. Most CAS languages have this operator (see Figure 4.1on page
124), and transformation rules for the operator are given in Section 6.5.
Hint:This operation can be performed by the Collect
terms(u,S)p r o c e -
dure with the appropriate generalized variables inS.
3. Let ubeanalgebraic expression ,andlet Sbeasetof generalized variables .
Give a procedure Collect
terms
2(u,S) that collects coeﬃcients in Sbut
doesn’t require that ube aGPEinS. For example,
Collect
terms
2(ax+sin(x)x+b,{x})→(a+sin(x))x+b.
258 6. Structure of Polynomials and Rational Expressions
4. Explore the capacity of the algebraic expand operator in a CAS. How does
it compare with the version of the operator described in this section? (Use
expandin Maple and MuPAD, and Expandin Mathematica.)
5. Let ube analgebraic expression . The operator Distribute (u), which pro-
vides a fast way to apply the distributive transformation, can replaceAlgebraic
expandin some situations. It is deﬁnedusing the following rules.
(a) If uis not a product, then
Distribute (u)→u.
(b) If uis a product, then
i. Ifudoes not have an operand that is a sum, then
Distribute (u)→u.
ii. Suppose uhas an operand that is a sum, and let vbe the ﬁrst
such operand. Form a new sum by multiplying the remaining
operands of uby each operand of v.R e t ur nt h i ss um .
For example,
Distribute (a(b+c)(d+e))→ab(d+e)+ac(d+e),
DistributeWx+y
xy}
→1/y+1/x.
Give a procedure for Distribute (u).
6. Give a procedure Expand
main
op(u) that expands only with respect to
the main operator of u. In other words, the operator does not recursively
expand the operands of sums, products, or powers before it applies the
distributive transformations. For example,
Expand
main
opi
xi
2+(1+ x)2JJ
→2x+x(1+x)2,
Expand
main
opQi
x+(1+ x)2J2w
→x2+2x(1+x)2+(1+ x)4.
7. Let Tbe a set of expressions that are sums. Give procedures for an
operatorExpand
restricted(u,T) which applies the distributive laws as
Algebraic
expanddoes, except that it does not apply the laws to members
ofT. For example, for u=(x+a)2(x+b),
Expand
restricted(u,{x+a})→(x+a)2x+(x+a)2b,
Expand
 restricted (u,{x+b})→(x+b)x2+2a(x+b)x+a2(x+b),
Expand
restricted(u,{x+a,x+b})→(x+a)2(x+b).
6.5. General Rational Expressions 259
8. Let ube analgebraic expression . Modify the expand algorithm so that it
returns anexpression with properties (1) and(2) on page 256.Y o urp r o c e -
dureshould obtain theexpansionsin ( 6.38), (6.47), and(6.48). Sincethese
properties require the expansion of denominators, there is the possibilitythat a denominator expands and simpliﬁes to 0. For example, this occurs
with1
x2+1−x(x+1).
Make sure your procedures check for this situation and return the global
symbol Undeﬁned when it occurs. This exercise requires the Numerator
andDenominator operators. Most CAS languages have these operators
(see Figure 4.1on124), and transformation rules for these operators are
given in Section 6.5.
9. (a) Modify the Algebraic
expandalgorithm so that it obtains the ex-
pandedform whentheinputexpressions includepowers withfractionexponents. Assume that the transformations in ( 6.41)a n d(6.42)a r e
included in automatic simpliﬁcation.
(b) Modifythe Expand
powerprocedureinpart(a)sothatitalso obtains
the expansions using the decomposition of fraction powers in ( 6.49)
and (6.50). Most computer algebra languages have an operator to
compute ⌊N⌋. (InMapleandMuPADuse floor,andinMathematica
useFloor.)
6.5 General Rational Expressions
In a mathematical sense, a rational expression is deﬁned as a quotient of two
polynomials. In this section we discuss the rational expression structure
of an algebraic expression and describe an algorithm that transforms an
expression to a particular rational form.
Definition 6.46. (Mathematical Deﬁnition) LetS={x1,...,x m}be a
set of generalized variables .A n algebraic expression uis ageneral ratio-
nal expression (GRE) in Sif it has the form u=p/q,w h e r epandqare
GPEs inS.
Example 6.47.
x2−x+y
x+4,S ={x},
x2sin(y)−xsin2(y)+2(z+1 )
x+s i n (y),S ={x,sin(y)},
x2+bx+c, S ={x}.
260 6. Structure of Polynomials and Rational Expressions
F o re a c he x a m p l e ,w eh a v eg i v e no n ep o s s i b l ec h o i c ef o r S. Notice that the
deﬁnition is interpreted in a broad sense to include GPEs for which the
denominator is understood to be 1. /square
TheNumerator andDenominator Operators. To determine if an expression
is a GRE, we must deﬁne precisely the numerator and denominator of the
expression. The Numerator andDenominator operators, which are used
for this purpose, are deﬁned by the following transformation rules.
Definition 6.48. Letube an algebraic expression .
ND-1 .I fuis a fraction, then
Numerator (u)→Operand (u,1),
Denominator (u)→Operand (u,2).
ND-2 .S u p p o s e uis a power. If the exponent of uis a negative integer or
a negative fraction, then
Numerator (u)→1,Denominator (u)→u−1,
otherwise
Numerator (u)→u, Denominator (u)→1.
ND-3 .S u p p o s e uis a product and v=Operand (u,1).T h e n
Numerator (u)→Numerator (v)∗Numerator (u/v),
Denominator (u)→Denominator (v)∗Denominator (u/v).
ND-4 .I fudoes not satisfy any of the previous rules, then
Numerator (u)→u, Denominator (u)→1.
Example 6.49. Consider the expression u=( 2/3)x(x+1 )
x+2yn.T h e n
Numerator (u)→2x(x+1 )yn,Denominator (u)→3(x+2 )./square
TheNumerator andDenominator operators are deﬁned in terms of
the tree structure of an expression and are interpreted in the context of
automatic simpliﬁcation. Although the operators are adequate for our
6.5. General Rational Expressions 261
purposes, the next two examples show in some cases they give unusual
results.
Example 6.50. Consider the expression
1
x+1
y.
Certainly, if we transform the expression to
x+y
xy,
it is clear which expression is the numerator and which is the denominator.
The deﬁnition, however, does not include this transformation as part of the
simpliﬁcation context, and so the numerator is
1
x+1
y
and the denominator is 1. /square
Example 6.51. Consider the expression x−r2−4r−5. In this case, the expo-
nent is negative for all real values of r. However, since the exponent of the
expression is not a negative integer or fraction, the numerator is x−r2−4r−5
and the denominator is 1. /square
Modiﬁcations of the Numerator andDenominator operators that ad-
dress the issues in the last two examples are described in Exercise 4.
We give next a deﬁnition of a general rational expression that is more
suitable for computational purposes.
Definition 6.52. (Computational Deﬁnition) LetS={x1,...,x m}
be a set of generalized variables .A n algebraic expression uis ageneral
rational expression (GRE) in SifNumerator (u)andDenominator (u)
areGPEs inS.
TheRational
 gre Operator
Definition 6.53. Letube an algebraic expression ,a n dl e tvbe either a
generalized variable xor a setSofgeneralized variables . The operator
Rational
 gre(u,v)
returnstrue wheneveruis a GRE in {x}orSand otherwise returns false.
The operator is deﬁned by the following transformation rule:
262 6. Structure of Polynomials and Rational Expressions
Rational
 gre(u,v)→
Polynomial
 gpe(Numerator (u),v)andPolynomial
 gpe(Denominator (u),v)
where the Polynomial
 gpe operator is given in Figure 6.6on page 228.
Example 6.54.
Rational
 gre/parenleftbiggx2+1
2x+3,x/parenrightbigg
→true,
Rational
 gre/parenleftbigg1
x+1
y,{x,y}/parenrightbigg
→false. (6.52)
/square
TheRational
 variables Operator. TheRational
 variables operator deﬁnes
a natural set of generalized variables for a rational expression.
Definition 6.55. Letube an algebraic expression . The operator
Rational
 variables (u)
is deﬁned by the transformation rule:
Rational
 variables (u)→
Variables (Numerator (u))∪Variables (Denominator (u)),
where the Variables operator is given in Deﬁnition 6.19on page 227.
Example 6.56.
Rational
 variables/parenleftbigg2x+3y
z+4/parenrightbigg
→{x,y,z },
Rational
 variables/parenleftbigg1
x+1
y/parenrightbigg
→/braceleftbigg1
x,1
y/bracerightbigg
.
There is a natural way to view (2 x+3y)/(z+4 )a sa GREinx,y,a n d
z. On the other hand, 1 /x+1/yis not a GRE in xandy(see Expression
(6.52) )b u tc a nb ev i e w e da sa GREin the two generalized variables 1/x
and 1/y. /square
Rationalization of Algebraic Expressions
The rationalization process, which is based on the transformation that
combines operands in a sum over a common denominator, transforms an
6.5. General Rational Expressions 263
algebraic expression to a form with a more appropriate set of generalized
variables. When the process is applied (in a recursive manner), it obtains
the following transformations:
a
b+c
d→ad+bc
bd,
1+1
1+1/x→2x+1
x+1,
1
/parenleftbigg
1+1
x/parenrightbigg1/2+/parenleftbigg
1+1
x/parenrightbigg3/2
→x2+(x+1 )2
x2/parenleftbiggx+1
x/parenrightbigg1/2. (6.53)
The goal of rationalization is described in the following deﬁnition.
Definition 6.57. Analgebraic expression uis inrationalized form if it
satisﬁes one of the following properties:
1.uis an integer, fraction, symbol, factorial, or function form.
2.uis any other type, and consider uas a rational expression in
S=Rational
 variables (u).
Then,
(a) each expression vinSis in rationalized form with
Denominator (v)=1,
(b) the coeﬃcient part of each of the monomials in Numerator (u)
andDenominator (u)is an integer.
Observe that Rule 2(a) is recursive. As usual, we interpret this deﬁni-
tion in the context of automatic simpliﬁcation.
Some examples will help clarify the deﬁnition.
Example 6.58. The expression a/b+c/dis not in rationalized form because
Rational
 variables (a/b+c/d)→{a,1/b,c,1/d,},
264 6. Structure of Polynomials and Rational Expressions
and so property 2(a) of Deﬁnition 6.57is not satisﬁed. However, ( ad+
bc)/(bd) is in rationalized form because
Rational
 variables/parenleftbiggad+bc
bd/parenrightbigg
→{a,b,c,d },
and the coeﬃcient part of each of the monomials ad,bc,a n dbdis 1.
The expression
1+1
1+1/x
is not in rationalized form because
Rational
 variables/parenleftbigg
1+1
1+1/x/parenrightbigg
→/braceleftbigg1
1+1/x/bracerightbigg
,
and so property 2(a) of Deﬁnition 6.57is not satisﬁed. This expression can
be transformed to2x+1
x+1,
which is in rationalized form because
Rational
 variables/parenleftbigg2x+1
x+1/parenrightbigg
→{x},
and the coeﬃcient parts of all monomials in the numerator and denomina-
tor are integers.
The expression a+b/2 is not in rationalized form because the coeﬃcient
part ofb/2 is not an integer, and so property 2(b) in Deﬁnition 6.57is not
satisﬁed. However, its sum (2 a+b)/2 is in rationalized form. /square
TheRationalize
 expression Operator. The operator
Rationalize
 expression (u)
n transforms an algebraic expression uto an equivalent expression in ra-
tionalized form. The operator is understood to operate in an automatic
simpliﬁcation context that includes the power transformations7
7In Maple, automatic simpliﬁcation obtains the transformation ( 6.54)w h e nvand
ware rational numbers, ( 6.55)w h e nvis a rational number, and ( 6.56).
In Mathematica, automatic simpliﬁcation obtains the transformation ( 6.54), (6.55),
and ( 6.56).
In MuPAD, automatic simpliﬁcation obtains the transformation ( 6.54)w h e nvandw
are rational numbers, ( 6.55), and ( 6.56).
For a summary of power transformation rules in Maple, Mathematica, and MuPAD,
see Cohen [ 24], Section 3.1.
6.5. General Rational Expressions 265
Procedure Rationalize
expression (u);
Input
u:a nalgebraic expression ;
Output
a rationalized form of u;
Local Variables f,g,r;
Begin
1 ifKind(u)=” ∧”then
2ReturnQ
Rationalize
expression (Operand(u,1))Operand (u,2)w
3 elseifKind(u)=” ∗”then
4 f:=Operand(u,1);
5Return(Rationalize
expression (f)∗Rationalize
expression (u/f))
6 elseifKind(u)=”+” then
7 f:=Operand(u,1);
8 g:=Rationalize
expression (f);
9 r:=Rationalize
expression (u−f);
10Return(Rationalize
sum(g,r))
11 else
12Return(u)
End
Procedure Rationalize
sum(u,v);
Input
u,v:algebraic expressions in rationalized form;
Output
analgebraic expression in rationalized form;
Local Variables m,n,r,s;
Begin
1 m:=Numerator (u);
2 r:=Denominator (u);
3 n:=Numerator (v);
4 s:=Denominator (v);
5 ifr=1ands=1then
6Return(u+v)
7 else
8Return(Rationalize
sum(m∗s, n∗r)/(r∗s))
End
Figure 6.12. An MPL algorithm that rationalizes an algebraic expression. (Im-
plementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
266 6. Structure of Polynomials and Rational Expressions
uvuw→uv+w, (6.54)
(uv)n→uvn, (6.55)
(uv)n→unvn, (6.56)
whereu,v,a n dware algebraic expressions and nis an integer. These
transformations hold for both the real and complex interpretations of the
power operation.
Procedures that transform an expression to rationalized form are given
in Figure 6.12. In the main procedure Rationalize
 expression , in lines 1-2 a
power is rationalized by recursively rationalizing its base. For example,
Rationalize
 expression/parenleftbig
(1 + 1/x)2/parenrightbig
→(x+1 )2
x2,
where the transformation is obtained by rationalizing the base 1+1 /xand
then using the transformation ( 6.56). Notice that we rationalize the base
even when the exponent is not an integer because the base may appear with
an integer exponent later in the computation as a result of the rational-ization process (see Example 6.59below). Unfortunately, this means that
some expressions that are already in rationalized form are transformed to
another rationalized form. For example,
Rationalize
expression/parenleftBig
(1 + 1/x)1/2/parenrightBig
→/parenleftbiggx+1
x/parenrightbigg1/2
.
In lines 3-5, a product is rationalized by recursively rationalizing each
of its operands.
In lines 6-10, a sum is rationalized by ﬁrst rationalizing its operands
and then combining the operands over a common denominator (line 10).
The actual sum transformation occurs in the Rationalize
 sumprocedure
that performs the transformation
m/r+n/s→ms+nr
rs. (6.57)
Notice that Rationalize
 sumis recursive (line 8) because the sum in the
numerator of the right side of ( 6.57) may not be in rationalized form (see
Example 6.59below). The termination condition for the recursion is in
lines 5-6. We have separated the computation into two procedures to avoid
some redundant recursion.
Example 6.59. In this example we outline the steps in a rationalization that
requires both the rationalization of powers with non-integer exponents and
the recursive step in Rationalize
 sum. Consider the expression8
8For clarity, we use notation with the quotient operator even though quotients are
transformed to products and powers by automatic simpliﬁcation.
6.5. General Rational Expressions 267
1
/parenleftbigg
1+1
x/parenrightbigg1/2+/parenleftbigg
1+1
x/parenrightbigg3/2
.
Rationalizing the two operands of the sum, we obtain
1
/parenleftbiggx+1
x/parenrightbigg1/2+/parenleftbiggx+1
x/parenrightbigg3/2
.
Applying the sum transformation in ( 6.57) followed by the power transfor-
mations in ( 6.54)a n d( 6.55), we obtain
1+(x+1 )2
x2
/parenleftbiggx+1
x/parenrightbigg1/2,
where the sum in the numerator is not in rationalized form. Again apply-
ing the transformation ( 6.57) to the numerator, we obtain with automatic
simpliﬁcation
x2+(x+1 )2
x2/parenleftbiggx+1
x/parenrightbigg1/2,
which is in rationalized form. /square
Example 6.60. In order for the algorithm to obtain a rationalized form, dis-
tributive transformations that undo a rationalization cannot be included in
automatic simpliﬁcation. A problem arises with both the Maple and Mu-PAD systems in which integers and fractions are automatically distributed
over sums. For example, in Maple or MuPAD, implementations of the al-
gorithm attempt to transform a+b/2t o( 2a+b)/2, but then automatic
simpliﬁcation transforms it back to a+b/2. /square
Rational-Expanded Form
Since algebraic expansion is not part of the simpliﬁcation context of ratio-
nalization, the Rationalize
 expression operator may return an expression
with the numerator or denominator in unexpanded form. For example,
Rationalize
 expression (a/b+c/d+e/f)→adf+b(cf+de)
bdf.
268 6. Structure of Polynomials and Rational Expressions
The following deﬁnition combines rationalization and expansion.
Definition 6.61. Analgebraic expression uis inrational-expanded
form if it satisﬁes the following two properties:
1.uis in rationalized form.
2.Numerator (u)andDenominator (u)are in algebraic expanded form.
The next example shows that there is an involved interaction between
the rationalization and expansion operations.
Example 6.62. Consider the expression
/parenleftBig/radicalBig
1
(x+y)2+1+1/parenrightBig/parenleftBig/radicalBig
1
(x+y)2+1−1/parenrightBig
x+1.
This expression is in rationalized form, but not rational-expanded form.
Expanding the numerator we obtain
1
(x+y)2+1−1
x+1,
which is not in rationalized form. Transforming this expression to ratio-
nalized form we obtain
−(x+y)2
/parenleftBig
(x+y)2+1/parenrightBig
(x+1 ),
which again is not in rational-expanded form. Expanding the numerator
and denominator, we obtain
−x2−2xy−y2
x3+x2+2x2y+2xy+xy2+y2+x+1,
which is in rational-expanded form. /square
The operator Rational
 expand (u) transforms an algebraic expression u
to rational-expanded form. The procedure for this operator is left to the
reader (Exercise 3).
6.5. General Rational Expressions 269
Normal Simplification Operators
LetMrepresent the set of algebraic expressions that do not contain fac-
torials, function forms, or powers with non-integer exponents. For this
class of expressions, the Rational
 expand operator together with automatic
simpliﬁcation can always determine if an expression simpliﬁes to 0. An
operator with this property is called a normal simpliﬁcation operator or a
zero equivalence operator for the class M. For example,
Rational
 expand/parenleftBigg
1
1/a+c/(ab)+abc+ac2
(b+c)2−a/parenrightBigg
→0.
On the other hand, rationalization alone does not obtain this transforma-
tion:
Rationalize
 expression/parenleftBigg
1
1/a+c/(ab)+abc+ac2
(b+c)2−a/parenrightBigg
→(b+c)2a2b+/parenleftBig
abc+ac2−a(b+c)2/parenrightBig
(ab+ca)
(ab+ca)(b+c)2.
Rational Simplification
Although the Rationalize
 expression operator transforms an expression to
rationalized form, it often introduces extraneous common factors into the
numerator and denominator. For example, the operator obtains
Rationalize
 expression (x/z+y/z2)→z2x+zy
z3,
where an extraneous common factor zappears in the numerator and de-
nominator. Although it is possible to modify the algorithm to avoid this,
it is better to eliminate the common factors after rationalization because
other common factors can be eliminated then as well. In Exercise 6,w e
describe an operator that eliminates the explicit common factors that ariseduring rationalization as well as some other explicit common factors.
The more interesting problem, however, involves the elimination of com-
mon factors that are implicit or hidden. For example, it is not so obviousthat the expression
2a
3+2 2ab+6a2+7a+6ba2+1 2b2+2 1b
7a2−5ab2−2ba2−5a+2 1ab+3b3−15b(6.58)
has a common factor a+3bin the numerator and denominator and can be
simpliﬁed to
2a2+4b+6a+7
7a−2ab−5+b2. (6.59)
270 6. Structure of Polynomials and Rational Expressions
The process of eliminating explicit and implicit common factors from the
numerator and denominator of a rational expression is called rational sim-
pliﬁcation . One way to obtain this simpliﬁcation is by factoring the nu-
merator and denominator and cancelling the common factors. Since fac-torization is a time consuming process, this is usually done instead with a
greatest common divisor algorithm. Since the topic is beyond the scope of
this chapter, the reader may consult Cohen [ 24], Sections 4.2 and 6.3, for
more information on this problem.
Since rational simpliﬁcation is an important aspect of simpliﬁcation,
most computer algebra systems have some capability to perform this oper-
ation (Exercise 5).
Exercises
1. Explore the capacity of the numerator and denominator operators in a
CAS. What is the simpliﬁcation context of these operators in the CAS?
Are the operators deﬁned with the same transformations as the ones givenin the text? (See Figure 4.1on page124.)
2. Let ubeanalgebraic expression . Give procedures for each of the following
operators:
(a)Numerator (u) (Deﬁnition 6.48).
(b)Denominator (u) (Deﬁnition 6.48).
(c)Rational
gre(u,v) (Deﬁnition 6.53).
(d)Rational
variables(u) (Deﬁnition 6.55).
3. Let ube analgebraic expression . Give a procedure Rational
expand(u)
that transforms uto rational-expanded form (Deﬁnition 6.61). Since ratio-
nal expansion includes the expansion of denominators, there is the possi-
bility that a denominator expands and simpliﬁes to 0. For example, thisoccurs with
1
x2+x−x(x+1).
Make sure your procedure checks for this situation and returns the global
symbol Undeﬁned when it occurs. Your procedure should obtain the
rational expansion in Example 6.59.
4. In this exercise we describe two modiﬁcations of the operators Numerator
andDenominator .
(a) Give procedures for Numerator (u)a n dDenominator (u)t h a tr a t i o -
nalize ubefore obtaining the numerator and denominator.
(b) Let ube analgebraic expression ,a n dl e t Lbe a list of distinct sym-
bols. In addition, suppose the exponent of each power in uis a
multivariate polynomial in the variables in L. A modiﬁcation of
6.5. General Rational Expressions 271
the deﬁnition for the Numerator andDenominator operators is ob-
tained by determining the sign of the exponent of a power using the
Polynomial
signoperatordescribed in Exercise 7on page246.I nt h i s
case, Rule ND-2 is replaced by the following rule.
ND-2. Suppose that uis a power, and let z=Operand(u,2). If
Polynomial
sign(z,L)<0,
then
Numerator (u,L)→1,
and
Denominator (u,L)→
Operand(u,1)∧Algebraic
expand(−1∗z),
otherwise
Numerator (u,L)→u,Denominator (u,L)→1.
Notice that the list Lappears as an input parameter because the
polynomial sign depends on the order of the symbols in L.G i v e
proceduresNumerator (u,L)a n dDenominator (u,L) that obtain the
numerator and denominator of uwith this modiﬁcation to the ND
rules.
5. Explore the rational simpliﬁcation capability of a CAS. For example can
the rational simpliﬁcation operator in a CAS simplify Expression ( 6.58)t o
Expression ( 6.59)? How about the transformation
x3+i√
2+√
3J
x2+i
2√
2√
3−5J
x+√
2−√
3
x3+i
−√
2+√
3J
x2+i
−5−2√
2√
3J
x−√
2−√
3
→x+√
2−√
3
x−√
2−√
3,
which is more involved because it includes radical expressions? (See Fig-
ure4.1on page124.)
6. Let ube analgebraic expression in rationalized form. In this exercise we
outline an algorithm for an operator Cancel(u) that performs a limited
version of rational simpliﬁcation. The operator can eliminate extrane-
ous common factors introduced by the Rationalize
expression operator as
well as some other explicit common factors. The cancellation is obtainedthrough automatic simpliﬁcation after performing a limited version of fac-
torization on the numerator and denominator of u. The operator is based
on the following operators:
272 6. Structure of Polynomials and Rational Expressions
(a) Let uandvbealgebraic expressions . The operator
Common
factors(u,v)
ﬁnds some factors that are common to uandv. It is deﬁned using
the following transformation rules.
CF-1.Ifuandvare integers then Common
factors(u,v)r e t ur n s
the greatest (positive) common divisor of uandv. Most com-
puteralgebra systems haveanoperator thatobtains thegreatestcommon divisor of integers (see Figure 4.1on page124).
CF-2.Ifuis a product, let
f=Operand(u,1),r=Common
factors(f,v).
Then
Common
factors(u,v)→r∗Common
factors(u/f, v/r).
CF-3.Ifvis a product then
Common
factors(u,v)→Common
factors(v,u).
CF-4.If none of the previous rules apply, then deﬁne
base(u)=k
Operand(u,1) ifKind(u)=” ∧”,
u otherwise,
exponent( u)=Operand(u,2) ifKind(u)=” ∧”,
1o t h e r w i s e .
If base( u)=b a s e ( v) and both exponent( u) and exponent( v)a r e
positive rational numbers, then
Common
factors(u,v)→
base(u)Min({exponent( u),exponent( v)}),
otherwiseCommon
factors(u,v)→1.
For example, the operator obtains
Common
factorsi
6xy3,2x2yzJ
→2xy,
Common
factors(x+y, a(x+y))→x+y.
Give a procedure for this operator.
(b) Let ube analgebraic expression . The operator Factor
out(u)p e r -
forms a limited version of factorization. It is deﬁned using the fol-lowing transformation rules.
FO-1.Ifuis a product then Factor
out(u)→Map(Factor
out,u).
6.5. General Rational Expressions 273
FO-2.Ifuis a power then
Factor
out(u)→Factor
out(Operand(u,1))Operand (u,2).
FO-3.Suppose that uis a sum with noperands, and let
s=Map(Factor
out,u).
Ifsis not a sum, then
Factor
out(u)→s.
Otherwise, suppose that sis a sum with operands s1,...,s n,
and let cbe the common factor of all the siobtained using the
Common
factorsoperator described in part (a). Then
Factor
out(u)→c(s1/c+···+sn/c),
where the divisions are obtained with automatic simpliﬁcation.
FO-4.If none of the previous rules apply, then Factor
out(u)→u.
For example,
Factor
outi
(x2+xy)3J
→x3(x+y)3,
Factor
out(a(b+bx))→ab(1+x),
Factor
outQ
21/2+2w
→21/2(1+21/2),
Factor
out(abx+acx+bcx)→(ab+ac+bc)x,
Factor
out(a/x+b/x)→a/x+b/x.
In the last example, 1 /xis not isolated because the Common
factors
operator in FO-3 retrieves only powers with positive rational expo-nents (see CF-4). Give a procedure for this operator.
(c) Let ube analgebraic expression in rationalized form. Give a pro-
cedure for the operator Cancel(u) that is deﬁned by the following
transformation rule.
Letn=Numerator (u)a n dd=Denominator (u). Then
Cancel(u)→Factor
out(n)/Factor
out(d).
For example,
CancelW(a+b)c+(a+b)d
ae+be}
→c+d
e.(6.60)
Note: Cancel (u) does not remove all explicit common factors. For
example, although
a(a+b)−a2−ab+rs+rt
r2
274 6. Structure of Polynomials and Rational Expressions
hasacommonfactor of rinthenumeratoranddenominatorandsim-
pliﬁes to ( s+t)/r,t h i si sn o to b t a i n e dw i t h Cancel. However, if the
expression is ﬁrst transformed to rational-expanded form, the sim-
pliﬁcation is obtained with Cancel. On the other hand, if the input
toCancelin Expression ( 6.60) is transformed to rational-expanded
form, the common factor is not removed. For further discussion of
common factors in these cases and implicit common factors, see Co-hen [24], Section 6.3.
7
Exponential and Trigonometric
Transformations
This chapter is concerned with the manipulation of algebraic expressions
that contain exponential or trigonometric functions. In Section 7.1we
describe expansion algorithms that expand these functions with respect totheir arguments. These algorithms obtain the transformations
exp(2x+y)→(exp(x))
2exp(y), (7.1)
sin(2x+y)→2c o s (y)sin(x)cos(x)+2s i n (y)(cos(x))2(7.2)
−sin(y).
In Section 7.2we describe contraction algorithms that invert the trans-
formations in ( 7.1)a n d( 7.2). In addition, we describe a simpliﬁcation
algorithm that can verify a large class of trigonometric identities.
7.1 Exponential and Trigonometric Expansion
In this section we describe algorithms that expand the exponential andtrigonometric functions that appear in an expression.
275
276 7. Exponential and Trigonometric Transformations
Exponential Expansion
Letu,v,a n dwbe algebraic expressions. The exponential function satisﬁes
the following properties1:
exp(u+v)=e x p (u)e x p (v), (7.3)
exp(wu)=e x p (u)w. (7.4)
The operation that applies these transformations in a left to right manner
is called exponential expansion , and the operation that applies the trans-
formations in a right to left manner is called exponential contraction2.In
this section we describe procedures for exponential expansion. Procedures
for exponential contraction are described in Section 7.2.
The goal of exponential expansion is described in the next deﬁnition.
Definition 7.1. Analgebraic expression uis inexponential-expanded
form if the argument of each exponential function in u
1. is not a sum;
2. is not a product with an operand that is an integer.
Although Equation ( 7.4) provides a way to remove any operand of a
product from the argument of an exponential function, it doesn’t specifywhich operand should be removed. To eliminate this ambiguity, we only
remove an integer operand from the argument
3. This point is illustrated
in the next two examples.
Example 7.2. Consider the manipulation
exp(2wx+3yz)=e x p ( 2 wx)exp(3yz)
=e x p (wx)2exp(yz)3.
1Property ( 7.3) is valid in either a real number of complex number context. Property
(7.4) is valid in a real context but is only valid in a complex context when wis an
integer. For example, if u=( 3/2)πı(whereı=√
−1) andw=1/2, by using the
principal value of the square root function, we have (exp( u))w=√
2/2−√
2/2ıand
exp(wu)=−√
2/2+√
2/2ı. For a discussion of the exponent relationships in a complex
setting, see Pennisi [ 78], pages 112-113. (Implementation: Maple (mws), Mathematica
(nb), MuPAD (mnb).)
2During automatic simpliﬁcation the Mathematica system transforms the function
form Exp[u]t ot h ep o w e r Euand also applies the contraction EuEv→Eu+v. In addition,
it applies the contraction ( Eu)n→Enuwhennis an integer. Therefore, to implement
the expansion and contraction procedures described in this chapter in this system, it isnecessary to use another representation for the exponential function. (Implementation:Mathematica (nb).)
3In Maple and Mathematica, an integer operand in a product is the ﬁrst operand.
In MuPAD, an integer operand in a product is the last operand.
7.1. Exponential and Trigonometric Expansion 277
The exponential on the left has an operand that is a sum and so is
not in exponential-expanded form. Applying Equation ( 7.3), we obtain
two new exponentials, which are also not in expanded form. Applying
Equation ( 7.4) to each exponential, we obtain the expanded form of the
expression. /square
Example 7.3. Consider the manipulation
exp(2(x+y)) = exp( x+y)2
=e x p (x)2exp(y)2.
The exponential on the left has an operand that is a product with an integer
operand and so is not in exponential-expanded form. Applying Equation
(7.4), we obtain a new exponential that has an operand that is a sum and so
is not in expanded form. Applying Equation ( 7.3), we obtain the expanded
form of the expression. /square
A procedure that transforms an expression to exponential-expanded
f o r mi sg i v e ni nF i g u r e 7.1. At line 4, the Mapoperator calls on the proce-
dure recursively to search all operands of the expression for exponentials. If
the resulting expression is an exponential (line 5), the procedure attempts
to apply Equation ( 7.3) (lines 7-9) or Equation ( 7.4) (lines 10-13). At line
9, two new exponentials are created that may not be in expanded form, and
so the procedure is called recursively to reapply the rules. (This recursion
is needed in Example 7.2.) For the same reason, the procedure is applied
recursively4to the new exponential created in line 13. (This recursion is
needed in Example 7.3.)
Unfortunately, because recursion is used in two ways, to traverse all
operands of the expression tree and to reapply the rules to newly created
exponentials, Expd
 expcreates some redundant recursion. To see how this
happens, consider the expansion of the expression exp(2 wx+3yz)d e -
s c r i b e di nE x a m p l e 7.2. In this case, there are 28 procedure calls with the
following inputs:
exp(2wx+3yz),2wx+3yz,2wx,2,w ,x , 3yz,3,y,z, (7.5)
exp(2wx),2wx,2,w ,x , (7.6)
exp(wx), w x, w, x, (7.7)
exp(3yz),3yz,3,y,z, (7.8)
exp(yz),yz,y,z. (7.9)
4In the Maple and MuPAD systems an expression like exp( 2(x+y)) is transformed
to exp( 2x+2y) by automatic simpliﬁcation, and so the recursive call at line 13 is not
needed. (Implementation: Maple (mws), MuPAD (mnb).)
278 7. Exponential and Trigonometric Transformations
Procedure Expd
exp(u);
Input
u:a nalgebraic expression ;
Output
analgebraic expression in exponential-expanded form;
Local Variables
v,A,f;
Begin
1 ifKind(u)∈{integer ,fraction ,symbol }then
2Return(u)
3 else
4 v:=Map(Expd
exp,u);
5 ifKind(v)=e xp then
6A : = Operand(v,1);
7 ifKind(A)=”+” then
8 f:=Operand(A,1);
9 Return(Expd
exp(exp(f))∗Expd
exp(exp(A−f)))
10 elseifKind(A)=” ∗”then
11 f:=Operand(A,1);
12 ifKind(f)=integer then
13 Return(Expd
exp(exp(A/f))f);
14Return(v)
End
Figure 7.1. An MPL procedure that transforms an algebraic expression to
exponential-expanded form. (Implementation: Maple(txt),Mathematica (txt),
MuPAD(txt). In the MuPAD implementation, the statement at line 11 assigns
the last operand of Atof.)
The inputs associated with the tree traversal of exp(2 wx+3yz) from line
4a r eg i v e ni n( 7.5). Since there are no exponentials in 2 wx+3yz,t h e
next recursive step occurs when the new exponential exp(2 wx)i sc r e a t e d
at line 9, which leads to the inputs for the next sequence of calls in ( 7.6).
Observe that redundant recursion occurs (from line 4) because all sub-
expressions of 2 wxare traversed for a second time. In a similar way, the
next sequence of inputs is given in ( 7.7) when the procedure attempts at line
13 to expand the new exponential exp( wx). Once again, more redundant
recursion arises (from line 4) as the sub-expressions of wxare traversed
for a third time. Finally, more redundant recursion occurs (from lines 9
and 13) with expansion of the new expressions exp(3 yz) and exp( yz)( s e e
(7.8)a n d( 7.9)).
7.1. Exponential and Trigonometric Expansion 279
One simple way to eliminate the redundant recursion is to implement
the procedure in a language that remembers the input-output values of pro-
cedure calls. Another approach is to separate the two roles for recursion by
using two procedures. The procedures that perform exponential expansionin this way are shown in Figure 7.2. Notice that there is an outer main
procedure Expand
expand an inner procedure Expand
 exp
rules.T h er e -
cursion that is used to traverse all operands of the expression tree is ob-tained with the Mapoperator at line 4 of Expand
exp. This procedure also
calls on Expand
 exp
rulesat line 6, which takes as input the argument of
an exponential function and applies the transformation rules (Equations
(7.3)a n d( 7.4)). Notice that the reapplication of the rules is obtained in
Expand
 exp
rulesat lines 3 and 7. Since Expand
 exp
rulesonly applies re-
cursion when a rule is applied, some redundant recursion is eliminated. For
example, to obtain the expanded form of exp(2 wx+3yz), the sequence
of inputs to Expand
 expis still given in ( 7.5), while the sequence of inputs
forExpand
 exp
rulesis given by
2wx+3yz,2wx, wx, 3yz, yz.
Using the two procedures in Figure 7.2, there are 15 procedure calls, while
using the single procedure in Figure 7.1, there are 28 procedure calls.
Appraisal of Expand
 exp. In the present form, the algorithm encounters a
division by zero whenever an application of a transformation rule together
with automatic simpliﬁcation transforms a denominator to zero. This oc-curs, for example, with
1
exp(2x)−exp(x)2.
A modiﬁcation of the algorithm that recognizes this and returns the symbol
Undeﬁned is described in Exercise 2.
Since Expand
 expis applied in the simpliﬁcation context of automatic
simpliﬁcation, it is unable to obtain some transformations that require
additional algebraic operations. For example, the manipulation
exp((x+y)(x−y)) = exp(x2)/exp(y2) (7.10)
is not obtained with exponential expansion unless the argument of the
exponential on the left is ﬁrst algebraically expanded. A modiﬁcation of
the algorithm that obtains this transformation is described in Exercise 3.
280 7. Exponential and Trigonometric Transformations
Procedure Expand
exp(u);
Input
u:a nalgebraic expression ;
Output
analgebraic expression in exponential-expanded form;
Local Variables
v;
Begin
1 ifKind(u)∈{integer ,fraction ,symbol }then
2Return(u)
3 else
4 v:=Map(Expand
exp,u);
5 ifKind(v)=e xp then
6 Return(Expand
exp
rules(Operand(v,1)))
7 else
8 Return(v)
End
Procedure Expand
exp
rules(A);
Input
A:a nalgebraic expression that is the argument of an exponential
function;
Output
the exponential-expanded form of exp( A);
Local Variables
f;
Begin
1 ifKind(A)=”+” then
2 f:=Operand(A,1);
3Return(Expand
exp
rules(f)∗Expand
exp
rules(A−f))
4 elseifKind(A)=” ∗”then
5 f:=Operand(A,1);
6 ifKind(f)=integer then
7 Return(Expand
exp
rules(A/f)f);
8Return(exp(A))
End
Figure 7.2. Two MPL procedures that separate the two roles for recursion
in exponential expansion. (Implementation: Maple(txt),Mathematica (txt),
MuPAD(txt). In the MuPAD implementation, the statement at line 5 of
Expand
exp
rulesassigns the last operand of Atof.)
7.1. Exponential and Trigonometric Expansion 281
Trigonometric Expansion
The sin and cos functions satisfy the identities:
sin(θ+φ)=s i n (θ)c o s (φ)+c o s (θ)s i n (φ), (7.11)
cos(θ+φ)=c o s (θ)c o s (φ)−sin(θ)s i n (φ). (7.12)
Thetrigonometric expansion operation applies these identities in a left to
right manner to all sin and cos functions in an expression. We also obtain
expanded forms for sin( nθ)a n dc o s ( nθ)(na positive integer) by viewing
the argument nθas a sum with nidentical operands θand repeatedly ap-
plying the rules. In addition, by applying the identities sin( −θ)=−sin(θ)
and cos( −θ)=c o s (θ), we obtain expanded forms for sin( nθ)a n dc o s ( nθ)
whennis a negative integer as well.
The goal of trigonometric expansion is described in the next deﬁnition.
Definition 7.4. An expression uis intrigonometric-expanded form if
the argument of each sinandcosfunction in u
1. is not a sum;
2. is not a product with an operand that is an integer.
The deﬁnition is given only in terms of sine and cosine functions be-
cause the other trigonometric functions can be expressed in terms of these
functions. (See the Trig
substitute procedure in Figure 5.12on page 190.)
Example 7.5. Consider the manipulation
sin(2x+3y)=s i n ( 2 x)cos(3y)+c o s ( 2x)sin(3y) (7.13)
=2 s i n (x)cos(x)/parenleftbig
cos3(y)−3cos (y)sin2(y)/parenrightbig
(7.14)
+/parenleftbig
cos2(x)−sin2(x)/parenrightbig/parenleftbig
3cos2(y)sin(y)−sin3(y)/parenrightbig
.
The sin on the left is not in trigonometric-expanded form because its ar-
gument is a sum. Applying the identity ( 7.11), we obtain two new sines
and two new cosines that are also not in expanded form. By reapplyingthe rules, we obtain the ﬁnal expanded form in Expression ( 7.14). /square
Example 7.6. Consider the manipulation
sin(2(x+y)) = 2 sin( x+y)cos(x+y) (7.15)
=2 ( s i n ( x)cos(y)+c o s (x)sin(y))(cos(x)cos(y)
−sin(x)sin(y)). (7.16)
282 7. Exponential and Trigonometric Transformations
The sin on the left is not in trigonometric-expanded form because its argu-
ment is a product with an integer operand. Applying the identity ( 7.11),
we obtain a new sine and a new cosine that are not in expanded form. By
reapplying the rules, we obtain the expanded form in Expression ( 7.16).
/square
Because of the identity
sin2(θ)+c o s2(θ)=1, (7.17)
an expression can have a number of trigonometric-expanded forms. For
example, our algorithm (shown in Figure 7.3) obtains the expanded form
cos(5x)=c o s5(x)−10 cos3(x)sin2(x)+5c o s (x)sin4(x).(7.18)
By using the identity ( 7.17), however, we can remove sin2(x)a n ds i n4(x)
from the expression and obtain another expanded form that involves only
cosines
cos(5x)=1 6c o s5(x)−20 cos3(x)+5c o s (x). (7.19)
Although a simple expansion algorithm is obtained by repeatedly ap-
plying the identities ( 7.11)a n d( 7.12), a straightforward implementation
can involve excessive recursion. We describe next three modiﬁcations to
this process that reduce some of this recursion.
First, as with exponential expansion, recursion is used two ways: to
examine all the operands of an expression tree and to reapply the transfor-
mations ( 7.11)a n d( 7.12) when a new sine or cosine is created. To reduce
redundant recursion, we divide the computation into two procedures that
handle each of the recursive tasks.
The next example shows another way that redundant recursion can
arise.
Example 7.7. Consider the trigonometric expansion of sin( a+b+c+d).
First, we apply the identity ( 7.11)w i t hθ=aandφ=b+c+dto obtain
sin(a+b+c+d)=s i n (a)cos(b+c+d)+c o s (a)sin(b+c+d).
Next, apply the identities ( 7.11)a n d( 7.12) recursively to cos( b+c+d)a n d
sin(b+c+d)w i t hθ=bandφ=c+d.t oo b t a i n
cos(b+c+d)=c o s (b)cos(c+d)−sin(b)sin(c+d),
sin(b+c+d)=s i n (b)cos(c+d)+c o s (b)sin(c+d).
Because both of the expressions on the right require expansions for cos( c+d)
and sin(c+d), the next recursive application of the rules leads to some
redundant recursion. Using this approach, this example requires seven
7.1. Exponential and Trigonometric Expansion 283
Procedure Expand
trig(u);
Input
u:a nalgebraic expression ;
Output
analgebraic expression in trigonometric-expanded form;
Local Variables v;
Begin
1 ifKind(u)∈{integer ,fraction ,symbol }then
2Return(u)
3 else
4 v:=Map(Expand
trig,u);
5 ifKind(v)=s i n then
6 Return(Operand(Expand
trig
rules(Operand(v,1)),1))
7 elseifKind(v)=c o s then
8 Return(Operand(Expand
trig
rules(Operand(v,1)),2))
9 else
10 Return(v)
End
Procedure Expand
trig
rules(A);
Input
A:a nalgebraic expression that is the argument of a sin or cos;
Output
a two element list [ s,c]w h e r e sandcare the
trigonometric-expanded forms of sin( A)a n dc o s ( A);
Local Variables f,r,s,c;
Begin
1 ifKind(A)=”+” then
2 f:=Expand
trig
rules(Operand(A,1));
3 r:=Expand
trig
rules(A−Operand(A,1));
4 s:=Operand(f,1)∗Operand(r,2)+Operand(f,2)∗Operand(r,1);
5 c:=Operand(f,2)∗Operand(r,2)−Operand(f,1)∗Operand(r,1);
6Return([s,c])
7 elseifKind(A)=” ∗”then
8 f:=Operand(A,1);
9 ifKind(f)=integer then
10 Return([Multiple
angle
sin(f,A/f),Multiple
angle
cos(f,A/f)]);
11Return([sin(A),cos(A)])
End
Figure 7.3. MPL procedures that transform an algebraic expression to
trigonometric-expanded form. (Implementation: Maple(txt),Mathematica
(txt),MuPAD(txt). In the MuPAD implementation, the statement at line 8
ofExpand
trig
rulesassigns the last operand of Atof.)
284 7. Exponential and Trigonometric Transformations
applications of the rules. In general, if a sin or cos has an argument that
is a sum of nsymbols, the number of rule applications grows exponentially
as 2n−1−1 (Exercise 6(a)). /square
There are a number of ways to eliminate this redundant recursion. One
way is simply to implement the algorithm in a language that remembers the
input-output values of procedure calls. Another approach, which we usehere, is to obtain sin( A)a n dc o s ( A) simultaneously. (See the discussion on
page285and the procedure Expand
trig
rulesin Figure 7.3.) This approach
requires only 2( n−1) rule applications to expand a sin or cos of a sum of
nsymbols (Exercise 6(b)).
Another improvement to the algorithm is based on the following repre-
sentations for multiple angle expansions. For na positive integer,
cos(nθ)=n/summationdisplay
j=0
jeven(−1)j/2/parenleftbiggn
j/parenrightbigg
cosn−j(θ)sinj(θ), (7.20)
sin(nθ)=n/summationdisplay
j=1
jodd(−1)(j−1)/2/parenleftbiggn
j/parenrightbigg
cosn−j(θ)sinj(θ). (7.21)
For example, the expansion in Equation ( 7.18) is obtained using the ﬁrst
formula.
These representations are derived using the exponential representations
for sin and cos and the binomial theorem. For example to obtain the sum
(7.20),
cos(nθ)=exp(ınθ)+e x p ( −ınθ)
2=exp(ıθ)n+e x p ( −ıθ)n
2
=(cos(θ)+ısin(θ))n+( c o s (θ)−ısin(θ))n
2
=( 1/2)
n/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
cosn−j(θ)ıjsinj(θ)
+n/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
cosn−j(θ)(−ı)jsinj(θ)

=( 1/2)n/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
cosn−j(θ)s i nj(θ)ıj(1 + ( −1)j).
7.1. Exponential and Trigonometric Expansion 285
However, using
ıj(1 + ( −1)j)=/braceleftbigg
2(−1)j/2,jeven,
0,j odd,
we obtain the representation ( 7.20).
Another approach for expanding sin( nθ)a n dc o s ( nθ) that uses recur-
rence relations is described in Exercise 10.
Procedures that transform an expression to trigonometric-expanded
form are given in Figure 7.3. The main procedure Expand
 trigapplies
the process to the operands of an expression using the Mapoperator in
line 4 and, if the resulting expression is a sin or cos, invokes the procedureExpand
trig
rulesto apply the expansion rules (lines 6 and 8).
Expand
 trig
rules(A) returns a two element list with the trigonometric-
expanded forms of sin( A)a n dc o s ( A). WhenAis a sum, the procedure is
applied recursively to both Operand (A,1) and to A−Operand (A,1) (line
2-3) after which the identities ( 7.11)a n d( 7.12) are applied to the result-
ing expressions (lines 4-5). (This recursion is needed in Example 7.5.)
WhenAis a product with an integer operand, the procedure invokes the
Multiple
 angle
 sinandMultiple
 angle
 cosprocedures, which apply the mul-
tiple angle representations given in ( 7.21)a n d( 7.20). (These procedures
are left to the reader (Exercise 5).) This step is also recursive because these
procedures invoke Expand
 trig
rules. (This recursion is needed in Exam-
ple7.7.) Finally, when neither transformation rule applies, the procedure
returns [sin( A),cos(A)] (line 11).
Appraisal of Expand
 trig.In the present form the algorithm encounters a
division by zero whenever an application of a transformation rule together
with automatic simpliﬁcation transforms a denominator to zero. For ex-ample, this occurs with the expression 1 /(sin(2x)−2sin(x)cos(x)). A
modiﬁcation of the algorithm that recognizes this and returns Undeﬁned
is described in Exercise 7.
Since the Expand
trigalgorithm does not include algebraic expansion, it
misses some opportunities to apply the trigonometric expansion rules. Forexample, the expression sin(( x+y)
2) is not expanded because ( x+y)2is
not in (algebraic) expanded form. In addition, the output for an expression
like sin(a+b+c+d) is cumbersome because it is returned in a nested form
rather than in an algebraic expanded form. In Exercise 8, we describe
modiﬁcations of the procedures that handle these problems.
In some instances, Expand
 trigdistorts the mathematical meaning of
an expression. Consider the expression
sin(2x)−2s i n (x)cos(x)
(sin(x))2+( c o s (x))2−1.
286 7. Exponential and Trigonometric Transformations
Strictly speaking, this expression is an indeterminate form because both the
numerator and denominator simplify to 0. However, Expand
 trigsimpliﬁes
the expression to 0 because the expanded form of the numerator is 0 while
the denominator is already in expanded form and is not changed. In Section7.2, we describe the Simplify
trigoperator that recognizes the problem for
this expression and indicates that it is undeﬁned. However, because it is
theoretically impossible to give an algorithm that can always determine ifan algebraic expression simpliﬁes to 0, it is impossible to avoid this problem
in all cases
5.
Exercises
1. Give the exponential-expanded form of the expression
exp((exp(2 x)−exp2(x)+1)(2 x+3y)).
2. TheExpand
expalgorithm encounters a division by zero if the transfor-
mation rules transform a sub-expression in a denominator to zero. For
example, this occurs with 1 /(exp(2 x)−exp(x)2). Modify the procedure so
that it recognizes this situation and returns the global symbol Undeﬁned
when it occurs.
3. Modify the deﬁnition of an exponential-expanded expression ugiven in
Deﬁnition 7.1so that it includes properties 1 and 2 from that deﬁnition
as well as the property that each complete sub-expression of uis in alge-
braic expanded form. Modify the procedures in Figure 7.2to obtain an
expression in this form. For example, your procedures should obtain
Expand
expi
expi
(x+y)2JJ
→expi
x2J
(exp(xy))2expi
y2J
.
4. Let u,v,a n dwbealgebraic expressions . The natural logarithm function
satisﬁes the following two properties:
ln(uv)=l n( u)+ln( v), (7.22)
ln(uw)=wln(u). (7.23)
Analgebraic expression is inlog-expanded form if the argument of each
logarithm is not a product or a power. For example, the manipulation
ln((wx)a)+ln( ybz)→a(ln(w)+ln( x))+bln(y)+ln( z).
transforms the expression on the left to log-expanded form. An expression
can be transformed to log-expanded form by applying Equations ( 7.22)
and (7.23) in a left to right manner. Give a procedure Expand
log(u)t h a t
transforms an algebraic expression uto log-expanded form.
5See footnote 6on page 145.
7.1. Exponential and Trigonometric Expansion 287
5. Let θbe analgebraic expression ,a n dl e t nbe an integer. Give procedures
Multiple
angle
sin(n,θ),Multiple
angle
cos(n,θ)
that ﬁnd the expansions for sin( nθ)a n dc o s ( nθ) using Equations ( 7.20)
and (7.21). Keep in mind when θis a sum, sin( θ)a n dc o s ( θ)a r en o ti n
expanded form. (This situation occurs in Example 7.6.) In this case it is
necessary6to expand these expressions with Expand
trig
rules.
Besuretoaccount forthepossibility that nisanegativeinteger. Although
most computeralgebra systemsapply transformations suchas sin( −2y)→
−sin(2y) during automatic simpliﬁcation, this situation will arise in our
algorithm with sin( x−2y)b e c a us eExpand
trig
rulestakes theargument
of a sin or cos as input rather than the function form.
6. Considertheexpansionofsin( A)andcos( A)where Aisasumof nsymbols.
(a) Showthattoexpandsin( A)orcos( A)usingtheapproachinExample
7.7requires 2n−1−1 rule applications.
(b) Show that to expand sin( A)a n dc o s ( A) simultaneously using the
algorithm in Figure 7.3requires 2( n−1) rule applications.
7. TheExpand
trigalgorithm may encounter a division by zero if the trans-
formation rules transform a sub-expression in a denominator to zero. For
example, this occurs with 1 /(sin(2x)−2sin(x)c o s (x)). Modify the pro-
cedure so that it recognizes this situation and returns the global symbol
Undeﬁned when it occurs.
8. Suppose we modify the deﬁnition of a trigonometric-expanded expression
uin Deﬁnition 7.4so that it includes properties (1) and (2) in that deﬁni-
tion as well as the property that each complete sub-expression of uis in
algebraic expandedform. Modify theprocedures inFigure 7.3to obtainan
expression in this form. For example, your procedures should obtain
Expand
trigi
sini
(x+y)2JJ
→
sin(x2)ii
(cos(xy))2−(sin(xy))2J
cos(y2)
−2c o s (xy)sin(xy)sin(y2)J
+cos(x2)i
2c o s (xy)sin(xy)cos(y2)
+i
(cos(xy))2−(sin(xy))2J
sin(y2)J
.
9. In this exercise we describe an extension to the Expand
trigalgorithm to
include the sinh and cosh functions. These functions satisfy the identities
sinh(θ+φ)=sinh( θ)c o s h ( φ)+cosh( θ) sinh( φ),
cosh(θ+φ)=c o s h( θ)c o s h ( φ)+sinh( θ) sinh( φ),
6In the Maple and MuPAD systems, it is not necessary to invoke Expand
 trig
rules
here because an integer is distributed over the operands of a sum by automatic simpli-ﬁcation, and so θcannot be a sum.
288 7. Exponential and Trigonometric Transformations
sinh(−θ)=−sinh(θ),cosh(−θ)=c o s h( θ),
cosh(nθ)±sinh(nθ)=(c o s h( θ)±sinh(θ))n,(7.24)
where nis a positive integer.
(a) Using the identity ( 7.24)i tf o l l o w st h a t
cosh(nθ)=1/2( ( c o s h ( θ)+sinh( θ))n+(cosh( θ)−sinh(θ))n),
sinh(nθ)=1/2 ((cosh( θ)+sinh( θ))n−(cosh(θ)−sinh(θ))n).
Usetheseformulas toderiverepresentations similar tothosein Equa-
tions (7.20)a n d(7.21) for sinh( nθ)a n dc o s h ( nθ).
(b) Extend the Expand
trigalgorithm so that it also expands the sinh
and cosh functions.
10. This exercise describes another approach that ﬁnds the expanded form for
sin(nθ)a n dc o s ( nθ) that uses recurrence relations.
(a) Show that for n≥2,pn=s i n(nθ) satisﬁes the recurrence relation
pn=2c o s( θ)pn−1−pn−2,p 1=s i n(θ),p 0=0.
(b) Show that for n≥2,qn=c o s( nθ) satisﬁes the recurrence relation
qn=2c o s( θ)qn−1−qn−2,q 1=c o s( θ),q 0=1.
Notice that this recurrence relation gives the expansion in ( 7.19).
(c) Giveproceduresthatﬁndtheexpandedformsforsin( nθ)andcos( nθ)
usingtherecurrencerelations inparts(a)and(b). Besuretoaccountforthepossibilitythat nisnegativeand θisasum. (Seethediscussion
in Exercise 5above.)
11. In this exercise we ask youto give a procedu re for trigonometric expansion
of the tangent function that is based on the identity
tan(θ+φ)=tan(θ)t a n (φ)
1−tan(θ)t a n (φ). (7.25)
(a) Let nbe a positive integer. Show that
tan(nθ)=n
j=1
jodd(−1)(j−1)/2~
n
j^
tanj(θ)
n
j=0
jeven(−1)j/2~
n
j^
tanj(θ).(7.26)
(b) Give a procedure Expand
tan(u) that is based on Equations ( 7.25)
and (7.26).
7.2. Exponential and Trigonometric Contraction 289
7.2 Exponential and Trigonometric Contraction
In this section we describe the exponential and trigonometric contraction
operators and a trigonometric simpliﬁcation operator that can verify a large
class of trigonometric identities.
Exponential Contraction
Exponential contraction applies the two transformation rules7
exp(u)e x p (v)→exp(u+v), (7.27)
exp(u)w→exp(wu). (7.28)
The goal of this operation is described in the following deﬁnition.
Definition 7.8. Analgebraic expression uis inexponential-contracted
form if it satisﬁes the following properties.
1. Each product in ucontains at most one operand that is an exponential
function.
2. Each power in udoes not have an exponential function for its base.
3. Each complete sub-expression of uis in algebraic-expanded form.
Properties (1) and (2) are obtained by applying the transformations
(7.27)a n d( 7.28). We have included property (3) because algebraic expan-
sion creates new opportunities to apply these rules. This point is illustrated
in the next example.
Example 7.9. Consider the manipulation
exp(x)(exp(x)+e x p (y)) = (exp( x))2+e x p (x)e x p (y)
=e x p ( 2 x)+e x p (x+y).
The expression on the left is not in contracted form because it is not in
algebraic-expanded form. Algebraic expansion gives a new sum with two
operands, a new power and a new product, that are not in contracted form.Applying the transformations ( 7.27)a n d( 7.28) we obtain the contracted
form. /square
7See footnote 1on page 276for some remarks about the validity of these transfor-
mations in real and complex contexts.
290 7. Exponential and Trigonometric Transformations
Procedure Contract
exp(u);
Input
u:a nalgebraic expression ;
Output
analgebraic expression in exponential-contracted form;
Local Variables
v;
Begin
1 ifKind(u)∈{integer ,fraction ,symbol }then
2Return(u)
3 else
4 v:=Map(Contract
exp,u);
5 ifKind(v)∈{”∗”,”∧”}then
6 Return(Contract
exp
rules(v))
7 else
8 Return(v)
End
Figure 7.4. The main MPL procedure that transforms an algebraic expression to
exponential-contracted form. (Implementation: Maple(txt),Mathematica (txt),
MuPAD(txt).)
Example 7.10. Consider the manipulation
exp(exp(x))exp(y)= exp(exp( x)e x p (y))
= exp(exp( x+y)).
The expression on the left is not in contracted form because it is a power
with an exponential for a base. Applying Equation ( 7.28)w eo b t a i na n
expression with a new product that is not in contracted form. Applying
Equation ( 7.27) we obtain the contracted form. /square
Procedures8for exponential contraction are shown in Figures 7.4and
7.5. Notice that there is an outer main procedure Contract
 expa n da ni n n e r
procedure Contract
 exp
rules. We have divided the computation in this
way to account for the two types of recursion that occur in the algorithm
and to indicate clearly where algebraic expansion or a reapplication of ther u l e si sr e q u i r e d .
The recursion that is used to traverse all operands of the expression tree
is obtained with the Mapoperator in line 4 of Contract
exp. At line 6, this
8See footnote 2on page 276concerning the Mathematica implementation of these
procedures.
7.2. Exponential and Trigonometric Contraction 291
Procedure Contract
exp
rules(u);
Input
u:a nalgebraic expression that is sent by either Contract
exp
or a recursive call of this procedure;
Output
analgebraic expression in exponential-contracted form;
Local Variables v,b,s,p,i,y ;
Begin
1 v:=Expand
main
op(u);
2 ifKind(v)=” ∧”then
3 b:=Operand(v,1);
4 s:=Operand(v,2);
5 ifKind(b)=e xp then
6 p:=Operand(b,1)∗s;
7 ifKind(p)∈{”∗”,”∧”}then
8 p:=Contract
exp
rules(p);
9 Return(exp(p))
10 else
11 Return(v)
12 elseifKind(v)=” ∗”then
13 p:= 1;
14 s:= 0;
15 fori:= 1toNumber
of
operands(v)do
16 y:=Operand(v,i);
17 ifKind(y)=exp then
18 s:=s+Operand(y,1)
19 else
20 p:=p∗y;
21Return(exp(s)∗p)
22 elseifKind(v)=”+” then
23 s:= 0;
24 fori:= 1toNumber
of
operands(v)do
25 y:=Operand(v,i);
26 ifKind(y)∈{”∗”,”∧”}then
27 s:=s+Contract
exp
rules(y)
28 else
29 s:=s+y;
30Return(s)
31 else
32Return(v)
End
Figure 7.5. The inner MPL procedure for exponential contraction. (Implemen-
tation:Maple(txt),Mathematica (txt),MuPAD(txt).)
292 7. Exponential and Trigonometric Transformations
procedure calls on Contract
 exp
ruleswhich applies algebraic expansion
and the transformation rules (Equations ( 7.27)a n d( 7.28)). Notice that
we only invoke Contract
 exp
ruleswhenvis a product or a power.
The second type of recursion occurs when either algebraic expansion or
an application of one of the contraction rules creates a new sum, product,or power that is not in contracted form. This recursion is invoked at lines 8
and 27 of Contract
exp
rules. At line 1 we algebraically expand the input
expression. To avoid redundant recursion, we use the Expand
 main
 opop-
erator that does not recursively expand its operands (Exercise 6, page 258).
Whenvis power (line 2) with an exponential function at its base (line 5),
we apply Equation ( 7.28) to obtain a new operand pof the exponential.
Then, ifpis a product or a power (by automatic simpliﬁcation), we recur-
sively contract this expression (lines 7 and 8). (This recursion is requiredin Example 7.10.) If the base is not an exponential, no transformation is
possible and we return v(line 11).
Next, ifvis a product (line 12), we loop through its operands (lines
13-20) combining exponentials with Equation ( 7.27). Lines 22-30 handle
the case when vis a sum. (This part is only invoked when a sum is created
by the expansion in line 1.) In this case, we loop through the operands andrecursively contract when an operand is a product or power. Finally, lines
31 and 32 apply to any other type of expression that was created by the
expansion at line 1. For example, for u=(√
2+1 )(√
2−1) the expansion
at line 1 assigns 1 to vwhich is returned at line 32.
Appraisal of Contract
 exp.Although exponential contraction acts as an
expression simpliﬁer for many expressions with exponentials, it does not
simplify all such expressions. For example, consider the exponential con-
traction
Contract
 exp/parenleftbigg1
exp(x)(exp(y)+e x p ( −x))−exp(x+y)−1
(exp(x+y))2−1/parenrightbigg
(7.29)
→exp(−x)
exp(y)+e x p ( −x)−exp(x+y)
(exp(x+y))2−1+1
(exp(x+y))2−1.
Although the (uncontracted) expression in ( 7.29) simpliﬁes to 0, this simpli-
ﬁcation is not obtained with Contract
 exp. There are two reasons for this.
First, since the ﬁrst term in ( 7.29) has the internal form exp( x)−1(exp(y)+
exp(−x))−1which is in algebraic-expanded form, the contraction operation
does not distribute exp( x)o v e rt h es u me x p ( y)+e x p ( −x). Next, in the
second term in ( 7.29), the numerator and denominator have a common fac-
tor exp(x+y)−1 that is not eliminated by exponential contraction. One
way to simplify the expression in ( 7.29) is to ﬁrst rationalize it using the
7.2. Exponential and Trigonometric Contraction 293
Rationalize
 expression operator described in Section 6.5and then contract
the numerator of the resulting expression. An operator that obtains the
simpliﬁcation in this way is described in Exercise 4.
Trigonometric Contraction
The sin and cos functions satisfy the identities:
sin(θ)s i n (φ)=cos(θ−φ)
2−cos(θ+φ)
2, (7.30)
cos(θ)c o s (φ)=cos(θ+φ)
2+cos(θ−φ)
2, (7.31)
sin(θ)c o s (φ)=sin(θ+φ)
2+sin(θ−φ)
2. (7.32)
Thetrigonometric contraction operation applies these identities in a left to
right manner. By repeatedly applying the identities ( 7.30)a n d( 7.31), we
also obtain contracted forms for sinn(θ)a n dc o sn(θ) (for an integer n>1).
The goal of this operation is given in the following deﬁnition.
Definition 7.11. An expression uis intrigonometric-contracted form
if it satisﬁes the following properties.
1. A product in uhas at most one operand that is a sine or cosine.
2. A power in uwith a positive integer exponent does not have a base
that is a sine or cosine.
3. Each complete sub-expression of uis in algebraic-expanded form.
Notice that the deﬁnition does not refer to the tan, cot, sec, and csc
functions because these functions can be expressed in terms of sin and cos.
We have included property (3) because algebraic expansion creates new
opportunities to apply the contraction rules. This point is illustrated in
the next two examples.
Example 7.12. Consider the manipulation
(sin(x)+c o s (y)) cos(y)=s i n ( x)c o s (y)+c o s2(y)
=sin(x+y)
2+sin(x−y)
2+1
2+cos(2y)
2.
294 7. Exponential and Trigonometric Transformations
The expression on the left is not in contracted form because it is not in
algebraic-expanded form. By expanding the expression, we obtain a new
sum with two operands, a new product and a new power, that are not in
contracted form. By applying the identities ( 7.32)a n d( 7.31), we obtain
the contracted form. /square
Example 7.13. Consider the manipulation
sin2(x)cos2(x)=/parenleftbigg1
2−cos(2x)
2/parenrightbigg/parenleftbigg1
2+cos(2x)
2/parenrightbigg
(7.33)
=1
4−cos2(2x)
4(7.34)
=1
4−1/2+c o s ( 4x)/2
4
=1
8−cos(4x)
8.
The expression on the left is not in contracted form because it contains a
sine and cosine to positive integer powers. Applying the identities ( 7.30)
and (7.31), we obtain a new product that is not in contracted form because
it is not in algebraic-expanded form. Algebraically expanding the right
side of Equation ( 7.33), we obtain in ( 7.34) a new sum that again is not
in contracted form because it contains a positive integer power of a cosine.
Applying the identity ( 7.31) and algebraically expanding, we obtain the
contracted form. /square
A simple algorithm for trigonometric contraction is obtained by repeat-
edly applying the identities ( 7.30), (7.31), and ( 7.32) although the approach
involves an excessive amount of recursion. As with exponential contraction,
we can reduce the redundant recursion by dividing the operation into twoprocedures. Another improvement involves the contraction of positive in-
teger powers of sines and cosines using the following representations. For
na positive integer,
cos
n(θ)=

/parenleftbig
n
n/2/parenrightbig
2n+1
2n−1n/2−1/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
cos((n−2j)θ),neven,
1
2n−1⌊n/2⌋/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
cos((n−2j)θ),n odd,(7.35)
7.2. Exponential and Trigonometric Contraction 295
sinn(θ)=

(−1)
n/parenleftbign
n/2/parenrightbig
2n+(−1)n
2
2n−1n/2−1/summationdisplay
j=0(−1)j/parenleftbiggn
j/parenrightbigg
cos((n−2j)θ),neven,
(−1)n−1
2
2n−1⌊n/2⌋/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
(−1)jsin((n−2j)θ),n odd,
(7.36)
where the ﬂoor function ⌊n/2⌋is the largest integer ≤n/2. We verify the
representation for cosn(θ)f o rnodd. Using the exponential representation
for cos(θ) and the binomial theorem, we have
cosn(θ)=/parenleftbiggeiθ+e−iθ
2/parenrightbiggn
=1
2nn/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
(eiθ)n−j(e−iθ)j
=1
2nn/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
ei(n−2j)θ
=1
2n
⌊n/2⌋/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
ei(n−2j)θ+n/summationdisplay
j=⌊n/2⌋+1/parenleftbiggn
j/parenrightbigg
ei(n−2j)θ
,
where the two sums in the last expression have the same number of terms.
We can combine these two sums by expressing the second sum in termsof a new summation index k=n−j. Observe that since nis odd,n=
2⌊n/2⌋+1, and this implies that k=⌊n/2⌋whenj=⌊n/2⌋+1. Therefore,
by reversing the order of summation in the second sum and using theidentity/parenleftbiggn
n−k/parenrightbigg
=/parenleftbiggn
k/parenrightbigg
,
we have
cos
n(θ)=1
2n
⌊n/2⌋/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
ei(n−2j)θ+⌊n/2⌋/summationdisplay
k=0/parenleftbiggn
k/parenrightbigg
ei(n−2(n−k))θ

=1
2n⌊n/2⌋/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
(ei(n−2j)θ+e−i(n−2j)θ)
296 7. Exponential and Trigonometric Transformations
=1
2n−1⌊n/2⌋/summationdisplay
j=0/parenleftbiggn
j/parenrightbigg
cos((n−2j)θ).
The derivations for the other cases are similar (Exercise 6).
Example 7.14. Using Equation ( 7.35)w eh a v e
cos4(x)=1/8c o s ( 4x)+1/2c o s ( 2x)+3/8. /square
Procedures for trigonometric contraction are given in Figures 7.6,7.7,
and7.8. The recursion that is used to traverse all operands of an expression
tree is obtained with the Mapoperator in line 4 of Contract
 trig.A t
line 6, this procedure calls on Contract
 trig
rules, which applies algebraic
expansion and calls on other procedures that apply the transformation rules
in (7.30), (7.31), and ( 7.32).
The second type of recursion occurs when either algebraic expansion
or an application of one of the contraction rules creates a new sum, prod-
uct, or power that is not in contracted form. This recursion is invoked
inContract
 trig
rulesat line 15 through Contract
 trig
product and directly
at line 21. At line 1 of Contract
 trig
rules, we algebraically expand the
Procedure Contract
trig(u);
Input
u:a nalgebraic expression ;
Output
analgebraic expression in trigonometric-contracted form;
Local Variables
v;
Begin
1 ifKind(u)∈{integer ,fraction ,symbol }then
2Return(u)
3 else
4 v:=Map(Contract
trig,u);
5 ifKind(v)∈{”∗”,”∧”}then
6 Return(Contract
trig
rules(v))
7 else
8 Return(v)
End
Figure 7.6. The main MPL procedure that transforms an algebraic expression
to trigonometric-contracted form. (Implementation: Maple(txt),Mathematica
(txt),MuPAD(txt).)
7.2. Exponential and Trigonometric Contraction 297
Procedure Contract
trig
rules(u);
Input
u:a nalgebraic expression (sum, product, power) that is sent by
eitherContract
trig,Contract
trig
power, or a recursive call
of this procedure;
Output
analgebraic expression in trigonometric-contracted form;
Local Variables
v,s,c,d,i,y ;
Begin
1 v:=Expand
main
op(u);
2 ifKind(v)=” ∧”then
3Return(Contract
trig
power(v))
4 elseifKind(v)=” ∗”then
5 s:=Separate
sin
cos(v);
6 c:=Operand(s,1);
7 d:=Operand(s,2);
8 ifd=1then
9 Return(v)
10 ifKind(d)∈{sin,cos}then
11 Return(v)
12 elseifKind(d)=” ∧”then
13 Return(Expand
main
op(c∗Contract
trig
power(d)))
14 else
15 Return(Expand
main
op(c∗Contract
trig
product(d)))
16 elseifKind(v)=”+” then
17 s:= 0;
18 fori:= 1toNumber
of
operands(v)do
19 y:=Operand(v,i);
20 ifKind(y)∈{”∗”,”∧”}then
21 s:=s+Contract
trig
rules(y)
22 else
23 s:=s+y;
24Return(s)
25 else
26Return(v)
End
Figure 7.7. The inner MPL procedure for trigonometric contraction. (Imple-
mentation: Maple(txt),Mathematica (txt),MuPAD(txt).)
298 7. Exponential and Trigonometric Transformations
Procedure Contract
trig
product(u);
Input
u: a product of sines, cosines, and positive integer powers
of sines and cosines;
Output
the trigonometric-contracted form of u;
Local Variables
A,B,θ,φ;
Begin
1 ifNumber
of
operands(u)=2then
2 A:=Operand(u,1);
3 B:=Operand(u,2);
4 ifKind(A)=” ∧”then
5 A:=Contract
trig
power(A);
6 Return(Contract
trig
rules(A∗B))
7 elseifKind(B)=” ∧”then
8 B:=Contract
trig
power(B);
9 Return(Contract
trig
rules(A∗B))
10 else
11 θ:=Operand(A,1);
12 φ:=Operand(B,1);
13 ifKind(A)=s i n andKind(B)=s i n then
14 Return(cos(θ−φ)/2−cos(θ+φ)/2)
15 elseifKind(A)=cos andKind(B)=c o s then
16 Return(cos(θ+φ)/2+cos( θ−φ)/2)
17 elseifKind(A)=sin andKind(B)=c o s then
18 Return(sin(θ+φ)/2+sin( θ−φ)/2)
19 elseifKind(A)=cos andKind(B)=s i n then
20 Return(sin(θ+φ)/2+sin( φ−θ)/2)
21 else
22 A:=Operand(u,1);
23 B:=Contract
trig
product(u/A);
24Return(Contract
trig
rules(A∗B))
End
Figure 7.8. The MPL procedure Contract
trig
productthat contracts products
whose operands are sines, cosines, or positive integer powers of sines or cosines.(Implementation: Maple(txt),Mathematica (txt),MuPAD(txt).)
input expression using the operator Expand
 main
 op(Exercise 6, page 258).
Whenvis a power (lines 2-3), we contract using Contract
 trig
power which
checks ifvis a positive integer power of a sine or cosine and if so, applies
Equation ( 7.35)o rE q u a t i o n( 7.36) (Exercise 7).
7.2. Exponential and Trigonometric Contraction 299
Next, in lines 4-15, when vis a product we ﬁrst apply Separate
 sin
cos
(Exercise 12, page 152) which returns a two element list with the operands
ofvseparated into two categories: the product of the operands that are
sines, cosines, or positive integer powers of sines and cosines (representedbyd), and the product of the remaining operands (represented by c). At
lines 8-9, when d= 1, there are no opportunities for contraction, and so v
is returned. In a similar way, at lines 10-11, when dis a sine or cosine, there
are no opportunities for contraction, and so vis returned. At lines 12-13,
whendis a positive integer power of a sine or cosine, we contract using
Contract
trig
power which applies Equation ( 7.35)o rE q u a t i o n( 7.36)( E x -
ercise7). Because this procedure returns a sum, we algebraically expand to
distribute cover the sum so that property (3) in Deﬁnition 7.11is satisﬁed.
Line 15 handles the case when dis a product of sines, cosines, or positive in-
teger powers of sines and cosines using the procedure Contract
 trig
product
which is described below. Again, expansion is required because the outputof this procedure is a sum.
Lines 16-24 handle the case when vis a sum, and lines 25-26 handle
other types of expressions that may arise because of the expansion at line 1.
Contract
trig
product , which contracts a product of sines, cosines and
positive integer powers of sines and cosines, is shown in Figure 7.8.T h e
case where uhas two operands is handled in lines 1-20. When one of the
operands is a power, this power is contracted (line 5 or 8), and the new
product is contracted with a recursive call to Contract
 trig
rules(line 6 or
9). At lines 11-20, both AandBare either sines or cosines, and so we
apply the transformations in ( 7.30), (7.31), or ( 7.32). The case when u
has three or more operands is handled in lines 21-24. In this situation, the
product with the ﬁrst operand removed is contracted recursively (line 23),and then the new product is contracted with Contract
trig
rules(line 24).
Simplification of Trigonometric Expressions
We now have all the building blocks that are needed to construct an oper-
ator that can verify a large class of trigonometric identities.
Automatic Simplification of Trigonometric Functions. Because our simpliﬁca-
tion operator performs in the context of automatic simpliﬁcation, we con-
sider ﬁrst the trigonometric transformations that are applied in this setting.
These include the following transformations.
1.Evaluation of trigonometric functions. Letf(x) be a trigono-
metric function. Typically, automatic simpliﬁcation evaluates f(kπ/n)
wherekandn/negationslash= 0 are integers and nis small (usually n=1,2,3,4,6).
300 7. Exponential and Trigonometric Transformations
Although the values f(kπ/n) can always be expressed using radicals, the
representations are quite involved for large values of n. For example
sin(π/60) =/radicalbig
5+√
5
8−/radicalbig
5+√
5√
3
8−/parenleftBig
−√
5
4+1/4/parenrightBig√
2
4
−/parenleftBig
−√
5
4+1/4/parenrightBig√
2√
3
4. (7.37)
Because it is rarely useful to evaluate f(kπ/n) for large values of n,t h e s e
evaluations are usually not performed during automatic simpliﬁcation (Ex-ercise 3, page 56).
2.Transformation to argument with positive sign and other
standard forms. In most computer algebra systems, automatic simpliﬁ-
cation transforms a trigonometric function to an equivalent form with anargument with positive sign. This includes transformations such as
sin(−2/3)→−sin(2/3),sin(−x)→−sin(x),cos(−2ab)→cos(2ab).
In addition, in both Maple and Mathematica automatic simpliﬁcation trans-
forms trigonometric functions so that arguments that are sums are trans-
formed to a standard form, although each system uses its own scheme todetermine the standard form. For example, the Maple system obtains the
transformation
sin(1−x)→−sin(x−1),
while the Mathematica system obtains the opposite transformation
Sin[x−1]→− Sin[1−x].
3.Transformationstoargumentsintheﬁrstquadrant. Ins o m e
systems, automatic simpliﬁcation transforms a trigonometric function with
an argument that includes a rational multiple of πto an equivalent function
where the multiple of πis between 0 and π/2. Typical transformations are
sin(15π/16)→sin(π/16),sin(x+2π/3)→cos(x+π/6).
4.Elementary trigonometric expansions. Ins o m es y s t e m s ,a u -
tomatic simpliﬁcation applies a limited form of trigonometric expansion
when the argument of a trigonometric function is a sum with an operand
of the form kπ/2w h e r ekis an integer. For example,
sin(x+π/2+y)→cos(x+y), cos(x+2π)→cos(x).
7.2. Exponential and Trigonometric Contraction 301
MPL
 Maple
 Mathematica
 MuPAD
sin(π/3)
→√
3/2
√
3/2
√
3/2
√
3/2
sin(−x)
→−sin(x)
 −sin(x)
 −Sin[x]
 −sin(x)
sin(1−x)
→−sin(x−1)
 −sin(x−1)
 Sin[1−x]
 sin(−x+1)
sin(−1+x)
→sin(−1+x)
 sin(−1+x)
 −Sin[1−x]
 sin(x−1)
sin(15 π/16)
→sin(π/16)
 sin(π/16)
 Sin[15π/16]
 sin(π/16)
sin(x+2π/3)
→cos(x+π/6)
 cos(x+π/6)
 Sin[2π/3+x]
 sin(x+2π/3)
sin(x+π/2+y)
→cos(x+y)
 cos(x+y)
 Cos[x+y]
sin(x+y+π/2)
cos(x+2π)
→cos(x)
 cos(x)
 Cos[x]
 cos(x)
sin(x)/cos(x)
→sin(x)/cos(x)
sin(x)/cos(x)
 Tan[x]
 sin(x)/cos(x)
Figure 7.9. Examples of trigonometric transformations in automatic simpliﬁ-
cation in Maple, Mathematica, and MuPAD. (Implementation: Maple(mws),
Mathematica (nb),MuPAD(mnb).)
However, for other rational multiples of π(such as sin( x+π/6)), the ex-
pansion does not occur.
5.Function transformations. The Mathematica system obtains the
following function transformations in automatic simpliﬁcation:
Sin[x]/Cos[x]→ Tan[x],
Cos[x]/Sin[x]→ Cot[x],
1/Sin[x]→ Csc[x],
1/Cos[x]→ Sec[x].
These transformation are not obtained by automatic simpliﬁcation in either
Maple or MuPAD.
Examples of trigonometric transformations in automatic simpliﬁcation
in Maple, Mathematica, and MuPAD are given in Figure 7.9.
The Simplification Algorithm. To motivate the simpliﬁcation algorithm, let’s
consider a number of examples.
302 7. Exponential and Trigonometric Transformations
Example 7.15. Consider the expression
(cos(x)+s i n (x))4+( c o s (x)−sin(x))4+c o s ( 4x)−3. (7.38)
The trigonometric contraction algorithm simpliﬁes this expression to 0.
On the other hand, the trigonometric expansion algorithm described
in Section 7.1(together with algebraic expansion) does not simplify Ex-
pression ( 7.38) to 0. These operations obtain the trigonometric-expanded
form
3c o s4(x)+6c o s2(x)sin2(x)+3s i n4(x)−3./square
Example 7.16. Consider the expression
sin(x)+s i n (y)−2s i n (x/2+y/2)cos(x/2−y/2).
Again, the contraction algorithm simpliﬁes this expression to 0. On the
other hand, trigonometric expansion gives the expanded form
sin(x)+s i n (y)−/parenleftBig
2( s i n (x/2)cos(y/2) + cos(x/2)sin(y/2))
(cos(x/2)cos(y/2) + sin(x/2)sin(y/2))/parenrightBig
. /square
These examples suggest that trigonometric contraction is a more pow-
erful simpliﬁer than trigonometric expansion. However, the next example
shows that both expansion and contraction play a role in simpliﬁcation.
Example 7.17. Consider the expression
sin3(x)+c o s3(x+π
6)−sin3(x+π
3)+3s i n ( 3x)
4. (7.39)
Although this expression simpliﬁes to 0, this is not obtained with trigono-
metric contraction, which obtains
3
4sin(x)+3
4cos/parenleftBig
x+π
6/parenrightBig
−3
4sin/parenleftBig
x+π
3/parenrightBig
.
The problem here is that the simpliﬁcation requires the trigonometric ex-
pansion of cos( x+π/6) and sin( x+π/3) and evaluation of the resulting sin
and cos functions at π/3o rπ/6. The simpliﬁcation to 0 is obtained by ﬁrst
expanding Expression ( 7.39) and then contracting the resulting expression.
/square
Example 7.18. Consider the identity
sin(x)+s i n ( 3x)+s i n ( 5x)+s i n ( 7x)
cos(x)+c o s ( 3x)+c o s ( 5x)+c o s ( 7x)=t a n ( 4x).
7.2. Exponential and Trigonometric Contraction 303
Procedure Simplify
trig(u);
Input
u:a nalgebraic expression ;
Output
either an algebraic expression in trigonometric contracted form
or the global symbol Undeﬁned ;
Local Variables
v,w,n,d;
Begin
1 v:=Trig
substitute(u);
2 w:=Rationalize
expression (v);
3 n:=Expand
trig(Numerator (w));
4 n:=Contract
trig(n);
5 d:=Expand
trig(Denominator (w));
6 d:=Contract
trig(d);
7 ifd=0then
8Return(Undeﬁned )
9 else
10Return(n/d)
End
Figure 7.10. The MPL procedure Simplify
trig. (Implementation: Maple(txt),
Mathematica (txt),MuPAD(txt).)
We verify the identity by subtracting the right side from the left side and
showing this expression simpliﬁes to 0. Our algorithm does this by replacing
tan(4x) with sin(4 x)/cos(4x), rationalizing the resulting expression, and
then contracting the numerator of the rationalized form. In this case the
numerator of the rationalized expression is
cos(4x)(sin(x)+s i n ( 3x)+s i n ( 5x)+s i n ( 7x))
−(cos(x)+c o s ( 3x)+c o s ( 5x)+c o s ( 7x))sin(4x),
which has 0 as a contracted form. /square
A procedure that obtains the simpliﬁcations in the above examples is
given in Figure 7.10. At line 1 we form a new expression by replacing the
tan, sec, cot, and csc functions with equivalent forms with sin and cos using
theTrig
substitute operator9(given in Section 5.2), and at line 2 we ratio-
9These substitutions do not occur in Mathematica because automatic simpliﬁcation
performs the inverse transformations (see footnote 2, page 187). Our implementation of
the algorithm in this system does not include the step in line 1.
304 7. Exponential and Trigonometric Transformations
nalize the resulting expression. At line 3, we trigonometrically expand the
numerator of wso that a rational multiple of πthat appears as an operand
of a sum in an argument of a sin or cos now appears directly as the argu-
ment of a sin or cos. This operation together with automatic simpliﬁcationobtains the numerical representation of some sines and cosines. (This op-
eration is required in Example 7.17.) At line 4, we contract the numerator
and in lines 5 and 6 apply expansion and contraction to the denominator.Finally, at line 7 we check if the denominator has been simpliﬁed to 0, and,
if so, return the global symbol Undeﬁned . Otherwise, we return n/d.
Appraisal of
Simplify
 trig.TheSimplify
 trigoperator can verify many trig-
onometric identities that appear in trigonometry textbooks. In this role,
it is most eﬀective by showing that the diﬀerence of the two sides of an
identity simplify to 0, as was done in Example 7.18. For expressions that
do not simplify to 0, however, it is less successful. For example, for theidentity
sin(x)+s i n ( 3x)+s i n ( 5x)+s i n ( 7x)
cos(x)+c o s ( 3x)+c o s ( 5x)+c o s ( 7x)=sin(4x)
cos(4x),
the smaller expression on the right is a simpler form than the one on the
left. However, Simplify
 trigdoes not change either side of this expres-
sion because the numerators and denominators on both sides are in con-
tracted form.
In addition, identities that require other (non-trigonometric) transfor-
mations might not be veriﬁed with Simplify
 trig. For example, although
the expression
sin2/parenleftbiggx+1
x+2/parenrightbigg
+c o s2/parenleftbigg1+1/x
1+2/x/parenrightbigg
simpliﬁes to 1, this is not obtained by our algorithm because it does not
recognize the arguments of sin and cos as equivalent expressions.
The algorithm depends, of course, on the transformations applied to
trigonometric functions during automatic simpliﬁcation. For example, both
the Maple and Mathematica implementations of the algorithm simplify
Expression ( 7.39) to 0. On the other hand, the MuPAD implementation
obtains
−sin(x−y)
2−sin(−x+y)
2
because arguments of sines that are sums are not transformed to a stan-
dard form in this system. In a similar way, both the Maple and MuPAD
implementations simplify
sin(x)+s i n ( 3x)+s i n ( 5x)+s i n ( 7x)
cos(x)+c o s ( 3x)+c o s ( 5x)+c o s ( 7x)−tan(4x)
7.2. Exponential and Trigonometric Contraction 305
to 0, while the Mathematica implementation does not because automatic
simpliﬁcation does not permit the transformation
tan(4x)→sin(4x)/cos(4x).
Exercises
1. Determine if each of the following expressions is in exponential-contracted
form. If the expression is not in exponential-contracted form, transform it
to this form.
(a)1
(1+exp( x))(1+exp( y)).
(b) exp(( x+y)(x−y)).
(c) exp(( a+b)exp(x))exp(y).
2. Analgebraic expression uis inlog-contracted form if it satisﬁes the follow-
ing two properties.
(a) A sum in uhas at most one operand that is a logarithm.
(b) A product in uthat has an operand that is a logarithm does not also
have an operand that is an integer or fraction.
For example, aln(x)+aln(y)+(ln( x))2is in log-contracted form, while
ln(x)+ln( y)+2ln( x)i sn o t .A n algebraic expression can be transformed
to log-contracted form by applying the transformations
ln(u)+ln( v)→ln(uv), (7.40)
nln(u)→ln(un), (7.41)
where nis an integer or fraction. If a product contains more than one
logarithm, ( 7.41) is applied to the ﬁrst operand that is a logarithm. Give
a procedureContract
log(u) that transforms an algebraic expression uto
log-contracted form.
3. TheContract
expalgorithmencountersadivisionby0ifthetransformation
rules transform a sub-expression in a denominator to 0. For example, this
occurs with 1 /(exp(2 x)−(exp(x))2). Modify the algorithm so that it
recognizes this situation and returns the global symbol Undeﬁned when
it occurs.
4. Let ube analgebraic expression . Give a procedure for Simplify
exp(u)
which rationalizes uand then exponentially contracts the numerator and
denominator of the resulting expression. If the denominator contracts to0, the procedure returns the global symbol Undeﬁned . Your procedure
should simplify Expression ( 7.29)t o0 .
5. Find the trigonometric-contracted form of sin( x)cos
2(x)cos(2 x).
6. Verify Equation ( 7.35)f o rneven and Equation ( 7.36)f o rneven and n
odd.
306 7. Exponential and Trigonometric Transformations
7. Let ube a power. Give a procedure Contract
trig
power(u) that does the
following.
(a) If the exponent of uis a positive integer and the base is a sine or
cosine, then contract uusing Equation ( 7.35)o rE q ua t i o n( 7.36).
The ﬂoor function is obtained in Maple and MuPAD with floorand
in Mathematica with Floor.
(b) If the exponent of uis not a positive integer or the base is not a sine
or cosine, then return u.
8. TheContract
trigalgorithm encounters a division by 0 if the transforma-
tion rules transform a sub-expression in a denominator to 0. For example,
this occurs with 1 /(sin(2x)−2sin(x)cos(x)). Modify the algorithm so
that it recognizes this situation and returns the global symbol Undeﬁned
when it occurs.
9. (a) State and derive the formulas similar to Equation ( 7.35)o rE q ua t i o n
(7.36)f o rs i n hn(θ)a n dc o s hn(θ).
(b) Modify the algorithm Contract
trigso that it also contracts the hy-
perbolic functions sinh and cosh.
Identities for sinh and cosh are given in Exercise 9, page287.
10. This exercise refers to the Trig
formoperator described in Exercise 8, page
211. Modify this procedure so that it evaluates	
sinm(ax)cosn(ax)dxby
transforming sinm(ax)c o sn(ax)to contractedform andthenapplyingthe
Integraloperator to the contracted form.
11. Each of the following expressions simpliﬁes to 0. Is this simpliﬁcation
obtained bySimplify
trig? If 0 is obtained, then explain how this is done.
If not, explain why not.
(a) tan( x/2)−(sin(x)/(1+cos( x))).
(b) sin2(15π/16)+cos2(π/16)−1.
(c) sin2(x2−1)+cos2i
1−x2J
−1.
(d) sin2W
x+1
x}
+cos2Wx2+1
x}
−1.
(e) sinQ
xQ
1+π
6xww
−√
3/2s i n (x)−1/2s i n (x).
(f) sinQi
sin2(x)+cos2(x)J
(x+π/6)w
−√
3/2s i n (x)−1/2s i n (x).
(g) 8 cos3(2π/7)+4 cos2(2π/7)−4c o s ( 2 π/7)−1.
Further Reading
SeeHobson[ 47]forotherapproachestotrigonometricexpansionandcontraction.
Gutierrez and Recio [ 42] discuss new algorithms for trigonometric simpliﬁcation
and some applications to robotics.
Bibliography
[1] Williams W. Adams and Philippe Loustaunau. An Introduction to
Gr¨obner Bases . Graduate Studies in Mathematics, Volume 3. Amer-
ican Mathematical Society, Providence, RI, 1994.
[2] Alkiviadis G. Akritas. Elements of Computer Algebra with Applica-
tions. John Wiley & Sons, New York, 1989.
[3] Michael Artin. Algebra . Prentice Hall, Inc., Englewood Cliﬀs, NJ,
1991.
[ 4 ]E .J .B a r b e a u . Polynomials . Springer-Verlag, New York, 1989.
[5] David Barton and Richard Zippel. Polynomial decomposition algo-
rithms. Journal of Symbolic Computation , 1(1):159–168, 1985.
[6] Thomas Becker, Volker Weispfenning, and Heinz Kredel. Gr¨obner
bases, A Computational Approach to Commutative Algebra . Springer-
Verlag, New York, 1993.
[7] Laurent Bernardin. A review of symbolic solvers. SIGSAM Bulletin ,
30(1):9–20, March 1996.
[8] Laurent Bernardin. A review of symbolic solvers. In Michael J.
Wester, editor, Computer Algebra Systems, A Practical Guide , pages
101–120. John Wiley & Sons, Ltd., New York, 1999.
[9] A. S. Besicovitch. On the linear independence of fractional powers of
integers. J. London Math. Soc. , 15:3–6, 1940.
307
308 Bibliography
[10] Garrett Birkhoﬀ and Saunders Mac Lane. A Survey of Modern Al-
gebra. A K Peters, Ltd., Natick, MA, 1997.
[11] E. Bond, M. Auslander, S. Grisoﬀ, R. Kenney, M. Myszewski, J. Sam-
met, R. Tobey, and S. Zilles. Formac–An experimental formula ma-
nipulation compiler. In Proc. 19th ACM National Conference , pages
K2.1–1–K2.1–11, August 1964.
[12] William E. Boyce and Richard C. DiPrima. Elementary Diﬀerential
Equations . Sixth Edition. John Wiley & Sons, New York, 1997.
[13] Manuel Bronstein. Symbolic Integration I, Transcendental Functions .
Springer-Verlag, New York, 1997.
[14] W. S. Brown. On Euclid’s algorithm and the computation of polyno-
mial greatest common divisors. Journal of the Association for Com-
puting Machinery , 18(4):478–504, October 1971.
[15] W. S. Brown. The subresultant prs algorithm. ACM Transactions
on Math. Software , 4(3):237–249, September 1978.
[16] W. S. Brown and J. F. Traub. On Euclid’s algorithm and the theory of
subresultants. Journal of the Association for Computing Machinery ,
18(4):505–514, October 1971.
[17] B. Buchberger, G. E. Collins, R. Loos, and R. Albrecht. Com-
puter Algebra, Symbolic and Algebraic Computation . Second Edition.
Springer-Verlag, New York, 1983.
[18] Bruno Buchberger. Gr¨ obner bases: An algorithmic method in poly-
nomial ideal theory. In N. K. Bose, editor, Recent Trends in Mul-
tidimensional Systems Theory , pages 184–232. D. Reidel Publishing
Company, Dordrecht, Holland, 1985.
[19] Ronald Calinger. Classics of Mathematics . Moore Publishing Com-
pany Inc., Oak Park, IL, 1982.
[20] Shang-Ching Chou. Mechanical Geometry Theorem Proving .D .R e i -
del Publishing Company, Boston, 1988.
[21] Barry A. Cipra. Do mathematicians still do math. Science , 244:769–
770, May 19, 1989.
[22] Henri Cohen. A Course in Computational Algebraic Number Theory .
Springer-Verlag, New York, 1993.
Bibliography 309
[23] J. S. Cohen, L. Haskins, and J. P. Marchand. Geometry of equilib-
rium conﬁgurations in the ising model. Journal of Statistical Physics ,
31(3):671–678, June 1983.
[24] Joel S. Cohen. Computer Algebra and Symbolic Computation: Math-
ematical Methods . A K Peters, Natick, MA, 2002.
[25] George Collins. Subresultants and reduced polynomial remainder
sequences. J. ACM , 14:128–142, January 1967.
[26] George Collins. The calculation of multivariate polynomial resul-
tants. J.ACM , 18(4):515–532, October 1971.
[27] George Collins. Computer algebra of polynomials and rational func-
tions. American Mathematical Monthly , 80(7):725–754, September
1973.
[28] Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest.
Introduction to Algorithms . McGraw-Hill, New York, 1989.
[29] J. H. Davenport, Y. Siret, and E. Tournier. Computer Algebra, Sys-
tems and Algorithms for Algebraic Computation . Academic Press,
New York, 1988.
[30] P. J. Davis and R. Hersh. The Mathematical Experience .B i r k h ¨ auser,
Boston, MA, 1981.
[31] Richard A. Dean. Classical Abstract Algebra .H a r p e ra n dR o w ,N e w
York, 1990.
[32] William R. Derrick and Stanley I. Grossman. Diﬀerential Equations
with Applications . Third Edition. West Publishing Company, St.
Paul, MN, 1987.
[33] F. Dorey and G. Whaples. Prime and composite polynomials. Journal
of Algebra , 28:88–101, 1974.
[34] H. T. Engstrom. Polynomial substitutions. A m e r .J .o fM a t h e m a t i c s ,
63:249–255, 1941.
[35] James F. Epperson. An Introduction to Numerical Methods and Anal-
ysis. John Wiley & Sons, New York, 2002.
[36] R. J. Fateman. Macsyma’s general simpliﬁer. philosophy and op-
eration. In V.E. Lewis, editor, Proceedings of MACSYMA’s Users’
Conference , Washington, D.C., June 20–22 1979, pages 563–582. MIT
Laboratory for Computer Science, Cambridge, MA, 1979.
310 Bibliography
[37] Richard J. Fateman. Symbolic mathematics system evaluators. In
M i c h a e lJ .W e s t e r ,e d i t o r , Computer Algebra Systems, A Practical
Guide, pages 255–284. John Wiley & Sons, Ltd., New York, 1999.
[38] Richard J. Gaylord, N. Kamin, Samuel, and Paul R. Wellin. An
Introduction to Programming with Mathematica, Second Edition .
Springer-Verlag, New York, 1996.
[39] K.O. Geddes, S.R. Czapor, and G. Labahn. Algorithms for Computer
Algebra . Kluwer Academic Publishers, Boston, 1992.
[40] J¨urgen Gerhard, Walter Oevel, Frank Postel, and Stefan Wehmeier.
MuPAD Tutorial, English Edition . Springer-Verlag, New York, 2000.
[41] John W. Gray. Mastering Mathematica, Programming Methods and
Applications . Second Edition. Academic Press, New York, 1997.
[42] J. Gutierrez and T. Recio. Advances on the simpliﬁcation of sine-
cosine equations. Journal of Symbolic Computation , 26(1):31–70,
July 1998.
[43] G. H. Hardy and E. M. Wright. An Introduction To The Theory of
Numbers . Oxford at The Clarendon Press, London, 1960.
[44] K. M. Heal, M. L. Hansen, and K. M. Rickard. Maple 6 Learning
Guide. Waterloo Maple Inc., Waterloo, ON, Canada, 2000.
[45] Andr´ eH e c k . Introduction to Maple . Second Edition. Springer-Verlag,
New York, 1996.
[46] I. N. Herstein. Topics in Algebra . Second Edition. Xerox Publishing
Company, Lexington, MA, 1975.
[47] E. W. Hobson. Treatise on Plane and Advanced Trigonometry .S e v -
enth Edition. Dover Publications, Inc., New York, 1957.
[48] Douglas R. Hofstadter. G¨odel, Escher, Bach: An Eternal Golden
Braid. Random House Inc., New York, 1980.
[49] David J. Jeﬀrey and Albert D. Rich. Simplifying square roots of
square roots by denesting. In Michael J. Wester, editor, Computer
Algebra Systems, A Practical Guide , pages 61–72. John Wiley & Sons,
Ltd., New York, 1999.
[50] Richard D. Jenks and Robert S. Sutor. Axiom, The Scientiﬁc Com-
putation System . Springer-Verlag, New York, 1992.
Bibliography 311
[51] N. Kajler, editor. Computer-Human Interaction in Symbolic Compu-
tation. Springer-Verlag, New York, 1998.
[52] Israel Kleiner. Field theory, from equations to axiomatization. part i.
American Mathematical Monthly , 106(7):677–684, August-September
1999.
[53] Israel Kleiner. Field theory, from equations to axiomatization. part ii.
American Mathematical Monthly , 106(9):859–863, November 1999.
[54] Morris Kline. Mathematics and The Search for Knowledge .O x f o r d
University Press, New York, 1985.
[55] D. Knuth. The Art of Computer Programming , volume 2. Second
Edition. Addison-Wesley, Reading, MA, 1981.
[56] Donald Knuth, Ronald Graham, and Oren Patashnik. Concrete
Mathematics, A Foundation For Computer Science . Addison-Wesley,
Reading, MA, 1989.
[57] K. Korsvold. An on-line algebraic simplify program. Technical report,
Stanford University, 1965. Stanford University Artiﬁcial Intelligence
Project, Memorandum 37.
[58] J. S. Kowalik, editor. Coupling Symbolic and Numerical Computing
in Expert Systems . Elsevier Science Publishers, New York, 1986.
[59] Dexter Kozen and Susan Landau. Polynomial decomposition algo-
rithms. Journal of Symbolic Computation , 7:445–456, 1989.
[60] Susan Landau. Simpliﬁcation of nested radicals. SIAM J. Comput. ,
21(1):85–110, February 1992.
[61] Ulrich Libbrecht. Chinese Mathematics in the Thirteenth Century .
MIT Press, Cambridge, MA, 1973.
[62] R. Lidl and H. Niederreiter. Introduction to Finite Fields and their
Applications . Revised Edition. Cambridge University Press, New
York, 1994.
[63] C. C. Lin and L. A. Segel. Mathematics Applied to Deterministic
Problems in the Natural Sciences . Classics in Applied Mathematics
1. Society for Industrial and Applied Mathematics, Philadelphia,
1988.
[64] John D. Lipson. Elements of Algebra and Algebraic Computing .B e n -
jamin/Cummings, Menlo Park, CA, 1981.
312 Bibliography
[65] Stephen B. Maurer and Anthony Ralston. Discrete Algorithmic
Mathematics . A K Peters, Ltd., Natick, MA, 1998.
[66] Maurice Mignotte. Mathematics for Computer Algebra . Springer-
Verlag, New York, 1991.
[67] Maurice Mignotte and Doru S ¸tef˘anescu. Polynomials, An Algorith-
mic Approach . Springer-Verlag, New York, 1999.
[68] Bhubaneswar Mishra. Algorithmic Algebra . Springer-Verlag, New
York, 1993.
[69] M. B. Monagan, K. O. Geddes, K. M. Heal, G. Labahn, S. M.
Vorkoetter, and J. McCarron. Maple 6 Programming Guide .W a -
terloo Maple Inc., Waterloo, ON, Canada, 2000.
[70] Joel Moses. Symbolic Integration . PhD thesis, MIT, September 1967.
[71] Joel Moses. Algebraic simpliﬁcation: A guide for the perplexed.
Communications of the ACM , 14(8):527–537, August 1971.
[72] George M. Murphy. Ordinary Diﬀerential Equations and Their So-
lutions . D. Van Nostrand, New York, 1960.
[73] David Musser. Algorithms for Polynomial Factorization .P h Dt h e s i s ,
Department of Computer Science, University of Wisconsin, 1971.
[74] Paul J. Nahin. An Imaginary Tale, The Story of√
−1. Princeton
University Press, Princeton, NJ, 1998.
[75] Jurg Nievergelt, J. Craig Farrar, and Edward M. Reingold. Com-
puter Approaches to Mathematical Problems . Prentice-Hall, Engle-
wood Cliﬀs, NJ, 1974.
[76] F. S. Nowlan. Objectives in the teaching college mathematics. Amer-
ican Mathematical Monthly , 57(1):73–82, February 1950.
[77] R. Pavelle, M. Rothstein, and J. P. Fitch. Computer algebra. Scien-
tiﬁc American , 245:136–152, 1981.
[78] Louis L. Pennisi. Elements of Complex Variables . Holt, Rinehart and
Winston, New York, 1963.
[79] Charles Pinter. A Book of Abstract Algebra . Second Edition.
McGraw-Hill, New York, 1990.
Bibliography 313
[80] Marcelo Polezzi. A geometrical method for ﬁnding an explicit formula
for the greatest common divisor. American Mathematical Monthly ,
104(5):445–446, May 1997.
[81] Frank Postel and Paul Zimmermann. Solving ordinary diﬀerential
equations. In Michael J. Wester, editor, Computer Algebra Systems,
A Practical Guide , pages 191–209. John Wiley & Sons, Ltd., New
York, 1999.
[82] T. W. Pratt. Programming Languages, Design and Implementation .
Second Edition. Prentice Hall, Englewood Cliﬀs, NJ, 1984.
[83] Gerhard Rayna. Reduce, Software for Algebraic Computation .
Springer-Verlag, New York, 1987.
[84] D. Richardson. Some undecidable problems involving elementary
functions of a real variable. Journal of Symbolic Logic , 33(4):511–
520, December 1968.
[85] J. F. Ritt. Prime and composite polynomials. Trans. Am. Math.
Soc., 23:51–66, 1922.
[86] P. Sconzo, A. LeSchack, and R. Tobey. Symbolic computation of f
andgseries by computer. The Astronomical Journal , 70(1329):269–
271, May 1965.
[87] George F. Simmons. Diﬀerential Equations with Applications and
Historical Notes . Second Edition. McGraw-Hill, New York, 1991.
[88] George F. Simmons. Calculus with Analytic Geometry . Second Edi-
tion. McGraw-Hill, New York, 1996.
[89] Barry Simon. Symbolic magic. In Michael J. Wester, editor, Com-
puter Algebra Systems, A Practical Guide , pages 21–24. John Wiley
& Sons, Ltd., New York, 1999.
[90] Barry Simon. Symbolic math powerhouses revisited. In Michael J.
Wester, editor, Computer Algebra Systems, A Practical Guide .J o h n
Wiley & Sons, Ltd., New York, 1999.
[91] Trevor J. Smedley. Fast methods for computation with algebraic
numbers. Research Report CS-90-12, Department of Computer Sci-ence, University of Waterloo, May 1990.
[92] Jerome Spanier and Keith B. Oldham. An Atlas of Functions .H e m i -
sphere Publishing Corporation, New York, 1987.
314 Bibliography
[93] Frederick W. Stevenson. Exploring the Real Numbers . Prentice Hall,
Upper Saddle River, NJ, 2000.
[94] David R. Stoutemyer. Crimes and misdemeanors in the com-
puter algebra trade. Notices of the American Mathematical Society ,
38(7):778–785, September 1991.
[95] R. Tobey, R. Bobrow, and S. Zilles. Automatic simpliﬁcation in
Formac. In Proc. AFIPS 1965 Fall Joint Computer Conference ,v o l -
ume 27, pages 37–52. Spartan Books, Washington, DC, November
1965. Part 1.
[96] Joachim von zur Gathen and J¨ urgen Gerhard. Modern Computer
Algebra . Cambridge University Press, New York, 1999.
[97] Paul Wang and Barry Trager. New algorithms for polynomial square
free decomposition over the integers. SIAM Journal of Comp. , 8:300–
305, 1979.
[98] Mark Allen Weiss. Data Structures and Problem Solving Using C++ .
Second Edition. Addison-Wesley, Reading, MA, 2000.
[99] Clark Weissman. Lisp 1.5 Primer . Dickenson Publishing Company,
Belmont, CA, 1967.
[100] Michael J. Wester. Computer Algebra Systems, A Practical Guide .
John Wiley & Sons, Ltd., New York, 1999.
[101] F. Winkler. Polynomial Algorithms in Computer Algebra . Springer-
Verlag, New York, 1996.
[102] Stephen Wolfram. The Mathematica Book . Fourth Edition. Cam-
bridge University Press., New York, 1999.
[103] D. Wooldridge. An algebraic simplify program in Lisp. Technical
report, Stanford University, December 1965. Artiﬁcial Intelligence
Project, Memo 11.
[104] W. A. Wulf, M. Shaw, P. Hilﬁnger, and L. Flon. Fundamental Struc-
tures of Computer Science . Addison-Wesley, Reading, MA, 1981.
[105] Chee Keng Yap. Fundamental Problems of Algorithmic Algebra .O x -
ford University Press, New York, 2000.
[106] David Y. Y. Yun. On square-free decomposition algorithms. In R. D.
Jenks, Proceedings of the 1976 ACM Symposium of Symbolic and
Algebraic Computation , pages 26–35. ACM, New York, 1976.
Bibliography 315
[107] David Y. Y. Yun and David R. Stoutemyer. Symbolic mathematical
computation. In J. Belzer, A.G. Holzman, and A. Kent, editors,
Encyclopedia of Computer Science and Technology , volume 15, pages
235–310. M. Dekker, New York, 1980.
[108] Richard Zippel. Eﬀective Polynomial Computation .K l u w e r A c a -
demic Publishers, Boston, 1993.
[109] Daniel Zwillinger. Handbook of Diﬀerential Equations .A c a d e m i c
Press, Boston, MA, 1989.
Index
Absolute
value(u),34,123,199
Actual parameters
for a procedure, 134
of a function, 133
Adjoin(x,L),72
Akritas, A., 26
Algebraic expression
conventional structure, 84
expanded form, 251
exponential-contracted
form,289
exponential-expanded
form,276,286
log-contracted form, 305
log-expanded form, 286
simpliﬁed structure, 93
trigonometric-contracted
form,293
trigonometric-expanded
form,281,287
Algebraic
expand(u),34,253,259
Algebraic
expression (u),194
Assignment, 38
Atomic expression, 81
Automatic simpliﬁcation, 52
context of, 54
Automatically simpliﬁed algebraic
expression ( ASAE),93Automatic
simplify(u),83
Axiom,6
base(u),272
Bernardin, L., 27
Bernoulli(u,x,y),242
Bilinear
form(u,x,y),237
Buchberger, B., 26
By
parts(f,x),212
CAIN (Computer Algebra
Information Network), 26
Cancel(u),273
CAS,2
Chou, S.C., 27
Cipra, B.A., 27
Coeﬃcient (u, x, j),34,64
Coeﬃcient
alternate(u,x,j),239
Coeﬃcient
gpe(u,x,j),230,233
Coeﬃcient
list(u,x),223
Coeﬃcient
 monomial
 gpe
(u,x),232
Coeﬃcient
monomial
sv(u,x),222
Coeﬃcient
sv(u,x,j),218,222
Coeﬃcient
vars(u,L),,247
Coeﬀ
var
monomial (u,S),237
Cohen, Joel S., 10
Collect
terms(u,S),248,249
Collect
terms
2(u,S),257
Comb(S,k),196
316
Index 317
Combine(u),257
Common
factors(u,v),272
Complete sub-expression, 109
Complete
sub
expressions (u),177
Compound expression, 81
Computer algebra, 2
Computer algebra language, 5
Computer algebra system (CAS), 2
commercial, 6
mathematical knowledge in, 8
COMPUTER ALGEBRA,
Algorithms, Systems
and Applications, 26
Concurrent structural
substitution, 115
Concurrent
substitute (u,S),115,195
Contain
parameters (u,x),194
Contract
exp(u),290,305
Contract
exp
rules(u),291
Contract
log(u),305
Contract
trig(u),296,306
Contract
trig
power(u),306
Contract
trig
rules(u),297
Curvature (f,x),150
Czapor, S.R., 26
Data objects, 39
logical expressions, 54
Davenport, J.H., 26
Decimal(u),34,123
Decision structures, 141
Default simpliﬁcation, 52
deg(u,S),230
deg(u,x),214,230
Degree
of a GME, 229
of a GPE, 230
Degree(u,x),34,63
Degree
alternate(u,x),239
Degree
general(u,x),239
Degree
gpe(u,v),238
Degree
monomial
gpe(u,v),238
Degree
monomial
sv(u,x),219
Degree
sv(u,x),217,220
Delete(x,L),73
Denominator (u),123,260,270Denominator (u,L),271
Derivative (u,x),34,182,196
Derivative
order(u,x,y),197
Derive,6
Diﬀerential equation
Bernoulli, 241
exact,157
homogeneous, 168
homogeneous second order, 169
integrating factor, 157
separable, 157
singular solution, 166
variation of parameters, 169
Diﬀerentiation
of factorials, 196
of undeﬁned functions, 196
Distance
point
line(u,x,y,p),151
Distribute (u),258
Eﬀective step in an algorithm, 120
Evaluate(u,n),50
Evaluation
in Maple, 52
in Mathematica, 52
in MuPAD, 52
multi-level, 50
single level, 50
suppressed, 50
Even
odd(u,x),144
Expand
exp(u),279,280,286
Expand
exp
rules(A),279,280,286
Expand
log(u),286
Expand
main
op,258
Expand
power(u,n),254,259
Expand
product(r,s),253
Expand
restricted(u,T),258
Expand
tan(u),288
Expand
trig(u),283,287
Expand
trig
rules(u),283,287
Expd
exp(u),278
exponent( u),272
Exponential contraction, 276,289
Exponential expansion, 276
Expression
main operator, 87
root node of tree, 87
318 Index
structure, 84
tree,87
branch,87
evaluation, 49
FandGseries,155
Factor(u),34
Fateman, R. J., 75
FG(n,t),156
Fibonacci numbers
recursive deﬁnition, 175
Find
min
deg(S,x),151
First(L),72
Fitch, J.P., 26
Floor function, 257,306
FORMAC computer algebra
system,155
Formal parameters
in MPL,140
of a function, 133
of a procedure, 133
Fraction ( fraction),92
Free
of(u,t),110,179,194
mathematical properties
of,242
Free
of
sort(S),246
Geddes, K.O., 26
General monomial expression
(GME)
coeﬃcient part, 224
computational deﬁnition, 225
mathematical deﬁnition, 224
variable part, 224
General polynomial expression
(GPE)
collected form, 248
computational deﬁnition, 225
degree of, 229
mathematical deﬁnition, 224
General rational expression (GRE)
computational deﬁnition, 261
mathematical deﬁnition, 259
Generalized coeﬃcients, 224
Generalized variables, 224
Gerhard, J., 26Global symbol, 137
GPE
to
mult(u),246
Haskins, L., 10
Heck, A., 7
Homogeneous
polynomial, 238
Homogeneous (M,N,x,y ),169
Homogeneous
 2(a,b,c,x),169
Homogeneous
 polynomial
(u,x,y),238
Horner(u,x),195
Identiﬁer
as a mathematical symbol or
variable,32
as a programming variable, 32
in MPL,32
ifstructure, 141
if-elsestructure, 142
Implicit
derivative (u,y,x,n),197
Inﬁnite recursive loop, 175
Integer ( integer),104
Integer
gcd(a,b),122
Integral
linear properties, 200
Integral(f,x),34,206
Integral
table(f,x),209
Integration
derivative divides method, 203
substitution method, 200
table,200
Iquot(a,b),122
Irem(a,b),122
Irrational numbers
in MPL,32
Iteration structures, 145
Iter
fact(n),79
Jenks, R.D., 6
Join(L,M,...,N ),72
Kajler, N., 27
Kind(u),104
Index 319
Kline, M., 26
Kowalik, J.S., 27
Labahn, G., 26
Lagrange
polynomial (P,x),153
lc(u,x),214,233
Leading
coeﬀ
degree
gpe
(u,x),238
Leading
Coeﬃcient
gpe(u,x),234,238
Leading
coeﬃcient
monomial
sv
(u,x),222
Leading
coeﬃcient
sv(u,x),220,222
Leading
numer
coeﬀ
(u,L),246
Legendre (n,x),191
Legendre polynomials, 189
iterative algorithm, 192
Limit(u,x,a),34
Lin, C.C., 10
Line(u,x,y),153
Linear diﬀerential
operator, 240
Linear
derivative
order
(u,x,y),240
Linear
factors(u,x),151
Linear
form(u,x),181
Linear
properties (f,x),209
Lipson, J.D., 26
List (list),100
Lists,71
empty list([ ]), 71
mathematical properties, 71
primitive operations, 72
use in MPL, 71
membership( ∈),73
Local environment of a procedure,
134
Local variables in a procedure, 134
low
deg(u,x),236
Macsyma, 7,21,55,256
Maple,3,4,6,7,14–16,44,54,127,
129,130,145,193,246,267,
277,287
improperlyposedexpressions, 127
list operations, 73set operations, 70
MPL reserved operators, 35
MPL reserved symbols, 33
Map(F,u),188
Map(G,u,y,...,z ),188
Marchand, J.P., 10
Mathematica, 7,12,40,46,54,94,
95,113,130,145,240,246,256,
276
list operations, 73
set operations, 70
diﬀerential equations, 36
MPL operators, 35
MPL reserved symbols, 33
Mathematical algorithm, 119
Mathematical operators
procedures for, 133
Mathematical pseudo-language
(MPL),29
Max(S),198
Max
exponent(u,x),198
Mignotte, M., 26
Mishra, B., 26
Monomial
gpe(u,v),226,227
Monomial
sv(u,x),215,217,218
MPL
general form of a
function, 133
general form of a
procedure, 135
mathematical algorithm, 58
operators
algebraic, 32
logical,36
relational, 36
reserved symbols
e,33
∅,70
false,33
ı,33
∞,33
π,33
true,33
Multi-branch structure, 142
MuPAD,7,18,47,54,145,267,277,
287
320 Index
list operations, 73
MPL reserved operators, 35
MPL reserved symbols, 33
set operations, 70
Normal simpliﬁcation operator, 269
Number
of
operands(u),105
Numerator
simpliﬁcation context, 130
Numerator (u),123,260,270
Numerator (u,L),271
Numerical (u),195
Numerical expression, 195
Numerical
coeﬃcient (u),152
Operand(u,i),34,43,105
Operand
list(u),151
Operator
binary inﬁx, 85
function postﬁx, 85
n-ary inﬁx, 85
structure based, 108
unary postﬁx, 85
unary preﬁx, 85
Operator evaluation
and automatic simpliﬁcation of
arguments, 54
Parentheses level
diﬀerent, 85
same,85
Pavelle, R., 26
Perpendicular
 line(u,x,y,p),150
Polynomial
degree,214
height,221
leading coeﬃcient, 214
multivariate
mathematical
deﬁnition, 221
single variable
computational
deﬁnition, 215
mathematical deﬁnition, 214
Polynomial sign, 247
Polynomial
gpe(u,v),226,228Polynomial
height(u,x),221
Polynomial
mv(u,S),222
Polynomial
sign(u,L),247
Polynomial
sign
var(u),247
Polynomial
sq2(u,x),222
Polynomial
sv(u,x),215,218
Polynomial
sv
unexp(u,x),222
Polynomial
xy(u,x,y),222
Power set, 196
Power
set(S),196
Precedence rules
conventional
algebraic expressions, 86
simpliﬁed
algebraic expressions, 93
Primitive operations
general polynomial
expressions, 225
simpliﬁed mathematical
expressions, 104
single variable
polynomials, 215
Procedure
body of,134
iterative, 79
Properly posed operation, 126
Quadratic
form(u,x),195
Radical
form(f,x),210
Rational number arithmetic, 31
Rational simpliﬁcation, 270,271
Rational-expanded form, 268,270
Rational
expand(u),270
Rational
form(f,x),210
Rational
gre(u,v),261,270
Rationalization of algebraic
expressions, 262
Rationalized form
of an algebraic expression, 263
Rationalize
expression (u),265
Rationalize
sum(u,v),265
Rational
simplify(u),123
Rational
sv(u,x),223
Rational
variables(u),262,270
Rayna, G., 7
Index 321
real,31
Real ( real),104
Rec
fact(n),80,172
Recurrence relation, 190
Recursion
redundant, 183,193,226,256,266,
277,282
Recursion in mathematics, 82
Recursive chain, 193
Recursivedeﬁnitionoralgorithm, 77
Recursive procedure, 80,172
Recursivestructureofmathematical
expressions, 80
Reduce,7
Remembering procedure calls
in Maple, 193
Remove
duplicates (L),151
Rest(L),72
Return(u),135
Reverse(L),73
Richardson, D., 145
Rothstein, M., 26
Rule-based programming
in Maple, 185
in Mathematica, 184
sci.math.symbolicdiscussionsite, 26
Segel, L.A., 10
Semantic capacity, 126
Separable
ode(M,N,x,y ),168
Separate
factors(u,x),148
Separate
sin
cos(u),152
Separate
variables(u,x,y),152
Sequential structural
substitution, 114
Sequential
substitute (u,L),114,195
Set (set),100
Set
free
of(u,S),180,194
Set
product(A,B),151
Sets,69
diﬀerence ( ∼),69
empty set ( ∅),70
intersection ( ∩),69
mathematical properties, 69
union ( ∪),69use in MPL, 69
membership ( ∈),70
SIGSAM(SpecialInterestGroupon
Symbolic and Algebraic
Manipulation), 26
Simpliﬁcation context, 128
Simpliﬁed structure
of algebraic expressions, 90
of diﬀerences, 90
of fractions, 92
of lists,100
of logical expressions, 97
of products, 90
of quotients, 92
of relational expressions, 96
of set expressions, 100
of sums,90
Simplify
exp(u),305
Siret, Y., 26
Solve(u,x),34
Solve
ode(w,x,y),34,161,162
Solve
ode
2(a,b,c,f,x,y ),170
Solve
quadratic(u,x),151
Solve
exact(M,N,x,y ),163
Stack,174
S¸tef˘anescu, D., 26
Stoutemyer, D.R., 26
Structural assumptions for conven-
tional algebraic expressions, 86
Structural assumptions for
simpliﬁed algebraic
expressions, 90
Structural substitution
multiple, 114
Substitute (u,t=r),34,111
Substitute (u,v),195
Substitution
and evaluation, 112
structural, 111
Substitution
 method(f,x),206
Sutor, R.S., 6
Symbol ( symbol),104
Symbol manipulation, 2
Symbol manipulation system, 2
Symbolic programming language, 5
322 Index
SymbolicNet, 26
Symbols(u),194
Symmetric (u,x,y),151
Tangent
line(f,x,a),136
Taylor
2(u,x,y,a,b,n ),153
Taylor
ode(w,x,y,a,b,n ),155
Termination condition
in a recursive procedure, 172
in a recursive
procedure, 80
Total
degree(u),238
Tournier, E., 26
Transformation rule sequence, 182
rule convention, 184
Transformation rules
CF(Common
factors
(u,v)),272
FO(Factor
out(u)),272
GMEALT (alternate general
monomial expression), 238
GME(general monomial
expression), 225
GPE(general polynomial
expression), 225
ND(Numerator (u),
Denominator (u)),260
DERIV(Derivative
(u,x)),182
LNC(Leading
numer
coeﬀ
(u,L)),246
MON(singlevariablemonomial),
215
NUM(Numerical (u)),195POLY(singlevariablepolynomial),
215
TRIGSUB (Trig
substitute
(u)),186
VAR(Variables(u)),227
Transform
ode(w,x,y),162,240
Transform
ode
2(w,x,y),241
Tree-size of an expression, 195
Tree
size(u),195
Trial
substitutions (f),209
Trig
form(f,x),211,306
Trig
free
of(u),194
Trigonometric contraction, 293
Trigonometric expansion, 281
Trig
substitute (u),187,303
Trig
substitute
 map(u),190
Unassign(u),52
Variable evaluation, 50
Variables(u),227,237
Variation
of
param
(y1,y2,f,a,x),170
von zur Gathen, J., 26
Wester, M., 7,26
Winkler, F., 26
Wolfram, S., 7
Yap, C.K., 26
Yun, D.Y.Y., 26
Zero equivalence operator, 269
Zero equivalence problem, 145
Zippel, R., 26

A K
PETERS Computer Algebra and Symbolic ComputationCohenElementary Algorithms
A K Peters, Ltd.ISBN 1-56881-158-6Computer Algebra and
Symbolic Computation
Elementary AlgorithmsJOEL S. COHEN
The author explores the structure and implementation of computer
algebra algorithms as well as the mathematical and computationalconcepts behind them.
This book:
•Is accessible to students and appeals to professionals
•Introduces mathematical concepts as needed
•Contains a CD with the entire text, active reference hyperlinks,
and complete algorithms
Computer Algebra and Symbolic Computation  bridges the gap
between software manuals, which only explain how to use computeralgebra programs such as Mathematica, Maple, Derive , etc., and
graduate level texts, which only describe algorithms.
For a more advanced look at computer algebra, including the
application of algorithms to methods such as automatic simplification,polynomial decomposition, and polynomial factorization, see Computer
Algebra and Symbolic Computation: Mathematical Methods.
